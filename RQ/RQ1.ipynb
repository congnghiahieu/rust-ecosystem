{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdates\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmdates\u001b[39;00m\n\u001b[1;32m      6\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../utils\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "sys.path.append('../utils')\n",
    "import database as db\n",
    "from utils import plot_evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql(\"SELECT id, package, sfp_id, published, vul_version FROM cve\", con=db.conn)\n",
    "if not os.path.exists(\"fig/rq1\"):\n",
    "    os.makedirs(\"fig/rq1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type of Vulnerabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql(\"SELECT id, package, sfp_id, published, vul_version FROM cve\", con=db.conn)\n",
    "temp = df[\"sfp_id\"].apply(lambda x: len(eval(x)))\n",
    "temp = temp[temp.apply(lambda x: False if x==0 else True)]\n",
    "categorized_vul = df[df[\"sfp_id\"].apply(lambda x: False if len(eval(x))==0 else True)]\n",
    "print(\"# vulnerablities:\"+str(len(df)))\n",
    "print(f\"# categorized vulnerabilities: {len(categorized_vul)}\")\n",
    "print(f\"# minimum vulnerability categories: {temp.min()}\")\n",
    "print(f\"# maximum vulnerability categories: {temp.max()}\")\n",
    "print(f\"# median vulnerability categories: {temp.median()}\")\n",
    "print(f\"# average vulnerability categories: {temp.sum()/len(categorized_vul)}\")\n",
    "print(f\"std of vulnerability categories: {temp.std()}\")\n",
    "print()\n",
    "\n",
    "cve_type = dict()\n",
    "cve_type[\"non category\"] = 0\n",
    "men_sync_cnt = 0\n",
    "mem_cnt = 0\n",
    "for index, row in df.iterrows():\n",
    "    categories = eval(row[\"sfp_id\"])\n",
    "    if categories!= None and len(categories):\n",
    "        for cat in categories:\n",
    "            if cve_type.get(cat) == None:\n",
    "                cve_type[cat] = 1\n",
    "            else:\n",
    "                cve_type[cat] += 1\n",
    "    else:\n",
    "        cve_type[\"non category\"]+=1\n",
    "    if 'Memory Management' in categories or 'Memory Access' in categories or 'Synchronization' in categories:\n",
    "        men_sync_cnt += 1\n",
    "    if 'Memory Management' in categories or 'Memory Access' in categories:\n",
    "        mem_cnt += 1\n",
    "num_cateorized_vul = len(df)-cve_type[\"non category\"]\n",
    "cve_type = sorted(cve_type.items(), key=lambda kv: kv[1])\n",
    "print(f\"# mem_sync_vul: {men_sync_cnt} ({men_sync_cnt/num_cateorized_vul*100}%) \")\n",
    "print(f\"# mem_cnt: {mem_cnt} ({mem_cnt/num_cateorized_vul*100}%) \")\n",
    "total = temp.sum()\n",
    "# print(f\"# count: {total}\")\n",
    "for t in cve_type:\n",
    "    print(f\"{t[0]:<25} {t[1]:<5} {t[1]/num_cateorized_vul*100}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Vulnerability life spans -- When are vulnerabilities introduced? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import datetime\n",
    "import scipy.stats\n",
    "\n",
    "df = pd.read_sql(\"SELECT cve_id, introduced_date FROM commit_life_spans\", con=db.conn)\n",
    "df_vul = pd.read_sql(\"SELECT id, published, sfp_id FROM cve2\", con=db.conn)\n",
    "df = df[df['introduced_date'].apply(lambda x: x is not None)]\n",
    "# get earliest introduced date for each vulnerability\n",
    "df = df.groupby(['cve_id']).min()\n",
    "df = df.reset_index()\n",
    "# get published date & vul types for each vulnerability\n",
    "for _, row in df.iterrows():\n",
    "    cve_id = row['cve_id']\n",
    "    ids = list(df_vul['id'].apply(lambda x: eval(x)))\n",
    "    published = None\n",
    "    for id in ids:\n",
    "        if cve_id in id:\n",
    "            published = df_vul[df_vul['id']==str(id)]['published'].values[0]\n",
    "            df.loc[df['cve_id']==cve_id, 'published'] = published\n",
    "            df.loc[df['cve_id']==cve_id, 'sfp_id'] = df_vul[df_vul['id']==str(id)]['sfp_id'].values[0]\n",
    "            break\n",
    "\n",
    "# calculate number of vulnerabilities introduced per day\n",
    "introduced = df[\"introduced_date\"]\n",
    "introduced = introduced.apply(lambda x: pd.to_datetime(datetime.datetime.strptime(x.split()[0],\"%Y-%m-%d\").strftime(\"%Y-%m\")))\n",
    "num_introduced_per_day = introduced.value_counts().sort_index()\n",
    "num_introduced_acc = num_introduced_per_day.cumsum()\n",
    "# plot the introduced vulnerabilities over time\n",
    "plot_evolution(num_introduced_acc.index, num_introduced_acc.values, 'Number of vulnerabilities', 'fig/rq1/vulnerabilities_introduced_over_time.png')\n",
    "# calculate R-square value\n",
    "num_introduced_acc = num_introduced_acc[5:-15]\n",
    "days = (num_introduced_acc.index - num_introduced_acc.index[0]).days\n",
    "slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(days, num_introduced_acc.values)\n",
    "print(f\"r2 from 2015-07 to 2020-02: {r_value**2}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CDF of disclosure duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# get time between introduced & disclosed\n",
    "introduced = df['introduced_date'].apply(lambda x: pd.to_datetime(x, utc=True))\n",
    "published = df['published'].apply(lambda x: pd.to_datetime(x, utc=True))\n",
    "df['disclosed_duration'] = (published - introduced).dt.days\n",
    "\n",
    "df = df[df['disclosed_duration'] > 0]\n",
    "days = df['disclosed_duration']\n",
    "print(f\"Disclosure Duration Mean={days.mean()}\")\n",
    "print(f\"Disclosure Duration Median={days.median()}\")\n",
    "print(f\"Disclosure Duration Min={days.min()}\")\n",
    "print(f\"Disclosure Duration Max={days.max()}\")\n",
    "print(f\"Disclosure Duration Std={days.std()}\")\n",
    "print(\"=\"*20)\n",
    "\n",
    "# check statistics of disclosed duration\n",
    "longest = df[df['disclosed_duration']==df['disclosed_duration'].max()]\n",
    "print(\"The vulnerability with the longest disclosed duration: \")\n",
    "print(longest.to_dict('records')[0])\n",
    "#  disclosure duration less than 30 day\n",
    "temp = df[df['disclosed_duration']<30]\n",
    "print(f\"# the vulnerability with disclosed duration < 30: {len(temp)} ({len(temp)/len(df)*100}%)\")\n",
    "mean_temp = (np.array(temp['introduced_date'], dtype='datetime64[s]')\n",
    "        .view('i8')\n",
    "        .mean()\n",
    "        .astype('datetime64[s]'))\n",
    "mean_df = (np.array(df['introduced_date'], dtype='datetime64[s]')\n",
    "        .view('i8')\n",
    "        .mean()\n",
    "        .astype('datetime64[s]'))\n",
    "print(f\"average introduced date of < 30: {mean_temp}\")\n",
    "print(f\"average introduced date of total: {mean_df}\")\n",
    "\n",
    "# plot CDF of disclosure duration\n",
    "import numpy as np\n",
    "days = np.array(list(df['disclosed_duration']))\n",
    "# compute the CDF\n",
    "cdfx = np.sort(days)\n",
    "cdfy = np.linspace(1 / len(days), 1.0, len(days))\n",
    "# plot the CDF\n",
    "plot_evolution(cdfx, cdfy, 'CDF', 'fig/rq1/vulnerabilities_disclosure_duration.png', evol=False, xlog=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disclosure duration across vul types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ranksums\n",
    "interest_cats = ['Memory Management', 'Memory Access' , 'Synchronization', 'Tainted Input', 'Resource Management', 'Exception Management', 'Cryptography',\\\n",
    "                 'Other', 'Risky Values', 'Path Resolution', 'Information Leak', 'Privilege', 'Predictability', 'Authentication', 'API', 'Access Control', 'Failure to Release Memory']\n",
    "frequent_cats = ['Memory Management', 'Memory Access' , 'Synchronization', 'Tainted Input', 'Resource Management', 'Exception Management', 'Cryptography',\\\n",
    "                    'Other', 'Risky Values']\n",
    "rare_cats = ['Path Resolution', 'Information Leak', 'Privilege', 'Predictability', 'Authentication', 'API', 'Access Control', 'Failure to Release Memory']\n",
    "frequent_durations = []\n",
    "rare_durations = []\n",
    "for cat in interest_cats:\n",
    "    temp = df[df['sfp_id'].apply(lambda x: True if cat in x else False)]\n",
    "    days = temp['disclosed_duration']\n",
    "    if cat in frequent_cats:\n",
    "        frequent_durations.append(days.median())\n",
    "    elif cat in rare_cats:\n",
    "        rare_durations.append(days.median())\n",
    "    print(f\"{cat}: {days.median()} {len(days)}\")\n",
    "\n",
    "# Wilcoxon rank-sum tests\n",
    "print(ranksums(frequent_durations, rare_durations, alternative='greater', nan_policy='omit'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Vulnerability life spans --  When are vulnerabilities fixed? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql(\"SELECT cve_id, fix_date FROM commit_life_spans\", con=db.conn)\n",
    "df_vul = pd.read_sql(\"SELECT id, published, sfp_id FROM cve2\", con=db.conn)\n",
    "df = df[df['fix_date'].apply(lambda x: x is not None)]\n",
    "# get latest fix date for each vulnerability\n",
    "df = df.groupby(['cve_id']).max()\n",
    "df = df.reset_index()\n",
    "# get published date for each vulnerability\n",
    "for _, row in df.iterrows():\n",
    "    cve_id = row['cve_id']\n",
    "    ids = list(df_vul['id'].apply(lambda x: eval(x)))\n",
    "    published = None\n",
    "    for id in ids:\n",
    "        if cve_id in id:\n",
    "            published = df_vul[df_vul['id']==str(id)]['published'].values[0]\n",
    "            df.loc[df['cve_id']==cve_id, 'published'] = published\n",
    "            df.loc[df['cve_id']==cve_id, 'sfp_id'] = df_vul[df_vul['id']==str(id)]['sfp_id'].values[0]\n",
    "            break\n",
    "\n",
    "# get time between disclosed & fixed\n",
    "fixed = df['fix_date'].apply(lambda x: pd.to_datetime(x, utc=True))\n",
    "published = df['published'].apply(lambda x: pd.to_datetime(x, utc=True))\n",
    "df['fix_duration'] = (fixed-published).dt.days\n",
    "print(f\"# fixed before disclosure: {len(df[df['fix_duration'] <= 0])}\")\n",
    "print(f\"# fixed after disclosure: {len(df[df['fix_duration'] > 0])}\")\n",
    "days = df['fix_duration']\n",
    "# print(df[df['disclosed_duration']>2500])\n",
    "print(f\"Fix Duration Mean={days.mean()}\")\n",
    "print(f\"Fix Duration Median={days.median()}\")\n",
    "print(f\"Fix Duration Min={days.min()}\")\n",
    "print(f\"Fix Duration Max={days.max()}\")\n",
    "print(f\"Fix Duration Std={days.std()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CDFs of fix duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot CDF of fix duration\n",
    "import numpy as np\n",
    "days = np.array(list(df['fix_duration']))\n",
    "# compute the CDF\n",
    "cdfx = np.sort(days)\n",
    "cdfy = np.linspace(1 / len(days), 1.0, len(days))\n",
    "# plot the CDF\n",
    "plot_evolution(cdfx, cdfy, 'CDF', 'fig/rq1/vulnerabilities_fix_duration.png', evol=False, xlog=True)\n",
    "\n",
    "print((df[df['fix_duration']>680]))\n",
    "days = df[df['fix_duration']>0]['fix_duration']\n",
    "print(f\"Fix Duration Mean after disclosure={days.mean()}\")\n",
    "print(f\"Fix Duration Median after disclosure={days.median()}\")\n",
    "print(f\"Fix Duration Min after disclosure={days.min()}\")\n",
    "print(f\"Fix Duration Max after disclosure={days.max()}\")\n",
    "print(f\"Fix Duration Std after disclosure={days.std()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix duration across vul types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interest_cats = ['Memory Management', 'Memory Access' , 'Synchronization', 'Tainted Input', 'Resource Management', 'Exception Management', 'Cryptography',\\\n",
    "                 'Other', 'Risky Values', 'Path Resolution', 'Information Leak', 'Privilege', 'Predictability', 'Authentication', 'API', 'Access Control', 'Failure to Release Memory']\n",
    "for cat in interest_cats:\n",
    "    temp = df[df['sfp_id'].apply(lambda x: True if cat in x else False)]\n",
    "    days = temp['fix_duration']\n",
    "    # days = (days[days > 1])\n",
    "    print(f\"{cat}: {days.median()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolution of Vulnerabilities--All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "df = pd.read_sql(\"SELECT id, package, sfp_id, published, severity FROM cve\", con=db.conn)\n",
    "published = df[\"published\"]\n",
    "published = published.apply(lambda x: pd.to_datetime(datetime.datetime.strptime(x,\"%Y-%m-%dT%H:%M:%SZ\").strftime(\"%Y-%m\")))\n",
    "num_published_per_day = published.value_counts().sort_index()\n",
    "num_created_acc = num_published_per_day.cumsum()\n",
    "# print(num_created_acc)\n",
    "plot_evolution(num_created_acc.index, num_created_acc.values, 'Number of vulnerabilities', 'fig/rq1/vulnerabilities_over_time.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolution of Vulnerabilities--across vulnerability type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "df = pd.read_sql(\"SELECT id, package, sfp_id, published, severity FROM cve\", con=db.conn)\n",
    "interest_cats = ['Memory Access', 'Memory Management', 'Synchronization', 'Tainted Input', 'Resource Management', 'Exception Management', 'Cryptography']\n",
    "color_list = ['tab:blue', 'tab:green', 'tab:orange', 'tab:red', 'tab:purple', 'tab:brown', 'black', 'salmon', 'navy', 'olive']\n",
    "\n",
    "plt.style.use('seaborn-colorblind')\n",
    "fig, ax = plt.subplots(1, 1, figsize=(18, 10))\n",
    "ax.tick_params(labelsize=25)\n",
    "ax.yaxis.label.set_size(25)\n",
    "ax.title.set_size(20)\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "ax.xaxis.set_minor_locator(mdates.MonthLocator())\n",
    "fig.autofmt_xdate()\n",
    "\n",
    "ax.grid(True, linestyle='--', which=\"major\")\n",
    "markers = '.,ov2sP*|d+x'\n",
    "i=0\n",
    "for cat in interest_cats:\n",
    "    temp = df[df['sfp_id'].apply(lambda x: True if cat in x else False)]\n",
    "    published = temp[\"published\"]\n",
    "    published = published.apply(lambda x: pd.to_datetime(datetime.datetime.strptime(x,\"%Y-%m-%dT%H:%M:%SZ\").strftime(\"%Y-%m\")))\n",
    "    num_published_per_day = published.value_counts().sort_index()\n",
    "    num_created_acc = num_published_per_day.cumsum()\n",
    "    ax.plot(num_created_acc.index, num_created_acc.values,color=color_list[i%10], label=cat, markersize=9, marker=markers[i%10])\n",
    "    i = i+1\n",
    "    # if cat =='Exception Management':\n",
    "    #     print(num_created_acc)\n",
    "\n",
    "legend = ax.legend(framealpha=1)\n",
    "plt.legend(loc=2, prop={'size': 25},frameon = 1, facecolor = 'white', edgecolor = 'black')\n",
    "fig.savefig('fig/rq1/vul_overtime_across_type.png', facecolor='white', dpi=200)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rate of reported vulnerabilities per 1,000 packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vul_rate(num_created_acc, num_published_acc):\n",
    "    res = list()\n",
    "    ind2 = 0\n",
    "    for i in range(len(num_created_acc)):\n",
    "        if ind2 >=len(num_published_acc):\n",
    "            res.append(res[i-1])\n",
    "        else:\n",
    "            if num_created_acc.index[i] == num_published_acc.index[ind2]:\n",
    "                res.append(num_published_acc[ind2])\n",
    "                ind2+=1\n",
    "            else:\n",
    "                res.append( 0 if ind2==0 else res[i-1])\n",
    "    for i in range(len(res)):\n",
    "        res[i] = res[i]/(num_created_acc[i]/1000)\n",
    "    return res\n",
    "\n",
    "df = pd.read_sql(\"SELECT * FROM crates\", con=db.conn)\n",
    "temp = df[\"created_at\"]\n",
    "temp = temp.apply(lambda x: pd.to_datetime(datetime.datetime.strptime(x.split()[0],\"%Y-%m-%d\").strftime(\"%Y-%m\")))\n",
    "num_created_per_day = temp.value_counts().sort_index()\n",
    "num_created_acc = num_created_per_day.cumsum()\n",
    "\n",
    "df = pd.read_sql(\"SELECT id, package, published FROM cve\", con=db.conn)\n",
    "temp = df[\"published\"]\n",
    "temp = temp.apply(lambda x: pd.to_datetime(datetime.datetime.strptime(x,\"%Y-%m-%dT%H:%M:%SZ\").strftime(\"%Y-%m\")))\n",
    "num_published_per_day = temp.value_counts().sort_index()\n",
    "num_published_acc = num_published_per_day.cumsum()\n",
    "res = get_vul_rate(num_created_acc, num_published_acc)\n",
    "\n",
    "plot_evolution(num_created_acc.index, res, 'Number of vulnerabilities', 'fig/rq1/vulnerabilities_crates_over_time.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of published vulnerabilities normalized to LOC vulnerable package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from packaging.version import Version\n",
    "\n",
    "def get_affect_loc(package, vul_version):\n",
    "  cur = db.conn.cursor()\n",
    "  cur.execute(f\"SELECT num, crate_size from versions where\\\n",
    "                crate_id = (SELECT id from crates where name=\\'{package}\\')\")\n",
    "  results = cur.fetchall()\n",
    "  tmp = list()\n",
    "  if len(results) == 0:\n",
    "    return 0\n",
    "  for res in results:\n",
    "    try:\n",
    "      tmp.append((Version(res[0]), res[1]))\n",
    "    except:\n",
    "      continue\n",
    "  results = tmp\n",
    "  results = sorted(results, key=lambda kv: kv[0])\n",
    "  # find latest affected version\n",
    "  vul_versions = ast.literal_eval(str(vul_version))\n",
    "  affected = []\n",
    "  if len(vul_versions) == 0:\n",
    "    affected.append(results[-1][0])\n",
    "  for v in vul_versions:\n",
    "    if v[1] is None:\n",
    "      affected.append(results[-1][0])\n",
    "    else:\n",
    "      affected.append(Version(v[1]))\n",
    "  assert len(affected) > 0\n",
    "  affected = sorted(affected)[-1]\n",
    "\n",
    "  for r in results:\n",
    "    if r[0] == affected:\n",
    "      return float(r[1]) if r[1] is not None else 0\n",
    "  return 0\n",
    "\n",
    "df = pd.read_sql(\"SELECT id, package, vul_version, published FROM cve\", con=db.conn)\n",
    "df['lines'] = df.apply(lambda x: get_affect_loc(x.package, x.vul_version), axis=1)\n",
    "df = df[df['lines']>0]\n",
    "\n",
    "\n",
    "df[\"published\"] = df[\"published\"].apply(lambda x: datetime.datetime.strptime(x,\"%Y-%m-%dT%H:%M:%SZ\").strftime(\"%Y-%m\"))\n",
    "packages = list()\n",
    "def get_loc(lines, package):\n",
    "  res = lines if package not in packages else 0\n",
    "  packages.append(package)\n",
    "  return res\n",
    "lines = df.apply(lambda x: get_loc(x.lines, x.package), axis=1)\n",
    "df_temp = pd.DataFrame()\n",
    "df_temp['lines'] = lines\n",
    "df_temp[\"created_month\"] = df[\"published\"]\n",
    "temp = df_temp.groupby(['created_month']).sum()\n",
    "num_loc_acc = temp.cumsum()\n",
    "\n",
    "num_published_per_day = df[\"published\"].value_counts().sort_index()\n",
    "num_published_acc = num_published_per_day.cumsum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.concat([num_published_acc, num_loc_acc], axis=1)\n",
    "t.rename(columns={'count': 'published'}, inplace = True)\n",
    "t = t.filter(['published', 'lines'], axis=1)\n",
    "t_index = list(t.index)\n",
    "t['normalized'] = t.apply(lambda x: x.published/x.lines, axis=1)\n",
    "temp = pd.date_range('2016-05-01','2017-10-01',\n",
    "              freq='MS').strftime(\"%Y-%m\").tolist()\n",
    "\n",
    "df_temp = pd.DataFrame(index=temp)\n",
    "df_temp[\"published\"] = 0\n",
    "df_temp['lines'] = 0\n",
    "df_temp['normalized'] = 0\n",
    "df_temp = pd.concat([df_temp, t], ignore_index=True)\n",
    "temp.extend(t_index)\n",
    "#\n",
    "df_temp['date'] = [pd.to_datetime(d) for d in temp]\n",
    "t = df_temp\n",
    "t = t.set_index('date')\n",
    "plot_evolution(t.index, t.normalized, 'Number of vulnerabilities per \\nlines of code of vulnerable packages', 'fig/rq1/vulnerabilities_norm_loc.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolution of Vulnerabilities--across package categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "df = pd.read_sql(\"SELECT id, package, sfp_id, published, severity FROM cve\", con=db.conn)\n",
    "vul_cat = list()\n",
    "markers = '.,ov2sP*|d+x'\n",
    "for index, row in df.iterrows():\n",
    "    package = row[\"package\"]\n",
    "    cur = db.conn.cursor()\n",
    "    cur.execute(\"SELECT category from categories where id in (\\\n",
    "                SELECT category_id from crates_categories where\\\n",
    "                crate_id = (SELECT id from crates where name=\\'\"+package+\"\\'))\")\n",
    "    results = cur.fetchall()\n",
    "    categories = list()\n",
    "#     if len(results)==0:\n",
    "#         categories[\"no categories\"] += 1\n",
    "    for res in results:\n",
    "        res = res[0]\n",
    "        words = res.split(\"::\")\n",
    "        categories.append(words[0])\n",
    "    vul_cat.append(categories)\n",
    "df['category'] = vul_cat\n",
    "\n",
    "interest_cats = ['No standard library', 'Development tools', 'Command line utilities',\\\n",
    "               'Data structures', 'Memory management', 'Web programming', \\\n",
    "               'Asynchronous', 'Cryptography']\n",
    "interest_types = ['Memory Access', 'Memory Management', 'Synchronization', 'Tainted Input', 'Resource Management', 'Exception Management', 'Cryptography']\n",
    "# color_list = ['#3682be','#45a776','#f05326','#eed777','#334f65','#b3974e','#38cb7d','#ddae33','#844bb3','#93c555','#5f6694','#df3881']\n",
    "# color_list = cm.get_cmap('viridis', 12)(range(12))\n",
    "color_list = ['#fcffa4', '#65156e', '#fac228', '#280b53','#f57d15', '#000004', '#d44842','#9f2a63']\n",
    "\n",
    "plt.style.use('seaborn-colorblind') # 设置画图的风格\n",
    "plt.figure(figsize=(36, 40))\n",
    "\n",
    "def format_time(num_created_acc, num_created_acc_ty):\n",
    "    num_acc_ty = pd.Series(dtype=float)\n",
    "    k = 0\n",
    "    value = 0\n",
    "    for month in num_created_acc.index:\n",
    "        if k >= len(num_created_acc_ty):\n",
    "            num_acc_ty = num_acc_ty.append(pd.Series([value], index=[month]))\n",
    "        elif month < num_created_acc_ty.index[k]:\n",
    "            num_acc_ty = num_acc_ty.append(pd.Series([value], index=[month]))\n",
    "        elif month == num_created_acc_ty.index[k]:\n",
    "            value = num_created_acc_ty.values[k]\n",
    "            num_acc_ty = num_acc_ty.append(pd.Series([value], index=[month]))\n",
    "            k += 1\n",
    "    return num_acc_ty\n",
    "\n",
    "i=0\n",
    "published = df[\"published\"]\n",
    "published = published.apply(lambda x: pd.to_datetime(datetime.datetime.strptime(x,\"%Y-%m-%dT%H:%M:%SZ\").strftime(\"%Y-%m\")))\n",
    "num_published_per_day = published.value_counts().sort_index()\n",
    "num_created_acc_total = num_published_per_day.cumsum()\n",
    "for cat in interest_cats:\n",
    "    df_cat = df[df['category'].apply(lambda x: True if cat in x else False)]\n",
    "    published = df_cat[\"published\"]\n",
    "    published = published.apply(lambda x: pd.to_datetime(datetime.datetime.strptime(x,\"%Y-%m-%dT%H:%M:%SZ\").strftime(\"%Y-%m\")))\n",
    "    num_published_per_day = published.value_counts().sort_index()\n",
    "    num_created_acc = num_published_per_day.cumsum()\n",
    "    num_created_acc = format_time(num_created_acc_total, num_created_acc)\n",
    "    # ax = plt.subplot(4, 2, i + 1)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(18, 10))\n",
    "    ax.tick_params(labelsize=25)\n",
    "    ax.yaxis.label.set_size(35)\n",
    "    ax.title.set_size(20)\n",
    "    ax.set(ylabel='Number of reported vulnerabilities')\n",
    "    # ax.set_title(f\"Distribution of vulnerabilities types in {cat}\", fontsize=30, pad=10)\n",
    "\n",
    "    # ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "    # ax.xaxis.set_major_locator(mdates.MonthLocator(interval=6))\n",
    "    # ax.xaxis.set_minor_locator(mdates.MonthLocator())\n",
    "    # fig.autofmt_xdate()\n",
    "\n",
    "    ax.grid(True, linestyle='--', which=\"major\")\n",
    "    ax.plot(num_created_acc.index, num_created_acc.values,color='navy', label=cat,markersize=9, marker='.')\n",
    "    cnt = None\n",
    "    j = 0\n",
    "    for ty in interest_types:\n",
    "        temp = df_cat[df_cat['sfp_id'].apply(lambda x: True if ty in x else False)]\n",
    "        published_ty = temp[\"published\"]\n",
    "        published_ty = published_ty.apply(lambda x: pd.to_datetime(datetime.datetime.strptime(x,\"%Y-%m-%dT%H:%M:%SZ\").strftime(\"%Y-%m\")))\n",
    "        num_published_per_day_ty = published_ty.value_counts().sort_index()\n",
    "        num_created_acc_ty = num_published_per_day_ty.cumsum()\n",
    "        num_acc_ty = format_time(num_created_acc, num_created_acc_ty)\n",
    "        if cnt is None:\n",
    "            ax.bar(num_acc_ty.index, num_acc_ty.values, width = 10, color=color_list[j%10], label=ty)\n",
    "            cnt = num_acc_ty.values\n",
    "        else:\n",
    "            ax.bar(num_acc_ty.index, num_acc_ty.values, bottom=cnt, width = 10, color=color_list[j%10], label=ty)\n",
    "            for index, value in enumerate(cnt):\n",
    "                cnt[index] = cnt[index] + num_acc_ty.values[index]\n",
    "\n",
    "        j+= 1\n",
    "    legend = ax.legend(framealpha=1)\n",
    "    plt.legend(loc=2, prop={'size': 25},frameon = 1, facecolor = 'white', edgecolor = 'black')\n",
    "    plt.savefig(f'fig/rq1/vul_package_{cat}.png', facecolor='white')\n",
    "    i = i+1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
