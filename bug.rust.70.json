[
  {
    "project": "lettre",
    "target": 1,
    "commit_id": "d930c42d5069e344a9dfa84ebe4b60bf3b11ac64",
    "func": "//! SMTP client\n\nuse bufstream::BufStream;\nuse nom::ErrorKind as NomErrorKind;\nuse smtp::authentication::{Credentials, Mechanism};\nuse smtp::client::net::{ClientTlsParameters, Connector, NetworkStream, Timeout};\nuse smtp::commands::*;\nuse smtp::error::{Error, SmtpResult};\nuse smtp::response::Response;\nuse std::fmt::{Debug, Display};\nuse std::io::{self, BufRead, BufReader, Read, Write};\nuse std::net::ToSocketAddrs;\nuse std::string::String;\nuse std::time::Duration;\n\npub mod mock;\npub mod net;\n\n/// The codec used for transparency\n#[derive(Default, Clone, Copy, Debug)]\n#[cfg_attr(feature = \"serde-impls\", derive(Serialize, Deserialize))]\npub struct ClientCodec {\n    escape_count: u8,\n}\n\nimpl ClientCodec {\n    /// Creates a new client codec\n    pub fn new() -> Self {\n        ClientCodec::default()\n    }\n}\n\nimpl ClientCodec {\n    /// Adds transparency\n    /// TODO: replace CR and LF by CRLF\n    fn encode(&mut self, frame: &[u8], buf: &mut Vec<u8>) -> Result<(), Error> {\n        match frame.len() {\n            0 => {\n                match self.escape_count {\n                    0 => buf.write_all(b\"\\r\\n.\\r\\n\")?,\n                    1 => buf.write_all(b\"\\n.\\r\\n\")?,\n                    2 => buf.write_all(b\".\\r\\n\")?,\n                    _ => unreachable!(),\n                }\n                self.escape_count = 0;\n                Ok(())\n            }\n            _ => {\n                let mut start = 0;\n                for (idx, byte) in frame.iter().enumerate() {\n                    match self.escape_count {\n                        0 => self.escape_count = if *byte == b'\\r' { 1 } else { 0 },\n                        1 => self.escape_count = if *byte == b'\\n' { 2 } else { 0 },\n                        2 => self.escape_count = if *byte == b'.' { 3 } else { 0 },\n                        _ => unreachable!(),\n                    }\n                    if self.escape_count == 3 {\n                        self.escape_count = 0;\n                        buf.write_all(&frame[start..idx])?;\n                        buf.write_all(b\".\")?;\n                        start = idx;\n                    }\n                }\n                buf.write_all(&frame[start..])?;\n                Ok(())\n            }\n        }\n    }\n}\n\n/// Returns the string replacing all the CRLF with \"\\<CRLF\\>\"\n/// Used for debug displays\nfn escape_crlf(string: &str) -> String {\n    string.replace(\"\\r\\n\", \"<CRLF>\")\n}\n\n/// Structure that implements the SMTP client\n#[derive(Debug, Default)]\npub struct InnerClient<S: Write + Read = NetworkStream> {\n    /// TCP stream between client and server\n    /// Value is None before connection\n    stream: Option<BufStream<S>>,\n}\n\nmacro_rules! return_err (\n    ($err: expr, $client: ident) => ({\n        return Err(From::from($err))\n    })\n);\n\n#[cfg_attr(feature = \"cargo-clippy\", allow(clippy::new_without_default_derive))]\nimpl<S: Write + Read> InnerClient<S> {\n    /// Creates a new SMTP client\n    ///\n    /// It does not connects to the server, but only creates the `Client`\n    pub fn new() -> InnerClient<S> {\n        InnerClient { stream: None }\n    }\n}\n\nimpl<S: Connector + Write + Read + Timeout + Debug> InnerClient<S> {\n    /// Closes the SMTP transaction if possible\n    pub fn close(&mut self) {\n        let _ = self.command(QuitCommand);\n        self.stream = None;\n    }\n\n    /// Sets the underlying stream\n    pub fn set_stream(&mut self, stream: S) {\n        self.stream = Some(BufStream::new(stream));\n    }\n\n    /// Upgrades the underlying connection to SSL/TLS\n    pub fn upgrade_tls_stream(&mut self, tls_parameters: &ClientTlsParameters) -> io::Result<()> {\n        match self.stream {\n            Some(ref mut stream) => stream.get_mut().upgrade_tls(tls_parameters),\n            None => Ok(()),\n        }\n    }\n\n    /// Tells if the underlying stream is currently encrypted\n    pub fn is_encrypted(&self) -> bool {\n        match self.stream {\n            Some(ref stream) => stream.get_ref().is_encrypted(),\n            None => false,\n        }\n    }\n\n    /// Set timeout\n    pub fn set_timeout(&mut self, duration: Option<Duration>) -> io::Result<()> {\n        match self.stream {\n            Some(ref mut stream) => {\n                stream.get_mut().set_read_timeout(duration)?;\n                stream.get_mut().set_write_timeout(duration)?;\n                Ok(())\n            }\n            None => Ok(()),\n        }\n    }\n\n    /// Connects to the configured server\n    pub fn connect<A: ToSocketAddrs>(\n        &mut self,\n        addr: &A,\n        tls_parameters: Option<&ClientTlsParameters>,\n    ) -> SmtpResult {\n        // Connect should not be called when the client is already connected\n        if self.stream.is_some() {\n            return_err!(\"The connection is already established\", self);\n        }\n\n        let mut addresses = addr.to_socket_addrs()?;\n\n        let server_addr = match addresses.next() {\n            Some(addr) => addr,\n            None => return_err!(\"Could not resolve hostname\", self),\n        };\n\n        debug!(\"connecting to {}\", server_addr);\n\n        // Try to connect\n        self.set_stream(Connector::connect(&server_addr, tls_parameters)?);\n\n        self.read_response()\n    }\n\n    /// Checks if the server is connected using the NOOP SMTP command\n    #[cfg_attr(feature = \"cargo-clippy\", allow(clippy::wrong_self_convention))]\n    pub fn is_connected(&mut self) -> bool {\n        self.stream.is_some() && self.command(NoopCommand).is_ok()\n    }\n\n    /// Sends an AUTH command with the given mechanism, and handles challenge if needed\n    pub fn auth(&mut self, mechanism: Mechanism, credentials: &Credentials) -> SmtpResult {\n        // TODO\n        let mut challenges = 10;\n        let mut response = self.command(AuthCommand::new(mechanism, credentials.clone(), None)?)?;\n\n        while challenges > 0 && response.has_code(334) {\n            challenges -= 1;\n            response = self.command(AuthCommand::new_from_response(\n                mechanism,\n                credentials.clone(),\n                &response,\n            )?)?;\n        }\n\n        if challenges == 0 {\n            Err(Error::ResponseParsing(\"Unexpected number of challenges\"))\n        } else {\n            Ok(response)\n        }\n    }\n\n    /// Sends the message content\n    pub fn message(&mut self, message: Box<dyn Read>) -> SmtpResult {\n        let mut out_buf: Vec<u8> = vec![];\n        let mut codec = ClientCodec::new();\n\n        let mut message_reader = BufReader::new(message);\n\n        loop {\n            out_buf.clear();\n\n            let consumed = match message_reader.fill_buf() {\n                Ok(bytes) => {\n                    codec.encode(bytes, &mut out_buf)?;\n                    bytes.len()\n                }\n                Err(ref err) => panic!(\"Failed with: {}\", err),\n            };\n            message_reader.consume(consumed);\n\n            if consumed == 0 {\n                break;\n            }\n\n            self.write(out_buf.as_slice())?;\n        }\n\n        self.write(b\"\\r\\n.\\r\\n\")?;\n        self.read_response()\n    }\n\n    /// Sends an SMTP command\n    pub fn command<C: Display>(&mut self, command: C) -> SmtpResult {\n        self.write(command.to_string().as_bytes())?;\n        self.read_response()\n    }\n\n    /// Writes a string to the server\n    fn write(&mut self, string: &[u8]) -> Result<(), Error> {\n        if self.stream.is_none() {\n            return Err(From::from(\"Connection closed\"));\n        }\n\n        self.stream.as_mut().unwrap().write_all(string)?;\n        self.stream.as_mut().unwrap().flush()?;\n\n        debug!(\n            \"Wrote: {}\",\n            escape_crlf(String::from_utf8_lossy(string).as_ref())\n        );\n        Ok(())\n    }\n\n    /// Gets the SMTP response\n    fn read_response(&mut self) -> SmtpResult {\n        let mut raw_response = String::new();\n        let mut response = raw_response.parse::<Response>();\n\n        while response.is_err() {\n            if response.as_ref().err().unwrap() != &NomErrorKind::Complete {\n                break;\n            }\n            // TODO read more than one line\n            let read_count = self.stream.as_mut().unwrap().read_line(&mut raw_response)?;\n\n            // EOF is reached\n            if read_count == 0 {\n                break;\n            }\n\n            response = raw_response.parse::<Response>();\n        }\n\n        debug!(\"Read: {}\", escape_crlf(raw_response.as_ref()));\n\n        let final_response = response?;\n\n        if final_response.is_positive() {\n            Ok(final_response)\n        } else {\n            Err(From::from(final_response))\n        }\n    }\n}\n\n#[cfg(test)]\nmod test {\n    use super::{escape_crlf, ClientCodec};\n\n    #[test]\n    fn test_codec() {\n        let mut codec = ClientCodec::new();\n        let mut buf: Vec<u8> = vec![];\n\n        assert!(codec.encode(b\"test\\r\\n\", &mut buf).is_ok());\n        assert!(codec.encode(b\".\\r\\n\", &mut buf).is_ok());\n        assert!(codec.encode(b\"\\r\\ntest\", &mut buf).is_ok());\n        assert!(codec.encode(b\"te\\r\\n.\\r\\nst\", &mut buf).is_ok());\n        assert!(codec.encode(b\"test\", &mut buf).is_ok());\n        assert!(codec.encode(b\"test.\", &mut buf).is_ok());\n        assert!(codec.encode(b\"test\\n\", &mut buf).is_ok());\n        assert!(codec.encode(b\".test\\n\", &mut buf).is_ok());\n        assert!(codec.encode(b\"test\", &mut buf).is_ok());\n        assert_eq!(\n            String::from_utf8(buf).unwrap(),\n            \"test\\r\\n..\\r\\n\\r\\ntestte\\r\\n..\\r\\nsttesttest.test\\n.test\\ntest\"\n        );\n    }\n\n    #[test]\n    fn test_escape_crlf() {\n        assert_eq!(escape_crlf(\"\\r\\n\"), \"<CRLF>\");\n        assert_eq!(escape_crlf(\"EHLO my_name\\r\\n\"), \"EHLO my_name<CRLF>\");\n        assert_eq!(\n            escape_crlf(\"EHLO my_name\\r\\nSIZE 42\\r\\n\"),\n            \"EHLO my_name<CRLF>SIZE 42<CRLF>\"\n        );\n    }\n}\n"
  },
  {
    "project": "tiny_future",
    "target": 1,
    "commit_id": "c7919199a0f6d1ce0e3c33499d1b37f862c990e4",
    "func": "#[macro_use] extern crate etrace;\nuse etrace::Error;\n\n\n#[derive(Clone, Copy, Debug, Eq, PartialEq)]\npub enum State{ Waiting, Ready, Consumed, Canceled }\n\n\n/// The futures inner state\nstruct Inner<T, U> {\n\tpayload: std::sync::Mutex<(State, Option<T>)>,\n\tcond_var: std::sync::Condvar,\n\tshared_state: std::sync::Mutex<U>,\n\tcancel_on_drop: std::sync::atomic::AtomicBool\n}\nunsafe impl<T, U> Sync for Inner<T, U> {}\n\n\n\npub struct Future<T, U = ()>(std::sync::Arc<Inner<T, U>>);\nimpl<T, U> Future<T, U> {\n\t/// Creates a new `Future<T, U>` with `shared_state` as shared-state\n\tpub fn with_state(shared_state: U) -> Self {\n\t\tFuture(std::sync::Arc::new(Inner {\n\t\t\tpayload: std::sync::Mutex::new((State::Waiting, None)),\n\t\t\tcond_var: std::sync::Condvar::new(),\n\t\t\tshared_state: std::sync::Mutex::new(shared_state),\n\t\t\tcancel_on_drop: std::sync::atomic::AtomicBool::new(true)\n\t\t}))\n\t}\n\t\n\t/// Sets the future\n\tpub fn set(&self, result: T) -> Result<(), Error<State>> {\n\t\t// Check if the future can be set (is `State::Waiting`)\n\t\tlet mut payload = self.0.payload.lock().unwrap();\n\t\tif payload.0 != State::Waiting { throw_err!(payload.0) }\n\t\t\n\t\t// Set result\n\t\t*payload = (State::Ready, Some(result));\n\t\tself.0.cond_var.notify_all();\n\t\tOk(())\n\t}\n\t\n\t/// Cancels (poisons) the future\n\t///\n\t/// This is useful to indicate that the future is obsolete and should not be `set` anymore\n\tpub fn cancel(&self) {\n\t\tlet mut payload = self.0.payload.lock().unwrap();\n\t\t// Check if the payload is still cancelable\n\t\tif payload.0 == State::Waiting {\n\t\t\tpayload.0 = State::Canceled;\n\t\t\tself.0.cond_var.notify_all();\n\t\t}\n\t}\n\t\n\t/// Returns the future's state\n\tpub fn get_state(&self) -> State {\n\t\tself.0.payload.lock().unwrap().0\n\t}\n\t\n\t/// Checks if the future is still waiting or has been set/canceled\n\tpub fn is_waiting(&self) -> bool {\n\t\tself.get_state() == State::Waiting\n\t}\n\t\n\t/// Tries to get the future's result\n\t///\n\t/// If the future is ready, it is consumed and `T` is returned;\n\t/// if the future is not ready, `Error::InvalidState(State)` is returned\n\tpub fn try_get(&self) -> Result<T, Error<State>> {\n\t\t// Lock this future and check if it has a result (is `State::Ready`)\n\t\tlet payload = self.0.payload.lock().unwrap();\n\t\tOk(try_err!(Future::<T, U>::extract_payload(payload)))\n\t}\n\t\n\t/// Tries to get the future's result\n\t///\n\t/// If the future is ready or or becomes ready before the timeout occurres, it is consumed\n\t/// and `T` is returned; if the future is not ready, `Error::InvalidState(State)` is returned\n\tpub fn try_get_timeout(&self, timeout: std::time::Duration) -> Result<T, Error<State>> {\n\t\tlet timeout_point = std::time::Instant::now() + timeout;\n\t\t\n\t\t// Wait for condvar until the state is not `State::Waiting` anymore or the timeout has occurred\n\t\tlet mut payload = self.0.payload.lock().unwrap();\n\t\twhile payload.0 == State::Waiting && std::time::Instant::now() < timeout_point {\n\t\t\tpayload = self.0.cond_var.wait_timeout(payload, time_remaining(timeout_point)).unwrap().0;\n\t\t}\n\t\tOk(try_err!(Future::<T, U>::extract_payload(payload)))\n\t}\n\t\n\t/// Gets the future's result\n\t///\n\t/// __Warning: this function will block until a result becomes available__\n\tpub fn get(&self) -> Result<T, Error<State>> {\n\t\t// Wait for condvar until the state is not `State::Waiting` anymore\n\t\tlet mut payload = self.0.payload.lock().unwrap();\n\t\twhile payload.0 == State::Waiting { payload = self.0.cond_var.wait(payload).unwrap() }\n\t\t\n\t\tOk(try_err!(Future::<T, U>::extract_payload(payload)))\n\t}\n\t\n\t/// Get a clone of the current shared state\n\tpub fn get_shared_state(&self) -> U where U: Clone {\n\t\tself.0.shared_state.lock().unwrap().clone()\n\t}\n\t\n\t/// Replace the current shared state\n\tpub fn set_shared_state(&self, shared_state: U) {\n\t\t*self.0.shared_state.lock().unwrap() = shared_state\n\t}\n\t\n\t/// Provides exclusive access to the shared state within `modifier` until `modifier` returns\n\tpub fn access_shared_state<F: FnOnce(&mut U)>(&self, modifier: F) {\n\t\tlet mut shared_state_lock = self.0.shared_state.lock().unwrap();\n\t\tmodifier(&mut *shared_state_lock);\n\t}\n\t\n\t/// Provides exclusive access to the shared state within `modifier` until `modifier` returns\n\tpub fn access_shared_state_param<V, F: FnOnce(&mut U, V)>(&self, modifier: F, parameter: V) {\n\t\tlet mut shared_state_lock = self.0.shared_state.lock().unwrap();\n\t\tmodifier(&mut *shared_state_lock, parameter);\n\t}\n\t\n\t/// Detaches the future so it won't be canceled if there is only one instance left\n\t///\n\t/// Useful if you either don't want that your future is ever canceled or if there's always only\n\t/// one instance (e.g. if you wrap it into a reference-counting container)\n\tpub fn detach(&self) {\n\t\tself.0.cancel_on_drop.store(false, std::sync::atomic::Ordering::Relaxed)\n\t}\n\t\n\t\n\t/// Internal helper to validate/update the future's state and get the payload\n\tfn extract_payload(mut payload: std::sync::MutexGuard<(State, Option<T>)>) -> Result<T, Error<State>> {\n\t\t// Validate state\n\t\tif payload.0 == State::Ready {\n\t\t\t// Update state and return the payload\n\t\t\tpayload.0 = State::Consumed;\n\t\t\t// If the payload cannot be taken, we'll fall to `throw_err!(payload.0)` where `payload.0 == State::Consumed`\n\t\t\tif let Some(payload) = payload.1.take() { return Ok(payload) }\n\t\t}\n\t\tthrow_err!(payload.0)\n\t}\n}\nimpl<T> Future<T, ()> {\n\tpub fn new() -> Self {\n\t\tFuture::with_state(())\n\t}\n}\nimpl<T, U> Default for Future<T, U> where U: Default {\n\tfn default() -> Self {\n\t\tFuture::with_state(U::default())\n\t}\n}\nimpl<T, U> Drop for Future<T, U> {\n\tfn drop(&mut self) {\n\t\tif std::sync::Arc::strong_count(&self.0) <= 2 && self.0.cancel_on_drop.load(std::sync::atomic::Ordering::Relaxed) { self.cancel() }\n\t}\n}\nimpl<T, U> Clone for Future<T, U> {\n\tfn clone(&self) -> Self {\n\t\tFuture(self.0.clone())\n\t}\n}\nunsafe impl<T: Send, U: Send> Send for Future<T, U> {}\nunsafe impl<T, U> Sync for Future<T, U> {}\n\n\n\n/// Computes the remaining time underflow-safe\npub fn time_remaining(timeout_point: std::time::Instant) -> std::time::Duration {\n\tlet now = std::time::Instant::now();\n\tif now > timeout_point { std::time::Duration::default() } else { timeout_point - now }\n}\n\n\n\n/// Creates a future for `job` and runs `job`. The result of `job` will be set as result into the\n/// future. The parameter passed to `job` is a function that returns if the future is still waiting\n/// so that `job` can check for cancellation.\npub fn async_with_state<T: 'static, U: 'static, F: FnOnce(Future<T, U>) + Send + 'static>(job: F, shared_state: U) -> Future<T, U> {\n\tuse std::clone::Clone;\n\t\n\t// Create future and spawn job\n\tlet future = Future::with_state(shared_state);\n\tlet _future = future.clone();\n\tstd::thread::spawn(move || job(_future));\n\t\n\tfuture\n}\n\n/// Creates a future for `job` and runs `job`. The result of `job` will be set as result into the\n/// future. The parameter passed to `job` is a function that returns if the future is still waiting\n/// so that `job` can check for cancellation.\npub fn async<T: 'static, F: FnOnce(Future<T, ()>) + Send + 'static>(job: F) -> Future<T, ()> {\n\tasync_with_state(job, ())\n}\n\n\n\n/// Sets `$result` as the `$future`'s result and returns\n#[macro_export]\nmacro_rules! job_return {\n    ($future:expr, $result:expr) => ({\n    \tlet _ = $future.set($result);\n\t\treturn\n\t})\n}\n\n/// Cancels `$future` and returns\n#[macro_export]\nmacro_rules! job_die {\n    ($future:expr) => ({\n    \t$future.cancel();\n    \treturn\n    })\n}\n\n\n\n#[cfg(test)]\nmod test {\n\tuse std;\n\tuse super::{ Future, State, async };\n\t\n\t#[test]\n\tfn double_set_err() {\n\t\tlet fut = Future::<u8>::new();\n\t\tfut.set(7).unwrap();\n\t\tassert_eq!(fut.set(77).unwrap_err().kind, State::Ready)\n\t}\n\t\n\t#[test]\n\tfn cancel_set_err() {\n\t\tlet fut = Future::<u8>::new();\n\t\tfut.cancel();\n\t\tassert_eq!(fut.set(7).unwrap_err().kind, State::Canceled)\n\t}\n\t\n\t#[test]\n\tfn drop_is_canceled() {\n\t\tlet fut = Future::<u8>::new();\n\t\tassert_eq!(fut.get_state(), State::Waiting);\n\t\t{\n\t\t\tlet _fut = fut.clone();\n\t\t\tstd::thread::sleep(std::time::Duration::from_secs(2));\n\t\t}\n\t\tassert_eq!(fut.get_state(), State::Canceled)\n\t}\n\t\n\t#[test]\n\tfn cancel_get_err() {\n\t\tlet fut = async(|fut: Future<u8>| {\n\t\t\tstd::thread::sleep(std::time::Duration::from_secs(4));\n\t\t\tjob_die!(fut)\n\t\t});\n\t\tassert_eq!(fut.get().unwrap_err().kind, State::Canceled)\n\t}\n\t\n\t#[test]\n\tfn is_ready_and_get() {\n\t\tlet fut = async(|fut: Future<u8>| {\n\t\t\tstd::thread::sleep(std::time::Duration::from_secs(4));\n\t\t\tfut.set(7).unwrap();\n\t\t});\n\t\tassert_eq!(fut.get_state(), State::Waiting);\n\t\t\n\t\t// Create and drop future\n\t\t{\n\t\t\tlet _fut = fut.clone();\n\t\t\tstd::thread::sleep(std::time::Duration::from_secs(7));\n\t\t\tassert_eq!(_fut.get_state(), State::Ready);\n\t\t}\n\t\t\n\t\tassert_eq!(fut.get().unwrap(), 7);\n\t}\n}"
  },
  {
    "project": "tiny_future",
    "target": 1,
    "commit_id": "50bd80f874c851413a721bbe144eeba4dfb68b4e",
    "func": "#[macro_use] extern crate etrace;\nuse etrace::Error;\n\n\n#[derive(Clone, Copy, Debug, Eq, PartialEq)]\npub enum State{ Waiting, Ready, Consumed, Canceled }\n\n\n/// The futures inner state\nstruct Inner<T, U> {\n\tpayload: std::sync::Mutex<(State, Option<T>)>,\n\tcond_var: std::sync::Condvar,\n\tshared_state: std::sync::Mutex<U>,\n\tcancel_on_drop: std::sync::atomic::AtomicBool\n}\nunsafe impl<T, U> Sync for Inner<T, U> {}\n\n\n\npub struct Future<T, U = ()>(std::sync::Arc<Inner<T, U>>);\nimpl<T, U> Future<T, U> {\n\t/// Creates a new `Future<T, U>` with `shared_state` as shared-state\n\tpub fn with_state(shared_state: U) -> Self {\n\t\tFuture(std::sync::Arc::new(Inner {\n\t\t\tpayload: std::sync::Mutex::new((State::Waiting, None)),\n\t\t\tcond_var: std::sync::Condvar::new(),\n\t\t\tshared_state: std::sync::Mutex::new(shared_state),\n\t\t\tcancel_on_drop: std::sync::atomic::AtomicBool::new(true)\n\t\t}))\n\t}\n\t\n\t/// Sets the future\n\tpub fn set(&self, result: T) -> Result<(), Error<State>> {\n\t\t// Check if the future can be set (is `State::Waiting`)\n\t\tlet mut payload = self.0.payload.lock().unwrap();\n\t\tif payload.0 != State::Waiting { throw_err!(payload.0) }\n\t\t\n\t\t// Set result\n\t\t*payload = (State::Ready, Some(result));\n\t\tself.0.cond_var.notify_all();\n\t\tOk(())\n\t}\n\t\n\t/// Cancels (poisons) the future\n\t///\n\t/// This is useful to indicate that the future is obsolete and should not be `set` anymore\n\tpub fn cancel(&self) {\n\t\tlet mut payload = self.0.payload.lock().unwrap();\n\t\t// Check if the payload is still cancelable\n\t\tif payload.0 == State::Waiting {\n\t\t\tpayload.0 = State::Canceled;\n\t\t\tself.0.cond_var.notify_all();\n\t\t}\n\t}\n\t\n\t/// Returns the future's state\n\tpub fn get_state(&self) -> State {\n\t\tself.0.payload.lock().unwrap().0\n\t}\n\t\n\t/// Checks if the future is still waiting or has been set/canceled\n\tpub fn is_waiting(&self) -> bool {\n\t\tself.get_state() == State::Waiting\n\t}\n\t\n\t/// Tries to get the future's result\n\t///\n\t/// If the future is ready, it is consumed and `T` is returned;\n\t/// if the future is not ready, `Error::InvalidState(State)` is returned\n\tpub fn try_get(&self) -> Result<T, Error<State>> {\n\t\t// Lock this future and check if it has a result (is `State::Ready`)\n\t\tlet payload = self.0.payload.lock().unwrap();\n\t\tOk(try_err!(Future::<T, U>::extract_payload(payload)))\n\t}\n\t\n\t/// Tries to get the future's result\n\t///\n\t/// If the future is ready or or becomes ready before the timeout occurres, it is consumed\n\t/// and `T` is returned; if the future is not ready, `Error::InvalidState(State)` is returned\n\tpub fn try_get_timeout(&self, timeout: std::time::Duration) -> Result<T, Error<State>> {\n\t\tlet timeout_point = std::time::Instant::now() + timeout;\n\t\t\n\t\t// Wait for condvar until the state is not `State::Waiting` anymore or the timeout has occurred\n\t\tlet mut payload = self.0.payload.lock().unwrap();\n\t\twhile payload.0 == State::Waiting && std::time::Instant::now() < timeout_point {\n\t\t\tpayload = self.0.cond_var.wait_timeout(payload, time_remaining(timeout_point)).unwrap().0;\n\t\t}\n\t\tOk(try_err!(Future::<T, U>::extract_payload(payload)))\n\t}\n\t\n\t/// Gets the future's result\n\t///\n\t/// __Warning: this function will block until a result becomes available__\n\tpub fn get(&self) -> Result<T, Error<State>> {\n\t\t// Wait for condvar until the state is not `State::Waiting` anymore\n\t\tlet mut payload = self.0.payload.lock().unwrap();\n\t\twhile payload.0 == State::Waiting { payload = self.0.cond_var.wait(payload).unwrap() }\n\t\t\n\t\tOk(try_err!(Future::<T, U>::extract_payload(payload)))\n\t}\n\t\n\t/// Get a clone of the current shared state\n\tpub fn get_shared_state(&self) -> U where U: Clone {\n\t\tself.0.shared_state.lock().unwrap().clone()\n\t}\n\t\n\t/// Replace the current shared state\n\tpub fn set_shared_state(&self, shared_state: U) {\n\t\t*self.0.shared_state.lock().unwrap() = shared_state\n\t}\n\t\n\t/// Provides exclusive access to the shared state within `modifier` until `modifier` returns\n\tpub fn access_shared_state<F: FnOnce(&mut U)>(&self, modifier: F) {\n\t\tlet mut shared_state_lock = self.0.shared_state.lock().unwrap();\n\t\tmodifier(&mut *shared_state_lock);\n\t}\n\t\n\t/// Provides exclusive access to the shared state within `modifier` until `modifier` returns\n\tpub fn access_shared_state_param<V, F: FnOnce(&mut U, V)>(&self, modifier: F, parameter: V) {\n\t\tlet mut shared_state_lock = self.0.shared_state.lock().unwrap();\n\t\tmodifier(&mut *shared_state_lock, parameter);\n\t}\n\t\n\t/// Detaches the future so it won't be canceled if there is only one instance left\n\t///\n\t/// Useful if you either don't want that your future is ever canceled or if there's always only\n\t/// one instance (e.g. if you wrap it into a reference-counting container)\n\tpub fn detach(&self) {\n\t\tself.0.cancel_on_drop.store(false, std::sync::atomic::Ordering::Relaxed)\n\t}\n\t\n\t\n\t/// Internal helper to validate/update the future's state and get the payload\n\tfn extract_payload(mut payload: std::sync::MutexGuard<(State, Option<T>)>) -> Result<T, Error<State>> {\n\t\t// Validate state\n\t\tif payload.0 == State::Ready {\n\t\t\t// Update state and return the payload\n\t\t\tpayload.0 = State::Consumed;\n\t\t\t// If the payload cannot be taken, we'll fall to `throw_err!(payload.0)` where `payload.0 == State::Consumed`\n\t\t\tif let Some(payload) = payload.1.take() { return Ok(payload) }\n\t\t}\n\t\tthrow_err!(payload.0)\n\t}\n}\nimpl<T> Future<T, ()> {\n\tpub fn new() -> Self {\n\t\tFuture::with_state(())\n\t}\n}\nimpl<T, U> Default for Future<T, U> where U: Default {\n\tfn default() -> Self {\n\t\tFuture::with_state(U::default())\n\t}\n}\nimpl<T, U> Drop for Future<T, U> {\n\tfn drop(&mut self) {\n\t\tif std::sync::Arc::strong_count(&self.0) <= 2 && self.0.cancel_on_drop.load(std::sync::atomic::Ordering::Relaxed) { self.cancel() }\n\t}\n}\nimpl<T, U> Clone for Future<T, U> {\n\tfn clone(&self) -> Self {\n\t\tFuture(self.0.clone())\n\t}\n}\nunsafe impl<T, U> Send for Future<T, U> {}\nunsafe impl<T, U> Sync for Future<T, U> {}\n\n\n\n/// Computes the remaining time underflow-safe\npub fn time_remaining(timeout_point: std::time::Instant) -> std::time::Duration {\n\tlet now = std::time::Instant::now();\n\tif now > timeout_point { std::time::Duration::default() } else { timeout_point - now }\n}\n\n\n\n/// Creates a future for `job` and runs `job`. The result of `job` will be set as result into the\n/// future. The parameter passed to `job` is a function that returns if the future is still waiting\n/// so that `job` can check for cancellation.\npub fn async_with_state<T: 'static, U: 'static, F: FnOnce(Future<T, U>) + Send + 'static>(job: F, shared_state: U) -> Future<T, U> {\n\tuse std::clone::Clone;\n\t\n\t// Create future and spawn job\n\tlet future = Future::with_state(shared_state);\n\tlet _future = future.clone();\n\tstd::thread::spawn(move || job(_future));\n\t\n\tfuture\n}\n\n/// Creates a future for `job` and runs `job`. The result of `job` will be set as result into the\n/// future. The parameter passed to `job` is a function that returns if the future is still waiting\n/// so that `job` can check for cancellation.\npub fn async<T: 'static, F: FnOnce(Future<T, ()>) + Send + 'static>(job: F) -> Future<T, ()> {\n\tasync_with_state(job, ())\n}\n\n\n\n/// Sets `$result` as the `$future`'s result and returns\n#[macro_export]\nmacro_rules! job_return {\n    ($future:expr, $result:expr) => ({\n    \tlet _ = $future.set($result);\n\t\treturn\n\t})\n}\n\n/// Cancels `$future` and returns\n#[macro_export]\nmacro_rules! job_die {\n    ($future:expr) => ({\n    \t$future.cancel();\n    \treturn\n    })\n}\n\n\n\n#[cfg(test)]\nmod test {\n\tuse std;\n\tuse super::{ Future, State, async };\n\t\n\t#[test]\n\tfn double_set_err() {\n\t\tlet fut = Future::<u8>::new();\n\t\tfut.set(7).unwrap();\n\t\tassert_eq!(fut.set(77).unwrap_err().kind, State::Ready)\n\t}\n\t\n\t#[test]\n\tfn cancel_set_err() {\n\t\tlet fut = Future::<u8>::new();\n\t\tfut.cancel();\n\t\tassert_eq!(fut.set(7).unwrap_err().kind, State::Canceled)\n\t}\n\t\n\t#[test]\n\tfn drop_is_canceled() {\n\t\tlet fut = Future::<u8>::new();\n\t\tassert_eq!(fut.get_state(), State::Waiting);\n\t\t{\n\t\t\tlet _fut = fut.clone();\n\t\t\tstd::thread::sleep(std::time::Duration::from_secs(2));\n\t\t}\n\t\tassert_eq!(fut.get_state(), State::Canceled)\n\t}\n\t\n\t#[test]\n\tfn cancel_get_err() {\n\t\tlet fut = async(|fut: Future<u8>| {\n\t\t\tstd::thread::sleep(std::time::Duration::from_secs(4));\n\t\t\tjob_die!(fut)\n\t\t});\n\t\tassert_eq!(fut.get().unwrap_err().kind, State::Canceled)\n\t}\n\t\n\t#[test]\n\tfn is_ready_and_get() {\n\t\tlet fut = async(|fut: Future<u8>| {\n\t\t\tstd::thread::sleep(std::time::Duration::from_secs(4));\n\t\t\tfut.set(7).unwrap();\n\t\t});\n\t\tassert_eq!(fut.get_state(), State::Waiting);\n\t\t\n\t\t// Create and drop future\n\t\t{\n\t\t\tlet _fut = fut.clone();\n\t\t\tstd::thread::sleep(std::time::Duration::from_secs(7));\n\t\t\tassert_eq!(_fut.get_state(), State::Ready);\n\t\t}\n\t\t\n\t\tassert_eq!(fut.get().unwrap(), 7);\n\t}\n}"
  },
  {
    "project": "rusqlite",
    "target": 1,
    "commit_id": "71b2f5187b0cbace3f8b6ff53432ff2ca0defcf0",
    "func": "//! `feature = \"functions\"` Create or redefine SQL functions.\n//!\n//! # Example\n//!\n//! Adding a `regexp` function to a connection in which compiled regular\n//! expressions are cached in a `HashMap`. For an alternative implementation\n//! that uses SQLite's [Function Auxilliary Data](https://www.sqlite.org/c3ref/get_auxdata.html) interface\n//! to avoid recompiling regular expressions, see the unit tests for this\n//! module.\n//!\n//! ```rust\n//! use regex::Regex;\n//! use rusqlite::functions::FunctionFlags;\n//! use rusqlite::{Connection, Error, Result, NO_PARAMS};\n//!\n//! fn add_regexp_function(db: &Connection) -> Result<()> {\n//!     db.create_scalar_function(\n//!         \"regexp\",\n//!         2,\n//!         FunctionFlags::SQLITE_UTF8 | FunctionFlags::SQLITE_DETERMINISTIC,\n//!         move |ctx| {\n//!             assert_eq!(ctx.len(), 2, \"called with unexpected number of arguments\");\n//!\n//!             let saved_re: Option<&Regex> = ctx.get_aux(0)?;\n//!             let new_re = match saved_re {\n//!                 None => {\n//!                     let s = ctx.get::<String>(0)?;\n//!                     match Regex::new(&s) {\n//!                         Ok(r) => Some(r),\n//!                         Err(err) => return Err(Error::UserFunctionError(Box::new(err))),\n//!                     }\n//!                 }\n//!                 Some(_) => None,\n//!             };\n//!\n//!             let is_match = {\n//!                 let re = saved_re.unwrap_or_else(|| new_re.as_ref().unwrap());\n//!\n//!                 let text = ctx\n//!                     .get_raw(1)\n//!                     .as_str()\n//!                     .map_err(|e| Error::UserFunctionError(e.into()))?;\n//!\n//!                 re.is_match(text)\n//!             };\n//!\n//!             if let Some(re) = new_re {\n//!                 ctx.set_aux(0, re);\n//!             }\n//!\n//!             Ok(is_match)\n//!         },\n//!     )\n//! }\n//!\n//! fn main() -> Result<()> {\n//!     let db = Connection::open_in_memory()?;\n//!     add_regexp_function(&db)?;\n//!\n//!     let is_match: bool = db.query_row(\n//!         \"SELECT regexp('[aeiou]*', 'aaaaeeeiii')\",\n//!         NO_PARAMS,\n//!         |row| row.get(0),\n//!     )?;\n//!\n//!     assert!(is_match);\n//!     Ok(())\n//! }\n//! ```\nuse std::any::TypeId;\nuse std::os::raw::{c_int, c_void};\nuse std::panic::{catch_unwind, RefUnwindSafe, UnwindSafe};\nuse std::ptr;\nuse std::slice;\n\nuse crate::ffi;\nuse crate::ffi::sqlite3_context;\nuse crate::ffi::sqlite3_value;\n\nuse crate::context::set_result;\nuse crate::types::{FromSql, FromSqlError, ToSql, ValueRef};\n\nuse crate::{str_to_cstring, Connection, Error, InnerConnection, Result};\n\nunsafe fn report_error(ctx: *mut sqlite3_context, err: &Error) {\n    // Extended constraint error codes were added in SQLite 3.7.16. We don't have\n    // an explicit feature check for that, and this doesn't really warrant one.\n    // We'll use the extended code if we're on the bundled version (since it's\n    // at least 3.17.0) and the normal constraint error code if not.\n    #[cfg(feature = \"modern_sqlite\")]\n    fn constraint_error_code() -> i32 {\n        ffi::SQLITE_CONSTRAINT_FUNCTION\n    }\n    #[cfg(not(feature = \"modern_sqlite\"))]\n    fn constraint_error_code() -> i32 {\n        ffi::SQLITE_CONSTRAINT\n    }\n\n    match *err {\n        Error::SqliteFailure(ref err, ref s) => {\n            ffi::sqlite3_result_error_code(ctx, err.extended_code);\n            if let Some(Ok(cstr)) = s.as_ref().map(|s| str_to_cstring(s)) {\n                ffi::sqlite3_result_error(ctx, cstr.as_ptr(), -1);\n            }\n        }\n        _ => {\n            ffi::sqlite3_result_error_code(ctx, constraint_error_code());\n            if let Ok(cstr) = str_to_cstring(&err.to_string()) {\n                ffi::sqlite3_result_error(ctx, cstr.as_ptr(), -1);\n            }\n        }\n    }\n}\n\nunsafe extern \"C\" fn free_boxed_value<T>(p: *mut c_void) {\n    drop(Box::from_raw(p as *mut T));\n}\n\n/// `feature = \"functions\"` Context is a wrapper for the SQLite function\n/// evaluation context.\npub struct Context<'a> {\n    ctx: *mut sqlite3_context,\n    args: &'a [*mut sqlite3_value],\n}\n\nimpl Context<'_> {\n    /// Returns the number of arguments to the function.\n    pub fn len(&self) -> usize {\n        self.args.len()\n    }\n\n    /// Returns `true` when there is no argument.\n    pub fn is_empty(&self) -> bool {\n        self.args.is_empty()\n    }\n\n    /// Returns the `idx`th argument as a `T`.\n    ///\n    /// # Failure\n    ///\n    /// Will panic if `idx` is greater than or equal to `self.len()`.\n    ///\n    /// Will return Err if the underlying SQLite type cannot be converted to a\n    /// `T`.\n    pub fn get<T: FromSql>(&self, idx: usize) -> Result<T> {\n        let arg = self.args[idx];\n        let value = unsafe { ValueRef::from_value(arg) };\n        FromSql::column_result(value).map_err(|err| match err {\n            FromSqlError::InvalidType => {\n                Error::InvalidFunctionParameterType(idx, value.data_type())\n            }\n            FromSqlError::OutOfRange(i) => Error::IntegralValueOutOfRange(idx, i),\n            FromSqlError::Other(err) => {\n                Error::FromSqlConversionFailure(idx, value.data_type(), err)\n            }\n            #[cfg(feature = \"i128_blob\")]\n            FromSqlError::InvalidI128Size(_) => {\n                Error::FromSqlConversionFailure(idx, value.data_type(), Box::new(err))\n            }\n            #[cfg(feature = \"uuid\")]\n            FromSqlError::InvalidUuidSize(_) => {\n                Error::FromSqlConversionFailure(idx, value.data_type(), Box::new(err))\n            }\n        })\n    }\n\n    /// Returns the `idx`th argument as a `ValueRef`.\n    ///\n    /// # Failure\n    ///\n    /// Will panic if `idx` is greater than or equal to `self.len()`.\n    pub fn get_raw(&self, idx: usize) -> ValueRef<'_> {\n        let arg = self.args[idx];\n        unsafe { ValueRef::from_value(arg) }\n    }\n\n    /// Sets the auxilliary data associated with a particular parameter. See\n    /// https://www.sqlite.org/c3ref/get_auxdata.html for a discussion of\n    /// this feature, or the unit tests of this module for an example.\n    pub fn set_aux<T: 'static>(&self, arg: c_int, value: T) {\n        let boxed = Box::into_raw(Box::new(AuxData {\n            id: TypeId::of::<T>(),\n            value,\n        }));\n        unsafe {\n            ffi::sqlite3_set_auxdata(\n                self.ctx,\n                arg,\n                boxed as *mut c_void,\n                Some(free_boxed_value::<AuxData<T>>),\n            )\n        };\n    }\n\n    /// Gets the auxilliary data that was associated with a given parameter\n    /// via `set_aux`. Returns `Ok(None)` if no data has been associated,\n    /// and .\n    pub fn get_aux<T: 'static>(&self, arg: c_int) -> Result<Option<&T>> {\n        let p = unsafe { ffi::sqlite3_get_auxdata(self.ctx, arg) as *const AuxData<T> };\n        if p.is_null() {\n            Ok(None)\n        } else {\n            let id = unsafe { (*p).id };\n            if TypeId::of::<T>() != id {\n                Err(Error::GetAuxWrongType)\n            } else {\n                Ok(Some(unsafe { &(*p).value }))\n            }\n        }\n    }\n}\n\n#[repr(C)]\nstruct AuxData<T: 'static> {\n    id: TypeId,\n    value: T,\n}\n\n/// `feature = \"functions\"` Aggregate is the callback interface for user-defined\n/// aggregate function.\n///\n/// `A` is the type of the aggregation context and `T` is the type of the final\n/// result. Implementations should be stateless.\npub trait Aggregate<A, T>\nwhere\n    A: RefUnwindSafe + UnwindSafe,\n    T: ToSql,\n{\n    /// Initializes the aggregation context. Will be called prior to the first\n    /// call to `step()` to set up the context for an invocation of the\n    /// function. (Note: `init()` will not be called if there are no rows.)\n    fn init(&self) -> A;\n\n    /// \"step\" function called once for each row in an aggregate group. May be\n    /// called 0 times if there are no rows.\n    fn step(&self, _: &mut Context<'_>, _: &mut A) -> Result<()>;\n\n    /// Computes and returns the final result. Will be called exactly once for\n    /// each invocation of the function. If `step()` was called at least\n    /// once, will be given `Some(A)` (the same `A` as was created by\n    /// `init` and given to `step`); if `step()` was not called (because\n    /// the function is running against 0 rows), will be given `None`.\n    fn finalize(&self, _: Option<A>) -> Result<T>;\n}\n\n/// `feature = \"window\"` WindowAggregate is the callback interface for\n/// user-defined aggregate window function.\n#[cfg(feature = \"window\")]\npub trait WindowAggregate<A, T>: Aggregate<A, T>\nwhere\n    A: RefUnwindSafe + UnwindSafe,\n    T: ToSql,\n{\n    /// Returns the current value of the aggregate. Unlike xFinal, the\n    /// implementation should not delete any context.\n    fn value(&self, _: Option<&A>) -> Result<T>;\n\n    /// Removes a row from the current window.\n    fn inverse(&self, _: &mut Context<'_>, _: &mut A) -> Result<()>;\n}\n\nbitflags::bitflags! {\n    #[doc = \"Function Flags.\"]\n    #[doc = \"See [sqlite3_create_function](https://sqlite.org/c3ref/create_function.html) for details.\"]\n    #[repr(C)]\n    pub struct FunctionFlags: ::std::os::raw::c_int {\n        const SQLITE_UTF8     = ffi::SQLITE_UTF8;\n        const SQLITE_UTF16LE  = ffi::SQLITE_UTF16LE;\n        const SQLITE_UTF16BE  = ffi::SQLITE_UTF16BE;\n        const SQLITE_UTF16    = ffi::SQLITE_UTF16;\n        const SQLITE_DETERMINISTIC = ffi::SQLITE_DETERMINISTIC;\n        const SQLITE_DIRECTONLY    = 0x0000_0008_0000; // 3.30.0\n        const SQLITE_SUBTYPE       = 0x0000_0010_0000; // 3.30.0\n        const SQLITE_INNOCUOUS     = 0x0000_0020_0000; // 3.31.0\n    }\n}\n\nimpl Default for FunctionFlags {\n    fn default() -> FunctionFlags {\n        FunctionFlags::SQLITE_UTF8\n    }\n}\n\nimpl Connection {\n    /// `feature = \"functions\"` Attach a user-defined scalar function to\n    /// this database connection.\n    ///\n    /// `fn_name` is the name the function will be accessible from SQL.\n    /// `n_arg` is the number of arguments to the function. Use `-1` for a\n    /// variable number. If the function always returns the same value\n    /// given the same input, `deterministic` should be `true`.\n    ///\n    /// The function will remain available until the connection is closed or\n    /// until it is explicitly removed via `remove_function`.\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// # use rusqlite::{Connection, Result, NO_PARAMS};\n    /// # use rusqlite::functions::FunctionFlags;\n    /// fn scalar_function_example(db: Connection) -> Result<()> {\n    ///     db.create_scalar_function(\n    ///         \"halve\",\n    ///         1,\n    ///         FunctionFlags::SQLITE_UTF8 | FunctionFlags::SQLITE_DETERMINISTIC,\n    ///         |ctx| {\n    ///             let value = ctx.get::<f64>(0)?;\n    ///             Ok(value / 2f64)\n    ///         },\n    ///     )?;\n    ///\n    ///     let six_halved: f64 = db.query_row(\"SELECT halve(6)\", NO_PARAMS, |r| r.get(0))?;\n    ///     assert_eq!(six_halved, 3f64);\n    ///     Ok(())\n    /// }\n    /// ```\n    ///\n    /// # Failure\n    ///\n    /// Will return Err if the function could not be attached to the connection.\n    pub fn create_scalar_function<F, T>(\n        &self,\n        fn_name: &str,\n        n_arg: c_int,\n        flags: FunctionFlags,\n        x_func: F,\n    ) -> Result<()>\n    where\n        F: FnMut(&Context<'_>) -> Result<T> + Send + UnwindSafe + 'static,\n        T: ToSql,\n    {\n        self.db\n            .borrow_mut()\n            .create_scalar_function(fn_name, n_arg, flags, x_func)\n    }\n\n    /// `feature = \"functions\"` Attach a user-defined aggregate function to this\n    /// database connection.\n    ///\n    /// # Failure\n    ///\n    /// Will return Err if the function could not be attached to the connection.\n    pub fn create_aggregate_function<A, D, T>(\n        &self,\n        fn_name: &str,\n        n_arg: c_int,\n        flags: FunctionFlags,\n        aggr: D,\n    ) -> Result<()>\n    where\n        A: RefUnwindSafe + UnwindSafe,\n        D: Aggregate<A, T>,\n        T: ToSql,\n    {\n        self.db\n            .borrow_mut()\n            .create_aggregate_function(fn_name, n_arg, flags, aggr)\n    }\n\n    /// `feature = \"window\"` Attach a user-defined aggregate window function to\n    /// this database connection.\n    ///\n    /// See https://sqlite.org/windowfunctions.html#udfwinfunc for more\n    /// information.\n    #[cfg(feature = \"window\")]\n    pub fn create_window_function<A, W, T>(\n        &self,\n        fn_name: &str,\n        n_arg: c_int,\n        flags: FunctionFlags,\n        aggr: W,\n    ) -> Result<()>\n    where\n        A: RefUnwindSafe + UnwindSafe,\n        W: WindowAggregate<A, T>,\n        T: ToSql,\n    {\n        self.db\n            .borrow_mut()\n            .create_window_function(fn_name, n_arg, flags, aggr)\n    }\n\n    /// `feature = \"functions\"` Removes a user-defined function from this\n    /// database connection.\n    ///\n    /// `fn_name` and `n_arg` should match the name and number of arguments\n    /// given to `create_scalar_function` or `create_aggregate_function`.\n    ///\n    /// # Failure\n    ///\n    /// Will return Err if the function could not be removed.\n    pub fn remove_function(&self, fn_name: &str, n_arg: c_int) -> Result<()> {\n        self.db.borrow_mut().remove_function(fn_name, n_arg)\n    }\n}\n\nimpl InnerConnection {\n    fn create_scalar_function<F, T>(\n        &mut self,\n        fn_name: &str,\n        n_arg: c_int,\n        flags: FunctionFlags,\n        x_func: F,\n    ) -> Result<()>\n    where\n        F: FnMut(&Context<'_>) -> Result<T> + Send + UnwindSafe + 'static,\n        T: ToSql,\n    {\n        unsafe extern \"C\" fn call_boxed_closure<F, T>(\n            ctx: *mut sqlite3_context,\n            argc: c_int,\n            argv: *mut *mut sqlite3_value,\n        ) where\n            F: FnMut(&Context<'_>) -> Result<T>,\n            T: ToSql,\n        {\n            let r = catch_unwind(|| {\n                let boxed_f: *mut F = ffi::sqlite3_user_data(ctx) as *mut F;\n                assert!(!boxed_f.is_null(), \"Internal error - null function pointer\");\n                let ctx = Context {\n                    ctx,\n                    args: slice::from_raw_parts(argv, argc as usize),\n                };\n                (*boxed_f)(&ctx)\n            });\n            let t = match r {\n                Err(_) => {\n                    report_error(ctx, &Error::UnwindingPanic);\n                    return;\n                }\n                Ok(r) => r,\n            };\n            let t = t.as_ref().map(|t| ToSql::to_sql(t));\n\n            match t {\n                Ok(Ok(ref value)) => set_result(ctx, value),\n                Ok(Err(err)) => report_error(ctx, &err),\n                Err(err) => report_error(ctx, err),\n            }\n        }\n\n        let boxed_f: *mut F = Box::into_raw(Box::new(x_func));\n        let c_name = str_to_cstring(fn_name)?;\n        let r = unsafe {\n            ffi::sqlite3_create_function_v2(\n                self.db(),\n                c_name.as_ptr(),\n                n_arg,\n                flags.bits(),\n                boxed_f as *mut c_void,\n                Some(call_boxed_closure::<F, T>),\n                None,\n                None,\n                Some(free_boxed_value::<F>),\n            )\n        };\n        self.decode_result(r)\n    }\n\n    fn create_aggregate_function<A, D, T>(\n        &mut self,\n        fn_name: &str,\n        n_arg: c_int,\n        flags: FunctionFlags,\n        aggr: D,\n    ) -> Result<()>\n    where\n        A: RefUnwindSafe + UnwindSafe,\n        D: Aggregate<A, T>,\n        T: ToSql,\n    {\n        let boxed_aggr: *mut D = Box::into_raw(Box::new(aggr));\n        let c_name = str_to_cstring(fn_name)?;\n        let r = unsafe {\n            ffi::sqlite3_create_function_v2(\n                self.db(),\n                c_name.as_ptr(),\n                n_arg,\n                flags.bits(),\n                boxed_aggr as *mut c_void,\n                None,\n                Some(call_boxed_step::<A, D, T>),\n                Some(call_boxed_final::<A, D, T>),\n                Some(free_boxed_value::<D>),\n            )\n        };\n        self.decode_result(r)\n    }\n\n    #[cfg(feature = \"window\")]\n    fn create_window_function<A, W, T>(\n        &mut self,\n        fn_name: &str,\n        n_arg: c_int,\n        flags: FunctionFlags,\n        aggr: W,\n    ) -> Result<()>\n    where\n        A: RefUnwindSafe + UnwindSafe,\n        W: WindowAggregate<A, T>,\n        T: ToSql,\n    {\n        let boxed_aggr: *mut W = Box::into_raw(Box::new(aggr));\n        let c_name = str_to_cstring(fn_name)?;\n        let r = unsafe {\n            ffi::sqlite3_create_window_function(\n                self.db(),\n                c_name.as_ptr(),\n                n_arg,\n                flags.bits(),\n                boxed_aggr as *mut c_void,\n                Some(call_boxed_step::<A, W, T>),\n                Some(call_boxed_final::<A, W, T>),\n                Some(call_boxed_value::<A, W, T>),\n                Some(call_boxed_inverse::<A, W, T>),\n                Some(free_boxed_value::<W>),\n            )\n        };\n        self.decode_result(r)\n    }\n\n    fn remove_function(&mut self, fn_name: &str, n_arg: c_int) -> Result<()> {\n        let c_name = str_to_cstring(fn_name)?;\n        let r = unsafe {\n            ffi::sqlite3_create_function_v2(\n                self.db(),\n                c_name.as_ptr(),\n                n_arg,\n                ffi::SQLITE_UTF8,\n                ptr::null_mut(),\n                None,\n                None,\n                None,\n                None,\n            )\n        };\n        self.decode_result(r)\n    }\n}\n\nunsafe fn aggregate_context<A>(ctx: *mut sqlite3_context, bytes: usize) -> Option<*mut *mut A> {\n    let pac = ffi::sqlite3_aggregate_context(ctx, bytes as c_int) as *mut *mut A;\n    if pac.is_null() {\n        return None;\n    }\n    Some(pac)\n}\n\nunsafe extern \"C\" fn call_boxed_step<A, D, T>(\n    ctx: *mut sqlite3_context,\n    argc: c_int,\n    argv: *mut *mut sqlite3_value,\n) where\n    A: RefUnwindSafe + UnwindSafe,\n    D: Aggregate<A, T>,\n    T: ToSql,\n{\n    let pac = match aggregate_context(ctx, ::std::mem::size_of::<*mut A>()) {\n        Some(pac) => pac,\n        None => {\n            ffi::sqlite3_result_error_nomem(ctx);\n            return;\n        }\n    };\n\n    let r = catch_unwind(|| {\n        let boxed_aggr: *mut D = ffi::sqlite3_user_data(ctx) as *mut D;\n        assert!(\n            !boxed_aggr.is_null(),\n            \"Internal error - null aggregate pointer\"\n        );\n        if (*pac as *mut A).is_null() {\n            *pac = Box::into_raw(Box::new((*boxed_aggr).init()));\n        }\n        let mut ctx = Context {\n            ctx,\n            args: slice::from_raw_parts(argv, argc as usize),\n        };\n        (*boxed_aggr).step(&mut ctx, &mut **pac)\n    });\n    let r = match r {\n        Err(_) => {\n            report_error(ctx, &Error::UnwindingPanic);\n            return;\n        }\n        Ok(r) => r,\n    };\n    match r {\n        Ok(_) => {}\n        Err(err) => report_error(ctx, &err),\n    };\n}\n\n#[cfg(feature = \"window\")]\nunsafe extern \"C\" fn call_boxed_inverse<A, W, T>(\n    ctx: *mut sqlite3_context,\n    argc: c_int,\n    argv: *mut *mut sqlite3_value,\n) where\n    A: RefUnwindSafe + UnwindSafe,\n    W: WindowAggregate<A, T>,\n    T: ToSql,\n{\n    let pac = match aggregate_context(ctx, ::std::mem::size_of::<*mut A>()) {\n        Some(pac) => pac,\n        None => {\n            ffi::sqlite3_result_error_nomem(ctx);\n            return;\n        }\n    };\n\n    let r = catch_unwind(|| {\n        let boxed_aggr: *mut W = ffi::sqlite3_user_data(ctx) as *mut W;\n        assert!(\n            !boxed_aggr.is_null(),\n            \"Internal error - null aggregate pointer\"\n        );\n        let mut ctx = Context {\n            ctx,\n            args: slice::from_raw_parts(argv, argc as usize),\n        };\n        (*boxed_aggr).inverse(&mut ctx, &mut **pac)\n    });\n    let r = match r {\n        Err(_) => {\n            report_error(ctx, &Error::UnwindingPanic);\n            return;\n        }\n        Ok(r) => r,\n    };\n    match r {\n        Ok(_) => {}\n        Err(err) => report_error(ctx, &err),\n    };\n}\n\nunsafe extern \"C\" fn call_boxed_final<A, D, T>(ctx: *mut sqlite3_context)\nwhere\n    A: RefUnwindSafe + UnwindSafe,\n    D: Aggregate<A, T>,\n    T: ToSql,\n{\n    // Within the xFinal callback, it is customary to set N=0 in calls to\n    // sqlite3_aggregate_context(C,N) so that no pointless memory allocations occur.\n    let a: Option<A> = match aggregate_context(ctx, 0) {\n        Some(pac) => {\n            if (*pac as *mut A).is_null() {\n                None\n            } else {\n                let a = Box::from_raw(*pac);\n                Some(*a)\n            }\n        }\n        None => None,\n    };\n\n    let r = catch_unwind(|| {\n        let boxed_aggr: *mut D = ffi::sqlite3_user_data(ctx) as *mut D;\n        assert!(\n            !boxed_aggr.is_null(),\n            \"Internal error - null aggregate pointer\"\n        );\n        (*boxed_aggr).finalize(a)\n    });\n    let t = match r {\n        Err(_) => {\n            report_error(ctx, &Error::UnwindingPanic);\n            return;\n        }\n        Ok(r) => r,\n    };\n    let t = t.as_ref().map(|t| ToSql::to_sql(t));\n    match t {\n        Ok(Ok(ref value)) => set_result(ctx, value),\n        Ok(Err(err)) => report_error(ctx, &err),\n        Err(err) => report_error(ctx, err),\n    }\n}\n\n#[cfg(feature = \"window\")]\nunsafe extern \"C\" fn call_boxed_value<A, W, T>(ctx: *mut sqlite3_context)\nwhere\n    A: RefUnwindSafe + UnwindSafe,\n    W: WindowAggregate<A, T>,\n    T: ToSql,\n{\n    // Within the xValue callback, it is customary to set N=0 in calls to\n    // sqlite3_aggregate_context(C,N) so that no pointless memory allocations occur.\n    let a: Option<&A> = match aggregate_context(ctx, 0) {\n        Some(pac) => {\n            if (*pac as *mut A).is_null() {\n                None\n            } else {\n                let a = &**pac;\n                Some(a)\n            }\n        }\n        None => None,\n    };\n\n    let r = catch_unwind(|| {\n        let boxed_aggr: *mut W = ffi::sqlite3_user_data(ctx) as *mut W;\n        assert!(\n            !boxed_aggr.is_null(),\n            \"Internal error - null aggregate pointer\"\n        );\n        (*boxed_aggr).value(a)\n    });\n    let t = match r {\n        Err(_) => {\n            report_error(ctx, &Error::UnwindingPanic);\n            return;\n        }\n        Ok(r) => r,\n    };\n    let t = t.as_ref().map(|t| ToSql::to_sql(t));\n    match t {\n        Ok(Ok(ref value)) => set_result(ctx, value),\n        Ok(Err(err)) => report_error(ctx, &err),\n        Err(err) => report_error(ctx, err),\n    }\n}\n\n#[cfg(test)]\nmod test {\n    use regex::Regex;\n    use std::f64::EPSILON;\n    use std::os::raw::c_double;\n\n    #[cfg(feature = \"window\")]\n    use crate::functions::WindowAggregate;\n    use crate::functions::{Aggregate, Context, FunctionFlags};\n    use crate::{Connection, Error, Result, NO_PARAMS};\n\n    fn half(ctx: &Context<'_>) -> Result<c_double> {\n        assert_eq!(ctx.len(), 1, \"called with unexpected number of arguments\");\n        let value = ctx.get::<c_double>(0)?;\n        Ok(value / 2f64)\n    }\n\n    #[test]\n    fn test_function_half() {\n        let db = Connection::open_in_memory().unwrap();\n        db.create_scalar_function(\n            \"half\",\n            1,\n            FunctionFlags::SQLITE_UTF8 | FunctionFlags::SQLITE_DETERMINISTIC,\n            half,\n        )\n        .unwrap();\n        let result: Result<f64> = db.query_row(\"SELECT half(6)\", NO_PARAMS, |r| r.get(0));\n\n        assert!((3f64 - result.unwrap()).abs() < EPSILON);\n    }\n\n    #[test]\n    fn test_remove_function() {\n        let db = Connection::open_in_memory().unwrap();\n        db.create_scalar_function(\n            \"half\",\n            1,\n            FunctionFlags::SQLITE_UTF8 | FunctionFlags::SQLITE_DETERMINISTIC,\n            half,\n        )\n        .unwrap();\n        let result: Result<f64> = db.query_row(\"SELECT half(6)\", NO_PARAMS, |r| r.get(0));\n        assert!((3f64 - result.unwrap()).abs() < EPSILON);\n\n        db.remove_function(\"half\", 1).unwrap();\n        let result: Result<f64> = db.query_row(\"SELECT half(6)\", NO_PARAMS, |r| r.get(0));\n        assert!(result.is_err());\n    }\n\n    // This implementation of a regexp scalar function uses SQLite's auxilliary data\n    // (https://www.sqlite.org/c3ref/get_auxdata.html) to avoid recompiling the regular\n    // expression multiple times within one query.\n    fn regexp_with_auxilliary(ctx: &Context<'_>) -> Result<bool> {\n        assert_eq!(ctx.len(), 2, \"called with unexpected number of arguments\");\n\n        let saved_re: Option<&Regex> = ctx.get_aux(0)?;\n        let new_re = match saved_re {\n            None => {\n                let s = ctx.get::<String>(0)?;\n                match Regex::new(&s) {\n                    Ok(r) => Some(r),\n                    Err(err) => return Err(Error::UserFunctionError(Box::new(err))),\n                }\n            }\n            Some(_) => None,\n        };\n\n        let is_match = {\n            let re = saved_re.unwrap_or_else(|| new_re.as_ref().unwrap());\n\n            let text = ctx\n                .get_raw(1)\n                .as_str()\n                .map_err(|e| Error::UserFunctionError(e.into()))?;\n\n            re.is_match(text)\n        };\n\n        if let Some(re) = new_re {\n            ctx.set_aux(0, re);\n        }\n\n        Ok(is_match)\n    }\n\n    #[test]\n    fn test_function_regexp_with_auxilliary() {\n        let db = Connection::open_in_memory().unwrap();\n        db.execute_batch(\n            \"BEGIN;\n             CREATE TABLE foo (x string);\n             INSERT INTO foo VALUES ('lisa');\n             INSERT INTO foo VALUES ('lXsi');\n             INSERT INTO foo VALUES ('lisX');\n             END;\",\n        )\n        .unwrap();\n        db.create_scalar_function(\n            \"regexp\",\n            2,\n            FunctionFlags::SQLITE_UTF8 | FunctionFlags::SQLITE_DETERMINISTIC,\n            regexp_with_auxilliary,\n        )\n        .unwrap();\n\n        let result: Result<bool> =\n            db.query_row(\"SELECT regexp('l.s[aeiouy]', 'lisa')\", NO_PARAMS, |r| {\n                r.get(0)\n            });\n\n        assert_eq!(true, result.unwrap());\n\n        let result: Result<i64> = db.query_row(\n            \"SELECT COUNT(*) FROM foo WHERE regexp('l.s[aeiouy]', x) == 1\",\n            NO_PARAMS,\n            |r| r.get(0),\n        );\n\n        assert_eq!(2, result.unwrap());\n    }\n\n    #[test]\n    fn test_varargs_function() {\n        let db = Connection::open_in_memory().unwrap();\n        db.create_scalar_function(\n            \"my_concat\",\n            -1,\n            FunctionFlags::SQLITE_UTF8 | FunctionFlags::SQLITE_DETERMINISTIC,\n            |ctx| {\n                let mut ret = String::new();\n\n                for idx in 0..ctx.len() {\n                    let s = ctx.get::<String>(idx)?;\n                    ret.push_str(&s);\n                }\n\n                Ok(ret)\n            },\n        )\n        .unwrap();\n\n        for &(expected, query) in &[\n            (\"\", \"SELECT my_concat()\"),\n            (\"onetwo\", \"SELECT my_concat('one', 'two')\"),\n            (\"abc\", \"SELECT my_concat('a', 'b', 'c')\"),\n        ] {\n            let result: String = db.query_row(query, NO_PARAMS, |r| r.get(0)).unwrap();\n            assert_eq!(expected, result);\n        }\n    }\n\n    #[test]\n    fn test_get_aux_type_checking() {\n        let db = Connection::open_in_memory().unwrap();\n        db.create_scalar_function(\"example\", 2, FunctionFlags::default(), |ctx| {\n            if !ctx.get::<bool>(1)? {\n                ctx.set_aux::<i64>(0, 100);\n            } else {\n                assert_eq!(ctx.get_aux::<String>(0), Err(Error::GetAuxWrongType));\n                assert_eq!(ctx.get_aux::<i64>(0), Ok(Some(&100)));\n            }\n            Ok(true)\n        })\n        .unwrap();\n\n        let res: bool = db\n            .query_row(\n                \"SELECT example(0, i) FROM (SELECT 0 as i UNION SELECT 1)\",\n                NO_PARAMS,\n                |r| r.get(0),\n            )\n            .unwrap();\n        // Doesn't actually matter, we'll assert in the function if there's a problem.\n        assert!(res);\n    }\n\n    struct Sum;\n    struct Count;\n\n    impl Aggregate<i64, Option<i64>> for Sum {\n        fn init(&self) -> i64 {\n            0\n        }\n\n        fn step(&self, ctx: &mut Context<'_>, sum: &mut i64) -> Result<()> {\n            *sum += ctx.get::<i64>(0)?;\n            Ok(())\n        }\n\n        fn finalize(&self, sum: Option<i64>) -> Result<Option<i64>> {\n            Ok(sum)\n        }\n    }\n\n    impl Aggregate<i64, i64> for Count {\n        fn init(&self) -> i64 {\n            0\n        }\n\n        fn step(&self, _ctx: &mut Context<'_>, sum: &mut i64) -> Result<()> {\n            *sum += 1;\n            Ok(())\n        }\n\n        fn finalize(&self, sum: Option<i64>) -> Result<i64> {\n            Ok(sum.unwrap_or(0))\n        }\n    }\n\n    #[test]\n    fn test_sum() {\n        let db = Connection::open_in_memory().unwrap();\n        db.create_aggregate_function(\n            \"my_sum\",\n            1,\n            FunctionFlags::SQLITE_UTF8 | FunctionFlags::SQLITE_DETERMINISTIC,\n            Sum,\n        )\n        .unwrap();\n\n        // sum should return NULL when given no columns (contrast with count below)\n        let no_result = \"SELECT my_sum(i) FROM (SELECT 2 AS i WHERE 1 <> 1)\";\n        let result: Option<i64> = db.query_row(no_result, NO_PARAMS, |r| r.get(0)).unwrap();\n        assert!(result.is_none());\n\n        let single_sum = \"SELECT my_sum(i) FROM (SELECT 2 AS i UNION ALL SELECT 2)\";\n        let result: i64 = db.query_row(single_sum, NO_PARAMS, |r| r.get(0)).unwrap();\n        assert_eq!(4, result);\n\n        let dual_sum = \"SELECT my_sum(i), my_sum(j) FROM (SELECT 2 AS i, 1 AS j UNION ALL SELECT \\\n                        2, 1)\";\n        let result: (i64, i64) = db\n            .query_row(dual_sum, NO_PARAMS, |r| Ok((r.get(0)?, r.get(1)?)))\n            .unwrap();\n        assert_eq!((4, 2), result);\n    }\n\n    #[test]\n    fn test_count() {\n        let db = Connection::open_in_memory().unwrap();\n        db.create_aggregate_function(\n            \"my_count\",\n            -1,\n            FunctionFlags::SQLITE_UTF8 | FunctionFlags::SQLITE_DETERMINISTIC,\n            Count,\n        )\n        .unwrap();\n\n        // count should return 0 when given no columns (contrast with sum above)\n        let no_result = \"SELECT my_count(i) FROM (SELECT 2 AS i WHERE 1 <> 1)\";\n        let result: i64 = db.query_row(no_result, NO_PARAMS, |r| r.get(0)).unwrap();\n        assert_eq!(result, 0);\n\n        let single_sum = \"SELECT my_count(i) FROM (SELECT 2 AS i UNION ALL SELECT 2)\";\n        let result: i64 = db.query_row(single_sum, NO_PARAMS, |r| r.get(0)).unwrap();\n        assert_eq!(2, result);\n    }\n\n    #[cfg(feature = \"window\")]\n    impl WindowAggregate<i64, Option<i64>> for Sum {\n        fn inverse(&self, ctx: &mut Context<'_>, sum: &mut i64) -> Result<()> {\n            *sum -= ctx.get::<i64>(0)?;\n            Ok(())\n        }\n\n        fn value(&self, sum: Option<&i64>) -> Result<Option<i64>> {\n            Ok(sum.copied())\n        }\n    }\n\n    #[test]\n    #[cfg(feature = \"window\")]\n    fn test_window() {\n        use fallible_iterator::FallibleIterator;\n\n        let db = Connection::open_in_memory().unwrap();\n        db.create_window_function(\n            \"sumint\",\n            1,\n            FunctionFlags::SQLITE_UTF8 | FunctionFlags::SQLITE_DETERMINISTIC,\n            Sum,\n        )\n        .unwrap();\n        db.execute_batch(\n            \"CREATE TABLE t3(x, y);\n             INSERT INTO t3 VALUES('a', 4),\n                     ('b', 5),\n                     ('c', 3),\n                     ('d', 8),\n                     ('e', 1);\",\n        )\n        .unwrap();\n\n        let mut stmt = db\n            .prepare(\n                \"SELECT x, sumint(y) OVER (\n                   ORDER BY x ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING\n                 ) AS sum_y\n                 FROM t3 ORDER BY x;\",\n            )\n            .unwrap();\n\n        let results: Vec<(String, i64)> = stmt\n            .query(NO_PARAMS)\n            .unwrap()\n            .map(|row| Ok((row.get(\"x\")?, row.get(\"sum_y\")?)))\n            .collect()\n            .unwrap();\n        let expected = vec![\n            (\"a\".to_owned(), 9),\n            (\"b\".to_owned(), 12),\n            (\"c\".to_owned(), 16),\n            (\"d\".to_owned(), 12),\n            (\"e\".to_owned(), 9),\n        ];\n        assert_eq!(expected, results);\n    }\n}\n"
  },
  {
    "project": "lucet",
    "target": 1,
    "commit_id": "8fb1fece339927e178f6cfef4eb67328b500237d",
    "func": "pub mod execution;\nmod siginfo_ext;\npub mod signals;\npub mod state;\n\npub use crate::instance::execution::{KillError, KillState, KillSuccess, KillSwitch};\npub use crate::instance::signals::{signal_handler_none, SignalBehavior, SignalHandler};\npub use crate::instance::state::State;\n\nuse crate::alloc::Alloc;\nuse crate::context::Context;\nuse crate::embed_ctx::CtxMap;\nuse crate::error::Error;\n#[cfg(feature = \"concurrent_testpoints\")]\nuse crate::lock_testpoints::LockTestpoints;\nuse crate::module::{self, FunctionHandle, Global, GlobalValue, Module, TrapCode};\nuse crate::region::RegionInternal;\nuse crate::sysdeps::HOST_PAGE_SIZE_EXPECTED;\nuse crate::val::{UntypedRetVal, Val};\nuse crate::vmctx::Vmctx;\nuse crate::WASM_PAGE_SIZE;\nuse libc::{c_void, pthread_self, siginfo_t, uintptr_t};\nuse lucet_module::InstanceRuntimeData;\nuse memoffset::offset_of;\nuse std::any::Any;\nuse std::cell::{BorrowError, BorrowMutError, Ref, RefCell, RefMut, UnsafeCell};\nuse std::convert::TryFrom;\nuse std::marker::PhantomData;\nuse std::mem;\nuse std::ops::{Deref, DerefMut};\nuse std::ptr::{self, NonNull};\nuse std::sync::Arc;\n\npub const LUCET_INSTANCE_MAGIC: u64 = 746_932_922;\n\nthread_local! {\n    /// The host context.\n    ///\n    /// Control returns here implicitly due to the setup in `Context::init()` when guest functions\n    /// return normally. Control can return here explicitly from signal handlers when the guest\n    /// program needs to be terminated.\n    ///\n    /// This is an `UnsafeCell` due to nested borrows. The context must be borrowed mutably when\n    /// swapping to the guest context, which means that borrow exists for the entire time the guest\n    /// function runs even though the mutation to the host context is done only at the beginning of\n    /// the swap. Meanwhile, the signal handler can run at any point during the guest function, and\n    /// so it also must be able to immutably borrow the host context if it needs to swap back. The\n    /// runtime borrowing constraints for a `RefCell` are therefore too strict for this variable.\n    pub(crate) static HOST_CTX: UnsafeCell<Context> = UnsafeCell::new(Context::new());\n\n    /// The currently-running `Instance`, if one exists.\n    pub(crate) static CURRENT_INSTANCE: RefCell<Option<NonNull<Instance>>> = RefCell::new(None);\n}\n\n/// A smart pointer to an [`Instance`](struct.Instance.html) that properly manages cleanup when dropped.\n///\n/// Instances are always stored in memory backed by a `Region`; we never want to create one directly\n/// with the Rust allocator. This type allows us to abide by that rule while also having an owned\n/// type that cleans up the instance when we are done with it.\n///\n/// Since this type implements `Deref` and `DerefMut` to `Instance`, it can usually be treated as\n/// though it were a `&mut Instance`.\npub struct InstanceHandle {\n    inst: NonNull<Instance>,\n    needs_inst_drop: bool,\n}\n\n// raw pointer lint\nunsafe impl Send for InstanceHandle {}\n\n/// Create a new `InstanceHandle`.\n///\n/// This is not meant for public consumption, but rather is used to make implementations of\n/// `Region`.\npub fn new_instance_handle(\n    instance: *mut Instance,\n    module: Arc<dyn Module>,\n    alloc: Alloc,\n    embed_ctx: CtxMap,\n) -> Result<InstanceHandle, Error> {\n    let inst = NonNull::new(instance)\n        .ok_or_else(|| lucet_format_err!(\"instance pointer is null; this is a bug\"))?;\n\n    lucet_ensure!(\n        unsafe { inst.as_ref().magic } != LUCET_INSTANCE_MAGIC,\n        \"created a new instance handle in memory with existing instance magic; this is a bug\"\n    );\n\n    let mut handle = InstanceHandle {\n        inst,\n        needs_inst_drop: false,\n    };\n\n    let inst = Instance::new(alloc, module, embed_ctx);\n\n    unsafe {\n        // this is wildly unsafe! you must be very careful to not let the drop impls run on the\n        // uninitialized fields; see\n        // <https://doc.rust-lang.org/std/mem/fn.forget.html#use-case-1>\n\n        // write the whole struct into place over the uninitialized page\n        ptr::write(&mut *handle, inst);\n    };\n\n    handle.needs_inst_drop = true;\n\n    handle.reset()?;\n\n    Ok(handle)\n}\n\npub fn instance_handle_to_raw(mut inst: InstanceHandle) -> *mut Instance {\n    inst.needs_inst_drop = false;\n    inst.inst.as_ptr()\n}\n\npub unsafe fn instance_handle_from_raw(\n    ptr: *mut Instance,\n    needs_inst_drop: bool,\n) -> InstanceHandle {\n    InstanceHandle {\n        inst: NonNull::new_unchecked(ptr),\n        needs_inst_drop,\n    }\n}\n\n// Safety argument for these deref impls: the instance's `Alloc` field contains an `Arc` to the\n// region that backs this memory, keeping the page containing the `Instance` alive as long as the\n// region exists\n\nimpl Deref for InstanceHandle {\n    type Target = Instance;\n    fn deref(&self) -> &Self::Target {\n        unsafe { self.inst.as_ref() }\n    }\n}\n\nimpl DerefMut for InstanceHandle {\n    fn deref_mut(&mut self) -> &mut Self::Target {\n        unsafe { self.inst.as_mut() }\n    }\n}\n\nimpl Drop for InstanceHandle {\n    fn drop(&mut self) {\n        if self.needs_inst_drop {\n            unsafe {\n                let inst = self.inst.as_mut();\n\n                // Grab a handle to the region to ensure it outlives `inst`.\n                //\n                // This ensures that the region won't be dropped by `inst` being\n                // dropped, which could result in `inst` being unmapped by the\n                // Region *during* drop of the Instance's fields.\n                let region: Arc<dyn RegionInternal> = inst.alloc().region.clone();\n\n                // drop the actual instance\n                std::ptr::drop_in_place(inst);\n\n                // and now we can drop what may be the last Arc<Region>. If it is\n                // it can safely do what it needs with memory; we're not running\n                // destructors on it anymore.\n                mem::drop(region);\n            }\n        }\n    }\n}\n\n/// A Lucet program, together with its dedicated memory and signal handlers.\n///\n/// This is the primary interface for running programs, examining return values, and accessing the\n/// WebAssembly heap.\n///\n/// `Instance`s are never created by runtime users directly, but rather are acquired from\n/// [`Region`](../region/trait.Region.html)s and often accessed through\n/// [`InstanceHandle`](../instance/struct.InstanceHandle.html) smart pointers. This guarantees that instances\n/// and their fields are never moved in memory, otherwise raw pointers in the metadata could be\n/// unsafely invalidated.\n///\n/// An instance occupies one 4096-byte page in memory, with a layout like:\n/// ```text\n/// 0xXXXXX000:\n///   Instance {\n///     .magic\n///     .embed_ctx\n///      ... etc ...\n///   }\n///\n///   // unused space\n///\n///   InstanceInternals {\n///     .globals\n///     .instruction_counter\n///   } // last address *inside* `InstanceInternals` is 0xXXXXXFFF\n/// 0xXXXXY000: // start of next page, VMContext points here\n///   Heap {\n///     ..\n///   }\n/// ```\n///\n/// This layout allows modules to tightly couple to a handful of fields related to the instance,\n/// rather than possibly requiring compiler-side changes (and recompiles) whenever `Instance`\n/// changes.\n///\n/// It also obligates `Instance` to be immediately followed by the heap, but otherwise leaves the\n/// locations of the stack, globals, and any other data, to be implementation-defined by the\n/// `Region` that actually creates `Slot`s onto which `Instance` are mapped.\n/// For information about the layout of all instance-related memory, see the documentation of\n/// [MmapRegion](../region/mmap/struct.MmapRegion.html).\n#[repr(C)]\n#[repr(align(4096))]\npub struct Instance {\n    /// Used to catch bugs in pointer math used to find the address of the instance\n    magic: u64,\n\n    /// The embedding context is a map containing embedder-specific values that are used to\n    /// implement hostcalls\n    pub(crate) embed_ctx: CtxMap,\n\n    /// The program (WebAssembly module) that is the entrypoint for the instance.\n    pub(crate) module: Arc<dyn Module>,\n\n    /// The `Context` in which the guest program runs\n    pub(crate) ctx: Context,\n\n    /// Instance state and error information\n    pub(crate) state: State,\n\n    /// Small mutexed state used for remote kill switch functionality\n    pub(crate) kill_state: Arc<KillState>,\n\n    #[cfg(feature = \"concurrent_testpoints\")]\n    /// Conditionally-present helpers to force permutations of possible races in testing.\n    pub lock_testpoints: Arc<LockTestpoints>,\n\n    /// The memory allocated for this instance\n    alloc: Alloc,\n\n    /// Handler run for signals that do not arise from a known WebAssembly trap, or that involve\n    /// memory outside of the current instance.\n    fatal_handler: fn(&Instance) -> !,\n\n    /// A fatal handler set from C\n    c_fatal_handler: Option<unsafe extern \"C\" fn(*mut Instance)>,\n\n    /// Handler run when `SIGBUS`, `SIGFPE`, `SIGILL`, or `SIGSEGV` are caught by the instance thread.\n    signal_handler: Box<\n        dyn Fn(\n            &Instance,\n            &Option<TrapCode>,\n            libc::c_int,\n            *const siginfo_t,\n            *const c_void,\n        ) -> SignalBehavior,\n    >,\n\n    /// Whether to ensure the Lucet signal handler is installed when running this instance.\n    ensure_signal_handler_installed: bool,\n\n    /// Whether to install an alternate signal stack while the instance is running.\n    ensure_sigstack_installed: bool,\n\n    /// Pointer to the function used as the entrypoint.\n    entrypoint: Option<FunctionHandle>,\n\n    /// The value passed back to the guest when resuming a yielded instance.\n    pub(crate) resumed_val: Option<Box<dyn Any + 'static>>,\n\n    pub(crate) memory_limiter: Option<Box<dyn MemoryLimiter + Send + Sync + 'static>>,\n\n    /// `_padding` must be the last member of the structure.\n    /// This marks where the padding starts to make the structure exactly 4096 bytes long.\n    /// It is also used to compute the size of the structure up to that point, i.e. without padding.\n    _padding: (),\n}\n\n#[async_trait::async_trait]\npub trait MemoryLimiter {\n    async fn memory_growing(&mut self, current: usize, desired: usize) -> bool;\n    fn memory_grow_failed(&mut self, _error: &Error) {}\n}\n\n/// Users of `Instance` must be very careful about when instances are dropped!\n///\n/// Typically you will not have to worry about this, as InstanceHandle will robustly handle\n/// Instance drop semantics. If an instance is dropped, and the Region it's in has already dropped,\n/// it may contain the last reference counted pointer to its Region. If so, when Instance's\n/// destructor runs, Region will be dropped, and may free or otherwise invalidate the memory that\n/// this Instance exists in, *while* the Instance destructor is executing.\nimpl Drop for Instance {\n    fn drop(&mut self) {\n        // Reset magic to indicate this instance\n        // is no longer valid\n        self.magic = 0;\n    }\n}\n\n/// The result of running or resuming an [`Instance`](struct.Instance.html).\n#[derive(Debug)]\npub enum RunResult {\n    /// An instance returned with a value.\n    ///\n    /// The actual type of the contained value depends on the return type of the guest function that\n    /// was called. For guest functions with no return value, it is undefined behavior to do\n    /// anything with this value.\n    Returned(UntypedRetVal),\n    /// An instance yielded, potentially with a value.\n    ///\n    /// This arises when a hostcall invokes one of the\n    /// [`Vmctx::yield_*()`](vmctx/struct.Vmctx.html#method.yield_) family of methods. Depending on which\n    /// variant is used, the `YieldedVal` may contain a value passed from the guest context to the\n    /// host.\n    ///\n    /// An instance that has yielded may only be resumed\n    /// ([with](struct.Instance.html#method.resume_with_val) or\n    /// [without](struct.Instance.html#method.resume) a value to returned to the guest),\n    /// [reset](struct.Instance.html#method.reset), or dropped. Attempting to run an instance from a\n    /// new entrypoint after it has yielded but without first resetting will result in an error.\n    Yielded(YieldedVal),\n}\n\nimpl RunResult {\n    /// Try to get a return value from a run result, returning `Error::InstanceNotReturned` if the\n    /// instance instead yielded.\n    pub fn returned(self) -> Result<UntypedRetVal, Error> {\n        match self {\n            RunResult::Returned(rv) => Ok(rv),\n            RunResult::Yielded(_) => Err(Error::InstanceNotReturned),\n        }\n    }\n\n    /// Try to get a reference to a return value from a run result, returning\n    /// `Error::InstanceNotReturned` if the instance instead yielded.\n    pub fn returned_ref(&self) -> Result<&UntypedRetVal, Error> {\n        match self {\n            RunResult::Returned(rv) => Ok(rv),\n            RunResult::Yielded(_) => Err(Error::InstanceNotReturned),\n        }\n    }\n\n    /// Returns `true` if the instance returned a value.\n    pub fn is_returned(&self) -> bool {\n        self.returned_ref().is_ok()\n    }\n\n    /// Unwraps a run result into a return value.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the instance instead yielded, with a panic message including the passed message.\n    pub fn expect_returned(self, msg: &str) -> UntypedRetVal {\n        self.returned().expect(msg)\n    }\n\n    /// Unwraps a run result into a returned value.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the instance instead yielded.\n    pub fn unwrap_returned(self) -> UntypedRetVal {\n        self.returned().unwrap()\n    }\n\n    /// Try to get a yielded value from a run result, returning `Error::InstanceNotYielded` if the\n    /// instance instead returned.\n    pub fn yielded(self) -> Result<YieldedVal, Error> {\n        match self {\n            RunResult::Returned(_) => Err(Error::InstanceNotYielded),\n            RunResult::Yielded(yv) => Ok(yv),\n        }\n    }\n\n    /// Try to get a reference to a yielded value from a run result, returning\n    /// `Error::InstanceNotYielded` if the instance instead returned.\n    pub fn yielded_ref(&self) -> Result<&YieldedVal, Error> {\n        match self {\n            RunResult::Returned(_) => Err(Error::InstanceNotYielded),\n            RunResult::Yielded(yv) => Ok(yv),\n        }\n    }\n\n    /// Returns `true` if the instance yielded.\n    pub fn is_yielded(&self) -> bool {\n        self.yielded_ref().is_ok()\n    }\n\n    /// Returns `true` if the instance can be resumed: either it has yielded, or its bound has\n    /// expired.\n    pub fn can_resume(&self) -> bool {\n        self.is_yielded()\n    }\n\n    /// Returns `true` if the instance has yielded a value of the given type.\n    pub fn has_yielded<A: Any>(&self) -> bool {\n        match self {\n            RunResult::Yielded(yv) => yv.is::<A>(),\n            _ => false,\n        }\n    }\n\n    /// Unwraps a run result into a yielded value.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the instance instead returned, with a panic message including the passed message.\n    pub fn expect_yielded(self, msg: &str) -> YieldedVal {\n        self.yielded().expect(msg)\n    }\n\n    /// Unwraps a run result into a yielded value.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the instance instead returned.\n    pub fn unwrap_yielded(self) -> YieldedVal {\n        self.yielded().unwrap()\n    }\n}\n\n/// An \"internal\" run result: either a `RunResult` or a bound expiration. We do not expose bound\n/// expirations to the caller directly; rather, we only handle them in `run_async()`.\npub(crate) enum InternalRunResult {\n    Normal(RunResult),\n    BoundExpired,\n}\n\nimpl InternalRunResult {\n    pub(crate) fn unwrap(self) -> RunResult {\n        match self {\n            InternalRunResult::Normal(result) => result,\n            InternalRunResult::BoundExpired => panic!(\"should not have had a runtime bound\"),\n        }\n    }\n}\n\nimpl std::convert::Into<InternalRunResult> for RunResult {\n    fn into(self) -> InternalRunResult {\n        InternalRunResult::Normal(self)\n    }\n}\n\n/// APIs that are internal, but useful to implementors of extension modules; you probably don't want\n/// this trait!\n///\n/// This is a trait rather than inherent `impl`s in order to keep the `lucet-runtime` API clean and\n/// safe.\npub trait InstanceInternal {\n    fn alloc(&self) -> &Alloc;\n    fn alloc_mut(&mut self) -> &mut Alloc;\n    fn module(&self) -> &dyn Module;\n    fn state(&self) -> &State;\n    fn valid_magic(&self) -> bool;\n}\n\nimpl InstanceInternal for Instance {\n    /// Get a reference to the instance's `Alloc`.\n    fn alloc(&self) -> &Alloc {\n        &self.alloc\n    }\n\n    /// Get a mutable reference to the instance's `Alloc`.\n    fn alloc_mut(&mut self) -> &mut Alloc {\n        &mut self.alloc\n    }\n\n    /// Get a reference to the instance's `Module`.\n    fn module(&self) -> &dyn Module {\n        self.module.deref()\n    }\n\n    /// Get a reference to the instance's `State`.\n    fn state(&self) -> &State {\n        &self.state\n    }\n\n    /// Check whether the instance magic is valid.\n    fn valid_magic(&self) -> bool {\n        self.magic == LUCET_INSTANCE_MAGIC\n    }\n}\n\n// Public API\nimpl Instance {\n    /// Run a function with arguments in the guest context at the given entrypoint.\n    ///\n    /// ```no_run\n    /// # use lucet_runtime_internals::instance::InstanceHandle;\n    /// # let instance: InstanceHandle = unimplemented!();\n    /// // regular execution yields `Ok(UntypedRetVal)`\n    /// let retval = instance.run(\"factorial\", &[5u64.into()]).unwrap().unwrap_returned();\n    /// assert_eq!(u64::from(retval), 120u64);\n    ///\n    /// // runtime faults yield `Err(Error)`\n    /// let result = instance.run(\"faulting_function\", &[]);\n    /// assert!(result.is_err());\n    /// ```\n    ///\n    /// # Safety\n    ///\n    /// This is unsafe in two ways:\n    ///\n    /// - The type of the entrypoint might not be correct. It might take a different number or\n    /// different types of arguments than are provided to `args`. It might not even point to a\n    /// function! We will likely add type information to `lucetc` output so we can dynamically check\n    /// the type in the future.\n    ///\n    /// - The entrypoint is foreign code. While we may be convinced that WebAssembly compiled to\n    /// native code by `lucetc` is safe, we do not have the same guarantee for the hostcalls that a\n    /// guest may invoke. They might be implemented in an unsafe language, so we must treat this\n    /// call as unsafe, just like any other FFI call.\n    ///\n    /// For the moment, we do not mark this as `unsafe` in the Rust type system, but that may change\n    /// in the future.\n    pub fn run(&mut self, entrypoint: &str, args: &[Val]) -> Result<RunResult, Error> {\n        let func = self.module.get_export_func(entrypoint)?;\n        Ok(self.run_func(func, &args, false, None)?.unwrap())\n    }\n\n    /// Run a function with arguments in the guest context from the [WebAssembly function\n    /// table](https://webassembly.github.io/spec/core/syntax/modules.html#tables).\n    ///\n    /// # Safety\n    ///\n    /// The same safety caveats of [`Instance::run()`](struct.Instance.html#method.run) apply.\n    pub fn run_func_idx(\n        &mut self,\n        table_idx: u32,\n        func_idx: u32,\n        args: &[Val],\n    ) -> Result<RunResult, Error> {\n        let func = self.module.get_func_from_idx(table_idx, func_idx)?;\n        Ok(self.run_func(func, &args, false, None)?.unwrap())\n    }\n\n    /// Resume execution of an instance that has yielded without providing a value to the guest.\n    ///\n    /// This should only be used when the guest yielded with\n    /// [`Vmctx::yield_()`](vmctx/struct.Vmctx.html#method.yield_) or\n    /// [`Vmctx::yield_val()`](vmctx/struct.Vmctx.html#method.yield_val).\n    ///\n    /// # Safety\n    ///\n    /// The foreign code safety caveat of [`Instance::run()`](struct.Instance.html#method.run)\n    /// applies.\n    pub fn resume(&mut self) -> Result<RunResult, Error> {\n        self.resume_with_val(EmptyYieldVal)\n    }\n\n    /// Resume execution of an instance that has yielded, providing a value to the guest.\n    ///\n    /// The type of the provided value must match the type expected by\n    /// [`Vmctx::yield_expecting_val()`](vmctx/struct.Vmctx.html#method.yield_expecting_val) or\n    /// [`Vmctx::yield_val_expecting_val()`](vmctx/struct.Vmctx.html#method.yield_val_expecting_val).\n    ///\n    /// The provided value will be dynamically typechecked against the type the guest expects to\n    /// receive, and if that check fails, this call will fail with `Error::InvalidArgument`.\n    ///\n    /// # Safety\n    ///\n    /// The foreign code safety caveat of [`Instance::run()`](struct.Instance.html#method.run)\n    /// applies.\n    pub fn resume_with_val<A: Any + 'static>(&mut self, val: A) -> Result<RunResult, Error> {\n        Ok(self.resume_with_val_impl(val, false, None)?.unwrap())\n    }\n\n    pub(crate) fn resume_with_val_impl<A: Any + 'static>(\n        &mut self,\n        val: A,\n        async_context: bool,\n        max_insn_count: Option<u64>,\n    ) -> Result<InternalRunResult, Error> {\n        match &self.state {\n            State::Yielded { expecting, .. } => {\n                // make sure the resumed value is of the right type\n                if !expecting.is::<PhantomData<A>>() {\n                    return Err(Error::InvalidArgument(\n                        \"type mismatch between yielded instance expected value and resumed value\",\n                    ));\n                }\n            }\n            _ => return Err(Error::InvalidArgument(\"can only resume a yielded instance\")),\n        }\n\n        self.resumed_val = Some(Box::new(val) as Box<dyn Any + 'static>);\n\n        self.set_instruction_bound_delta(max_insn_count);\n        self.swap_and_return(async_context)\n    }\n\n    /// Resume execution of an instance that has previously reached an instruction bound.\n    ///\n    /// The execution slice that begins with this call is bounded by the new bound provided.\n    ///\n    /// This should only be used when `run_func()` returned a `RunResult::Bounded`. This is an\n    /// internal function used by `run_async()`.\n    ///\n    /// # Safety\n    ///\n    /// The foreign code safety caveat of [`Instance::run()`](struct.Instance.html#method.run)\n    /// applies.\n    pub(crate) fn resume_bounded(\n        &mut self,\n        max_insn_count: u64,\n    ) -> Result<InternalRunResult, Error> {\n        if !self.state.is_bound_expired() {\n            return Err(Error::InvalidArgument(\n                \"can only call resume_bounded() on an instance that hit an instruction bound\",\n            ));\n        }\n        self.set_instruction_bound_delta(Some(max_insn_count));\n        self.swap_and_return(true)\n    }\n\n    /// Run the module's [start function][start], if one exists.\n    ///\n    /// If there is no start function in the module, this does nothing.\n    ///\n    /// If the module contains a start function, you must run it before running any other exported\n    /// functions. If an instance is reset, you must run the start function again.\n    ///\n    /// Start functions may assume that Wasm tables and memories are properly initialized, but may\n    /// not assume that imported functions or globals are available.\n    ///\n    /// # Errors\n    ///\n    /// In addition to the errors that can be returned from [`Instance::run()`][run], this can also\n    /// return `Error::StartYielded` if the start function attempts to yield. This should not arise\n    /// as long as the start function does not attempt to use any imported functions.\n    ///\n    /// This also returns `Error::StartAlreadyRun` if the start function has already run since the\n    /// instance was created or last reset.\n    ///\n    /// Wasm start functions are not allowed to call imported functions. If the start function\n    /// attempts to do so, the instance will be terminated with\n    /// `TerminationDetails::StartCalledImportFunc`.\n    ///\n    /// # Safety\n    ///\n    /// The foreign code safety caveat of [`Instance::run()`][run]\n    /// applies.\n    ///\n    /// [run]: struct.Instance.html#method.run\n    /// [start]: https://webassembly.github.io/spec/core/syntax/modules.html#syntax-start\n    pub fn run_start(&mut self) -> Result<(), Error> {\n        if let Some(start) = self.module.get_start_func()? {\n            if !self.is_not_started() {\n                return Err(Error::StartAlreadyRun);\n            }\n            self.run_func(start, &[], false, None)?;\n        }\n        Ok(())\n    }\n\n    /// Reset the instance's heap and global variables to their initial state.\n    ///\n    /// The WebAssembly `start` section, if present, will need to be re-run with\n    /// [`Instance::run_start()`][run_start] before running any other exported functions.\n    ///\n    /// The embedder contexts present at instance creation or added with\n    /// [`Instance::insert_embed_ctx()`](struct.Instance.html#method.insert_embed_ctx) are not\n    /// modified by this call; it is the embedder's responsibility to clear or reset their state if\n    /// necessary.\n    ///\n    /// This will also reinitialize the kill state, which means that any outstanding\n    /// [`KillSwitch`](struct.KillSwitch.html) objects will be unable to terminate this instance.\n    /// It is the embedder's responsibility to initialize new `KillSwitch`es after resetting an\n    /// instance.\n    ///\n    /// [run_start]: struct.Instance.html#method.run\n    pub fn reset(&mut self) -> Result<(), Error> {\n        self.alloc.reset_heap(self.module.as_ref())?;\n        let globals = unsafe { self.alloc.globals_mut() };\n        let mod_globals = self.module.globals();\n        for (i, v) in mod_globals.iter().enumerate() {\n            globals[i] = match v.global() {\n                Global::Import { .. } => {\n                    return Err(Error::Unsupported(format!(\n                        \"global imports are unsupported; found: {:?}\",\n                        v\n                    )));\n                }\n                Global::Def(def) => def.init_val(),\n            };\n        }\n\n        if self.module.get_start_func()?.is_some() {\n            self.state = State::NotStarted;\n        } else {\n            self.state = State::Ready;\n        }\n\n        #[cfg(feature = \"concurrent_testpoints\")]\n        {\n            self.kill_state = Arc::new(KillState::new(Arc::clone(&self.lock_testpoints)));\n        }\n        #[cfg(not(feature = \"concurrent_testpoints\"))]\n        {\n            self.kill_state = Arc::new(KillState::new());\n        }\n\n        Ok(())\n    }\n\n    /// Grow the guest memory by the given number of WebAssembly pages.\n    ///\n    /// On success, returns the number of pages that existed before the call.\n    pub fn grow_memory(&mut self, additional_pages: u32) -> Result<u32, Error> {\n        let additional_bytes = additional_pages\n            .checked_mul(WASM_PAGE_SIZE)\n            .ok_or_else(|| lucet_format_err!(\"additional pages larger than wasm address space\",))?;\n        let orig_len = self\n            .alloc\n            .expand_heap(additional_bytes, self.module.as_ref())?;\n        Ok(orig_len / WASM_PAGE_SIZE)\n    }\n\n    /// Grow memory from a hostcall context.\n    pub fn grow_memory_from_hostcall(\n        &mut self,\n        vmctx: &Vmctx,\n        additional_pages: u32,\n    ) -> Result<u32, Error> {\n        // Use a function so that we can report all Errs via memory_grow_failed.\n        fn aux(\n            instance: &mut Instance,\n            vmctx: &Vmctx,\n            additional_pages: u32,\n        ) -> Result<u32, Error> {\n            // Calculate current and desired bytes\n            let current_bytes = instance.alloc.heap_len();\n            let additional_bytes =\n                additional_pages\n                    .checked_mul(WASM_PAGE_SIZE)\n                    .ok_or_else(|| {\n                        lucet_format_err!(\"additional pages larger than wasm address space\",)\n                    })? as usize;\n            let desired_bytes = additional_bytes\n                .checked_add(current_bytes)\n                .ok_or_else(|| lucet_format_err!(\"desired bytes overflow\",))?;\n            // Let the limiter reject the grow\n            if let Some(ref mut limiter) = instance.memory_limiter {\n                if !vmctx.block_on(async move {\n                    limiter.memory_growing(current_bytes, desired_bytes).await\n                }) {\n                    lucet_bail!(\"memory limiter denied growth\");\n                }\n            }\n            // Try the grow itself\n            instance.grow_memory(additional_pages)\n        }\n\n        match aux(self, vmctx, additional_pages) {\n            Ok(n) => Ok(n),\n            Err(e) => {\n                if let Some(ref mut limiter) = self.memory_limiter {\n                    limiter.memory_grow_failed(&e);\n                    Err(e)\n                } else {\n                    Err(e)\n                }\n            }\n        }\n    }\n\n    /// Return the WebAssembly heap as a slice of bytes.\n    pub fn heap(&self) -> &[u8] {\n        unsafe { self.alloc.heap() }\n    }\n\n    /// Return the WebAssembly heap as a mutable slice of bytes.\n    pub fn heap_mut(&mut self) -> &mut [u8] {\n        unsafe { self.alloc.heap_mut() }\n    }\n\n    /// Return the WebAssembly heap as a slice of `u32`s.\n    pub fn heap_u32(&self) -> &[u32] {\n        unsafe { self.alloc.heap_u32() }\n    }\n\n    /// Return the WebAssembly heap as a mutable slice of `u32`s.\n    pub fn heap_u32_mut(&mut self) -> &mut [u32] {\n        unsafe { self.alloc.heap_u32_mut() }\n    }\n\n    /// Return the WebAssembly globals as a slice of `i64`s.\n    pub fn globals(&self) -> &[GlobalValue] {\n        unsafe { self.alloc.globals() }\n    }\n\n    /// Return the WebAssembly globals as a mutable slice of `i64`s.\n    pub fn globals_mut(&mut self) -> &mut [GlobalValue] {\n        unsafe { self.alloc.globals_mut() }\n    }\n\n    /// Check whether a given range in the host address space overlaps with the memory that backs\n    /// the instance heap.\n    pub fn check_heap<T>(&self, ptr: *const T, len: usize) -> bool {\n        self.alloc.mem_in_heap(ptr, len)\n    }\n\n    /// Check whether a context value of a particular type exists.\n    pub fn contains_embed_ctx<T: Any>(&self) -> bool {\n        self.embed_ctx.contains::<T>()\n    }\n\n    /// Get a reference to a context value of a particular type, if it exists.\n    pub fn get_embed_ctx<T: Any>(&self) -> Option<Result<Ref<'_, T>, BorrowError>> {\n        self.embed_ctx.try_get::<T>()\n    }\n\n    /// Get a mutable reference to a context value of a particular type, if it exists.\n    pub fn get_embed_ctx_mut<T: Any>(&self) -> Option<Result<RefMut<'_, T>, BorrowMutError>> {\n        self.embed_ctx.try_get_mut::<T>()\n    }\n\n    /// Insert a context value.\n    ///\n    /// If a context value of the same type already existed, it is returned.\n    pub fn insert_embed_ctx<T: Any>(&mut self, x: T) -> Option<T> {\n        self.embed_ctx.insert(x)\n    }\n\n    /// Remove a context value of a particular type, returning it if it exists.\n    pub fn remove_embed_ctx<T: Any>(&mut self) -> Option<T> {\n        self.embed_ctx.remove::<T>()\n    }\n\n    /// Set the handler run when `SIGBUS`, `SIGFPE`, `SIGILL`, or `SIGSEGV` are caught by the\n    /// instance thread.\n    ///\n    /// In most cases, these signals are unrecoverable for the instance that raised them, but do not\n    /// affect the rest of the process.\n    ///\n    /// The default signal handler returns\n    /// [`SignalBehavior::Default`](enum.SignalBehavior.html#variant.Default), which yields a\n    /// runtime fault error.\n    ///\n    /// The signal handler must be\n    /// [signal-safe](http://man7.org/linux/man-pages/man7/signal-safety.7.html).\n    pub fn set_signal_handler<H>(&mut self, handler: H)\n    where\n        H: 'static\n            + Fn(\n                &Instance,\n                &Option<TrapCode>,\n                libc::c_int,\n                *const siginfo_t,\n                *const c_void,\n            ) -> SignalBehavior,\n    {\n        self.signal_handler = Box::new(handler) as Box<SignalHandler>;\n    }\n\n    /// Set the handler run for signals that do not arise from a known WebAssembly trap, or that\n    /// involve memory outside of the current instance.\n    ///\n    /// Fatal signals are not only unrecoverable for the instance that raised them, but may\n    /// compromise the correctness of the rest of the process if unhandled.\n    ///\n    /// The default fatal handler calls `panic!()`.\n    pub fn set_fatal_handler(&mut self, handler: fn(&Instance) -> !) {\n        self.fatal_handler = handler;\n    }\n\n    /// Set the fatal handler to a C-compatible function.\n    ///\n    /// This is a separate interface, because C functions can't return the `!` type. Like the\n    /// regular `fatal_handler`, it is not expected to return, but we cannot enforce that through\n    /// types.\n    ///\n    /// When a fatal error occurs, this handler is run first, and then the regular `fatal_handler`\n    /// runs in case it returns.\n    pub fn set_c_fatal_handler(&mut self, handler: unsafe extern \"C\" fn(*mut Instance)) {\n        self.c_fatal_handler = Some(handler);\n    }\n\n    /// Set whether the Lucet signal handler is installed when running or resuming this instance\n    /// (`true` by default).\n    ///\n    /// If this is `true`, the Lucet runtime checks whether its signal handler is installed whenever\n    /// an instance runs, installing it if it is not present, and uninstalling it when there are no\n    /// longer any Lucet instances running. If this is `false`, that check is disabled, which can\n    /// improve performance when running or resuming an instance.\n    ///\n    /// Use `install_lucet_signal_handler()` and `remove_lucet_signal_handler()` to manually install\n    /// or remove the signal handler.\n    ///\n    /// # Safety\n    ///\n    /// If the Lucet signal handler is not installed when an instance runs, WebAssembly traps such\n    /// as division by zero, assertion failures, or out-of-bounds memory access will raise signals\n    /// to the default signal handlers, usually causing the entire process to crash.\n    pub fn ensure_signal_handler_installed(&mut self, ensure: bool) {\n        self.ensure_signal_handler_installed = ensure;\n    }\n\n    /// Set whether an alternate signal stack is installed for the current thread when running or\n    /// resuming this instance (`true` by default).\n    ///\n    /// If this is `true`, the Lucet runtime installs an alternate signal stack whenever an instance\n    /// runs, and uninstalls it afterwards. If this is `false`, the signal stack is not\n    /// automatically manipulated.\n    ///\n    /// The automatically-installed signal stack uses space allocated in the instance's `Region`,\n    /// sized according to the `signal_stack_size` field of the region's `Limits`.\n    ///\n    /// If you wish to instead provide your own signal stack, we recommend using a stack of size\n    /// `DEFAULT_SIGNAL_STACK_SIZE`, which varies depending on platform and optimization level.\n    ///\n    /// Signal stacks are installed on a per-thread basis, so any thread that runs this instance\n    /// must have a signal stack installed.\n    ///\n    /// # Safety\n    ///\n    /// If an alternate signal stack is not installed when an instance runs, there may not be enough\n    /// stack space for the Lucet signal handler to run. If the signal handler runs out of stack\n    /// space, a double fault could occur and crash the entire process, or the program could\n    /// continue with corrupted memory.\n    pub fn ensure_sigstack_installed(&mut self, ensure: bool) {\n        self.ensure_sigstack_installed = ensure;\n    }\n\n    pub fn kill_switch(&self) -> KillSwitch {\n        KillSwitch::new(Arc::downgrade(&self.kill_state))\n    }\n\n    pub fn is_not_started(&self) -> bool {\n        self.state.is_not_started()\n    }\n\n    pub fn is_ready(&self) -> bool {\n        self.state.is_ready()\n    }\n\n    pub fn is_yielded(&self) -> bool {\n        self.state.is_yielded()\n    }\n\n    pub fn is_bound_expired(&self) -> bool {\n        self.state.is_bound_expired()\n    }\n\n    pub fn is_faulted(&self) -> bool {\n        self.state.is_faulted()\n    }\n\n    pub fn is_terminated(&self) -> bool {\n        self.state.is_terminated()\n    }\n\n    // This needs to be public as it's used in the expansion of `lucet_hostcalls`, available for\n    // external use. But you *really* shouldn't have to call this yourself, so we're going to keep\n    // it out of rustdoc.\n    #[doc(hidden)]\n    pub fn uninterruptable<T, F: FnOnce() -> T>(&mut self, f: F) -> T {\n        self.kill_state.begin_hostcall();\n        let res = f();\n        let stop_reason = self.kill_state.end_hostcall();\n\n        if let Some(termination_details) = stop_reason {\n            // TODO: once we have unwinding, panic here instead so we unwind host frames\n            unsafe {\n                self.terminate(termination_details);\n            }\n        }\n\n        res\n    }\n\n    #[inline]\n    pub fn get_instruction_count(&self) -> Option<u64> {\n        if self.module.is_instruction_count_instrumented() {\n            let implicits = self.get_instance_implicits();\n            let sum = implicits.instruction_count_bound + implicits.instruction_count_adj;\n            // This invariant is ensured as we always set up the fields to have a positive sum, and\n            // generated code only increments `adj`.\n            debug_assert!(sum >= 0);\n            return Some(sum as u64);\n        }\n        None\n    }\n\n    /// Set the total instruction count and bound.\n    #[inline]\n    pub fn set_instruction_count_and_bound(&mut self, instruction_count: u64, bound: u64) {\n        let implicits = self.get_instance_implicits_mut();\n        let instruction_count =\n            i64::try_from(instruction_count).expect(\"instruction count too large\");\n        let bound = i64::try_from(bound).expect(\"bound too large\");\n        // These two sum to `instruction_count`, which must be non-negative.\n        implicits.instruction_count_bound = bound;\n        implicits.instruction_count_adj = instruction_count - bound;\n    }\n\n    /// Set the instruction bound to be `delta` above the current count.\n    ///\n    /// See the comments on `instruction_count_adj` in `InstanceRuntimeData` for more details on\n    /// how this bound works; most relevant is that a bound-yield is only triggered if the bound\n    /// value is *crossed*, but not if execution *begins* with the value exceeded. Hence `delta`\n    /// must be greater than zero for this to set up the instance state to trigger a yield.\n    #[inline]\n    pub fn set_instruction_bound_delta(&mut self, delta: Option<u64>) {\n        let implicits = self.get_instance_implicits_mut();\n        let sum = implicits.instruction_count_adj + implicits.instruction_count_bound;\n        let delta = delta.unwrap_or(i64::MAX as u64);\n        let delta = i64::try_from(delta).expect(\"delta too large\");\n        implicits.instruction_count_bound = sum.wrapping_add(delta);\n        implicits.instruction_count_adj = -delta;\n    }\n\n    #[inline]\n    pub fn set_hostcall_stack_reservation(&mut self) {\n        let slot = self\n            .alloc\n            .slot\n            .as_ref()\n            .expect(\"reachable instance has a slot\");\n\n        let reservation = slot.limits.hostcall_reservation;\n\n        // The `.stack` field is a pointer to the lowest address of the stack - the start of its\n        // allocation. Because the stack grows downward, this is the end of the stack space. So the\n        // limit we'll need to check for hostcalls is some reserved space upwards from here, to\n        // meet some guest stack pointer early.\n        self.get_instance_implicits_mut().stack_limit = slot.stack as u64 + reservation as u64;\n    }\n\n    /// Set a memory limiter for the instance.\n    ///\n    /// If set, this instance must be run asynchronously via [`InstanceHandle::run_async`]\n    pub fn set_memory_limiter(&mut self, limiter: Box<dyn MemoryLimiter + Send + Sync + 'static>) {\n        self.memory_limiter = Some(limiter)\n    }\n}\n\n// Private API\nimpl Instance {\n    fn new(alloc: Alloc, module: Arc<dyn Module>, embed_ctx: CtxMap) -> Self {\n        let globals_ptr = alloc.slot().globals as *mut i64;\n\n        #[cfg(feature = \"concurrent_testpoints\")]\n        let lock_testpoints = Arc::new(LockTestpoints::new());\n\n        #[cfg(feature = \"concurrent_testpoints\")]\n        let kill_state = Arc::new(KillState::new(Arc::clone(&lock_testpoints)));\n        #[cfg(not(feature = \"concurrent_testpoints\"))]\n        let kill_state = Arc::new(KillState::new());\n\n        let mut inst = Instance {\n            magic: LUCET_INSTANCE_MAGIC,\n            embed_ctx,\n            module,\n            ctx: Context::new(),\n            state: State::Ready,\n            kill_state,\n            #[cfg(feature = \"concurrent_testpoints\")]\n            lock_testpoints,\n            alloc,\n            fatal_handler: default_fatal_handler,\n            c_fatal_handler: None,\n            signal_handler: Box::new(signal_handler_none) as Box<SignalHandler>,\n            ensure_signal_handler_installed: true,\n            ensure_sigstack_installed: true,\n            entrypoint: None,\n            resumed_val: None,\n            memory_limiter: None,\n            _padding: (),\n        };\n        inst.set_globals_ptr(globals_ptr);\n        inst.set_instruction_count_and_bound(0, 0);\n        // Ensure the hostcall limit tracked in this instance's guest-shared data is up-to-date.\n        inst.set_hostcall_stack_reservation();\n\n        assert_eq!(mem::size_of::<Instance>(), HOST_PAGE_SIZE_EXPECTED);\n        let unpadded_size = offset_of!(Instance, _padding);\n        assert!(unpadded_size <= HOST_PAGE_SIZE_EXPECTED - mem::size_of::<*mut i64>());\n        inst\n    }\n\n    // The globals pointer must be stored right before the end of the structure, padded to the page size,\n    // so that it is 8 bytes before the heap.\n    // For this reason, the alignment of the structure is set to 4096, and we define accessors that\n    // read/write the globals pointer as bytes [4096-8..4096] of that structure represented as raw bytes.\n    // InstanceRuntimeData is placed such that it ends at the end of the page this `Instance` starts\n    // on. So we can access it by *self + PAGE_SIZE - size_of::<InstanceRuntimeData>\n    #[inline]\n    fn get_instance_implicits(&self) -> &InstanceRuntimeData {\n        unsafe {\n            let implicits_ptr = (self as *const _ as *const u8)\n                .add(HOST_PAGE_SIZE_EXPECTED - mem::size_of::<InstanceRuntimeData>())\n                as *const InstanceRuntimeData;\n            mem::transmute::<*const InstanceRuntimeData, &InstanceRuntimeData>(implicits_ptr)\n        }\n    }\n\n    #[inline]\n    fn get_instance_implicits_mut(&mut self) -> &mut InstanceRuntimeData {\n        unsafe {\n            let implicits_ptr = (self as *mut _ as *mut u8)\n                .add(HOST_PAGE_SIZE_EXPECTED - mem::size_of::<InstanceRuntimeData>())\n                as *mut InstanceRuntimeData;\n            mem::transmute::<*mut InstanceRuntimeData, &mut InstanceRuntimeData>(implicits_ptr)\n        }\n    }\n\n    #[allow(dead_code)]\n    #[inline]\n    fn get_globals_ptr(&self) -> *mut i64 {\n        self.get_instance_implicits().globals_ptr\n    }\n\n    #[inline]\n    fn set_globals_ptr(&mut self, globals_ptr: *mut i64) {\n        self.get_instance_implicits_mut().globals_ptr = globals_ptr\n    }\n\n    /// Run a function in guest context at the given entrypoint.\n    pub(crate) fn run_func(\n        &mut self,\n        func: FunctionHandle,\n        args: &[Val],\n        async_context: bool,\n        inst_count_bound: Option<u64>,\n    ) -> Result<InternalRunResult, Error> {\n        let needs_start = self.state.is_not_started() && !func.is_start_func;\n        if needs_start {\n            return Err(Error::InstanceNeedsStart);\n        }\n\n        let is_ready = self.state.is_ready();\n        let is_starting = self.state.is_not_started() && func.is_start_func;\n        let is_non_fatally_faulted = self.state.is_faulted() && !self.state.is_fatal();\n        if !(is_ready || is_starting || is_non_fatally_faulted) {\n            return Err(Error::InvalidArgument(\n                \"instance must be ready, starting, or non-fatally faulted\",\n            ));\n        }\n        if func.ptr.as_usize() == 0 {\n            return Err(Error::InvalidArgument(\n                \"entrypoint function cannot be null; this is probably a malformed module\",\n            ));\n        }\n\n        let sig = self.module.get_signature(func.id);\n\n        // in typechecking these values, we can only really check that arguments are correct.\n        // in the future we might want to make return value use more type safe as well.\n\n        if sig.params.len() != args.len() {\n            return Err(Error::InvalidArgument(\n                \"entrypoint function signature mismatch (number of arguments is incorrect)\",\n            ));\n        }\n\n        for (param_ty, arg) in sig.params.iter().zip(args.iter()) {\n            if param_ty != &arg.value_type() {\n                return Err(Error::InvalidArgument(\n                    \"entrypoint function signature mismatch\",\n                ));\n            }\n        }\n\n        self.entrypoint = Some(func);\n\n        let mut args_with_vmctx = vec![Val::from(self.alloc.slot().heap)];\n        args_with_vmctx.extend_from_slice(args);\n\n        self.set_instruction_bound_delta(inst_count_bound);\n\n        let self_ptr = self as *mut _;\n        Context::init_with_callback(\n            unsafe { self.alloc.stack_u64_mut() },\n            &mut self.ctx,\n            execution::exit_guest_region,\n            self_ptr,\n            func.ptr.as_usize(),\n            &args_with_vmctx,\n        )?;\n\n        self.install_activator();\n        self.swap_and_return(async_context)\n    }\n\n    /// Prepare the guest so that it will update its execution domain upon entry.\n    ///\n    /// This mutates the context's registers so that an activation function that will be run after\n    /// performing a context switch. This function (`enter_guest_region`) will mark the guest as\n    /// terminable before continuing to whatever guest code we want to run.\n    ///\n    /// `lucet_context_activate` takes three arguments in the following registers:\n    ///   * rdi: the data for the entry callback.\n    ///   * rsi: the address of the entry callback.\n    ///   * rbx: the address of the guest code to execute.\n    ///\n    /// The appropriate value for `rbx` is the top of the guest stack, which we would otherwise\n    /// return to and start executing immediately. For `rdi`, we want to pass our callback data\n    /// (a raw pointer to the instance). This will be passed as the first argument to the entry\n    /// function, which is responsible for updating the kill state's execution domain.\n    ///\n    /// See `lucet_runtime_internals::context::lucet_context_activate`, and\n    /// `execution::enter_guest_region` for more info.\n    // TODO KTM 2020-03-13: This should be a method on `Context`.\n    fn install_activator(&mut self) {\n        unsafe {\n            // Get a raw pointer to the top of the guest stack.\n            let top_of_stack = self.ctx.gpr.rsp as *mut u64;\n            // Move the guest code address to rbx, and then put the address of the activation thunk\n            // at the top of the stack, so that we will start execution at `enter_guest_region`.\n            self.ctx.gpr.rbx = *top_of_stack;\n            *top_of_stack = crate::context::lucet_context_activate as u64;\n            // Pass a pointer to our guest-side entrypoint bootstrap code in `rsi`, and then put\n            // its first argument (a raw pointer to `self`) in `rdi`.\n            self.ctx.gpr.rsi = execution::enter_guest_region as u64;\n            self.ctx.gpr.rdi = self.ctx.callback_data_ptr() as u64;\n        }\n    }\n\n    /// The core routine for context switching into a guest, and extracting a result.\n    ///\n    /// This must only be called for an instance in a ready, non-fatally faulted, or yielded state,\n    /// or in the not-started state on the start function. The public wrappers around this function\n    /// should make sure the state is appropriate.\n    fn swap_and_return(&mut self, async_context: bool) -> Result<InternalRunResult, Error> {\n        let is_start_func = self\n            .entrypoint\n            .expect(\"we always have an entrypoint by now\")\n            .is_start_func;\n        debug_assert!(\n            self.state.is_ready()\n                || self.state.is_not_started() && is_start_func\n                || (self.state.is_faulted() && !self.state.is_fatal())\n                || self.state.is_yielded()\n                || self.state.is_bound_expired()\n        );\n        self.state = State::Running { async_context };\n\n        let res = self.with_current_instance(|i| {\n            i.with_signals_on(|i| {\n                HOST_CTX.with(|host_ctx| {\n                    // Save the current context into `host_ctx`, and jump to the guest context. The\n                    // lucet context is linked to host_ctx, so it will return here after it finishes,\n                    // successfully or otherwise.\n                    unsafe { Context::swap(&mut *host_ctx.get(), &mut i.ctx) };\n                    Ok(())\n                })\n            })\n        });\n\n        #[cfg(feature = \"concurrent_testpoints\")]\n        self.lock_testpoints\n            .instance_after_clearing_current_instance\n            .check();\n\n        if let Err(e) = res {\n            // Something went wrong setting up or tearing down the signal handlers and signal\n            // stack. This is an error, but we don't want it to mask an error that may have arisen\n            // due to a guest fault or guest termination. So, we set the state back to `Ready` or\n            // `NotStarted` only if it is still `Running`, which likely indicates we never even made\n            // it into the guest.\n            //\n            // As of 2020-03-20, the only early return points in the code above happen before the\n            // guest would be able to run, so this should always transition from running to\n            // ready or not started if there's an error.\n            if let State::Running { .. } = self.state {\n                if is_start_func {\n                    self.state = State::NotStarted;\n                } else {\n                    self.state = State::Ready;\n                }\n            }\n            return Err(e);\n        }\n\n        // Sandbox has jumped back to the host process, indicating it has either:\n        //\n        // * returned: state should be `Running`; transition to `Ready` and return a RunResult\n        // * yielded: state should be `Yielding`; transition to `Yielded` and return a RunResult\n        // * trapped: state should be `Faulted`; populate details and return an error or call a handler as appropriate\n        // * terminated: state should be `Terminating`; transition to `Terminated` and return the termination details as an Err\n        //\n        // The state should never be `Ready`, `Terminated`, `Yielded`, or `Transitioning` at this point\n\n        // Set transitioning state temporarily so that we can move values out of the current state\n        let st = mem::replace(&mut self.state, State::Transitioning);\n\n        if !st.is_yielding() && !st.is_bound_expired() {\n            // If the instance is *not* yielding, initialize a fresh `KillState` for subsequent\n            // executions, which will invalidate any existing `KillSwitch`'s weak references.\n            #[cfg(feature = \"concurrent_testpoints\")]\n            {\n                self.kill_state = Arc::new(KillState::new(Arc::clone(&self.lock_testpoints)));\n            }\n            #[cfg(not(feature = \"concurrent_testpoints\"))]\n            {\n                self.kill_state = Arc::new(KillState::default());\n            }\n        }\n\n        match st {\n            State::Running { .. } => {\n                let retval = self.ctx.get_untyped_retval();\n                self.state = State::Ready;\n                Ok(RunResult::Returned(retval).into())\n            }\n            State::Terminating { details, .. } => {\n                self.state = State::Terminated;\n                Err(Error::RuntimeTerminated(details).into())\n            }\n            State::Yielding { val, expecting } => {\n                self.state = State::Yielded { expecting };\n                Ok(RunResult::Yielded(val).into())\n            }\n            State::Faulted {\n                mut details,\n                siginfo,\n                context,\n            } => {\n                // Sandbox is no longer runnable. It's unsafe to determine all error details in the signal\n                // handler, so we fill in extra details here.\n                //\n                // FIXME after lucet-module is complete it should be possible to fill this in without\n                // consulting the process symbol table\n                details.rip_addr_details = self\n                    .module\n                    .addr_details(details.rip_addr as *const c_void)?;\n\n                // fill the state back in with the updated details in case fatal handlers need it\n                self.state = State::Faulted {\n                    details: details.clone(),\n                    siginfo,\n                    context,\n                };\n\n                if details.fatal {\n                    // Some errors indicate that the guest is not functioning correctly or that\n                    // the loaded code violated some assumption, so bail out via the fatal\n                    // handler.\n\n                    // Run the C-style fatal handler, if it exists.\n                    if let Some(h) = self.c_fatal_handler {\n                        unsafe { h(self as *mut Instance) }\n                    }\n\n                    // If there is no C-style fatal handler, or if it (erroneously) returns,\n                    // call the Rust handler that we know will not return\n                    (self.fatal_handler)(self)\n                } else {\n                    // leave the full fault details in the instance state, and return the\n                    // higher-level info to the user\n                    Err(Error::RuntimeFault(details).into())\n                }\n            }\n            State::BoundExpired => {\n                self.state = State::BoundExpired;\n                Ok(InternalRunResult::BoundExpired)\n            }\n            State::NotStarted\n            | State::Ready\n            | State::Terminated\n            | State::Yielded { .. }\n            | State::Transitioning => Err(lucet_format_err!(\n                \"\\\"impossible\\\" state found in `swap_and_return()`: {}\",\n                st\n            )),\n        }\n    }\n\n    fn with_current_instance<F, R>(&mut self, f: F) -> Result<R, Error>\n    where\n        F: FnOnce(&mut Instance) -> Result<R, Error>,\n    {\n        CURRENT_INSTANCE.with(|current_instance| {\n            let mut current_instance = current_instance.borrow_mut();\n            lucet_ensure!(\n                current_instance.is_none(),\n                \"no instance must already be running on this thread\"\n            ); // safety: `self` is not null if we are in this function\n            *current_instance = Some(unsafe { NonNull::new_unchecked(self) });\n            Ok(())\n        })?;\n\n        self.kill_state.schedule(unsafe { pthread_self() });\n\n        let res = f(self);\n\n        self.kill_state.deschedule();\n\n        CURRENT_INSTANCE.with(|current_instance| {\n            *current_instance.borrow_mut() = None;\n        });\n\n        res\n    }\n}\n\n/// Information about a runtime fault.\n///\n/// Runtime faults are raised implictly by signal handlers that return `SignalBehavior::Default` in\n/// response to signals arising while a guest is running.\n#[derive(Clone, Debug)]\npub struct FaultDetails {\n    /// If true, the instance's `fatal_handler` will be called.\n    pub fatal: bool,\n    /// Information about the type of fault that occurred.\n    pub trapcode: Option<TrapCode>,\n    /// The instruction pointer where the fault occurred.\n    pub rip_addr: uintptr_t,\n    /// Extra information about the instruction pointer's location, if available.\n    pub rip_addr_details: Option<module::AddrDetails>,\n}\n\nimpl std::fmt::Display for FaultDetails {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        if self.fatal {\n            write!(f, \"fault FATAL \")?;\n        } else {\n            write!(f, \"fault \")?;\n        }\n\n        if let Some(trapcode) = self.trapcode {\n            write!(f, \"{:?} \", trapcode)?;\n        } else {\n            write!(f, \"TrapCode::UNKNOWN \")?;\n        }\n\n        write!(f, \"code at address {:p}\", self.rip_addr as *const c_void)?;\n\n        if let Some(ref addr_details) = self.rip_addr_details {\n            if let Some(ref fname) = addr_details.file_name {\n                let sname = addr_details.sym_name.as_deref().unwrap_or(\"<unknown>\");\n                write!(f, \" (symbol {}:{})\", fname, sname)?;\n            }\n            if addr_details.in_module_code {\n                write!(f, \" (inside module code)\")\n            } else {\n                write!(f, \" (not inside module code)\")\n            }\n        } else {\n            write!(f, \" (unknown whether in module)\")\n        }\n    }\n}\n\n/// Information about a terminated guest.\npub enum TerminationDetails {\n    /// Returned when a signal handler terminates the instance.\n    Signal,\n    /// Returned when `get_embed_ctx` or `get_embed_ctx_mut` are used with a type that is not present.\n    CtxNotFound,\n    /// Returned when the type of the value passed to `Instance::resume_with_val()` does not match\n    /// the type expected by `Vmctx::yield_expecting_val()` or `Vmctx::yield_val_expecting_val`, or\n    /// if `Instance::resume()` was called when a value was expected.\n    ///\n    /// **Note**: If you see this termination value, please report it as a Lucet bug. The types of\n    /// resumed values are dynamically checked by `Instance::resume()` and\n    /// `Instance::resume_with_val()`, so this should never arise.\n    YieldTypeMismatch,\n    /// Returned when dynamic borrowing rules of methods like `Vmctx::heap()` are violated.\n    BorrowError(&'static str),\n    /// Calls to `lucet_hostcall_terminate` provide a payload for use by the embedder.\n    Provided {\n        type_name: &'static str,\n        provided: Box<dyn Any + 'static>,\n    },\n    /// The instance was terminated by its `KillSwitch`.\n    Remote,\n    /// A panic occurred during a hostcall other than the specialized panic used to implement\n    /// Lucet runtime features.\n    ///\n    /// Panics are raised by the Lucet runtime in order to unwind the hostcall before jumping back\n    /// to the host context for any of the reasons described by the variants of this type. The panic\n    /// payload in that case is a already a `TerminationDetails` value.\n    ///\n    /// This variant is created when any type other than `TerminationDetails` is the payload of a\n    /// panic arising during a hostcall, meaning it was not intentionally raised by the Lucet\n    /// runtime.\n    ///\n    /// The panic payload contained in this variant should be rethrown using\n    /// [`resume_unwind`](https://doc.rust-lang.org/std/panic/fn.resume_unwind.html) once returned\n    /// to the host context.\n    ///\n    /// Note that this variant will be removed once cross-FFI unwinding support lands in\n    /// [Rust](https://github.com/rust-lang/rfcs/pull/2945) and\n    /// [Lucet](https://github.com/bytecodealliance/lucet/pull/254).\n    OtherPanic(Box<dyn Any + Send + 'static>),\n    /// The instance was terminated by `Vmctx::block_on` being called from an instance\n    /// that isnt running in an async context\n    BlockOnNeedsAsync,\n}\n\nimpl TerminationDetails {\n    pub fn provide<A: Any + 'static>(details: A) -> Self {\n        TerminationDetails::Provided {\n            type_name: std::any::type_name::<A>(),\n            provided: Box::new(details),\n        }\n    }\n    pub fn provided_details(&self) -> Option<&dyn Any> {\n        match self {\n            TerminationDetails::Provided { provided, .. } => Some(provided.as_ref()),\n            _ => None,\n        }\n    }\n    /// Try to interpret the termination details as a provided exit code.\n    ///\n    /// The most consistent form of `TerminationDetails::Provided` comes from Lucet's\n    /// implementation of `proc_exit`, which exits with a `Provided` holding the given exit code.\n    /// For cases where a Lucet user simply wants \"`proc_exit` or continue panicking\" behavior,\n    /// `as_exitcode` can simplify handling `TerminationDetails`.\n    pub fn as_exitcode(&self) -> Option<u32> {\n        match self {\n            TerminationDetails::Provided { provided, .. } => {\n                // I apologize for this load-bearing `as u32`.\n                // Wasi uses an u32 for the proc_exist status (`lucet_wasi::Exitcode`) in the\n                // witx. However, wasmtime::Trap exit status is an i32, so the\n                // wiggle::Trap::I32Exit variant mirrors Wasmtime. The `as u32` lets this method\n                // return a type equivalent to `lucet_wasi::Exitcode`, but users interested in the\n                // full range of `wiggle::Trap` will have to handle an i32 variant.\n                match provided.downcast_ref::<wiggle::Trap>() {\n                    Some(wiggle::Trap::I32Exit(code)) => Some(*code as u32),\n                    _ => None,\n                }\n            }\n            _ => None,\n        }\n    }\n}\n\n// Because of deref coercions, the code above was tricky to get right-\n// test that a string makes it through\n#[test]\nfn termination_details_any_typing() {\n    let hello = \"hello, world\".to_owned();\n    let details = TerminationDetails::provide(hello.clone());\n    let provided = details.provided_details().expect(\"got Provided\");\n    assert_eq!(\n        provided.downcast_ref::<String>().expect(\"right type\"),\n        &hello\n    );\n}\n\nimpl PartialEq for TerminationDetails {\n    fn eq(&self, rhs: &TerminationDetails) -> bool {\n        use TerminationDetails::*;\n        match (self, rhs) {\n            (Signal, Signal) => true,\n            (BorrowError(msg1), BorrowError(msg2)) => msg1 == msg2,\n            (CtxNotFound, CtxNotFound) => true,\n            (BlockOnNeedsAsync, BlockOnNeedsAsync) => true,\n            // can't compare `Any`\n            _ => false,\n        }\n    }\n}\n\nimpl std::fmt::Debug for TerminationDetails {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        write!(f, \"TerminationDetails::\")?;\n        match self {\n            TerminationDetails::Signal => write!(f, \"Signal\"),\n            TerminationDetails::BorrowError(msg) => write!(f, \"BorrowError({})\", msg),\n            TerminationDetails::CtxNotFound => write!(f, \"CtxNotFound\"),\n            TerminationDetails::YieldTypeMismatch => write!(f, \"YieldTypeMismatch\"),\n            TerminationDetails::Provided { type_name, .. } => write!(f, \"Provided({})\", type_name),\n            TerminationDetails::Remote => write!(f, \"Remote\"),\n            TerminationDetails::OtherPanic(_) => write!(f, \"OtherPanic(Any)\"),\n            TerminationDetails::BlockOnNeedsAsync => write!(f, \"BlockOnNeedsAsync\"),\n        }\n    }\n}\n\nunsafe impl Send for TerminationDetails {}\nunsafe impl Sync for TerminationDetails {}\n\n/// The value yielded by an instance through a [`Vmctx`](vmctx/struct.Vmctx.html) and returned to\n/// the host.\npub struct YieldedVal {\n    val: Box<dyn Any + Send + 'static>,\n}\n\nimpl std::fmt::Debug for YieldedVal {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        if self.is_none() {\n            write!(f, \"YieldedVal {{ val: None }}\")\n        } else {\n            write!(f, \"YieldedVal {{ val: Some }}\")\n        }\n    }\n}\n\nimpl YieldedVal {\n    pub(crate) fn new<A: Any + Send + 'static>(val: A) -> Self {\n        YieldedVal { val: Box::new(val) }\n    }\n\n    /// Returns `true` if the guest yielded the parameterized type.\n    pub fn is<A: Any>(&self) -> bool {\n        self.val.is::<A>()\n    }\n\n    /// Returns `true` if the guest yielded without a value.\n    pub fn is_none(&self) -> bool {\n        self.is::<EmptyYieldVal>()\n    }\n\n    /// Returns `true` if the guest yielded with a value.\n    pub fn is_some(&self) -> bool {\n        !self.is_none()\n    }\n\n    /// Attempt to downcast the yielded value to a concrete type, returning the original\n    /// `YieldedVal` if unsuccessful.\n    pub fn downcast<A: Any + Send + 'static>(self) -> Result<Box<A>, YieldedVal> {\n        match self.val.downcast() {\n            Ok(val) => Ok(val),\n            Err(val) => Err(YieldedVal { val }),\n        }\n    }\n\n    /// Returns a reference to the yielded value if it is present and of type `A`, or `None` if it\n    /// isn't.\n    pub fn downcast_ref<A: Any + Send + 'static>(&self) -> Option<&A> {\n        self.val.downcast_ref()\n    }\n}\n\n/// A marker value to indicate a yield or resume with no value.\n///\n/// This exists to unify the implementations of the various operators, and should only ever be\n/// created by internal code.\n#[derive(Debug)]\npub(crate) struct EmptyYieldVal;\n\nfn default_fatal_handler(inst: &Instance) -> ! {\n    panic!(\"> instance {:p} had fatal error: {}\", inst, inst.state);\n}\n"
  },
  {
    "project": "ruspiro-singleton",
    "target": 1,
    "commit_id": "0565f8ef459bd336eda8a6a63d1d50cdb581c2b3",
    "func": "/***********************************************************************************************************************\n * Copyright (c) 2019 by the authors\n *\n * Author: Andr\u00e9 Borrmann\n * License: MIT / Apache License 2.0\n **********************************************************************************************************************/\n#![doc(html_root_url = \"https://docs.rs/ruspiro-singleton/||VERSION||\")]\n#![no_std]\n#![feature(const_fn)]\n\n//! # Singleton pattern implementation\n//!\n//! Provide a cross core synchronisation safe singleton implementation pattern. The `Singleton` is intended to be used\n//! to declare crate level static variables that require safe access accross cores. This is helpful where the data\n//! structure used within the `Singleton` represents a peripheral where the crate shall only hand out a single instance\n//! to safely represent to unique existance of the peripheral.\n//!\n//! # HINT\n//! Safe lazy initialization is ensured using atomics. On the Raspberry Pi atmomic operations require the *MMU* to be \n//! configured and active. Otherwise the executing CPU core will hang when trying to execute the atomic operation.\n//!\n//! # Example\n//! ```no_run\n//! # use ruspiro_singleton::*;\n//! // define the static variable with an inizialization closure\n//! static FOO:Singleton<u32> = Singleton::new(20);\n//!\n//! // define the static variable with an inizialization closure\n//! static DEMO:Singleton<Box<Demo>> = Singleton::lazy(&|| {\n//!     Box::new(\n//!         Demo::new()\n//!     )\n//! });\n//!\n//! // define the type to be accessible as singleton\n//! struct Demo {\n//!     pub count: u32,\n//! }\n//!\n//! // implement the type that should provided as singlton\n//! impl Demo {\n//!     pub const fn new() -> Self {\n//!         Demo {\n//!             count: 0,\n//!         }\n//!     }\n//! }\n//!\n//! fn main() {\n//!     // safely use the singleton inside the closure passed to [with_mut] to update it's contents\n//!     DEMO.with_mut(|d| {\n//!         d.count += 10;\n//!     });\n//!\n//!     // safely use the singleton inside the closure passed to [with_ref] if read-only access is required\n//!     DEMO.with_mut(|d| {\n//!         println!(\"Value: {}\", d.count);\n//!     });\n//!\n//!     // you may also return a value from the singleton to work with it after the safe singleton access\n//!     let val = DEMO.with_ref(|d| {\n//!         if d.count != 0 {\n//!             true\n//!         } else {\n//!             false\n//!         }\n//!     });\n//! }\n//! ```\n\nmod lazy;\n\nuse lazy::LazyValue;\nuse ruspiro_lock::RWLock;\n\n/// The Singleton wrapper stores any type\npub struct Singleton<T: 'static> {\n    /// the inner value wrapping the contained data for safe read/write access\n    inner: RWLock<LazyValue<T>>,\n}\n\n// The Singleton need to implement Send & Sync to ensure cross core compile check mechanics\n// this is safe as the inner RWLock ensures cross core safety\nunsafe impl<T> Sync for Singleton<T> {}\nunsafe impl<T> Send for Singleton<T> {}\n\nimpl<T: 'static> Singleton<T> {\n    /// Create a new [Singleton] instance to be used in a static variable. Only ``const fn`` constructors are allowed\n    /// here.\n    /// # Example\n    /// ```no_run\n    /// # use ruspiro_singleton::*;\n    /// static FOO: Singleton<u32> = Singleton::new(20);\n    /// # fn main() {}\n    /// ```\n    pub const fn new(value: T) -> Self {\n        Singleton {\n            inner: RWLock::new(LazyValue::with_value(value)),\n        }\n    }\n\n    /// Create a new [Singleton] instance passing a closure that will be evaluated at first access to the contents of\n    /// the singleton that will provide its value\n    /// # Example\n    /// ```no_run\n    /// # use ruspiro_singleton::*;\n    /// static FOO: Singleton<String> = Singleton::lazy(&|| String::from(\"foo\"));\n    /// # fn main() {}\n    /// ```\n    pub const fn lazy<F>(init: &'static F) -> Self\n    where\n        F: Fn() -> T,\n    {\n        Self {\n            inner: RWLock::new(LazyValue::with_init(init)),\n        }\n    }\n\n    /// Take the stored singleton for whatever operation and prevent usage by other cores\n    /// Safe access to the singleton mutable instance is guarantied inside the given closure.\n    ///\n    pub fn with_mut<F, R>(&self, f: F) -> R\n    where\n        F: FnOnce(&mut T) -> R,\n    {\n        let inner = self.inner.lock();\n        // use write lock to mutably access the inner value of the singleton. As long\n        // as the write lock exists no other write or read lock is possible\n        let r = f(inner.get_mut());\n\n        // explicitly release the lock befor providing the result of the closure to the caller\n        drop(inner);\n\n        r\n    }\n\n    /// Immutable access to a singleton for a specific operation.\n    /// This access does not enforce any lock nor guarantees safe atomic access to the instance. However, it is usefull\n    /// in read-only access scenarios like inside interrupt handlers.\n    ///\n    pub fn with_ref<F, R>(&self, f: F) -> R\n    where\n        F: FnOnce(&T) -> R,\n    {\n        let inner = self.inner.read();\n        // multiple read locks are possible when accessing the inner data of the singleton\n        // all read locks are required to be release before the next write lock could happen\n        let r = f(inner.get());\n\n        // explicitly release the lock befor providing the result of the closure to the caller\n        drop(inner);\n\n        r\n    }\n}\n"
  },
  {
    "project": "nanorand-rs",
    "target": 1,
    "commit_id": "7bf49ecbb254991585c04dd4f4d2a23cb16a1240",
    "func": "use crate::RNG;\n\n/// A trait used for generating a random object with an RNG,\npub trait RandomGen<R: RNG> {\n\t/// Return a random instance of the implementing type, from the specified RNG instance.\n\tfn random(r: &mut R) -> Self;\n}\n\n/// A trait used for generating a random number within a range, with an RNG,\npub trait RandomRange<R: RNG>: RandomGen<R> {\n\t/// Return a ranged number of the implementing type, from the specified RNG instance.\n\tfn random_range(r: &mut R, lower: Self, upper: Self) -> Self;\n}\n\nimpl<R: RNG> RandomGen<R> for char {\n\tfn random(r: &mut R) -> Self {\n\t\tloop {\n\t\t\tlet generated = r.rand();\n\t\t\tlet mut bytes = [0u8; core::mem::size_of::<u32>()];\n\t\t\tbytes\n\t\t\t\t.iter_mut()\n\t\t\t\t.zip(generated.as_ref())\n\t\t\t\t.for_each(|(a, b)| *a = *b);\n\t\t\tif let Some(c) = core::char::from_u32(u32::from_ne_bytes(bytes)) {\n\t\t\t\tbreak c;\n\t\t\t}\n\t\t}\n\t}\n}\n\nimpl<R: RNG> RandomGen<R> for bool {\n\tfn random(r: &mut R) -> bool {\n\t\tr.rand().as_ref()[0] < 0b10000000\n\t}\n}\n\nimpl<R: RNG> RandomGen<R> for u64 {\n\tfn random(r: &mut R) -> Self {\n\t\tlet generated = r.rand();\n\t\tlet mut bytes = [0u8; core::mem::size_of::<u64>()];\n\t\tbytes\n\t\t\t.iter_mut()\n\t\t\t.zip(generated.as_ref())\n\t\t\t.for_each(|(a, b)| *a = *b);\n\t\tSelf::from_le_bytes(bytes)\n\t}\n}\n\nimpl<R: RNG> RandomRange<R> for u64 {\n\tfn random_range(r: &mut R, lower: u64, upper: u64) -> Self {\n\t\tlet t = ((-(upper as i64)) % (upper as i64)) as u64;\n\t\tlet in_range = loop {\n\t\t\tlet x = Self::random(r);\n\t\t\tlet m = (x as u128).wrapping_mul(upper as u128);\n\t\t\tif (m as u64) >= t {\n\t\t\t\tbreak (m >> 64) as u64;\n\t\t\t}\n\t\t};\n\t\tin_range.max(lower)\n\t}\n}\n\n#[cfg(target_pointer_width = \"64\")]\nimpl<R: RNG> RandomGen<R> for usize {\n\tfn random(r: &mut R) -> Self {\n\t\tr.generate::<u64>() as usize\n\t}\n}\n#[cfg(target_pointer_width = \"64\")]\nimpl<R: RNG> RandomRange<R> for usize {\n\tfn random_range(r: &mut R, lower: usize, upper: usize) -> Self {\n\t\tr.generate_range::<u64>(lower as u64, upper as u64) as usize\n\t}\n}\n\n#[cfg(target_pointer_width = \"32\")]\nimpl<R: RNG> RandomGen<R> for usize {\n\tfn random(r: &mut R) -> Self {\n\t\tr.generate::<u32>() as usize\n\t}\n}\n#[cfg(target_pointer_width = \"32\")]\nimpl<R: RNG> RandomRange<R> for usize {\n\tfn random_range(r: &mut R, lower: usize, upper: usize) -> Self {\n\t\tr.generate_range::<u32>(lower as u32, upper as u32) as usize\n\t}\n}\n\n#[cfg(target_pointer_width = \"16\")]\nimpl<R: RNG> RandomGen<R> for usize {\n\tfn random(r: &mut R) -> Self {\n\t\tr.generate::<u16>() as usize\n\t}\n}\n#[cfg(target_pointer_width = \"16\")]\nimpl<R: RNG> RandomRange<R> for usize {\n\tfn random_range(r: &mut R, lower: usize, upper: usize) -> Self {\n\t\tr.generate_range::<u16>(lower as u16, upper as u16) as usize\n\t}\n}\n\nimpl<R: RNG> RandomGen<R> for u32 {\n\tfn random(r: &mut R) -> Self {\n\t\t(r.generate::<u64>() >> 32) as u32\n\t}\n}\n\nimpl<R: RNG> RandomRange<R> for u32 {\n\tfn random_range(r: &mut R, lower: u32, upper: u32) -> Self {\n\t\t(r.generate_range::<u64>(lower as u64, upper as u64) >> 32) as u32\n\t}\n}\n\nimpl<R: RNG> RandomGen<R> for u16 {\n\tfn random(r: &mut R) -> Self {\n\t\t(r.generate::<u64>() >> 16) as u16\n\t}\n}\n\nimpl<R: RNG> RandomRange<R> for u16 {\n\tfn random_range(r: &mut R, lower: u16, upper: u16) -> Self {\n\t\t(r.generate_range::<u64>(lower as u64, upper as u64) >> 16) as u16\n\t}\n}\n\nimpl<R: RNG> RandomGen<R> for u8 {\n\tfn random(r: &mut R) -> Self {\n\t\t(r.generate::<u64>() >> 8) as u8\n\t}\n}\n\nimpl<R: RNG> RandomRange<R> for u8 {\n\tfn random_range(r: &mut R, lower: u8, upper: u8) -> Self {\n\t\t(r.generate_range::<u64>(lower as u64, upper as u64) >> 8) as u8\n\t}\n}\n\nimpl<R: RNG> RandomRange<R> for char {\n\tfn random_range(r: &mut R, lower: char, upper: char) -> Self {\n\t\tloop {\n\t\t\tlet ret = (r.generate_range::<u64>(lower as u64, upper as u64) >> 32) as u32;\n\t\t\tif let Some(c) = core::char::from_u32(ret) {\n\t\t\t\tbreak c;\n\t\t\t}\n\t\t}\n\t}\n}\n"
  },
  {
    "project": "claxon",
    "target": 1,
    "commit_id": "cd82be35f413940ba446d2a19f10d74b86466487",
    "func": "// Claxon -- A FLAC decoding library in Rust\n// Copyright 2014 Ruud van Asseldonk\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// A copy of the License has been included in the root of the repository.\n\n//! The `subframe` module deals with subframes that make up a frame of the FLAC stream.\n\nuse std::cmp;\nuse std::num;\nuse error::{Error, Result, fmt_err};\nuse input::{Bitstream, ReadBytes};\n\n#[derive(Clone, Copy, Debug)]\nenum SubframeType {\n    Constant,\n    Verbatim,\n    Fixed(u8),\n    Lpc(u8),\n}\n\n#[derive(Clone, Copy)]\nstruct SubframeHeader {\n    sf_type: SubframeType,\n    wasted_bits_per_sample: u32,\n}\n\nfn read_subframe_header<R: ReadBytes>(input: &mut Bitstream<R>) -> Result<SubframeHeader> {\n    // The first bit must be a 0 padding bit.\n    if try!(input.read_bit()) {\n        return fmt_err(\"invalid subframe header\");\n    }\n\n    // Next is a 6-bit subframe type.\n    let sf_type = match try!(input.read_leq_u8(6)) {\n        0 => SubframeType::Constant,\n        1 => SubframeType::Verbatim,\n\n        // Bit patterns 00001x, 0001xx and 01xxxx are reserved, this library\n        // would not know how to handle them, so this is an error. Values that\n        // are reserved at the time of writing are a format error, the\n        // `Unsupported` error type is for specified features that are not\n        // implemented.\n        n if (n & 0b111_110 == 0b000_010) || (n & 0b111_100 == 0b000_100) ||\n             (n & 0b110_000 == 0b010_000) => {\n            return fmt_err(\"invalid subframe header, encountered reserved value\");\n        }\n\n        n if n & 0b111_000 == 0b001_000 => {\n            let order = n & 0b000_111;\n\n            // A fixed frame has order up to 4, other bit patterns are reserved.\n            if order > 4 {\n                return fmt_err(\"invalid subframe header, encountered reserved value\");\n            }\n\n            SubframeType::Fixed(order)\n        }\n\n        // The only possibility left is bit pattern 1xxxxx, an LPC subframe.\n        n => {\n            // The xxxxx bits are the order minus one.\n            let order_mo = n & 0b011_111;\n            SubframeType::Lpc(order_mo + 1)\n        }\n    };\n\n    // Next bits indicates whether there are wasted bits per sample.\n    let wastes_bits = try!(input.read_bit());\n\n    // If so, k - 1 zero bits follow, where k is the number of wasted bits.\n    let wasted_bits = if !wastes_bits {\n        0\n    } else {\n        1 + try!(input.read_unary())\n    };\n\n    // The spec puts no bounds on the number of wasted bits per sample, but more\n    // than 31 does not make sense, as it would remove all data even for 32-bit\n    // samples.\n    if wasted_bits > 31 {\n        return fmt_err(\"wasted bits per sample must not exceed 31\");\n    }\n\n    let subframe_header = SubframeHeader {\n        sf_type: sf_type,\n        wasted_bits_per_sample: wasted_bits,\n    };\n    Ok(subframe_header)\n}\n\n/// Given a signed two's complement integer in the `bits` least significant\n/// bits of `val`, extends the sign bit to a valid 16-bit signed integer.\n#[inline(always)]\nfn extend_sign_u16(val: u16, bits: u32) -> i16 {\n    // First shift the value so the desired sign bit is the actual sign bit,\n    // then convert to a signed integer, and then do an arithmetic shift back,\n    // which will extend the sign bit.\n    return ((val << (16 - bits)) as i16) >> (16 - bits);\n}\n\n#[test]\nfn verify_extend_sign_u16() {\n    assert_eq!(5, extend_sign_u16(5, 4));\n    assert_eq!(0x3ffe, extend_sign_u16(0x3ffe, 15));\n    assert_eq!(-5, extend_sign_u16(16 - 5, 4));\n    assert_eq!(-3, extend_sign_u16(512 - 3, 9));\n    assert_eq!(-1, extend_sign_u16(0xffff, 16));\n    assert_eq!(-2, extend_sign_u16(0xfffe, 16));\n    assert_eq!(-1, extend_sign_u16(0x7fff, 15));\n}\n\n/// Given a signed two's complement integer in the `bits` least significant\n/// bits of `val`, extends the sign bit to a valid 32-bit signed integer.\n#[inline(always)]\npub fn extend_sign_u32(val: u32, bits: u32) -> i32 {\n    // First shift the value so the desired sign bit is the actual sign bit,\n    // then convert to a signed integer, and then do an arithmetic shift back,\n    // which will extend the sign bit.\n    ((val << (32 - bits)) as i32) >> (32 - bits)\n}\n\n#[test]\nfn verify_extend_sign_u32() {\n    assert_eq!(5, extend_sign_u32(5, 4));\n    assert_eq!(0x3ffffffe, extend_sign_u32(0x3ffffffe, 31));\n    assert_eq!(-5, extend_sign_u32(16 - 5, 4));\n    assert_eq!(-3, extend_sign_u32(512 - 3, 9));\n    assert_eq!(-2, extend_sign_u32(0xfffe, 16));\n    assert_eq!(-1, extend_sign_u32(0xffffffff_u32, 32));\n    assert_eq!(-2, extend_sign_u32(0xfffffffe_u32, 32));\n    assert_eq!(-1, extend_sign_u32(0x7fffffff, 31));\n\n    // The data below are samples from a real FLAC stream.\n    assert_eq!(-6392, extend_sign_u32(124680, 17));\n    assert_eq!(-6605, extend_sign_u32(124467, 17));\n    assert_eq!(-6850, extend_sign_u32(124222, 17));\n    assert_eq!(-7061, extend_sign_u32(124011, 17));\n}\n\n/// Decodes a signed number from Rice coding to the two's complement.\n///\n/// The Rice coding used by FLAC operates on unsigned integers, but the\n/// residual is signed. The mapping is done as follows:\n///\n///  0 -> 0\n/// -1 -> 1\n///  1 -> 2\n/// -2 -> 3\n///  2 -> 4\n///  etc.\n///\n/// This function takes the unsigned value and converts it into a signed\n/// number.\n#[inline(always)]\nfn rice_to_signed(val: u32) -> i32 {\n    // The following bit-level hackery compiles to only four instructions on\n    // x64. It is equivalent to the following code:\n    //\n    //   if val & 1 == 1 {\n    //       -1 - (val / 2) as i32\n    //   } else {\n    //       (val / 2) as i32\n    //   }\n    //\n    let half = (val >> 1) as i32;\n    let extended_bit_0 = ((val << 31) as i32) >> 31;\n    half ^ extended_bit_0\n}\n\n#[test]\nfn verify_rice_to_signed() {\n    assert_eq!(rice_to_signed(0), 0);\n    assert_eq!(rice_to_signed(1), -1);\n    assert_eq!(rice_to_signed(2), 1);\n    assert_eq!(rice_to_signed(3), -2);\n    assert_eq!(rice_to_signed(4), 2);\n}\n\n/// Decodes a subframe into the provided block-size buffer.\n///\n/// It is assumed that the length of the buffer is the block size.\npub fn decode<R: ReadBytes>(input: &mut Bitstream<R>,\n                            bps: u32,\n                            buffer: &mut [i32])\n                            -> Result<()> {\n    // The sample type i32 should be wide enough to accomodate for all bits of\n    // the stream, but this can be verified at a higher level than here. Still,\n    // it is a good idea to make the assumption explicit. FLAC supports up to\n    // sample widths of 32 in theory, so with the delta between channels that\n    // requires 33 bits, but the reference decoder supports only subset FLAC of\n    // 24 bits per sample at most, so restricting ourselves to i32 is fine.\n    debug_assert!(32 >= bps);\n\n    let header = try!(read_subframe_header(input));\n\n    if header.wasted_bits_per_sample >= bps {\n        return fmt_err(\"subframe has no non-wasted bits\");\n    }\n\n    // If there are wasted bits, the subframe stores samples with a lower bps\n    // than the stream bps. We later shift all the samples left to correct this.\n    let sf_bps = bps - header.wasted_bits_per_sample;\n\n    match header.sf_type {\n        SubframeType::Constant => try!(decode_constant(input, sf_bps, buffer)),\n        SubframeType::Verbatim => try!(decode_verbatim(input, sf_bps, buffer)),\n        SubframeType::Fixed(ord) => try!(decode_fixed(input, sf_bps, ord as u32, buffer)),\n        SubframeType::Lpc(ord) => try!(decode_lpc(input, sf_bps, ord as u32, buffer)),\n    }\n\n    // Finally, everything must be shifted by 'wasted bits per sample' to\n    // the left. Note: it might be better performance-wise to do this on\n    // the fly while decoding. That could be done if this is a bottleneck.\n    if header.wasted_bits_per_sample > 0 {\n        debug_assert!(header.wasted_bits_per_sample <= 31,\n                      \"Cannot shift by more than the sample width.\");\n        for s in buffer {\n            // For a valid FLAC file, this shift does not overflow. For an\n            // invalid file it might, and then we decode garbage, but we don't\n            // crash the program in debug mode due to shift overflow.\n            *s = s.wrapping_shl(header.wasted_bits_per_sample);\n        }\n    }\n\n    Ok(())\n}\n\n#[derive(Copy, Clone)]\nenum RicePartitionType {\n    Rice,\n    Rice2,\n}\n\nfn decode_residual<R: ReadBytes>(input: &mut Bitstream<R>,\n                                 block_size: u16,\n                                 buffer: &mut [i32])\n                                 -> Result<()> {\n    // Residual starts with two bits of coding method.\n    let partition_type = match try!(input.read_leq_u8(2)) {\n        0b00 => RicePartitionType::Rice,\n        0b01 => RicePartitionType::Rice2,\n        // 10 and 11 are reserved.\n        _ => return fmt_err(\"invalid residual, encountered reserved value\"),\n    };\n\n    // Next are 4 bits partition order.\n    let order = try!(input.read_leq_u8(4));\n\n    // There are 2^order partitions. Note: the specification states a 4-bit\n    // partition order, so the order is at most 31, so there could be 2^31\n    // partitions, but the block size is a 16-bit number, so there are at\n    // most 2^16 - 1 samples in the block. No values have been marked as\n    // invalid by the specification though.\n    let n_partitions = 1u32 << order;\n    let n_samples = block_size >> order;\n    let n_warm_up = block_size - buffer.len() as u16;\n\n    // The partition size must be at least as big as the number of warm-up\n    // samples, otherwise the size of the first partition is negative.\n    if n_warm_up > n_samples {\n        return fmt_err(\"invalid residual\");\n    }\n\n    // Finally decode the partitions themselves.\n    match partition_type {\n        RicePartitionType::Rice => {\n            let mut start = 0;\n            let mut len = n_samples - n_warm_up;\n            for _ in 0..n_partitions {\n                let slice = &mut buffer[start..start + len as usize];\n                try!(decode_rice_partition(input, slice));\n                start = start + len as usize;\n                len = n_samples;\n            }\n        }\n        RicePartitionType::Rice2 => {\n            let mut start = 0;\n            let mut len = n_samples - n_warm_up;\n            for _ in 0..n_partitions {\n                let slice = &mut buffer[start..start + len as usize];\n                try!(decode_rice2_partition(input, slice));\n                start = start + len as usize;\n                len = n_samples;\n            }\n        }\n    }\n\n    Ok(())\n}\n\n// Performance note: all Rice partitions in real-world FLAC files are Rice\n// partitions, not Rice2 partitions. Therefore it makes sense to inline this\n// function into decode_residual.\n#[inline(always)]\nfn decode_rice_partition<R: ReadBytes>(input: &mut Bitstream<R>,\n                                       buffer: &mut [i32])\n                                       -> Result<()> {\n    // A Rice partition (not Rice2), starts with a 4-bit Rice parameter.\n    let rice_param = try!(input.read_leq_u8(4)) as u32;\n\n    // All ones is an escape code that indicates unencoded binary.\n    if rice_param == 0b1111 {\n        return Err(Error::Unsupported(\"unencoded binary is not yet implemented\"))\n    }\n\n    // About the decoding below: the first part of the sample is the quotient,\n    // unary encoded. This means that there are q zeros, and then a one.\n    //\n    // The reference decoder supports sample widths up to 24 bits, so with\n    // the additional bytes for difference in channels and for prediction, a\n    // sample fits in 26 bits. The Rice parameter could be as little as 1,\n    // so the quotient can potentially be very large. However, in practice\n    // it is rarely greater than 5. Values as large as 75 still occur though.\n    //\n    // Next up is the remainder in rice_param bits. Depending on the number of\n    // bits, at most two or three bytes need to be read, so the code below is\n    // split into two cases to allow a more efficient reading function to be\n    // used when possible. About 45% of the time, rice_param is less than 9\n    // (measured from real-world FLAC files).\n\n    if rice_param <= 8 {\n        for sample in buffer.iter_mut() {\n            let q = try!(input.read_unary());\n            let r = try!(input.read_leq_u8(rice_param)) as u32;\n            *sample = rice_to_signed((q << rice_param) | r);\n        }\n    } else {\n        for sample in buffer.iter_mut() {\n            let q = try!(input.read_unary());\n            let r = try!(input.read_gt_u8_leq_u16(rice_param));\n            *sample = rice_to_signed((q << rice_param) | r);\n        }\n    }\n\n    Ok(())\n}\n\n// Performance note: a Rice2 partition is extremely uncommon, I haven\u2019t seen a\n// single one in any real-world FLAC file. So do not inline it, in order not to\n// pollute the caller with dead code.\n#[inline(never)]\n#[cold]\nfn decode_rice2_partition<R: ReadBytes>(input: &mut Bitstream<R>,\n                                        buffer: &mut [i32])\n                                        -> Result<()> {\n    // A Rice2 partition, starts with a 5-bit Rice parameter.\n    let rice_param = try!(input.read_leq_u8(5)) as u32;\n\n    // All ones is an escape code that indicates unencoded binary.\n    if rice_param == 0b11111 {\n        return Err(Error::Unsupported(\"unencoded binary is not yet implemented\"))\n    }\n\n    for sample in buffer.iter_mut() {\n        // First part of the sample is the quotient, unary encoded.\n        let q = try!(input.read_unary());\n\n        // Next is the remainder, in rice_param bits. Because at this\n        // point rice_param is at most 30, we can safely read into a u32.\n        let r = try!(input.read_leq_u32(rice_param));\n        *sample = rice_to_signed((q << rice_param) | r);\n    }\n\n    Ok(())\n}\n\nfn decode_constant<R: ReadBytes>(input: &mut Bitstream<R>,\n                                 bps: u32,\n                                 buffer: &mut [i32])\n                                 -> Result<()> {\n    let sample_u32 = try!(input.read_leq_u32(bps));\n    let sample = extend_sign_u32(sample_u32, bps);\n\n    for s in buffer {\n        *s = sample;\n    }\n\n    Ok(())\n}\n\n#[cold]\nfn decode_verbatim<R: ReadBytes>(input: &mut Bitstream<R>,\n                                 bps: u32,\n                                 buffer: &mut [i32])\n                                 -> Result<()> {\n\n    // This function must not be called for a sample wider than the sample type.\n    // This has been verified at an earlier stage, but it is good to state the\n    // assumption explicitly. FLAC supports up to 32-bit samples, so the\n    // mid/side delta would require 33 bits per sample. But that is not subset\n    // FLAC, and the reference decoder does not support it either.\n    debug_assert!(bps <= 32);\n\n    // A verbatim block stores samples without encoding whatsoever.\n    for s in buffer {\n        *s = extend_sign_u32(try!(input.read_leq_u32(bps)), bps);\n    }\n\n    Ok(())\n}\n\nfn predict_fixed(order: u32, buffer: &mut [i32]) -> Result<()> {\n    // When this is called during decoding, the order as read from the subframe\n    // header has already been verified, so it is safe to assume that\n    // 0 <= order <= 4. Still, it is good to state that assumption explicitly.\n    debug_assert!(order <= 4);\n\n    // Coefficients for fitting an order n polynomial. You get these\n    // coefficients by writing down n numbers, then their differences, then the\n    // differences of the differences, etc. What results is Pascal's triangle\n    // with alternating signs.\n    let o0 = [];\n    let o1 = [1];\n    let o2 = [-1, 2];\n    let o3 = [1, -3, 3];\n    let o4 = [-1, 4, -6, 4];\n\n    // Multiplying samples with at most 6 adds 3 bits. Then summing at most 5\n    // of those values again adds at most 4 bits, so a sample type that is 7\n    // bits wider than bps should suffice. Subset FLAC supports at most 24 bits\n    // per sample, 25 for the channel delta, so using an i32 is safe here.\n\n    let coefficients: &[i32] = match order {\n        0 => &o0,\n        1 => &o1,\n        2 => &o2,\n        3 => &o3,\n        4 => &o4,\n        _ => unreachable!(),\n    };\n\n    let window_size = order as usize + 1;\n\n    // TODO: abstract away this iterating over a window into a function?\n    for i in 0..buffer.len() - order as usize {\n        // Manually do the windowing, because .windows() returns immutable slices.\n        let window = &mut buffer[i..i + window_size];\n\n        // The #coefficients elements of the window store already decoded\n        // samples, the last element of the window is the delta. Therefore,\n        // predict based on the first #coefficients samples. From the note\n        // above we know that the multiplication will not overflow for 24-bit\n        // samples, so the wrapping mul is safe. If it wraps, the file was\n        // invalid, and we make no guarantees about the decoded result. But\n        // we explicitly do not crash.\n        let prediction = coefficients.iter()\n                                     .zip(window.iter())\n                                     .map(|(&c, &s)| num::Wrapping(c) * num::Wrapping(s))\n                                     // Rust 1.13 does not support using `sum`\n                                     // with `Wrapping`, so do a fold.\n                                     .fold(num::Wrapping(0), |a, x| a + x).0;\n\n        // The delta is stored, so the sample is the prediction + delta.\n        let delta = window[coefficients.len()];\n        window[coefficients.len()] = prediction.wrapping_add(delta);\n    }\n\n    Ok(())\n}\n\n#[test]\nfn verify_predict_fixed() {\n    // The following data is from an actual FLAC stream and has been verified\n    // against the reference decoder. The data is from a 16-bit stream.\n    let mut buffer = [-729, -722, -667, -19, -16,  17, -23, -7,\n                        16,  -16,   -5,   3,  -8, -13, -15, -1];\n    assert!(predict_fixed(3, &mut buffer).is_ok());\n    assert_eq!(&buffer, &[-729, -722, -667, -583, -486, -359, -225, -91,\n                            59,  209,  354,  497,  630,  740,  812, 845]);\n\n    // The following data causes overflow of i32 when not handled with care.\n    let mut buffer = [21877, 27482, -6513];\n    assert!(predict_fixed(2, &mut buffer).is_ok());\n    assert_eq!(&buffer, &[21877, 27482, 26574]);\n}\n\nfn decode_fixed<R: ReadBytes>(input: &mut Bitstream<R>,\n                              bps: u32,\n                              order: u32,\n                              buffer: &mut [i32])\n                              -> Result<()> {\n    // The length of the buffer which is passed in, is the length of the block.\n    // Thus, the number of warm-up samples must not exceed that length.\n    if buffer.len() < order as usize {\n        return fmt_err(\"invalid fixed subframe, order is larger than block size\")\n    }\n\n    // There are order * bits per sample unencoded warm-up sample bits.\n    try!(decode_verbatim(input, bps, &mut buffer[..order as usize]));\n\n    // Next up is the residual. We decode into the buffer directly, the\n    // predictor contributions will be added in a second pass. The first\n    // `order` samples have been decoded already, so continue after that.\n    try!(decode_residual(input,\n                         buffer.len() as u16,\n                         &mut buffer[order as usize..]));\n\n    try!(predict_fixed(order, buffer));\n\n    Ok(())\n}\n\nfn predict_lpc(raw_coefficients: &[i16],\n               qlp_shift: i16,\n               buffer: &mut [i32])\n               -> Result<()> {\n    debug_assert!(qlp_shift >= 0, \"Right-shift by negative value is not allowed.\");\n    debug_assert!(qlp_shift < 64, \"Cannot shift by more than integer width.\");\n    // The decoded residuals are 25 bits at most (assuming subset FLAC of at\n    // most 24 bits per sample, but there is the delta encoding for channels).\n    // The coefficients are 16 bits at most, so their product is 41 bits. In\n    // practice the predictor order does not exceed 12, so adding 12 numbers of\n    // 41 bits each requires at most 53 bits. Therefore, do all intermediate\n    // computations as i64.\n\n    // The spec allocates 5 bits for (order - 1), so the order could be as much\n    // as 32. However, I have never observed an order larger than 12, in\n    // practice, and this function is optimized under that assumption. If there\n    // ever is a need for higher orders, it a fallback predictor could be added\n    // easily.\n    if raw_coefficients.len() > 12 {\n        return Err(Error::Unsupported(\"LPC order > 12 is not supported\"));\n    }\n\n    // In the code below, a predictor order of 12 is assumed. This aids\n    // optimization and vectorization by making some counts available at compile\n    // time. If the actual order is less than 12, simply set the early\n    // coefficients to 0.\n    let order = raw_coefficients.len();\n    let coefficients = {\n        let mut buf = [0i64; 12];\n        let mut i = 12 - order;\n        for c in raw_coefficients {\n            buf[i] = *c as i64;\n            i = i + 1;\n        }\n        buf\n    };\n\n    // The linear prediction is essentially an inner product of the known\n    // samples with the coefficients, followed by a shift. To be able to do an\n    // inner product of 12 elements at a time, we must first have 12 samples.\n    // If the predictor order is less, first predict the few samples after the\n    // warm-up samples.\n    let left = cmp::min(12, buffer.len()) - order;\n    for i in 0..left {\n        let prediction = raw_coefficients.iter()\n                                         .zip(&buffer[i..order + i])\n                                         .map(|(&c, &s)| c as i64 * s as i64)\n                                         .sum::<i64>() >> qlp_shift;\n        let delta = buffer[order + i] as i64;\n        buffer[order + i] = (prediction + delta) as i32;\n    }\n\n    if buffer.len() <= 12 { return Ok(()) }\n\n    // At this point, buffer[0..12] has been predicted. For the rest of the\n    // buffer we can do inner products of 12 samples. This reduces the amount of\n    // conditional code, and improves performance significantly.\n    for i in 12..buffer.len() {\n        let prediction = coefficients.iter()\n                                     .zip(&buffer[i - 12..i])\n                                     .map(|(&c, &s)| c * s as i64)\n                                     .sum::<i64>() >> qlp_shift;\n        let delta = buffer[i] as i64;\n        buffer[i] = (prediction + delta) as i32;\n    }\n\n    Ok(())\n}\n\n#[test]\nfn verify_predict_lpc() {\n    // The following data is from an actual FLAC stream and has been verified\n    // against the reference decoder. The data is from a 16-bit stream.\n    let coefficients = [-75, 166,  121, -269, -75, -399, 1042];\n    let mut buffer = [-796, -547, -285,  -32, 199,  443,  670, -2,\n                       -23,   14,    6,    3,  -4,   12,   -2, 10];\n    assert!(predict_lpc(&coefficients, 9, &mut buffer).is_ok());\n    assert_eq!(&buffer, &[-796, -547, -285,  -32,  199,  443,  670,  875,\n                          1046, 1208, 1343, 1454, 1541, 1616, 1663, 1701]);\n\n    // The following data causes an overflow when not handled with care.\n    let coefficients = [119, -255, 555, -836, 879, -1199, 1757];\n    let mut buffer = [-21363, -21951, -22649, -24364, -27297, -26870, -30017, 3157];\n    assert!(predict_lpc(&coefficients, 10, &mut buffer).is_ok());\n    assert_eq!(&buffer, &[-21363, -21951, -22649, -24364, -27297, -26870, -30017, -29718]);\n}\n\nfn decode_lpc<R: ReadBytes>(input: &mut Bitstream<R>,\n                            bps: u32,\n                            order: u32,\n                            buffer: &mut [i32])\n                            -> Result<()> {\n    // The order minus one fits in 5 bits, so the order is at most 32.\n    debug_assert!(order <= 32);\n\n    // On the frame decoding level it is ensured that the buffer is large\n    // enough. If it can't even fit the warm-up samples, then there is a frame\n    // smaller than its lpc order, which is invalid.\n    if buffer.len() < order as usize {\n        return fmt_err(\"invalid LPC subframe, lpc order is larger than block size\")\n    }\n\n    // There are order * bits per sample unencoded warm-up sample bits.\n    try!(decode_verbatim(input, bps, &mut buffer[..order as usize]));\n\n    // Next are four bits quantised linear predictor coefficient precision - 1.\n    let qlp_precision = try!(input.read_leq_u8(4)) as u32 + 1;\n\n    // The bit pattern 1111 is invalid.\n    if qlp_precision - 1 == 0b1111 {\n        return fmt_err(\"invalid subframe, qlp precision value invalid\");\n    }\n\n    // Next are five bits quantized linear predictor coefficient shift,\n    // in signed two's complement. Read 5 bits and then extend the sign bit.\n    let qlp_shift_unsig = try!(input.read_leq_u16(5));\n    let qlp_shift = extend_sign_u16(qlp_shift_unsig, 5);\n\n    // The spec does allow the qlp shift to be negative, but in practice this\n    // does not happen. Fully supporting it would be a performance hit, as an\n    // arithmetic shift by a negative amount is invalid, so this would incur a\n    // branch. If a real-world file ever hits this case, then we should consider\n    // making two LPC predictors, one for positive, and one for negative qlp.\n    if qlp_shift < 0 {\n        let msg = \"a negative quantized linear predictor coefficient shift is \\\n                   not supported, please file a bug.\";\n        return Err(Error::Unsupported(msg))\n    }\n\n    // Finally, the coefficients themselves. The order is at most 32, so all\n    // coefficients can be kept on the stack. Store them in reverse, because\n    // that how they are used in prediction.\n    let mut coefficients = [0; 32];\n    for coef in coefficients[..order as usize].iter_mut().rev() {\n        // We can safely read into a u16, qlp_precision is at most 15.\n        let coef_unsig = try!(input.read_leq_u16(qlp_precision));\n        *coef = extend_sign_u16(coef_unsig, qlp_precision);\n    }\n\n    // Next up is the residual. We decode it into the buffer directly, the\n    // predictor contributions will be added in a second pass. The first\n    // `order` samples have been decoded already, so continue after that.\n    try!(decode_residual(input,\n                         buffer.len() as u16,\n                         &mut buffer[order as usize..]));\n\n    try!(predict_lpc(&coefficients[..order as usize], qlp_shift, buffer));\n\n    Ok(())\n}\n"
  },
  {
    "project": "frontier",
    "target": 1,
    "commit_id": "4b6c80808209d5ea7a2d3225b572214667a27cd2",
    "func": "// SPDX-License-Identifier: Apache-2.0\n// This file is part of Frontier.\n//\n// Copyright (c) 2020 Parity Technologies (UK) Ltd.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n// \thttp://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n//! # Ethereum pallet\n//!\n//! The Ethereum pallet works together with EVM pallet to provide full emulation\n//! for Ethereum block processing.\n\n// Ensure we're `no_std` when compiling for Wasm.\n#![cfg_attr(not(feature = \"std\"), no_std)]\n\nuse codec::{Decode, Encode};\nuse ethereum_types::{Bloom, BloomInput, H160, H256, H64, U256};\nuse evm::ExitReason;\nuse fp_consensus::{PostLog, PreLog, FRONTIER_ENGINE_ID};\nuse fp_evm::CallOrCreateInfo;\nuse fp_storage::PALLET_ETHEREUM_SCHEMA;\nuse frame_support::ensure;\nuse frame_support::{\n\tdispatch::DispatchResultWithPostInfo,\n\ttraits::Get,\n\tweights::{Pays, PostDispatchInfo, Weight},\n};\nuse pallet_evm::{BlockHashMapping, FeeCalculator, GasWeightMapping, Runner};\nuse sha3::{Digest, Keccak256};\nuse sp_runtime::{\n\tgeneric::DigestItem,\n\ttraits::{One, Saturating, UniqueSaturatedInto, Zero},\n\ttransaction_validity::ValidTransactionBuilder,\n\tDispatchError,\n};\nuse sp_std::{marker::PhantomData, prelude::*};\n\npub use ethereum::{\n\tBlockV0 as Block, LegacyTransactionMessage, Log, Receipt, TransactionAction,\n\tTransactionV0 as Transaction,\n};\npub use fp_rpc::TransactionStatus;\n\n#[cfg(all(feature = \"std\", test))]\nmod mock;\n#[cfg(all(feature = \"std\", test))]\nmod tests;\n\npub use pallet::*;\n\n#[frame_support::pallet]\npub mod pallet {\n\tuse super::*;\n\tuse frame_support::pallet_prelude::*;\n\tuse frame_system::pallet_prelude::*;\n\n\t#[pallet::config]\n\tpub trait Config:\n\t\tframe_system::Config\n\t\t+ pallet_balances::Config\n\t\t+ pallet_timestamp::Config\n\t\t+ pallet_evm::Config\n\t{\n\t\t/// The overarching event type.\n\t\ttype Event: From<Event> + IsType<<Self as frame_system::Config>::Event>;\n\t\t/// How Ethereum state root is calculated.\n\t\ttype StateRoot: Get<H256>;\n\t}\n\t#[pallet::pallet]\n\t#[pallet::generate_store(pub(super) trait Store)]\n\tpub struct Pallet<T>(PhantomData<T>);\n\n\t#[pallet::hooks]\n\timpl<T: Config> Hooks<BlockNumberFor<T>> for Pallet<T> {\n\t\tfn on_finalize(n: T::BlockNumber) {\n\t\t\t<Pallet<T>>::store_block(\n\t\t\t\tfp_consensus::find_pre_log(&frame_system::Pallet::<T>::digest()).is_err(),\n\t\t\t\tU256::from(UniqueSaturatedInto::<u128>::unique_saturated_into(\n\t\t\t\t\tframe_system::Pallet::<T>::block_number(),\n\t\t\t\t)),\n\t\t\t);\n\t\t\t// move block hash pruning window by one block\n\t\t\tlet block_hash_count = T::BlockHashCount::get();\n\t\t\tlet to_remove = n\n\t\t\t\t.saturating_sub(block_hash_count)\n\t\t\t\t.saturating_sub(One::one());\n\t\t\t// keep genesis hash\n\t\t\tif !to_remove.is_zero() {\n\t\t\t\t<BlockHash<T>>::remove(U256::from(\n\t\t\t\t\tUniqueSaturatedInto::<u32>::unique_saturated_into(to_remove),\n\t\t\t\t));\n\t\t\t}\n\t\t}\n\n\t\tfn on_initialize(_: T::BlockNumber) -> Weight {\n\t\t\tPending::<T>::kill();\n\n\t\t\tif let Ok(log) = fp_consensus::find_pre_log(&frame_system::Pallet::<T>::digest()) {\n\t\t\t\tlet PreLog::Block(block) = log;\n\n\t\t\t\tfor transaction in block.transactions {\n\t\t\t\t\tSelf::do_transact(transaction).expect(\n\t\t\t\t\t\t\"pre-block transaction verification failed; the block cannot be built\",\n\t\t\t\t\t);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t0\n\t\t}\n\t}\n\n\t#[pallet::call]\n\timpl<T: Config> Pallet<T> {\n\t\t/// Transact an Ethereum transaction.\n\t\t#[pallet::weight(<T as pallet_evm::Config>::GasWeightMapping::gas_to_weight(transaction.gas_limit.unique_saturated_into()))]\n\t\tpub fn transact(\n\t\t\torigin: OriginFor<T>,\n\t\t\ttransaction: Transaction,\n\t\t) -> DispatchResultWithPostInfo {\n\t\t\tensure_none(origin)?;\n\n\t\t\tSelf::do_transact(transaction)\n\t\t}\n\t}\n\n\t#[pallet::event]\n\t#[pallet::generate_deposit(pub(super) fn deposit_event)]\n\tpub enum Event {\n\t\t/// An ethereum transaction was successfully executed. [from, to/contract_address, transaction_hash, exit_reason]\n\t\tExecuted(H160, H160, H256, ExitReason),\n\t}\n\n\t#[pallet::error]\n\tpub enum Error<T> {\n\t\t/// Signature is invalid.\n\t\tInvalidSignature,\n\t\t/// Pre-log is present, therefore transact is not allowed.\n\t\tPreLogExists,\n\t}\n\n\t/// Current building block's transactions and receipts.\n\t#[pallet::storage]\n\tpub(super) type Pending<T: Config> =\n\t\tStorageValue<_, Vec<(Transaction, TransactionStatus, ethereum::Receipt)>, ValueQuery>;\n\n\t/// The current Ethereum block.\n\t#[pallet::storage]\n\tpub(super) type CurrentBlock<T: Config> = StorageValue<_, ethereum::BlockV0>;\n\n\t/// The current Ethereum receipts.\n\t#[pallet::storage]\n\tpub(super) type CurrentReceipts<T: Config> = StorageValue<_, Vec<ethereum::Receipt>>;\n\n\t/// The current transaction statuses.\n\t#[pallet::storage]\n\tpub(super) type CurrentTransactionStatuses<T: Config> = StorageValue<_, Vec<TransactionStatus>>;\n\n\t// Mapping for block number and hashes.\n\t#[pallet::storage]\n\tpub(super) type BlockHash<T: Config> = StorageMap<_, Twox64Concat, U256, H256, ValueQuery>;\n\n\t#[pallet::genesis_config]\n\t#[derive(Default)]\n\tpub struct GenesisConfig {}\n\n\t#[pallet::genesis_build]\n\timpl<T: Config> GenesisBuild<T> for GenesisConfig {\n\t\tfn build(&self) {\n\t\t\t<Pallet<T>>::store_block(false, U256::zero());\n\t\t\tframe_support::storage::unhashed::put::<EthereumStorageSchema>(\n\t\t\t\t&PALLET_ETHEREUM_SCHEMA,\n\t\t\t\t&EthereumStorageSchema::V1,\n\t\t\t);\n\t\t}\n\t}\n\n\t#[pallet::validate_unsigned]\n\timpl<T: Config> ValidateUnsigned for Pallet<T> {\n\t\ttype Call = Call<T>;\n\n\t\tfn validate_unsigned(_source: TransactionSource, call: &Self::Call) -> TransactionValidity {\n\t\t\tif let Call::transact(transaction) = call {\n\t\t\t\tif let Some(chain_id) = transaction.signature.chain_id() {\n\t\t\t\t\tif chain_id != T::ChainId::get() {\n\t\t\t\t\t\treturn InvalidTransaction::Custom(\n\t\t\t\t\t\t\tTransactionValidationError::InvalidChainId as u8,\n\t\t\t\t\t\t)\n\t\t\t\t\t\t.into();\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tlet origin = Self::recover_signer(&transaction).ok_or_else(|| {\n\t\t\t\t\tInvalidTransaction::Custom(TransactionValidationError::InvalidSignature as u8)\n\t\t\t\t})?;\n\n\t\t\t\tif transaction.gas_limit >= T::BlockGasLimit::get() {\n\t\t\t\t\treturn InvalidTransaction::Custom(\n\t\t\t\t\t\tTransactionValidationError::InvalidGasLimit as u8,\n\t\t\t\t\t)\n\t\t\t\t\t.into();\n\t\t\t\t}\n\n\t\t\t\tlet account_data = pallet_evm::Pallet::<T>::account_basic(&origin);\n\n\t\t\t\tif transaction.nonce < account_data.nonce {\n\t\t\t\t\treturn InvalidTransaction::Stale.into();\n\t\t\t\t}\n\n\t\t\t\tlet fee = transaction.gas_price.saturating_mul(transaction.gas_limit);\n\t\t\t\tlet total_payment = transaction.value.saturating_add(fee);\n\t\t\t\tif account_data.balance < total_payment {\n\t\t\t\t\treturn InvalidTransaction::Payment.into();\n\t\t\t\t}\n\n\t\t\t\tlet min_gas_price = T::FeeCalculator::min_gas_price();\n\n\t\t\t\tif transaction.gas_price < min_gas_price {\n\t\t\t\t\treturn InvalidTransaction::Payment.into();\n\t\t\t\t}\n\n\t\t\t\tlet mut builder = ValidTransactionBuilder::default()\n\t\t\t\t\t.and_provides((origin, transaction.nonce))\n\t\t\t\t\t.priority(transaction.gas_price.unique_saturated_into());\n\n\t\t\t\tif transaction.nonce > account_data.nonce {\n\t\t\t\t\tif let Some(prev_nonce) = transaction.nonce.checked_sub(1.into()) {\n\t\t\t\t\t\tbuilder = builder.and_requires((origin, prev_nonce))\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbuilder.build()\n\t\t\t} else {\n\t\t\t\tErr(InvalidTransaction::Call.into())\n\t\t\t}\n\t\t}\n\t}\n}\n\nimpl<T: Config> Pallet<T> {\n\tfn recover_signer(transaction: &Transaction) -> Option<H160> {\n\t\tlet mut sig = [0u8; 65];\n\t\tlet mut msg = [0u8; 32];\n\t\tsig[0..32].copy_from_slice(&transaction.signature.r()[..]);\n\t\tsig[32..64].copy_from_slice(&transaction.signature.s()[..]);\n\t\tsig[64] = transaction.signature.standard_v();\n\t\tmsg.copy_from_slice(&LegacyTransactionMessage::from(transaction.clone()).hash()[..]);\n\n\t\tlet pubkey = sp_io::crypto::secp256k1_ecdsa_recover(&sig, &msg).ok()?;\n\t\tSome(H160::from(H256::from_slice(\n\t\t\tKeccak256::digest(&pubkey).as_slice(),\n\t\t)))\n\t}\n\n\tfn store_block(post_log: bool, block_number: U256) {\n\t\tlet mut transactions = Vec::new();\n\t\tlet mut statuses = Vec::new();\n\t\tlet mut receipts = Vec::new();\n\t\tlet mut logs_bloom = Bloom::default();\n\t\tfor (transaction, status, receipt) in Pending::<T>::get() {\n\t\t\ttransactions.push(transaction);\n\t\t\tstatuses.push(status);\n\t\t\treceipts.push(receipt.clone());\n\t\t\tSelf::logs_bloom(receipt.logs.clone(), &mut logs_bloom);\n\t\t}\n\n\t\tlet ommers = Vec::<ethereum::Header>::new();\n\t\tlet receipts_root =\n\t\t\tethereum::util::ordered_trie_root(receipts.iter().map(|r| rlp::encode(r)));\n\t\tlet partial_header = ethereum::PartialHeader {\n\t\t\tparent_hash: Self::current_block_hash().unwrap_or_default(),\n\t\t\tbeneficiary: pallet_evm::Pallet::<T>::find_author(),\n\t\t\tstate_root: T::StateRoot::get(),\n\t\t\treceipts_root,\n\t\t\tlogs_bloom,\n\t\t\tdifficulty: U256::zero(),\n\t\t\tnumber: block_number,\n\t\t\tgas_limit: T::BlockGasLimit::get(),\n\t\t\tgas_used: receipts\n\t\t\t\t.clone()\n\t\t\t\t.into_iter()\n\t\t\t\t.fold(U256::zero(), |acc, r| acc + r.used_gas),\n\t\t\ttimestamp: UniqueSaturatedInto::<u64>::unique_saturated_into(\n\t\t\t\tpallet_timestamp::Pallet::<T>::get(),\n\t\t\t),\n\t\t\textra_data: Vec::new(),\n\t\t\tmix_hash: H256::default(),\n\t\t\tnonce: H64::default(),\n\t\t};\n\t\tlet block = ethereum::Block::new(partial_header, transactions.clone(), ommers);\n\n\t\tCurrentBlock::<T>::put(block.clone());\n\t\tCurrentReceipts::<T>::put(receipts.clone());\n\t\tCurrentTransactionStatuses::<T>::put(statuses.clone());\n\t\tBlockHash::<T>::insert(block_number, block.header.hash());\n\n\t\tif post_log {\n\t\t\tlet digest = DigestItem::<T::Hash>::Consensus(\n\t\t\t\tFRONTIER_ENGINE_ID,\n\t\t\t\tPostLog::Hashes(fp_consensus::Hashes::from_block(block)).encode(),\n\t\t\t);\n\t\t\tframe_system::Pallet::<T>::deposit_log(digest.into());\n\t\t}\n\t}\n\n\tfn logs_bloom(logs: Vec<Log>, bloom: &mut Bloom) {\n\t\tfor log in logs {\n\t\t\tbloom.accrue(BloomInput::Raw(&log.address[..]));\n\t\t\tfor topic in log.topics {\n\t\t\t\tbloom.accrue(BloomInput::Raw(&topic[..]));\n\t\t\t}\n\t\t}\n\t}\n\n\tfn do_transact(transaction: Transaction) -> DispatchResultWithPostInfo {\n\t\tensure!(\n\t\t\tfp_consensus::find_pre_log(&frame_system::Pallet::<T>::digest()).is_err(),\n\t\t\tError::<T>::PreLogExists,\n\t\t);\n\n\t\tlet source =\n\t\t\tSelf::recover_signer(&transaction).ok_or_else(|| Error::<T>::InvalidSignature)?;\n\n\t\tlet transaction_hash =\n\t\t\tH256::from_slice(Keccak256::digest(&rlp::encode(&transaction)).as_slice());\n\t\tlet transaction_index = Pending::<T>::get().len() as u32;\n\n\t\tlet (to, contract_address, info) = Self::execute(\n\t\t\tsource,\n\t\t\ttransaction.input.clone(),\n\t\t\ttransaction.value,\n\t\t\ttransaction.gas_limit,\n\t\t\tSome(transaction.gas_price),\n\t\t\tSome(transaction.nonce),\n\t\t\ttransaction.action,\n\t\t\tNone,\n\t\t)?;\n\n\t\tlet (reason, status, used_gas, dest) = match info {\n\t\t\tCallOrCreateInfo::Call(info) => (\n\t\t\t\tinfo.exit_reason,\n\t\t\t\tTransactionStatus {\n\t\t\t\t\ttransaction_hash,\n\t\t\t\t\ttransaction_index,\n\t\t\t\t\tfrom: source,\n\t\t\t\t\tto,\n\t\t\t\t\tcontract_address: None,\n\t\t\t\t\tlogs: info.logs.clone(),\n\t\t\t\t\tlogs_bloom: {\n\t\t\t\t\t\tlet mut bloom: Bloom = Bloom::default();\n\t\t\t\t\t\tSelf::logs_bloom(info.logs, &mut bloom);\n\t\t\t\t\t\tbloom\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tinfo.used_gas,\n\t\t\t\tto,\n\t\t\t),\n\t\t\tCallOrCreateInfo::Create(info) => (\n\t\t\t\tinfo.exit_reason,\n\t\t\t\tTransactionStatus {\n\t\t\t\t\ttransaction_hash,\n\t\t\t\t\ttransaction_index,\n\t\t\t\t\tfrom: source,\n\t\t\t\t\tto,\n\t\t\t\t\tcontract_address: Some(info.value),\n\t\t\t\t\tlogs: info.logs.clone(),\n\t\t\t\t\tlogs_bloom: {\n\t\t\t\t\t\tlet mut bloom: Bloom = Bloom::default();\n\t\t\t\t\t\tSelf::logs_bloom(info.logs, &mut bloom);\n\t\t\t\t\t\tbloom\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tinfo.used_gas,\n\t\t\t\tSome(info.value),\n\t\t\t),\n\t\t};\n\n\t\tlet receipt = ethereum::Receipt {\n\t\t\tstate_root: match reason {\n\t\t\t\tExitReason::Succeed(_) => H256::from_low_u64_be(1),\n\t\t\t\tExitReason::Error(_) => H256::from_low_u64_le(0),\n\t\t\t\tExitReason::Revert(_) => H256::from_low_u64_le(0),\n\t\t\t\tExitReason::Fatal(_) => H256::from_low_u64_le(0),\n\t\t\t},\n\t\t\tused_gas,\n\t\t\tlogs_bloom: status.clone().logs_bloom,\n\t\t\tlogs: status.clone().logs,\n\t\t};\n\n\t\tPending::<T>::append((transaction, status, receipt));\n\n\t\tSelf::deposit_event(Event::Executed(\n\t\t\tsource,\n\t\t\tdest.unwrap_or_default(),\n\t\t\ttransaction_hash,\n\t\t\treason,\n\t\t));\n\t\tOk(PostDispatchInfo {\n\t\t\tactual_weight: Some(T::GasWeightMapping::gas_to_weight(\n\t\t\t\tused_gas.unique_saturated_into(),\n\t\t\t)),\n\t\t\tpays_fee: Pays::No,\n\t\t})\n\t\t.into()\n\t}\n\n\t/// Get the transaction status with given index.\n\tpub fn current_transaction_statuses() -> Option<Vec<TransactionStatus>> {\n\t\tCurrentTransactionStatuses::<T>::get()\n\t}\n\n\t/// Get current block.\n\tpub fn current_block() -> Option<ethereum::BlockV0> {\n\t\tCurrentBlock::<T>::get()\n\t}\n\n\t/// Get current block hash\n\tpub fn current_block_hash() -> Option<H256> {\n\t\tSelf::current_block().map(|block| block.header.hash())\n\t}\n\n\t/// Get receipts by number.\n\tpub fn current_receipts() -> Option<Vec<ethereum::Receipt>> {\n\t\tCurrentReceipts::<T>::get()\n\t}\n\n\t/// Execute an Ethereum transaction.\n\tpub fn execute(\n\t\tfrom: H160,\n\t\tinput: Vec<u8>,\n\t\tvalue: U256,\n\t\tgas_limit: U256,\n\t\tgas_price: Option<U256>,\n\t\tnonce: Option<U256>,\n\t\taction: TransactionAction,\n\t\tconfig: Option<evm::Config>,\n\t) -> Result<(Option<H160>, Option<H160>, CallOrCreateInfo), DispatchError> {\n\t\tmatch action {\n\t\t\tethereum::TransactionAction::Call(target) => {\n\t\t\t\tlet res = T::Runner::call(\n\t\t\t\t\tfrom,\n\t\t\t\t\ttarget,\n\t\t\t\t\tinput.clone(),\n\t\t\t\t\tvalue,\n\t\t\t\t\tgas_limit.low_u64(),\n\t\t\t\t\tgas_price,\n\t\t\t\t\tnonce,\n\t\t\t\t\tconfig.as_ref().unwrap_or(T::config()),\n\t\t\t\t)\n\t\t\t\t.map_err(Into::into)?;\n\n\t\t\t\tOk((Some(target), None, CallOrCreateInfo::Call(res)))\n\t\t\t}\n\t\t\tethereum::TransactionAction::Create => {\n\t\t\t\tlet res = T::Runner::create(\n\t\t\t\t\tfrom,\n\t\t\t\t\tinput.clone(),\n\t\t\t\t\tvalue,\n\t\t\t\t\tgas_limit.low_u64(),\n\t\t\t\t\tgas_price,\n\t\t\t\t\tnonce,\n\t\t\t\t\tconfig.as_ref().unwrap_or(T::config()),\n\t\t\t\t)\n\t\t\t\t.map_err(Into::into)?;\n\n\t\t\t\tOk((None, Some(res.value), CallOrCreateInfo::Create(res)))\n\t\t\t}\n\t\t}\n\t}\n}\n\n#[derive(Eq, PartialEq, Clone, sp_runtime::RuntimeDebug)]\npub enum ReturnValue {\n\tBytes(Vec<u8>),\n\tHash(H160),\n}\n\n/// The schema version for Pallet Ethereum's storage\n#[derive(Clone, Copy, Debug, Encode, Decode, PartialEq, Eq, PartialOrd, Ord)]\npub enum EthereumStorageSchema {\n\tUndefined,\n\tV1,\n}\n\nimpl Default for EthereumStorageSchema {\n\tfn default() -> Self {\n\t\tSelf::Undefined\n\t}\n}\n\npub struct IntermediateStateRoot;\nimpl Get<H256> for IntermediateStateRoot {\n\tfn get() -> H256 {\n\t\tH256::decode(&mut &sp_io::storage::root()[..])\n\t\t\t.expect(\"Node is configured to use the same hash; qed\")\n\t}\n}\n\n/// Returns the Ethereum block hash by number.\npub struct EthereumBlockHashMapping<T>(PhantomData<T>);\nimpl<T: Config> BlockHashMapping for EthereumBlockHashMapping<T> {\n\tfn block_hash(number: u32) -> H256 {\n\t\tBlockHash::<T>::get(U256::from(number))\n\t}\n}\n\n#[repr(u8)]\nenum TransactionValidationError {\n\t#[allow(dead_code)]\n\tUnknownError,\n\tInvalidChainId,\n\tInvalidSignature,\n\tInvalidGasLimit,\n}\n"
  },
  {
    "project": "hyper",
    "target": 1,
    "commit_id": "4d2125c67c8087de863f74278a017c4caf37e6a9",
    "func": "// `mem::uninitialized` replaced with `mem::MaybeUninit`,\n// can't upgrade yet\n#![allow(deprecated)]\n\nuse std::fmt::{self, Write};\nuse std::mem;\n\n#[cfg(feature = \"ffi\")]\nuse bytes::Bytes;\nuse bytes::BytesMut;\nuse http::header::{self, Entry, HeaderName, HeaderValue};\nuse http::{HeaderMap, Method, StatusCode, Version};\n\nuse crate::body::DecodedLength;\n#[cfg(feature = \"server\")]\nuse crate::common::date;\nuse crate::error::Parse;\nuse crate::headers;\nuse crate::proto::h1::{\n    Encode, Encoder, Http1Transaction, ParseContext, ParseResult, ParsedMessage,\n};\nuse crate::proto::{BodyLength, MessageHead, RequestHead, RequestLine};\n\nconst MAX_HEADERS: usize = 100;\nconst AVERAGE_HEADER_SIZE: usize = 30; // totally scientific\n\nmacro_rules! header_name {\n    ($bytes:expr) => {{\n        #[cfg(debug_assertions)]\n        {\n            match HeaderName::from_bytes($bytes) {\n                Ok(name) => name,\n                Err(_) => panic!(\n                    \"illegal header name from httparse: {:?}\",\n                    ::bytes::Bytes::copy_from_slice($bytes)\n                ),\n            }\n        }\n\n        #[cfg(not(debug_assertions))]\n        {\n            match HeaderName::from_bytes($bytes) {\n                Ok(name) => name,\n                Err(_) => panic!(\"illegal header name from httparse: {:?}\", $bytes),\n            }\n        }\n    }};\n}\n\nmacro_rules! header_value {\n    ($bytes:expr) => {{\n        #[cfg(debug_assertions)]\n        {\n            let __hvb: ::bytes::Bytes = $bytes;\n            match HeaderValue::from_maybe_shared(__hvb.clone()) {\n                Ok(name) => name,\n                Err(_) => panic!(\"illegal header value from httparse: {:?}\", __hvb),\n            }\n        }\n\n        #[cfg(not(debug_assertions))]\n        {\n            // Unsafe: httparse already validated header value\n            unsafe { HeaderValue::from_maybe_shared_unchecked($bytes) }\n        }\n    }};\n}\n\npub(super) fn parse_headers<T>(\n    bytes: &mut BytesMut,\n    ctx: ParseContext<'_>,\n) -> ParseResult<T::Incoming>\nwhere\n    T: Http1Transaction,\n{\n    // If the buffer is empty, don't bother entering the span, it's just noise.\n    if bytes.is_empty() {\n        return Ok(None);\n    }\n\n    let span = trace_span!(\"parse_headers\");\n    let _s = span.enter();\n    T::parse(bytes, ctx)\n}\n\npub(super) fn encode_headers<T>(\n    enc: Encode<'_, T::Outgoing>,\n    dst: &mut Vec<u8>,\n) -> crate::Result<Encoder>\nwhere\n    T: Http1Transaction,\n{\n    let span = trace_span!(\"encode_headers\");\n    let _s = span.enter();\n    T::encode(enc, dst)\n}\n\n// There are 2 main roles, Client and Server.\n\n#[cfg(feature = \"client\")]\npub(crate) enum Client {}\n\n#[cfg(feature = \"server\")]\npub(crate) enum Server {}\n\n#[cfg(feature = \"server\")]\nimpl Http1Transaction for Server {\n    type Incoming = RequestLine;\n    type Outgoing = StatusCode;\n    const LOG: &'static str = \"{role=server}\";\n\n    fn parse(buf: &mut BytesMut, ctx: ParseContext<'_>) -> ParseResult<RequestLine> {\n        debug_assert!(!buf.is_empty(), \"parse called with empty buf\");\n\n        let mut keep_alive;\n        let is_http_11;\n        let subject;\n        let version;\n        let len;\n        let headers_len;\n\n        // Unsafe: both headers_indices and headers are using uninitialized memory,\n        // but we *never* read any of it until after httparse has assigned\n        // values into it. By not zeroing out the stack memory, this saves\n        // a good ~5% on pipeline benchmarks.\n        let mut headers_indices: [HeaderIndices; MAX_HEADERS] = unsafe { mem::uninitialized() };\n        {\n            let mut headers: [httparse::Header<'_>; MAX_HEADERS] = unsafe { mem::uninitialized() };\n            trace!(\n                \"Request.parse([Header; {}], [u8; {}])\",\n                headers.len(),\n                buf.len()\n            );\n            let mut req = httparse::Request::new(&mut headers);\n            let bytes = buf.as_ref();\n            match req.parse(bytes) {\n                Ok(httparse::Status::Complete(parsed_len)) => {\n                    trace!(\"Request.parse Complete({})\", parsed_len);\n                    len = parsed_len;\n                    subject = RequestLine(\n                        Method::from_bytes(req.method.unwrap().as_bytes())?,\n                        req.path.unwrap().parse()?,\n                    );\n                    version = if req.version.unwrap() == 1 {\n                        keep_alive = true;\n                        is_http_11 = true;\n                        Version::HTTP_11\n                    } else {\n                        keep_alive = false;\n                        is_http_11 = false;\n                        Version::HTTP_10\n                    };\n                    trace!(\"headers: {:?}\", &req.headers);\n\n                    record_header_indices(bytes, &req.headers, &mut headers_indices)?;\n                    headers_len = req.headers.len();\n                }\n                Ok(httparse::Status::Partial) => return Ok(None),\n                Err(err) => {\n                    return Err(match err {\n                        // if invalid Token, try to determine if for method or path\n                        httparse::Error::Token => {\n                            if req.method.is_none() {\n                                Parse::Method\n                            } else {\n                                debug_assert!(req.path.is_none());\n                                Parse::Uri\n                            }\n                        }\n                        other => other.into(),\n                    });\n                }\n            }\n        };\n\n        let slice = buf.split_to(len).freeze();\n\n        // According to https://tools.ietf.org/html/rfc7230#section-3.3.3\n        // 1. (irrelevant to Request)\n        // 2. (irrelevant to Request)\n        // 3. Transfer-Encoding: chunked has a chunked body.\n        // 4. If multiple differing Content-Length headers or invalid, close connection.\n        // 5. Content-Length header has a sized body.\n        // 6. Length 0.\n        // 7. (irrelevant to Request)\n\n        let mut decoder = DecodedLength::ZERO;\n        let mut expect_continue = false;\n        let mut con_len = None;\n        let mut is_te = false;\n        let mut is_te_chunked = false;\n        let mut wants_upgrade = subject.0 == Method::CONNECT;\n\n        let mut headers = ctx.cached_headers.take().unwrap_or_else(HeaderMap::new);\n\n        headers.reserve(headers_len);\n\n        for header in &headers_indices[..headers_len] {\n            let name = header_name!(&slice[header.name.0..header.name.1]);\n            let value = header_value!(slice.slice(header.value.0..header.value.1));\n\n            match name {\n                header::TRANSFER_ENCODING => {\n                    // https://tools.ietf.org/html/rfc7230#section-3.3.3\n                    // If Transfer-Encoding header is present, and 'chunked' is\n                    // not the final encoding, and this is a Request, then it is\n                    // malformed. A server should respond with 400 Bad Request.\n                    if !is_http_11 {\n                        debug!(\"HTTP/1.0 cannot have Transfer-Encoding header\");\n                        return Err(Parse::Header);\n                    }\n                    is_te = true;\n                    if headers::is_chunked_(&value) {\n                        is_te_chunked = true;\n                        decoder = DecodedLength::CHUNKED;\n                    }\n                }\n                header::CONTENT_LENGTH => {\n                    if is_te {\n                        continue;\n                    }\n                    let len = value\n                        .to_str()\n                        .map_err(|_| Parse::Header)\n                        .and_then(|s| s.parse().map_err(|_| Parse::Header))?;\n                    if let Some(prev) = con_len {\n                        if prev != len {\n                            debug!(\n                                \"multiple Content-Length headers with different values: [{}, {}]\",\n                                prev, len,\n                            );\n                            return Err(Parse::Header);\n                        }\n                        // we don't need to append this secondary length\n                        continue;\n                    }\n                    decoder = DecodedLength::checked_new(len)?;\n                    con_len = Some(len);\n                }\n                header::CONNECTION => {\n                    // keep_alive was previously set to default for Version\n                    if keep_alive {\n                        // HTTP/1.1\n                        keep_alive = !headers::connection_close(&value);\n                    } else {\n                        // HTTP/1.0\n                        keep_alive = headers::connection_keep_alive(&value);\n                    }\n                }\n                header::EXPECT => {\n                    expect_continue = value.as_bytes() == b\"100-continue\";\n                }\n                header::UPGRADE => {\n                    // Upgrades are only allowed with HTTP/1.1\n                    wants_upgrade = is_http_11;\n                }\n\n                _ => (),\n            }\n\n            headers.append(name, value);\n        }\n\n        if is_te && !is_te_chunked {\n            debug!(\"request with transfer-encoding header, but not chunked, bad request\");\n            return Err(Parse::Header);\n        }\n\n        *ctx.req_method = Some(subject.0.clone());\n\n        Ok(Some(ParsedMessage {\n            head: MessageHead {\n                version,\n                subject,\n                headers,\n                extensions: http::Extensions::default(),\n            },\n            decode: decoder,\n            expect_continue,\n            keep_alive,\n            wants_upgrade,\n        }))\n    }\n\n    fn encode(\n        mut msg: Encode<'_, Self::Outgoing>,\n        mut dst: &mut Vec<u8>,\n    ) -> crate::Result<Encoder> {\n        trace!(\n            \"Server::encode status={:?}, body={:?}, req_method={:?}\",\n            msg.head.subject,\n            msg.body,\n            msg.req_method\n        );\n        debug_assert!(\n            !msg.title_case_headers,\n            \"no server config for title case headers\"\n        );\n\n        let mut wrote_len = false;\n\n        // hyper currently doesn't support returning 1xx status codes as a Response\n        // This is because Service only allows returning a single Response, and\n        // so if you try to reply with a e.g. 100 Continue, you have no way of\n        // replying with the latter status code response.\n        let (ret, mut is_last) = if msg.head.subject == StatusCode::SWITCHING_PROTOCOLS {\n            (Ok(()), true)\n        } else if msg.req_method == &Some(Method::CONNECT) && msg.head.subject.is_success() {\n            // Sending content-length or transfer-encoding header on 2xx response\n            // to CONNECT is forbidden in RFC 7231.\n            wrote_len = true;\n            (Ok(()), true)\n        } else if msg.head.subject.is_informational() {\n            warn!(\"response with 1xx status code not supported\");\n            *msg.head = MessageHead::default();\n            msg.head.subject = StatusCode::INTERNAL_SERVER_ERROR;\n            msg.body = None;\n            (Err(crate::Error::new_user_unsupported_status_code()), true)\n        } else {\n            (Ok(()), !msg.keep_alive)\n        };\n\n        // In some error cases, we don't know about the invalid message until already\n        // pushing some bytes onto the `dst`. In those cases, we don't want to send\n        // the half-pushed message, so rewind to before.\n        let orig_len = dst.len();\n        let rewind = |dst: &mut Vec<u8>| {\n            dst.truncate(orig_len);\n        };\n\n        let init_cap = 30 + msg.head.headers.len() * AVERAGE_HEADER_SIZE;\n        dst.reserve(init_cap);\n        if msg.head.version == Version::HTTP_11 && msg.head.subject == StatusCode::OK {\n            extend(dst, b\"HTTP/1.1 200 OK\\r\\n\");\n        } else {\n            match msg.head.version {\n                Version::HTTP_10 => extend(dst, b\"HTTP/1.0 \"),\n                Version::HTTP_11 => extend(dst, b\"HTTP/1.1 \"),\n                Version::HTTP_2 => {\n                    debug!(\"response with HTTP2 version coerced to HTTP/1.1\");\n                    extend(dst, b\"HTTP/1.1 \");\n                }\n                other => panic!(\"unexpected response version: {:?}\", other),\n            }\n\n            extend(dst, msg.head.subject.as_str().as_bytes());\n            extend(dst, b\" \");\n            // a reason MUST be written, as many parsers will expect it.\n            extend(\n                dst,\n                msg.head\n                    .subject\n                    .canonical_reason()\n                    .unwrap_or(\"<none>\")\n                    .as_bytes(),\n            );\n            extend(dst, b\"\\r\\n\");\n        }\n\n        let mut encoder = Encoder::length(0);\n        let mut wrote_date = false;\n        let mut cur_name = None;\n        let mut is_name_written = false;\n        let mut must_write_chunked = false;\n        let mut prev_con_len = None;\n\n        macro_rules! handle_is_name_written {\n            () => {{\n                if is_name_written {\n                    // we need to clean up and write the newline\n                    debug_assert_ne!(\n                        &dst[dst.len() - 2..],\n                        b\"\\r\\n\",\n                        \"previous header wrote newline but set is_name_written\"\n                    );\n\n                    if must_write_chunked {\n                        extend(dst, b\", chunked\\r\\n\");\n                    } else {\n                        extend(dst, b\"\\r\\n\");\n                    }\n                }\n            }};\n        }\n\n        'headers: for (opt_name, value) in msg.head.headers.drain() {\n            if let Some(n) = opt_name {\n                cur_name = Some(n);\n                handle_is_name_written!();\n                is_name_written = false;\n            }\n            let name = cur_name.as_ref().expect(\"current header name\");\n            match *name {\n                header::CONTENT_LENGTH => {\n                    if wrote_len && !is_name_written {\n                        warn!(\"unexpected content-length found, canceling\");\n                        rewind(dst);\n                        return Err(crate::Error::new_user_header());\n                    }\n                    match msg.body {\n                        Some(BodyLength::Known(known_len)) => {\n                            // The HttpBody claims to know a length, and\n                            // the headers are already set. For performance\n                            // reasons, we are just going to trust that\n                            // the values match.\n                            //\n                            // In debug builds, we'll assert they are the\n                            // same to help developers find bugs.\n                            #[cfg(debug_assertions)]\n                            {\n                                if let Some(len) = headers::content_length_parse(&value) {\n                                    assert!(\n                                        len == known_len,\n                                        \"payload claims content-length of {}, custom content-length header claims {}\",\n                                        known_len,\n                                        len,\n                                    );\n                                }\n                            }\n\n                            if !is_name_written {\n                                encoder = Encoder::length(known_len);\n                                extend(dst, b\"content-length: \");\n                                extend(dst, value.as_bytes());\n                                wrote_len = true;\n                                is_name_written = true;\n                            }\n                            continue 'headers;\n                        }\n                        Some(BodyLength::Unknown) => {\n                            // The HttpBody impl didn't know how long the\n                            // body is, but a length header was included.\n                            // We have to parse the value to return our\n                            // Encoder...\n\n                            if let Some(len) = headers::content_length_parse(&value) {\n                                if let Some(prev) = prev_con_len {\n                                    if prev != len {\n                                        warn!(\n                                            \"multiple Content-Length values found: [{}, {}]\",\n                                            prev, len\n                                        );\n                                        rewind(dst);\n                                        return Err(crate::Error::new_user_header());\n                                    }\n                                    debug_assert!(is_name_written);\n                                    continue 'headers;\n                                } else {\n                                    // we haven't written content-length yet!\n                                    encoder = Encoder::length(len);\n                                    extend(dst, b\"content-length: \");\n                                    extend(dst, value.as_bytes());\n                                    wrote_len = true;\n                                    is_name_written = true;\n                                    prev_con_len = Some(len);\n                                    continue 'headers;\n                                }\n                            } else {\n                                warn!(\"illegal Content-Length value: {:?}\", value);\n                                rewind(dst);\n                                return Err(crate::Error::new_user_header());\n                            }\n                        }\n                        None => {\n                            // We have no body to actually send,\n                            // but the headers claim a content-length.\n                            // There's only 2 ways this makes sense:\n                            //\n                            // - The header says the length is `0`.\n                            // - This is a response to a `HEAD` request.\n                            if msg.req_method == &Some(Method::HEAD) {\n                                debug_assert_eq!(encoder, Encoder::length(0));\n                            } else {\n                                if value.as_bytes() != b\"0\" {\n                                    warn!(\n                                        \"content-length value found, but empty body provided: {:?}\",\n                                        value\n                                    );\n                                }\n                                continue 'headers;\n                            }\n                        }\n                    }\n                    wrote_len = true;\n                }\n                header::TRANSFER_ENCODING => {\n                    if wrote_len && !is_name_written {\n                        warn!(\"unexpected transfer-encoding found, canceling\");\n                        rewind(dst);\n                        return Err(crate::Error::new_user_header());\n                    }\n                    // check that we actually can send a chunked body...\n                    if msg.head.version == Version::HTTP_10\n                        || !Server::can_chunked(msg.req_method, msg.head.subject)\n                    {\n                        continue;\n                    }\n                    wrote_len = true;\n                    // Must check each value, because `chunked` needs to be the\n                    // last encoding, or else we add it.\n                    must_write_chunked = !headers::is_chunked_(&value);\n\n                    if !is_name_written {\n                        encoder = Encoder::chunked();\n                        is_name_written = true;\n                        extend(dst, b\"transfer-encoding: \");\n                        extend(dst, value.as_bytes());\n                    } else {\n                        extend(dst, b\", \");\n                        extend(dst, value.as_bytes());\n                    }\n                    continue 'headers;\n                }\n                header::CONNECTION => {\n                    if !is_last && headers::connection_close(&value) {\n                        is_last = true;\n                    }\n                    if !is_name_written {\n                        is_name_written = true;\n                        extend(dst, b\"connection: \");\n                        extend(dst, value.as_bytes());\n                    } else {\n                        extend(dst, b\", \");\n                        extend(dst, value.as_bytes());\n                    }\n                    continue 'headers;\n                }\n                header::DATE => {\n                    wrote_date = true;\n                }\n                _ => (),\n            }\n            //TODO: this should perhaps instead combine them into\n            //single lines, as RFC7230 suggests is preferable.\n\n            // non-special write Name and Value\n            debug_assert!(\n                !is_name_written,\n                \"{:?} set is_name_written and didn't continue loop\",\n                name,\n            );\n            extend(dst, name.as_str().as_bytes());\n            extend(dst, b\": \");\n            extend(dst, value.as_bytes());\n            extend(dst, b\"\\r\\n\");\n        }\n\n        handle_is_name_written!();\n\n        if !wrote_len {\n            encoder = match msg.body {\n                Some(BodyLength::Unknown) => {\n                    if msg.head.version == Version::HTTP_10\n                        || !Server::can_chunked(msg.req_method, msg.head.subject)\n                    {\n                        Encoder::close_delimited()\n                    } else {\n                        extend(dst, b\"transfer-encoding: chunked\\r\\n\");\n                        Encoder::chunked()\n                    }\n                }\n                None | Some(BodyLength::Known(0)) => {\n                    if msg.head.subject != StatusCode::NOT_MODIFIED {\n                        extend(dst, b\"content-length: 0\\r\\n\");\n                    }\n                    Encoder::length(0)\n                }\n                Some(BodyLength::Known(len)) => {\n                    if msg.head.subject == StatusCode::NOT_MODIFIED {\n                        Encoder::length(0)\n                    } else {\n                        extend(dst, b\"content-length: \");\n                        let _ = ::itoa::write(&mut dst, len);\n                        extend(dst, b\"\\r\\n\");\n                        Encoder::length(len)\n                    }\n                }\n            };\n        }\n\n        if !Server::can_have_body(msg.req_method, msg.head.subject) {\n            trace!(\n                \"server body forced to 0; method={:?}, status={:?}\",\n                msg.req_method,\n                msg.head.subject\n            );\n            encoder = Encoder::length(0);\n        }\n\n        // cached date is much faster than formatting every request\n        if !wrote_date {\n            dst.reserve(date::DATE_VALUE_LENGTH + 8);\n            extend(dst, b\"date: \");\n            date::extend(dst);\n            extend(dst, b\"\\r\\n\\r\\n\");\n        } else {\n            extend(dst, b\"\\r\\n\");\n        }\n\n        ret.map(|()| encoder.set_last(is_last))\n    }\n\n    fn on_error(err: &crate::Error) -> Option<MessageHead<Self::Outgoing>> {\n        use crate::error::Kind;\n        let status = match *err.kind() {\n            Kind::Parse(Parse::Method)\n            | Kind::Parse(Parse::Header)\n            | Kind::Parse(Parse::Uri)\n            | Kind::Parse(Parse::Version) => StatusCode::BAD_REQUEST,\n            Kind::Parse(Parse::TooLarge) => StatusCode::REQUEST_HEADER_FIELDS_TOO_LARGE,\n            _ => return None,\n        };\n\n        debug!(\"sending automatic response ({}) for parse error\", status);\n        let mut msg = MessageHead::default();\n        msg.subject = status;\n        Some(msg)\n    }\n\n    fn is_server() -> bool {\n        true\n    }\n\n    fn update_date() {\n        date::update();\n    }\n}\n\n#[cfg(feature = \"server\")]\nimpl Server {\n    fn can_have_body(method: &Option<Method>, status: StatusCode) -> bool {\n        Server::can_chunked(method, status)\n    }\n\n    fn can_chunked(method: &Option<Method>, status: StatusCode) -> bool {\n        if method == &Some(Method::HEAD) || method == &Some(Method::CONNECT) && status.is_success()\n        {\n            false\n        } else {\n            match status {\n                // TODO: support for 1xx codes needs improvement everywhere\n                // would be 100...199 => false\n                StatusCode::SWITCHING_PROTOCOLS\n                | StatusCode::NO_CONTENT\n                | StatusCode::NOT_MODIFIED => false,\n                _ => true,\n            }\n        }\n    }\n}\n\n#[cfg(feature = \"client\")]\nimpl Http1Transaction for Client {\n    type Incoming = StatusCode;\n    type Outgoing = RequestLine;\n    const LOG: &'static str = \"{role=client}\";\n\n    fn parse(buf: &mut BytesMut, ctx: ParseContext<'_>) -> ParseResult<StatusCode> {\n        debug_assert!(!buf.is_empty(), \"parse called with empty buf\");\n\n        // Loop to skip information status code headers (100 Continue, etc).\n        loop {\n            // Unsafe: see comment in Server Http1Transaction, above.\n            let mut headers_indices: [HeaderIndices; MAX_HEADERS] = unsafe { mem::uninitialized() };\n            let (len, status, reason, version, headers_len) = {\n                let mut headers: [httparse::Header<'_>; MAX_HEADERS] =\n                    unsafe { mem::uninitialized() };\n                trace!(\n                    \"Response.parse([Header; {}], [u8; {}])\",\n                    headers.len(),\n                    buf.len()\n                );\n                let mut res = httparse::Response::new(&mut headers);\n                let bytes = buf.as_ref();\n                match res.parse(bytes)? {\n                    httparse::Status::Complete(len) => {\n                        trace!(\"Response.parse Complete({})\", len);\n                        let status = StatusCode::from_u16(res.code.unwrap())?;\n\n                        #[cfg(not(feature = \"ffi\"))]\n                        let reason = ();\n                        #[cfg(feature = \"ffi\")]\n                        let reason = {\n                            let reason = res.reason.unwrap();\n                            // Only save the reason phrase if it isnt the canonical reason\n                            if Some(reason) != status.canonical_reason() {\n                                Some(Bytes::copy_from_slice(reason.as_bytes()))\n                            } else {\n                                None\n                            }\n                        };\n\n                        let version = if res.version.unwrap() == 1 {\n                            Version::HTTP_11\n                        } else {\n                            Version::HTTP_10\n                        };\n                        record_header_indices(bytes, &res.headers, &mut headers_indices)?;\n                        let headers_len = res.headers.len();\n                        (len, status, reason, version, headers_len)\n                    }\n                    httparse::Status::Partial => return Ok(None),\n                }\n            };\n\n            let slice = buf.split_to(len).freeze();\n\n            let mut headers = ctx.cached_headers.take().unwrap_or_else(HeaderMap::new);\n\n            let mut keep_alive = version == Version::HTTP_11;\n\n            #[cfg(feature = \"ffi\")]\n            let mut header_case_map = crate::ffi::HeaderCaseMap::default();\n\n            headers.reserve(headers_len);\n            for header in &headers_indices[..headers_len] {\n                let name = header_name!(&slice[header.name.0..header.name.1]);\n                let value = header_value!(slice.slice(header.value.0..header.value.1));\n\n                if let header::CONNECTION = name {\n                    // keep_alive was previously set to default for Version\n                    if keep_alive {\n                        // HTTP/1.1\n                        keep_alive = !headers::connection_close(&value);\n                    } else {\n                        // HTTP/1.0\n                        keep_alive = headers::connection_keep_alive(&value);\n                    }\n                }\n\n                #[cfg(feature = \"ffi\")]\n                if ctx.preserve_header_case {\n                    header_case_map.append(&name, slice.slice(header.name.0..header.name.1));\n                }\n\n                headers.append(name, value);\n            }\n\n            #[allow(unused_mut)]\n            let mut extensions = http::Extensions::default();\n\n            #[cfg(feature = \"ffi\")]\n            if ctx.preserve_header_case {\n                extensions.insert(header_case_map);\n            }\n\n            #[cfg(feature = \"ffi\")]\n            if let Some(reason) = reason {\n                extensions.insert(crate::ffi::ReasonPhrase(reason));\n            }\n            #[cfg(not(feature = \"ffi\"))]\n            drop(reason);\n\n            let head = MessageHead {\n                version,\n                subject: status,\n                headers,\n                extensions,\n            };\n            if let Some((decode, is_upgrade)) = Client::decoder(&head, ctx.req_method)? {\n                return Ok(Some(ParsedMessage {\n                    head,\n                    decode,\n                    expect_continue: false,\n                    // a client upgrade means the connection can't be used\n                    // again, as it is definitely upgrading.\n                    keep_alive: keep_alive && !is_upgrade,\n                    wants_upgrade: is_upgrade,\n                }));\n            }\n\n            // Parsing a 1xx response could have consumed the buffer, check if\n            // it is empty now...\n            if buf.is_empty() {\n                return Ok(None);\n            }\n        }\n    }\n\n    fn encode(msg: Encode<'_, Self::Outgoing>, dst: &mut Vec<u8>) -> crate::Result<Encoder> {\n        trace!(\n            \"Client::encode method={:?}, body={:?}\",\n            msg.head.subject.0,\n            msg.body\n        );\n\n        *msg.req_method = Some(msg.head.subject.0.clone());\n\n        let body = Client::set_length(msg.head, msg.body);\n\n        let init_cap = 30 + msg.head.headers.len() * AVERAGE_HEADER_SIZE;\n        dst.reserve(init_cap);\n\n        extend(dst, msg.head.subject.0.as_str().as_bytes());\n        extend(dst, b\" \");\n        //TODO: add API to http::Uri to encode without std::fmt\n        let _ = write!(FastWrite(dst), \"{} \", msg.head.subject.1);\n\n        match msg.head.version {\n            Version::HTTP_10 => extend(dst, b\"HTTP/1.0\"),\n            Version::HTTP_11 => extend(dst, b\"HTTP/1.1\"),\n            Version::HTTP_2 => {\n                debug!(\"request with HTTP2 version coerced to HTTP/1.1\");\n                extend(dst, b\"HTTP/1.1\");\n            }\n            other => panic!(\"unexpected request version: {:?}\", other),\n        }\n        extend(dst, b\"\\r\\n\");\n\n        #[cfg(feature = \"ffi\")]\n        {\n            if msg.title_case_headers {\n                write_headers_title_case(&msg.head.headers, dst);\n            } else if let Some(orig_headers) =\n                msg.head.extensions.get::<crate::ffi::HeaderCaseMap>()\n            {\n                write_headers_original_case(&msg.head.headers, orig_headers, dst);\n            } else {\n                write_headers(&msg.head.headers, dst);\n            }\n        }\n\n        #[cfg(not(feature = \"ffi\"))]\n        {\n            if msg.title_case_headers {\n                write_headers_title_case(&msg.head.headers, dst);\n            } else {\n                write_headers(&msg.head.headers, dst);\n            }\n        }\n\n        extend(dst, b\"\\r\\n\");\n        msg.head.headers.clear(); //TODO: remove when switching to drain()\n\n        Ok(body)\n    }\n\n    fn on_error(_err: &crate::Error) -> Option<MessageHead<Self::Outgoing>> {\n        // we can't tell the server about any errors it creates\n        None\n    }\n\n    fn is_client() -> bool {\n        true\n    }\n}\n\n#[cfg(feature = \"client\")]\nimpl Client {\n    /// Returns Some(length, wants_upgrade) if successful.\n    ///\n    /// Returns None if this message head should be skipped (like a 100 status).\n    fn decoder(\n        inc: &MessageHead<StatusCode>,\n        method: &mut Option<Method>,\n    ) -> Result<Option<(DecodedLength, bool)>, Parse> {\n        // According to https://tools.ietf.org/html/rfc7230#section-3.3.3\n        // 1. HEAD responses, and Status 1xx, 204, and 304 cannot have a body.\n        // 2. Status 2xx to a CONNECT cannot have a body.\n        // 3. Transfer-Encoding: chunked has a chunked body.\n        // 4. If multiple differing Content-Length headers or invalid, close connection.\n        // 5. Content-Length header has a sized body.\n        // 6. (irrelevant to Response)\n        // 7. Read till EOF.\n\n        match inc.subject.as_u16() {\n            101 => {\n                return Ok(Some((DecodedLength::ZERO, true)));\n            }\n            100 | 102..=199 => {\n                trace!(\"ignoring informational response: {}\", inc.subject.as_u16());\n                return Ok(None);\n            }\n            204 | 304 => return Ok(Some((DecodedLength::ZERO, false))),\n            _ => (),\n        }\n        match *method {\n            Some(Method::HEAD) => {\n                return Ok(Some((DecodedLength::ZERO, false)));\n            }\n            Some(Method::CONNECT) => {\n                if let 200..=299 = inc.subject.as_u16() {\n                    return Ok(Some((DecodedLength::ZERO, true)));\n                }\n            }\n            Some(_) => {}\n            None => {\n                trace!(\"Client::decoder is missing the Method\");\n            }\n        }\n\n        if inc.headers.contains_key(header::TRANSFER_ENCODING) {\n            // https://tools.ietf.org/html/rfc7230#section-3.3.3\n            // If Transfer-Encoding header is present, and 'chunked' is\n            // not the final encoding, and this is a Request, then it is\n            // malformed. A server should respond with 400 Bad Request.\n            if inc.version == Version::HTTP_10 {\n                debug!(\"HTTP/1.0 cannot have Transfer-Encoding header\");\n                Err(Parse::Header)\n            } else if headers::transfer_encoding_is_chunked(&inc.headers) {\n                Ok(Some((DecodedLength::CHUNKED, false)))\n            } else {\n                trace!(\"not chunked, read till eof\");\n                Ok(Some((DecodedLength::CLOSE_DELIMITED, false)))\n            }\n        } else if let Some(len) = headers::content_length_parse_all(&inc.headers) {\n            Ok(Some((DecodedLength::checked_new(len)?, false)))\n        } else if inc.headers.contains_key(header::CONTENT_LENGTH) {\n            debug!(\"illegal Content-Length header\");\n            Err(Parse::Header)\n        } else {\n            trace!(\"neither Transfer-Encoding nor Content-Length\");\n            Ok(Some((DecodedLength::CLOSE_DELIMITED, false)))\n        }\n    }\n    fn set_length(head: &mut RequestHead, body: Option<BodyLength>) -> Encoder {\n        let body = if let Some(body) = body {\n            body\n        } else {\n            head.headers.remove(header::TRANSFER_ENCODING);\n            return Encoder::length(0);\n        };\n\n        // HTTP/1.0 doesn't know about chunked\n        let can_chunked = head.version == Version::HTTP_11;\n        let headers = &mut head.headers;\n\n        // If the user already set specific headers, we should respect them, regardless\n        // of what the HttpBody knows about itself. They set them for a reason.\n\n        // Because of the borrow checker, we can't check the for an existing\n        // Content-Length header while holding an `Entry` for the Transfer-Encoding\n        // header, so unfortunately, we must do the check here, first.\n\n        let existing_con_len = headers::content_length_parse_all(headers);\n        let mut should_remove_con_len = false;\n\n        if !can_chunked {\n            // Chunked isn't legal, so if it is set, we need to remove it.\n            if headers.remove(header::TRANSFER_ENCODING).is_some() {\n                trace!(\"removing illegal transfer-encoding header\");\n            }\n\n            return if let Some(len) = existing_con_len {\n                Encoder::length(len)\n            } else if let BodyLength::Known(len) = body {\n                set_content_length(headers, len)\n            } else {\n                // HTTP/1.0 client requests without a content-length\n                // cannot have any body at all.\n                Encoder::length(0)\n            };\n        }\n\n        // If the user set a transfer-encoding, respect that. Let's just\n        // make sure `chunked` is the final encoding.\n        let encoder = match headers.entry(header::TRANSFER_ENCODING) {\n            Entry::Occupied(te) => {\n                should_remove_con_len = true;\n                if headers::is_chunked(te.iter()) {\n                    Some(Encoder::chunked())\n                } else {\n                    warn!(\"user provided transfer-encoding does not end in 'chunked'\");\n\n                    // There's a Transfer-Encoding, but it doesn't end in 'chunked'!\n                    // An example that could trigger this:\n                    //\n                    //     Transfer-Encoding: gzip\n                    //\n                    // This can be bad, depending on if this is a request or a\n                    // response.\n                    //\n                    // - A request is illegal if there is a `Transfer-Encoding`\n                    //   but it doesn't end in `chunked`.\n                    // - A response that has `Transfer-Encoding` but doesn't\n                    //   end in `chunked` isn't illegal, it just forces this\n                    //   to be close-delimited.\n                    //\n                    // We can try to repair this, by adding `chunked` ourselves.\n\n                    headers::add_chunked(te);\n                    Some(Encoder::chunked())\n                }\n            }\n            Entry::Vacant(te) => {\n                if let Some(len) = existing_con_len {\n                    Some(Encoder::length(len))\n                } else if let BodyLength::Unknown = body {\n                    // GET, HEAD, and CONNECT almost never have bodies.\n                    //\n                    // So instead of sending a \"chunked\" body with a 0-chunk,\n                    // assume no body here. If you *must* send a body,\n                    // set the headers explicitly.\n                    match head.subject.0 {\n                        Method::GET | Method::HEAD | Method::CONNECT => Some(Encoder::length(0)),\n                        _ => {\n                            te.insert(HeaderValue::from_static(\"chunked\"));\n                            Some(Encoder::chunked())\n                        }\n                    }\n                } else {\n                    None\n                }\n            }\n        };\n\n        // This is because we need a second mutable borrow to remove\n        // content-length header.\n        if let Some(encoder) = encoder {\n            if should_remove_con_len && existing_con_len.is_some() {\n                headers.remove(header::CONTENT_LENGTH);\n            }\n            return encoder;\n        }\n\n        // User didn't set transfer-encoding, AND we know body length,\n        // so we can just set the Content-Length automatically.\n\n        let len = if let BodyLength::Known(len) = body {\n            len\n        } else {\n            unreachable!(\"BodyLength::Unknown would set chunked\");\n        };\n\n        set_content_length(headers, len)\n    }\n}\n\nfn set_content_length(headers: &mut HeaderMap, len: u64) -> Encoder {\n    // At this point, there should not be a valid Content-Length\n    // header. However, since we'll be indexing in anyways, we can\n    // warn the user if there was an existing illegal header.\n    //\n    // Or at least, we can in theory. It's actually a little bit slower,\n    // so perhaps only do that while the user is developing/testing.\n\n    if cfg!(debug_assertions) {\n        match headers.entry(header::CONTENT_LENGTH) {\n            Entry::Occupied(mut cl) => {\n                // Internal sanity check, we should have already determined\n                // that the header was illegal before calling this function.\n                debug_assert!(headers::content_length_parse_all_values(cl.iter()).is_none());\n                // Uh oh, the user set `Content-Length` headers, but set bad ones.\n                // This would be an illegal message anyways, so let's try to repair\n                // with our known good length.\n                error!(\"user provided content-length header was invalid\");\n\n                cl.insert(HeaderValue::from(len));\n                Encoder::length(len)\n            }\n            Entry::Vacant(cl) => {\n                cl.insert(HeaderValue::from(len));\n                Encoder::length(len)\n            }\n        }\n    } else {\n        headers.insert(header::CONTENT_LENGTH, HeaderValue::from(len));\n        Encoder::length(len)\n    }\n}\n\n#[derive(Clone, Copy)]\nstruct HeaderIndices {\n    name: (usize, usize),\n    value: (usize, usize),\n}\n\nfn record_header_indices(\n    bytes: &[u8],\n    headers: &[httparse::Header<'_>],\n    indices: &mut [HeaderIndices],\n) -> Result<(), crate::error::Parse> {\n    let bytes_ptr = bytes.as_ptr() as usize;\n\n    for (header, indices) in headers.iter().zip(indices.iter_mut()) {\n        if header.name.len() >= (1 << 16) {\n            debug!(\"header name larger than 64kb: {:?}\", header.name);\n            return Err(crate::error::Parse::TooLarge);\n        }\n        let name_start = header.name.as_ptr() as usize - bytes_ptr;\n        let name_end = name_start + header.name.len();\n        indices.name = (name_start, name_end);\n        let value_start = header.value.as_ptr() as usize - bytes_ptr;\n        let value_end = value_start + header.value.len();\n        indices.value = (value_start, value_end);\n    }\n\n    Ok(())\n}\n\n// Write header names as title case. The header name is assumed to be ASCII,\n// therefore it is trivial to convert an ASCII character from lowercase to\n// uppercase. It is as simple as XORing the lowercase character byte with\n// space.\nfn title_case(dst: &mut Vec<u8>, name: &[u8]) {\n    dst.reserve(name.len());\n\n    let mut iter = name.iter();\n\n    // Uppercase the first character\n    if let Some(c) = iter.next() {\n        if *c >= b'a' && *c <= b'z' {\n            dst.push(*c ^ b' ');\n        } else {\n            dst.push(*c);\n        }\n    }\n\n    while let Some(c) = iter.next() {\n        dst.push(*c);\n\n        if *c == b'-' {\n            if let Some(c) = iter.next() {\n                if *c >= b'a' && *c <= b'z' {\n                    dst.push(*c ^ b' ');\n                } else {\n                    dst.push(*c);\n                }\n            }\n        }\n    }\n}\n\nfn write_headers_title_case(headers: &HeaderMap, dst: &mut Vec<u8>) {\n    for (name, value) in headers {\n        title_case(dst, name.as_str().as_bytes());\n        extend(dst, b\": \");\n        extend(dst, value.as_bytes());\n        extend(dst, b\"\\r\\n\");\n    }\n}\n\nfn write_headers(headers: &HeaderMap, dst: &mut Vec<u8>) {\n    for (name, value) in headers {\n        extend(dst, name.as_str().as_bytes());\n        extend(dst, b\": \");\n        extend(dst, value.as_bytes());\n        extend(dst, b\"\\r\\n\");\n    }\n}\n\n#[cfg(feature = \"ffi\")]\n#[cold]\nfn write_headers_original_case(\n    headers: &HeaderMap,\n    orig_case: &crate::ffi::HeaderCaseMap,\n    dst: &mut Vec<u8>,\n) {\n    // For each header name/value pair, there may be a value in the casemap\n    // that corresponds to the HeaderValue. So, we iterator all the keys,\n    // and for each one, try to pair the originally cased name with the value.\n    //\n    // TODO: consider adding http::HeaderMap::entries() iterator\n    for name in headers.keys() {\n        let mut names = orig_case.get_all(name).iter();\n\n        for value in headers.get_all(name) {\n            if let Some(orig_name) = names.next() {\n                extend(dst, orig_name);\n            } else {\n                extend(dst, name.as_str().as_bytes());\n            }\n\n            // Wanted for curl test cases that send `X-Custom-Header:\\r\\n`\n            if value.is_empty() {\n                extend(dst, b\":\\r\\n\");\n            } else {\n                extend(dst, b\": \");\n                extend(dst, value.as_bytes());\n                extend(dst, b\"\\r\\n\");\n            }\n        }\n    }\n}\n\nstruct FastWrite<'a>(&'a mut Vec<u8>);\n\nimpl<'a> fmt::Write for FastWrite<'a> {\n    #[inline]\n    fn write_str(&mut self, s: &str) -> fmt::Result {\n        extend(self.0, s.as_bytes());\n        Ok(())\n    }\n\n    #[inline]\n    fn write_fmt(&mut self, args: fmt::Arguments<'_>) -> fmt::Result {\n        fmt::write(self, args)\n    }\n}\n\n#[inline]\nfn extend(dst: &mut Vec<u8>, data: &[u8]) {\n    dst.extend_from_slice(data);\n}\n\n#[cfg(test)]\nmod tests {\n    use bytes::BytesMut;\n\n    use super::*;\n\n    #[test]\n    fn test_parse_request() {\n        let _ = pretty_env_logger::try_init();\n        let mut raw = BytesMut::from(\"GET /echo HTTP/1.1\\r\\nHost: hyper.rs\\r\\n\\r\\n\");\n        let mut method = None;\n        let msg = Server::parse(\n            &mut raw,\n            ParseContext {\n                cached_headers: &mut None,\n                req_method: &mut method,\n                #[cfg(feature = \"ffi\")]\n                preserve_header_case: false,\n            },\n        )\n        .unwrap()\n        .unwrap();\n        assert_eq!(raw.len(), 0);\n        assert_eq!(msg.head.subject.0, crate::Method::GET);\n        assert_eq!(msg.head.subject.1, \"/echo\");\n        assert_eq!(msg.head.version, crate::Version::HTTP_11);\n        assert_eq!(msg.head.headers.len(), 1);\n        assert_eq!(msg.head.headers[\"Host\"], \"hyper.rs\");\n        assert_eq!(method, Some(crate::Method::GET));\n    }\n\n    #[test]\n    fn test_parse_response() {\n        let _ = pretty_env_logger::try_init();\n        let mut raw = BytesMut::from(\"HTTP/1.1 200 OK\\r\\nContent-Length: 0\\r\\n\\r\\n\");\n        let ctx = ParseContext {\n            cached_headers: &mut None,\n            req_method: &mut Some(crate::Method::GET),\n            #[cfg(feature = \"ffi\")]\n            preserve_header_case: false,\n        };\n        let msg = Client::parse(&mut raw, ctx).unwrap().unwrap();\n        assert_eq!(raw.len(), 0);\n        assert_eq!(msg.head.subject, crate::StatusCode::OK);\n        assert_eq!(msg.head.version, crate::Version::HTTP_11);\n        assert_eq!(msg.head.headers.len(), 1);\n        assert_eq!(msg.head.headers[\"Content-Length\"], \"0\");\n    }\n\n    #[test]\n    fn test_parse_request_errors() {\n        let mut raw = BytesMut::from(\"GET htt:p// HTTP/1.1\\r\\nHost: hyper.rs\\r\\n\\r\\n\");\n        let ctx = ParseContext {\n            cached_headers: &mut None,\n            req_method: &mut None,\n            #[cfg(feature = \"ffi\")]\n            preserve_header_case: false,\n        };\n        Server::parse(&mut raw, ctx).unwrap_err();\n    }\n\n    #[test]\n    fn test_decoder_request() {\n        fn parse(s: &str) -> ParsedMessage<RequestLine> {\n            let mut bytes = BytesMut::from(s);\n            Server::parse(\n                &mut bytes,\n                ParseContext {\n                    cached_headers: &mut None,\n                    req_method: &mut None,\n                    #[cfg(feature = \"ffi\")]\n                    preserve_header_case: false,\n                },\n            )\n            .expect(\"parse ok\")\n            .expect(\"parse complete\")\n        }\n\n        fn parse_err(s: &str, comment: &str) -> crate::error::Parse {\n            let mut bytes = BytesMut::from(s);\n            Server::parse(\n                &mut bytes,\n                ParseContext {\n                    cached_headers: &mut None,\n                    req_method: &mut None,\n                    #[cfg(feature = \"ffi\")]\n                    preserve_header_case: false,\n                },\n            )\n            .expect_err(comment)\n        }\n\n        // no length or transfer-encoding means 0-length body\n        assert_eq!(\n            parse(\n                \"\\\n                 GET / HTTP/1.1\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::ZERO\n        );\n\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::ZERO\n        );\n\n        // transfer-encoding: chunked\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 transfer-encoding: chunked\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 transfer-encoding: gzip, chunked\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 transfer-encoding: gzip\\r\\n\\\n                 transfer-encoding: chunked\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        // content-length\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::new(10)\n        );\n\n        // transfer-encoding and content-length = chunked\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 transfer-encoding: chunked\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 transfer-encoding: chunked\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 transfer-encoding: gzip\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 transfer-encoding: chunked\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        // multiple content-lengths of same value are fine\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::new(10)\n        );\n\n        // multiple content-lengths with different values is an error\n        parse_err(\n            \"\\\n             POST / HTTP/1.1\\r\\n\\\n             content-length: 10\\r\\n\\\n             content-length: 11\\r\\n\\\n             \\r\\n\\\n             \",\n            \"multiple content-lengths\",\n        );\n\n        // transfer-encoding that isn't chunked is an error\n        parse_err(\n            \"\\\n             POST / HTTP/1.1\\r\\n\\\n             transfer-encoding: gzip\\r\\n\\\n             \\r\\n\\\n             \",\n            \"transfer-encoding but not chunked\",\n        );\n\n        parse_err(\n            \"\\\n             POST / HTTP/1.1\\r\\n\\\n             transfer-encoding: chunked, gzip\\r\\n\\\n             \\r\\n\\\n             \",\n            \"transfer-encoding doesn't end in chunked\",\n        );\n\n        // http/1.0\n\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.0\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::new(10)\n        );\n\n        // 1.0 doesn't understand chunked, so its an error\n        parse_err(\n            \"\\\n             POST / HTTP/1.0\\r\\n\\\n             transfer-encoding: chunked\\r\\n\\\n             \\r\\n\\\n             \",\n            \"1.0 chunked\",\n        );\n    }\n\n    #[test]\n    fn test_decoder_response() {\n        fn parse(s: &str) -> ParsedMessage<StatusCode> {\n            parse_with_method(s, Method::GET)\n        }\n\n        fn parse_ignores(s: &str) {\n            let mut bytes = BytesMut::from(s);\n            assert!(Client::parse(\n                &mut bytes,\n                ParseContext {\n                    cached_headers: &mut None,\n                    req_method: &mut Some(Method::GET),\n                    #[cfg(feature = \"ffi\")]\n                    preserve_header_case: false,\n                }\n            )\n            .expect(\"parse ok\")\n            .is_none())\n        }\n\n        fn parse_with_method(s: &str, m: Method) -> ParsedMessage<StatusCode> {\n            let mut bytes = BytesMut::from(s);\n            Client::parse(\n                &mut bytes,\n                ParseContext {\n                    cached_headers: &mut None,\n                    req_method: &mut Some(m),\n                    #[cfg(feature = \"ffi\")]\n                    preserve_header_case: false,\n                },\n            )\n            .expect(\"parse ok\")\n            .expect(\"parse complete\")\n        }\n\n        fn parse_err(s: &str) -> crate::error::Parse {\n            let mut bytes = BytesMut::from(s);\n            Client::parse(\n                &mut bytes,\n                ParseContext {\n                    cached_headers: &mut None,\n                    req_method: &mut Some(Method::GET),\n                    #[cfg(feature = \"ffi\")]\n                    preserve_header_case: false,\n                },\n            )\n            .expect_err(\"parse should err\")\n        }\n\n        // no content-length or transfer-encoding means close-delimited\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CLOSE_DELIMITED\n        );\n\n        // 204 and 304 never have a body\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 204 No Content\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::ZERO\n        );\n\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 304 Not Modified\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::ZERO\n        );\n\n        // content-length\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 content-length: 8\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::new(8)\n        );\n\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 content-length: 8\\r\\n\\\n                 content-length: 8\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::new(8)\n        );\n\n        parse_err(\n            \"\\\n             HTTP/1.1 200 OK\\r\\n\\\n             content-length: 8\\r\\n\\\n             content-length: 9\\r\\n\\\n             \\r\\n\\\n             \",\n        );\n\n        // transfer-encoding: chunked\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 transfer-encoding: chunked\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        // transfer-encoding not-chunked is close-delimited\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 transfer-encoding: yolo\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CLOSE_DELIMITED\n        );\n\n        // transfer-encoding and content-length = chunked\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 transfer-encoding: chunked\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        // HEAD can have content-length, but not body\n        assert_eq!(\n            parse_with_method(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 content-length: 8\\r\\n\\\n                 \\r\\n\\\n                 \",\n                Method::HEAD\n            )\n            .decode,\n            DecodedLength::ZERO\n        );\n\n        // CONNECT with 200 never has body\n        {\n            let msg = parse_with_method(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 \\r\\n\\\n                 \",\n                Method::CONNECT,\n            );\n            assert_eq!(msg.decode, DecodedLength::ZERO);\n            assert!(!msg.keep_alive, \"should be upgrade\");\n            assert!(msg.wants_upgrade, \"should be upgrade\");\n        }\n\n        // CONNECT receiving non 200 can have a body\n        assert_eq!(\n            parse_with_method(\n                \"\\\n                 HTTP/1.1 400 Bad Request\\r\\n\\\n                 \\r\\n\\\n                 \",\n                Method::CONNECT\n            )\n            .decode,\n            DecodedLength::CLOSE_DELIMITED\n        );\n\n        // 1xx status codes\n        parse_ignores(\n            \"\\\n             HTTP/1.1 100 Continue\\r\\n\\\n             \\r\\n\\\n             \",\n        );\n\n        parse_ignores(\n            \"\\\n             HTTP/1.1 103 Early Hints\\r\\n\\\n             \\r\\n\\\n             \",\n        );\n\n        // 101 upgrade not supported yet\n        {\n            let msg = parse(\n                \"\\\n                 HTTP/1.1 101 Switching Protocols\\r\\n\\\n                 \\r\\n\\\n                 \",\n            );\n            assert_eq!(msg.decode, DecodedLength::ZERO);\n            assert!(!msg.keep_alive, \"should be last\");\n            assert!(msg.wants_upgrade, \"should be upgrade\");\n        }\n\n        // http/1.0\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.0 200 OK\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CLOSE_DELIMITED\n        );\n\n        // 1.0 doesn't understand chunked\n        parse_err(\n            \"\\\n             HTTP/1.0 200 OK\\r\\n\\\n             transfer-encoding: chunked\\r\\n\\\n             \\r\\n\\\n             \",\n        );\n\n        // keep-alive\n        assert!(\n            parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 content-length: 0\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .keep_alive,\n            \"HTTP/1.1 keep-alive is default\"\n        );\n\n        assert!(\n            !parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 content-length: 0\\r\\n\\\n                 connection: foo, close, bar\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .keep_alive,\n            \"connection close is always close\"\n        );\n\n        assert!(\n            !parse(\n                \"\\\n                 HTTP/1.0 200 OK\\r\\n\\\n                 content-length: 0\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .keep_alive,\n            \"HTTP/1.0 close is default\"\n        );\n\n        assert!(\n            parse(\n                \"\\\n                 HTTP/1.0 200 OK\\r\\n\\\n                 content-length: 0\\r\\n\\\n                 connection: foo, keep-alive, bar\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .keep_alive,\n            \"connection keep-alive is always keep-alive\"\n        );\n    }\n\n    #[test]\n    fn test_client_request_encode_title_case() {\n        use crate::proto::BodyLength;\n        use http::header::HeaderValue;\n\n        let mut head = MessageHead::default();\n        head.headers\n            .insert(\"content-length\", HeaderValue::from_static(\"10\"));\n        head.headers\n            .insert(\"content-type\", HeaderValue::from_static(\"application/json\"));\n        head.headers.insert(\"*-*\", HeaderValue::from_static(\"o_o\"));\n\n        let mut vec = Vec::new();\n        Client::encode(\n            Encode {\n                head: &mut head,\n                body: Some(BodyLength::Known(10)),\n                keep_alive: true,\n                req_method: &mut None,\n                title_case_headers: true,\n            },\n            &mut vec,\n        )\n        .unwrap();\n\n        assert_eq!(vec, b\"GET / HTTP/1.1\\r\\nContent-Length: 10\\r\\nContent-Type: application/json\\r\\n*-*: o_o\\r\\n\\r\\n\".to_vec());\n    }\n\n    #[test]\n    fn test_server_encode_connect_method() {\n        let mut head = MessageHead::default();\n\n        let mut vec = Vec::new();\n        let encoder = Server::encode(\n            Encode {\n                head: &mut head,\n                body: None,\n                keep_alive: true,\n                req_method: &mut Some(Method::CONNECT),\n                title_case_headers: false,\n            },\n            &mut vec,\n        )\n        .unwrap();\n\n        assert!(encoder.is_last());\n    }\n\n    #[test]\n    fn parse_header_htabs() {\n        let mut bytes = BytesMut::from(\"HTTP/1.1 200 OK\\r\\nserver: hello\\tworld\\r\\n\\r\\n\");\n        let parsed = Client::parse(\n            &mut bytes,\n            ParseContext {\n                cached_headers: &mut None,\n                req_method: &mut Some(Method::GET),\n                #[cfg(feature = \"ffi\")]\n                preserve_header_case: false,\n            },\n        )\n        .expect(\"parse ok\")\n        .expect(\"parse complete\");\n\n        assert_eq!(parsed.head.headers[\"server\"], \"hello\\tworld\");\n    }\n\n    #[cfg(feature = \"ffi\")]\n    #[test]\n    fn test_write_headers_orig_case_empty_value() {\n        let mut headers = HeaderMap::new();\n        let name = http::header::HeaderName::from_static(\"x-empty\");\n        headers.insert(&name, \"\".parse().expect(\"parse empty\"));\n        let mut orig_cases = crate::ffi::HeaderCaseMap::default();\n        orig_cases.insert(name, Bytes::from_static(b\"X-EmptY\"));\n\n        let mut dst = Vec::new();\n        super::write_headers_original_case(&headers, &orig_cases, &mut dst);\n\n        assert_eq!(\n            dst, b\"X-EmptY:\\r\\n\",\n            \"there should be no space between the colon and CRLF\"\n        );\n    }\n\n    #[cfg(feature = \"ffi\")]\n    #[test]\n    fn test_write_headers_orig_case_multiple_entries() {\n        let mut headers = HeaderMap::new();\n        let name = http::header::HeaderName::from_static(\"x-empty\");\n        headers.insert(&name, \"a\".parse().unwrap());\n        headers.append(&name, \"b\".parse().unwrap());\n\n        let mut orig_cases = crate::ffi::HeaderCaseMap::default();\n        orig_cases.insert(name.clone(), Bytes::from_static(b\"X-Empty\"));\n        orig_cases.append(name, Bytes::from_static(b\"X-EMPTY\"));\n\n        let mut dst = Vec::new();\n        super::write_headers_original_case(&headers, &orig_cases, &mut dst);\n\n        assert_eq!(dst, b\"X-Empty: a\\r\\nX-EMPTY: b\\r\\n\");\n    }\n\n    #[cfg(feature = \"nightly\")]\n    use test::Bencher;\n\n    #[cfg(feature = \"nightly\")]\n    #[bench]\n    fn bench_parse_incoming(b: &mut Bencher) {\n        let mut raw = BytesMut::from(\n            &b\"GET /super_long_uri/and_whatever?what_should_we_talk_about/\\\n            I_wonder/Hard_to_write_in_an_uri_after_all/you_have_to_make\\\n            _up_the_punctuation_yourself/how_fun_is_that?test=foo&test1=\\\n            foo1&test2=foo2&test3=foo3&test4=foo4 HTTP/1.1\\r\\nHost: \\\n            hyper.rs\\r\\nAccept: a lot of things\\r\\nAccept-Charset: \\\n            utf8\\r\\nAccept-Encoding: *\\r\\nAccess-Control-Allow-\\\n            Credentials: None\\r\\nAccess-Control-Allow-Origin: None\\r\\n\\\n            Access-Control-Allow-Methods: None\\r\\nAccess-Control-Allow-\\\n            Headers: None\\r\\nContent-Encoding: utf8\\r\\nContent-Security-\\\n            Policy: None\\r\\nContent-Type: text/html\\r\\nOrigin: hyper\\\n            \\r\\nSec-Websocket-Extensions: It looks super important!\\r\\n\\\n            Sec-Websocket-Origin: hyper\\r\\nSec-Websocket-Version: 4.3\\r\\\n            \\nStrict-Transport-Security: None\\r\\nUser-Agent: hyper\\r\\n\\\n            X-Content-Duration: None\\r\\nX-Content-Security-Policy: None\\\n            \\r\\nX-DNSPrefetch-Control: None\\r\\nX-Frame-Options: \\\n            Something important obviously\\r\\nX-Requested-With: Nothing\\\n            \\r\\n\\r\\n\"[..],\n        );\n        let len = raw.len();\n        let mut headers = Some(HeaderMap::new());\n\n        b.bytes = len as u64;\n        b.iter(|| {\n            let mut msg = Server::parse(\n                &mut raw,\n                ParseContext {\n                    cached_headers: &mut headers,\n                    req_method: &mut None,\n                    #[cfg(feature = \"ffi\")]\n                    preserve_header_case: false,\n                },\n            )\n            .unwrap()\n            .unwrap();\n            ::test::black_box(&msg);\n            msg.head.headers.clear();\n            headers = Some(msg.head.headers);\n            restart(&mut raw, len);\n        });\n\n        fn restart(b: &mut BytesMut, len: usize) {\n            b.reserve(1);\n            unsafe {\n                b.set_len(len);\n            }\n        }\n    }\n\n    #[cfg(feature = \"nightly\")]\n    #[bench]\n    fn bench_parse_short(b: &mut Bencher) {\n        let s = &b\"GET / HTTP/1.1\\r\\nHost: localhost:8080\\r\\n\\r\\n\"[..];\n        let mut raw = BytesMut::from(s);\n        let len = raw.len();\n        let mut headers = Some(HeaderMap::new());\n\n        b.bytes = len as u64;\n        b.iter(|| {\n            let mut msg = Server::parse(\n                &mut raw,\n                ParseContext {\n                    cached_headers: &mut headers,\n                    req_method: &mut None,\n                    #[cfg(feature = \"ffi\")]\n                    preserve_header_case: false,\n                },\n            )\n            .unwrap()\n            .unwrap();\n            ::test::black_box(&msg);\n            msg.head.headers.clear();\n            headers = Some(msg.head.headers);\n            restart(&mut raw, len);\n        });\n\n        fn restart(b: &mut BytesMut, len: usize) {\n            b.reserve(1);\n            unsafe {\n                b.set_len(len);\n            }\n        }\n    }\n\n    #[cfg(feature = \"nightly\")]\n    #[bench]\n    fn bench_server_encode_headers_preset(b: &mut Bencher) {\n        use crate::proto::BodyLength;\n        use http::header::HeaderValue;\n\n        let len = 108;\n        b.bytes = len as u64;\n\n        let mut head = MessageHead::default();\n        let mut headers = HeaderMap::new();\n        headers.insert(\"content-length\", HeaderValue::from_static(\"10\"));\n        headers.insert(\"content-type\", HeaderValue::from_static(\"application/json\"));\n\n        b.iter(|| {\n            let mut vec = Vec::new();\n            head.headers = headers.clone();\n            Server::encode(\n                Encode {\n                    head: &mut head,\n                    body: Some(BodyLength::Known(10)),\n                    keep_alive: true,\n                    req_method: &mut Some(Method::GET),\n                    title_case_headers: false,\n                },\n                &mut vec,\n            )\n            .unwrap();\n            assert_eq!(vec.len(), len);\n            ::test::black_box(vec);\n        })\n    }\n\n    #[cfg(feature = \"nightly\")]\n    #[bench]\n    fn bench_server_encode_no_headers(b: &mut Bencher) {\n        use crate::proto::BodyLength;\n\n        let len = 76;\n        b.bytes = len as u64;\n\n        let mut head = MessageHead::default();\n        let mut vec = Vec::with_capacity(128);\n\n        b.iter(|| {\n            Server::encode(\n                Encode {\n                    head: &mut head,\n                    body: Some(BodyLength::Known(10)),\n                    keep_alive: true,\n                    req_method: &mut Some(Method::GET),\n                    title_case_headers: false,\n                },\n                &mut vec,\n            )\n            .unwrap();\n            assert_eq!(vec.len(), len);\n            ::test::black_box(&vec);\n\n            vec.clear();\n        })\n    }\n}\n"
  },
  {
    "project": "rusqlite",
    "target": 1,
    "commit_id": "c9ef5bd63cad5c0c123344c072b490a1a9bcbe1f",
    "func": "//! [Unlock Notification](http://sqlite.org/unlock_notify.html)\n\nuse std::os::raw::c_int;\n#[cfg(feature = \"unlock_notify\")]\nuse std::os::raw::c_void;\n#[cfg(feature = \"unlock_notify\")]\nuse std::panic::catch_unwind;\n#[cfg(feature = \"unlock_notify\")]\nuse std::sync::{Condvar, Mutex};\n\nuse crate::ffi;\n\n#[cfg(feature = \"unlock_notify\")]\nstruct UnlockNotification {\n    cond: Condvar,      // Condition variable to wait on\n    mutex: Mutex<bool>, // Mutex to protect structure\n}\n\n#[cfg(feature = \"unlock_notify\")]\n#[allow(clippy::mutex_atomic)]\nimpl UnlockNotification {\n    fn new() -> UnlockNotification {\n        UnlockNotification {\n            cond: Condvar::new(),\n            mutex: Mutex::new(false),\n        }\n    }\n\n    fn fired(&mut self) {\n        *self.mutex.lock().unwrap() = true;\n        self.cond.notify_one();\n    }\n\n    fn wait(&mut self) {\n        let mut fired = self.mutex.lock().unwrap();\n        while !*fired {\n            fired = self.cond.wait(fired).unwrap();\n        }\n    }\n}\n\n/// This function is an unlock-notify callback\n#[cfg(feature = \"unlock_notify\")]\nunsafe extern \"C\" fn unlock_notify_cb(ap_arg: *mut *mut c_void, n_arg: c_int) {\n    use std::slice::from_raw_parts;\n    let args = from_raw_parts(ap_arg, n_arg as usize);\n    for arg in args {\n        let _ = catch_unwind(|| {\n            let un: &mut UnlockNotification = &mut *(*arg as *mut UnlockNotification);\n            un.fired()\n        });\n    }\n}\n\n#[cfg(feature = \"unlock_notify\")]\npub unsafe fn is_locked(db: *mut ffi::sqlite3, rc: c_int) -> bool {\n    rc == ffi::SQLITE_LOCKED_SHAREDCACHE\n        || (rc & 0xFF) == ffi::SQLITE_LOCKED\n            && ffi::sqlite3_extended_errcode(db) == ffi::SQLITE_LOCKED_SHAREDCACHE\n}\n\n/// This function assumes that an SQLite API call (either `sqlite3_prepare_v2()`\n/// or `sqlite3_step()`) has just returned `SQLITE_LOCKED`. The argument is the\n/// associated database connection.\n///\n/// This function calls `sqlite3_unlock_notify()` to register for an\n/// unlock-notify callback, then blocks until that callback is delivered\n/// and returns `SQLITE_OK`. The caller should then retry the failed operation.\n///\n/// Or, if `sqlite3_unlock_notify()` indicates that to block would deadlock\n/// the system, then this function returns `SQLITE_LOCKED` immediately. In\n/// this case the caller should not retry the operation and should roll\n/// back the current transaction (if any).\n#[cfg(feature = \"unlock_notify\")]\npub unsafe fn wait_for_unlock_notify(db: *mut ffi::sqlite3) -> c_int {\n    let mut un = UnlockNotification::new();\n    /* Register for an unlock-notify callback. */\n    let rc = ffi::sqlite3_unlock_notify(\n        db,\n        Some(unlock_notify_cb),\n        &mut un as *mut UnlockNotification as *mut c_void,\n    );\n    debug_assert!(\n        rc == ffi::SQLITE_LOCKED || rc == ffi::SQLITE_LOCKED_SHAREDCACHE || rc == ffi::SQLITE_OK\n    );\n    if rc == ffi::SQLITE_OK {\n        un.wait();\n    }\n    rc\n}\n\n#[cfg(not(feature = \"unlock_notify\"))]\npub unsafe fn is_locked(_db: *mut ffi::sqlite3, _rc: c_int) -> bool {\n    unreachable!()\n}\n\n#[cfg(not(feature = \"unlock_notify\"))]\npub unsafe fn wait_for_unlock_notify(_db: *mut ffi::sqlite3) -> c_int {\n    unreachable!()\n}\n\n#[cfg(feature = \"unlock_notify\")]\n#[cfg(test)]\nmod test {\n    use crate::{Connection, OpenFlags, Result, Transaction, TransactionBehavior, NO_PARAMS};\n    use std::sync::mpsc::sync_channel;\n    use std::thread;\n    use std::time;\n\n    #[test]\n    fn test_unlock_notify() {\n        let url = \"file::memory:?cache=shared\";\n        let flags = OpenFlags::SQLITE_OPEN_READ_WRITE | OpenFlags::SQLITE_OPEN_URI;\n        let db1 = Connection::open_with_flags(url, flags).unwrap();\n        db1.execute_batch(\"CREATE TABLE foo (x)\").unwrap();\n        let (rx, tx) = sync_channel(0);\n        let child = thread::spawn(move || {\n            let mut db2 = Connection::open_with_flags(url, flags).unwrap();\n            let tx2 = Transaction::new(&mut db2, TransactionBehavior::Immediate).unwrap();\n            tx2.execute_batch(\"INSERT INTO foo VALUES (42)\").unwrap();\n            rx.send(1).unwrap();\n            let ten_millis = time::Duration::from_millis(10);\n            thread::sleep(ten_millis);\n            tx2.commit().unwrap();\n        });\n        assert_eq!(tx.recv().unwrap(), 1);\n        let the_answer: Result<i64> = db1.query_row(\"SELECT x FROM foo\", NO_PARAMS, |r| r.get(0));\n        assert_eq!(42i64, the_answer.unwrap());\n        child.join().unwrap();\n    }\n}\n"
  },
  {
    "project": "swhkd",
    "target": 1,
    "commit_id": "4a4d76df3b3df1bd0bc132694e2985770a95e464",
    "func": "use clap::{arg, Command};\nuse evdev::{AttributeSet, Device, InputEventKind, Key};\nuse nix::unistd::{Group, Uid};\nuse signal_hook_tokio::Signals;\nuse std::{\n    collections::{HashMap, HashSet},\n    env, fs,\n    io::prelude::*,\n    os::unix::net::UnixStream,\n    path::Path,\n    process::{exit, id},\n};\nuse sysinfo::{ProcessExt, System, SystemExt};\nuse tokio::select;\nuse tokio::time::Duration;\nuse tokio::time::{sleep, Instant};\nuse tokio_stream::{StreamExt, StreamMap};\n\nuse signal_hook::consts::signal::*;\n\nmod config;\nuse crate::config::Value;\nmod uinput;\n\n#[cfg(test)]\nmod tests;\n\nstruct KeyboardState {\n    state_modifiers: HashSet<config::Modifier>,\n    state_keysyms: AttributeSet<evdev::Key>,\n}\n\nimpl KeyboardState {\n    fn new() -> KeyboardState {\n        KeyboardState { state_modifiers: HashSet::new(), state_keysyms: AttributeSet::new() }\n    }\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Box<dyn std::error::Error>> {\n    let args = set_command_line_args().get_matches();\n    env::set_var(\"RUST_LOG\", \"swhkd=warn\");\n\n    if args.is_present(\"debug\") {\n        env::set_var(\"RUST_LOG\", \"swhkd=trace\");\n    }\n\n    env_logger::init();\n    log::trace!(\"Logger initialized.\");\n\n    let pidfile: String = String::from(\"/tmp/swhkd.pid\");\n    if Path::new(&pidfile).exists() {\n        log::trace!(\"Reading {} file and checking for running instances.\", pidfile);\n        let swhkd_pid = match fs::read_to_string(&pidfile) {\n            Ok(swhkd_pid) => swhkd_pid,\n            Err(e) => {\n                log::error!(\"Unable to read {} to check all running instances\", e);\n                exit(1);\n            }\n        };\n        log::debug!(\"Previous PID: {}\", swhkd_pid);\n\n        let mut sys = System::new_all();\n        sys.refresh_all();\n        for (pid, process) in sys.processes() {\n            if pid.to_string() == swhkd_pid && process.exe() == env::current_exe().unwrap() {\n                log::error!(\"Swhkd is already running!\");\n                log::error!(\"pid of existing swhkd process: {}\", pid.to_string());\n                log::error!(\"To close the existing swhkd process, run `sudo killall swhkd`\");\n                exit(1);\n            }\n        }\n    }\n\n    match fs::write(&pidfile, id().to_string()) {\n        Ok(_) => {}\n        Err(e) => {\n            log::error!(\"Unable to write to {}: {}\", pidfile, e);\n            exit(1);\n        }\n    }\n\n    if check_user_permissions().is_err() {\n        exit(1);\n    }\n\n    let load_config = || {\n        let config_file_path: std::path::PathBuf = if args.is_present(\"config\") {\n            Path::new(args.value_of(\"config\").unwrap()).to_path_buf()\n        } else {\n            fetch_xdg_config_path()\n        };\n\n        log::debug!(\"Using config file path: {:#?}\", config_file_path);\n\n        if !config_file_path.exists() {\n            log::error!(\"{:#?} doesn't exist\", config_file_path);\n            exit(1);\n        }\n\n        let hotkeys = match config::load(&config_file_path) {\n            Err(e) => {\n                log::error!(\"Config Error: {}\", e);\n                exit(1);\n            }\n            Ok(out) => out,\n        };\n\n        for hotkey in &hotkeys {\n            log::debug!(\"hotkey: {:#?}\", hotkey);\n        }\n\n        hotkeys\n    };\n\n    let mut hotkeys = load_config();\n\n    log::trace!(\"Attempting to find all keyboard file descriptors.\");\n    let keyboard_devices: Vec<Device> =\n        evdev::enumerate().filter(check_device_is_keyboard).collect();\n\n    let mut uinput_device = match uinput::create_uinput_device() {\n        Ok(dev) => dev,\n        Err(e) => {\n            log::error!(\"Err: {:#?}\", e);\n            exit(1);\n        }\n    };\n\n    if keyboard_devices.is_empty() {\n        log::error!(\"No valid keyboard device was detected!\");\n        exit(1);\n    }\n    log::debug!(\"{} Keyboard device(s) detected.\", keyboard_devices.len());\n\n    let modifiers_map: HashMap<Key, config::Modifier> = HashMap::from([\n        (Key::KEY_LEFTMETA, config::Modifier::Super),\n        (Key::KEY_RIGHTMETA, config::Modifier::Super),\n        (Key::KEY_LEFTMETA, config::Modifier::Super),\n        (Key::KEY_RIGHTMETA, config::Modifier::Super),\n        (Key::KEY_LEFTALT, config::Modifier::Alt),\n        (Key::KEY_RIGHTALT, config::Modifier::Alt),\n        (Key::KEY_LEFTCTRL, config::Modifier::Control),\n        (Key::KEY_RIGHTCTRL, config::Modifier::Control),\n        (Key::KEY_LEFTSHIFT, config::Modifier::Shift),\n        (Key::KEY_RIGHTSHIFT, config::Modifier::Shift),\n    ]);\n\n    let repeat_cooldown_duration: u64 = if args.is_present(\"cooldown\") {\n        args.value_of(\"cooldown\").unwrap().parse::<u64>().unwrap()\n    } else {\n        250\n    };\n\n    let mut signals = Signals::new(&[\n        SIGUSR1, SIGUSR2, SIGHUP, SIGABRT, SIGBUS, SIGCHLD, SIGCONT, SIGINT, SIGPIPE, SIGQUIT,\n        SIGSYS, SIGTERM, SIGTRAP, SIGTSTP, SIGVTALRM, SIGXCPU, SIGXFSZ,\n    ])?;\n\n    let mut execution_is_paused = false;\n    let mut last_hotkey: Option<config::Hotkey> = None;\n    let mut pending_release: bool = false;\n    let mut keyboard_states: Vec<KeyboardState> = Vec::new();\n    let mut keyboard_stream_map = StreamMap::new();\n\n    for (i, mut device) in keyboard_devices.into_iter().enumerate() {\n        let _ = device.grab();\n        keyboard_stream_map.insert(i, device.into_event_stream()?);\n        keyboard_states.push(KeyboardState::new());\n    }\n\n    // The initial sleep duration is never read because last_hotkey is initialized to None\n    let hotkey_repeat_timer = sleep(Duration::from_millis(0));\n    tokio::pin!(hotkey_repeat_timer);\n\n    loop {\n        select! {\n            _ = &mut hotkey_repeat_timer, if &last_hotkey.is_some() => {\n                let hotkey = last_hotkey.clone().unwrap();\n                if hotkey.keybinding.on_release {\n                    continue;\n                }\n                send_command(hotkey.clone());\n                hotkey_repeat_timer.as_mut().reset(Instant::now() + Duration::from_millis(repeat_cooldown_duration));\n            }\n\n            Some(signal) = signals.next() => {\n                match signal {\n                    SIGUSR1 => {\n                        execution_is_paused = true;\n                        for mut device in evdev::enumerate().filter(check_device_is_keyboard) {\n                            let _ = device.ungrab();\n                        }\n                    }\n\n                    SIGUSR2 => {\n                        execution_is_paused = false;\n                        for mut device in evdev::enumerate().filter(check_device_is_keyboard) {\n                            let _ = device.grab();\n                        }\n                    }\n\n                    SIGHUP => {\n                        hotkeys = load_config();\n                    }\n\n                    SIGINT => {\n                        for mut device in evdev::enumerate().filter(check_device_is_keyboard) {\n                            let _ = device.ungrab();\n                        }\n                        log::warn!(\"Received SIGINT signal, exiting...\");\n                        exit(1);\n                    }\n\n                    _ => {\n                        for mut device in evdev::enumerate().filter(check_device_is_keyboard) {\n                            let _ = device.ungrab();\n                        }\n\n                        log::warn!(\"Received signal: {:#?}\", signal);\n                        log::warn!(\"Exiting...\");\n                        exit(1);\n                    }\n                }\n            }\n\n            Some((i, Ok(event))) = keyboard_stream_map.next() => {\n                let keyboard_state = &mut keyboard_states[i];\n\n                let key = match event.kind() {\n                    InputEventKind::Key(keycode) => keycode,\n                    _ => continue\n                };\n\n                match event.value() {\n                    // Key press\n                    1 => {\n                        if let Some(modifier) = modifiers_map.get(&key) {\n                            keyboard_state.state_modifiers.insert(*modifier);\n                        } else {\n                            keyboard_state.state_keysyms.insert(key);\n                        }\n                    }\n\n                    // Key release\n                    0 => {\n                        if last_hotkey.is_some() && pending_release {\n                            pending_release = false;\n                            send_command(last_hotkey.clone().unwrap());\n                            last_hotkey = None;\n                        }\n                        if let Some(modifier) = modifiers_map.get(&key) {\n                            if let Some(hotkey) = &last_hotkey {\n                                if hotkey.modifiers().contains(modifier) {\n                                    last_hotkey = None;\n                                }\n                            }\n                            keyboard_state.state_modifiers.remove(modifier);\n                        } else if keyboard_state.state_keysyms.contains(key) {\n                            if let Some(hotkey) = &last_hotkey {\n                                if key == hotkey.keysym() {\n                                    last_hotkey = None;\n                                }\n                            }\n                            keyboard_state.state_keysyms.remove(key);\n                        }\n                    }\n\n                    _ => {}\n                }\n\n                let possible_hotkeys: Vec<&config::Hotkey> = hotkeys.iter()\n                    .filter(|hotkey| hotkey.modifiers().len() == keyboard_state.state_modifiers.len())\n                    .collect();\n\n                let event_in_hotkeys = hotkeys.iter().any(|hotkey| {\n                    hotkey.keysym().code() == event.code() &&\n                    keyboard_state.state_modifiers\n                        .iter()\n                        .all(|x| hotkey.modifiers().contains(x)) &&\n                    keyboard_state.state_modifiers.len() == hotkey.modifiers().len()\n                    && !hotkey.is_send()\n                        });\n\n                // Don't emit event to virtual device if it's from a valid hotkey\n                if !event_in_hotkeys {\n                    uinput_device.emit(&[event]).unwrap();\n                }\n\n                if execution_is_paused || possible_hotkeys.is_empty() || last_hotkey.is_some() {\n                    continue;\n                }\n\n                log::debug!(\"state_modifiers: {:#?}\", keyboard_state.state_modifiers);\n                log::debug!(\"state_keysyms: {:#?}\", keyboard_state.state_keysyms);\n                log::debug!(\"hotkey: {:#?}\", possible_hotkeys);\n\n                for hotkey in possible_hotkeys {\n                    // this should check if state_modifiers and hotkey.modifiers have the same elements\n                    if keyboard_state.state_modifiers.iter().all(|x| hotkey.modifiers().contains(x))\n                        && keyboard_state.state_modifiers.len() == hotkey.modifiers().len()\n                        && keyboard_state.state_keysyms.contains(hotkey.keysym())\n                    {\n                        last_hotkey = Some(hotkey.clone());\n                        if pending_release { break; }\n                        if hotkey.is_on_release() {\n                            pending_release = true;\n                            break;\n                        }\n                        send_command(hotkey.clone());\n                        hotkey_repeat_timer.as_mut().reset(Instant::now() + Duration::from_millis(repeat_cooldown_duration));\n                        break;\n                    }\n                }\n            }\n        }\n    }\n}\n\nfn sock_send(command: &str) -> std::io::Result<()> {\n    let mut stream = UnixStream::connect(\"/tmp/swhkd.sock\")?;\n    stream.write_all(command.as_bytes())?;\n    Ok(())\n}\n\nfn send_command(hotkey: config::Hotkey) {\n    log::info!(\"Hotkey pressed: {:#?}\", hotkey);\n    if let Err(e) = sock_send(&hotkey.command) {\n        log::error!(\"Failed to send command to swhks through IPC.\");\n        log::error!(\"Please make sure that swhks is running.\");\n        log::error!(\"Err: {:#?}\", e)\n    }\n}\n\npub fn check_user_permissions() -> Result<(), ()> {\n    if !Uid::current().is_root() {\n        let groups = nix::unistd::getgroups();\n        for (_, groups) in groups.iter().enumerate() {\n            for group in groups {\n                let group = Group::from_gid(*group);\n                if group.unwrap().unwrap().name == \"input\" {\n                    log::error!(\"Note: INVOKING USER IS IN INPUT GROUP!!!!\");\n                    log::error!(\"THIS IS A HUGE SECURITY RISK!!!!\");\n                }\n            }\n        }\n        log::error!(\"Consider using `pkexec swhkd ...`\");\n        Err(())\n    } else {\n        log::warn!(\"Running swhkd as root!\");\n        Ok(())\n    }\n}\n\npub fn check_device_is_keyboard(device: &Device) -> bool {\n    if device.supported_keys().map_or(false, |keys| keys.contains(Key::KEY_ENTER)) {\n        if device.name() == Some(\"swhkd virtual output\") {\n            return false;\n        }\n        log::debug!(\"Keyboard: {}\", device.name().unwrap(),);\n        true\n    } else {\n        log::trace!(\"Other: {}\", device.name().unwrap(),);\n        false\n    }\n}\n\npub fn set_command_line_args() -> Command<'static> {\n    let app = Command::new(\"swhkd\")\n        .version(env!(\"CARGO_PKG_VERSION\"))\n        .author(env!(\"CARGO_PKG_AUTHORS\"))\n        .about(\"Simple Wayland HotKey Daemon\")\n        .arg(\n            arg!(-c --config <CONFIG_FILE_PATH>)\n                .required(false)\n                .takes_value(true)\n                .help(\"Set a custom config file path.\"),\n        )\n        .arg(\n            arg!(-C --cooldown <COOLDOWN_IN_MS>)\n                .required(false)\n                .takes_value(true)\n                .help(\"Set a custom repeat cooldown duration. Default is 250ms.\"),\n        )\n        .arg(arg!(-d - -debug).required(false).help(\"Enable debug mode.\"));\n    app\n}\n\npub fn fetch_xdg_config_path() -> std::path::PathBuf {\n    let config_file_path: std::path::PathBuf = match env::var(\"XDG_CONFIG_HOME\") {\n        Ok(val) => {\n            log::debug!(\"XDG_CONFIG_HOME exists: {:#?}\", val);\n            Path::new(&val).join(\"swhkd/swhkdrc\")\n        }\n        Err(_) => {\n            log::error!(\"XDG_CONFIG_HOME has not been set.\");\n            Path::new(\"/etc/swhkd/swhkdrc\").to_path_buf()\n        }\n    };\n    config_file_path\n}\n"
  },
  {
    "project": "coreos-installer",
    "target": 1,
    "commit_id": "1239f0cb60efb398c0cd545a81877c26f9f83897",
    "func": "// Copyright 2019 CoreOS, Inc.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\nuse anyhow::{bail, Context, Result};\nuse lazy_static::lazy_static;\nuse nix::mount;\nuse regex::Regex;\nuse std::fs::{copy as fscopy, create_dir_all, read_dir, File, OpenOptions};\nuse std::io::{copy, Read, Seek, SeekFrom, Write};\nuse std::os::unix::fs::FileTypeExt;\nuse std::path::{Path, PathBuf};\n\nuse crate::blockdev::*;\nuse crate::cmdline::*;\nuse crate::download::*;\nuse crate::io::*;\n#[cfg(target_arch = \"s390x\")]\nuse crate::s390x;\nuse crate::source::*;\n\npub fn install(config: &InstallConfig) -> Result<()> {\n    // set up image source\n    // we only support installing from a single artifact\n    let mut sources = config.location.sources()?;\n    let mut source = sources.pop().context(\"no artifacts found\")?;\n    if !sources.is_empty() {\n        bail!(\"found multiple artifacts\");\n    }\n    if source.signature.is_none() && config.location.require_signature() {\n        if config.insecure {\n            eprintln!(\"Signature not found; skipping verification as requested\");\n        } else {\n            bail!(\"--insecure not specified and signature not found\");\n        }\n    }\n\n    #[cfg(target_arch = \"s390x\")]\n    {\n        if is_dasd(&config.device, None)? {\n            if !config.save_partitions.is_empty() {\n                // The user requested partition saving, but SavedPartitions\n                // doesn't understand DASD VTOCs and won't find any partitions\n                // to save.\n                bail!(\"saving DASD partitions is not supported\");\n            }\n            s390x::prepare_dasd(&config.device)?;\n        }\n    }\n\n    // open output; ensure it's a block device and we have exclusive access\n    let mut dest = OpenOptions::new()\n        .read(true)\n        .write(true)\n        .open(&config.device)\n        .with_context(|| format!(\"opening {}\", &config.device))?;\n    if !dest\n        .metadata()\n        .with_context(|| format!(\"getting metadata for {}\", &config.device))?\n        .file_type()\n        .is_block_device()\n    {\n        bail!(\"{} is not a block device\", &config.device);\n    }\n    ensure_exclusive_access(&config.device)\n        .with_context(|| format!(\"checking for exclusive access to {}\", &config.device))?;\n\n    // save partitions that we plan to keep\n    let saved = SavedPartitions::new_from_disk(&mut dest, &config.save_partitions)\n        .with_context(|| format!(\"saving partitions from {}\", config.device))?;\n\n    // get reference to partition table\n    // For kpartx partitioning, this will conditionally call kpartx -d\n    // when dropped\n    let mut table = Disk::new(&config.device)?\n        .get_partition_table()\n        .with_context(|| format!(\"getting partition table for {}\", &config.device))?;\n\n    // copy and postprocess disk image\n    // On failure, clear and reread the partition table to prevent the disk\n    // from accidentally being used.\n    dest.seek(SeekFrom::Start(0))\n        .with_context(|| format!(\"seeking {}\", config.device))?;\n    if let Err(err) = write_disk(&config, &mut source, &mut dest, &mut *table, &saved) {\n        // log the error so the details aren't dropped if we encounter\n        // another error during cleanup\n        eprintln!(\"\\nError: {:?}\\n\", err);\n\n        // clean up\n        if config.preserve_on_error {\n            eprintln!(\"Preserving partition table as requested\");\n            if saved.is_saved() {\n                // The user asked to preserve the damaged partition table\n                // for debugging.  We also have saved partitions, and those\n                // may or may not be in the damaged table depending where we\n                // failed.  Preserve the saved partitions by writing them to\n                // a file in /tmp and telling the user about it.  Hey, it's\n                // a debug flag.\n                stash_saved_partitions(&mut dest, &saved)?;\n            }\n        } else {\n            reset_partition_table(config, &mut dest, &mut *table, &saved)?;\n        }\n\n        // return a generic error so our exit status is right\n        bail!(\"install failed\");\n    }\n\n    eprintln!(\"Install complete.\");\n    Ok(())\n}\n\nfn ensure_exclusive_access(device: &str) -> Result<()> {\n    let mut parts = Disk::new(device)?.get_busy_partitions()?;\n    if parts.is_empty() {\n        return Ok(());\n    }\n    parts.sort_unstable_by_key(|p| p.path.to_string());\n    eprintln!(\"Partitions in use on {}:\", device);\n    for part in parts {\n        if let Some(mountpoint) = part.mountpoint.as_ref() {\n            eprintln!(\"    {} mounted on {}\", part.path, mountpoint);\n        }\n        if part.swap {\n            eprintln!(\"    {} is swap device\", part.path);\n        }\n        for holder in part.get_holders()? {\n            eprintln!(\"    {} in use by {}\", part.path, holder);\n        }\n    }\n    bail!(\"found busy partitions\");\n}\n\n/// Copy the image source to the target disk and do all post-processing.\n/// If this function fails, the caller should wipe the partition table\n/// to ensure the user doesn't boot from a partially-written disk.\nfn write_disk(\n    config: &InstallConfig,\n    source: &mut ImageSource,\n    dest: &mut File,\n    table: &mut dyn PartTable,\n    saved: &SavedPartitions,\n) -> Result<()> {\n    // Get sector size of destination, for comparing with image\n    let sector_size = get_sector_size(dest)?;\n\n    // copy the image\n    #[allow(clippy::match_bool, clippy::match_single_binding)]\n    let image_copy = match is_dasd(&config.device, Some(dest))? {\n        #[cfg(target_arch = \"s390x\")]\n        true => s390x::image_copy_s390x,\n        _ => image_copy_default,\n    };\n    write_image(\n        source,\n        dest,\n        Path::new(&config.device),\n        image_copy,\n        true,\n        Some(&saved),\n        Some(sector_size),\n    )?;\n    table.reread()?;\n\n    // postprocess\n    if config.ignition.is_some()\n        || config.firstboot_kargs.is_some()\n        || !config.append_kargs.is_empty()\n        || !config.delete_kargs.is_empty()\n        || config.platform.is_some()\n        || config.network_config.is_some()\n        || cfg!(target_arch = \"s390x\")\n    {\n        let mount = Disk::new(&config.device)?.mount_partition_by_label(\n            \"boot\",\n            false,\n            mount::MsFlags::empty(),\n        )?;\n        if let Some(ignition) = config.ignition.as_ref() {\n            write_ignition(mount.mountpoint(), &config.ignition_hash, ignition)\n                .context(\"writing Ignition configuration\")?;\n        }\n        if let Some(firstboot_kargs) = config.firstboot_kargs.as_ref() {\n            write_firstboot_kargs(mount.mountpoint(), firstboot_kargs)\n                .context(\"writing firstboot kargs\")?;\n        }\n        if !config.append_kargs.is_empty() || !config.delete_kargs.is_empty() {\n            eprintln!(\"Modifying kernel arguments\");\n\n            visit_bls_entry_options(mount.mountpoint(), |orig_options: &str| {\n                bls_entry_options_delete_and_append_kargs(\n                    orig_options,\n                    config.delete_kargs.as_slice(),\n                    config.append_kargs.as_slice(),\n                    &[],\n                )\n            })\n            .context(\"deleting and appending kargs\")?;\n        }\n        if let Some(platform) = config.platform.as_ref() {\n            write_platform(mount.mountpoint(), platform).context(\"writing platform ID\")?;\n        }\n        if let Some(network_config) = config.network_config.as_ref() {\n            copy_network_config(mount.mountpoint(), network_config)?;\n        }\n        #[cfg(target_arch = \"s390x\")]\n        s390x::install_bootloader(\n            mount.mountpoint(),\n            &config.device,\n            config.firstboot_kargs.as_ref().map(|s| s.as_str()),\n        )?;\n    }\n\n    // detect any latent write errors\n    dest.sync_all().context(\"syncing data to disk\")?;\n\n    Ok(())\n}\n\n/// Write the Ignition config.\nfn write_ignition(\n    mountpoint: &Path,\n    digest_in: &Option<IgnitionHash>,\n    mut config_in: &File,\n) -> Result<()> {\n    eprintln!(\"Writing Ignition config\");\n\n    // Verify configuration digest, if any.\n    if let Some(ref digest) = digest_in {\n        digest\n            .validate(&mut config_in)\n            .context(\"failed to validate Ignition configuration digest\")?;\n        config_in\n            .seek(SeekFrom::Start(0))\n            .context(\"rewinding Ignition configuration file\")?;\n    };\n\n    // make parent directory\n    let mut config_dest = mountpoint.to_path_buf();\n    config_dest.push(\"ignition\");\n    create_dir_all(&config_dest).context(\"creating Ignition config directory\")?;\n\n    // do the copy\n    config_dest.push(\"config.ign\");\n    let mut config_out = OpenOptions::new()\n        .write(true)\n        .create_new(true)\n        .open(&config_dest)\n        .with_context(|| {\n            format!(\n                \"opening destination Ignition config {}\",\n                config_dest.display()\n            )\n        })?;\n    copy(&mut config_in, &mut config_out).context(\"writing Ignition config\")?;\n\n    Ok(())\n}\n\n/// Write first-boot kernel arguments.\nfn write_firstboot_kargs(mountpoint: &Path, args: &str) -> Result<()> {\n    eprintln!(\"Writing first-boot kernel arguments\");\n\n    // write the arguments\n    let mut config_dest = mountpoint.to_path_buf();\n    config_dest.push(\"ignition.firstboot\");\n    // if the file doesn't already exist, fail, since our assumptions\n    // are wrong\n    let mut config_out = OpenOptions::new()\n        .append(true)\n        .open(&config_dest)\n        .with_context(|| format!(\"opening first-boot file {}\", config_dest.display()))?;\n    let contents = format!(\"set ignition_network_kcmdline=\\\"{}\\\"\\n\", args);\n    config_out\n        .write_all(contents.as_bytes())\n        .context(\"writing first-boot kernel arguments\")?;\n\n    Ok(())\n}\n\n/// To be used with `visit_bls_entry_options()`. Modifies the BLS config as instructed by\n/// `delete_args` and `append_args`.\npub fn bls_entry_options_delete_and_append_kargs(\n    orig_options: &str,\n    delete_args: &[String],\n    append_args: &[String],\n    append_args_if_missing: &[String],\n) -> Result<Option<String>> {\n    if delete_args.is_empty() && append_args.is_empty() && append_args_if_missing.is_empty() {\n        return Ok(None);\n    }\n    Ok(Some(modify_kargs(\n        orig_options,\n        append_args,\n        append_args_if_missing,\n        &[],\n        delete_args,\n    )?))\n}\n\n// XXX: Need a proper parser here and share it with afterburn. The approach we use here\n// is to just do a dumb substring search and replace. This is naive (e.g. doesn't\n// handle occurrences in quoted args) but will work for now (one thing that saves us is\n// that we're acting on our baked configs, which have straight-forward kargs).\npub fn modify_kargs(\n    current_kargs: &str,\n    kargs_append: &[String],\n    kargs_append_if_missing: &[String],\n    kargs_replace: &[String],\n    kargs_delete: &[String],\n) -> Result<String> {\n    lazy_static! {\n        static ref RE: Regex = Regex::new(r\"^([^=]+)=([^=]+)=([^=]+)$\").unwrap();\n    }\n    let mut new_kargs: String = format!(\" {} \", current_kargs);\n    for karg in kargs_delete {\n        let s = format!(\" {} \", karg.trim());\n        new_kargs = new_kargs.replace(&s, \" \");\n    }\n    for karg in kargs_append {\n        new_kargs.push_str(karg.trim());\n        new_kargs.push(' ');\n    }\n    for karg in kargs_append_if_missing {\n        let karg = karg.trim();\n        let s = format!(\" {} \", karg);\n        if !new_kargs.contains(&s) {\n            new_kargs.push_str(karg);\n            new_kargs.push(' ');\n        }\n    }\n    for karg in kargs_replace {\n        let caps = match RE.captures(karg) {\n            Some(caps) => caps,\n            None => bail!(\"Wrong input, format should be: KEY=OLD=NEW\"),\n        };\n        let old = format!(\" {}={} \", &caps[1], &caps[2]);\n        let new = format!(\" {}={} \", &caps[1], &caps[3]);\n        new_kargs = new_kargs.replace(&old, &new);\n    }\n    Ok(new_kargs.trim().into())\n}\n\n/// Override the platform ID.\nfn write_platform(mountpoint: &Path, platform: &str) -> Result<()> {\n    // early return if setting the platform to the default value, since\n    // otherwise we'll think we failed to set it\n    if platform == \"metal\" {\n        return Ok(());\n    }\n\n    eprintln!(\"Setting platform to {}\", platform);\n    visit_bls_entry_options(mountpoint, |orig_options: &str| {\n        bls_entry_options_write_platform(orig_options, platform)\n    })?;\n\n    Ok(())\n}\n\n/// To be used with `visit_bls_entry_options()`. Modifies the BLS config, only changing the\n/// `ignition.platform.id`. This assumes that we will only install from metal images and that the\n/// bootloader configs will always set ignition.platform.id.  Fail if those assumptions change.\n/// This is deliberately simplistic.\nfn bls_entry_options_write_platform(orig_options: &str, platform: &str) -> Result<Option<String>> {\n    let new_options = orig_options.replace(\n        \"ignition.platform.id=metal\",\n        &format!(\"ignition.platform.id={}\", platform),\n    );\n    if orig_options == new_options {\n        bail!(\"Couldn't locate platform ID\");\n    }\n    Ok(Some(new_options))\n}\n\n/// Calls a function on the latest (default) BLS entry and optionally updates it if the function\n/// returns new content. Errors out if no BLS entry was found.\npub fn visit_bls_entry(\n    mountpoint: &Path,\n    f: impl Fn(&str) -> Result<Option<String>>,\n) -> Result<()> {\n    // walk /boot/loader/entries/*.conf\n    let mut config_path = mountpoint.to_path_buf();\n    config_path.push(\"loader/entries\");\n\n    // We only want to affect the latest BLS entry (i.e. the default one). This confusingly is the\n    // *last* BLS config in the directory because they are sorted by reverse order:\n    // https://github.com/ostreedev/ostree/pull/1654\n    //\n    // Because `read_dir` doesn't guarantee any ordering, we gather all the filenames up front and\n    // sort them before picking the last one.\n    let mut entries: Vec<PathBuf> = Vec::new();\n    for entry in read_dir(&config_path)\n        .with_context(|| format!(\"reading directory {}\", config_path.display()))?\n    {\n        let path = entry\n            .with_context(|| format!(\"reading directory {}\", config_path.display()))?\n            .path();\n        if path.extension().unwrap_or_default() != \"conf\" {\n            continue;\n        }\n        entries.push(path);\n    }\n    entries.sort();\n\n    if let Some(path) = entries.pop() {\n        // slurp in the file\n        let mut config = OpenOptions::new()\n            .read(true)\n            .write(true)\n            .open(&path)\n            .with_context(|| format!(\"opening bootloader config {}\", path.display()))?;\n        let orig_contents = {\n            let mut s = String::new();\n            config\n                .read_to_string(&mut s)\n                .with_context(|| format!(\"reading {}\", path.display()))?;\n            s\n        };\n\n        let r = f(&orig_contents).with_context(|| format!(\"visiting {}\", path.display()))?;\n\n        if let Some(new_contents) = r {\n            // write out the modified data\n            config\n                .seek(SeekFrom::Start(0))\n                .with_context(|| format!(\"seeking {}\", path.display()))?;\n            config\n                .set_len(0)\n                .with_context(|| format!(\"truncating {}\", path.display()))?;\n            config\n                .write(new_contents.as_bytes())\n                .with_context(|| format!(\"writing {}\", path.display()))?;\n        }\n    } else {\n        bail!(\"Found no BLS entries in {}\", config_path.display());\n    }\n\n    Ok(())\n}\n\n/// Wrapper around `visit_bls_entry` to specifically visit just the BLS entry's `options` line and\n/// optionally update it if the function returns new content. Errors out if none or more than one\n/// `options` field was found.\npub fn visit_bls_entry_options(\n    mountpoint: &Path,\n    f: impl Fn(&str) -> Result<Option<String>>,\n) -> Result<()> {\n    visit_bls_entry(mountpoint, |orig_contents: &str| {\n        let mut new_contents = String::with_capacity(orig_contents.len());\n        let mut found_options = false;\n        let mut modified = false;\n        for line in orig_contents.lines() {\n            if !line.starts_with(\"options \") {\n                new_contents.push_str(line.trim_end());\n            } else if found_options {\n                bail!(\"Multiple 'options' lines found\");\n            } else {\n                let r = f(line[\"options \".len()..].trim()).context(\"visiting options\")?;\n                if let Some(new_options) = r {\n                    new_contents.push_str(\"options \");\n                    new_contents.push_str(new_options.trim());\n                    modified = true;\n                }\n                found_options = true;\n            }\n            new_contents.push('\\n');\n        }\n        if !found_options {\n            bail!(\"Couldn't locate 'options' line\");\n        }\n        if !modified {\n            Ok(None)\n        } else {\n            Ok(Some(new_contents))\n        }\n    })\n}\n\n/// Copy networking config if asked to do so\nfn copy_network_config(mountpoint: &Path, net_config_src: &str) -> Result<()> {\n    eprintln!(\"Copying networking configuration from {}\", net_config_src);\n\n    // get the path to the destination directory\n    let net_config_dest = mountpoint.join(\"coreos-firstboot-network\");\n\n    // make the directory if it doesn't exist\n    create_dir_all(&net_config_dest).with_context(|| {\n        format!(\n            \"creating destination networking config directory {}\",\n            net_config_dest.display()\n        )\n    })?;\n\n    // copy files from source to destination directories\n    for entry in read_dir(&net_config_src)\n        .with_context(|| format!(\"reading directory {}\", net_config_src))?\n    {\n        let entry = entry.with_context(|| format!(\"reading directory {}\", net_config_src))?;\n        let srcpath = entry.path();\n        let destpath = net_config_dest.join(entry.file_name());\n        if srcpath.is_file() {\n            eprintln!(\"Copying {} to installed system\", srcpath.display());\n            fscopy(&srcpath, &destpath).context(\"Copying networking config\")?;\n        }\n    }\n\n    Ok(())\n}\n\n/// Clear the partition table and restore saved partitions.  For use after\n/// a failure.\nfn reset_partition_table(\n    config: &InstallConfig,\n    dest: &mut File,\n    table: &mut dyn PartTable,\n    saved: &SavedPartitions,\n) -> Result<()> {\n    eprintln!(\"Resetting partition table\");\n\n    if is_dasd(&config.device, Some(dest))? {\n        // Don't write out a GPT, since the backup GPT may overwrite\n        // something we're not allowed to touch.  Just clear the first MiB\n        // of disk.\n        dest.seek(SeekFrom::Start(0))\n            .context(\"seeking to start of disk\")?;\n        let zeroes = [0u8; 1024 * 1024];\n        dest.write_all(&zeroes)\n            .context(\"clearing primary partition table\")?;\n    } else {\n        // Write a new GPT including any saved partitions.\n        saved\n            .overwrite(dest)\n            .context(\"restoring saved partitions\")?;\n    }\n\n    // Finish writeback and reread the partition table.\n    dest.sync_all().context(\"syncing partition table to disk\")?;\n    table.reread()?;\n\n    Ok(())\n}\n\n// Preserve saved partitions by writing them to a file in /tmp and reporting\n// the path.\nfn stash_saved_partitions(disk: &mut File, saved: &SavedPartitions) -> Result<()> {\n    let mut stash = tempfile::Builder::new()\n        .prefix(\"coreos-installer-partitions.\")\n        .tempfile()\n        .context(\"creating partition stash file\")?;\n    let path = stash.path().to_owned();\n    eprintln!(\"Storing saved partition entries to {}\", path.display());\n    let len = disk.seek(SeekFrom::End(0)).context(\"seeking disk\")?;\n    stash\n        .as_file()\n        .set_len(len)\n        .with_context(|| format!(\"extending partition stash file {}\", path.display()))?;\n    saved\n        .overwrite(stash.as_file_mut())\n        .with_context(|| format!(\"stashing saved partitions to {}\", path.display()))?;\n    stash\n        .keep()\n        .with_context(|| format!(\"retaining saved partition stash in {}\", path.display()))?;\n    Ok(())\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_platform_id() {\n        let orig_content = \"ignition.platform.id=metal foo bar\";\n        let new_content = bls_entry_options_write_platform(orig_content, \"openstack\").unwrap();\n        assert_eq!(\n            new_content.unwrap(),\n            \"ignition.platform.id=openstack foo bar\"\n        );\n\n        let orig_content = \"foo ignition.platform.id=metal bar\";\n        let new_content = bls_entry_options_write_platform(orig_content, \"openstack\").unwrap();\n        assert_eq!(\n            new_content.unwrap(),\n            \"foo ignition.platform.id=openstack bar\"\n        );\n\n        let orig_content = \"foo bar ignition.platform.id=metal\";\n        let new_content = bls_entry_options_write_platform(orig_content, \"openstack\").unwrap();\n        assert_eq!(\n            new_content.unwrap(),\n            \"foo bar ignition.platform.id=openstack\"\n        );\n    }\n\n    #[test]\n    fn test_modify_kargs() {\n        let orig_kargs = \"foo bar foobar\";\n\n        let delete_kargs = vec![\"foo\".into()];\n        let new_kargs = modify_kargs(orig_kargs, &[], &[], &[], &delete_kargs).unwrap();\n        assert_eq!(new_kargs, \"bar foobar\");\n\n        let delete_kargs = vec![\"bar\".into()];\n        let new_kargs = modify_kargs(orig_kargs, &[], &[], &[], &delete_kargs).unwrap();\n        assert_eq!(new_kargs, \"foo foobar\");\n\n        let delete_kargs = vec![\"foobar\".into()];\n        let new_kargs = modify_kargs(orig_kargs, &[], &[], &[], &delete_kargs).unwrap();\n        assert_eq!(new_kargs, \"foo bar\");\n\n        let delete_kargs = vec![\"foo bar\".into()];\n        let new_kargs = modify_kargs(orig_kargs, &[], &[], &[], &delete_kargs).unwrap();\n        assert_eq!(new_kargs, \"foobar\");\n\n        let delete_kargs = vec![\"bar\".into(), \"foo\".into()];\n        let new_kargs = modify_kargs(orig_kargs, &[], &[], &[], &delete_kargs).unwrap();\n        assert_eq!(new_kargs, \"foobar\");\n\n        let orig_kargs = \"foo=val bar baz=val\";\n\n        let delete_kargs = vec![\"   foo=val\".into()];\n        let new_kargs = modify_kargs(orig_kargs, &[], &[], &[], &delete_kargs).unwrap();\n        assert_eq!(new_kargs, \"bar baz=val\");\n\n        let delete_kargs = vec![\"baz=val  \".into()];\n        let new_kargs = modify_kargs(orig_kargs, &[], &[], &[], &delete_kargs).unwrap();\n        assert_eq!(new_kargs, \"foo=val bar\");\n\n        let orig_kargs = \"foo mitigations=auto,nosmt console=tty0 bar console=ttyS0,115200n8 baz\";\n\n        let delete_kargs = vec![\n            \"mitigations=auto,nosmt\".into(),\n            \"console=ttyS0,115200n8\".into(),\n        ];\n        let append_kargs = vec![\"console=ttyS1,115200n8  \".into()];\n        let append_kargs_if_missing =\n                 // base       // append_kargs dupe             // missing\n            vec![\"bar\".into(), \"console=ttyS1,115200n8\".into(), \"boo\".into()];\n        let new_kargs = modify_kargs(\n            orig_kargs,\n            &append_kargs,\n            &append_kargs_if_missing,\n            &[],\n            &delete_kargs,\n        )\n        .unwrap();\n        assert_eq!(\n            new_kargs,\n            \"foo console=tty0 bar baz console=ttyS1,115200n8 boo\"\n        );\n\n        let orig_kargs = \"foo mitigations=auto,nosmt console=tty0 bar console=ttyS0,115200n8 baz\";\n\n        let append_kargs = vec![\"console=ttyS1,115200n8\".into()];\n        let replace_kargs = vec![\"mitigations=auto,nosmt=auto\".into()];\n        let delete_kargs = vec![\"console=ttyS0,115200n8\".into()];\n        let new_kargs = modify_kargs(\n            orig_kargs,\n            &append_kargs,\n            &[],\n            &replace_kargs,\n            &delete_kargs,\n        )\n        .unwrap();\n        assert_eq!(\n            new_kargs,\n            \"foo mitigations=auto console=tty0 bar baz console=ttyS1,115200n8\"\n        );\n    }\n}\n"
  },
  {
    "project": "swhkd",
    "target": 1,
    "commit_id": "0b620a09605afb815c6d8d8953bbb7a10a8c0575",
    "func": "use clap::{arg, Command};\nuse evdev::{AttributeSet, Device, InputEventKind, Key};\nuse nix::unistd::{Group, Uid};\nuse signal_hook_tokio::Signals;\nuse std::{\n    collections::{HashMap, HashSet},\n    env, fs,\n    io::prelude::*,\n    os::unix::net::UnixStream,\n    path::Path,\n    process::{exit, id},\n};\nuse sysinfo::{ProcessExt, System, SystemExt};\nuse tokio::select;\nuse tokio::time::Duration;\nuse tokio::time::{sleep, Instant};\nuse tokio_stream::{StreamExt, StreamMap};\n\nuse signal_hook::consts::signal::*;\n\nmod config;\nuse crate::config::Value;\nmod uinput;\n\n#[cfg(test)]\nmod tests;\n\nstruct KeyboardState {\n    state_modifiers: HashSet<config::Modifier>,\n    state_keysyms: AttributeSet<evdev::Key>,\n}\n\nimpl KeyboardState {\n    fn new() -> KeyboardState {\n        KeyboardState { state_modifiers: HashSet::new(), state_keysyms: AttributeSet::new() }\n    }\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Box<dyn std::error::Error>> {\n    let args = set_command_line_args().get_matches();\n    env::set_var(\"RUST_LOG\", \"swhkd=warn\");\n\n    if args.is_present(\"debug\") {\n        env::set_var(\"RUST_LOG\", \"swhkd=trace\");\n    }\n\n    env_logger::init();\n    log::trace!(\"Logger initialized.\");\n\n    let pidfile: String = String::from(\"/tmp/swhkd.pid\");\n    if Path::new(&pidfile).exists() {\n        log::trace!(\"Reading {} file and checking for running instances.\", pidfile);\n        let swhkd_pid = match fs::read_to_string(&pidfile) {\n            Ok(swhkd_pid) => swhkd_pid,\n            Err(e) => {\n                log::error!(\"Unable to read {} to check all running instances\", e);\n                exit(1);\n            }\n        };\n        log::debug!(\"Previous PID: {}\", swhkd_pid);\n\n        let mut sys = System::new_all();\n        sys.refresh_all();\n        for (pid, process) in sys.processes() {\n            if pid.to_string() == swhkd_pid && process.exe() == env::current_exe().unwrap() {\n                log::error!(\"Swhkd is already running!\");\n                log::error!(\"pid of existing swhkd process: {}\", pid.to_string());\n                log::error!(\"To close the existing swhkd process, run `sudo killall swhkd`\");\n                exit(1);\n            }\n        }\n    }\n\n    match fs::write(&pidfile, id().to_string()) {\n        Ok(_) => {}\n        Err(e) => {\n            log::error!(\"Unable to write to {}: {}\", pidfile, e);\n            exit(1);\n        }\n    }\n\n    if check_user_permissions().is_err() {\n        exit(1);\n    }\n\n    let load_config = || {\n        seteuid(env::var(\"PKEXEC_UID\").unwrap().parse::<u32>().unwrap()); // Dropping privileges to invoking user.\n        let config_file_path: std::path::PathBuf = if args.is_present(\"config\") {\n            Path::new(args.value_of(\"config\").unwrap()).to_path_buf()\n        } else {\n            fetch_xdg_config_path()\n        };\n\n        log::debug!(\"Using config file path: {:#?}\", config_file_path);\n\n        let hotkeys = match config::load(&config_file_path) {\n            Err(e) => {\n                log::error!(\"Config Error: {}\", e);\n                exit(1);\n            }\n            Ok(out) => out,\n        };\n\n        for hotkey in &hotkeys {\n            log::debug!(\"hotkey: {:#?}\", hotkey);\n        }\n\n        hotkeys\n    };\n\n    let mut hotkeys = load_config();\n    seteuid(0); // Escalating back to root after reading config file.\n    log::trace!(\"Attempting to find all keyboard file descriptors.\");\n    let keyboard_devices: Vec<Device> =\n        evdev::enumerate().filter(check_device_is_keyboard).collect();\n\n    let mut uinput_device = match uinput::create_uinput_device() {\n        Ok(dev) => dev,\n        Err(e) => {\n            log::error!(\"Err: {:#?}\", e);\n            exit(1);\n        }\n    };\n\n    if keyboard_devices.is_empty() {\n        log::error!(\"No valid keyboard device was detected!\");\n        exit(1);\n    }\n    log::debug!(\"{} Keyboard device(s) detected.\", keyboard_devices.len());\n\n    let modifiers_map: HashMap<Key, config::Modifier> = HashMap::from([\n        (Key::KEY_LEFTMETA, config::Modifier::Super),\n        (Key::KEY_RIGHTMETA, config::Modifier::Super),\n        (Key::KEY_LEFTMETA, config::Modifier::Super),\n        (Key::KEY_RIGHTMETA, config::Modifier::Super),\n        (Key::KEY_LEFTALT, config::Modifier::Alt),\n        (Key::KEY_RIGHTALT, config::Modifier::Alt),\n        (Key::KEY_LEFTCTRL, config::Modifier::Control),\n        (Key::KEY_RIGHTCTRL, config::Modifier::Control),\n        (Key::KEY_LEFTSHIFT, config::Modifier::Shift),\n        (Key::KEY_RIGHTSHIFT, config::Modifier::Shift),\n    ]);\n\n    let repeat_cooldown_duration: u64 = if args.is_present(\"cooldown\") {\n        args.value_of(\"cooldown\").unwrap().parse::<u64>().unwrap()\n    } else {\n        250\n    };\n\n    let mut signals = Signals::new(&[\n        SIGUSR1, SIGUSR2, SIGHUP, SIGABRT, SIGBUS, SIGCHLD, SIGCONT, SIGINT, SIGPIPE, SIGQUIT,\n        SIGSYS, SIGTERM, SIGTRAP, SIGTSTP, SIGVTALRM, SIGXCPU, SIGXFSZ,\n    ])?;\n\n    let mut execution_is_paused = false;\n    let mut last_hotkey: Option<config::Hotkey> = None;\n    let mut pending_release: bool = false;\n    let mut keyboard_states: Vec<KeyboardState> = Vec::new();\n    let mut keyboard_stream_map = StreamMap::new();\n\n    for (i, mut device) in keyboard_devices.into_iter().enumerate() {\n        let _ = device.grab();\n        keyboard_stream_map.insert(i, device.into_event_stream()?);\n        keyboard_states.push(KeyboardState::new());\n    }\n\n    // The initial sleep duration is never read because last_hotkey is initialized to None\n    let hotkey_repeat_timer = sleep(Duration::from_millis(0));\n    tokio::pin!(hotkey_repeat_timer);\n\n    loop {\n        select! {\n            _ = &mut hotkey_repeat_timer, if &last_hotkey.is_some() => {\n                let hotkey = last_hotkey.clone().unwrap();\n                if hotkey.keybinding.on_release {\n                    continue;\n                }\n                send_command(hotkey.clone());\n                hotkey_repeat_timer.as_mut().reset(Instant::now() + Duration::from_millis(repeat_cooldown_duration));\n            }\n\n            Some(signal) = signals.next() => {\n                match signal {\n                    SIGUSR1 => {\n                        execution_is_paused = true;\n                        for mut device in evdev::enumerate().filter(check_device_is_keyboard) {\n                            let _ = device.ungrab();\n                        }\n                    }\n\n                    SIGUSR2 => {\n                        execution_is_paused = false;\n                        for mut device in evdev::enumerate().filter(check_device_is_keyboard) {\n                            let _ = device.grab();\n                        }\n                    }\n\n                    SIGHUP => {\n                        hotkeys = load_config();\n                    }\n\n                    SIGINT => {\n                        for mut device in evdev::enumerate().filter(check_device_is_keyboard) {\n                            let _ = device.ungrab();\n                        }\n                        log::warn!(\"Received SIGINT signal, exiting...\");\n                        exit(1);\n                    }\n\n                    _ => {\n                        for mut device in evdev::enumerate().filter(check_device_is_keyboard) {\n                            let _ = device.ungrab();\n                        }\n\n                        log::warn!(\"Received signal: {:#?}\", signal);\n                        log::warn!(\"Exiting...\");\n                        exit(1);\n                    }\n                }\n            }\n\n            Some((i, Ok(event))) = keyboard_stream_map.next() => {\n                let keyboard_state = &mut keyboard_states[i];\n\n                let key = match event.kind() {\n                    InputEventKind::Key(keycode) => keycode,\n                    _ => continue\n                };\n\n                match event.value() {\n                    // Key press\n                    1 => {\n                        if let Some(modifier) = modifiers_map.get(&key) {\n                            keyboard_state.state_modifiers.insert(*modifier);\n                        } else {\n                            keyboard_state.state_keysyms.insert(key);\n                        }\n                    }\n\n                    // Key release\n                    0 => {\n                        if last_hotkey.is_some() && pending_release {\n                            pending_release = false;\n                            send_command(last_hotkey.clone().unwrap());\n                            last_hotkey = None;\n                        }\n                        if let Some(modifier) = modifiers_map.get(&key) {\n                            if let Some(hotkey) = &last_hotkey {\n                                if hotkey.modifiers().contains(modifier) {\n                                    last_hotkey = None;\n                                }\n                            }\n                            keyboard_state.state_modifiers.remove(modifier);\n                        } else if keyboard_state.state_keysyms.contains(key) {\n                            if let Some(hotkey) = &last_hotkey {\n                                if key == hotkey.keysym() {\n                                    last_hotkey = None;\n                                }\n                            }\n                            keyboard_state.state_keysyms.remove(key);\n                        }\n                    }\n\n                    _ => {}\n                }\n\n                let possible_hotkeys: Vec<&config::Hotkey> = hotkeys.iter()\n                    .filter(|hotkey| hotkey.modifiers().len() == keyboard_state.state_modifiers.len())\n                    .collect();\n\n                let event_in_hotkeys = hotkeys.iter().any(|hotkey| {\n                    hotkey.keysym().code() == event.code() &&\n                    keyboard_state.state_modifiers\n                        .iter()\n                        .all(|x| hotkey.modifiers().contains(x)) &&\n                    keyboard_state.state_modifiers.len() == hotkey.modifiers().len()\n                    && !hotkey.is_send()\n                        });\n\n                // Don't emit event to virtual device if it's from a valid hotkey\n                if !event_in_hotkeys {\n                    uinput_device.emit(&[event]).unwrap();\n                }\n\n                if execution_is_paused || possible_hotkeys.is_empty() || last_hotkey.is_some() {\n                    continue;\n                }\n\n                log::debug!(\"state_modifiers: {:#?}\", keyboard_state.state_modifiers);\n                log::debug!(\"state_keysyms: {:#?}\", keyboard_state.state_keysyms);\n                log::debug!(\"hotkey: {:#?}\", possible_hotkeys);\n\n                for hotkey in possible_hotkeys {\n                    // this should check if state_modifiers and hotkey.modifiers have the same elements\n                    if keyboard_state.state_modifiers.iter().all(|x| hotkey.modifiers().contains(x))\n                        && keyboard_state.state_modifiers.len() == hotkey.modifiers().len()\n                        && keyboard_state.state_keysyms.contains(hotkey.keysym())\n                    {\n                        last_hotkey = Some(hotkey.clone());\n                        if pending_release { break; }\n                        if hotkey.is_on_release() {\n                            pending_release = true;\n                            break;\n                        }\n                        send_command(hotkey.clone());\n                        hotkey_repeat_timer.as_mut().reset(Instant::now() + Duration::from_millis(repeat_cooldown_duration));\n                        break;\n                    }\n                }\n            }\n        }\n    }\n}\n\nfn sock_send(command: &str) -> std::io::Result<()> {\n    let sock_file_path =\n        String::from(format!(\"/run/user/{}/swhkd.sock\", env::var(\"PKEXEC_UID\").unwrap()));\n    let mut stream = UnixStream::connect(sock_file_path)?;\n    stream.write_all(command.as_bytes())?;\n    Ok(())\n}\n\nfn send_command(hotkey: config::Hotkey) {\n    log::info!(\"Hotkey pressed: {:#?}\", hotkey);\n    if let Err(e) = sock_send(&hotkey.command) {\n        log::error!(\"Failed to send command to swhks through IPC.\");\n        log::error!(\"Please make sure that swhks is running.\");\n        log::error!(\"Err: {:#?}\", e)\n    }\n}\n\npub fn check_user_permissions() -> Result<(), ()> {\n    if !Uid::current().is_root() {\n        let groups = nix::unistd::getgroups();\n        for (_, groups) in groups.iter().enumerate() {\n            for group in groups {\n                let group = Group::from_gid(*group);\n                if group.unwrap().unwrap().name == \"input\" {\n                    log::error!(\"Note: INVOKING USER IS IN INPUT GROUP!!!!\");\n                    log::error!(\"THIS IS A HUGE SECURITY RISK!!!!\");\n                }\n            }\n        }\n        log::error!(\"Consider using `pkexec swhkd ...`\");\n        Err(())\n    } else {\n        log::warn!(\"Running swhkd as root!\");\n        Ok(())\n    }\n}\n\npub fn check_device_is_keyboard(device: &Device) -> bool {\n    if device.supported_keys().map_or(false, |keys| keys.contains(Key::KEY_ENTER)) {\n        if device.name() == Some(\"swhkd virtual output\") {\n            return false;\n        }\n        log::debug!(\"Keyboard: {}\", device.name().unwrap(),);\n        true\n    } else {\n        log::trace!(\"Other: {}\", device.name().unwrap(),);\n        false\n    }\n}\n\npub fn set_command_line_args() -> Command<'static> {\n    let app = Command::new(\"swhkd\")\n        .version(env!(\"CARGO_PKG_VERSION\"))\n        .author(env!(\"CARGO_PKG_AUTHORS\"))\n        .about(\"Simple Wayland HotKey Daemon\")\n        .arg(\n            arg!(-c --config <CONFIG_FILE_PATH>)\n                .required(false)\n                .takes_value(true)\n                .help(\"Set a custom config file path.\"),\n        )\n        .arg(\n            arg!(-C --cooldown <COOLDOWN_IN_MS>)\n                .required(false)\n                .takes_value(true)\n                .help(\"Set a custom repeat cooldown duration. Default is 250ms.\"),\n        )\n        .arg(arg!(-d - -debug).required(false).help(\"Enable debug mode.\"));\n    app\n}\n\npub fn fetch_xdg_config_path() -> std::path::PathBuf {\n    let config_file_path: std::path::PathBuf = match env::var(\"XDG_CONFIG_HOME\") {\n        Ok(val) => {\n            log::debug!(\"XDG_CONFIG_HOME exists: {:#?}\", val);\n            Path::new(&val).join(\"swhkd/swhkdrc\")\n        }\n        Err(_) => {\n            log::error!(\"XDG_CONFIG_HOME has not been set.\");\n            Path::new(\"/etc/swhkd/swhkdrc\").to_path_buf()\n        }\n    };\n    config_file_path\n}\n\npub fn seteuid(uid: u32) {\n    let uid = Uid::from_raw(uid);\n    match nix::unistd::seteuid(uid) {\n        Ok(_) => log::debug!(\"Dropping privileges...\"),\n        Err(e) => {\n            log::error!(\"Failed to set EUID: {:#?}\", e);\n            exit(1);\n        }\n    }\n}\n"
  },
  {
    "project": "afire",
    "target": 1,
    "commit_id": "5644d94eec95abe9323d99e307851a52957777d5",
    "func": "//! Extention to serve static files from disk\n\nuse std::fs;\nuse std::sync::RwLock;\n\nuse crate::{Method, Request, Response, Server};\n\ntype Middleware = fn(req: Request, res: Response, success: bool) -> Option<(Response, bool)>;\n\n/// Serve Static Content\n#[derive(Clone)]\npub struct ServeStatic {\n    /// Content Path\n    pub data_dir: String,\n\n    /// Disabled file paths (relative from data dir)\n    pub disabled_files: Vec<String>,\n\n    /// Page not found route\n    pub not_found: fn(&Request, bool) -> Response,\n\n    /// Middleware\n    ///\n    /// (Request, Static Response, Sucess [eg If file found])\n    pub middleware: Vec<Middleware>,\n\n    /// MIME Types\n    pub types: Vec<(String, String)>,\n}\n\nimpl ServeStatic {\n    /// Make a new Static File Server\n    /// ## Example\n    /// ```rust\n    /// // Import Library\n    /// use afire::{Server, ServeStatic};\n    ///\n    /// // Create a server for localhost on port 8080\n    /// let mut server: Server = Server::new(\"localhost\", 8080);\n    ///\n    /// // Make a new static file server and attach it to the afire server\n    /// ServeStatic::new(\"data/static\").attach(&mut server);\n    ///\n    /// # server.set_run(false);\n    /// server.start().unwrap();\n    /// ```\n    pub fn new<T>(path: T) -> Self\n    where\n        T: std::fmt::Display,\n    {\n        Self {\n            data_dir: path.to_string(),\n            disabled_files: Vec::new(),\n            not_found: |req, _| {\n                Response::new()\n                    .status(404)\n                    .text(format!(\"The page `{}` was not found...\", req.path))\n                    .header(\"Content-Type\", \"text/plain\")\n            },\n            middleware: Vec::new(),\n            types: TYPES\n                .to_vec()\n                .iter()\n                .map(|x| (x.0.to_owned(), x.1.to_owned()))\n                .collect(),\n        }\n    }\n\n    /// Disable serving a file\n    /// Path is relative to the dir being served\n    /// ## Example\n    /// ```rust\n    /// // Import Library\n    /// use afire::{Server, ServeStatic};\n    ///\n    /// // Create a server for localhost on port 8080\n    /// let mut server: Server = Server::new(\"localhost\", 8080);\n    ///\n    /// // Make a new static sevrer\n    /// ServeStatic::new(\"data/static\")\n    ///     // Disable a file from being served\n    ///     .disable(\"index.scss\")\n    ///     // Attatch it to the afire server\n    ///     .attach(&mut server);\n    ///\n    /// # server.set_run(false);\n    /// server.start().unwrap();\n    /// ```\n    pub fn disable<T>(self, file_path: T) -> Self\n    where\n        T: std::fmt::Display,\n    {\n        let mut disabled = self.disabled_files;\n        disabled.push(file_path.to_string());\n\n        Self {\n            disabled_files: disabled,\n            ..self\n        }\n    }\n\n    /// Disable serving a many files at once\n    /// Path is relative to the dir being served\n    /// ## Example\n    /// ```rust\n    /// // Import Library\n    /// use afire::{Server, ServeStatic};\n    ///\n    /// // Create a server for localhost on port 8080\n    /// let mut server: Server = Server::new(\"localhost\", 8080);\n    ///\n    /// // Make a new static sevrer\n    /// ServeStatic::new(\"data/static\")\n    ///     // Disable a vec of files from being served\n    ///     .disable_vec(vec![\"index.scss\", \"index.css.map\"])\n    ///     // Attatch it to the afire server\n    ///     .attach(&mut server);\n    ///\n    /// # server.set_run(false);\n    /// server.start().unwrap();\n    /// ```\n    pub fn disable_vec<T>(self, file_paths: Vec<T>) -> Self\n    where\n        T: std::fmt::Display,\n    {\n        let mut disabled = self.disabled_files;\n        for i in file_paths {\n            disabled.push(i.to_string());\n        }\n\n        Self {\n            disabled_files: disabled,\n            ..self\n        }\n    }\n\n    /// Add a middleware to the static file server\n    ///\n    /// Middleware here works much diffrently to afire middleware\n    ///\n    /// The middleware priority is still by most recently defined\n    ///\n    /// But this middleware takes functions only - no closures.\n    /// The Resultes of the middleware are put togther so more then one middleware can affect thre response\n    /// ## Example\n    /// ```rust\n    /// // Import Library\n    /// use afire::{Server, ServeStatic};\n    ///\n    /// // Create a server for localhost on port 8080\n    /// let mut server: Server = Server::new(\"localhost\", 8080);\n    ///\n    /// // Make a new static sevrer\n    /// ServeStatic::new(\"data/static\")\n    ///     // Add some middleware to the Static File Server\n    ///     .middleware(|req, res, suc| {\n    ///        // Print the path of the file served\n    ///        println!(\"Staticly Served: {}\", req.path);\n    ///\n    ///         None\n    ///     })\n    ///     // Attatch it to the afire server\n    ///     .attach(&mut server);\n    ///\n    /// # server.set_run(false);\n    /// server.start().unwrap();\n    /// ```\n    pub fn middleware(self, f: Middleware) -> Self {\n        let mut middleware = self.middleware;\n        middleware.push(f);\n\n        Self { middleware, ..self }\n    }\n\n    /// Set the not found page\n    ///\n    /// This will run if no file is found to serve or the file is disabled\n    ///\n    /// The bool in the fn parms is if the file is blocked\n    /// ## Example\n    /// ```rust\n    /// // Import Library\n    /// use afire::{Response, Server, ServeStatic};\n    ///\n    /// // Create a server for localhost on port 8080\n    /// let mut server: Server = Server::new(\"localhost\", 8080);\n    ///\n    /// // Make a new static sevrer\n    /// ServeStatic::new(\"data/static\")\n    ///     // Set a new file not found page\n    ///     .not_found(|_req, _dis| Response::new().status(404).text(\"Page Not Found!\"))\n    ///     // Attatch it to the afire server\n    ///     .attach(&mut server);\n    ///\n    /// # server.set_run(false);\n    /// server.start().unwrap();\n    /// ```\n    pub fn not_found(self, f: fn(&Request, bool) -> Response) -> Self {\n        Self {\n            not_found: f,\n            ..self\n        }\n    }\n\n    /// Add a MIME type to the Static file Server\n    ///\n    /// This extension comes with alot of builtin MIME types\n    /// but if you need to add more thats what this is for\n    ///\n    /// The key is the file extension\n    ///\n    /// The value is the MIME type\n    /// ## Example\n    /// ```rust\n    /// // Import Library\n    /// use afire::{Server, ServeStatic};\n    ///\n    /// // Create a server for localhost on port 8080\n    /// let mut server: Server = Server::new(\"localhost\", 8080);\n    ///\n    /// // Make a new static sevrer\n    /// ServeStatic::new(\"data/static\")\n    ///     // Add a new MIME type\n    ///     .mime_type(\".3gp\", \"video/3gpp\")\n    ///     // Attatch it to the afire server\n    ///     .attach(&mut server);\n    ///\n    /// # server.set_run(false);\n    /// server.start().unwrap();\n    /// ```\n    pub fn mime_type<T, M>(self, key: T, value: M) -> Self\n    where\n        T: std::fmt::Display,\n        M: std::fmt::Display,\n    {\n        let mut types = self.types;\n\n        types.push((key.to_string(), value.to_string()));\n\n        Self { types, ..self }\n    }\n\n    /// Add a vector of MIME type to the Static file Server\n    ///\n    /// The key is the file extension\n    ///\n    /// The value is the MIME type\n    ///\n    /// Ex: (\"html\", \"text/html\")\n    /// ## Example\n    /// ```rust\n    /// // Import Library\n    /// use afire::{Server, ServeStatic};\n    ///\n    /// // Create a server for localhost on port 8080\n    /// let mut server: Server = Server::new(\"localhost\", 8080);\n    ///\n    /// // Make a new static sevrer\n    /// ServeStatic::new(\"data/static\")\n    ///     // Add a new MIME type\n    ///     .mime_types(vec![(\".3gp\", \"video/3gpp\")])\n    ///     // Attatch it to the afire server\n    ///     .attach(&mut server);\n    ///\n    /// # server.set_run(false);\n    /// server.start().unwrap();\n    /// ```\n    pub fn mime_types<T, M>(self, new_types: Vec<(T, M)>) -> Self\n    where\n        T: std::fmt::Display,\n        M: std::fmt::Display,\n    {\n        let mut new_types = new_types\n            .iter()\n            .map(|x| (x.0.to_string(), x.1.to_string()))\n            .collect();\n        let mut types = self.types;\n\n        types.append(&mut new_types);\n\n        Self { types, ..self }\n    }\n\n    /// Attatch it to a Server\n    ///\n    /// Not much to say really\n    /// ## Example\n    /// ```rust\n    /// // Import Library\n    /// use afire::{Server, ServeStatic};\n    ///\n    /// // Create a server for localhost on port 8080\n    /// let mut server: Server = Server::new(\"localhost\", 8080);\n    ///\n    /// // Make a new static sevrer\n    /// ServeStatic::new(\"data/static\")\n    ///     // Attatch it to the afire server\n    ///     .attach(&mut server);\n    ///\n    /// # server.set_run(false);\n    /// server.start().unwrap();\n    /// ```\n    pub fn attach(self, server: &mut Server) {\n        let cell = RwLock::new(self);\n\n        server.route(Method::ANY, \"**\", move |req| {\n            let mut res = process_req(req.clone(), &cell);\n\n            for i in cell.read().unwrap().middleware.clone().iter().rev() {\n                if let Some(i) = i(req.clone(), res.0.clone(), res.1) {\n                    res = i\n                };\n            }\n\n            res.0\n        });\n    }\n}\n\nfn process_req(req: Request, cell: &RwLock<ServeStatic>) -> (Response, bool) {\n    let this = cell.read().unwrap();\n\n    let mut path = format!(\"{}{}\", this.data_dir, req.path.replace(\"/..\", \"\"));\n\n    // Add Index.html if path ends with /\n    if path.ends_with('/') {\n        path.push_str(\"index.html\");\n    }\n\n    // Also add '/index.html' if path dose not end with a file\n    if !path.split('/').last().unwrap_or_default().contains('.') {\n        path.push_str(\"/index.html\");\n    }\n\n    if this\n        .disabled_files\n        .contains(&path.splitn(2, &this.data_dir).last().unwrap().to_string())\n    {\n        return ((this.not_found)(&req, true), false);\n    }\n\n    // Try to read File\n    match fs::read(&path) {\n        // If its found send it as response\n        Ok(content) => (\n            Response::new()\n                .bytes(content)\n                .header(\"Content-Type\", get_type(&path, &this.types)),\n            true,\n        ),\n\n        // If not send the 404 route defined\n        Err(_) => ((this.not_found)(&req, false), false),\n    }\n}\n\nfn get_type(path: &str, types: &[(String, String)]) -> String {\n    for i in types {\n        if i.0 == path.split('.').last().unwrap_or(\"\") {\n            return i.1.to_owned();\n        }\n    }\n\n    \"application/octet-stream\".to_owned()\n}\n\n/// Common MIME Types\n///\n/// Used by Servestatic Extentions\npub const TYPES: [(&str, &str); 56] = [\n    (\"html\", \"text/html\"),\n    (\"css\", \"text/css\"),\n    (\"js\", \"application/javascript\"),\n    (\"png\", \"image/png\"),\n    (\"jpg\", \"image/jpeg\"),\n    (\"jpeg\", \"image/jpeg\"),\n    (\"gif\", \"image/gif\"),\n    (\"ico\", \"image/x-icon\"),\n    (\"svg\", \"image/svg+xml\"),\n    (\"txt\", \"text/plain\"),\n    (\"aac\", \"audio/aac\"),\n    (\"avi\", \"video/x-msvideo\"),\n    (\"bin\", \"application/octet-stream\"),\n    (\"bmp\", \"image/bmp\"),\n    (\"bz\", \"application/x-bzip\"),\n    (\"bz2\", \"application/x-bzip2\"),\n    (\"cda\", \"application/x-cdf\"),\n    (\"csv\", \"text/csv\"),\n    (\"epub\", \"application/epub+zip\"),\n    (\"gz\", \"application/gzip\"),\n    (\"htm\", \"text/html\"),\n    (\"ics\", \"text/calendar\"),\n    (\"jar\", \"application/java-archive\"),\n    (\"json\", \"application/json\"),\n    (\"jsonld\", \"application/ld+json\"),\n    (\"midi\", \"audio/midi audio/x-midi\"),\n    (\"mid\", \"audio/midi audio/x-midi\"),\n    (\"mjs\", \"text/javascript\"),\n    (\"mp3\", \"audio/mpeg\"),\n    (\"mp4\", \"video/mp4\"),\n    (\"mpeg\", \"video/mpeg\"),\n    (\"oga\", \"audio/ogg\"),\n    (\"ogv\", \"video/ogg\"),\n    (\"ogx\", \"application/ogg\"),\n    (\"opus\", \"audio/opus\"),\n    (\"otf\", \"font/otf\"),\n    (\"pdf\", \"application/pdf\"),\n    (\"rar\", \"application/vnd.rar\"),\n    (\"rtf\", \"application/rtf\"),\n    (\"sh\", \"application/x-sh\"),\n    (\"swf\", \"application/x-shockwave-flash\"),\n    (\"tar\", \"application/x-tar\"),\n    (\"tif\", \"image/tiff\"),\n    (\"tiff\", \"image/tiff\"),\n    (\"ts\", \"text/x-typescript\"),\n    (\"ttf\", \"font/ttf\"),\n    (\"wav\", \"audio/wav\"),\n    (\"weba\", \"audio/webm\"),\n    (\"webm\", \"video/webm\"),\n    (\"webp\", \"image/webp\"),\n    (\"woff\", \"font/woff\"),\n    (\"woff2\", \"font/woff2\"),\n    (\"xhtml\", \"application/xhtml+xml\"),\n    (\"xml\", \"application/xml\"),\n    (\"zip\", \"application/zip\"),\n    (\"7z\", \"application/x-7z-compressed\"),\n];\n"
  },
  {
    "project": "isahc",
    "target": 1,
    "commit_id": "298bf062a27339dd3411c932e5ac2e91a497e43a",
    "func": "use std::io::{self, Read, Write};\nuse std::mem;\nuse std::slice;\n\n\n/// Macro for making memory copies more readable.\nmacro_rules! copy {\n    ($src:expr, $src_start:expr, $dest:expr, $dest_start:expr, $len:expr) => {\n        (&mut $dest[$dest_start..$dest_start+$len]).copy_from_slice(&$src[$src_start..$src_start+$len])\n    };\n}\n\n\n/// Growable byte buffer implemented as a ring buffer.\n///\n/// Optimized for repeated appending of bytes to the end and removing bytes from the front of the buffer.\n#[derive(Clone, Debug)]\npub struct Buffer {\n    array: Box<[u8]>,\n    head: usize,\n    len: usize,\n}\n\nimpl Default for Buffer {\n    fn default() -> Buffer {\n        Buffer::new()\n    }\n}\n\nimpl Buffer {\n    pub const DEFAULT_CAPACITY: usize = 4096;\n\n    /// Create a new buffer with the default capacity.\n    pub fn new() -> Self {\n        Self::with_capacity(Self::DEFAULT_CAPACITY)\n    }\n\n    /// Create a new buffer with a given minimum capacity pre-allocated.\n    pub fn with_capacity(capacity: usize) -> Self {\n        Self {\n            array: Buffer::allocate(capacity.next_power_of_two()),\n            head: 0,\n            len: 0,\n        }\n    }\n\n    /// Create a new buffer containing the given bytes.\n    pub fn from<B: Into<Vec<u8>>>(bytes: B) -> Self {\n        let bytes = bytes.into();\n        let len = bytes.len();\n\n        Self {\n            array: bytes.into_boxed_slice(),\n            head: 0,\n            len: len,\n        }\n    }\n\n    /// Returns `true` if the buffer is empty.\n    #[inline]\n    pub fn is_empty(&self) -> bool {\n        self.len == 0\n    }\n\n    #[inline]\n    pub fn len(&self) -> usize {\n        self.len\n    }\n\n    #[inline]\n    pub fn capacity(&self) -> usize {\n        self.array.len()\n    }\n\n    /// Copy bytes from the front of the buffer into the given slice.\n    ///\n    /// Returns the number of bytes copied. If there are less bytes in the buffer than the length of `dest`, then only\n    /// part of `dest` will be written to.\n    pub fn copy_to(&self, dest: &mut [u8]) -> usize {\n        // Determine the number of bytes to copy.\n        let count = dest.len().min(self.len);\n\n        // Nothing to do.\n        if count == 0 {\n            return 0;\n        }\n\n        // Current buffer is wrapped; copy head segment and tail segment separately.\n        let tail = self.offset(count);\n        if tail <= self.head {\n            let head_len = self.capacity() - self.head;\n            copy!(self.array, self.head, dest, 0, head_len);\n            copy!(self.array, 0, dest, head_len, tail);\n        }\n\n        // Buffer is contiguous; copy in one step.\n        else {\n            copy!(self.array, self.head, dest, 0, count);\n        }\n\n        count\n    }\n\n    /// Consume up to `count` bytes from the front of the buffer and discard them.\n    ///\n    /// Returns the number of bytes consumed, which may be less than `count` if `count` was greater than the number of\n    /// bytes in the buffer.\n    ///\n    /// This operation has a runtime cost of `O(1)`.\n    pub fn consume(&mut self, count: usize) -> usize {\n        let count = count.min(self.len);\n\n        self.head = self.offset(count);\n        self.len -= count;\n\n        count\n    }\n\n    /// Copy the given bytes and insert them into the back of the buffer.\n    pub fn push(&mut self, src: &[u8]) {\n        let new_len = self.len + src.len();\n\n        // If the number of bytes to add would exceed the capacity, grow the internal array first.\n        if new_len > self.capacity() {\n            let new_capacity = new_len.next_power_of_two();\n            let mut new_array = Self::allocate(new_capacity);\n\n            self.copy_to(&mut new_array);\n            self.array = new_array;\n            self.head = 0;\n        }\n\n        // Calculate how much of `src` should be copied to which regions.\n        let head_available = self.capacity().checked_sub(self.head + self.len).unwrap_or(0);\n        let copy_to_head = src.len().min(head_available);\n        let copy_to_tail = src.len() - copy_to_head;\n\n        if copy_to_head > 0 {\n            let tail = self.offset(self.len);\n            copy!(src, 0, self.array, tail, copy_to_head);\n        }\n\n        if copy_to_tail > 0 {\n            copy!(src, copy_to_head, self.array, 0, copy_to_tail);\n        }\n\n        self.len = new_len;\n    }\n\n    /// Pull bytes from the front of the buffer into the given location, up to the length of the destination buffer.\n    ///\n    /// Returns the number of bytes pulled.\n    pub fn pull(&mut self, dest: &mut [u8]) -> usize {\n        let count = self.copy_to(dest);\n        self.consume(count)\n    }\n\n    /// Remove all bytes from the buffer.\n    pub fn clear(&mut self) {\n        self.head = 0;\n        self.len = 0;\n    }\n\n    /// Calculate the internal offset of the given byte position.\n    fn offset(&self, index: usize) -> usize {\n        let mut offset = self.head + index;\n\n        if offset >= self.capacity() {\n            offset -= self.capacity();\n        }\n\n        offset\n    }\n\n    /// Allocate an array of memory on the heap.\n    ///\n    /// Note that the contents of the array are not initialized and the values are undefined. This is safe only because\n    /// we are asking for an array of bytes anyway.\n    fn allocate(size: usize) -> Box<[u8]> {\n        unsafe {\n            let mut vec = Vec::<u8>::with_capacity(size);\n            let slice = slice::from_raw_parts_mut(vec.as_mut_ptr(), vec.capacity());\n            mem::forget(vec);\n            Box::from_raw(slice)\n        }\n    }\n}\n\nimpl From<Buffer> for Vec<u8> {\n    fn from(buffer: Buffer) -> Vec<u8> {\n        let mut slice = Buffer::allocate(buffer.len);\n        let len = buffer.copy_to(&mut slice);\n\n        unsafe {\n            Vec::from_raw_parts(slice.as_mut_ptr(), len, slice.len())\n        }\n    }\n}\n\nimpl Read for Buffer {\n    fn read(&mut self, buf: &mut [u8]) -> io::Result<usize> {\n        Ok(self.pull(buf))\n    }\n}\n\nimpl Write for Buffer {\n    fn write(&mut self, buf: &[u8]) -> io::Result<usize> {\n        self.push(buf);\n        Ok(buf.len())\n    }\n\n    fn flush(&mut self) -> io::Result<()> {\n        Ok(())\n    }\n}\n\n\n#[cfg(test)]\nmod tests {\n    use super::Buffer;\n\n    #[test]\n    fn test_capacity() {\n        let buffer = Buffer::with_capacity(16);\n        assert!(buffer.capacity() == 16);\n    }\n\n    #[test]\n    fn test_push() {\n        let mut buffer = Buffer::new();\n\n        assert!(buffer.is_empty());\n\n        let bytes = b\"hello world\";\n        buffer.push(bytes);\n\n        assert!(!buffer.is_empty());\n        assert!(buffer.len() == bytes.len());\n    }\n\n    #[test]\n    fn test_push_and_consume() {\n        let mut buffer = Buffer::with_capacity(12);\n\n        buffer.push(b\"hello world\");\n\n        assert!(buffer.consume(6) == 6);\n        assert!(buffer.len() == 5);\n\n        buffer.push(b\" hello\");\n\n        assert!(buffer.len() == 11);\n    }\n\n    #[test]\n    fn test_pull_more_than_buffer() {\n        let mut buffer = Buffer::new();\n        let bytes = b\"hello world\";\n        buffer.push(bytes);\n\n        let mut dst = [0; 1024];\n        assert!(buffer.pull(&mut dst) == bytes.len());\n        assert!(&dst[0..bytes.len()] == bytes);\n        assert!(buffer.is_empty());\n    }\n\n    #[test]\n    fn test_pull_less_than_buffer() {\n        let mut buffer = Buffer::new();\n        let bytes = b\"hello world\";\n        buffer.push(bytes);\n\n        let mut dst = [0; 4];\n        assert!(buffer.pull(&mut dst) == dst.len());\n        assert!(&dst == &bytes[0..4]);\n        assert!(!buffer.is_empty());\n        assert!(buffer.len() == bytes.len() - dst.len());\n    }\n\n    #[test]\n    fn test_force_resize() {\n        let mut buffer = Buffer::with_capacity(8);\n\n        buffer.push(b\"hello\");\n        assert!(buffer.capacity() == 8);\n\n        buffer.push(b\" world\");\n        assert!(buffer.capacity() > 8);\n\n        let mut out = [0; 11];\n        buffer.copy_to(&mut out);\n        assert!(&out == b\"hello world\");\n    }\n}\n"
  },
  {
    "project": "stack-rs",
    "target": 1,
    "commit_id": "76cc1855a3ce966182bcf6fb2dc6a1d765cb5138",
    "func": "use std::mem::transmute;\nuse std::ptr::{read, write, swap, copy};\nuse std::slice::{from_raw_parts, from_raw_parts_mut};\nuse util::PointerExt;\n\npub trait Vector {\n    type Item;\n\n    #[inline]\n    fn new() -> Self where Self: Sized {\n        Self::with_capacity(0)\n    }\n\n    fn with_capacity(cap: usize) -> Self where Self: Sized;\n\n    fn capacity(&self) -> usize;\n    fn reserve(&mut self, additional: usize);\n    fn reserve_exact(&mut self, additional: usize);\n    fn shrink_to_fit(&mut self);\n    fn into_boxed_slice(self) -> Box<[Self::Item]>;\n\n    fn truncate(&mut self, len: usize) {\n        let s_len = self.len();\n        assert!(len <= s_len);\n        let ptr = self.as_mut_ptr();\n\n        unsafe {\n            self.set_len(len);\n            for i in len..s_len {\n                read(ptr.uoffset(i));\n            }\n        }\n    }\n\n    unsafe fn set_len(&mut self, len: usize);\n\n    fn swap_remove(&mut self, index: usize) -> Self::Item {\n        let len = self.len();\n        assert!(index < len);\n        unsafe {\n            let ptr = self.as_mut_ptr();\n            let v = read(ptr.uoffset(index));\n            if index != len - 1 {\n                swap(ptr.uoffset(len - 1), ptr.uoffset(index));\n            }\n            self.set_len(len - 1);\n            v\n        }\n    }\n\n    fn insert(&mut self, index: usize, element: Self::Item) {\n        self.reserve(1);\n        unsafe {\n            let len = self.len();\n            let ptr = self.as_mut_ptr().uoffset(index);\n            copy(ptr, ptr.uoffset(1), len - index);\n            write(ptr, element);\n            self.set_len(len + 1);\n        }\n    }\n\n    fn remove(&mut self, index: usize) -> Self::Item {\n        let len = self.len();\n        assert!(index < len);\n        unsafe {\n            let ptr = self.as_mut_ptr().uoffset(index);\n            self.set_len(len - 1);\n            let v = read(ptr);\n            copy(ptr.uoffset(1), ptr, len - index - 1);\n            v\n        }\n    }\n\n    fn retain<F: FnMut(&Self::Item) -> bool>(&mut self, mut f: F) where Self: Sized {\n        let len = self.len();\n        let mut del = 0;\n        unsafe {\n            let v = self.as_mut_ptr();\n\n            for i in 0..len {\n                if !f(transmute(v.uoffset(i) as *const _)) {\n                    del += 1;\n                } else if del > 0 {\n                    swap(v.uoffset(i - del), v.uoffset(i));\n                }\n            }\n        }\n        if del > 0 {\n            self.truncate(len - del);\n        }\n    }\n\n    fn push(&mut self, value: Self::Item) {\n        self.reserve(1);\n        let len = self.len();\n        unsafe {\n            write(self.as_mut_ptr().uoffset(len), value);\n            self.set_len(len + 1);\n        }\n    }\n\n    fn pop(&mut self) -> Option<Self::Item> {\n        let len = self.len();\n        if len == 0 {\n            None\n        } else {\n            Some(self.swap_remove(len - 1))\n        }\n    }\n\n    #[inline]\n    fn clear(&mut self) { self.truncate(0) }\n\n    fn len(&self) -> usize;\n\n    #[inline]\n    fn is_empty(&self) -> bool { self.len() == 0 }\n\n    fn push_cap(&mut self, value: Self::Item) -> Result<(), Self::Item> {\n        if self.len() < self.capacity() {\n            self.push(value);\n            Ok(())\n        } else {\n            Err(value)\n        }\n    }\n\n    fn insert_cap(&mut self, index: usize, element: Self::Item) -> Option<Self::Item> {\n        let cap = self.capacity();\n\n        if index >= cap {\n            return Some(element);\n        }\n\n        let ret = if self.len() < cap {\n            None\n        } else {\n            self.pop()\n        };\n        self.insert(index, element);\n        ret\n    }\n\n    fn as_ptr(&self) -> *const Self::Item;\n    fn as_mut_ptr(&mut self) -> *mut Self::Item;\n\n    #[inline]\n    fn as_slice(&self) -> &[Self::Item] {\n        unsafe { from_raw_parts(self.as_ptr(), self.len()) }\n    }\n\n    #[inline]\n    fn as_mut_slice(&mut self) -> &mut [Self::Item] {\n        unsafe { from_raw_parts_mut(self.as_mut_ptr(), self.len()) }\n    }\n\n    unsafe fn uninitialized_resize(&mut self, new_len: usize) {\n        let len = self.len();\n        if new_len > len {\n            self.reserve_exact(new_len - len);\n        }\n        self.set_len(new_len);\n    }\n}\n\nimpl<T> Vector for Vec<T> {\n    type Item = T;\n\n    #[inline] fn new() -> Self { Vec::new() }\n    #[inline] fn with_capacity(cap: usize) -> Self { Vec::with_capacity(cap) }\n    #[inline] fn capacity(&self) -> usize { Vec::capacity(self) }\n    #[inline] fn reserve(&mut self, additional: usize) { Vec::reserve(self, additional) }\n    #[inline] fn reserve_exact(&mut self, additional: usize) { Vec::reserve_exact(self, additional) }\n    #[inline] fn shrink_to_fit(&mut self) { Vec::shrink_to_fit(self) }\n    #[inline] fn into_boxed_slice(self) -> Box<[T]> { Vec::into_boxed_slice(self) }\n    #[inline] fn truncate(&mut self, len: usize) { Vec::truncate(self, len) }\n    #[inline] unsafe fn set_len(&mut self, len: usize) { Vec::set_len(self, len) }\n    #[inline] fn swap_remove(&mut self, index: usize) -> T { Vec::swap_remove(self, index) }\n    #[inline] fn insert(&mut self, index: usize, element: T) { Vec::insert(self, index, element) }\n    #[inline] fn remove(&mut self, index: usize) -> T { Vec::remove(self, index) }\n    #[inline] fn retain<F: FnMut(&T) -> bool>(&mut self, f: F) { Vec::retain(self, f) }\n    #[inline] fn push(&mut self, value: T) { Vec::push(self, value) }\n    #[inline] fn pop(&mut self) -> Option<T> { Vec::pop(self) }\n    #[inline] fn clear(&mut self) { Vec::clear(self) }\n    #[inline] fn len(&self) -> usize { Vec::len(self) }\n    #[inline] fn is_empty(&self) -> bool { Vec::is_empty(self) }\n    #[inline] fn as_ptr(&self) -> *const T { self[..].as_ptr() }\n    #[inline] fn as_mut_ptr(&mut self) -> *mut T { self[..].as_mut_ptr() }\n    #[inline] fn as_slice(&self) -> &[T] { &self[..] }\n    #[inline] fn as_mut_slice(&mut self) -> &mut [T] { &mut self[..] }\n}\n"
  },
  {
    "project": "conquer-once",
    "target": 1,
    "commit_id": "06db899114401235392321af8225b55e2290e1f6",
    "func": "//! Generic definition and implementation of the [`OnceCell`] type.\n\nuse core::cell::UnsafeCell;\nuse core::fmt;\nuse core::marker::PhantomData;\nuse core::mem::{self, MaybeUninit};\nuse core::ptr;\nuse core::sync::atomic::Ordering;\n\nuse crate::state::{AtomicOnceState, BlockedState, OnceState, SwapState, TryBlockError};\nuse crate::POISON_PANIC_MSG;\n\n////////////////////////////////////////////////////////////////////////////////////////////////////\n// Unblock (trait)\n////////////////////////////////////////////////////////////////////////////////////////////////////\n\n/// An internal (sealed) trait specifying the unblocking mechanism of a cell\n/// locking strategy.\npub unsafe trait Unblock {\n    /// Unblocks all waiting threads after setting the cell state to `READY`.\n    ///\n    /// # Safety\n    ///\n    /// Must only be called after swapping the cell with `READY` with the state\n    /// returned by the swap operation.\n    unsafe fn on_unblock(state: BlockedState);\n}\n\n////////////////////////////////////////////////////////////////////////////////////////////////////\n// Block (trait)\n////////////////////////////////////////////////////////////////////////////////////////////////////\n\n/// An internal (sealed) trait specifying the blocking mechanism of a cell\n/// locking strategy.\npub unsafe trait Block: Unblock {\n    /// Blocks the current thread until `state` is either `READY` or `POISONED`.\n    fn block(state: &AtomicOnceState);\n}\n\n////////////////////////////////////////////////////////////////////////////////////////////////////\n// OnceCell\n////////////////////////////////////////////////////////////////////////////////////////////////////\n\n/// An interior mutability cell type which allows synchronized one-time\n/// initialization and read-only access exclusively after initialization.\n///\n/// # Poisoning\n///\n/// A thread that panics in the course of executing its `init` function or\n/// closure **poisons** the cell.\n/// All subsequent accesses to a poisoned cell will propagate this and panic\n/// themselves.\npub struct OnceCell<T, B> {\n    /// The current initialization status.\n    state: AtomicOnceState,\n    /// The internal and potentially uninitialized value.\n    inner: UnsafeCell<MaybeUninit<T>>,\n    /// A marker for the blocking strategy (i.e. OS-level block or spin-lock)\n    _marker: PhantomData<B>,\n}\n\n/********** impl Send + Sync **********************************************************************/\n\nunsafe impl<T, B> Send for OnceCell<T, B> where T: Send {}\nunsafe impl<T, B> Sync for OnceCell<T, B> where T: Sync {}\n\n/********** impl inherent *************************************************************************/\n\nimpl<T, B> OnceCell<T, B> {\n    /// Creates a new uninitialized [`OnceCell`].\n    #[inline]\n    pub const fn uninit() -> Self {\n        Self {\n            state: AtomicOnceState::new(),\n            inner: UnsafeCell::new(MaybeUninit::uninit()),\n            _marker: PhantomData,\n        }\n    }\n\n    /// Creates a new [`OnceCell`] pre-initialized with `value`.\n    #[inline]\n    pub const fn new(value: T) -> Self {\n        Self {\n            state: AtomicOnceState::ready(),\n            inner: UnsafeCell::new(MaybeUninit::new(value)),\n            _marker: PhantomData,\n        }\n    }\n\n    /// Consumes `self` and returns a [`Some(T)`](Some) if the [`OnceCell`] has\n    /// previously been successfully initialized or [`None`] otherwise.\n    ///\n    /// # Panics\n    ///\n    /// This method panics if the [`OnceCell`] has been poisoned.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # use conquer_once::spin::OnceCell;\n    ///\n    /// let uninit: OnceCell<i32> = OnceCell::uninit();\n    /// assert!(uninit.into_inner().is_none());\n    ///\n    /// let once = OnceCell::uninit();\n    /// once.init_once(|| \"initialized\");\n    /// assert_eq!(once.into_inner(), Some(\"initialized\"));\n    /// ```\n    #[inline]\n    pub fn into_inner(mut self) -> Option<T> {\n        let res = self.take_inner(false);\n        mem::forget(self);\n        res\n    }\n\n    /// Returns true if the [`OnceCell`] has been successfully initialized.\n    ///\n    /// This method does not panic if the [`OnceCell`] is poisoned and\n    /// never blocks.\n    #[inline]\n    pub fn is_initialized(&self) -> bool {\n        // (cell:1) this acquire load syncs-with the acq-rel swap (guard:2)\n        self.state.load(Ordering::Acquire) == Ok(OnceState::Ready)\n    }\n\n    /// Returns true if the [`OnceCell`] has been poisoned during\n    /// initialization.\n    ///\n    /// This method does not panic if the [`OnceCell`] is poisoned and\n    /// never blocks.\n    /// Once this method has returned `true` all other means of accessing the\n    /// [`OnceCell`] except for further calls to\n    /// [`is_initialized`][OnceCell::is_initialized] or\n    /// [`is_poisoned`][OnceCell::is_poisoned] will lead to a panic\n    #[inline]\n    pub fn is_poisoned(&self) -> bool {\n        self.state.load(Ordering::Relaxed).is_err()\n    }\n\n    /// Returns a reference to the [`OnceCell`]'s initialized inner state or\n    /// an [`Err`].\n    ///\n    /// This method never blocks.\n    ///\n    /// When this function returns with an [`Ok`] result, it is guaranteed that\n    /// some initialization closure has run and completed.\n    /// It is also guaranteed that any memory writes performed by the executed\n    /// closure can be reliably observed by other threads at this point (there\n    /// is a happens-before relation between the closure and code executing\n    /// after the return).\n    ///\n    /// # Errors\n    ///\n    /// This method fails if the [`OnceCell`] is either not initialized\n    /// ([`Uninit`][TryGetError::Uninit]) or is currently being\n    /// initialized by some other thread\n    /// ([`WouldBlock`][TryGetError::WouldBlock]).\n    ///\n    /// # Panics\n    ///\n    /// This method panics if the [`OnceCell`] has been poisoned.\n    #[inline]\n    pub fn try_get(&self) -> Result<&T, TryGetError> {\n        // (cell:2) this acquire load syncs-with the acq-rel swap (guard:2)\n        match self.state.load(Ordering::Acquire).expect(POISON_PANIC_MSG) {\n            OnceState::Ready => Ok(unsafe { self.get_unchecked() }),\n            OnceState::Uninit => Err(TryGetError::Uninit),\n            OnceState::WouldBlock(_) => Err(TryGetError::WouldBlock),\n        }\n    }\n\n    /// Returns a reference to the inner value without checking whether the\n    /// [`OnceCell`] is actually initialized.\n    ///\n    /// # Safety\n    ///\n    /// The caller has to ensure that the cell has been successfully\n    /// initialized, otherwise uninitialized memory will be read.\n    ///\n    /// # Examples\n    ///\n    /// This is one safe way to use this method, although\n    /// [`try_get`][OnceCell::try_get] is the better alternative:\n    ///\n    /// ```\n    /// # #[cfg(feature = \"std\")]\n    /// use conquer_once::OnceCell;\n    /// # #[cfg(not(feature = \"std\"))]\n    /// # use conquer_once::spin::OnceCell;\n    ///\n    /// // let cell = ...\n    /// # let cell = OnceCell::uninit();\n    /// # cell.init_once(|| 0);\n    ///\n    /// let res = if cell.is_initialized() {\n    ///     Some(unsafe { cell.get_unchecked() })\n    /// } else {\n    ///     None\n    /// };\n    ///\n    /// # assert_eq!(res, Some(&0));\n    /// ```\n    #[inline]\n    pub unsafe fn get_unchecked(&self) -> &T {\n        let inner = &*self.inner.get();\n        &*inner.as_ptr()\n    }\n\n    /// Moves the inner cell value out of the [`OnceCell`] and returns it\n    /// wrapped in [`Some`], if it has been successfully initialized.\n    ///\n    /// # Panics\n    ///\n    /// If `ignore_panic` is `false`, this method will panic if the [`OnceCell`]\n    /// has been poisoned, otherwise it will simply return [`None`].\n    #[inline]\n    fn take_inner(&mut self, ignore_panic: bool) -> Option<T> {\n        #[allow(clippy::match_wild_err_arm)]\n        match self.state.load(Ordering::Relaxed) {\n            Err(_) if !ignore_panic => panic!(POISON_PANIC_MSG),\n            Ok(OnceState::Ready) => Some(unsafe { ptr::read(self.get_unchecked()) }),\n            _ => None,\n        }\n    }\n}\n\nimpl<T, B: Unblock> OnceCell<T, B> {\n    /// Attempts to initialize the [`OnceCell`] with `func` if is is\n    /// uninitialized and returns [`Ok(())`](Ok) only if `func` is successfully\n    /// executed.\n    ///\n    /// This method never blocks.\n    ///\n    /// When this function returns with an [`Ok`] or\n    /// [`AlreadyInit`][TryInitError::AlreadyInit] result, it is guaranteed that\n    /// some initialization closure has run and completed (it may not be the\n    /// closure specified).\n    /// It is also guaranteed that any memory writes performed by the executed\n    /// closure can be reliably observed by other threads at this point (there\n    /// is a happens-before relation between the closure and code executing\n    /// after the return).\n    ///\n    /// # Errors\n    ///\n    /// This method fails if the initialization of [`OnceCell`] has already been\n    /// completed previously, in which case an\n    /// [`AlreadyInit`][TryInitError::AlreadyInit] error is returned.\n    /// If another thread is concurrently in the process of initializing it and\n    /// this thread would have to block, a\n    /// [`WouldBlock`][TryInitError::WouldBlock] error is returned.\n    ///\n    /// # Panics\n    ///\n    /// This method panics if the [`OnceCell`] has been poisoned.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[cfg(feature = \"std\")]\n    /// use conquer_once::{OnceCell, TryInitError};\n    /// # #[cfg(not(feature = \"std\"))]\n    /// # use conquer_once::{spin::OnceCell, TryInitError};\n    ///\n    /// let cell = OnceCell::uninit();\n    ///\n    /// // .. in thread 1\n    /// let res = cell.try_init_once(|| {\n    ///     1\n    /// });\n    /// assert!(res.is_ok());\n    ///\n    /// // .. in thread 2\n    /// let res = cell.try_init_once(|| {\n    ///     2\n    /// });\n    /// assert_eq!(res, Err(TryInitError::AlreadyInit));\n    ///\n    /// # assert_eq!(cell.get().copied(), Some(1));\n    /// ```\n    #[inline]\n    pub fn try_init_once(&self, func: impl FnOnce() -> T) -> Result<(), TryInitError> {\n        // (cell:3) this acq load syncs-with the acq-rel swap (guard:2)\n        match self.state.load(Ordering::Acquire).expect(POISON_PANIC_MSG) {\n            OnceState::Ready => Err(TryInitError::AlreadyInit),\n            OnceState::WouldBlock(_) => Err(TryInitError::WouldBlock),\n            OnceState::Uninit => {\n                let mut func = Some(func);\n                self.try_init_inner(&mut || func.take().unwrap()())?;\n                Ok(())\n            }\n        }\n    }\n\n    /// This method is annotated with `#[cold]` in order to keep it out of the\n    /// fast path.\n    #[inline(never)]\n    #[cold]\n    fn try_init_inner(&self, func: &mut dyn FnMut() -> T) -> Result<&T, TryBlockError> {\n        // sets the state to blocked (i.e. guarantees mutual exclusion) or\n        // returns with an error.\n        let guard = PanicGuard::<B>::try_block(&self.state)?;\n        unsafe {\n            let inner = &mut *self.inner.get();\n            inner.as_mut_ptr().write(func());\n        }\n        guard.disarm();\n\n        Ok(unsafe { self.get_unchecked() })\n    }\n\n    /// Returns a reference to the [`OnceCell`]'s initialized inner state or\n    /// otherwise attempts to initialize it with `func` and return the result.\n    ///\n    /// This method never blocks.\n    ///\n    /// When this function returns with an [`Ok`] result, it is guaranteed that\n    /// some initialization closure has run and completed (it may not be the\n    /// closure specified).\n    /// It is also guaranteed that any memory writes performed by the executed\n    /// closure can be reliably observed by other threads at this point (there\n    /// is a happens-before relation between the closure and code executing\n    /// after the return).\n    ///\n    /// # Errors\n    ///\n    /// This method only fails if the calling thread would have to block in case\n    /// another thread is concurrently initializing the [`OnceCell`].\n    ///\n    /// # Panics\n    ///\n    /// This method panics if the [`OnceCell`] has been poisoned.\n    #[inline]\n    pub fn try_get_or_init(&self, func: impl FnOnce() -> T) -> Result<&T, WouldBlockError> {\n        match self.try_get() {\n            Ok(res) => Ok(res),\n            Err(TryGetError::WouldBlock) => Err(WouldBlockError(())),\n            Err(TryGetError::Uninit) => {\n                let mut func = Some(func);\n                let res = self.try_init_inner(&mut || func.take().unwrap()())?;\n                Ok(res)\n            }\n        }\n    }\n}\n\nimpl<T, B: Block> OnceCell<T, B> {\n    /// Returns a reference to the [`OnceCell`]'s initialized inner state or\n    /// [`None`].\n    ///\n    /// This method **blocks** if another thread has already begun initializing\n    /// the [`OnceCell`] concurrently.\n    /// See [`try_get`][OnceCell::try_get] for a non-blocking alternative.\n    ///\n    /// When this function returns with [`Some`], it is guaranteed that some\n    /// initialization closure has run and completed.\n    /// It is also guaranteed that any memory writes performed by the executed\n    /// closure can be reliably observed by other threads at this point (there\n    /// is a happens-before relation between the closure and code executing\n    /// after the return).\n    ///\n    /// # Panics\n    ///\n    /// This method panics if the [`OnceCell`] has been poisoned.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[cfg(feature = \"std\")]\n    /// use conquer_once::OnceCell;\n    /// # #[cfg(not(feature = \"std\"))]\n    /// # use conquer_once::spin::OnceCell;\n    ///\n    /// let cell = OnceCell::uninit();\n    /// assert_eq!(cell.get(), None);\n    /// cell.init_once(|| {\n    ///     1\n    /// });\n    /// assert_eq!(cell.get(), Some(&1));\n    /// ```\n    #[inline]\n    pub fn get(&self) -> Option<&T> {\n        match self.try_get() {\n            Ok(res) => Some(res),\n            Err(TryGetError::WouldBlock) => {\n                B::block(&self.state);\n                Some(unsafe { self.get_unchecked() })\n            }\n            Err(TryGetError::Uninit) => None,\n        }\n    }\n\n    /// Attempts to initialize the [`OnceCell`] with `func` if it is\n    /// uninitialized.\n    ///\n    /// This method **blocks** if another thread has already begun initializing\n    /// the [`OnceCell`] concurrently.\n    ///\n    /// If the initialization of the [`OnceCell`] has already been\n    /// completed previously, this method returns early with minimal\n    /// overhead.\n    ///\n    /// When this function returns, it is guaranteed that some initialization\n    /// closure has run and completed (it may not be the closure specified).\n    /// It is also guaranteed that any memory writes performed by the executed\n    /// closure can be reliably observed by other threads at this point (there\n    /// is a happens-before relation between the closure and code executing\n    /// after the return).\n    ///\n    /// # Panics\n    ///\n    /// This method panics if the [`OnceCell`] has been poisoned.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[cfg(feature = \"std\")]\n    /// use conquer_once::OnceCell;\n    /// # #[cfg(not(feature = \"std\"))]\n    /// # use conquer_once::spin::OnceCell;\n    ///\n    /// let cell = OnceCell::uninit();\n    /// cell.init_once(|| {\n    ///     // expensive calculation\n    ///     (0..1_000).map(|i| i * i).sum::<usize>()\n    /// });\n    ///\n    /// cell.init_once(|| {\n    ///     // any further or concurrent calls to `init_once` will do\n    ///     // nothing and return immediately with almost no overhead.\n    ///     # 0\n    /// });\n    ///\n    /// # let exp = (0..1_000).map(|i| i * i).sum::<usize>();\n    /// # assert_eq!(cell.get().copied(), Some(exp));\n    /// ```\n    #[inline]\n    pub fn init_once(&self, func: impl FnOnce() -> T) {\n        if let Err(TryInitError::WouldBlock) = self.try_init_once(func) {\n            B::block(&self.state);\n        }\n    }\n\n    /// Returns a reference to the [`OnceCell`]'s initialized inner state or\n    /// otherwise attempts to initialize it with `func` and return the result.\n    ///\n    /// This method **blocks** if another thread has already begun\n    /// initializing the [`OnceCell`] concurrently.\n    /// See [`try_get_or_init`][OnceCell::try_get_or_init] for a non-blocking\n    /// alternative.\n    ///\n    /// When this function returns, it is guaranteed that some initialization\n    /// closure has run and completed (it may not be the closure specified).\n    /// It is also guaranteed that any memory writes performed by the executed\n    /// closure can be reliably observed by other threads at this point (there\n    /// is a happens-before relation between the closure and code executing\n    /// after the return).\n    ///\n    /// # Panics\n    ///\n    /// This method panics if the [`OnceCell`] has been poisoned.\n    #[inline]\n    pub fn get_or_init(&self, func: impl FnOnce() -> T) -> &T {\n        match self.try_get_or_init(func) {\n            Ok(res) => res,\n            Err(_) => {\n                B::block(&self.state);\n                // `block` only returns when the state is set to initialized and\n                // acts as an acquire barrier\n                unsafe { self.get_unchecked() }\n            }\n        }\n    }\n}\n\n/********** impl Debug ****************************************************************************/\n\nimpl<T: fmt::Debug, B> fmt::Debug for OnceCell<T, B> {\n    #[inline]\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        f.debug_struct(\"OnceCell\").field(\"inner\", &self.try_get().ok()).finish()\n    }\n}\n\n/********** impl Drop *****************************************************************************/\n\nimpl<T, B> Drop for OnceCell<T, B> {\n    #[inline]\n    fn drop(&mut self) {\n        // drop must never panic\n        mem::drop(self.take_inner(true))\n    }\n}\n\n////////////////////////////////////////////////////////////////////////////////////////////////////\n// TryInitError\n////////////////////////////////////////////////////////////////////////////////////////////////////\n\nconst UNINIT_MSG: &str = \"the `OnceCell` is uninitialized\";\nconst ALREADY_INIT_MSG: &str = \"the `OnceCell` has already been initialized\";\nconst WOULD_BLOCK_MSG: &str = \"the `OnceCell` is currently being initialized\";\n\n/// Possible error variants of non-blocking initialization calls.\n#[derive(Copy, Clone, Debug, Hash, Eq, Ord, PartialEq, PartialOrd)]\npub enum TryInitError {\n    /// The [`OnceCell`] is already initialized and the initialization procedure\n    /// was not called.\n    AlreadyInit,\n    /// The [`OnceCell`] is currently being initialized by another thread and\n    /// the current thread would have to block.\n    WouldBlock,\n}\n\n/*********** impl Display *************************************************************************/\n\nimpl fmt::Display for TryInitError {\n    #[inline]\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        match self {\n            TryInitError::AlreadyInit => write!(f, \"{}\", ALREADY_INIT_MSG),\n            TryInitError::WouldBlock => write!(f, \"{}\", WOULD_BLOCK_MSG),\n        }\n    }\n}\n\n/*********** impl From ****************************************************************************/\n\nimpl From<TryBlockError> for TryInitError {\n    #[inline]\n    fn from(err: TryBlockError) -> Self {\n        match err {\n            TryBlockError::AlreadyInit => TryInitError::AlreadyInit,\n            TryBlockError::WouldBlock(_) => TryInitError::WouldBlock,\n        }\n    }\n}\n\n/*********** impl Error ***************************************************************************/\n\n#[cfg(feature = \"std\")]\nimpl std::error::Error for TryInitError {}\n\n////////////////////////////////////////////////////////////////////////////////////////////////////\n// TryGetError\n////////////////////////////////////////////////////////////////////////////////////////////////////\n\n/// Possible error variants of non-blocking fallible get calls.\n#[derive(Copy, Clone, Debug, Hash, Eq, Ord, PartialEq, PartialOrd)]\npub enum TryGetError {\n    /// The [`OnceCell`] is currently not initialized.\n    Uninit,\n    /// The [`OnceCell`] is currently being initialized by another thread and\n    /// the current thread would have to block.\n    WouldBlock,\n}\n\n/*********** impl Display *************************************************************************/\n\nimpl fmt::Display for TryGetError {\n    #[inline]\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        match self {\n            TryGetError::Uninit => write!(f, \"{}\", UNINIT_MSG),\n            TryGetError::WouldBlock => write!(f, \"{}\", WOULD_BLOCK_MSG),\n        }\n    }\n}\n\n/*********** impl Error ***************************************************************************/\n\n#[cfg(feature = \"std\")]\nimpl std::error::Error for TryGetError {}\n\n////////////////////////////////////////////////////////////////////////////////////////////////////\n// WouldBlockError\n////////////////////////////////////////////////////////////////////////////////////////////////////\n\n/// An error indicating that a [`OnceCell`] would have to block.\n#[derive(Copy, Clone, Debug, Hash, Eq, Ord, PartialEq, PartialOrd)]\npub struct WouldBlockError(());\n\n/*********** impl Display *************************************************************************/\n\nimpl fmt::Display for WouldBlockError {\n    #[inline]\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        write!(f, \"{}\", WOULD_BLOCK_MSG)\n    }\n}\n\n/*********** impl From ****************************************************************************/\n\nimpl From<TryBlockError> for WouldBlockError {\n    #[inline]\n    fn from(err: TryBlockError) -> Self {\n        match err {\n            TryBlockError::AlreadyInit => unreachable!(),\n            TryBlockError::WouldBlock(_) => Self(()),\n        }\n    }\n}\n\n/*********** impl Error ***************************************************************************/\n\n#[cfg(feature = \"std\")]\nimpl std::error::Error for WouldBlockError {}\n\n////////////////////////////////////////////////////////////////////////////////////////////////////\n// PanicGuard\n////////////////////////////////////////////////////////////////////////////////////////////////////\n\n/// A guard for catching panics during the execution of the initialization\n/// closure.\n#[derive(Debug)]\nstruct PanicGuard<'a, B: Unblock> {\n    /// The state of the associated [`OnceCell`].\n    state: &'a AtomicOnceState,\n    /// Flag for indicating if a panic has occurred during the caller supplied\n    /// arbitrary closure.\n    poison: bool,\n    /// A marker for the [`OnceCell`]'s blocking strategy.\n    _marker: PhantomData<B>,\n}\n\nimpl<'a, B: Unblock> PanicGuard<'a, B> {\n    /// Attempts to block the [`OnceCell`] and return a guard on success.\n    #[inline]\n    fn try_block(state: &'a AtomicOnceState) -> Result<Self, TryBlockError> {\n        // (guard:1) this acquire CAS syncs-with the acq-rel swap (guard:2) and the acq-rel CAS\n        // (wait:2)\n        state.try_block(Ordering::Acquire)?;\n        Ok(Self { state, poison: true, _marker: PhantomData })\n    }\n\n    /// Consumes the guard and assures that no panic has occurred.\n    #[inline]\n    fn disarm(mut self) {\n        self.poison = false;\n        mem::drop(self);\n    }\n}\n\n/********** impl Drop *****************************************************************************/\n\nimpl<B: Unblock> Drop for PanicGuard<'_, B> {\n    #[inline]\n    fn drop(&mut self) {\n        let swap = if self.poison { SwapState::Poisoned } else { SwapState::Ready };\n        unsafe {\n            // (guard:2) this acq-rel swap syncs-with the acq-rel CAS (wait:2)\n            // and the acquire loads (cell:1), (cell:2), (wait:1) and the\n            // acquire CAS (guard:1)\n            let prev = self.state.unblock(swap, Ordering::AcqRel);\n            B::on_unblock(prev);\n        }\n    }\n}\n"
  },
  {
    "project": "Rocket",
    "target": 1,
    "commit_id": "c24f15c18f02319be83af4f3c1951dc220b52c5e",
    "func": "use std::fmt::{self, Write};\nuse std::marker::PhantomData;\n\nuse smallvec::SmallVec;\n\nuse crate::uri::{UriPart, Path, Query, UriDisplay, Origin};\n\n/// A struct used to format strings for [`UriDisplay`].\n///\n/// # Marker Generic: `Formatter<Path>` vs. `Formatter<Query>`\n///\n/// Like [`UriDisplay`], the [`UriPart`] parameter `P` in `Formatter<P>` must be\n/// either [`Path`] or [`Query`] resulting in either `Formatter<Path>` or\n/// `Formatter<Query>`. The `Path` version is used when formatting parameters\n/// in the path part of the URI while the `Query` version is used when\n/// formatting parameters in the query part of the URI. The\n/// [`write_named_value()`] method is only available to `UriDisplay<Query>`.\n///\n/// [`UriPart`]: crate::uri::UriPart\n/// [`Path`]: crate::uri::Path\n/// [`Query`]: crate::uri::Query\n///\n/// # Overview\n///\n/// A mutable version of this struct is passed to [`UriDisplay::fmt()`]. This\n/// struct properly formats series of values for use in URIs. In particular,\n/// this struct applies the following transformations:\n///\n///   * When **multiple values** are written, they are separated by `/` for\n///     `Path` types and `&` for `Query` types.\n///\n/// Additionally, for `Formatter<Query>`:\n///\n///   * When a **named value** is written with [`write_named_value()`], the name\n///     is written out, followed by a `=`, followed by the value.\n///\n///   * When **nested named values** are written, typically by passing a value\n///     to [`write_named_value()`] whose implementation of `UriDisplay` also\n///     calls `write_named_vlaue()`, the nested names are joined by a `.`,\n///     written out followed by a `=`, followed by the value.\n///\n/// [`UriDisplay`]: crate::uri::UriDisplay\n/// [`UriDisplay::fmt()`]: crate::uri::UriDisplay::fmt()\n/// [`write_named_value()`]: crate::uri::Formatter::write_named_value()\n///\n/// # Usage\n///\n/// Usage is fairly straightforward:\n///\n///   * For every _named value_ you wish to emit, call [`write_named_value()`].\n///   * For every _unnamed value_ you wish to emit, call [`write_value()`].\n///   * To write a string directly, call [`write_raw()`].\n///\n/// The `write_named_value` method automatically prefixes the `name` to the\n/// written value and, along with `write_value` and `write_raw`, handles nested\n/// calls to `write_named_value` automatically, prefixing names when necessary.\n/// Unlike the other methods, `write_raw` does _not_ prefix any nested names\n/// every time it is called. Instead, it only prefixes the _first_ time it is\n/// called, after a call to `write_named_value` or `write_value`, or after a\n/// call to [`refresh()`].\n///\n/// [`refresh()`]: crate::uri::Formatter::refresh()\n///\n/// # Example\n///\n/// The following example uses all of the `write` methods in a varied order to\n/// display the semantics of `Formatter<Query>`. Note that `UriDisplay` should\n/// rarely be implemented manually, preferring to use the derive, and that this\n/// implementation is purely demonstrative.\n///\n/// ```rust\n/// # extern crate rocket;\n/// use std::fmt;\n///\n/// use rocket::http::uri::{Formatter, UriDisplay, Query};\n///\n/// struct Outer {\n///     value: Inner,\n///     another: usize,\n///     extra: usize\n/// }\n///\n/// struct Inner {\n///     value: usize,\n///     extra: usize\n/// }\n///\n/// impl UriDisplay<Query> for Outer {\n///     fn fmt(&self, f: &mut Formatter<Query>) -> fmt::Result {\n///         f.write_named_value(\"outer_field\", &self.value)?;\n///         f.write_named_value(\"another\", &self.another)?;\n///         f.write_raw(\"out\")?;\n///         f.write_raw(\"side\")?;\n///         f.write_value(&self.extra)\n///     }\n/// }\n///\n/// impl UriDisplay<Query> for Inner {\n///     fn fmt(&self, f: &mut Formatter<Query>) -> fmt::Result {\n///         f.write_named_value(\"inner_field\", &self.value)?;\n///         f.write_value(&self.extra)?;\n///         f.write_raw(\"inside\")\n///     }\n/// }\n///\n/// let inner = Inner { value: 0, extra: 1 };\n/// let outer = Outer { value: inner, another: 2, extra: 3 };\n/// let uri_string = format!(\"{}\", &outer as &UriDisplay<Query>);\n/// assert_eq!(uri_string, \"outer_field.inner_field=0&\\\n///                         outer_field=1&\\\n///                         outer_field=inside&\\\n///                         another=2&\\\n///                         outside&\\\n///                         3\");\n/// ```\n///\n/// Note that you can also use the `write!` macro to write directly to the\n/// formatter as long as the [`std::fmt::Write`] trait is in scope. Internally,\n/// the `write!` macro calls [`write_raw()`], so care must be taken to ensure\n/// that the written string is URI-safe.\n///\n/// ```rust\n/// # #[macro_use] extern crate rocket;\n/// use std::fmt::{self, Write};\n///\n/// use rocket::http::uri::{UriDisplay, Formatter, UriPart, Path, Query};\n///\n/// pub struct Complex(u8, u8);\n///\n/// impl<P: UriPart> UriDisplay<P> for Complex {\n///     fn fmt(&self, f: &mut Formatter<P>) -> fmt::Result {\n///         write!(f, \"{}+{}\", self.0, self.1)\n///     }\n/// }\n///\n/// let uri_string = format!(\"{}\", &Complex(42, 231) as &UriDisplay<Path>);\n/// assert_eq!(uri_string, \"42+231\");\n///\n/// #[derive(UriDisplayQuery)]\n/// struct Message {\n///     number: Complex,\n/// }\n///\n/// let message = Message { number: Complex(42, 47) };\n/// let uri_string = format!(\"{}\", &message as &UriDisplay<Query>);\n/// assert_eq!(uri_string, \"number=42+47\");\n/// ```\n///\n/// [`write_value()`]: crate::uri::Formatter::write_value()\n/// [`write_raw()`]: crate::uri::Formatter::write_raw()\npub struct Formatter<'i, P: UriPart> {\n    prefixes: SmallVec<[&'static str; 3]>,\n    inner: &'i mut (dyn Write + 'i),\n    previous: bool,\n    fresh: bool,\n    _marker: PhantomData<P>,\n}\n\nimpl<'i, P: UriPart> Formatter<'i, P> {\n    #[inline(always)]\n    pub(crate) fn new(inner: &'i mut (dyn Write + 'i)) -> Self {\n        Formatter {\n            inner,\n            prefixes: SmallVec::new(),\n            previous: false,\n            fresh: true,\n            _marker: PhantomData,\n        }\n    }\n\n    #[inline(always)]\n    fn refreshed<F: FnOnce(&mut Self) -> fmt::Result>(&mut self, f: F) -> fmt::Result {\n        self.refresh();\n        let result = f(self);\n        self.refresh();\n        result\n    }\n\n    /// Writes `string` to `self`.\n    ///\n    /// If `self` is _fresh_ (after a call to other `write_` methods or\n    /// [`refresh()`]), prefixes any names and adds separators as necessary.\n    ///\n    /// This method is called by the `write!` macro.\n    ///\n    /// [`refresh()`]: Formatter::refresh()\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// # extern crate rocket;\n    /// use std::fmt;\n    ///\n    /// use rocket::http::uri::{Formatter, UriDisplay, UriPart, Path};\n    ///\n    /// struct Foo;\n    ///\n    /// impl<P: UriPart> UriDisplay<P> for Foo {\n    ///     fn fmt(&self, f: &mut Formatter<P>) -> fmt::Result {\n    ///         f.write_raw(\"f\")?;\n    ///         f.write_raw(\"o\")?;\n    ///         f.write_raw(\"o\")\n    ///     }\n    /// }\n    ///\n    /// let foo = Foo;\n    /// let uri_string = format!(\"{}\", &foo as &UriDisplay<Path>);\n    /// assert_eq!(uri_string, \"foo\");\n    /// ```\n    pub fn write_raw<S: AsRef<str>>(&mut self, string: S) -> fmt::Result {\n        // This implementation is a bit of a lie to the type system. Instead of\n        // implementing this twice, one for <Path> and again for <Query>, we do\n        // this once here. This is okay since we know that this handles the\n        // cases for both Path and Query, and doing it this way allows us to\n        // keep the uri part generic _generic_ in other implementations that use\n        // `write_raw`.\n        if self.fresh && P::DELIMITER == '/' {\n            if self.previous {\n                self.inner.write_char(P::DELIMITER)?;\n            }\n        } else if self.fresh && P::DELIMITER == '&' {\n            if self.previous {\n                self.inner.write_char(P::DELIMITER)?;\n            }\n\n            if !self.prefixes.is_empty() {\n                for (i, prefix) in self.prefixes.iter().enumerate() {\n                    self.inner.write_str(prefix)?;\n                    if i < self.prefixes.len() - 1 {\n                        self.inner.write_str(\".\")?;\n                    }\n                }\n\n                self.inner.write_str(\"=\")?;\n            }\n        }\n\n        self.fresh = false;\n        self.previous = true;\n        self.inner.write_str(string.as_ref())\n    }\n\n    /// Writes the unnamed value `value`. Any nested names are prefixed as\n    /// necessary.\n    ///\n    /// Refreshes `self` before and after the value is written.\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// # extern crate rocket;\n    /// use std::fmt;\n    ///\n    /// use rocket::http::uri::{Formatter, UriDisplay, UriPart, Path, Query};\n    ///\n    /// struct Foo(usize);\n    ///\n    /// impl<P: UriPart> UriDisplay<P> for Foo {\n    ///     fn fmt(&self, f: &mut Formatter<P>) -> fmt::Result {\n    ///         f.write_value(&self.0)\n    ///     }\n    /// }\n    ///\n    /// let foo = Foo(123);\n    ///\n    /// let uri_string = format!(\"{}\", &foo as &UriDisplay<Path>);\n    /// assert_eq!(uri_string, \"123\");\n    ///\n    /// let uri_string = format!(\"{}\", &foo as &UriDisplay<Query>);\n    /// assert_eq!(uri_string, \"123\");\n    /// ```\n    #[inline]\n    pub fn write_value<T: UriDisplay<P>>(&mut self, value: T) -> fmt::Result {\n        self.refreshed(|f| UriDisplay::fmt(&value, f))\n    }\n\n    /// Refreshes the formatter.\n    ///\n    /// After refreshing, [`write_raw()`] will prefix any nested names as well\n    /// as insert a separator.\n    ///\n    /// [`write_raw()`]: Formatter::write_raw()\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// # #[macro_use] extern crate rocket;\n    /// use std::fmt;\n    ///\n    /// use rocket::http::uri::{Formatter, UriDisplay, Query, Path};\n    ///\n    /// struct Foo;\n    ///\n    /// impl UriDisplay<Query> for Foo {\n    ///     fn fmt(&self, f: &mut Formatter<Query>) -> fmt::Result {\n    ///         f.write_raw(\"a\")?;\n    ///         f.write_raw(\"raw\")?;\n    ///         f.refresh();\n    ///         f.write_raw(\"format\")\n    ///     }\n    /// }\n    ///\n    /// let uri_string = format!(\"{}\", &Foo as &UriDisplay<Query>);\n    /// assert_eq!(uri_string, \"araw&format\");\n    ///\n    ///// #[derive(UriDisplayQuery)]\n    ///// struct Message {\n    /////     inner: Foo,\n    ///// }\n    /////\n    ///// let msg = Message { inner: Foo };\n    ///// let uri_string = format!(\"{}\", &msg as &UriDisplay);\n    ///// assert_eq!(uri_string, \"inner=araw&inner=format\");\n    ///\n    /// impl UriDisplay<Path> for Foo {\n    ///     fn fmt(&self, f: &mut Formatter<Path>) -> fmt::Result {\n    ///         f.write_raw(\"a\")?;\n    ///         f.write_raw(\"raw\")?;\n    ///         f.refresh();\n    ///         f.write_raw(\"format\")\n    ///     }\n    /// }\n    ///\n    /// let uri_string = format!(\"{}\", &Foo as &UriDisplay<Path>);\n    /// assert_eq!(uri_string, \"araw/format\");\n    /// ```\n    #[inline(always)]\n    pub fn refresh(&mut self) {\n        self.fresh = true;\n    }\n}\n\nimpl Formatter<'_, Query> {\n    fn with_prefix<F>(&mut self, prefix: &str, f: F) -> fmt::Result\n        where F: FnOnce(&mut Self) -> fmt::Result\n    {\n        // The `prefix` string is pushed in a `StackVec` for use by recursive\n        // (nested) calls to `write_raw`. The string is pushed here and then\n        // popped here. `self.prefixes` is modified nowhere else, and no strings\n        // leak from the the vector. As a result, it is impossible for a\n        // `prefix` to be accessed incorrectly as:\n        //\n        //   * Rust _guarantees_ it exists for the lifetime of this method\n        //   * it is only reachable while this method's stack is active because\n        //     it is popped before this method returns\n        //   * thus, at any point that it's reachable, it's valid\n        //\n        // Said succinctly: this `prefixes` stack shadows a subset of the\n        // `with_prefix` stack precisely, making it reachable to other code.\n        let prefix: &'static str = unsafe { std::mem::transmute(prefix) };\n\n        self.prefixes.push(prefix);\n        let result = f(self);\n        self.prefixes.pop();\n\n        result\n    }\n\n    /// Writes the named value `value` by prefixing `name` followed by `=` to\n    /// the value. Any nested names are also prefixed as necessary.\n    ///\n    /// Refreshes `self` before the name is written and after the value is\n    /// written.\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// # extern crate rocket;\n    /// use std::fmt;\n    ///\n    /// use rocket::http::uri::{Formatter, UriDisplay, Query};\n    ///\n    /// struct Foo {\n    ///     name: usize\n    /// }\n    ///\n    /// // Note: This is identical to what #[derive(UriDisplayQuery)] would\n    /// // generate! In practice, _always_ use the derive.\n    /// impl UriDisplay<Query> for Foo {\n    ///     fn fmt(&self, f: &mut Formatter<Query>) -> fmt::Result {\n    ///         f.write_named_value(\"name\", &self.name)\n    ///     }\n    /// }\n    ///\n    /// let foo = Foo { name: 123 };\n    /// let uri_string = format!(\"{}\", &foo as &UriDisplay<Query>);\n    /// assert_eq!(uri_string, \"name=123\");\n    /// ```\n    #[inline]\n    pub fn write_named_value<T: UriDisplay<Query>>(&mut self, name: &str, value: T) -> fmt::Result {\n        self.refreshed(|f| f.with_prefix(name, |f| f.write_value(value)))\n    }\n}\n\nimpl<P: UriPart> fmt::Write for Formatter<'_, P> {\n    fn write_str(&mut self, s: &str) -> fmt::Result {\n        self.write_raw(s)\n    }\n}\n\n// Used by code generation.\n#[doc(hidden)]\npub enum UriArgumentsKind<A> {\n    Static(&'static str),\n    Dynamic(A)\n}\n\n// Used by code generation.\n#[doc(hidden)]\npub enum UriQueryArgument<'a> {\n    Raw(&'a str),\n    NameValue(&'a str, &'a dyn UriDisplay<Query>),\n    Value(&'a dyn UriDisplay<Query>)\n}\n\n// Used by code generation.\n#[doc(hidden)]\npub struct UriArguments<'a> {\n    pub path: UriArgumentsKind<&'a [&'a dyn UriDisplay<Path>]>,\n    pub query: Option<UriArgumentsKind<&'a [UriQueryArgument<'a>]>>,\n}\n\n// Used by code generation.\nimpl UriArguments<'_> {\n    #[doc(hidden)]\n    pub fn into_origin(self) -> Origin<'static> {\n        use std::borrow::Cow;\n        use self::{UriArgumentsKind::*, UriQueryArgument::*};\n\n        let path: Cow<'static, str> = match self.path {\n            Static(path) => path.into(),\n            Dynamic(args) => {\n                let mut string = String::from(\"/\");\n                {\n                    let mut formatter = Formatter::<Path>::new(&mut string);\n                    for value in args {\n                        let _ = formatter.write_value(value);\n                    }\n                }\n\n                string.into()\n            }\n        };\n\n        let query: Option<Cow<'_, str>> = self.query.and_then(|q| match q {\n            Static(query) => Some(query.into()),\n            Dynamic(args) if args.is_empty() => None,\n            Dynamic(args) => {\n                let mut string = String::new();\n                {\n                    let mut f = Formatter::<Query>::new(&mut string);\n                    for arg in args {\n                        let _ = match arg {\n                            Raw(v) => f.write_raw(v),\n                            NameValue(n, v) => f.write_named_value(n, v),\n                            Value(v) => f.write_value(v),\n                        };\n                    }\n                }\n\n                match string.is_empty() {\n                    false => Some(string.into()),\n                    true => None,\n                }\n            }\n        });\n\n        Origin::new(path, query)\n    }\n}\n"
  },
  {
    "project": "futures-intrusive",
    "target": 1,
    "commit_id": "9ee6993ec7619f87dbbf0c995c19ef24b26586e6",
    "func": "//! An asynchronously awaitable mutex for synchronization between concurrently\n//! executing futures.\n\nuse crate::{\n    intrusive_double_linked_list::{LinkedList, ListNode},\n    utils::update_waker_ref,\n    NoopLock,\n};\nuse core::{\n    cell::UnsafeCell,\n    ops::{Deref, DerefMut},\n    pin::Pin,\n};\nuse futures_core::{\n    future::{FusedFuture, Future},\n    task::{Context, Poll, Waker},\n};\nuse lock_api::{Mutex as LockApiMutex, RawMutex};\n\n/// Tracks how the future had interacted with the mutex\n#[derive(PartialEq)]\nenum PollState {\n    /// The task has never interacted with the mutex.\n    New,\n    /// The task was added to the wait queue at the mutex.\n    Waiting,\n    /// The task had previously waited on the mutex, but was notified\n    /// that the mutex was released in the meantime.\n    Notified,\n    /// The task had been polled to completion.\n    Done,\n}\n\n/// Tracks the MutexLockFuture waiting state.\n/// Access to this struct is synchronized through the mutex in the Event.\nstruct WaitQueueEntry {\n    /// The task handle of the waiting task\n    task: Option<Waker>,\n    /// Current polling state\n    state: PollState,\n}\n\nimpl WaitQueueEntry {\n    /// Creates a new WaitQueueEntry\n    fn new() -> WaitQueueEntry {\n        WaitQueueEntry {\n            task: None,\n            state: PollState::New,\n        }\n    }\n}\n\n/// Internal state of the `Mutex`\nstruct MutexState {\n    is_fair: bool,\n    is_locked: bool,\n    waiters: LinkedList<WaitQueueEntry>,\n}\n\nimpl MutexState {\n    fn new(is_fair: bool) -> Self {\n        MutexState {\n            is_fair,\n            is_locked: false,\n            waiters: LinkedList::new(),\n        }\n    }\n\n    /// Returns the `Waker` associated with the up the last waiter\n    ///\n    /// If the Mutex is not fair, removes the associated wait node also from\n    /// the wait queue\n    fn return_last_waiter(&mut self) -> Option<Waker> {\n        let last_waiter = if self.is_fair {\n            self.waiters.peek_last()\n        } else {\n            self.waiters.remove_last()\n        };\n\n        if let Some(last_waiter) = last_waiter {\n            // Notify the waiter that it can try to lock the mutex again.\n            // The notification gets tracked inside the waiter.\n            // If the waiter aborts it's wait (drops the future), another task\n            // must be woken.\n            last_waiter.state = PollState::Notified;\n\n            let task = &mut last_waiter.task;\n            return task.take();\n        }\n\n        None\n    }\n\n    fn is_locked(&self) -> bool {\n        self.is_locked\n    }\n\n    /// Unlocks the mutex\n    ///\n    /// This is expected to be only called from the current holder of the mutex.\n    /// The method returns the `Waker` which is associated with the task that\n    /// needs to get woken due to the unlock.\n    fn unlock(&mut self) -> Option<Waker> {\n        if self.is_locked {\n            self.is_locked = false;\n            // TODO: Does this require a memory barrier for the actual data,\n            // or is this covered by unlocking the mutex which protects the data?\n            // Wakeup the last waiter\n            self.return_last_waiter()\n        } else {\n            None\n        }\n    }\n\n    /// Tries to lock the mutex synchronously.\n    ///\n    /// Returns true if the lock obtained and false otherwise.\n    fn try_lock_sync(&mut self) -> bool {\n        // The lock can only be obtained synchronously if\n        // - it is not locked\n        // - the Semaphore is either not fair, or there are no waiters\n        // - required_permits == 0\n        if !self.is_locked && (!self.is_fair || self.waiters.is_empty()) {\n            self.is_locked = true;\n            true\n        } else {\n            false\n        }\n    }\n\n    /// Tries to acquire the Mutex from a WaitQueueEntry.\n    ///\n    /// If it isn't available, the WaitQueueEntry gets added to the wait\n    /// queue at the Mutex, and will be signalled once ready.\n    /// This function is only safe as long as the `wait_node`s address is guaranteed\n    /// to be stable until it gets removed from the queue.\n    unsafe fn try_lock(\n        &mut self,\n        wait_node: &mut ListNode<WaitQueueEntry>,\n        cx: &mut Context<'_>,\n    ) -> Poll<()> {\n        match wait_node.state {\n            PollState::New => {\n                // The fast path - the Mutex isn't locked by anyone else.\n                // If the mutex is fair, noone must be in the wait list before us.\n                if self.try_lock_sync() {\n                    wait_node.state = PollState::Done;\n                    Poll::Ready(())\n                } else {\n                    // Add the task to the wait queue\n                    wait_node.task = Some(cx.waker().clone());\n                    wait_node.state = PollState::Waiting;\n                    self.waiters.add_front(wait_node);\n                    Poll::Pending\n                }\n            }\n            PollState::Waiting => {\n                // The MutexLockFuture is already in the queue.\n                if self.is_fair {\n                    // The task needs to wait until it gets notified in order to\n                    // maintain the ordering. However the caller might have\n                    // passed a different `Waker`. In this case we need to update it.\n                    update_waker_ref(&mut wait_node.task, cx);\n                    Poll::Pending\n                } else {\n                    // For throughput improvement purposes, grab the lock immediately\n                    // if it's available.\n                    if !self.is_locked {\n                        self.is_locked = true;\n                        wait_node.state = PollState::Done;\n                        // Since this waiter has been registered before, it must\n                        // get removed from the waiter list.\n                        // Safety: Due to the state, we know that the node must be part\n                        // of the waiter list\n                        self.force_remove_waiter(wait_node);\n                        Poll::Ready(())\n                    } else {\n                        // The caller might have passed a different `Waker`.\n                        // In this case we need to update it.\n                        update_waker_ref(&mut wait_node.task, cx);\n                        Poll::Pending\n                    }\n                }\n            }\n            PollState::Notified => {\n                // We had been woken by the mutex, since the mutex is available again.\n                // The mutex thereby removed us from the waiters list.\n                // Just try to lock again. If the mutex isn't available,\n                // we need to add it to the wait queue again.\n                if !self.is_locked {\n                    if self.is_fair {\n                        // In a fair Mutex, the WaitQueueEntry is kept in the\n                        // linked list and must be removed here\n                        // Safety: Due to the state, we know that the node must be part\n                        // of the waiter list\n                        self.force_remove_waiter(wait_node);\n                    }\n                    self.is_locked = true;\n                    wait_node.state = PollState::Done;\n                    Poll::Ready(())\n                } else {\n                    // Fair mutexes should always be able to acquire the lock\n                    // after they had been notified\n                    debug_assert!(!self.is_fair);\n                    // Add to queue\n                    wait_node.task = Some(cx.waker().clone());\n                    wait_node.state = PollState::Waiting;\n                    self.waiters.add_front(wait_node);\n                    Poll::Pending\n                }\n            }\n            PollState::Done => {\n                // The future had been polled to completion before\n                panic!(\"polled Mutex after completion\");\n            }\n        }\n    }\n\n    /// Tries to remove a waiter from the wait queue, and panics if the\n    /// waiter is no longer valid.\n    unsafe fn force_remove_waiter(\n        &mut self,\n        wait_node: &mut ListNode<WaitQueueEntry>,\n    ) {\n        if !self.waiters.remove(wait_node) {\n            // Panic if the address isn't found. This can only happen if the contract was\n            // violated, e.g. the WaitQueueEntry got moved after the initial poll.\n            panic!(\"Future could not be removed from wait queue\");\n        }\n    }\n\n    /// Removes the waiter from the list.\n    ///\n    /// This function is only safe as long as the reference that is passed here\n    /// equals the reference/address under which the waiter was added.\n    /// The waiter must not have been moved in between.\n    ///\n    /// Returns the `Waker` of another task which might get ready to run due to\n    /// this.\n    fn remove_waiter(\n        &mut self,\n        wait_node: &mut ListNode<WaitQueueEntry>,\n    ) -> Option<Waker> {\n        // MutexLockFuture only needs to get removed if it had been added to\n        // the wait queue of the Mutex. This has happened in the PollState::Waiting case.\n        // If the current waiter was notified, another waiter must get notified now.\n        match wait_node.state {\n            PollState::Notified => {\n                if self.is_fair {\n                    // In a fair Mutex, the WaitQueueEntry is kept in the\n                    // linked list and must be removed here\n                    // Safety: Due to the state, we know that the node must be part\n                    // of the waiter list\n                    unsafe { self.force_remove_waiter(wait_node) };\n                }\n                wait_node.state = PollState::Done;\n                // Since the task was notified but did not lock the Mutex,\n                // another task gets the chance to run.\n                self.return_last_waiter()\n            }\n            PollState::Waiting => {\n                // Remove the WaitQueueEntry from the linked list\n                // Safety: Due to the state, we know that the node must be part\n                // of the waiter list\n                unsafe { self.force_remove_waiter(wait_node) };\n                wait_node.state = PollState::Done;\n                None\n            }\n            PollState::New | PollState::Done => None,\n        }\n    }\n}\n\n/// An RAII guard returned by the `lock` and `try_lock` methods.\n/// When this structure is dropped (falls out of scope), the lock will be\n/// unlocked.\npub struct GenericMutexGuard<'a, MutexType: RawMutex, T: 'a> {\n    /// The Mutex which is associated with this Guard\n    mutex: &'a GenericMutex<MutexType, T>,\n}\n\nimpl<MutexType: RawMutex, T: core::fmt::Debug> core::fmt::Debug\n    for GenericMutexGuard<'_, MutexType, T>\n{\n    fn fmt(&self, f: &mut core::fmt::Formatter) -> core::fmt::Result {\n        f.debug_struct(\"GenericMutexGuard\").finish()\n    }\n}\n\nimpl<MutexType: RawMutex, T> Drop for GenericMutexGuard<'_, MutexType, T> {\n    fn drop(&mut self) {\n        // Release the mutex\n        let waker = { self.mutex.state.lock().unlock() };\n        if let Some(waker) = waker {\n            waker.wake();\n        }\n    }\n}\n\nimpl<MutexType: RawMutex, T> Deref for GenericMutexGuard<'_, MutexType, T> {\n    type Target = T;\n    fn deref(&self) -> &T {\n        unsafe { &*self.mutex.value.get() }\n    }\n}\n\nimpl<MutexType: RawMutex, T> DerefMut for GenericMutexGuard<'_, MutexType, T> {\n    fn deref_mut(&mut self) -> &mut T {\n        unsafe { &mut *self.mutex.value.get() }\n    }\n}\n\n/// A future which resolves when the target mutex has been successfully acquired.\n#[must_use = \"futures do nothing unless polled\"]\npub struct GenericMutexLockFuture<'a, MutexType: RawMutex, T: 'a> {\n    /// The Mutex which should get locked trough this Future\n    mutex: Option<&'a GenericMutex<MutexType, T>>,\n    /// Node for waiting at the mutex\n    wait_node: ListNode<WaitQueueEntry>,\n}\n\n// Safety: Futures can be sent between threads as long as the underlying\n// mutex is thread-safe (Sync), which allows to poll/register/unregister from\n// a different thread.\nunsafe impl<'a, MutexType: RawMutex + Sync, T: 'a> Send\n    for GenericMutexLockFuture<'a, MutexType, T>\n{\n}\n\nimpl<'a, MutexType: RawMutex, T: core::fmt::Debug> core::fmt::Debug\n    for GenericMutexLockFuture<'a, MutexType, T>\n{\n    fn fmt(&self, f: &mut core::fmt::Formatter) -> core::fmt::Result {\n        f.debug_struct(\"GenericMutexLockFuture\").finish()\n    }\n}\n\nimpl<'a, MutexType: RawMutex, T> Future\n    for GenericMutexLockFuture<'a, MutexType, T>\n{\n    type Output = GenericMutexGuard<'a, MutexType, T>;\n\n    fn poll(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> {\n        // Safety: The next operations are safe, because Pin promises us that\n        // the address of the wait queue entry inside GenericMutexLockFuture is stable,\n        // and we don't move any fields inside the future until it gets dropped.\n        let mut_self: &mut GenericMutexLockFuture<MutexType, T> =\n            unsafe { Pin::get_unchecked_mut(self) };\n\n        let mutex = mut_self\n            .mutex\n            .expect(\"polled GenericMutexLockFuture after completion\");\n        let mut mutex_state = mutex.state.lock();\n\n        let poll_res =\n            unsafe { mutex_state.try_lock(&mut mut_self.wait_node, cx) };\n\n        match poll_res {\n            Poll::Pending => Poll::Pending,\n            Poll::Ready(()) => {\n                // The mutex was acquired\n                mut_self.mutex = None;\n                Poll::Ready(GenericMutexGuard::<'a, MutexType, T> { mutex })\n            }\n        }\n    }\n}\n\nimpl<'a, MutexType: RawMutex, T> FusedFuture\n    for GenericMutexLockFuture<'a, MutexType, T>\n{\n    fn is_terminated(&self) -> bool {\n        self.mutex.is_none()\n    }\n}\n\nimpl<'a, MutexType: RawMutex, T> Drop\n    for GenericMutexLockFuture<'a, MutexType, T>\n{\n    fn drop(&mut self) {\n        // If this GenericMutexLockFuture has been polled and it was added to the\n        // wait queue at the mutex, it must be removed before dropping.\n        // Otherwise the mutex would access invalid memory.\n        let waker = if let Some(mutex) = self.mutex {\n            let mut mutex_state = mutex.state.lock();\n            mutex_state.remove_waiter(&mut self.wait_node)\n        } else {\n            None\n        };\n\n        if let Some(waker) = waker {\n            waker.wake();\n        }\n    }\n}\n\n/// A futures-aware mutex.\npub struct GenericMutex<MutexType: RawMutex, T> {\n    value: UnsafeCell<T>,\n    state: LockApiMutex<MutexType, MutexState>,\n}\n\n// It is safe to send mutexes between threads, as long as they are not used and\n// thereby borrowed\nunsafe impl<T: Send, MutexType: RawMutex + Send> Send\n    for GenericMutex<MutexType, T>\n{\n}\n// The mutex is thread-safe as long as the utilized mutex is thread-safe\nunsafe impl<T: Send, MutexType: RawMutex + Sync> Sync\n    for GenericMutex<MutexType, T>\n{\n}\n\nimpl<MutexType: RawMutex, T: core::fmt::Debug> core::fmt::Debug\n    for GenericMutex<MutexType, T>\n{\n    fn fmt(&self, f: &mut core::fmt::Formatter) -> core::fmt::Result {\n        f.debug_struct(\"Mutex\")\n            .field(\"is_locked\", &self.is_locked())\n            .finish()\n    }\n}\n\nimpl<MutexType: RawMutex, T> GenericMutex<MutexType, T> {\n    /// Creates a new futures-aware mutex.\n    ///\n    /// `is_fair` defines whether the `Mutex` should behave be fair regarding the\n    /// order of waiters. A fair `Mutex` will only allow the first waiter which\n    /// tried to lock but failed to lock the `Mutex` once it's available again.\n    /// Other waiters must wait until either this locking attempt completes, and\n    /// the `Mutex` gets unlocked again, or until the `MutexLockFuture` which\n    /// tried to gain the lock is dropped.\n    pub fn new(value: T, is_fair: bool) -> GenericMutex<MutexType, T> {\n        GenericMutex::<MutexType, T> {\n            value: UnsafeCell::new(value),\n            state: LockApiMutex::new(MutexState::new(is_fair)),\n        }\n    }\n\n    /// Acquire the mutex asynchronously.\n    ///\n    /// This method returns a future that will resolve once the mutex has been\n    /// successfully acquired.\n    pub fn lock(&self) -> GenericMutexLockFuture<'_, MutexType, T> {\n        GenericMutexLockFuture::<MutexType, T> {\n            mutex: Some(&self),\n            wait_node: ListNode::new(WaitQueueEntry::new()),\n        }\n    }\n\n    /// Tries to acquire the mutex\n    ///\n    /// If acquiring the mutex is successful, a [`GenericMutexGuard`]\n    /// will be returned, which allows to access the contained data.\n    ///\n    /// Otherwise `None` will be returned.\n    pub fn try_lock(&self) -> Option<GenericMutexGuard<'_, MutexType, T>> {\n        if self.state.lock().try_lock_sync() {\n            Some(GenericMutexGuard { mutex: self })\n        } else {\n            None\n        }\n    }\n\n    /// Returns whether the mutex is locked.\n    pub fn is_locked(&self) -> bool {\n        self.state.lock().is_locked()\n    }\n}\n\n// Export a non thread-safe version using NoopLock\n\n/// A [`GenericMutex`] which is not thread-safe.\npub type LocalMutex<T> = GenericMutex<NoopLock, T>;\n/// A [`GenericMutexGuard`] for [`LocalMutex`].\npub type LocalMutexGuard<'a, T> = GenericMutexGuard<'a, NoopLock, T>;\n/// A [`GenericMutexLockFuture`] for [`LocalMutex`].\npub type LocalMutexLockFuture<'a, T> = GenericMutexLockFuture<'a, NoopLock, T>;\n\n#[cfg(feature = \"alloc\")]\nmod if_alloc {\n    use super::*;\n\n    // Export a thread-safe version using parking_lot::RawMutex\n\n    /// A [`GenericMutex`] backed by [`parking_lot`].\n    pub type Mutex<T> = GenericMutex<parking_lot::RawMutex, T>;\n    /// A [`GenericMutexGuard`] for [`Mutex`].\n    pub type MutexGuard<'a, T> =\n        GenericMutexGuard<'a, parking_lot::RawMutex, T>;\n    /// A [`GenericMutexLockFuture`] for [`Mutex`].\n    pub type MutexLockFuture<'a, T> =\n        GenericMutexLockFuture<'a, parking_lot::RawMutex, T>;\n}\n\n#[cfg(feature = \"alloc\")]\npub use self::if_alloc::*;\n"
  },
  {
    "project": "prost",
    "target": 1,
    "commit_id": "0833d467bd55ee7ff427e0484fc299366ad9ab7d",
    "func": "#![doc(html_root_url = \"https://docs.rs/prost-types/0.7.0\")]\n\n//! Protocol Buffers well-known types.\n//!\n//! Note that the documentation for the types defined in this crate are generated from the Protobuf\n//! definitions, so code examples are not in Rust.\n//!\n//! See the [Protobuf reference][1] for more information about well-known types.\n//!\n//! [1]: https://developers.google.com/protocol-buffers/docs/reference/google.protobuf\n\n#![cfg_attr(not(feature = \"std\"), no_std)]\n\nuse core::convert::TryFrom;\nuse core::i32;\nuse core::i64;\nuse core::time;\n\ninclude!(\"protobuf.rs\");\npub mod compiler {\n    include!(\"compiler.rs\");\n}\n\n// The Protobuf `Duration` and `Timestamp` types can't delegate to the standard library equivalents\n// because the Protobuf versions are signed. To make them easier to work with, `From` conversions\n// are defined in both directions.\n\nconst NANOS_PER_SECOND: i32 = 1_000_000_000;\n\nimpl Duration {\n    /// Normalizes the duration to a canonical format.\n    ///\n    /// Based on [`google::protobuf::util::CreateNormalized`][1].\n    /// [1]: https://github.com/google/protobuf/blob/v3.3.2/src/google/protobuf/util/time_util.cc#L79-L100\n    pub fn normalize(&mut self) {\n        // Make sure nanos is in the range.\n        if self.nanos <= -NANOS_PER_SECOND || self.nanos >= NANOS_PER_SECOND {\n            self.seconds += (self.nanos / NANOS_PER_SECOND) as i64;\n            self.nanos %= NANOS_PER_SECOND;\n        }\n\n        // nanos should have the same sign as seconds.\n        if self.seconds < 0 && self.nanos > 0 {\n            self.seconds += 1;\n            self.nanos -= NANOS_PER_SECOND;\n        } else if self.seconds > 0 && self.nanos < 0 {\n            self.seconds -= 1;\n            self.nanos += NANOS_PER_SECOND;\n        }\n        // TODO: should this be checked?\n        // debug_assert!(self.seconds >= -315_576_000_000 && self.seconds <= 315_576_000_000,\n        //               \"invalid duration: {:?}\", self);\n    }\n}\n\n/// Converts a `std::time::Duration` to a `Duration`.\nimpl From<time::Duration> for Duration {\n    fn from(duration: time::Duration) -> Duration {\n        let seconds = duration.as_secs();\n        let seconds = if seconds > i64::MAX as u64 {\n            i64::MAX\n        } else {\n            seconds as i64\n        };\n        let nanos = duration.subsec_nanos();\n        let nanos = if nanos > i32::MAX as u32 {\n            i32::MAX\n        } else {\n            nanos as i32\n        };\n        let mut duration = Duration { seconds, nanos };\n        duration.normalize();\n        duration\n    }\n}\n\nimpl TryFrom<Duration> for time::Duration {\n    type Error = time::Duration;\n\n    /// Converts a `Duration` to a result containing a positive (`Ok`) or negative (`Err`)\n    /// `std::time::Duration`.\n    fn try_from(mut duration: Duration) -> Result<time::Duration, time::Duration> {\n        duration.normalize();\n        if duration.seconds >= 0 {\n            Ok(time::Duration::new(\n                duration.seconds as u64,\n                duration.nanos as u32,\n            ))\n        } else {\n            Err(time::Duration::new(\n                (-duration.seconds) as u64,\n                (-duration.nanos) as u32,\n            ))\n        }\n    }\n}\n\nimpl Timestamp {\n    /// Normalizes the timestamp to a canonical format.\n    ///\n    /// Based on [`google::protobuf::util::CreateNormalized`][1].\n    /// [1]: https://github.com/google/protobuf/blob/v3.3.2/src/google/protobuf/util/time_util.cc#L59-L77\n    #[cfg(feature = \"std\")]\n    pub fn normalize(&mut self) {\n        // Make sure nanos is in the range.\n        if self.nanos <= -NANOS_PER_SECOND || self.nanos >= NANOS_PER_SECOND {\n            self.seconds += (self.nanos / NANOS_PER_SECOND) as i64;\n            self.nanos %= NANOS_PER_SECOND;\n        }\n\n        // For Timestamp nanos should be in the range [0, 999999999].\n        if self.nanos < 0 {\n            self.seconds -= 1;\n            self.nanos += NANOS_PER_SECOND;\n        }\n\n        // TODO: should this be checked?\n        // debug_assert!(self.seconds >= -62_135_596_800 && self.seconds <= 253_402_300_799,\n        //               \"invalid timestamp: {:?}\", self);\n    }\n}\n\n#[cfg(feature = \"std\")]\nimpl From<std::time::SystemTime> for Timestamp {\n    fn from(system_time: std::time::SystemTime) -> Timestamp {\n        let (seconds, nanos) = match system_time.duration_since(std::time::UNIX_EPOCH) {\n            Ok(duration) => {\n                let seconds = i64::try_from(duration.as_secs()).unwrap();\n                (seconds, duration.subsec_nanos() as i32)\n            }\n            Err(error) => {\n                let duration = error.duration();\n                let seconds = i64::try_from(duration.as_secs()).unwrap();\n                let nanos = duration.subsec_nanos() as i32;\n                if nanos == 0 {\n                    (-seconds, 0)\n                } else {\n                    (-seconds - 1, 1_000_000_000 - nanos)\n                }\n            }\n        };\n        Timestamp { seconds, nanos }\n    }\n}\n\n#[cfg(feature = \"std\")]\nimpl From<Timestamp> for std::time::SystemTime {\n    fn from(mut timestamp: Timestamp) -> std::time::SystemTime {\n        timestamp.normalize();\n        let system_time = if timestamp.seconds >= 0 {\n            std::time::UNIX_EPOCH + time::Duration::from_secs(timestamp.seconds as u64)\n        } else {\n            std::time::UNIX_EPOCH - time::Duration::from_secs((-timestamp.seconds) as u64)\n        };\n\n        system_time + time::Duration::from_nanos(timestamp.nanos as u64)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use std::time::{Duration, SystemTime, UNIX_EPOCH};\n\n    use proptest::prelude::*;\n\n    use super::*;\n\n    #[cfg(feature = \"std\")]\n    proptest! {\n        #[test]\n        fn check_system_time_roundtrip(\n            system_time in SystemTime::arbitrary(),\n        ) {\n            prop_assert_eq!(SystemTime::from(Timestamp::from(system_time)), system_time);\n        }\n    }\n\n    #[cfg(feature = \"std\")]\n    #[test]\n    fn check_timestamp_negative_seconds() {\n        // Representative tests for the case of timestamps before the UTC Epoch time:\n        // validate the expected behaviour that \"negative second values with fractions\n        // must still have non-negative nanos values that count forward in time\"\n        // https://developers.google.com/protocol-buffers/docs/reference/google.protobuf#google.protobuf.Timestamp\n        //\n        // To ensure cross-platform compatibility, all nanosecond values in these\n        // tests are in minimum 100 ns increments.  This does not affect the general\n        // character of the behaviour being tested, but ensures that the tests are\n        // valid for both POSIX (1 ns precision) and Windows (100 ns precision).\n        assert_eq!(\n            Timestamp::from(UNIX_EPOCH - Duration::new(1_001, 0)),\n            Timestamp {\n                seconds: -1_001,\n                nanos: 0\n            }\n        );\n        assert_eq!(\n            Timestamp::from(UNIX_EPOCH - Duration::new(0, 999_999_900)),\n            Timestamp {\n                seconds: -1,\n                nanos: 100\n            }\n        );\n        assert_eq!(\n            Timestamp::from(UNIX_EPOCH - Duration::new(2_001_234, 12_300)),\n            Timestamp {\n                seconds: -2_001_235,\n                nanos: 999_987_700\n            }\n        );\n        assert_eq!(\n            Timestamp::from(UNIX_EPOCH - Duration::new(768, 65_432_100)),\n            Timestamp {\n                seconds: -769,\n                nanos: 934_567_900\n            }\n        );\n    }\n\n    #[cfg(all(unix, feature = \"std\"))]\n    #[test]\n    fn check_timestamp_negative_seconds_1ns() {\n        // UNIX-only test cases with 1 ns precision\n        assert_eq!(\n            Timestamp::from(UNIX_EPOCH - Duration::new(0, 999_999_999)),\n            Timestamp {\n                seconds: -1,\n                nanos: 1\n            }\n        );\n        assert_eq!(\n            Timestamp::from(UNIX_EPOCH - Duration::new(1_234_567, 123)),\n            Timestamp {\n                seconds: -1_234_568,\n                nanos: 999_999_877\n            }\n        );\n        assert_eq!(\n            Timestamp::from(UNIX_EPOCH - Duration::new(890, 987_654_321)),\n            Timestamp {\n                seconds: -891,\n                nanos: 12_345_679\n            }\n        );\n    }\n}\n"
  },
  {
    "project": "nano-arena",
    "target": 1,
    "commit_id": "f5306c73a0f8f260eb49f9f0a8509ef85f038244",
    "func": "use std::borrow::Borrow;\nuse std::hash::{Hash, Hasher};\nuse std::iter::FromIterator;\nuse std::sync::{\n    atomic::{AtomicBool, AtomicUsize, Ordering},\n    Arc,\n};\n\nmod split;\n\nuse split::ArenaSplit;\n\nstruct IdxInner {\n    index: AtomicUsize,\n    removed: AtomicBool,\n}\n\nimpl IdxInner {\n    fn index(&self) -> Option<usize> {\n        let removed = self.removed.load(Ordering::Relaxed);\n        if !removed {\n            Some(self.index.load(Ordering::Relaxed))\n        } else {\n            None\n        }\n    }\n}\n\n#[derive(Clone)]\npub struct Idx {\n    inner: Arc<IdxInner>,\n}\n\nimpl std::fmt::Debug for Idx {\n    fn fmt(&self, formatter: &mut std::fmt::Formatter<'_>) -> Result<(), std::fmt::Error> {\n        formatter.write_str(&format!(\n            \"{}Idx ( {} )\",\n            if self.inner.removed.load(Ordering::Relaxed) {\n                \"Removed \"\n            } else {\n                \"\"\n            },\n            self.inner.index.load(Ordering::Relaxed)\n        ))\n    }\n}\n\nimpl Idx {\n    pub fn value(&self) -> Option<usize> {\n        self.inner.index()\n    }\n}\n\nimpl Eq for Idx {}\nimpl PartialEq for Idx {\n    fn eq(&self, rhs: &Idx) -> bool {\n        Arc::ptr_eq(&self.inner, &rhs.inner)\n    }\n}\n\nimpl Hash for Idx {\n    fn hash<H: Hasher>(&self, state: &mut H) {\n        std::ptr::hash(self.inner.as_ref(), state)\n    }\n}\n\nconst DEFAULT_CAPACITY: usize = 4;\n\npub struct Arena<T> {\n    values: Vec<(Arc<IdxInner>, T)>,\n}\n\nimpl<T> Default for Arena<T> {\n    fn default() -> Self {\n        Self::new()\n    }\n}\n\n#[inline]\nfn choose_second_member_of_tuple_mut<A, B>((_, value): &mut (A, B)) -> &mut B {\n    value\n}\n\n#[inline]\nfn choose_second_member_of_tuple_ref<A, B>((_, value): &(A, B)) -> &B {\n    value\n}\n\npub struct IterMut<'a, T> {\n    iterator: std::iter::Map<\n        std::slice::IterMut<'a, (Arc<IdxInner>, T)>,\n        &'a dyn Fn(&mut (Arc<IdxInner>, T)) -> &mut T,\n    >,\n}\n\nimpl<'a, T> Iterator for IterMut<'a, T> {\n    type Item = &'a mut T;\n    fn next(&mut self) -> Option<Self::Item> {\n        self.iterator.next()\n    }\n}\n\npub struct Iter<'a, T> {\n    iterator: std::iter::Map<\n        std::slice::Iter<'a, (Arc<IdxInner>, T)>,\n        &'a dyn Fn(&(Arc<IdxInner>, T)) -> &T,\n    >,\n}\n\nimpl<'a, T> Iterator for Iter<'a, T> {\n    type Item = &'a T;\n    fn next(&mut self) -> Option<Self::Item> {\n        self.iterator.next()\n    }\n}\n\npub struct EntriesMut<'a, T> {\n    iterator: std::slice::IterMut<'a, (Arc<IdxInner>, T)>,\n}\n\npub struct Entries<'a, T> {\n    iterator: std::slice::Iter<'a, (Arc<IdxInner>, T)>,\n}\n\nimpl<'a, T> Iterator for EntriesMut<'a, T> {\n    type Item = (Idx, &'a mut T);\n    fn next(&mut self) -> Option<Self::Item> {\n        self.iterator.next().map(|(inner, value)| {\n            (\n                Idx {\n                    inner: inner.clone(),\n                },\n                value,\n            )\n        })\n    }\n}\n\nimpl<'a, T> Iterator for Entries<'a, T> {\n    type Item = (Idx, &'a T);\n    fn next(&mut self) -> Option<Self::Item> {\n        self.iterator.next().map(|(inner, value)| {\n            (\n                Idx {\n                    inner: inner.clone(),\n                },\n                value,\n            )\n        })\n    }\n}\n\nimpl<T> FromIterator<T> for Arena<T> {\n    fn from_iter<I: IntoIterator<Item = T>>(iter: I) -> Self {\n        Arena {\n            values: iter\n                .into_iter()\n                .enumerate()\n                .map(|(index, value)| (create_idx(index), value))\n                .collect(),\n        }\n    }\n}\n#[inline]\nfn create_idx(index: usize) -> Arc<IdxInner> {\n    Arc::new(IdxInner {\n        index: AtomicUsize::new(index),\n        removed: AtomicBool::new(false),\n    })\n}\n\nimpl<T> Arena<T> {\n    pub fn new() -> Arena<T> {\n        Self::with_capacity(DEFAULT_CAPACITY)\n    }\n\n    pub fn with_capacity(capacity: usize) -> Arena<T> {\n        Self {\n            values: Vec::with_capacity(capacity),\n        }\n    }\n\n    pub fn capacity(&self) -> usize {\n        self.values.capacity()\n    }\n\n    #[inline]\n    pub fn alloc_with_idx<F: FnOnce(Idx) -> T>(&mut self, func: F) -> Idx {\n        let len = self.values.len();\n        let inner = create_idx(len);\n        let idx = Idx {\n            inner: inner.clone(),\n        };\n        self.values.push((inner.clone(), func(idx)));\n        Idx { inner }\n    }\n\n    #[inline]\n    pub fn alloc_with<F: FnOnce() -> T>(&mut self, func: F) -> Idx {\n        self.alloc_with_idx(|_| func())\n    }\n\n    #[inline]\n    pub fn insert(&mut self, value: T) -> Idx {\n        self.alloc(value)\n    }\n\n    #[inline]\n    pub fn alloc(&mut self, value: T) -> Idx {\n        self.alloc_with(|| value)\n    }\n\n    pub fn len(&self) -> usize {\n        self.values.len()\n    }\n\n    pub fn get_idx_at_index(&self, index: usize) -> Option<Idx> {\n        self.values.get(index).map(|(inner, _)| Idx {\n            inner: Arc::clone(&inner),\n        })\n    }\n\n    pub fn split_at<'a, I: Borrow<Idx>>(\n        &'a mut self,\n        selected: I,\n    ) -> Option<(&mut T, ArenaSplit<'a, T>)> {\n        if let Some(value) = self.get_mut(selected.borrow()) {\n            Some((\n                unsafe { (value as *mut T).as_mut().unwrap() },\n                ArenaSplit {\n                    selected: selected.borrow().clone(),\n                    arena: self,\n                    __type: Default::default(),\n                },\n            ))\n        } else {\n            None\n        }\n    }\n\n    pub fn truncate(&mut self, len: usize) {\n        let end = self.values.len();\n        let start = end - (end - len);\n\n        for i in (start..end).rev() {\n            self.remove_index(i);\n        }\n    }\n\n    pub fn retain<F: FnMut(&T) -> bool>(&mut self, mut f: F) {\n        let len = self.values.len();\n        let mut del = 0;\n\n        for i in 0..len {\n            if !f(&self.values[i].1) {\n                del += 1;\n            } else {\n                self.swap_index(i - del, i);\n            }\n        }\n\n        if del > 0 {\n            self.truncate(len - del);\n        }\n    }\n\n    pub fn entries<'a>(&'a self) -> Entries<'a, T> {\n        Entries {\n            iterator: self.values.iter(),\n        }\n    }\n\n    pub fn entries_mut<'a>(&'a mut self) -> EntriesMut<'a, T> {\n        EntriesMut {\n            iterator: self.values.iter_mut(),\n        }\n    }\n\n    pub fn iter_mut<'a>(&'a mut self) -> IterMut<'a, T> {\n        IterMut {\n            iterator: self\n                .values\n                .iter_mut()\n                .map(&choose_second_member_of_tuple_mut),\n        }\n    }\n\n    pub fn iter<'a>(&'a self) -> Iter<'a, T> {\n        Iter {\n            iterator: self.values.iter().map(&choose_second_member_of_tuple_ref),\n        }\n    }\n\n    pub fn to_vec(self) -> Vec<T> {\n        self.into()\n    }\n\n    fn remove_index(&mut self, index: usize) -> T {\n        let (removed_index, value) = self.values.remove(index);\n\n        for (index, (idx, _)) in self.values.iter().enumerate().skip(index) {\n            idx.index.store(index, Ordering::Relaxed);\n        }\n\n        removed_index.removed.store(true, Ordering::Relaxed);\n\n        value\n    }\n\n    pub fn remove<I: Borrow<Idx>>(&mut self, index: I) -> T {\n        if let Some(index) = index.borrow().value() {\n            self.remove_index(index)\n        } else {\n            panic!(\"Trying to remove index that has already been removed!\");\n        }\n    }\n\n    fn swap_index(&mut self, a: usize, b: usize) {\n        self.values.swap(a, b);\n        self.values[a].0.index.store(a, Ordering::Relaxed);\n        self.values[b].0.index.store(b, Ordering::Relaxed);\n    }\n\n    pub fn swap<A: Borrow<Idx>, B: Borrow<Idx>>(&mut self, a: A, b: B) {\n        if let Some((a_index, b_index)) = a\n            .borrow()\n            .value()\n            .and_then(|a| b.borrow().value().map(|b| (a, b)))\n        {\n            self.swap_index(a_index, b_index);\n        }\n    }\n\n    pub fn position<F: Fn(&T) -> bool>(&self, func: F) -> Option<Idx> {\n        for (inner, value) in self.values.iter() {\n            if func(value) {\n                return Some(Idx {\n                    inner: Arc::clone(&inner),\n                });\n            }\n        }\n\n        None\n    }\n\n    pub fn apply_ordering<I: Borrow<Idx>>(&mut self, ordering: &Vec<I>) {\n        assert!(ordering.len() == self.values.len());\n\n        let mut old_arena = Arena::<T>::with_capacity(self.capacity());\n        std::mem::swap(&mut old_arena.values, &mut self.values);\n\n        for idx in ordering.iter() {\n            let new_index = self.values.len();\n            let old_index = idx.borrow().value().unwrap();\n\n            let (inner, value) = old_arena.swap_remove_index(old_index);\n\n            inner.index.store(new_index, Ordering::Relaxed);\n\n            self.values.push((inner, value));\n\n            idx.borrow().inner.index.store(new_index, Ordering::Relaxed);\n        }\n    }\n\n    fn swap_remove_index(&mut self, index: usize) -> (Arc<IdxInner>, T) {\n        let (removed_index, value) = self.values.swap_remove(index);\n\n        if self.values.len() > 0 && index != self.values.len() {\n            self.values[index].0.index.store(index, Ordering::Relaxed);\n        }\n\n        (removed_index, value)\n    }\n\n    #[cfg(test)]\n    fn get_index(&mut self, index: usize) -> &mut T {\n        &mut self.values[index].1\n    }\n\n    pub fn swap_remove<I: Borrow<Idx>>(&mut self, index: I) -> T {\n        if let Some(index) = index.borrow().value() {\n            let (removed_index, value) = self.swap_remove_index(index);\n            removed_index.removed.store(true, Ordering::Relaxed);\n            value\n        } else {\n            panic!(\"Trying to remove index that has already been removed!\");\n        }\n    }\n\n    pub fn get<I: Borrow<Idx>>(&self, index: I) -> Option<&T> {\n        index\n            .borrow()\n            .value()\n            .and_then(|index| self.values.get(index).and_then(|(_, value)| Some(value)))\n    }\n\n    pub fn get_mut<I: Borrow<Idx>>(&mut self, index: I) -> Option<&mut T> {\n        if let Some(index) = index.borrow().value() {\n            self.values\n                .get_mut(index)\n                .and_then(|(_, value)| Some(value))\n        } else {\n            None\n        }\n    }\n}\n\nimpl<T> Into<Vec<T>> for Arena<T> {\n    fn into(self) -> Vec<T> {\n        // Set all the indexes to removed, since we can't use them anymore\n        for (idx, _) in self.values.iter() {\n            idx.removed.store(true, Ordering::Relaxed);\n        }\n\n        // Grab all the values and turn them into an array\n        self.values.into_iter().map(|(_, value)| value).collect()\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    fn setup_arena() -> (Arena<String>, Idx, Idx, Idx, Idx) {\n        let mut arena = Arena::new();\n\n        let john = arena.alloc(\"John\".into());\n        let julia = arena.alloc(\"Julia\".into());\n        let jane = arena.alloc(\"Jane\".into());\n        let jake = arena.alloc(\"Jake\".into());\n\n        (arena, john, julia, jane, jake)\n    }\n\n    #[test]\n    fn should_construct_default() {\n        let arena: Arena<()> = Default::default();\n        assert_eq!(arena.len(), 0);\n        assert_eq!(arena.capacity(), DEFAULT_CAPACITY);\n    }\n\n    #[test]\n    fn should_construct_with_capacity() {\n        let arena: Arena<()> = Arena::with_capacity(100);\n        assert_eq!(arena.len(), 0);\n        assert_eq!(arena.capacity(), 100);\n    }\n\n    #[test]\n    fn getting_by_index() {\n        let (mut arena, john, julia, jane, jake) = setup_arena();\n\n        assert_eq!(arena.get_index(0), \"John\");\n        assert_eq!(arena.get_index(1), \"Julia\");\n        assert_eq!(arena.get_index(2), \"Jane\");\n        assert_eq!(arena.get_index(3), \"Jake\");\n\n        assert_eq!(arena.get(john).unwrap(), \"John\");\n        assert_eq!(arena.get(julia).unwrap(), \"Julia\");\n        assert_eq!(arena.get(jane).unwrap(), \"Jane\");\n        assert_eq!(arena.get(jake).unwrap(), \"Jake\");\n    }\n\n    #[test]\n    fn arena_length() {\n        let (mut arena, _, _, _, _) = setup_arena();\n        assert_eq!(arena.len(), 4);\n        arena.alloc(\"Wow\".into());\n        assert_eq!(arena.len(), 5);\n    }\n\n    #[test]\n    fn swap_indexes() {\n        let (mut arena, john, julia, jane, jake) = setup_arena();\n\n        assert_eq!(arena.get_index(0), \"John\");\n        assert_eq!(arena.get_index(1), \"Julia\");\n        assert_eq!(arena.get_index(2), \"Jane\");\n        assert_eq!(arena.get_index(3), \"Jake\");\n\n        assert_eq!(arena.get(&john).unwrap(), \"John\");\n        assert_eq!(arena.get(&julia).unwrap(), \"Julia\");\n        assert_eq!(arena.get(&jane).unwrap(), \"Jane\");\n        assert_eq!(arena.get(&jake).unwrap(), \"Jake\");\n\n        arena.swap(&john, &julia);\n        arena.swap(&jane, &jake);\n\n        assert_eq!(arena.get_index(0), \"Julia\");\n        assert_eq!(arena.get_index(1), \"John\");\n        assert_eq!(arena.get_index(2), \"Jake\");\n        assert_eq!(arena.get_index(3), \"Jane\");\n\n        assert_eq!(arena.get(&john).unwrap(), \"John\");\n        assert_eq!(arena.get(&julia).unwrap(), \"Julia\");\n        assert_eq!(arena.get(&jane).unwrap(), \"Jane\");\n        assert_eq!(arena.get(&jake).unwrap(), \"Jake\");\n    }\n\n    #[test]\n    fn remove() {\n        let (mut arena, john, julia, jane, jake) = setup_arena();\n\n        assert_eq!(arena.len(), 4);\n\n        arena.remove(&john);\n\n        assert!(arena.get(&john).is_none());\n        assert_eq!(arena.get(&julia).unwrap(), \"Julia\");\n        assert_eq!(arena.get(&jane).unwrap(), \"Jane\");\n        assert_eq!(arena.get(&jake).unwrap(), \"Jake\");\n\n        assert_eq!(arena.get_index(0), \"Julia\");\n        assert_eq!(arena.get_index(1), \"Jane\");\n        assert_eq!(arena.get_index(2), \"Jake\");\n    }\n\n    #[test]\n    fn swap_remove() {\n        let (mut arena, john, julia, jane, jake) = setup_arena();\n\n        assert_eq!(arena.len(), 4);\n\n        arena.swap_remove(&john);\n\n        assert!(arena.get(&john).is_none());\n        assert_eq!(arena.get(&julia).unwrap(), \"Julia\");\n        assert_eq!(arena.get(&jane).unwrap(), \"Jane\");\n        assert_eq!(arena.get(&jake).unwrap(), \"Jake\");\n\n        assert_eq!(arena.get_index(0), \"Jake\");\n        assert_eq!(arena.get_index(1), \"Julia\");\n        assert_eq!(arena.get_index(2), \"Jane\");\n    }\n\n    #[test]\n    fn remove_should_remove_last_value() {\n        let (mut arena, john, julia, jane, jake) = setup_arena();\n\n        assert_eq!(arena.len(), 4);\n\n        arena.swap_remove(&jake);\n        arena.remove(&jane);\n        arena.swap_remove(&julia);\n        arena.remove(&john);\n\n        assert_eq!(arena.len(), 0);\n    }\n\n    #[test]\n    fn convert_to_vec() {\n        let (arena, _, _, _, _) = setup_arena();\n        assert_eq!(arena.to_vec(), vec![\"John\", \"Julia\", \"Jane\", \"Jake\"]);\n    }\n\n    #[test]\n    fn index_should_be_hashable() {\n        let (mut arena, john, julia, jane, jake) = setup_arena();\n\n        let mut seen = std::collections::HashSet::<Idx>::new();\n\n        seen.insert(jake.clone());\n        assert!(seen.contains(&jake));\n        assert_eq!(jake.value().unwrap(), 3);\n\n        arena.remove(john);\n        arena.remove(julia);\n        arena.remove(jane);\n\n        assert_eq!(jake.value().unwrap(), 0);\n        assert!(seen.contains(&jake));\n    }\n\n    #[test]\n    fn cloned_index_should_equal() {\n        let (_, john, _, _, _) = setup_arena();\n\n        let a = john.clone();\n        let b = john;\n\n        assert!(a == b);\n    }\n\n    #[test]\n    fn apply_ordering() {\n        let (mut arena, john, julia, jane, jake) = setup_arena();\n\n        let ordering = vec![&jake, &julia, &john, &jane];\n\n        assert_eq!(arena.get_index(0), \"John\");\n        assert_eq!(arena.get_index(1), \"Julia\");\n        assert_eq!(arena.get_index(2), \"Jane\");\n        assert_eq!(arena.get_index(3), \"Jake\");\n\n        arena.apply_ordering(&ordering);\n\n        assert_eq!(arena.get_index(0), \"Jake\");\n        assert_eq!(arena.get_index(1), \"Julia\");\n        assert_eq!(arena.get_index(2), \"John\");\n        assert_eq!(arena.get_index(3), \"Jane\");\n\n        assert_eq!(arena.get(&john).unwrap(), \"John\");\n        assert_eq!(arena.get(&julia).unwrap(), \"Julia\");\n        assert_eq!(arena.get(&jane).unwrap(), \"Jane\");\n        assert_eq!(arena.get(&jake).unwrap(), \"Jake\");\n    }\n\n    #[test]\n    fn position() {\n        let (arena, _, julia, _, _) = setup_arena();\n\n        let j = arena.position(|v| v == \"Julia\").unwrap();\n\n        assert!(j == julia);\n    }\n\n    #[test]\n    fn truncate() {\n        let (mut arena, _, _, _, _) = setup_arena();\n        arena.truncate(0);\n        assert_eq!(arena.to_vec(), Vec::<String>::new());\n    }\n\n    #[test]\n    fn retain() {\n        let (mut arena, _, _, _, _) = setup_arena();\n\n        arena.retain(|v| v == \"Julia\" || v == \"Jane\");\n\n        assert_eq!(arena.to_vec(), vec![\"Julia\", \"Jane\"]);\n    }\n\n    #[test]\n    fn mut_iter() {\n        let (mut arena, _, _, _, _) = setup_arena();\n\n        for val in arena.iter_mut() {\n            *val = \"Wow\".into();\n        }\n\n        assert_eq!(arena.to_vec(), vec![\"Wow\"; 4])\n    }\n\n    #[test]\n    fn iter() {\n        let (arena, _, _, _, _) = setup_arena();\n\n        let names = vec![\"John\", \"Julia\", \"Jane\", \"Jake\"];\n\n        for (a, b) in arena.iter().zip(names.iter()) {\n            assert_eq!(a, b);\n        }\n    }\n\n    #[test]\n    fn turn_iterator_into_vector() {\n        let names = vec![\"John\", \"Julia\", \"Jane\", \"Jake\"];\n        let other_names = vec![\"John\", \"Julia\", \"Jane\", \"Jake\"];\n\n        let arena = names.into_iter().collect::<Arena<_>>();\n\n        for (a, b) in arena.iter().zip(other_names.iter()) {\n            assert_eq!(a, b);\n        }\n    }\n\n    #[test]\n    fn get_mut() {\n        let (mut arena, john, _, _, _) = setup_arena();\n        *(arena.get_mut(&john).unwrap()) = \"Not John\".into();\n        assert_eq!(arena.get(&john).unwrap(), \"Not John\");\n    }\n\n    struct Node {\n        id: Idx,\n    }\n\n    #[test]\n    fn alloc_with_idx() {\n        let mut arena = Arena::new();\n        let idx = arena.alloc_with_idx(|id| Node { id });\n        assert_eq!(arena.get(&idx).unwrap().id.value(), idx.value());\n    }\n\n    #[test]\n    fn split_at() {\n        let (mut arena, john, julia, jane, jake) = setup_arena();\n\n        let (j, mut arena) = arena.split_at(&julia).unwrap();\n\n        assert_eq!(j, \"Julia\");\n        assert!(arena.get_mut(john).is_some());\n        assert!(arena.get_mut(jane).is_some());\n        assert!(arena.get_mut(jake).is_some());\n\n        assert!(arena.get_mut(julia).is_none());\n    }\n\n    #[test]\n    fn debug_printing() {\n        let (mut arena, john, _, _, _) = setup_arena();\n\n        assert_eq!(format!(\"{:?}\", john), \"Idx ( 0 )\");\n\n        arena.swap_remove(&john);\n\n        assert_eq!(format!(\"{:?}\", john), \"Removed Idx ( 0 )\");\n    }\n}\n"
  },
  {
    "project": "rust-xcb",
    "target": 1,
    "commit_id": "121acde839901c33cde938a527f50993838dee89",
    "func": "use crate::cg;\nuse crate::cg::util;\nuse crate::ir;\n\nuse super::{\n    doc::DocField, CodeGen, Doc, Expr, Field, HasWireLayout, QualifiedRsTyp, RsTyp, StructStyle,\n    TypeInfo, WireSz,\n};\n\nuse std::io::{self, Write};\n\n/// struct of external parameters passed to functions such as compute_len\n/// This is very often `()` for which `None` is used, but sometimes an field external to struct is needed\n/// to compute the len of a list (i.e. <paramref> element types)\n#[derive(Clone, Debug)]\npub(super) struct ParamsStruct {\n    pub rs_typ: String,\n    pub params: Vec<String>,\n}\n\nimpl ParamsStruct {\n    pub fn emit<O: Write>(&self, out: &mut O) -> io::Result<()> {\n        writeln!(out)?;\n        writeln!(out, \"#[derive(Copy, Clone, Debug)]\")?;\n        writeln!(out, \"pub struct {} {{\", self.rs_typ)?;\n        for p in &self.params {\n            writeln!(out, \"    pub {}: usize,\", p)?;\n        }\n        writeln!(out, \"}}\")?;\n        Ok(())\n    }\n}\n\nimpl RsTyp for Option<&ParamsStruct> {\n    fn rs_typ(&self) -> &str {\n        match self {\n            Some(params_struct) => &params_struct.rs_typ,\n            _ => \"()\",\n        }\n    }\n}\n\n#[derive(Debug)]\npub(super) struct ResolvedFields {\n    pub fields: Vec<Field>,\n    pub wire_sz: Expr,\n    pub has_wire_layout: bool,\n    pub unresolved_fieldrefs: Vec<String>,\n    pub params_struct: Option<ParamsStruct>,\n}\n\nimpl CodeGen {\n    pub(super) fn resolve_struct(\n        &mut self,\n        typ: &str,\n        fields: &[ir::Field],\n        doc: &Option<ir::Doc>,\n    ) {\n        let rs_typ = cg::rust_type_name(typ);\n        let doc = self.resolve_doc(doc.clone());\n        let ResolvedFields {\n            fields,\n            wire_sz,\n            has_wire_layout,\n            params_struct,\n            // unresolved_fieldrefs,\n            ..\n        } = self.resolv_struct_fields(&rs_typ, \"\", fields, doc.as_ref());\n\n        // assert!(unresolved_fieldrefs.is_empty());\n\n        let typ_info = TypeInfo::Struct {\n            module: None,\n            rs_typ,\n            fields,\n            wire_sz,\n            has_wire_layout,\n            params_struct,\n            doc,\n        };\n        self.register_typ(typ.to_string(), typ_info);\n    }\n\n    pub(super) fn resolv_struct_fields(\n        &mut self,\n        struct_rs_typ: &str,\n        parent_switch: &str,\n        fields: &[ir::Field],\n        doc: Option<&Doc>,\n    ) -> ResolvedFields {\n        let mut vec = Vec::new();\n        let mut wire_off = Expr::Value(0usize);\n        let mut has_wire_layout = true;\n        let mut need_compute_offset = false;\n        // fields that are referenced in list length of this struct\n        let mut fieldrefs = Vec::new();\n        // external fields that are refereced in list length of this struct\n        let mut paramrefs = Vec::new();\n        // fields of this struct that are used as list length of other struct\n        let mut paramfields = Vec::new();\n        let mut unresolved_fieldrefs = Vec::new();\n\n        let has_prop_field = fields.iter().any(\n            |f| matches!(f, ir::Field::Field{name, typ, ..} if name == \"format\" && typ == \"CARD8\"),\n        ) && fields\n            .iter()\n            .any(|f| matches!(f, ir::Field::List{typ, ..} if typ == \"void\"));\n\n        for f in fields {\n            let f_sz = match f {\n                ir::Field::Field {\n                    name,\n                    typ,\n                    r#enum,\n                    mask,\n                    ..\n                } => {\n                    let FieldInfo {\n                        name,\n                        module,\n                        rs_typ,\n                        wire_sz,\n                        has_wire_layout: hfl,\n                        struct_style,\n                        is_union,\n                        is_xid,\n                        is_mask,\n                        params_struct,\n                        doc,\n                        ..\n                    } = self.get_field_info(name, typ, r#enum.is_some(), doc);\n\n                    if !hfl || (rs_typ != \"u32\" && (r#enum.is_some() || (mask.is_some()))) {\n                        has_wire_layout = false;\n                    }\n\n                    let r#enum = r#enum.as_ref().map(|typ| self.get_mod_rs_typ(typ));\n                    let mask = mask.as_ref().map(|typ| self.get_mod_rs_typ(typ));\n\n                    let wire_sz = wire_sz.reduce();\n\n                    let is_prop_format = has_prop_field && name == \"format\";\n\n                    vec.push(Field::Field {\n                        name,\n                        module,\n                        rs_typ,\n                        wire_off: wire_off.clone(),\n                        wire_sz: wire_sz.clone(),\n                        struct_style,\n                        params_struct,\n                        doc,\n                        is_mask: is_mask || mask.is_some(),\n                        r#enum,\n                        mask,\n                        is_fieldref: false,\n                        is_paramref: false,\n                        is_copy: hfl,\n                        is_union,\n                        is_xid,\n                        need_compute_offset,\n                        is_prop_format,\n                    });\n                    wire_sz\n                }\n                ir::Field::Pad(wire_sz) => {\n                    has_wire_layout = false;\n                    let wire_off = wire_off.clone().reduce();\n                    vec.push(Field::Pad {\n                        wire_off,\n                        wire_sz: Expr::Value(*wire_sz),\n                    });\n                    Expr::Value(*wire_sz)\n                }\n                ir::Field::AlignPad(sz) => {\n                    has_wire_layout = false;\n                    let wire_off = wire_off.clone().reduce();\n                    let wire_sz = Expr::AlignPad(*sz, Box::new(wire_off.clone())).reduce();\n                    vec.push(Field::AlignPad {\n                        wire_off,\n                        wire_sz: wire_sz.clone(),\n                    });\n                    wire_sz\n                }\n                ir::Field::List {\n                    name,\n                    typ,\n                    len_expr,\n                } => {\n                    let FieldInfo {\n                        name,\n                        module,\n                        mut rs_typ,\n                        typ,\n                        wire_sz,\n                        has_wire_layout: hfl,\n                        struct_style,\n                        params_struct,\n                        doc,\n                        ..\n                    } = self.get_field_info(name, typ, false, doc);\n\n                    let len_expr = self.resolve_expr(len_expr);\n\n                    wire_sz.fetch_paramrefs_owned(&mut paramfields);\n\n                    let wire_sz = Expr::Op(\n                        \"*\".to_string(),\n                        Box::new(len_expr.clone()),\n                        Box::new(wire_sz),\n                    );\n                    let wire_sz = wire_sz.reduce();\n\n                    let fixed_str = matches!((rs_typ.as_str(), &wire_sz), (\"char\", Expr::Value(_)));\n                    if fixed_str {\n                        rs_typ = \"u8\".into();\n                    } else if !hfl || !matches!(wire_sz, Expr::Value(_)) {\n                        has_wire_layout = false;\n                    }\n\n                    len_expr.fetch_fieldrefs_owned(&mut fieldrefs);\n                    len_expr.fetch_paramrefs_owned(&mut paramrefs);\n\n                    // assert!(!need_compute_offset, \"{}::{}\", self.xcb_mod, name);\n                    let is_prop = has_prop_field && typ == \"void\";\n\n                    vec.push(Field::List {\n                        name,\n                        module,\n                        rs_typ,\n                        wire_off: wire_off.clone(),\n                        wire_sz: wire_sz.clone(),\n                        struct_style,\n                        is_fieldref: false,\n                        len_expr,\n                        need_compute_offset,\n                        params_struct,\n                        is_prop,\n                        doc,\n                    });\n\n                    if let Some(StructStyle::DynBuf) = struct_style {\n                        need_compute_offset = true;\n                    }\n\n                    wire_sz\n                }\n                ir::Field::ListNoLen { typ, name } => {\n                    let FieldInfo {\n                        name,\n                        module,\n                        rs_typ,\n                        typ,\n                        struct_style,\n                        params_struct,\n                        doc,\n                        ..\n                    } = self.get_field_info(name, typ, false, doc);\n\n                    has_wire_layout = false;\n                    let is_prop = has_prop_field && typ == \"void\";\n\n                    vec.push(Field::List {\n                        name,\n                        module,\n                        rs_typ,\n                        wire_off: wire_off.clone(),\n                        wire_sz: Expr::UntilEnd,\n                        struct_style,\n                        params_struct,\n                        is_fieldref: false,\n                        len_expr: Expr::UntilEnd,\n                        need_compute_offset,\n                        is_prop,\n                        doc,\n                    });\n\n                    Expr::Unknown(\"list no len\".to_string())\n                }\n                ir::Field::ValueParam { .. } => {\n                    unreachable!(\"<valueparam> not anymore used with xcb-1.14\")\n                }\n                ir::Field::Switch(name, expr, cases) => {\n                    let expr = self.resolve_expr(expr);\n                    let field = self.resolve_switch(\n                        struct_rs_typ,\n                        parent_switch,\n                        name,\n                        &expr,\n                        &wire_off,\n                        cases,\n                        &mut vec,\n                        need_compute_offset,\n                    );\n                    expr.fetch_fieldrefs_owned(&mut fieldrefs);\n                    if let Field::Switch { params_struct, .. } = &field {\n                        let mut params = params_struct.params.clone();\n                        fieldrefs.append(&mut params);\n                    } else {\n                        unreachable!();\n                    };\n                    vec.push(field);\n                    need_compute_offset = true;\n                    has_wire_layout = false;\n                    Expr::Unknown(\"switch len\".to_string())\n                }\n                ir::Field::Expr { name, typ, expr } => {\n                    let FieldInfo {\n                        name, typ, wire_sz, ..\n                    } = self.get_field_info(name, typ, false, doc);\n\n                    has_wire_layout = false;\n\n                    let wire_sz = wire_sz.reduce();\n                    let expr = self.resolve_expr(expr);\n\n                    vec.push(Field::Expr {\n                        name,\n                        typ,\n                        wire_off: wire_off.clone(),\n                        wire_sz: wire_sz.clone(),\n                        expr,\n                    });\n                    wire_sz\n                }\n                ir::Field::Fd(name) => {\n                    eprintln!(\"partial treatment of Fd field: {}::{}\", struct_rs_typ, name);\n                    let doc = self.doc_lookup_field(doc, name);\n\n                    vec.push(Field::Field {\n                        name: name.clone(),\n                        module: None,\n                        rs_typ: \"RawFd\".to_string(),\n                        wire_off: wire_off.clone(),\n                        wire_sz: Expr::Value(4),\n                        struct_style: None,\n                        params_struct: None,\n                        doc,\n                        is_fieldref: false,\n                        is_paramref: false,\n                        is_copy: true,\n                        is_union: false,\n                        is_xid: false,\n                        is_mask: false,\n                        r#enum: None,\n                        mask: None,\n                        need_compute_offset: false,\n                        is_prop_format: false,\n                    });\n                    has_wire_layout = false;\n                    Expr::Value(4)\n                } // f => unreachable!(\"{:#?}\", f),\n            };\n\n            let new_off = Expr::Op(\"+\".to_string(), Box::new(wire_off), Box::new(f_sz));\n            wire_off = new_off.reduce();\n        }\n\n        for fr in fieldrefs {\n            let mut resolved = false;\n            for f in &mut vec {\n                match f {\n                    Field::Field {\n                        name, is_fieldref, ..\n                    } if name == &fr => {\n                        *is_fieldref = true;\n                        resolved = true;\n                        break;\n                    }\n                    Field::List {\n                        name, is_fieldref, ..\n                    } if name == &fr => {\n                        *is_fieldref = true;\n                        resolved = true;\n                        break;\n                    }\n                    _ => {}\n                }\n            }\n            if !resolved {\n                unresolved_fieldrefs.push(fr);\n            }\n        }\n        for pf in &paramfields {\n            for f in &mut vec {\n                match f {\n                    Field::Field {\n                        name, is_paramref, ..\n                    } if name == pf => {\n                        *is_paramref = true;\n                        break;\n                    }\n                    _ => {}\n                }\n            }\n        }\n        let params_struct = if paramrefs.is_empty() {\n            None\n        } else {\n            Some(ParamsStruct {\n                rs_typ: struct_rs_typ.to_string() + \"Params\",\n                params: paramrefs,\n            })\n        };\n\n        ResolvedFields {\n            fields: vec,\n            wire_sz: wire_off,\n            has_wire_layout,\n            unresolved_fieldrefs,\n            params_struct,\n        }\n    }\n\n    fn get_mod_rs_typ(&self, typ: &str) -> (Option<String>, String) {\n        let (module, typ) = util::extract_module(typ);\n        let typinfo = self.find_typinfo(module, typ);\n        let module = typinfo.module();\n        let rs_typ = typinfo.rs_typ();\n        (module.map(str::to_owned), rs_typ.to_string())\n    }\n\n    fn get_field_info(\n        &self,\n        name: &str,\n        typ: &str,\n        alt_repr: bool,\n        doc: Option<&Doc>,\n    ) -> FieldInfo {\n        let name = cg::rust_field_name(name);\n        let (module, typ) = util::extract_module(typ);\n        let typinfo = self.find_typinfo(module, typ);\n        let module = typinfo.module();\n        let rs_typ = typinfo.rs_typ();\n        let wire_sz = typinfo.wire_sz();\n        let is_union = matches!(typinfo, TypeInfo::Union { .. } | TypeInfo::XidUnion { .. });\n        let is_xid = matches!(typinfo, TypeInfo::Xid { .. } | TypeInfo::XidUnion { .. });\n        let is_mask = matches!(typinfo, TypeInfo::Mask { .. });\n        let params_struct = match typinfo {\n            TypeInfo::Struct { params_struct, .. } => params_struct.clone(),\n            _ => None,\n        };\n        let doc = self.doc_lookup_field(doc, &name);\n\n        FieldInfo {\n            name,\n            module: module.map(str::to_owned),\n            typ: typ.to_string(),\n            rs_typ: rs_typ.to_string(),\n            wire_sz,\n            has_wire_layout: !alt_repr && typinfo.has_wire_layout(),\n            struct_style: typinfo.struct_style(),\n            params_struct,\n            doc,\n            is_union,\n            is_xid,\n            is_mask,\n        }\n    }\n\n    fn build_params_expr(\n        &self,\n        params_struct: Option<&ParamsStruct>,\n        module: Option<&str>,\n        acc_pref: &str,\n        acc_post: &str,\n    ) -> String {\n        if params_struct.is_none() {\n            return \"()\".to_string();\n        }\n        let params_struct = params_struct.unwrap();\n        let q_rs_typ = (module, params_struct.rs_typ.as_str()).qualified_rs_typ();\n        let mut expr = q_rs_typ + \" {\";\n        for (i, p) in params_struct.params.iter().enumerate() {\n            expr.push_str(&format!(\"{}: {}{}{} as usize\", p, acc_pref, p, acc_post));\n            if i < params_struct.params.len() - 1 {\n                expr.push_str(\", \");\n            }\n        }\n        expr.push('}');\n        expr\n    }\n\n    #[allow(clippy::too_many_arguments)]\n    pub(super) fn emit_struct<O: Write>(\n        &self,\n        out: &mut O,\n        rs_typ: &str,\n        fields: &[Field],\n        wire_sz: &Expr,\n        has_wire_layout: bool,\n        params_struct: Option<&ParamsStruct>,\n        doc: Option<&Doc>,\n    ) -> io::Result<()> {\n        if !self.rs_typ_is_needed(rs_typ) {\n            return Ok(());\n        }\n\n        match (has_wire_layout, wire_sz) {\n            (true, Expr::Value(wire_sz)) => {\n                self.emit_wire_layout_struct(out, rs_typ, fields, *wire_sz, doc)?\n            }\n            (false, Expr::Value(wire_sz)) => {\n                self.emit_fix_buf_struct(out, rs_typ, fields, *wire_sz, doc)?\n            }\n            (false, _) => self.emit_dyn_buf_struct(out, rs_typ, fields, params_struct, doc)?,\n            _ => unreachable!(\"{}::{}\", self.xcb_mod, rs_typ),\n        }\n\n        Ok(())\n    }\n\n    fn emit_wire_layout_struct<O: Write>(\n        &self,\n        out: &mut O,\n        rs_typ: &str,\n        fields: &[Field],\n        wire_sz: usize,\n        doc: Option<&Doc>,\n    ) -> io::Result<()> {\n        writeln!(out)?;\n        if let Some(doc) = doc {\n            doc.emit(out, 0)?;\n        }\n        writeln!(out, \"#[derive(Copy, Clone, Debug)]\")?;\n        writeln!(out, \"#[repr(C)]\")?;\n        writeln!(out, \"pub struct {} {{\", rs_typ)?;\n        for f in fields {\n            match f {\n                Field::Field {\n                    name,\n                    module,\n                    rs_typ,\n                    r#enum,\n                    mask,\n                    doc,\n                    ..\n                } => {\n                    let q_rs_typ = enum_mask_qualified_rs_typ(module, rs_typ, r#enum, mask);\n                    if let Some(doc) = doc {\n                        doc.emit(out, 1)?;\n                    }\n                    writeln!(out, \"    pub {}: {},\", name, q_rs_typ)?;\n                }\n                Field::List {\n                    name,\n                    module,\n                    rs_typ,\n                    len_expr: Expr::Value(len),\n                    doc,\n                    ..\n                } => {\n                    let mod_rs_typ = (module, rs_typ);\n                    if let Some(doc) = doc {\n                        doc.emit(out, 1)?;\n                    }\n                    writeln!(\n                        out,\n                        \"    pub {}: [{}; {}],\",\n                        name,\n                        mod_rs_typ.qualified_rs_typ(),\n                        len\n                    )?;\n                }\n                _ => unreachable!(\"emitting struct field {:?}\", f),\n            }\n        }\n        writeln!(out, \"}}\")?;\n\n        self.emit_sizeof_test(out, rs_typ, wire_sz)?;\n\n        writeln!(out)?;\n        writeln!(out, \"impl base::Wired for {} {{\", rs_typ)?;\n        writeln!(out, \"    type Params = ();\")?;\n        writeln!(\n            out,\n            \"    unsafe fn compute_wire_len(_ptr: *const u8, _params: ()) -> usize {{ {} }}\",\n            wire_sz\n        )?;\n        writeln!(out)?;\n        writeln!(out, \"    fn wire_len(&self) -> usize {{ {} }}\", wire_sz)?;\n        writeln!(out)?;\n        writeln!(\n            out,\n            \"    fn serialize(&self, wire_buf: &mut [u8]) -> usize {{\"\n        )?;\n        writeln!(out, \"        let me = unsafe {{\")?;\n        writeln!(\n            out,\n            \"            std::slice::from_raw_parts(self as *const {} as _, {})\",\n            rs_typ, wire_sz\n        )?;\n        writeln!(out, \"        }};\")?;\n        writeln!(out, \"        wire_buf.copy_from_slice(me);\")?;\n        writeln!(out, \"        {}\", wire_sz)?;\n        writeln!(out, \"    }}\")?;\n        writeln!(out, \"}}\")?;\n\n        Ok(())\n    }\n\n    fn emit_fix_buf_struct<O: Write>(\n        &self,\n        out: &mut O,\n        rs_typ: &str,\n        fields: &[Field],\n        wire_sz: usize,\n        doc: Option<&Doc>,\n    ) -> io::Result<()> {\n        writeln!(out)?;\n        if let Some(doc) = doc {\n            doc.emit(out, 0)?;\n        }\n        writeln!(out, \"#[derive(Copy, Clone)]\")?;\n        writeln!(out, \"pub struct {} {{\", rs_typ)?;\n        writeln!(out, \"    data: [u8; {}],\", wire_sz)?;\n        writeln!(out, \"}}\")?;\n\n        writeln!(out)?;\n        writeln!(out, \"#[allow(unused_parens)]\")?;\n        writeln!(out, \"impl {} {{\", rs_typ)?;\n        writeln!(\n            out,\n            \"    pub(crate) unsafe fn from_data<D: AsRef<[u8]> + ?Sized>(data: &D) -> &{} {{\",\n            rs_typ\n        )?;\n        writeln!(\n            out,\n            \"        debug_assert_eq!(data.as_ref().len(), {});\",\n            wire_sz\n        )?;\n        writeln!(\n            out,\n            \"        &*(data.as_ref() as *const [u8] as *const {})\",\n            rs_typ\n        )?;\n        writeln!(out, \"    }}\")?;\n\n        writeln!(out)?;\n        writeln!(\n            out,\n            \"    fn wire_ptr(&self) -> *const u8 {{ self.data.as_ptr() }}\"\n        )?;\n\n        writeln!(out)?;\n        writeln!(out, \"    fn wire_len(&self) -> usize {{ self.data.len() }}\")?;\n\n        self.emit_struct_accessors(out, rs_typ, fields)?;\n\n        writeln!(out, \"}}\")?;\n\n        self.emit_sizeof_test(out, rs_typ, wire_sz)?;\n\n        writeln!(out)?;\n        writeln!(out, \"impl base::Wired for {} {{\", rs_typ)?;\n        writeln!(out, \"    type Params = ();\")?;\n        writeln!(\n            out,\n            \"    unsafe fn compute_wire_len(_ptr: *const u8, _params: ()) -> usize {{ {} }}\",\n            wire_sz\n        )?;\n        writeln!(out)?;\n        writeln!(out, \"    fn wire_len(&self) -> usize {{ {} }}\", wire_sz)?;\n        writeln!(out)?;\n        writeln!(\n            out,\n            \"    fn serialize(&self, wire_buf: &mut [u8]) -> usize {{\"\n        )?;\n        writeln!(out, \"        wire_buf.copy_from_slice(&self.data);\")?;\n        writeln!(out, \"        self.data.len()\")?;\n        writeln!(out, \"    }}\")?;\n        writeln!(out, \"}}\")?;\n\n        self.emit_debug_impl(out, rs_typ, fields)?;\n\n        Ok(())\n    }\n\n    fn emit_dyn_buf_struct<O: Write>(\n        &self,\n        out: &mut O,\n        rs_typ: &str,\n        fields: &[Field],\n        params_struct: Option<&ParamsStruct>,\n        doc: Option<&Doc>,\n    ) -> io::Result<()> {\n        if let Some(params_struct) = params_struct {\n            params_struct.emit(out)?;\n        }\n        writeln!(out)?;\n        if let Some(doc) = doc {\n            doc.emit(out, 0)?;\n        }\n        writeln!(out, \"pub struct {} {{\", rs_typ)?;\n        writeln!(out, \"    data: [u8],\")?;\n        writeln!(out, \"}}\")?;\n        writeln!(out)?;\n        writeln!(out, \"#[allow(unused_parens)]\")?;\n        writeln!(out, \"impl {} {{\", rs_typ)?;\n        writeln!(\n            out,\n            \"    pub(crate) unsafe fn from_data<D: AsRef<[u8]> + ?Sized>(data: &D) -> &{} {{\",\n            rs_typ\n        )?;\n        if params_struct.is_none() {\n            writeln!(\n                out,\n                \"        debug_assert_eq!(data.as_ref().len(), {}::compute_wire_len(data.as_ref().as_ptr(), ()));\",\n                rs_typ\n            )?;\n        }\n        writeln!(\n            out,\n            \"        &*(data.as_ref() as *const [u8] as *const {})\",\n            rs_typ\n        )?;\n        writeln!(out, \"    }}\")?;\n\n        writeln!(out)?;\n        writeln!(\n            out,\n            \"    fn wire_ptr(&self) -> *const u8 {{ self.data.as_ptr() }}\"\n        )?;\n\n        let compute_wire_len_stmts =\n            self.emit_compute_offset_and_get_stmts(out, rs_typ, fields, params_struct)?;\n        self.emit_struct_accessors(out, rs_typ, fields)?;\n\n        writeln!(out, \"}}\")?;\n\n        writeln!(out)?;\n        writeln!(out, \"impl base::Wired for {} {{\", rs_typ)?;\n        writeln!(out, \"    type Params = {};\", params_struct.rs_typ())?;\n        self.emit_compute_func(\n            out,\n            \"compute_wire_len\",\n            params_struct,\n            &compute_wire_len_stmts,\n        )?;\n        writeln!(out)?;\n        writeln!(out, \"    fn wire_len(&self) -> usize {{ self.data.len() }}\")?;\n        writeln!(out)?;\n        writeln!(\n            out,\n            \"    fn serialize(&self, wire_buf: &mut [u8]) -> usize {{\"\n        )?;\n        writeln!(out, \"        wire_buf.copy_from_slice(&self.data);\")?;\n        writeln!(out, \"        self.data.len()\")?;\n        writeln!(out, \"    }}\")?;\n        writeln!(out, \"}}\")?;\n\n        writeln!(out)?;\n        writeln!(out, \"#[derive(Clone)]\")?;\n        writeln!(out, \"pub struct {}Buf {{\", rs_typ)?;\n        writeln!(out, \"    data: Vec<u8>,\")?;\n        writeln!(out, \"}}\")?;\n\n        writeln!(out)?;\n        writeln!(out, \"impl {}Buf {{\", rs_typ)?;\n        writeln!(\n            out,\n            \"    pub(crate) unsafe fn from_data(data: Vec<u8>) -> {}Buf {{\",\n            rs_typ\n        )?;\n        if params_struct.is_none() {\n            writeln!(\n                out,\n                \"        debug_assert_eq!({}::compute_wire_len(data.as_ptr(), ()), data.len());\",\n                rs_typ\n            )?;\n        }\n        writeln!(out, \"        {}Buf {{ data }}\", rs_typ)?;\n        writeln!(out, \"    }}\")?;\n        writeln!(out, \"}}\")?;\n\n        writeln!(out)?;\n        writeln!(out, \"impl std::ops::Deref for {}Buf {{\", rs_typ)?;\n        writeln!(out, \"    type Target = {};\", rs_typ)?;\n        writeln!(out, \"    fn deref(&self) -> &Self::Target {{\")?;\n        writeln!(\n            out,\n            \"        unsafe {{ {}::from_data(&self.data) }}\",\n            rs_typ\n        )?;\n        writeln!(out, \"    }}\")?;\n        writeln!(out, \"}}\")?;\n\n        writeln!(out)?;\n        writeln!(\n            out,\n            \"impl std::borrow::Borrow<{}> for {}Buf {{\",\n            rs_typ, rs_typ\n        )?;\n        writeln!(out, \"    fn borrow(&self) -> &{} {{\", rs_typ)?;\n        writeln!(\n            out,\n            \"        unsafe {{ {}::from_data(&self.data) }}\",\n            rs_typ\n        )?;\n        writeln!(out, \"    }}\")?;\n        writeln!(out, \"}}\")?;\n\n        writeln!(out)?;\n        writeln!(out, \"impl std::borrow::ToOwned for {} {{\", rs_typ)?;\n        writeln!(out, \"    type Owned = {}Buf;\", rs_typ)?;\n        writeln!(out, \"    fn to_owned(&self) -> Self::Owned {{\")?;\n        writeln!(out, \"        {}Buf {{\", rs_typ)?;\n        writeln!(out, \"            data: self.data.to_vec()\")?;\n        writeln!(out, \"        }}\")?;\n        writeln!(out, \"    }}\")?;\n        writeln!(out, \"}}\")?;\n\n        self.emit_debug_impl(out, rs_typ, fields)?;\n        self.emit_debug_impl(out, &(rs_typ.to_string() + \"Buf\"), fields)?;\n\n        self.emit_dyn_buf_struct_iterator(out, rs_typ, params_struct)?;\n\n        Ok(())\n    }\n\n    pub(super) fn field_compute_len_stmts(\n        &self,\n        field: &Field,\n        stmts: &mut Vec<String>,\n        struct_offset: &Expr,\n    ) {\n        let struct_offset = if let Expr::Value(0) = struct_offset {\n            String::new()\n        } else {\n            self.build_rs_expr(struct_offset, \"\", \"\", &[]) + \" + \"\n        };\n        match field {\n            Field::Field {\n                name,\n                struct_style: Some(StructStyle::DynBuf),\n                params_struct,\n                module,\n                rs_typ,\n                ..\n            } => {\n                let q_rs_typ = (module, rs_typ).qualified_rs_typ();\n                let params_expr = self.build_params_expr(\n                    params_struct.as_ref(),\n                    module.as_ref().map(|s| s.as_str()),\n                    \"\",\n                    \"\",\n                );\n                stmts.push(format!(\"// {}\", name));\n                stmts.push(format!(\n                    \"sz += {}::compute_wire_len(ptr.add({}sz), {});\",\n                    q_rs_typ, struct_offset, params_expr\n                ));\n            }\n            Field::Field {\n                wire_sz,\n                name,\n                is_fieldref,\n                is_paramref,\n                rs_typ,\n                ..\n            } => {\n                stmts.push(format!(\"// {}\", name));\n\n                if *is_fieldref || *is_paramref {\n                    stmts.push(format!(\n                        \"let {} = *(ptr.add({}sz) as *const {});\",\n                        name, struct_offset, rs_typ\n                    ));\n                }\n\n                stmts.push(format!(\n                    \"sz += {};\",\n                    self.build_rs_expr(wire_sz, \"\", \"\", &[])\n                ));\n            }\n            Field::List {\n                name,\n                len_expr,\n                module,\n                rs_typ,\n                struct_style: Some(StructStyle::DynBuf),\n                params_struct,\n                is_fieldref,\n                ..\n            } => {\n                let q_rs_typ = (module, rs_typ).qualified_rs_typ();\n                stmts.push(format!(\"// {}\", name));\n                if *is_fieldref {\n                    stmts.push(format!(\"let mut {} = Vec::new();\", name));\n                }\n                stmts.push(format!(\n                    \"for _ in 0 .. {} {{\",\n                    self.build_rs_expr(len_expr, \"\", \"\", &[])\n                ));\n                let params_expr = self.build_params_expr(\n                    params_struct.as_ref(),\n                    module.as_ref().map(|s| s.as_str()),\n                    \"\",\n                    \"\",\n                );\n                if *is_fieldref {\n                    stmts.push(format!(\n                        \"    let len = {}::compute_wire_len(ptr.add({}sz), {});\",\n                        q_rs_typ, struct_offset, params_expr\n                    ));\n                    stmts.push(format!(\n                        \"    let data = std::slice::from_raw_parts(ptr.add({}sz), len);\",\n                        struct_offset\n                    ));\n                    stmts.push(format!(\"    {}.push({}::from_data(data));\", name, q_rs_typ));\n                    stmts.push(\"    sz += len;\".to_string());\n                } else {\n                    stmts.push(format!(\n                        \"    sz += {}::compute_wire_len(ptr.add({}sz), {});\",\n                        q_rs_typ, struct_offset, params_expr\n                    ));\n                }\n                stmts.push(\"}\".to_string());\n            }\n            Field::List {\n                name,\n                wire_sz,\n                is_fieldref,\n                len_expr,\n                module,\n                rs_typ,\n                ..\n            } => {\n                let q_rs_typ = (module, rs_typ).qualified_rs_typ();\n                stmts.push(format!(\"// {}\", name));\n                if *is_fieldref {\n                    stmts.push(format!(\"let {} = {{\", name));\n                    stmts.push(format!(\n                        \"    let len = {};\",\n                        self.build_rs_expr(len_expr, \"\", \"\", &[])\n                    ));\n                    stmts.push(format!(\n                        \"    let data = ptr.add({}sz) as *const {};\",\n                        struct_offset, q_rs_typ\n                    ));\n                    stmts.push(format!(\n                        \"    sz += len * std::mem::size_of::<{}>();\",\n                        q_rs_typ\n                    ));\n                    stmts.push(\"    std::slice::from_raw_parts(data, len)\".to_string());\n                    stmts.push(\"};\".to_string());\n                } else {\n                    stmts.push(format!(\n                        \"sz += {};\",\n                        self.build_rs_expr(wire_sz, \"\", \"\", &[])\n                    ));\n                }\n            }\n            Field::Switch {\n                name,\n                module,\n                rs_typ,\n                params_struct,\n                is_mask,\n                ..\n            } => {\n                let params_expr = self.build_params_expr(\n                    Some(params_struct),\n                    module.as_ref().map(|m| m.as_str()),\n                    \"\",\n                    \"\",\n                );\n                let q_rs_typ = (module, rs_typ).qualified_rs_typ();\n                let impl_type = if *is_mask {\n                    format!(\"<&[{}]>\", q_rs_typ)\n                } else {\n                    q_rs_typ\n                };\n                stmts.push(format!(\"// {}\", name));\n                stmts.push(format!(\n                    \"sz += {}::compute_wire_len(ptr.add({}sz), {});\",\n                    impl_type, struct_offset, params_expr\n                ));\n            }\n            Field::Pad { wire_sz, .. } => {\n                stmts.push(\"// pad\".to_string());\n                stmts.push(format!(\n                    \"sz += {};\",\n                    self.build_rs_expr(wire_sz, \"\", \"\", &[])\n                ));\n            }\n            Field::AlignPad {\n                wire_sz: Expr::AlignPad(align, _),\n                ..\n            } => {\n                stmts.push(\"// align pad\".to_string());\n                stmts.push(format!(\"sz += base::align_pad(sz, {});\", align));\n            }\n            f => unreachable!(\"missed handling of field in compute_wire_len: {:?}\", f),\n        }\n    }\n\n    pub(super) fn emit_compute_func<O: Write>(\n        &self,\n        out: &mut O,\n        fname: &str,\n        params_struct: Option<&ParamsStruct>,\n        stmts: &[String],\n    ) -> io::Result<()> {\n        writeln!(out)?;\n        writeln!(\n            out,\n            \"    unsafe fn {}(ptr: *const u8, {}params: {}) -> usize {{\",\n            fname,\n            if params_struct.is_none() { \"_\" } else { \"\" },\n            params_struct.rs_typ(),\n        )?;\n        if let Some(params_struct) = params_struct {\n            writeln!(out, \"        let {} {{\", params_struct.rs_typ)?;\n            for p in &params_struct.params {\n                writeln!(out, \"{}{},\", cg::ind(3), p)?;\n            }\n            writeln!(out, \"        }} = params;\")?;\n        }\n        for s in stmts {\n            writeln!(out, \"        {}\", s)?;\n        }\n        writeln!(out, \"        sz\")?;\n        writeln!(out, \"    }}\")?;\n        Ok(())\n    }\n\n    /// Get the statements for each field size calculation, and emit offset function\n    /// each time we hit a field that requires an offset function.\n    /// The resulting statements can be used to emit the compute_wire_len function\n    pub(super) fn emit_compute_offset_and_get_stmts<O: Write>(\n        &self,\n        out: &mut O,\n        _struct_rs_typ: &str,\n        fields: &[Field],\n        params_struct: Option<&ParamsStruct>,\n    ) -> io::Result<Vec<String>> {\n        let mut stmts = vec![\"let mut sz = 0;\".to_string()];\n\n        for f in fields {\n            if let Field::Field {\n                name,\n                need_compute_offset: true,\n                ..\n            }\n            | Field::List {\n                name,\n                need_compute_offset: true,\n                ..\n            }\n            | Field::Switch {\n                name,\n                need_compute_offset: true,\n                ..\n            } = f\n            {\n                let fname = format!(\"compute_{}_offset\", name);\n                self.emit_compute_func(out, &fname, params_struct, &stmts)?;\n            }\n            self.field_compute_len_stmts(f, &mut stmts, &Expr::Value(0));\n        }\n\n        Ok(stmts)\n    }\n\n    pub(super) fn emit_struct_accessors<O: Write>(\n        &self,\n        out: &mut O,\n        struct_rs_typ: &str,\n        fields: &[Field],\n    ) -> io::Result<()> {\n        for f in fields {\n            writeln!(out)?;\n            if self.handle_client_message_data(out, struct_rs_typ, f)? {\n                continue;\n            }\n            if self.handle_randr_notify_data(out, struct_rs_typ, f)? {\n                continue;\n            }\n            match f {\n                Field::Field {\n                    name,\n                    rs_typ,\n                    wire_off,\n                    doc,\n                    ..\n                } if rs_typ == \"bool\" => {\n                    if let Some(doc) = doc {\n                        doc.emit(out, 1)?;\n                    }\n                    writeln!(out, \"    pub fn {}(&self) -> bool {{\", name)?;\n                    writeln!(\n                        out,\n                        \"        let val = unsafe {{ *(self.wire_ptr().add({})) }};\",\n                        self.build_rs_expr(wire_off, \"self.\", \"()\", fields)\n                    )?;\n                    writeln!(out, \"        val != 0\")?;\n                    writeln!(out, \"    }}\")?;\n                }\n                Field::Field {\n                    name,\n                    module,\n                    rs_typ,\n                    wire_off,\n                    r#enum,\n                    mask,\n                    doc,\n                    ..\n                } if r#enum.is_some() || mask.is_some() => {\n                    let q_rs_typ = (module, rs_typ).qualified_rs_typ();\n                    let ret_q_rs_typ = r#enum.as_ref().or_else(|| mask.as_ref()).unwrap();\n                    let ret_q_rs_typ = {\n                        let (module, rs_typ) = ret_q_rs_typ;\n                        (module, rs_typ).qualified_rs_typ()\n                    };\n                    if let Some(doc) = doc {\n                        doc.emit(out, 1)?;\n                    }\n                    writeln!(out, \"    pub fn {}(&self) -> {} {{\", name, ret_q_rs_typ)?;\n                    writeln!(out, \"        unsafe {{\")?;\n                    writeln!(\n                        out,\n                        \"            let offset = {};\",\n                        self.build_rs_expr(wire_off, \"self.\", \"()\", fields)\n                    )?;\n                    writeln!(\n                        out,\n                        \"            let ptr = self.wire_ptr().add(offset) as *const {};\",\n                        q_rs_typ\n                    )?;\n                    writeln!(out, \"            let val = *ptr as u32;\")?;\n                    writeln!(\n                        out,\n                        \"            std::mem::transmute::<u32, {}>(val)\",\n                        ret_q_rs_typ,\n                    )?;\n                    writeln!(out, \"        }}\")?;\n                    writeln!(out, \"    }}\")?;\n                }\n                Field::Field {\n                    name,\n                    module,\n                    rs_typ,\n                    wire_off,\n                    is_xid: true,\n                    is_union: true,\n                    doc,\n                    ..\n                } => {\n                    // XID unions constructed out of context require a `Unknown` variant\n                    let q_rs_typ = (module, rs_typ).qualified_rs_typ();\n                    if let Some(doc) = doc {\n                        doc.emit(out, 1)?;\n                    }\n                    writeln!(out, \"    fn {}(&self) -> {} {{\", name, q_rs_typ)?;\n                    writeln!(out, \"        unsafe {{\")?;\n                    writeln!(\n                        out,\n                        \"{}let offset = {};\",\n                        cg::ind(3),\n                        self.build_rs_expr(wire_off, \"self.\", \"()\", fields)\n                    )?;\n                    writeln!(\n                        out,\n                        \"{}let res_id = *(self.wire_ptr().add(offset) as *const u32);\",\n                        cg::ind(3)\n                    )?;\n                    writeln!(out, \"{}{}::Unknown(res_id)\", cg::ind(3), q_rs_typ)?;\n                    writeln!(out, \"        }}\")?;\n                    writeln!(out, \"    }}\")?;\n                }\n                Field::Field {\n                    name,\n                    module,\n                    rs_typ,\n                    wire_off,\n                    is_fieldref,\n                    is_copy: true,\n                    doc,\n                    ..\n                } => {\n                    let q_rs_typ = (module, rs_typ).qualified_rs_typ();\n                    // lenfield visibility is not necessary, lists are exposed as sliced\n                    let visibility = if *is_fieldref { \"\" } else { \"pub \" };\n                    if let Some(doc) = doc {\n                        doc.emit(out, 1)?;\n                    }\n                    writeln!(\n                        out,\n                        \"{}{}fn {}(&self) -> {} {{\",\n                        cg::ind(1),\n                        visibility,\n                        name,\n                        q_rs_typ\n                    )?;\n                    writeln!(out, \"{}unsafe {{\", cg::ind(2))?;\n                    writeln!(\n                        out,\n                        \"{}let offset = {};\",\n                        cg::ind(3),\n                        self.build_rs_expr(wire_off, \"self.\", \"()\", fields)\n                    )?;\n                    writeln!(\n                        out,\n                        \"{}let ptr = self.wire_ptr().add(offset) as *const {};\",\n                        cg::ind(3),\n                        q_rs_typ\n                    )?;\n                    writeln!(out, \"            *ptr\")?;\n                    writeln!(out, \"        }}\")?;\n                    writeln!(out, \"    }}\")?;\n                }\n                Field::Field {\n                    name,\n                    module,\n                    rs_typ,\n                    wire_off,\n                    wire_sz,\n                    is_copy: false,\n                    is_union: false,\n                    struct_style,\n                    params_struct,\n                    doc,\n                    need_compute_offset,\n                    ..\n                } => {\n                    let q_rs_typ = (module, rs_typ).qualified_rs_typ();\n\n                    let params_expr = self.build_params_expr(\n                        params_struct.as_ref(),\n                        module.as_ref().map(|s| s.as_str()),\n                        \"self.\",\n                        \"()\",\n                    );\n                    if let Some(doc) = doc {\n                        doc.emit(out, 1)?;\n                    }\n                    writeln!(out, \"    pub fn {}(&self) -> &{} {{\", name, q_rs_typ)?;\n                    writeln!(out, \"{}unsafe {{\", cg::ind(2))?;\n                    if *need_compute_offset {\n                        writeln!(\n                            out,\n                            \"{}let offset = Self::compute_{}_offset(self.wire_ptr(), {});\",\n                            cg::ind(3),\n                            name,\n                            params_expr\n                        )?;\n                    } else {\n                        writeln!(\n                            out,\n                            \"{}let offset = {};\",\n                            cg::ind(3),\n                            self.build_rs_expr(wire_off, \"self.\", \"()\", fields)\n                        )?;\n                    }\n                    if let Some(StructStyle::DynBuf) = struct_style {\n                        writeln!(\n                            out,\n                            \"{}let len = {}::compute_wire_len(self.wire_ptr().add(offset), {});\",\n                            cg::ind(3),\n                            q_rs_typ,\n                            params_expr\n                        )?;\n                    } else {\n                        writeln!(\n                            out,\n                            \"            let len = {};\",\n                            self.build_rs_expr(wire_sz, \"self.\", \"()\", fields)\n                        )?;\n                    }\n                    writeln!(out, \"            let data = std::slice::from_raw_parts(self.wire_ptr().add(offset), len);\")?;\n                    writeln!(out, \"            {}::from_data(data)\", q_rs_typ,)?;\n                    writeln!(out, \"        }}\")?;\n                    writeln!(out, \"    }}\")?;\n                }\n                Field::Field {\n                    name,\n                    module,\n                    rs_typ,\n                    wire_off,\n                    wire_sz,\n                    is_copy: false,\n                    is_union: true,\n                    need_compute_offset,\n                    doc,\n                    ..\n                } => {\n                    let q_rs_typ = (module, rs_typ).qualified_rs_typ();\n                    if let Some(doc) = doc {\n                        doc.emit(out, 1)?;\n                    }\n                    writeln!(out, \"    fn {}(&self) -> {} {{\", name, q_rs_typ)?;\n                    writeln!(out, \"        unsafe {{\")?;\n                    if *need_compute_offset {\n                        writeln!(\n                            out,\n                            \"            let offset = Self::compute_{}_offset(self.wire_ptr());\",\n                            name\n                        )?;\n                    } else {\n                        writeln!(\n                            out,\n                            \"            let offset = {};\",\n                            self.build_rs_expr(wire_off, \"self.\", \"()\", fields)\n                        )?;\n                    }\n                    writeln!(\n                        out,\n                        \"{}let len = {};\",\n                        cg::ind(3),\n                        self.build_rs_expr(wire_sz, \"self.\", \"()\", fields)\n                    )?;\n                    writeln!(out, \"{}let data = std::slice::from_raw_parts(self.wire_ptr().add(offset), len);\", cg::ind(3))?;\n                    writeln!(out, \"{}{}::from_data(data)\", cg::ind(3), q_rs_typ)?;\n                    writeln!(out, \"        }}\")?;\n                    writeln!(out, \"    }}\")?;\n                }\n                Field::List {\n                    name,\n                    wire_off,\n                    len_expr,\n                    is_prop: true,\n                    doc,\n                    ..\n                } => {\n                    if let Some(doc) = doc {\n                        doc.emit(out, 1)?;\n                    }\n                    writeln!(\n                        out,\n                        \"{}pub fn {}<P: PropEl>(&self) -> &[P] {{\",\n                        cg::ind(1),\n                        name\n                    )?;\n                    writeln!(\n                        out,\n                        \"{}assert_eq!(self.format(), P::FORMAT, \\\"mismatched format of {}::{}::{}\\\");\",\n                        cg::ind(2),\n                        self.xcb_mod,\n                        struct_rs_typ,\n                        name\n                    )?;\n                    writeln!(out, \"{}unsafe {{\", cg::ind(2))?;\n                    writeln!(\n                        out,\n                        \"{}let offset = {};\",\n                        cg::ind(3),\n                        self.build_rs_expr(wire_off, \"self.\", \"()\", fields)\n                    )?;\n                    writeln!(\n                        out,\n                        \"{}let len = {};\",\n                        cg::ind(3),\n                        self.build_rs_expr(len_expr, \"self.\", \"()\", fields)\n                    )?;\n                    writeln!(\n                        out,\n                        \"{}let len = len / std::mem::size_of::<P>();\",\n                        cg::ind(3)\n                    )?;\n                    writeln!(\n                        out,\n                        \"{}let ptr = self.wire_ptr().add(offset) as *const P;\",\n                        cg::ind(3),\n                    )?;\n                    writeln!(out, \"{}std::slice::from_raw_parts(ptr, len)\", cg::ind(3))?;\n                    writeln!(out, \"{}}}\", cg::ind(2))?;\n                    writeln!(out, \"{}}}\", cg::ind(1))?;\n                }\n                Field::List {\n                    name,\n                    module,\n                    rs_typ,\n                    wire_off,\n                    len_expr,\n                    struct_style: None,\n                    doc,\n                    ..\n                } if rs_typ != \"char\" && !matches!(len_expr, Expr::Value(_)) => {\n                    let q_rs_typ = (module, rs_typ).qualified_rs_typ();\n                    let params = len_expr.params_str();\n                    if let Some(doc) = doc {\n                        doc.emit(out, 1)?;\n                    }\n                    writeln!(\n                        out,\n                        \"    pub fn {}(&self{}) -> &[{}] {{\",\n                        name, params, q_rs_typ\n                    )?;\n                    writeln!(out, \"{}unsafe {{\", cg::ind(2))?;\n                    writeln!(\n                        out,\n                        \"{}let offset = {};\",\n                        cg::ind(3),\n                        self.build_rs_expr(wire_off, \"self.\", \"()\", fields)\n                    )?;\n                    writeln!(\n                        out,\n                        \"{}let len = {};\",\n                        cg::ind(3),\n                        self.build_rs_expr(len_expr, \"self.\", \"()\", fields)\n                    )?;\n                    writeln!(\n                        out,\n                        \"{}let ptr = self.wire_ptr().add(offset) as *const {};\",\n                        cg::ind(3),\n                        q_rs_typ\n                    )?;\n                    writeln!(out, \"{}std::slice::from_raw_parts(ptr, len)\", cg::ind(3))?;\n                    writeln!(out, \"{}}}\", cg::ind(2))?;\n                    writeln!(out, \"{}}}\", cg::ind(1))?;\n                }\n                Field::List {\n                    name,\n                    module,\n                    rs_typ,\n                    wire_off,\n                    len_expr,\n                    struct_style: None,\n                    doc,\n                    ..\n                } if rs_typ != \"char\" => {\n                    let q_rs_typ = (module, rs_typ).qualified_rs_typ();\n                    let len = len_expr.fixed_length().unwrap();\n                    let params = len_expr.params_str();\n                    if let Some(doc) = doc {\n                        doc.emit(out, 1)?;\n                    }\n                    writeln!(\n                        out,\n                        \"    pub fn {}(&self{}) -> &[{}; {}] {{\",\n                        name, params, q_rs_typ, len\n                    )?;\n\n                    writeln!(out, \"        unsafe {{\")?;\n                    writeln!(\n                        out,\n                        \"            let offset = {};\",\n                        self.build_rs_expr(wire_off, \"self.\", \"()\", fields)\n                    )?;\n                    writeln!(\n                        out,\n                        \"            let ptr = self.wire_ptr().add(offset) as *const [{}; {}];\",\n                        q_rs_typ, len\n                    )?;\n                    writeln!(out, \"            &*ptr\")?;\n                    writeln!(out, \"        }}\")?;\n                    writeln!(out, \"    }}\")?;\n                }\n                Field::List {\n                    name,\n                    rs_typ,\n                    wire_off,\n                    len_expr,\n                    doc,\n                    ..\n                } if rs_typ == \"char\" => {\n                    let params = len_expr.params_str();\n                    if let Some(doc) = doc {\n                        doc.emit(out, 1)?;\n                    }\n                    writeln!(out, \"    pub fn {}(&self{}) -> &str {{\", name, params)?;\n\n                    writeln!(out, \"        unsafe {{\")?;\n                    writeln!(\n                        out,\n                        \"            let offset = {};\",\n                        self.build_rs_expr(wire_off, \"self.\", \"()\", fields)\n                    )?;\n                    writeln!(\n                        out,\n                        \"            let len = {} as _;\",\n                        self.build_rs_expr(len_expr, \"self.\", \"()\", fields)\n                    )?;\n                    writeln!(out, \"            let ptr = self.wire_ptr().add(offset);\",)?;\n                    writeln!(\n                        out,\n                        \"            let utf8 = std::slice::from_raw_parts(ptr, len);\",\n                    )?;\n                    writeln!(out, \"            std::str::from_utf8(utf8).unwrap()\")?;\n                    writeln!(out, \"        }}\")?;\n                    writeln!(out, \"    }}\")?;\n                }\n                Field::List {\n                    name,\n                    module,\n                    rs_typ,\n                    wire_off,\n                    len_expr: Expr::UntilEnd,\n                    struct_style: None | Some(StructStyle::WireLayout | StructStyle::FixBuf),\n                    doc,\n                    ..\n                } => {\n                    let q_rs_typ = (module, rs_typ).qualified_rs_typ();\n\n                    if let Some(doc) = doc {\n                        doc.emit(out, 1)?;\n                    }\n                    writeln!(\n                        out,\n                        \"{}pub fn {}(&self) -> &[{}] {{\",\n                        cg::ind(1),\n                        name,\n                        q_rs_typ\n                    )?;\n                    writeln!(out, \"{}unsafe {{\", cg::ind(2))?;\n                    writeln!(\n                        out,\n                        \"{}let offset = {};\",\n                        cg::ind(3),\n                        self.build_rs_expr(wire_off, \"self.\", \"()\", fields)\n                    )?;\n                    writeln!(out, \"{}assert_eq!((self.length() as usize - offset) % std::mem::size_of::<{}>(), 0);\", cg::ind(3), q_rs_typ)?;\n                    writeln!(out, \"{}let len = (self.length() as usize - offset) / std::mem::size_of::<{}>();\", cg::ind(3), q_rs_typ)?;\n                    writeln!(out, \"{}std::slice::from_raw_parts(self.wire_ptr().add(offset) as *const {}, len)\", cg::ind(3), q_rs_typ)?;\n                    writeln!(out, \"{}}}\", cg::ind(2))?;\n                    writeln!(out, \"{}}}\", cg::ind(1))?;\n                }\n                Field::List {\n                    name,\n                    module,\n                    rs_typ,\n                    wire_off,\n                    len_expr,\n                    struct_style: Some(StructStyle::WireLayout | StructStyle::FixBuf),\n                    doc,\n                    ..\n                } => {\n                    let q_rs_typ = (module, rs_typ).qualified_rs_typ();\n                    let params = len_expr.params_str();\n                    if let Some(doc) = doc {\n                        doc.emit(out, 1)?;\n                    }\n                    writeln!(\n                        out,\n                        \"    pub fn {}(&self{}) -> &[{}] {{\",\n                        name, params, q_rs_typ\n                    )?;\n\n                    writeln!(out, \"        unsafe {{\")?;\n                    writeln!(\n                        out,\n                        \"            let offset = {};\",\n                        self.build_rs_expr(wire_off, \"self.\", \"()\", fields)\n                    )?;\n                    writeln!(\n                        out,\n                        \"            let len = {} as _;\",\n                        self.build_rs_expr(len_expr, \"self.\", \"()\", fields)\n                    )?;\n                    writeln!(\n                        out,\n                        \"            let ptr = self.wire_ptr().add(offset) as *const {};\",\n                        q_rs_typ\n                    )?;\n                    writeln!(out, \"            std::slice::from_raw_parts(ptr, len)\",)?;\n                    writeln!(out, \"        }}\")?;\n                    writeln!(out, \"    }}\")?;\n                }\n                Field::List {\n                    name,\n                    module,\n                    rs_typ,\n                    wire_off,\n                    len_expr,\n                    struct_style: Some(StructStyle::DynBuf),\n                    params_struct,\n                    need_compute_offset,\n                    doc,\n                    ..\n                } => {\n                    let q_rs_typ = (module, rs_typ).qualified_rs_typ();\n                    let params = len_expr.params_str();\n                    let params_expr = self.build_params_expr(\n                        params_struct.as_ref(),\n                        module.as_ref().map(|s| s.as_str()),\n                        \"self.\",\n                        \"()\",\n                    );\n                    if let Some(doc) = doc {\n                        doc.emit(out, 1)?;\n                    }\n                    writeln!(\n                        out,\n                        \"    pub fn {}(&self{}) -> {}Iterator {{\",\n                        name, params, q_rs_typ\n                    )?;\n                    writeln!(out, \"        unsafe {{\")?;\n                    if *need_compute_offset {\n                        writeln!(\n                            out,\n                            \"{}let offset = Self::compute_{}_offset(self.wire_ptr(), {});\",\n                            cg::ind(3),\n                            name,\n                            params_expr\n                        )?;\n                    } else {\n                        writeln!(\n                            out,\n                            \"{}let offset = {};\",\n                            cg::ind(3),\n                            self.build_rs_expr(wire_off, \"self.\", \"()\", fields)\n                        )?;\n                    }\n                    writeln!(out, \"{}{}Iterator {{\", cg::ind(3), q_rs_typ)?;\n                    writeln!(out, \"{}    params: {},\", cg::ind(3), params_expr)?;\n                    writeln!(\n                        out,\n                        \"{}    rem: {},\",\n                        cg::ind(3),\n                        self.build_rs_expr(len_expr, \"self.\", \"()\", fields)\n                    )?;\n                    writeln!(out, \"{}    ptr: self.wire_ptr().add(offset),\", cg::ind(3))?;\n                    writeln!(out, \"{}    phantom: std::marker::PhantomData,\", cg::ind(3))?;\n                    writeln!(out, \"{}}}\", cg::ind(3))?;\n                    writeln!(out, \"        }}\")?;\n                    writeln!(out, \"    }}\")?;\n                }\n                _ => {}\n            }\n        }\n        Ok(())\n    }\n\n    // specific handling of ClientMessageEvent::data()\n    // This is nearly static function definition. We could possibly directly define that in the\n    // xproto module in lib.rs\n    fn handle_client_message_data<O: Write>(\n        &self,\n        out: &mut O,\n        struct_rs_typ: &str,\n        field: &Field,\n    ) -> io::Result<bool> {\n        if self.xcb_mod == \"xproto\"\n            && struct_rs_typ == \"ClientMessageEvent\"\n            && matches!(field, Field::Field{name, ..} if name == \"data\")\n        {\n            writeln!(out)?;\n            writeln!(\n                out,\n                \"{}pub fn data(&self) -> ClientMessageData {{\",\n                cg::ind(1)\n            )?;\n            writeln!(out, \"{}unsafe {{\", cg::ind(2))?;\n            writeln!(out, \"{}match self.format() {{\", cg::ind(3))?;\n            for sz in [8, 16, 32] {\n                writeln!(\n                    out,\n                    \"{}{} => ClientMessageData::Data{} (\",\n                    cg::ind(4),\n                    sz,\n                    sz\n                )?;\n                writeln!(out, \"{}std::slice::from_raw_parts(\", cg::ind(5))?;\n                writeln!(\n                    out,\n                    \"{}self.wire_ptr().add(12) as *const u{}, {}\",\n                    cg::ind(6),\n                    sz,\n                    (20 * 8) / sz\n                )?;\n                writeln!(out, \"{}).try_into().unwrap()\", cg::ind(5))?;\n                writeln!(out, \"{}),\", cg::ind(4))?;\n            }\n            writeln!(\n                out,\n                \"{}format => unreachable!(\\\"invalid ClientMessageEvent format: {{}}\\\", format),\",\n                cg::ind(4)\n            )?;\n            writeln!(out, \"{}}}\", cg::ind(3))?;\n            writeln!(out, \"{}}}\", cg::ind(2))?;\n            writeln!(out, \"{}}}\", cg::ind(1))?;\n            Ok(true)\n        } else {\n            Ok(false)\n        }\n    }\n\n    fn handle_randr_notify_data<O: Write>(\n        &self,\n        out: &mut O,\n        struct_rs_typ: &str,\n        field: &Field,\n    ) -> io::Result<bool> {\n        if self.xcb_mod == \"randr\"\n            && struct_rs_typ == \"NotifyEvent\"\n            && matches!(field, Field::Field{name, ..} if name == \"u\")\n        {\n            writeln!(out)?;\n            writeln!(out, \"{}pub fn u(&self) -> NotifyData {{\", cg::ind(1))?;\n            writeln!(out, \"{}unsafe {{\", cg::ind(2))?;\n            writeln!(out, \"{}match self.sub_code() {{\", cg::ind(3))?;\n\n            for code in RANDR_SUBCODES {\n                writeln!(\n                    out,\n                    \"{}Notify::{} => NotifyData::{}(\",\n                    cg::ind(4),\n                    code.0,\n                    code.2\n                )?;\n                writeln!(out, \"{}*{}::from_data(\", cg::ind(5), code.1)?;\n                writeln!(\n                    out,\n                    \"{}std::slice::from_raw_parts(self.wire_ptr().add(4), 28)\",\n                    cg::ind(6)\n                )?;\n                writeln!(out, \"{})\", cg::ind(5))?;\n                writeln!(out, \"{}),\", cg::ind(4))?;\n            }\n\n            writeln!(out, \"{}}}\", cg::ind(3))?;\n            writeln!(out, \"{}}}\", cg::ind(2))?;\n            writeln!(out, \"{}}}\", cg::ind(1))?;\n\n            Ok(true)\n        } else {\n            Ok(false)\n        }\n    }\n\n    pub(super) fn emit_debug_impl<O: Write>(\n        &self,\n        out: &mut O,\n        rs_typ: &str,\n        fields: &[Field],\n    ) -> io::Result<()> {\n        writeln!(out)?;\n        writeln!(out, \"impl std::fmt::Debug for {} {{\", rs_typ)?;\n        writeln!(\n            out,\n            \"    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {{\"\n        )?;\n        writeln!(out, \"        f.debug_struct(\\\"{}\\\")\", rs_typ)?;\n        for f in fields {\n            match f {\n                Field::Field { name, .. } => {\n                    writeln!(out, \"{}.field(\\\"{}\\\", &self.{}())\", cg::ind(3), name, name)?;\n                }\n                Field::List {\n                    name,\n                    is_prop: true,\n                    ..\n                } => {\n                    writeln!(\n                        out,\n                        \"{}.field(\\\"{}\\\", &self.{}::<u8>())\",\n                        cg::ind(3),\n                        name,\n                        name\n                    )?;\n                }\n                Field::List { name, wire_sz, .. } if wire_sz.params().is_empty() => {\n                    writeln!(out, \"{}.field(\\\"{}\\\", &self.{}())\", cg::ind(3), name, name)?;\n                }\n                Field::List { .. } => {\n                    // TODO\n                }\n                Field::Switch { .. } => {\n                    // TODO\n                }\n                Field::Pad {\n                    wire_sz: Expr::Value(sz),\n                    ..\n                } => {\n                    writeln!(out, \"{}.field(\\\"pad\\\", &{})\", cg::ind(3), sz)?;\n                }\n                Field::AlignPad {\n                    wire_sz: Expr::AlignPad(sz, _),\n                    ..\n                } => {\n                    writeln!(out, \"{}.field(\\\"align_pad\\\", &{})\", cg::ind(3), sz)?;\n                }\n                _ => {}\n            }\n        }\n        writeln!(out, \"            .finish()\")?;\n        writeln!(out, \"    }}\")?;\n        writeln!(out, \"}}\")?;\n\n        Ok(())\n    }\n\n    fn emit_dyn_buf_struct_iterator<O: Write>(\n        &self,\n        out: &mut O,\n        rs_typ: &str,\n        params_struct: Option<&ParamsStruct>,\n    ) -> io::Result<()> {\n        writeln!(out)?;\n        writeln!(out, \"#[derive(Clone)]\")?;\n        writeln!(out, \"pub struct {}Iterator<'a> {{\", rs_typ)?;\n        writeln!(out, \"    pub(crate) params: {},\", params_struct.rs_typ())?;\n        writeln!(out, \"    pub(crate) rem: usize,\")?;\n        writeln!(out, \"    pub(crate) ptr: *const u8,\")?;\n        writeln!(\n            out,\n            \"    pub(crate) phantom: std::marker::PhantomData<&'a {}>,\",\n            rs_typ\n        )?;\n        writeln!(out, \"}}\")?;\n\n        writeln!(out)?;\n        writeln!(out, \"impl<'a> Iterator for {}Iterator<'a> {{\", rs_typ)?;\n        writeln!(out, \"    type Item = &'a {};\", rs_typ)?;\n        writeln!(out)?;\n        writeln!(\n            out,\n            \"    fn next(&mut self) -> std::option::Option<Self::Item> {{\"\n        )?;\n        writeln!(out, \"        if self.rem == 0 {{\")?;\n        writeln!(out, \"            None\")?;\n        writeln!(out, \"        }} else {{ unsafe {{\")?;\n        writeln!(out, \"            self.rem -= 1;\")?;\n        writeln!(\n            out,\n            \"            let len = {}::compute_wire_len(self.ptr, self.params);\",\n            rs_typ\n        )?;\n        writeln!(\n            out,\n            \"            let res = {}::from_data(std::slice::from_raw_parts(self.ptr, len));\",\n            rs_typ\n        )?;\n        writeln!(out, \"            self.ptr = self.ptr.add(len);\")?;\n        writeln!(out, \"            Some(res)\")?;\n        writeln!(out, \"        }}}}\")?;\n        writeln!(out, \"    }}\")?;\n        writeln!(out, \"}}\")?;\n\n        writeln!(out)?;\n        writeln!(\n            out,\n            \"impl<'a> std::fmt::Debug for {}Iterator<'a> {{\",\n            rs_typ\n        )?;\n        writeln!(\n            out,\n            \"    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {{\"\n        )?;\n        writeln!(out, \"        f.debug_list().entries(self.clone()).finish()\")?;\n        writeln!(out, \"    }}\")?;\n        writeln!(out, \"}}\")?;\n        Ok(())\n    }\n}\n\nstruct FieldInfo {\n    name: String,\n    module: Option<String>,\n    typ: String,\n    rs_typ: String,\n    wire_sz: Expr,\n    has_wire_layout: bool,\n    struct_style: Option<StructStyle>,\n    params_struct: Option<ParamsStruct>,\n    doc: Option<DocField>,\n    is_union: bool,\n    is_xid: bool,\n    is_mask: bool,\n}\n\npub(super) const RANDR_SUBCODES: &[(&str, &str, &str)] = &[\n    (\"CrtcChange\", \"CrtcChange\", \"Cc\"),\n    (\"OutputChange\", \"OutputChange\", \"Oc\"),\n    (\"OutputProperty\", \"OutputProperty\", \"Op\"),\n    (\"ProviderChange\", \"ProviderChange\", \"Pc\"),\n    (\"ProviderProperty\", \"ProviderProperty\", \"Pp\"),\n    (\"ResourceChange\", \"ResourceChange\", \"Rc\"),\n    (\"Lease\", \"LeaseNotify\", \"Lc\"),\n];\n\npub(super) fn enum_mask_qualified_rs_typ(\n    module: &Option<String>,\n    rs_typ: &str,\n    r#enum: &Option<(Option<String>, String)>,\n    mask: &Option<(Option<String>, String)>,\n) -> String {\n    let mod_rs_typ = r#enum\n        .as_ref()\n        .or_else(|| mask.as_ref())\n        .map(|(m, t)| (m.as_ref().map(|m| m.as_str()), t.as_str()))\n        .or_else(|| Some((module.as_ref().map(|m| m.as_str()), rs_typ)))\n        .unwrap();\n    mod_rs_typ.qualified_rs_typ()\n}\n\npub(super) fn make_field(name: String, typ: String) -> ir::Field {\n    ir::Field::Field {\n        name,\n        typ,\n        r#enum: None,\n        mask: None,\n        altenum: None,\n        altmask: None,\n    }\n}\n"
  },
  {
    "project": "rust-marc",
    "target": 1,
    "commit_id": "e626775a6998e1f97c8c1a242362602924e1693f",
    "func": "#![cfg_attr(feature = \"nightly\", feature(test))]\n#![recursion_limit = \"1024\"]\n\n#[cfg(feature = \"nightly\")]\nextern crate test;\n\nuse std::{\n    borrow::{Borrow, Cow},\n    fmt, io, slice,\n};\n\nmod directory;\npub mod errors;\nmod field;\nmod identifier;\nmod indicator;\nmod misc;\nmod tag;\n\n#[doc(inline)]\npub use field::fields::Fields;\n#[doc(inline)]\npub use field::subfield::subfields::Subfields;\n#[doc(inline)]\npub use field::subfield::Subfield;\n#[doc(inline)]\npub use field::Field;\n#[doc(inline)]\npub use field::FieldRepr;\n#[doc(inline)]\npub use field::FromFieldData;\n#[doc(inline)]\npub use identifier::Identifier;\n#[doc(inline)]\npub use indicator::Indicator;\n#[doc(inline)]\npub use tag::Tag;\n\nuse directory::Directory;\nuse errors::*;\n\nconst MAX_FIELD_LEN: usize = 9_999;\nconst MAX_RECORD_LEN: usize = 99_999;\nconst RECORD_TERMINATOR: u8 = 0x1D;\nconst FIELD_TERMINATOR: u8 = 0x1E;\nconst SUBFIELD_DELIMITER: u8 = 0x1F;\n\nmacro_rules! get {\n    ($name:ident, $sname:ident, $num:expr) => {\n        pub fn $sname(&self) -> $name {\n            self.data[$num].into()\n        }\n    };\n}\n\n/// Parsed MARC Record.\n///\n/// It could be borrowed if it was parsed from a buffer or it could be owned if it was read from an\n/// `io::Read` implementor.\n#[derive(Debug, Clone)]\npub struct Record<'a> {\n    data: Cow<'a, [u8]>,\n    data_offset: usize,\n    directory: Directory,\n}\n\nimpl<'a> Record<'a> {\n    /// Will try to parse record from a buffer.\n    ///\n    /// Will borrow an `input` for the lifetime of a produced record.\n    pub fn parse(input: &[u8]) -> Result<Record<'_>> {\n        let len = misc::read_dec_5(input)?;\n        if input.len() < len {\n            return Err(Error::UnexpectedEof);\n        }\n\n        let data = &input[..len];\n        if data[len - 1] != RECORD_TERMINATOR {\n            return Err(Error::NoRecordTerminator);\n        }\n\n        let data_offset = misc::read_dec_5(&data[12..17])?;\n        let directory = Directory::parse(&data[24..data_offset])?;\n\n        Ok(Record {\n            data: Cow::Borrowed(data),\n            data_offset,\n            directory,\n        })\n    }\n\n    /// Will crate owned record from vector of bytes.\n    ///\n    /// # Panic\n    /// Will check that input length equals the record length.\n    pub fn from_vec<I>(input: I) -> Result<Record<'static>>\n    where\n        I: Into<Vec<u8>>,\n    {\n        let input = input.into();\n\n        let (data_offset, directory) = {\n            let Record {\n                data_offset,\n                directory,\n                data,\n            } = Record::parse(&*input)?;\n            assert_eq!(input.len(), data.as_ref().len());\n            (data_offset, directory)\n        };\n\n        Ok(Record {\n            data: Cow::Owned(input),\n            data_offset,\n            directory,\n        })\n    }\n\n    /// Will try to read a `Record` from an `io::Read` implementor.\n    ///\n    /// Will return `None` if reader is empty.\n    pub fn read<T: io::Read>(input: &mut T) -> Result<Option<Record<'static>>> {\n        let mut data = vec![0; 5];\n\n        if let 0 = input.read(&mut data[..1])? {\n            return Ok(None);\n        }\n\n        input.read_exact(&mut data[1..])?;\n\n        let len = misc::read_dec_5(&*data)?;\n\n        if len < 5 {\n            return Err(Error::RecordTooShort(len));\n        }\n\n        data.reserve(len - 5);\n        unsafe { data.set_len(len) };\n        input.read_exact(&mut data[5..len])?;\n\n        let data_offset = misc::read_dec_5(&data[12..17])?;\n        let directory = Directory::parse(&data[24..data_offset])?;\n\n        Ok(Some(Record {\n            data: Cow::Owned(data),\n            data_offset,\n            directory,\n        }))\n    }\n\n    /// Will return fields with tag == `Tag`\n    pub fn field<T: Into<tag::Tag>>(&self, tag: T) -> Vec<Field> {\n        let tag = tag.into();\n        let mut output = Vec::with_capacity(4);\n        for entry in self.directory.entries.iter() {\n            if entry.0 == tag {\n                let offset = self.data_offset + entry.2;\n                output.push(Field::new(tag, &self.data[offset..offset + entry.1 - 1]));\n            }\n        }\n        output\n    }\n\n    /// Will return iterator over fields of a record\n    pub fn fields(&self) -> Fields<'_> {\n        Fields::new(self)\n    }\n\n    get!(RecordStatus, record_status, 5);\n    get!(TypeOfRecord, type_of_record, 6);\n    get!(BibliographicLevel, bibliographic_level, 7);\n    get!(TypeOfControl, type_of_control, 8);\n    get!(CharacterCodingScheme, character_coding_scheme, 9);\n    get!(EncodingLevel, encoding_level, 17);\n    get!(DescriptiveCatalogingForm, descriptive_cataloging_form, 18);\n    get!(\n        MultipartResourceRecordLevel,\n        multipart_resource_record_level,\n        19\n    );\n}\n\nimpl AsRef<[u8]> for Record<'_> {\n    fn as_ref(&self) -> &[u8] {\n        self.data.borrow()\n    }\n}\n\nimpl<'a> fmt::Display for Record<'a> {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        writeln!(\n            f,\n            \"Leader: {}\",\n            String::from_utf8_lossy(&self.as_ref()[0..24])\n        )?;\n        for field in self.fields() {\n            writeln!(\n                f,\n                \"Field: {} Data({})\",\n                field.get_tag(),\n                field.get_data::<str>()\n            )?;\n        }\n        Ok(())\n    }\n}\n\n/// Write Record Extension on io::Write\npub trait WriteRecordExt: io::Write {\n    /// write a record to a io::Write implementor\n    ///\n    /// returns the length of the written record\n    fn write_record(&mut self, record: Record) -> io::Result<()>;\n}\n\nimpl<T> WriteRecordExt for T\nwhere\n    T: io::Write,\n{\n    fn write_record(&mut self, record: Record) -> io::Result<()> {\n        self.write_all(record.as_ref())\n    }\n}\n\n/// Reads records from an `io::Read` implementor.\npub struct Records<T>(T, bool);\n\nimpl<T: io::Read> Records<T> {\n    pub fn new(input: T) -> Records<T> {\n        Records(input, false)\n    }\n\n    /// Unwraps `io::Read` implementor.\n    pub fn unwrap(self) -> T {\n        self.0\n    }\n}\n\nimpl<T: io::Read> Iterator for Records<T> {\n    type Item = Result<Record<'static>>;\n\n    fn next(&mut self) -> Option<Result<Record<'static>>> {\n        if self.1 {\n            None\n        } else {\n            let result = Record::read(&mut self.0);\n            match result {\n                Ok(Some(record)) => Some(Ok(record)),\n                Ok(None) => {\n                    self.1 = true;\n                    None\n                }\n                Err(err) => {\n                    self.1 = true;\n                    Some(Err(err))\n                }\n            }\n        }\n    }\n}\n\nmacro_rules! getset {\n    ($name:ident, $geti:ident, $seti:ident, $num:expr) => {\n        pub fn $geti(&self) -> $name {\n            self.leader[$num].into()\n        }\n        pub fn $seti(&mut self, x: $name) -> &mut Self {\n            self.leader[$num] = x.into();\n            self\n        }\n    };\n}\n\n/// Record builder.\n#[derive(Clone)]\npub struct RecordBuilder {\n    leader: [u8; 24],\n    fields: Vec<FieldRepr>,\n}\n\nimpl RecordBuilder {\n    /// Creates default record builer\n    pub fn new() -> RecordBuilder {\n        RecordBuilder {\n            leader: *b\"00000nam  2200000 i 4500\",\n            fields: vec![],\n        }\n    }\n\n    /// Creates record builder from existing record\n    pub fn from_record(record: &Record) -> RecordBuilder {\n        let mut leader = [0; 24];\n        leader.copy_from_slice(&record.as_ref()[0..24]);\n        let fields = record.fields().map(FieldRepr::from).collect();\n        RecordBuilder { leader, fields }\n    }\n\n    /// Iterator over fields of this builder.\n    pub fn iter_fields(&self) -> slice::Iter<FieldRepr> {\n        self.fields.iter()\n    }\n\n    /// A way to add field to this builder.\n    ///\n    /// ### Errors\n    ///\n    /// Will return error if field is larger than 9.999 bytes.\n    pub fn add_field<T: Into<FieldRepr>>(&mut self, f: T) -> Result<&mut Self> {\n        let repr = f.into();\n        if repr.get_data().len() + 1 > MAX_FIELD_LEN {\n            return Err(Error::FieldTooLarge(repr.get_tag()));\n        }\n        self.fields.push(repr);\n        self.fields.sort_by_key(|f| f.get_tag());\n        Ok(self)\n    }\n\n    /// A way to add multiple fileds to this builder.\n    ///\n    /// ### Errors\n    ///\n    /// Will return error if any of fields is larger than 9.999 bytes.\n    pub fn add_fields<T: Into<FieldRepr>>(&mut self, fs: Vec<T>) -> Result<&mut Self> {\n        for f in fs {\n            self.add_field(f)?;\n        }\n        Ok(self)\n    }\n\n    /// Will filter fields of this builder by `fun` predicate.\n    pub fn filter_fields<F>(&mut self, mut fun: F) -> &mut RecordBuilder\n    where\n        F: FnMut(&Field) -> bool,\n    {\n        let fields = self\n            .fields\n            .clone()\n            .into_iter()\n            .filter(|ref f| {\n                let f = Field::from_repr(f);\n                fun(&f)\n            })\n            .collect();\n        self.fields = fields;\n        self\n    }\n\n    /// Will filter subfields of this builder by `fun` predicate.\n    pub fn filter_subfields<F>(&mut self, mut fun: F) -> &mut Self\n    where\n        F: FnMut(&Field, &Subfield) -> bool,\n    {\n        let fields = self\n            .fields\n            .clone()\n            .into_iter()\n            .map(|f| {\n                let fld = Field::from_repr(&f);\n                f.filter_subfields(|sf| fun(&fld, &sf))\n            })\n            .collect();\n        self.fields = fields;\n        self\n    }\n\n    /// Returns record.\n    ///\n    /// ### Errors\n    ///\n    /// Will return error if record length is greater than 99.999 bytes.\n    pub fn get_record(&self) -> Result<Record<'static>> {\n        let mut data: Vec<_> = self.leader.to_vec();\n\n        // leader + directory terminator + record terminator\n        let mut size = 24 + 1 + 1;\n        for f in self.fields.iter() {\n            // directory entry + field data length + field terminator\n            size += 12 + f.get_data().len() + 1;\n        }\n        if size > MAX_RECORD_LEN {\n            return Err(Error::RecordTooLarge(size));\n        }\n\n        // writing record length\n        data[0..5].copy_from_slice(format!(\"{:05}\", size).as_bytes());\n\n        // writing directory\n        let mut offset = 0;\n        for f in self.fields.iter() {\n            data.extend_from_slice(f.get_tag().as_ref());\n            // field data length + field terminator\n            data.extend_from_slice(format!(\"{:04}\", f.get_data().len() + 1).as_bytes());\n            data.extend_from_slice(format!(\"{:05}\", offset).as_bytes());\n            offset += f.get_data().len() + 1;\n        }\n        data.push(FIELD_TERMINATOR);\n\n        // writing base address of data\n        let len = data.len();\n        data[12..17].copy_from_slice(format!(\"{:05}\", len).as_bytes());\n\n        // writing fields\n        for f in self.fields.iter() {\n            data.extend_from_slice(f.get_data());\n            data.push(FIELD_TERMINATOR);\n        }\n\n        data.push(RECORD_TERMINATOR);\n\n        let (data_offset, directory) = match Record::parse(&*data) {\n            Ok(Record {\n                data: _,\n                data_offset,\n                directory,\n            }) => (data_offset, directory),\n            Err(err) => return Err(err),\n        };\n\n        Ok(Record {\n            data: Cow::Owned(data),\n            data_offset,\n            directory,\n        })\n    }\n\n    getset!(RecordStatus, get_record_status, set_record_status, 5);\n    getset!(TypeOfRecord, get_type_of_record, set_type_of_record, 6);\n    getset!(\n        BibliographicLevel,\n        get_bibliographic_level,\n        set_bibliographic_level,\n        7\n    );\n    getset!(TypeOfControl, get_type_of_control, set_type_of_control, 8);\n    getset!(\n        CharacterCodingScheme,\n        get_character_coding_scheme,\n        set_character_coding_scheme,\n        9\n    );\n    getset!(EncodingLevel, get_encoding_level, set_encoding_level, 17);\n    getset!(\n        DescriptiveCatalogingForm,\n        get_descriptive_cataloging_form,\n        set_descriptive_cataloging_form,\n        18\n    );\n    getset!(\n        MultipartResourceRecordLevel,\n        get_multipart_resource_record_level,\n        set_multipart_resource_record_level,\n        19\n    );\n}\n\nimpl Default for RecordBuilder {\n    fn default() -> Self {\n        Self::new()\n    }\n}\n\nmacro_rules! leader_field(\n    ($name:ident {\n        $($val:expr => $kind:ident,)+\n    }) => (\n        #[derive(Debug, PartialEq, Clone)]\n        pub enum $name {\n            $($kind),+,\n            Unknown(u8),\n        }\n\n        impl From<u8> for $name {\n            #[inline]\n            fn from(x: u8) -> $name {\n                match x {\n                    $($val => $name::$kind),+,\n                    b => $name::Unknown(b),\n                }\n            }\n        }\n\n        impl From<$name> for u8 {\n            #[inline]\n            fn from(x: $name) -> u8 {\n                match x {\n                    $($name::$kind => $val),+,\n                    $name::Unknown(b) => b,\n                }\n            }\n        }\n    );\n);\n\nleader_field! {\n    RecordStatus {\n        b'a' => IncreaseInEncodingLevel,\n        b'c' => CorrectedOrRevised,\n        b'd' => Deleted,\n        b'n' => New,\n        b'p' => IncreaseInEncodingLevelFromPrepublication,\n    }\n}\n\nleader_field! {\n    TypeOfRecord {\n        b'a' => LanguageMaterial,\n        b'c' => NotatedMusic,\n        b'd' => ManuscriptNotatedMusic,\n        b'e' => CartographicMaterial,\n        b'f' => ManuscriptCartographicMaterial,\n        b'g' => ProjectedMedium,\n        b'i' => NonmusicalSoundRecording,\n        b'j' => MusicalSoundRecording,\n        b'k' => TwoDimensionalNonprojectableGraphic,\n        b'm' => ComputerFile,\n        b'o' => Kit,\n        b'p' => MixedMaterials,\n        b'r' => ThreeDimensionalArtifactOrNaturallyOccurringObject,\n        b't' => ManuscriptLanguageMaterial,\n    }\n}\n\nleader_field! {\n    BibliographicLevel {\n        b'a' => MonographicComponentPart,\n        b'b' => SerialComponentPart,\n        b'c' => Collection,\n        b'd' => Subunit,\n        b'i' => IntegratingResource,\n        b'm' => MonographOrItem,\n        b's' => Serial,\n    }\n}\n\nleader_field! {\n    TypeOfControl {\n        b' ' => NoSpecifiedType,\n        b'a' => Archival,\n    }\n}\n\nleader_field! {\n    CharacterCodingScheme {\n        b' ' => Marc8,\n        b'a' => UcsUnicode,\n    }\n}\n\nleader_field! {\n    EncodingLevel {\n        b' ' => FullLevel,\n        b'1' => FullLevelMaterialNotExamined,\n        b'2' => LessThanFullLevelMaterialNotExamined,\n        b'3' => AbbreviatedLevel,\n        b'4' => CoreLevel,\n        b'5' => PartialLevel,\n        b'7' => MinimalLevel,\n        b'8' => PrepublicationLevel,\n        b'u' => UnknownEL,\n        b'z' => NotApplicable,\n    }\n}\n\nleader_field! {\n    DescriptiveCatalogingForm {\n        b' ' => NonIsbd,\n        b'a' => Aacr2,\n        b'c' => IsbdPunctuationOmitted,\n        b'i' => IsbdPunctuationIncluded,\n        b'u' => UnknownDCF,\n    }\n}\n\nleader_field! {\n    MultipartResourceRecordLevel {\n        b' ' => NotSpecifiedOrNotApplicable,\n        b'a' => Set,\n        b'b' => PartWithIndependentTitle,\n        b'c' => PartWithDependentTitle,\n    }\n}\n\n#[macro_export]\n/// Intended to use with `RecordBuilder::add_fields`.\n///\n/// ```ignore\n/// builder.add_fields(fields!(\n///     control fields: [\"001\" => \"foo\"];\n///     data fields: [\n///         \"856\", \"41\", [\n///             'q' = \"bar\",\n///             'u' => \"baz\",\n///         ],\n///     ]\n/// ));\n/// ```\nmacro_rules! fields {\n    (\n        control fields: [$($ctag:expr => $cdata:expr),*];\n    ) => (\n        fields!( control fields: [ $($ctag => $cdata,)* ];\n                 data fields: [ ]; )\n    );\n    (\n        control fields: [$($ctag:expr => $cdata:expr,)*];\n    ) => (\n        fields!( control fields: [ $($ctag => $cdata,)* ];\n                 data fields: [ ]; )\n    );\n\n    (\n        data fields: [ $( $dtag:expr, $dind:expr, [$($sfident:expr => $sfdata:expr),*] ),* ];\n    ) => (\n        fields!( control fields: [ ];\n                 data fields: [ $($dtag, $dind, [ $($sfident => $sfdata,)* ],)* ]; )\n    );\n    (\n        data fields: [ $( $dtag:expr, $dind:expr, [$($sfident:expr => $sfdata:expr,)*] ),* ];\n    ) => (\n        fields!( control fields: [ ];\n                 data fields: [ $($dtag, $dind, [ $($sfident => $sfdata,)* ],)* ]; )\n    );\n    (\n        data fields: [ $( $dtag:expr, $dind:expr, [$($sfident:expr => $sfdata:expr),*],)* ];\n    ) => (\n        fields!( control fields: [ ];\n                 data fields: [ $($dtag, $dind, [ $($sfident => $sfdata,)* ],)* ]; )\n    );\n    (\n        data fields: [ $( $dtag:expr, $dind:expr, [$($sfident:expr => $sfdata:expr,)*],)* ];\n    ) => (\n        fields!( control fields: [ ];\n                 data fields: [ $($dtag, $dind, [ $($sfident => $sfdata,)* ],)* ]; )\n    );\n\n    (\n        data fields: [ $( $dtag:expr, $dind:expr, [$($sfident:expr => $sfdata:expr),*] ),* ];\n        control fields: [$($ctag:expr => $cdata:expr),*];\n    ) => (\n        fields!( control fields: [ $($ctag => $cdata,)* ];\n                 data fields: [ $($dtag, $dind, [ $($sfident => $sfdata,)* ],)* ]; )\n    );\n    (\n        data fields: [ $( $dtag:expr, $dind:expr, [$($sfident:expr => $sfdata:expr),*] ),* ];\n        control fields: [$($ctag:expr => $cdata:expr,)*];\n    ) => (\n        fields!( control fields: [ $($ctag => $cdata,)* ];\n                 data fields: [ $($dtag, $dind, [ $($sfident => $sfdata,)* ],)* ]; )\n    );\n    (\n        data fields: [ $( $dtag:expr, $dind:expr, [$($sfident:expr => $sfdata:expr,)*] ),* ];\n        control fields: [$($ctag:expr => $cdata:expr),*];\n    ) => (\n        fields!( control fields: [ $($ctag => $cdata,)* ];\n                 data fields: [ $($dtag, $dind, [ $($sfident => $sfdata,)* ],)* ]; )\n    );\n    (\n        data fields: [ $( $dtag:expr, $dind:expr, [$($sfident:expr => $sfdata:expr,)*] ),* ];\n        control fields: [$($ctag:expr => $cdata:expr,)*];\n    ) => (\n        fields!( control fields: [ $($ctag => $cdata,)* ];\n                 data fields: [ $($dtag, $dind, [ $($sfident => $sfdata,)* ],)* ]; )\n    );\n    (\n        data fields: [ $( $dtag:expr, $dind:expr, [$($sfident:expr => $sfdata:expr),*],)* ];\n        control fields: [$($ctag:expr => $cdata:expr),*];\n    ) => (\n        fields!( control fields: [ $($ctag => $cdata,)* ];\n                 data fields: [ $($dtag, $dind, [ $($sfident => $sfdata,)* ],)* ]; )\n    );\n    (\n        data fields: [ $( $dtag:expr, $dind:expr, [$($sfident:expr => $sfdata:expr),*],)* ];\n        control fields: [$($ctag:expr => $cdata:expr,)*];\n    ) => (\n        fields!( control fields: [ $($ctag => $cdata,)* ];\n                 data fields: [ $($dtag, $dind, [ $($sfident => $sfdata,)* ],)* ]; )\n    );\n    (\n        data fields: [ $( $dtag:expr, $dind:expr, [$($sfident:expr => $sfdata:expr,)*],)* ];\n        control fields: [$($ctag:expr => $cdata:expr),*];\n    ) => (\n        fields!( control fields: [ $($ctag => $cdata,)* ];\n                 data fields: [ $($dtag, $dind, [ $($sfident => $sfdata,)* ],)* ]; )\n    );\n    (\n        data fields: [ $( $dtag:expr, $dind:expr, [$($sfident:expr => $sfdata:expr,)*], )* ];\n        control fields: [$($ctag:expr => $cdata:expr,)*];\n    ) => (\n        fields!( control fields: [ $($ctag => $cdata,)* ];\n                 data fields: [ $($dtag, $dind, [ $($sfident => $sfdata,)* ],)* ]; )\n    );\n\n\n    (\n        control fields: [$($ctag:expr => $cdata:expr),*];\n        data fields: [ $( $dtag:expr, $dind:expr, [$($sfident:expr => $sfdata:expr),*] ),* ];\n    ) => (\n        fields!( control fields: [ $($ctag => $cdata,)* ];\n                 data fields: [ $($dtag, $dind, [ $($sfident => $sfdata,)* ],)* ]; )\n    );\n    (\n        control fields: [$($ctag:expr => $cdata:expr,)*];\n        data fields: [ $( $dtag:expr, $dind:expr, [$($sfident:expr => $sfdata:expr),*] ),* ];\n    ) => (\n        fields!( control fields: [ $($ctag => $cdata,)* ];\n                 data fields: [ $($dtag, $dind, [ $($sfident => $sfdata,)* ],)* ]; )\n    );\n    (\n        control fields: [$($ctag:expr => $cdata:expr),*];\n        data fields: [ $( $dtag:expr, $dind:expr, [$($sfident:expr => $sfdata:expr,)*] ),* ];\n    ) => (\n        fields!( control fields: [ $($ctag => $cdata,)* ];\n                 data fields: [ $($dtag, $dind, [ $($sfident => $sfdata,)* ],)* ]; )\n    );\n    (\n        control fields: [$($ctag:expr => $cdata:expr,)*];\n        data fields: [ $( $dtag:expr, $dind:expr, [$($sfident:expr => $sfdata:expr,)*] ),* ];\n    ) => (\n        fields!( control fields: [ $($ctag => $cdata,)* ];\n                 data fields: [ $($dtag, $dind, [ $($sfident => $sfdata,)* ],)* ]; )\n    );\n    (\n        control fields: [$($ctag:expr => $cdata:expr),*];\n        data fields: [ $( $dtag:expr, $dind:expr, [$($sfident:expr => $sfdata:expr),*],)* ];\n    ) => (\n        fields!( control fields: [ $($ctag => $cdata,)* ];\n                 data fields: [ $($dtag, $dind, [ $($sfident => $sfdata,)* ],)* ]; )\n    );\n    (\n        control fields: [$($ctag:expr => $cdata:expr,)*];\n        data fields: [ $( $dtag:expr, $dind:expr, [$($sfident:expr => $sfdata:expr),*],)* ];\n    ) => (\n        fields!( control fields: [ $($ctag => $cdata,)* ];\n                 data fields: [ $($dtag, $dind, [ $($sfident => $sfdata,)* ],)* ]; )\n    );\n    (\n        control fields: [$($ctag:expr => $cdata:expr),*];\n        data fields: [ $( $dtag:expr, $dind:expr, [$($sfident:expr => $sfdata:expr,)*],)* ];\n    ) => (\n        fields!( control fields: [ $($ctag => $cdata,)* ];\n                 data fields: [ $($dtag, $dind, [ $($sfident => $sfdata,)* ],)* ]; )\n    );\n    (\n        control fields: [$($ctag:expr => $cdata:expr,)*];\n        data fields: [ $( $dtag:expr, $dind:expr, [$($sfident:expr => $sfdata:expr,)*], )* ];\n    ) => ({\n        let mut out = vec![];\n        $(out.push(\n            $crate::FieldRepr::from(\n                ($crate::Tag::from($ctag), Vec::<u8>::from($cdata))\n            )\n        );)*\n        $({\n            let mut sfs = vec![];\n            $(sfs.push(($crate::Identifier::from($sfident), Vec::<u8>::from($sfdata)));)*\n            out.push(\n                $crate::FieldRepr::from(\n                    ($crate::Tag::from($dtag), $crate::Indicator::from($dind), sfs)\n                )\n            )\n        })*\n        out\n    });\n\n}\n\n#[cfg(test)]\nmod tests {\n    const RECS: &'static str = \"00963nam a2200229 i 4500001001000000003000800010003000800018005001700026008004100043035002300084040002600107041000800133072001900141100005800160245028000218260004000498300001600538650004200554856010400596979001200700979002100712\\\n                                \\x1e000000001\\x1eRuMoRGB\\x1eEnMoRGB\\x1e20080528120000.0\\x1e080528s1992    ru a|||  a    |00 u rus d\\x1e  \\x1fa(RuMoEDL)-92k71098\\x1e  \\x1faRuMoRGB\\x1fbrus\\x1fcRuMoRGB\\x1e0 \\x1farus\\x1e 7\\x1fa07.00.03\\x1f2nsnr\\x1e1 \\x1fa'\u0410\u0431\u0434 \u0410\u043b-'\u0410\u0437\u0438\u0437 \u0414\u0436\u0430'\u0444\u0430\u0440 \u0411\u0438\u043d '\u0410\u043a\u0438\u0434\\x1e00\\x1fa\u042d\u0442\u043d\u043e\u0441\u043e\u0446\u0438\u0430\u043b\u044c\u043d\u0430\u044f \u0441\u0442\u0440\u0443\u043a\u0442\u0443\u0440\u0430 \u0438 \u0438\u043d\u0441\u0442\u0438\u0442\u0443\u0442\u044b \u0441\u043e\u0446\u0438\u0430\u043b\u044c\u043d\u043e\u0439 \u0437\u0430\u0449\u0438\u0442\u044b \u0432 \u0425\u0430\u0434\u0440\u0430\u043c\u0430\u0443\u0442\u0435 (19 - \u043f\u0435\u0440\u0432\u0430\u044f \u043f\u043e\u043b\u043e\u0432\u0438\u043d\u0430 20 \u0432\u0432.) :\\x1fb\u0430\u0432\u0442\u043e\u0440\u0435\u0444\u0435\u0440\u0430\u0442 \u0434\u0438\u0441. ... \u043a\u0430\u043d\u0434\u0438\u0434\u0430\u0442\u0430 \u0438\u0441\u0442\u043e\u0440\u0438\u0447\u0435\u0441\u043a\u0438\u0445 \u043d\u0430\u0443\u043a : 07.00.03\\x1e  \\x1fa\u0421\u0430\u043d\u043a\u0442-\u041f\u0435\u0442\u0435\u0440\u0431\u0443\u0440\u0433\\x1fc1992\\x1e  \\x1fa24 c.\\x1fb\u0438\u043b\\x1e 7\\x1fa\u0412\u0441\u0435\u043e\u0431\u0449\u0430\u044f \u0438\u0441\u0442\u043e\u0440\u0438\u044f\\x1f2nsnr\\x1e41\\x1fqapplication/pdf\\x1fuhttp://dlib.rsl.ru/rsl01000000000/rsl01000000000/rsl01000000001/rsl01000000001.pdf\\x1e  \\x1faautoref\\x1e  \\x1fbautoreg\\x1fbautoreh\\x1e\\x1d\\\n                                00963nam a2200229 i 4500001001000000003000800010003000800018005001700026008004100043035002300084040002600107041000800133072001900141100005800160245028000218260004000498300001600538650004200554856010400596979001200700979002100712\\\n                                \\x1e000000002\\x1eRuMoRGB\\x1eEnMoRGB\\x1e20080528120000.0\\x1e080528s1992    ru a|||  a    |00 u rus d\\x1e  \\x1fa(RuMoEDL)-92k71098\\x1e  \\x1faRuMoRGB\\x1fbrus\\x1fcRuMoRGB\\x1e0 \\x1farus\\x1e 7\\x1fa07.00.03\\x1f2nsnr\\x1e1 \\x1fa'\u0410\u0431\u0434 \u0410\u043b-'\u0410\u0437\u0438\u0437 \u0414\u0436\u0430'\u0444\u0430\u0440 \u0411\u0438\u043d '\u0410\u043a\u0438\u0434\\x1e00\\x1fa\u042d\u0442\u043d\u043e\u0441\u043e\u0446\u0438\u0430\u043b\u044c\u043d\u0430\u044f \u0441\u0442\u0440\u0443\u043a\u0442\u0443\u0440\u0430 \u0438 \u0438\u043d\u0441\u0442\u0438\u0442\u0443\u0442\u044b \u0441\u043e\u0446\u0438\u0430\u043b\u044c\u043d\u043e\u0439 \u0437\u0430\u0449\u0438\u0442\u044b \u0432 \u0425\u0430\u0434\u0440\u0430\u043c\u0430\u0443\u0442\u0435 (19 - \u043f\u0435\u0440\u0432\u0430\u044f \u043f\u043e\u043b\u043e\u0432\u0438\u043d\u0430 20 \u0432\u0432.) :\\x1fb\u0430\u0432\u0442\u043e\u0440\u0435\u0444\u0435\u0440\u0430\u0442 \u0434\u0438\u0441. ... \u043a\u0430\u043d\u0434\u0438\u0434\u0430\u0442\u0430 \u0438\u0441\u0442\u043e\u0440\u0438\u0447\u0435\u0441\u043a\u0438\u0445 \u043d\u0430\u0443\u043a : 07.00.03\\x1e  \\x1fa\u0421\u0430\u043d\u043a\u0442-\u041f\u0435\u0442\u0435\u0440\u0431\u0443\u0440\u0433\\x1fc1992\\x1e  \\x1fa24 c.\\x1fb\u0438\u043b\\x1e 7\\x1fa\u0412\u0441\u0435\u043e\u0431\u0449\u0430\u044f \u0438\u0441\u0442\u043e\u0440\u0438\u044f\\x1f2nsnr\\x1e41\\x1fqapplication/pdf\\x1fuhttp://dlib.rsl.ru/rsl01000000000/rsl01000000000/rsl01000000002/rsl01000000002.pdf\\x1e  \\x1faautoref\\x1e  \\x1fbautoreg\\x1fbautoreh\\x1e\\x1d\";\n    const REC_SIZE: u64 = 963;\n    mod read {\n        use super::{super::*, RECS, REC_SIZE};\n        use std::io;\n\n        #[test]\n        fn shoud_parse_record() {\n            let record = Record::parse(&RECS.as_bytes()[..963]).unwrap();\n            assert_eq!(record.record_status(), RecordStatus::New);\n            assert_eq!(record.type_of_record(), TypeOfRecord::LanguageMaterial);\n            assert_eq!(\n                record.bibliographic_level(),\n                BibliographicLevel::MonographOrItem\n            );\n            assert_eq!(record.type_of_control(), TypeOfControl::NoSpecifiedType);\n            assert_eq!(\n                record.character_coding_scheme(),\n                CharacterCodingScheme::UcsUnicode\n            );\n            assert_eq!(record.encoding_level(), EncodingLevel::FullLevel);\n            assert_eq!(\n                record.descriptive_cataloging_form(),\n                DescriptiveCatalogingForm::IsbdPunctuationIncluded\n            );\n            assert_eq!(\n                record.multipart_resource_record_level(),\n                MultipartResourceRecordLevel::NotSpecifiedOrNotApplicable\n            );\n            assert_eq!(record.as_ref(), &RECS.as_bytes()[0..REC_SIZE as usize]);\n        }\n\n        #[test]\n        fn should_create_record_from_vec() {\n            let record = Record::from_vec((&RECS.as_bytes()[..963]).to_vec()).unwrap();\n            assert_eq!(record.record_status(), RecordStatus::New);\n            assert_eq!(record.type_of_record(), TypeOfRecord::LanguageMaterial);\n            assert_eq!(\n                record.bibliographic_level(),\n                BibliographicLevel::MonographOrItem\n            );\n            assert_eq!(record.type_of_control(), TypeOfControl::NoSpecifiedType);\n            assert_eq!(\n                record.character_coding_scheme(),\n                CharacterCodingScheme::UcsUnicode\n            );\n            assert_eq!(record.encoding_level(), EncodingLevel::FullLevel);\n            assert_eq!(\n                record.descriptive_cataloging_form(),\n                DescriptiveCatalogingForm::IsbdPunctuationIncluded\n            );\n            assert_eq!(\n                record.multipart_resource_record_level(),\n                MultipartResourceRecordLevel::NotSpecifiedOrNotApplicable\n            );\n            assert_eq!(record.as_ref(), &RECS.as_bytes()[0..REC_SIZE as usize]);\n        }\n\n        #[test]\n        fn should_read_record() {\n            let mut data = vec![];\n            data.extend_from_slice(RECS.as_bytes());\n            let mut input = io::Cursor::new(data);\n            let record = Record::read(&mut input).unwrap();\n            let record = record.unwrap();\n            assert_eq!(record.record_status(), RecordStatus::New);\n            assert_eq!(record.type_of_record(), TypeOfRecord::LanguageMaterial);\n            assert_eq!(\n                record.bibliographic_level(),\n                BibliographicLevel::MonographOrItem\n            );\n            assert_eq!(record.type_of_control(), TypeOfControl::NoSpecifiedType);\n            assert_eq!(\n                record.character_coding_scheme(),\n                CharacterCodingScheme::UcsUnicode\n            );\n            assert_eq!(record.encoding_level(), EncodingLevel::FullLevel);\n            assert_eq!(\n                record.descriptive_cataloging_form(),\n                DescriptiveCatalogingForm::IsbdPunctuationIncluded\n            );\n            assert_eq!(\n                record.multipart_resource_record_level(),\n                MultipartResourceRecordLevel::NotSpecifiedOrNotApplicable\n            );\n            assert_eq!(record.as_ref(), &RECS.as_bytes()[0..REC_SIZE as usize]);\n            let record = Record::read(&mut input).unwrap();\n            let record = record.unwrap();\n            assert_eq!(record.record_status(), RecordStatus::New);\n            assert_eq!(record.type_of_record(), TypeOfRecord::LanguageMaterial);\n            assert_eq!(\n                record.bibliographic_level(),\n                BibliographicLevel::MonographOrItem\n            );\n            assert_eq!(record.type_of_control(), TypeOfControl::NoSpecifiedType);\n            assert_eq!(\n                record.character_coding_scheme(),\n                CharacterCodingScheme::UcsUnicode\n            );\n            assert_eq!(record.encoding_level(), EncodingLevel::FullLevel);\n            assert_eq!(\n                record.descriptive_cataloging_form(),\n                DescriptiveCatalogingForm::IsbdPunctuationIncluded\n            );\n            assert_eq!(\n                record.multipart_resource_record_level(),\n                MultipartResourceRecordLevel::NotSpecifiedOrNotApplicable\n            );\n            assert_eq!(record.as_ref(), &RECS.as_bytes()[REC_SIZE as usize..]);\n            let record = Record::read(&mut input).unwrap();\n            assert!(record.is_none());\n        }\n\n        #[test]\n        fn should_iterate_records() {\n            let mut data = vec![];\n            data.extend_from_slice(RECS.as_bytes());\n            let input = io::Cursor::new(data);\n            let mut records = Records::new(input);\n\n            let record = records.next().unwrap().unwrap();\n            assert_eq!(record.record_status(), RecordStatus::New);\n            assert_eq!(record.type_of_record(), TypeOfRecord::LanguageMaterial);\n            assert_eq!(\n                record.bibliographic_level(),\n                BibliographicLevel::MonographOrItem\n            );\n            assert_eq!(record.type_of_control(), TypeOfControl::NoSpecifiedType);\n            assert_eq!(\n                record.character_coding_scheme(),\n                CharacterCodingScheme::UcsUnicode\n            );\n            assert_eq!(record.encoding_level(), EncodingLevel::FullLevel);\n            assert_eq!(\n                record.descriptive_cataloging_form(),\n                DescriptiveCatalogingForm::IsbdPunctuationIncluded\n            );\n            assert_eq!(\n                record.multipart_resource_record_level(),\n                MultipartResourceRecordLevel::NotSpecifiedOrNotApplicable\n            );\n            assert_eq!(record.as_ref(), &RECS.as_bytes()[0..REC_SIZE as usize]);\n            let record = records.next().unwrap().unwrap();\n            assert_eq!(record.record_status(), RecordStatus::New);\n            assert_eq!(record.type_of_record(), TypeOfRecord::LanguageMaterial);\n            assert_eq!(\n                record.bibliographic_level(),\n                BibliographicLevel::MonographOrItem\n            );\n            assert_eq!(record.type_of_control(), TypeOfControl::NoSpecifiedType);\n            assert_eq!(\n                record.character_coding_scheme(),\n                CharacterCodingScheme::UcsUnicode\n            );\n            assert_eq!(record.encoding_level(), EncodingLevel::FullLevel);\n            assert_eq!(\n                record.descriptive_cataloging_form(),\n                DescriptiveCatalogingForm::IsbdPunctuationIncluded\n            );\n            assert_eq!(\n                record.multipart_resource_record_level(),\n                MultipartResourceRecordLevel::NotSpecifiedOrNotApplicable\n            );\n            assert_eq!(record.as_ref(), &RECS.as_bytes()[REC_SIZE as usize..]);\n            assert!(records.next().is_none());\n            assert!(records.next().is_none());\n\n            let data = &[0x30; 10];\n            let input = io::Cursor::new(data);\n            let mut records = Records::new(input);\n            assert!(records.next().unwrap().is_err());\n            assert!(records.next().is_none());\n        }\n\n        #[test]\n        fn should_get_field() {\n            let record = Record::parse(&RECS.as_bytes()[..963]).unwrap();\n\n            let repr = FieldRepr::from((\"001\", \"000000001\"));\n            let fields = record.field(\"001\");\n            assert_eq!(fields, vec![Field::from_repr(&repr)]);\n\n            let repr1 = FieldRepr::from((\"979\", \"  \\x1faautoref\"));\n            let repr2 = FieldRepr::from((\"979\", \"  \\x1fbautoreg\\x1fbautoreh\"));\n            let fields = record.field(\"979\");\n            assert_eq!(\n                fields,\n                vec![Field::from_repr(&repr1), Field::from_repr(&repr2),]\n            );\n\n            let fields = record.field(\"999\");\n            assert_eq!(fields, vec![]);\n        }\n\n        #[test]\n        fn should_get_fields() {\n            let record = Record::parse(&RECS.as_bytes()[..963]).unwrap();\n\n            let tags: Vec<Tag> = record.fields().map(|field| field.get_tag()).collect();\n            assert_eq!(\n                tags,\n                vec![\n                    Tag::from(\"001\"),\n                    Tag::from(\"003\"),\n                    Tag::from(\"003\"),\n                    Tag::from(\"005\"),\n                    Tag::from(\"008\"),\n                    Tag::from(\"035\"),\n                    Tag::from(\"040\"),\n                    Tag::from(\"041\"),\n                    Tag::from(\"072\"),\n                    Tag::from(\"100\"),\n                    Tag::from(\"245\"),\n                    Tag::from(\"260\"),\n                    Tag::from(\"300\"),\n                    Tag::from(\"650\"),\n                    Tag::from(\"856\"),\n                    Tag::from(\"979\"),\n                    Tag::from(\"979\"),\n                ]\n            );\n        }\n\n        #[test]\n        fn sholud_build_record() {\n            let record = Record::parse(&RECS.as_bytes()[..963]).unwrap();\n\n            let mut builder = RecordBuilder::new();\n            builder.add_fields(fields!(\n                data fields: [\n                    \"979\", \"  \", [\n                        'a' => \"autoref\",\n                    ],\n                    \"979\", \"  \", [\n                        'b' => \"autoreg\",\n                        'b' => \"autoreh\",\n                    ],\n                    \"856\", \"41\" , [\n                        'q' => \"application/pdf\",\n                        'u' => \"http://dlib.rsl.ru/rsl01000000000/rsl01000000000/rsl01000000001/rsl01000000001.pdf\",\n                    ],\n                    \"650\", \" 7\", [\n                        'a' => \"\u0412\u0441\u0435\u043e\u0431\u0449\u0430\u044f \u0438\u0441\u0442\u043e\u0440\u0438\u044f\",\n                        '2' => \"nsnr\",\n                    ],\n                    \"300\", \"  \", [\n                        'a' => \"24 c.\",\n                        'b' => \"\u0438\u043b\",\n                    ],\n                    \"260\", \"  \", [\n                        'a' => \"\u0421\u0430\u043d\u043a\u0442-\u041f\u0435\u0442\u0435\u0440\u0431\u0443\u0440\u0433\",\n                        'c' => \"1992\",\n                    ],\n                    \"245\", \"00\", [\n                        'a' => \"\u042d\u0442\u043d\u043e\u0441\u043e\u0446\u0438\u0430\u043b\u044c\u043d\u0430\u044f \u0441\u0442\u0440\u0443\u043a\u0442\u0443\u0440\u0430 \u0438 \u0438\u043d\u0441\u0442\u0438\u0442\u0443\u0442\u044b \u0441\u043e\u0446\u0438\u0430\u043b\u044c\u043d\u043e\u0439 \u0437\u0430\u0449\u0438\u0442\u044b \u0432 \u0425\u0430\u0434\u0440\u0430\u043c\u0430\u0443\u0442\u0435 (19 - \u043f\u0435\u0440\u0432\u0430\u044f \u043f\u043e\u043b\u043e\u0432\u0438\u043d\u0430 20 \u0432\u0432.) :\",\n                        'b' => \"\u0430\u0432\u0442\u043e\u0440\u0435\u0444\u0435\u0440\u0430\u0442 \u0434\u0438\u0441. ... \u043a\u0430\u043d\u0434\u0438\u0434\u0430\u0442\u0430 \u0438\u0441\u0442\u043e\u0440\u0438\u0447\u0435\u0441\u043a\u0438\u0445 \u043d\u0430\u0443\u043a : 07.00.03\",\n                    ],\n                    \"100\", \"1 \", [\n                        'a' => \"'\u0410\u0431\u0434 \u0410\u043b-'\u0410\u0437\u0438\u0437 \u0414\u0436\u0430'\u0444\u0430\u0440 \u0411\u0438\u043d '\u0410\u043a\u0438\u0434\",\n                    ],\n                    \"072\", \" 7\", [\n                        'a' => \"07.00.03\",\n                        '2' => \"nsnr\",\n                    ],\n                    \"041\", \"0 \", [\n                        'a' => \"rus\",\n                    ],\n                    \"040\", \"  \", [\n                        'a' => \"RuMoRGB\",\n                        'b' => \"rus\",\n                        'c' => \"RuMoRGB\",\n                    ],\n                    \"035\", \"  \", [\n                        'a' => \"(RuMoEDL)-92k71098\",\n                        'f' => \"filter\",\n                    ],\n                ];\n                control fields: [\n                    \"000\" => \"filter\",\n                    \"008\" => \"080528s1992    ru a|||  a    |00 u rus d\",\n                    \"005\" => \"20080528120000.0\",\n                    \"003\" => \"RuMoRGB\",\n                    \"003\" => \"EnMoRGB\",\n                    \"001\" => \"000000001\",\n                ];\n            )).unwrap();\n            builder\n                .set_record_status(record.record_status())\n                .set_type_of_record(record.type_of_record())\n                .set_bibliographic_level(record.bibliographic_level())\n                .set_type_of_control(record.type_of_control())\n                .set_character_coding_scheme(record.character_coding_scheme())\n                .set_encoding_level(record.encoding_level())\n                .set_descriptive_cataloging_form(record.descriptive_cataloging_form())\n                .set_multipart_resource_record_level(record.multipart_resource_record_level());\n            builder.filter_fields(|f| f.get_tag() != \"000\".into());\n            builder.filter_subfields(|_, sf| sf.get_data::<[u8]>() != &b\"filter\"[..]);\n\n            assert_eq!(builder.get_record().unwrap().as_ref(), record.as_ref());\n        }\n    }\n\n    mod write {\n        use super::{super::*, RECS};\n\n        #[test]\n        fn should_write_record() {\n            let mut vec = Vec::new();\n\n            let record = Record::parse(&RECS.as_bytes()[..963]).unwrap();\n\n            match vec.write_record(record.clone()) {\n                Err(why) => panic!(\"couldn't write file: {}\", why),\n                Ok(_) => (),\n            }\n\n            let record2 = Record::from_vec(vec).unwrap();\n            assert_eq!(record.as_ref(), record2.as_ref());\n        }\n    }\n\n    #[cfg(feature = \"nightly\")]\n    mod bench {\n        use super::{super::*, RECS, REC_SIZE};\n        use test;\n\n        #[bench]\n        fn read_record(b: &mut test::Bencher) {\n            b.iter(|| {\n                if let Ok(rec) = Record::read(&mut RECS.as_bytes()) {\n                    if let Some(rec) = rec {\n                        test::black_box(rec);\n                    } else {\n                        panic!();\n                    }\n                }\n            });\n            b.bytes += REC_SIZE;\n        }\n\n        #[bench]\n        fn parse_record(b: &mut test::Bencher) {\n            b.iter(|| {\n                if let Ok(rec) = Record::parse(RECS.as_bytes()) {\n                    test::black_box(rec);\n                } else {\n                    panic!();\n                }\n            });\n            b.bytes += REC_SIZE;\n        }\n    }\n}\n"
  },
  {
    "project": "buttplug",
    "target": 1,
    "commit_id": "c7bf7eb3223b9cd6743b5db901e271a856054c89",
    "func": "// Buttplug Rust Source Code File - See https://buttplug.io for more info.\n//\n// Copyright 2016-2020 Nonpolynomial Labs LLC. All rights reserved.\n//\n// Licensed under the BSD 3-Clause license. See LICENSE file in the project root\n// for full license information.\n\n//! Buttplug futures utilities. Mostly used for building message futures in the\n//! client, used to wait on responses from the server.\n\nuse core::pin::Pin;\nuse futures::{\n  future::Future,\n  task::{Context, Poll, Waker},\n};\nuse std::sync::{Arc, Mutex, MutexGuard};\n\n/// Struct used for facilitating resolving futures across contexts.\n///\n/// Since ButtplugFuture is [Pinned][Pin], we can't just go passing it around\n/// tasks or threads. This struct is therefore used to get replies from other\n/// contexts while letting the future stay pinned. It holds the reply to the\n/// future, as well as a [Waker] for waking up the future when the reply is set.\n#[derive(Debug, Clone)]\npub struct ButtplugFutureState<T> {\n  reply: Option<T>,\n  waker: Option<Waker>,\n}\n\n// For some reason, deriving default above doesn't work, but doing an explicit\n// derive here does work.\nimpl<T> Default for ButtplugFutureState<T> {\n  fn default() -> Self {\n    ButtplugFutureState::<T> {\n      reply: None,\n      waker: None,\n    }\n  }\n}\n\nimpl<T> ButtplugFutureState<T> {\n  /// Sets the response for the future, firing the waker.\n  ///\n  /// When a response is received from whatever we're waiting on, this function\n  /// takes the response, updates the state struct, and calls [Waker::wake] so\n  /// that the corresponding future can finish.\n  ///\n  /// # Panics\n  ///\n  /// If the reply is set twice, the library will panic. We have no way of\n  /// resolving two replies to the same future, so this is considered a\n  /// catastrophic error.\n  pub fn set_reply(&mut self, reply: T) {\n    if self.reply.is_some() {\n      panic!(\"set_reply_msg called multiple times on the same future.\");\n    }\n\n    self.reply = Some(reply);\n\n    if self.waker.is_some() {\n      self.waker.take().unwrap().wake();\n    }\n  }\n}\n\n/// Shared [ButtplugFutureState] type.\n///\n/// [ButtplugFutureState] is made to be shared across tasks, and we'll never\n/// know if those tasks are running on single or multithreaded executors.\n///\n/// # Panics and notes on setting replies\n///\n/// The lock for a [ButtplugFutureState] should only ever be taken when the\n/// reply is being set (which the `set_reply` method does internally), and there\n/// should never be a point where the reply is set twice (See the panic\n/// documentation for [ButtplugFutureState]). In order to make sure we never\n/// block, we always lock using try_lock with .expect(). If try_lock fails, this\n/// means we're already in a double reply situation, and therefore we'll panic\n/// on the .expect(). Any panic from this should be considered a library error\n/// and reported as a bug.\n#[derive(Debug)]\npub struct ButtplugFutureStateShared<T> {\n  /// The internal state of the future. When `set_reply` is run, we fill this in\n  /// with the value we want the related future to resolve with.\n  state: Arc<Mutex<ButtplugFutureState<T>>>,\n}\n\nunsafe impl<T> Sync for ButtplugFutureStateShared<T> {\n}\nunsafe impl<T> Send for ButtplugFutureStateShared<T> {\n}\n\nimpl<T> ButtplugFutureStateShared<T> {\n  pub fn new(state: ButtplugFutureState<T>) -> Self {\n    Self {\n      state: Arc::new(Mutex::new(state)),\n    }\n  }\n\n  /// Locks and returns a [MutexGuard].\n  ///\n  /// See [ButtplugFutureStateShared] struct documentation for more info on\n  /// locking.\n  ///\n  /// # Visibility\n  ///\n  /// The only thing that needs to read the reply from a future is our poll\n  /// method, in this module. Everything else should just be setting replies,\n  /// and can use set_reply accordingly.\n  pub(super) fn lock(&self) -> MutexGuard<'_, ButtplugFutureState<T>> {\n    // There should only ever be lock contention if we're polling while\n    // settings, which should rarely if ever happen.\n    self.state.lock().unwrap()\n  }\n\n  /// Locks immediately and sets the reply for the internal waker, or panics if\n  /// lock is held.\n  ///\n  /// See [ButtplugFutureStateShared] struct documentation for more info on\n  /// locking.\n  pub fn set_reply(&self, reply: T) {\n    self.lock().set_reply(reply);\n  }\n}\n\nimpl<T> Default for ButtplugFutureStateShared<T> {\n  fn default() -> Self {\n    Self {\n      state: Arc::new(Mutex::new(ButtplugFutureState::<T>::default())),\n    }\n  }\n}\n\nimpl<T> Clone for ButtplugFutureStateShared<T> {\n  fn clone(&self) -> Self {\n    Self {\n      state: self.state.clone(),\n    }\n  }\n}\n\n/// [Future] implementation for long operations in Buttplug.\n///\n/// This is a convenience struct, used for handling indeterminately long\n/// operations, like Buttplug's request/reply communications between the client\n/// and server. It allows us to say what type we expect back, then hold a waker\n/// that we can pass around as needed.\n#[derive(Debug)]\npub struct ButtplugFuture<T> {\n  /// State that holds the waker for the future, and the reply (once set).\n  ///\n  /// ## Notes\n  ///\n  /// This needs to be an [Arc]<[Mutex]<T>> in order to make it mutable under\n  /// pinning when dealing with being a future. There is a chance we could do\n  /// this as a [Pin::get_unchecked_mut] borrow, which would be way faster, but\n  /// that's dicey and hasn't been proven as needed for speed yet.\n  waker_state: ButtplugFutureStateShared<T>,\n}\n\n// TODO Should we implement drop on this?\n//\n// It'd be nice if the future would yell if its dropping and the waker didn't\n// fire? Otherwise it seems like we could have quiet deadlocks.\n\nimpl<T> Default for ButtplugFuture<T> {\n  fn default() -> Self {\n    ButtplugFuture::<T> {\n      waker_state: ButtplugFutureStateShared::<T>::default(),\n    }\n  }\n}\n\nimpl<T> ButtplugFuture<T> {\n  /// Returns a clone of the state, used for moving the state across contexts\n  /// (tasks/threads/etc...).\n  pub fn get_state_clone(&self) -> ButtplugFutureStateShared<T> {\n    self.waker_state.clone()\n  }\n}\n\nimpl<T> Future for ButtplugFuture<T> {\n  type Output = T;\n\n  /// Wakes up when the Output type reply has been set in the\n  /// [ButtplugFutureStateShared].\n  fn poll(self: Pin<&mut Self>, cx: &mut Context) -> Poll<Self::Output> {\n    // This is the only place lock_now_or_panic should be called, since we're\n    // reading the value.\n    let mut waker_state = self.waker_state.lock();\n    if waker_state.reply.is_some() {\n      let msg = waker_state.reply.take().unwrap();\n      Poll::Ready(msg)\n    } else {\n      waker_state.waker = Some(cx.waker().clone());\n      Poll::Pending\n    }\n  }\n}\n"
  },
  {
    "project": "ms3d",
    "target": 1,
    "commit_id": "d583d52f0143f833ee31f6adfe0d7ba06a2b5d6b",
    "func": "use std::io;\n\npub(crate) trait BufReadExact {\n    fn buf_read_exact(&mut self, len: usize) -> io::Result<&[u8]>;\n}\n\npub(crate) struct IoReader<R: io::Read> {\n    rdr: R,\n    buf: Vec<u8>,\n}\n\nimpl<R: io::Read> IoReader<R> {\n    pub fn new(rdr: R) -> Self {\n        IoReader { rdr, buf: Vec::new() }\n    }\n}\n\nimpl<R: io::Read> BufReadExact for IoReader<R> {\n    fn buf_read_exact(&mut self, len: usize) -> io::Result<&[u8]> {\n        unsafe {\n            self.buf.reserve(len);\n            let slice = self.buf.get_unchecked_mut(..len);\n            self.rdr.read_exact(slice)?;\n            Ok(slice)\n        }\n    }\n}\n\npub(crate) struct SliceReader<'a> {\n    slice: &'a [u8],\n}\n\nimpl<'a> SliceReader<'a> {\n    pub fn new(slice: &'a [u8]) -> Self {\n        SliceReader { slice }\n    }\n}\n\nimpl<'a> BufReadExact for SliceReader<'a> {\n    fn buf_read_exact(&mut self, len: usize) -> io::Result<&[u8]> {\n        if len > self.slice.len() {\n            return Err(io::ErrorKind::UnexpectedEof.into())\n        }\n        let (head, tail) = self.slice.split_at(len);\n        self.slice = tail;\n        Ok(head)\n    }\n}"
  },
  {
    "project": "rust-cpuid",
    "target": 1,
    "commit_id": "0ebd1da97b50e10c3672681c9508bab5692f10e3",
    "func": "//! A library to parse the x86 CPUID instruction, written in rust with no external dependencies.\n//! The implementation closely resembles the Intel CPUID manual description. The library does only\n//! depend on libcore.\n//!\n//! The code should be in sync with the latest March 2018 revision of the Intel Architectures\n//! Software Developer\u2019s Manual.\n//!\n//! ## Example\n//! ```rust\n//! use raw_cpuid::CpuId;\n//! let cpuid = CpuId::new();\n//!\n//! if let Some(vf) = cpuid.get_vendor_info() {\n//!     assert!(vf.as_string() == \"GenuineIntel\" || vf.as_string() == \"AuthenticAMD\");\n//! }\n//!\n//! let has_sse = cpuid.get_feature_info().map_or(false, |finfo| finfo.has_sse());\n//! if has_sse {\n//!     println!(\"CPU supports SSE!\");\n//! }\n//!\n//! if let Some(cparams) = cpuid.get_cache_parameters() {\n//!     for cache in cparams {\n//!         let size = cache.associativity() * cache.physical_line_partitions() * cache.coherency_line_size() * cache.sets();\n//!         println!(\"L{}-Cache size is {}\", cache.level(), size);\n//!     }\n//! } else {\n//!     println!(\"No cache parameter information available\")\n//! }\n//! ```\n\n#![no_std]\n#![crate_name = \"raw_cpuid\"]\n#![crate_type = \"lib\"]\n\n#[cfg(test)]\n#[macro_use]\nextern crate std;\n\n#[cfg(test)]\nmod tests;\n#[cfg(feature = \"serialize\")]\n#[macro_use]\nextern crate serde_derive;\n\n#[cfg(feature = \"serialize\")]\nextern crate serde;\n\n#[macro_use]\nextern crate bitflags;\n\n/// Uses Rust's `cpuid` function from the `arch` module.\npub mod native_cpuid {\n    use super::CpuIdResult;\n\n    #[cfg(all(target_arch = \"x86\", not(target_env = \"sgx\"), target_feature = \"sse\"))]\n    use core::arch::x86 as arch;\n    #[cfg(all(target_arch = \"x86_64\", not(target_env = \"sgx\")))]\n    use core::arch::x86_64 as arch;\n\n    pub fn cpuid_count(a: u32, c: u32) -> CpuIdResult {\n        // Safety: CPUID is supported on all x86_64 CPUs and all x86 CPUs with\n        // SSE, but not by SGX.\n        let result = unsafe { self::arch::__cpuid_count(a, c) };\n\n        CpuIdResult {\n            eax: result.eax,\n            ebx: result.ebx,\n            ecx: result.ecx,\n            edx: result.edx,\n        }\n    }\n}\n\nuse core::cmp::min;\nuse core::fmt;\nuse core::mem::size_of;\nuse core::slice;\nuse core::str;\n\n#[cfg(not(test))]\nmod std {\n    pub use core::ops;\n    pub use core::option;\n}\n\n/// Macro which queries cpuid directly.\n///\n/// First parameter is cpuid leaf (EAX register value),\n/// second optional parameter is the subleaf (ECX register value).\n#[macro_export]\nmacro_rules! cpuid {\n    ($eax:expr) => {\n        $crate::native_cpuid::cpuid_count($eax as u32, 0)\n    };\n\n    ($eax:expr, $ecx:expr) => {\n        $crate::native_cpuid::cpuid_count($eax as u32, $ecx as u32)\n    };\n}\n\nfn get_bits(r: u32, from: u32, to: u32) -> u32 {\n    assert!(from <= 31);\n    assert!(to <= 31);\n    assert!(from <= to);\n\n    let mask = match to {\n        31 => 0xffffffff,\n        _ => (1 << (to + 1)) - 1,\n    };\n\n    (r & mask) >> from\n}\n\nmacro_rules! check_flag {\n    ($doc:meta, $fun:ident, $flags:ident, $flag:expr) => {\n        #[$doc]\n        pub fn $fun(&self) -> bool {\n            self.$flags.contains($flag)\n        }\n    };\n}\n\nmacro_rules! is_bit_set {\n    ($field:expr, $bit:expr) => {\n        $field & (1 << $bit) > 0\n    };\n}\n\nmacro_rules! check_bit_fn {\n    ($doc:meta, $fun:ident, $field:ident, $bit:expr) => {\n        #[$doc]\n        pub fn $fun(&self) -> bool {\n            is_bit_set!(self.$field, $bit)\n        }\n    };\n}\n\n/// Implements function to read/write cpuid.\n/// This allows to conveniently swap out the underlying cpuid implementation\n/// with one that returns data that is deterministic (for unit-testing).\n#[derive(Debug, Clone, Copy)]\nstruct CpuIdReader {\n    cpuid_fn: fn(u32, u32) -> CpuIdResult,\n}\n\nimpl CpuIdReader {\n    fn new(cpuid_fn: fn(u32, u32) -> CpuIdResult) -> Self {\n        Self { cpuid_fn }\n    }\n\n    fn cpuid1(&self, eax: u32) -> CpuIdResult {\n        (self.cpuid_fn)(eax, 0)\n    }\n\n    fn cpuid2(&self, eax: u32, ecx: u32) -> CpuIdResult {\n        (self.cpuid_fn)(eax, ecx)\n    }\n}\n\nimpl Default for CpuIdReader {\n    fn default() -> Self {\n        Self {\n            cpuid_fn: native_cpuid::cpuid_count,\n        }\n    }\n}\n\n#[derive(Debug, Eq, PartialEq, Clone, Copy)]\n#[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\nenum Vendor {\n    Intel,\n    Amd,\n    Unknown(u32, u32, u32),\n}\n\nimpl Vendor {\n    fn from_vendor_leaf(res: CpuIdResult) -> Self {\n        let vi = VendorInfo {\n            ebx: res.ebx,\n            ecx: res.ecx,\n            edx: res.edx,\n        };\n\n        match vi.as_string() {\n            \"GenuineIntel\" => Vendor::Intel,\n            \"AuthenticAMD\" => Vendor::Amd,\n            _ => Vendor::Unknown(res.ebx, res.ecx, res.edx),\n        }\n    }\n}\n\n/// Main type used to query for information about the CPU we're running on.\n#[derive(Debug)]\n#[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\npub struct CpuId {\n    #[cfg_attr(feature = \"serialize\", serde(skip))]\n    read: CpuIdReader,\n    vendor: Vendor,\n    supported_leafs: u32,\n}\n\nimpl Default for CpuId {\n    fn default() -> CpuId {\n        CpuId::with_cpuid_fn(native_cpuid::cpuid_count)\n    }\n}\n\n/// Low-level data-structure to store result of cpuid instruction.\n#[derive(Copy, Clone, Debug, Default, Eq, PartialEq)]\n#[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\n#[repr(C)]\npub struct CpuIdResult {\n    /// Return value EAX register\n    pub eax: u32,\n    /// Return value EBX register\n    pub ebx: u32,\n    /// Return value ECX register\n    pub ecx: u32,\n    /// Return value EDX register\n    pub edx: u32,\n}\n\nimpl CpuIdResult {\n    pub fn all_zero(&self) -> bool {\n        self.eax == 0 && self.ebx == 0 && self.ecx == 0 && self.edx == 0\n    }\n}\n\nconst EAX_VENDOR_INFO: u32 = 0x0;\nconst EAX_FEATURE_INFO: u32 = 0x1;\nconst EAX_CACHE_INFO: u32 = 0x2;\nconst EAX_PROCESSOR_SERIAL: u32 = 0x3;\nconst EAX_CACHE_PARAMETERS: u32 = 0x4;\nconst EAX_MONITOR_MWAIT_INFO: u32 = 0x5;\nconst EAX_THERMAL_POWER_INFO: u32 = 0x6;\nconst EAX_STRUCTURED_EXTENDED_FEATURE_INFO: u32 = 0x7;\nconst EAX_DIRECT_CACHE_ACCESS_INFO: u32 = 0x9;\nconst EAX_PERFORMANCE_MONITOR_INFO: u32 = 0xA;\nconst EAX_EXTENDED_TOPOLOGY_INFO: u32 = 0xB;\nconst EAX_EXTENDED_STATE_INFO: u32 = 0xD;\nconst EAX_RDT_MONITORING: u32 = 0xF;\nconst EAX_RDT_ALLOCATION: u32 = 0x10;\nconst EAX_SGX: u32 = 0x12;\nconst EAX_TRACE_INFO: u32 = 0x14;\nconst EAX_TIME_STAMP_COUNTER_INFO: u32 = 0x15;\nconst EAX_FREQUENCY_INFO: u32 = 0x16;\nconst EAX_SOC_VENDOR_INFO: u32 = 0x17;\nconst EAX_DETERMINISTIC_ADDRESS_TRANSLATION_INFO: u32 = 0x18;\nconst EAX_HYPERVISOR_INFO: u32 = 0x40000000;\nconst EAX_EXTENDED_FUNCTION_INFO: u32 = 0x80000000;\nconst EAX_MEMORY_ENCRYPTION_INFO: u32 = 0x8000001F;\n\nimpl CpuId {\n    /// Return new CPUID struct.\n    pub fn new() -> Self {\n        Self::default()\n    }\n\n    pub fn with_cpuid_fn(cpuid_fn: fn(u32, u32) -> CpuIdResult) -> Self {\n        let read = CpuIdReader::new(cpuid_fn);\n        let vendor_leaf = read.cpuid1(EAX_VENDOR_INFO);\n        CpuId {\n            supported_leafs: vendor_leaf.eax,\n            vendor: Vendor::from_vendor_leaf(vendor_leaf),\n            read,\n        }\n    }\n\n    /// Check if a non extended leaf  (`val`) is supported.\n    fn leaf_is_supported(&self, val: u32) -> bool {\n        // Exclude reserved functions/leafs on AMD\n        if self.vendor == Vendor::Amd && ((0x2..=0x4).contains(&val) || (0x8..=0xa).contains(&val))\n        {\n            return false;\n        }\n\n        val <= self.supported_leafs\n    }\n\n    /// Return information about vendor.\n    /// This is typically a ASCII readable string such as\n    /// GenuineIntel for Intel CPUs or AuthenticAMD for AMD CPUs.\n    pub fn get_vendor_info(&self) -> Option<VendorInfo> {\n        if self.leaf_is_supported(EAX_VENDOR_INFO) {\n            let res = self.read.cpuid1(EAX_VENDOR_INFO);\n            Some(VendorInfo {\n                ebx: res.ebx,\n                ecx: res.ecx,\n                edx: res.edx,\n            })\n        } else {\n            None\n        }\n    }\n\n    /// Query a set of features that are available on this CPU.\n    pub fn get_feature_info(&self) -> Option<FeatureInfo> {\n        if self.leaf_is_supported(EAX_FEATURE_INFO) {\n            let res = self.read.cpuid1(EAX_FEATURE_INFO);\n            Some(FeatureInfo {\n                eax: res.eax,\n                ebx: res.ebx,\n                edx_ecx: FeatureInfoFlags {\n                    bits: (((res.edx as u64) << 32) | (res.ecx as u64)),\n                },\n            })\n        } else {\n            None\n        }\n    }\n\n    /// Query basic information about caches. This will just return an index\n    /// into a static table of cache descriptions (see `CACHE_INFO_TABLE`).\n    pub fn get_cache_info(&self) -> Option<CacheInfoIter> {\n        if self.leaf_is_supported(EAX_CACHE_INFO) {\n            let res = self.read.cpuid1(EAX_CACHE_INFO);\n            Some(CacheInfoIter {\n                current: 1,\n                eax: res.eax,\n                ebx: res.ebx,\n                ecx: res.ecx,\n                edx: res.edx,\n            })\n        } else {\n            None\n        }\n    }\n\n    /// Retrieve serial number of processor.\n    pub fn get_processor_serial(&self) -> Option<ProcessorSerial> {\n        if self.leaf_is_supported(EAX_PROCESSOR_SERIAL) {\n            let res = self.read.cpuid1(EAX_PROCESSOR_SERIAL);\n            Some(ProcessorSerial {\n                ecx: res.ecx,\n                edx: res.edx,\n            })\n        } else {\n            None\n        }\n    }\n\n    /// Retrieve more elaborate information about caches (as opposed\n    /// to `get_cache_info`). This will tell us about associativity,\n    /// set size, line size etc. for each level of the cache hierarchy.\n    pub fn get_cache_parameters(&self) -> Option<CacheParametersIter> {\n        if self.leaf_is_supported(EAX_CACHE_PARAMETERS) {\n            Some(CacheParametersIter {\n                read: self.read,\n                current: 0,\n            })\n        } else {\n            None\n        }\n    }\n\n    /// Information about how monitor/mwait works on this CPU.\n    pub fn get_monitor_mwait_info(&self) -> Option<MonitorMwaitInfo> {\n        if self.leaf_is_supported(EAX_MONITOR_MWAIT_INFO) {\n            let res = self.read.cpuid1(EAX_MONITOR_MWAIT_INFO);\n            Some(MonitorMwaitInfo {\n                eax: res.eax,\n                ebx: res.ebx,\n                ecx: res.ecx,\n                edx: res.edx,\n            })\n        } else {\n            None\n        }\n    }\n\n    /// Query information about thermal and power management features of the CPU.\n    pub fn get_thermal_power_info(&self) -> Option<ThermalPowerInfo> {\n        if self.leaf_is_supported(EAX_THERMAL_POWER_INFO) {\n            let res = self.read.cpuid1(EAX_THERMAL_POWER_INFO);\n            Some(ThermalPowerInfo {\n                eax: ThermalPowerFeaturesEax { bits: res.eax },\n                ebx: res.ebx,\n                ecx: ThermalPowerFeaturesEcx { bits: res.ecx },\n                edx: res.edx,\n            })\n        } else {\n            None\n        }\n    }\n\n    /// Find out about more features supported by this CPU.\n    pub fn get_extended_feature_info(&self) -> Option<ExtendedFeatures> {\n        if self.leaf_is_supported(EAX_STRUCTURED_EXTENDED_FEATURE_INFO) {\n            let res = self.read.cpuid1(EAX_STRUCTURED_EXTENDED_FEATURE_INFO);\n            Some(ExtendedFeatures {\n                eax: res.eax,\n                ebx: ExtendedFeaturesEbx { bits: res.ebx },\n                ecx: ExtendedFeaturesEcx { bits: res.ecx },\n                edx: res.edx,\n            })\n        } else {\n            None\n        }\n    }\n\n    /// Direct cache access info.\n    pub fn get_direct_cache_access_info(&self) -> Option<DirectCacheAccessInfo> {\n        if self.leaf_is_supported(EAX_DIRECT_CACHE_ACCESS_INFO) {\n            let res = self.read.cpuid1(EAX_DIRECT_CACHE_ACCESS_INFO);\n            Some(DirectCacheAccessInfo { eax: res.eax })\n        } else {\n            None\n        }\n    }\n\n    /// Info about performance monitoring (how many counters etc.).\n    pub fn get_performance_monitoring_info(&self) -> Option<PerformanceMonitoringInfo> {\n        if self.leaf_is_supported(EAX_PERFORMANCE_MONITOR_INFO) {\n            let res = self.read.cpuid1(EAX_PERFORMANCE_MONITOR_INFO);\n            Some(PerformanceMonitoringInfo {\n                eax: res.eax,\n                ebx: PerformanceMonitoringFeaturesEbx { bits: res.ebx },\n                ecx: res.ecx,\n                edx: res.edx,\n            })\n        } else {\n            None\n        }\n    }\n\n    /// Information about topology (how many cores and what kind of cores).\n    pub fn get_extended_topology_info(&self) -> Option<ExtendedTopologyIter> {\n        if self.leaf_is_supported(EAX_EXTENDED_TOPOLOGY_INFO) {\n            Some(ExtendedTopologyIter {\n                read: self.read,\n                level: 0,\n            })\n        } else {\n            None\n        }\n    }\n\n    /// Information for saving/restoring extended register state.\n    pub fn get_extended_state_info(&self) -> Option<ExtendedStateInfo> {\n        if self.leaf_is_supported(EAX_EXTENDED_STATE_INFO) {\n            let res = self.read.cpuid2(EAX_EXTENDED_STATE_INFO, 0);\n            let res1 = self.read.cpuid2(EAX_EXTENDED_STATE_INFO, 1);\n            Some(ExtendedStateInfo {\n                read: self.read,\n                eax: ExtendedStateInfoXCR0Flags { bits: res.eax },\n                ebx: res.ebx,\n                ecx: res.ecx,\n                edx: res.edx,\n                eax1: res1.eax,\n                ebx1: res1.ebx,\n                ecx1: ExtendedStateInfoXSSFlags { bits: res1.ecx },\n                edx1: res1.edx,\n            })\n        } else {\n            None\n        }\n    }\n\n    /// Quality of service informations.\n    pub fn get_rdt_monitoring_info(&self) -> Option<RdtMonitoringInfo> {\n        let res = self.read.cpuid1(EAX_RDT_MONITORING);\n\n        if self.leaf_is_supported(EAX_RDT_MONITORING) {\n            Some(RdtMonitoringInfo {\n                read: self.read,\n                ebx: res.ebx,\n                edx: res.edx,\n            })\n        } else {\n            None\n        }\n    }\n\n    /// Quality of service enforcement information.\n    pub fn get_rdt_allocation_info(&self) -> Option<RdtAllocationInfo> {\n        let res = self.read.cpuid1(EAX_RDT_ALLOCATION);\n\n        if self.leaf_is_supported(EAX_RDT_ALLOCATION) {\n            Some(RdtAllocationInfo {\n                read: self.read,\n                ebx: res.ebx,\n            })\n        } else {\n            None\n        }\n    }\n\n    pub fn get_sgx_info(&self) -> Option<SgxInfo> {\n        // Leaf 12H sub-leaf 0 (ECX = 0) is supported if CPUID.(EAX=07H, ECX=0H):EBX[SGX] = 1.\n        self.get_extended_feature_info().and_then(|info| {\n            if self.leaf_is_supported(EAX_SGX) && info.has_sgx() {\n                let res = self.read.cpuid2(EAX_SGX, 0);\n                let res1 = self.read.cpuid2(EAX_SGX, 1);\n                Some(SgxInfo {\n                    read: self.read,\n                    eax: res.eax,\n                    ebx: res.ebx,\n                    ecx: res.ecx,\n                    edx: res.edx,\n                    eax1: res1.eax,\n                    ebx1: res1.ebx,\n                    ecx1: res1.ecx,\n                    edx1: res1.edx,\n                })\n            } else {\n                None\n            }\n        })\n    }\n\n    /// Intel Processor Trace Enumeration Information.\n    pub fn get_processor_trace_info(&self) -> Option<ProcessorTraceInfo> {\n        if self.leaf_is_supported(EAX_TRACE_INFO) {\n            let res = self.read.cpuid2(EAX_TRACE_INFO, 0);\n            let res1 = if res.eax >= 1 {\n                Some(self.read.cpuid2(EAX_TRACE_INFO, 1))\n            } else {\n                None\n            };\n\n            Some(ProcessorTraceInfo {\n                eax: res.eax,\n                ebx: res.ebx,\n                ecx: res.ecx,\n                edx: res.edx,\n                leaf1: res1,\n            })\n        } else {\n            None\n        }\n    }\n\n    /// Time Stamp Counter/Core Crystal Clock Information.\n    pub fn get_tsc_info(&self) -> Option<TscInfo> {\n        if self.leaf_is_supported(EAX_TIME_STAMP_COUNTER_INFO) {\n            let res = self.read.cpuid2(EAX_TIME_STAMP_COUNTER_INFO, 0);\n            Some(TscInfo {\n                eax: res.eax,\n                ebx: res.ebx,\n                ecx: res.ecx,\n            })\n        } else {\n            None\n        }\n    }\n\n    /// Processor Frequency Information.\n    pub fn get_processor_frequency_info(&self) -> Option<ProcessorFrequencyInfo> {\n        if self.leaf_is_supported(EAX_FREQUENCY_INFO) {\n            let res = self.read.cpuid1(EAX_FREQUENCY_INFO);\n            Some(ProcessorFrequencyInfo {\n                eax: res.eax,\n                ebx: res.ebx,\n                ecx: res.ecx,\n            })\n        } else {\n            None\n        }\n    }\n\n    pub fn deterministic_address_translation_info(&self) -> Option<DatIter> {\n        if self.leaf_is_supported(EAX_DETERMINISTIC_ADDRESS_TRANSLATION_INFO) {\n            let res = self\n                .read\n                .cpuid2(EAX_DETERMINISTIC_ADDRESS_TRANSLATION_INFO, 0);\n            Some(DatIter {\n                read: self.read,\n                current: 0,\n                count: res.eax,\n            })\n        } else {\n            None\n        }\n    }\n\n    pub fn get_soc_vendor_info(&self) -> Option<SoCVendorInfo> {\n        if self.leaf_is_supported(EAX_SOC_VENDOR_INFO) {\n            let res = self.read.cpuid1(EAX_SOC_VENDOR_INFO);\n            Some(SoCVendorInfo {\n                read: self.read,\n                eax: res.eax,\n                ebx: res.ebx,\n                ecx: res.ecx,\n                edx: res.edx,\n            })\n        } else {\n            None\n        }\n    }\n\n    pub fn get_hypervisor_info(&self) -> Option<HypervisorInfo> {\n        let res = self.read.cpuid1(EAX_HYPERVISOR_INFO);\n        if res.eax > 0 {\n            Some(HypervisorInfo {\n                read: self.read,\n                res,\n            })\n        } else {\n            None\n        }\n    }\n\n    /// Extended functionality of CPU described here (including more supported features).\n    /// This also contains a more detailed CPU model identifier.\n    pub fn get_extended_function_info(&self) -> Option<ExtendedFunctionInfo> {\n        let res = self.read.cpuid1(EAX_EXTENDED_FUNCTION_INFO);\n\n        if res.eax == 0 {\n            return None;\n        }\n\n        let mut ef = ExtendedFunctionInfo {\n            max_eax_value: res.eax - EAX_EXTENDED_FUNCTION_INFO,\n            data: [\n                CpuIdResult {\n                    eax: res.eax,\n                    ebx: res.ebx,\n                    ecx: res.ecx,\n                    edx: res.edx,\n                },\n                CpuIdResult {\n                    eax: 0,\n                    ebx: 0,\n                    ecx: 0,\n                    edx: 0,\n                },\n                CpuIdResult {\n                    eax: 0,\n                    ebx: 0,\n                    ecx: 0,\n                    edx: 0,\n                },\n                CpuIdResult {\n                    eax: 0,\n                    ebx: 0,\n                    ecx: 0,\n                    edx: 0,\n                },\n                CpuIdResult {\n                    eax: 0,\n                    ebx: 0,\n                    ecx: 0,\n                    edx: 0,\n                },\n                CpuIdResult {\n                    eax: 0,\n                    ebx: 0,\n                    ecx: 0,\n                    edx: 0,\n                },\n                CpuIdResult {\n                    eax: 0,\n                    ebx: 0,\n                    ecx: 0,\n                    edx: 0,\n                },\n                CpuIdResult {\n                    eax: 0,\n                    ebx: 0,\n                    ecx: 0,\n                    edx: 0,\n                },\n                CpuIdResult {\n                    eax: 0,\n                    ebx: 0,\n                    ecx: 0,\n                    edx: 0,\n                },\n            ],\n        };\n\n        let max_eax_value = min(ef.max_eax_value + 1, ef.data.len() as u32);\n        for i in 1..max_eax_value {\n            ef.data[i as usize] = self.read.cpuid1(EAX_EXTENDED_FUNCTION_INFO + i);\n        }\n\n        Some(ef)\n    }\n\n    pub fn get_memory_encryption_info(&self) -> Option<MemoryEncryptionInfo> {\n        let res = self.read.cpuid1(EAX_EXTENDED_FUNCTION_INFO);\n        if res.eax < EAX_MEMORY_ENCRYPTION_INFO {\n            return None;\n        }\n\n        let res = self.read.cpuid1(EAX_MEMORY_ENCRYPTION_INFO);\n        Some(MemoryEncryptionInfo {\n            eax: MemoryEncryptionInfoEax { bits: res.eax },\n            ebx: res.ebx,\n            ecx: res.ecx,\n            edx: res.edx,\n        })\n    }\n}\n\n/// Vendor Info String, that can be for example \"AuthenticAMD\" or \"GenuineIntel\".\n///\n/// ## Technical Background\n/// The vendor info is a 12-byte (96 bit) long string stored in `ebx`, `edx` and `ecx` by\n/// the corresponding `cpuid` instruction.\n#[derive(Debug, Default)]\n#[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\n#[repr(C)]\npub struct VendorInfo {\n    ebx: u32,\n    edx: u32,\n    ecx: u32,\n}\n\nimpl VendorInfo {\n    /// Return vendor identification as human readable string.\n    pub fn as_string<'a>(&'a self) -> &'a str {\n        let brand_string_start = self as *const VendorInfo as *const u8;\n        unsafe {\n            // Safety: VendorInfo is laid out with repr(C) and exactly\n            // 12 byte long without any padding.\n            let slice: &'a [u8] =\n                slice::from_raw_parts(brand_string_start, size_of::<VendorInfo>());\n            // Safety: The field is specified to be ASCII, and the only safe\n            // way to construct VendorInfo is from real CPUID data or the\n            // Default implementation.\n            str::from_utf8_unchecked(slice)\n        }\n    }\n}\n\n/// Used to iterate over cache information contained in cpuid instruction.\n#[derive(Debug, Default)]\n#[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\npub struct CacheInfoIter {\n    current: u32,\n    eax: u32,\n    ebx: u32,\n    ecx: u32,\n    edx: u32,\n}\n\nimpl Iterator for CacheInfoIter {\n    type Item = CacheInfo;\n\n    /// Iterate over all cache information.\n    fn next(&mut self) -> Option<CacheInfo> {\n        // Every byte of the 4 register values returned by cpuid\n        // can contain information about a cache (except the\n        // very first one).\n        if self.current >= 4 * 4 {\n            return None;\n        }\n        let reg_index = self.current % 4;\n        let byte_index = self.current / 4;\n\n        let reg = match reg_index {\n            0 => self.eax,\n            1 => self.ebx,\n            2 => self.ecx,\n            3 => self.edx,\n            _ => unreachable!(),\n        };\n\n        let byte = match byte_index {\n            0 => reg,\n            1 => reg >> 8,\n            2 => reg >> 16,\n            3 => reg >> 24,\n            _ => unreachable!(),\n        } as u8;\n\n        if byte == 0 {\n            self.current += 1;\n            return self.next();\n        }\n\n        for cache_info in CACHE_INFO_TABLE.iter() {\n            if cache_info.num == byte {\n                self.current += 1;\n                return Some(*cache_info);\n            }\n        }\n\n        None\n    }\n}\n\n/// What type of cache are we dealing with?\n#[derive(Copy, Clone, Debug)]\n#[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\npub enum CacheInfoType {\n    General,\n    Cache,\n    TLB,\n    STLB,\n    DTLB,\n    Prefetch,\n}\n\nimpl Default for CacheInfoType {\n    fn default() -> CacheInfoType {\n        CacheInfoType::General\n    }\n}\n\n/// Describes any kind of cache (TLB, Data and Instruction caches plus prefetchers).\n#[derive(Copy, Clone, Debug, Default)]\n#[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\npub struct CacheInfo {\n    /// Number as retrieved from cpuid\n    pub num: u8,\n    /// Cache type\n    pub typ: CacheInfoType,\n}\n\nimpl CacheInfo {\n    /// Description of the cache (from Intel Manual)\n    pub fn desc(&self) -> &'static str {\n        match self.num {\n            0x00 => \"Null descriptor, this byte contains no information\",\n            0x01 => \"Instruction TLB: 4 KByte pages, 4-way set associative, 32 entries\",\n            0x02 => \"Instruction TLB: 4 MByte pages, fully associative, 2 entries\",\n            0x03 => \"Data TLB: 4 KByte pages, 4-way set associative, 64 entries\",\n            0x04 => \"Data TLB: 4 MByte pages, 4-way set associative, 8 entries\",\n            0x05 => \"Data TLB1: 4 MByte pages, 4-way set associative, 32 entries\",\n            0x06 => \"1st-level instruction cache: 8 KBytes, 4-way set associative, 32 byte line size\",\n            0x08 => \"1st-level instruction cache: 16 KBytes, 4-way set associative, 32 byte line size\",\n            0x09 => \"1st-level instruction cache: 32KBytes, 4-way set associative, 64 byte line size\",\n            0x0A => \"1st-level data cache: 8 KBytes, 2-way set associative, 32 byte line size\",\n            0x0B => \"Instruction TLB: 4 MByte pages, 4-way set associative, 4 entries\",\n            0x0C => \"1st-level data cache: 16 KBytes, 4-way set associative, 32 byte line size\",\n            0x0D => \"1st-level data cache: 16 KBytes, 4-way set associative, 64 byte line size\",\n            0x0E => \"1st-level data cache: 24 KBytes, 6-way set associative, 64 byte line size\",\n            0x1D => \"2nd-level cache: 128 KBytes, 2-way set associative, 64 byte line size\",\n            0x21 => \"2nd-level cache: 256 KBytes, 8-way set associative, 64 byte line size\",\n            0x22 => \"3rd-level cache: 512 KBytes, 4-way set associative, 64 byte line size, 2 lines per sector\",\n            0x23 => \"3rd-level cache: 1 MBytes, 8-way set associative, 64 byte line size, 2 lines per sector\",\n            0x24 => \"2nd-level cache: 1 MBytes, 16-way set associative, 64 byte line size\",\n            0x25 => \"3rd-level cache: 2 MBytes, 8-way set associative, 64 byte line size, 2 lines per sector\",\n            0x29 => \"3rd-level cache: 4 MBytes, 8-way set associative, 64 byte line size, 2 lines per sector\",\n            0x2C => \"1st-level data cache: 32 KBytes, 8-way set associative, 64 byte line size\",\n            0x30 => \"1st-level instruction cache: 32 KBytes, 8-way set associative, 64 byte line size\",\n            0x40 => \"No 2nd-level cache or, if processor contains a valid 2nd-level cache, no 3rd-level cache\",\n            0x41 => \"2nd-level cache: 128 KBytes, 4-way set associative, 32 byte line size\",\n            0x42 => \"2nd-level cache: 256 KBytes, 4-way set associative, 32 byte line size\",\n            0x43 => \"2nd-level cache: 512 KBytes, 4-way set associative, 32 byte line size\",\n            0x44 => \"2nd-level cache: 1 MByte, 4-way set associative, 32 byte line size\",\n            0x45 => \"2nd-level cache: 2 MByte, 4-way set associative, 32 byte line size\",\n            0x46 => \"3rd-level cache: 4 MByte, 4-way set associative, 64 byte line size\",\n            0x47 => \"3rd-level cache: 8 MByte, 8-way set associative, 64 byte line size\",\n            0x48 => \"2nd-level cache: 3MByte, 12-way set associative, 64 byte line size\",\n            0x49 => \"3rd-level cache: 4MB, 16-way set associative, 64-byte line size (Intel Xeon processor MP, Family 0FH, Model 06H); 2nd-level cache: 4 MByte, 16-way set ssociative, 64 byte line size\",\n            0x4A => \"3rd-level cache: 6MByte, 12-way set associative, 64 byte line size\",\n            0x4B => \"3rd-level cache: 8MByte, 16-way set associative, 64 byte line size\",\n            0x4C => \"3rd-level cache: 12MByte, 12-way set associative, 64 byte line size\",\n            0x4D => \"3rd-level cache: 16MByte, 16-way set associative, 64 byte line size\",\n            0x4E => \"2nd-level cache: 6MByte, 24-way set associative, 64 byte line size\",\n            0x4F => \"Instruction TLB: 4 KByte pages, 32 entries\",\n            0x50 => \"Instruction TLB: 4 KByte and 2-MByte or 4-MByte pages, 64 entries\",\n            0x51 => \"Instruction TLB: 4 KByte and 2-MByte or 4-MByte pages, 128 entries\",\n            0x52 => \"Instruction TLB: 4 KByte and 2-MByte or 4-MByte pages, 256 entries\",\n            0x55 => \"Instruction TLB: 2-MByte or 4-MByte pages, fully associative, 7 entries\",\n            0x56 => \"Data TLB0: 4 MByte pages, 4-way set associative, 16 entries\",\n            0x57 => \"Data TLB0: 4 KByte pages, 4-way associative, 16 entries\",\n            0x59 => \"Data TLB0: 4 KByte pages, fully associative, 16 entries\",\n            0x5A => \"Data TLB0: 2-MByte or 4 MByte pages, 4-way set associative, 32 entries\",\n            0x5B => \"Data TLB: 4 KByte and 4 MByte pages, 64 entries\",\n            0x5C => \"Data TLB: 4 KByte and 4 MByte pages,128 entries\",\n            0x5D => \"Data TLB: 4 KByte and 4 MByte pages,256 entries\",\n            0x60 => \"1st-level data cache: 16 KByte, 8-way set associative, 64 byte line size\",\n            0x61 => \"Instruction TLB: 4 KByte pages, fully associative, 48 entries\",\n            0x63 => \"Data TLB: 2 MByte or 4 MByte pages, 4-way set associative, 32 entries and a separate array with 1 GByte pages, 4-way set associative, 4 entries\",\n            0x64 => \"Data TLB: 4 KByte pages, 4-way set associative, 512 entries\",\n            0x66 => \"1st-level data cache: 8 KByte, 4-way set associative, 64 byte line size\",\n            0x67 => \"1st-level data cache: 16 KByte, 4-way set associative, 64 byte line size\",\n            0x68 => \"1st-level data cache: 32 KByte, 4-way set associative, 64 byte line size\",\n            0x6A => \"uTLB: 4 KByte pages, 8-way set associative, 64 entries\",\n            0x6B => \"DTLB: 4 KByte pages, 8-way set associative, 256 entries\",\n            0x6C => \"DTLB: 2M/4M pages, 8-way set associative, 128 entries\",\n            0x6D => \"DTLB: 1 GByte pages, fully associative, 16 entries\",\n            0x70 => \"Trace cache: 12 K-\u03bcop, 8-way set associative\",\n            0x71 => \"Trace cache: 16 K-\u03bcop, 8-way set associative\",\n            0x72 => \"Trace cache: 32 K-\u03bcop, 8-way set associative\",\n            0x76 => \"Instruction TLB: 2M/4M pages, fully associative, 8 entries\",\n            0x78 => \"2nd-level cache: 1 MByte, 4-way set associative, 64byte line size\",\n            0x79 => \"2nd-level cache: 128 KByte, 8-way set associative, 64 byte line size, 2 lines per sector\",\n            0x7A => \"2nd-level cache: 256 KByte, 8-way set associative, 64 byte line size, 2 lines per sector\",\n            0x7B => \"2nd-level cache: 512 KByte, 8-way set associative, 64 byte line size, 2 lines per sector\",\n            0x7C => \"2nd-level cache: 1 MByte, 8-way set associative, 64 byte line size, 2 lines per sector\",\n            0x7D => \"2nd-level cache: 2 MByte, 8-way set associative, 64byte line size\",\n            0x7F => \"2nd-level cache: 512 KByte, 2-way set associative, 64-byte line size\",\n            0x80 => \"2nd-level cache: 512 KByte, 8-way set associative, 64-byte line size\",\n            0x82 => \"2nd-level cache: 256 KByte, 8-way set associative, 32 byte line size\",\n            0x83 => \"2nd-level cache: 512 KByte, 8-way set associative, 32 byte line size\",\n            0x84 => \"2nd-level cache: 1 MByte, 8-way set associative, 32 byte line size\",\n            0x85 => \"2nd-level cache: 2 MByte, 8-way set associative, 32 byte line size\",\n            0x86 => \"2nd-level cache: 512 KByte, 4-way set associative, 64 byte line size\",\n            0x87 => \"2nd-level cache: 1 MByte, 8-way set associative, 64 byte line size\",\n            0xA0 => \"DTLB: 4k pages, fully associative, 32 entries\",\n            0xB0 => \"Instruction TLB: 4 KByte pages, 4-way set associative, 128 entries\",\n            0xB1 => \"Instruction TLB: 2M pages, 4-way, 8 entries or 4M pages, 4-way, 4 entries\",\n            0xB2 => \"Instruction TLB: 4KByte pages, 4-way set associative, 64 entries\",\n            0xB3 => \"Data TLB: 4 KByte pages, 4-way set associative, 128 entries\",\n            0xB4 => \"Data TLB1: 4 KByte pages, 4-way associative, 256 entries\",\n            0xB5 => \"Instruction TLB: 4KByte pages, 8-way set associative, 64 entries\",\n            0xB6 => \"Instruction TLB: 4KByte pages, 8-way set associative, 128 entries\",\n            0xBA => \"Data TLB1: 4 KByte pages, 4-way associative, 64 entries\",\n            0xC0 => \"Data TLB: 4 KByte and 4 MByte pages, 4-way associative, 8 entries\",\n            0xC1 => \"Shared 2nd-Level TLB: 4 KByte/2MByte pages, 8-way associative, 1024 entries\",\n            0xC2 => \"DTLB: 2 MByte/$MByte pages, 4-way associative, 16 entries\",\n            0xC3 => \"Shared 2nd-Level TLB: 4 KByte /2 MByte pages, 6-way associative, 1536 entries. Also 1GBbyte pages, 4-way, 16 entries.\",\n            0xC4 => \"DTLB: 2M/4M Byte pages, 4-way associative, 32 entries\",\n            0xCA => \"Shared 2nd-Level TLB: 4 KByte pages, 4-way associative, 512 entries\",\n            0xD0 => \"3rd-level cache: 512 KByte, 4-way set associative, 64 byte line size\",\n            0xD1 => \"3rd-level cache: 1 MByte, 4-way set associative, 64 byte line size\",\n            0xD2 => \"3rd-level cache: 2 MByte, 4-way set associative, 64 byte line size\",\n            0xD6 => \"3rd-level cache: 1 MByte, 8-way set associative, 64 byte line size\",\n            0xD7 => \"3rd-level cache: 2 MByte, 8-way set associative, 64 byte line size\",\n            0xD8 => \"3rd-level cache: 4 MByte, 8-way set associative, 64 byte line size\",\n            0xDC => \"3rd-level cache: 1.5 MByte, 12-way set associative, 64 byte line size\",\n            0xDD => \"3rd-level cache: 3 MByte, 12-way set associative, 64 byte line size\",\n            0xDE => \"3rd-level cache: 6 MByte, 12-way set associative, 64 byte line size\",\n            0xE2 => \"3rd-level cache: 2 MByte, 16-way set associative, 64 byte line size\",\n            0xE3 => \"3rd-level cache: 4 MByte, 16-way set associative, 64 byte line size\",\n            0xE4 => \"3rd-level cache: 8 MByte, 16-way set associative, 64 byte line size\",\n            0xEA => \"3rd-level cache: 12MByte, 24-way set associative, 64 byte line size\",\n            0xEB => \"3rd-level cache: 18MByte, 24-way set associative, 64 byte line size\",\n            0xEC => \"3rd-level cache: 24MByte, 24-way set associative, 64 byte line size\",\n            0xF0 => \"64-Byte prefetching\",\n            0xF1 => \"128-Byte prefetching\",\n            0xFE => \"CPUID leaf 2 does not report TLB descriptor information; use CPUID leaf 18H to query TLB and other address translation parameters.\",\n            0xFF => \"CPUID leaf 2 does not report cache descriptor information, use CPUID leaf 4 to query cache parameters\",\n            _ => \"Unknown cache type!\"\n        }\n    }\n}\n\nimpl fmt::Display for CacheInfo {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        let typ = match self.typ {\n            CacheInfoType::General => \"N/A\",\n            CacheInfoType::Cache => \"Cache\",\n            CacheInfoType::TLB => \"TLB\",\n            CacheInfoType::STLB => \"STLB\",\n            CacheInfoType::DTLB => \"DTLB\",\n            CacheInfoType::Prefetch => \"Prefetcher\",\n        };\n\n        write!(f, \"{:x}:\\t {}: {}\", self.num, typ, self.desc())\n    }\n}\n\n/// This table is taken from Intel manual (Section CPUID instruction).\npub const CACHE_INFO_TABLE: [CacheInfo; 108] = [\n    CacheInfo {\n        num: 0x00,\n        typ: CacheInfoType::General,\n    },\n    CacheInfo {\n        num: 0x01,\n        typ: CacheInfoType::TLB,\n    },\n    CacheInfo {\n        num: 0x02,\n        typ: CacheInfoType::TLB,\n    },\n    CacheInfo {\n        num: 0x03,\n        typ: CacheInfoType::TLB,\n    },\n    CacheInfo {\n        num: 0x04,\n        typ: CacheInfoType::TLB,\n    },\n    CacheInfo {\n        num: 0x05,\n        typ: CacheInfoType::TLB,\n    },\n    CacheInfo {\n        num: 0x06,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x08,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x09,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x0A,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x0B,\n        typ: CacheInfoType::TLB,\n    },\n    CacheInfo {\n        num: 0x0C,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x0D,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x0E,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x21,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x22,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x23,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x24,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x25,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x29,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x2C,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x30,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x40,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x41,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x42,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x43,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x44,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x45,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x46,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x47,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x48,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x49,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x4A,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x4B,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x4C,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x4D,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x4E,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x4F,\n        typ: CacheInfoType::TLB,\n    },\n    CacheInfo {\n        num: 0x50,\n        typ: CacheInfoType::TLB,\n    },\n    CacheInfo {\n        num: 0x51,\n        typ: CacheInfoType::TLB,\n    },\n    CacheInfo {\n        num: 0x52,\n        typ: CacheInfoType::TLB,\n    },\n    CacheInfo {\n        num: 0x55,\n        typ: CacheInfoType::TLB,\n    },\n    CacheInfo {\n        num: 0x56,\n        typ: CacheInfoType::TLB,\n    },\n    CacheInfo {\n        num: 0x57,\n        typ: CacheInfoType::TLB,\n    },\n    CacheInfo {\n        num: 0x59,\n        typ: CacheInfoType::TLB,\n    },\n    CacheInfo {\n        num: 0x5A,\n        typ: CacheInfoType::TLB,\n    },\n    CacheInfo {\n        num: 0x5B,\n        typ: CacheInfoType::TLB,\n    },\n    CacheInfo {\n        num: 0x5C,\n        typ: CacheInfoType::TLB,\n    },\n    CacheInfo {\n        num: 0x5D,\n        typ: CacheInfoType::TLB,\n    },\n    CacheInfo {\n        num: 0x60,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x61,\n        typ: CacheInfoType::TLB,\n    },\n    CacheInfo {\n        num: 0x63,\n        typ: CacheInfoType::TLB,\n    },\n    CacheInfo {\n        num: 0x66,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x67,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x68,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x6A,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x6B,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x6C,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x6D,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x70,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x71,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x72,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x76,\n        typ: CacheInfoType::TLB,\n    },\n    CacheInfo {\n        num: 0x78,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x79,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x7A,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x7B,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x7C,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x7D,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x7F,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x80,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x82,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x83,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x84,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x85,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x86,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0x87,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0xB0,\n        typ: CacheInfoType::TLB,\n    },\n    CacheInfo {\n        num: 0xB1,\n        typ: CacheInfoType::TLB,\n    },\n    CacheInfo {\n        num: 0xB2,\n        typ: CacheInfoType::TLB,\n    },\n    CacheInfo {\n        num: 0xB3,\n        typ: CacheInfoType::TLB,\n    },\n    CacheInfo {\n        num: 0xB4,\n        typ: CacheInfoType::TLB,\n    },\n    CacheInfo {\n        num: 0xB5,\n        typ: CacheInfoType::TLB,\n    },\n    CacheInfo {\n        num: 0xB6,\n        typ: CacheInfoType::TLB,\n    },\n    CacheInfo {\n        num: 0xBA,\n        typ: CacheInfoType::TLB,\n    },\n    CacheInfo {\n        num: 0xC0,\n        typ: CacheInfoType::TLB,\n    },\n    CacheInfo {\n        num: 0xC1,\n        typ: CacheInfoType::STLB,\n    },\n    CacheInfo {\n        num: 0xC2,\n        typ: CacheInfoType::DTLB,\n    },\n    CacheInfo {\n        num: 0xCA,\n        typ: CacheInfoType::STLB,\n    },\n    CacheInfo {\n        num: 0xD0,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0xD1,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0xD2,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0xD6,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0xD7,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0xD8,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0xDC,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0xDD,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0xDE,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0xE2,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0xE3,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0xE4,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0xEA,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0xEB,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0xEC,\n        typ: CacheInfoType::Cache,\n    },\n    CacheInfo {\n        num: 0xF0,\n        typ: CacheInfoType::Prefetch,\n    },\n    CacheInfo {\n        num: 0xF1,\n        typ: CacheInfoType::Prefetch,\n    },\n    CacheInfo {\n        num: 0xFE,\n        typ: CacheInfoType::General,\n    },\n    CacheInfo {\n        num: 0xFF,\n        typ: CacheInfoType::General,\n    },\n];\n\nimpl fmt::Display for VendorInfo {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        write!(f, \"{}\", self.as_string())\n    }\n}\n\n#[derive(Debug, Default)]\n#[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\npub struct ProcessorSerial {\n    ecx: u32,\n    edx: u32,\n}\n\nimpl ProcessorSerial {\n    /// Bits 00-31 of 96 bit processor serial number.\n    /// (Available in Pentium III processor only; otherwise, the value in this register is reserved.)\n    pub fn serial_lower(&self) -> u32 {\n        self.ecx\n    }\n\n    /// Bits 32-63 of 96 bit processor serial number.\n    /// (Available in Pentium III processor only; otherwise, the value in this register is reserved.)\n    pub fn serial_middle(&self) -> u32 {\n        self.edx\n    }\n\n    pub fn serial(&self) -> u64 {\n        (self.serial_lower() as u64) | (self.serial_middle() as u64) << 32\n    }\n}\n\n#[derive(Debug, Default)]\n#[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\npub struct FeatureInfo {\n    eax: u32,\n    ebx: u32,\n    edx_ecx: FeatureInfoFlags,\n}\n\nimpl FeatureInfo {\n    /// Version Information: Extended Family\n    pub fn extended_family_id(&self) -> u8 {\n        get_bits(self.eax, 20, 27) as u8\n    }\n\n    /// Version Information: Extended Model\n    pub fn extended_model_id(&self) -> u8 {\n        get_bits(self.eax, 16, 19) as u8\n    }\n\n    /// Version Information: Family\n    pub fn family_id(&self) -> u8 {\n        get_bits(self.eax, 8, 11) as u8\n    }\n\n    /// Version Information: Model\n    pub fn model_id(&self) -> u8 {\n        get_bits(self.eax, 4, 7) as u8\n    }\n\n    /// Version Information: Stepping ID\n    pub fn stepping_id(&self) -> u8 {\n        get_bits(self.eax, 0, 3) as u8\n    }\n\n    /// Brand Index\n    pub fn brand_index(&self) -> u8 {\n        get_bits(self.ebx, 0, 7) as u8\n    }\n\n    /// CLFLUSH line size (Value \u2217 8 = cache line size in bytes)\n    pub fn cflush_cache_line_size(&self) -> u8 {\n        get_bits(self.ebx, 8, 15) as u8\n    }\n\n    /// Initial APIC ID\n    pub fn initial_local_apic_id(&self) -> u8 {\n        get_bits(self.ebx, 24, 31) as u8\n    }\n\n    /// Maximum number of addressable IDs for logical processors in this physical package.\n    pub fn max_logical_processor_ids(&self) -> u8 {\n        get_bits(self.ebx, 16, 23) as u8\n    }\n\n    check_flag!(\n        doc = \"Streaming SIMD Extensions 3 (SSE3). A value of 1 indicates the processor \\\n               supports this technology.\",\n        has_sse3,\n        edx_ecx,\n        FeatureInfoFlags::SSE3\n    );\n\n    check_flag!(\n        doc = \"PCLMULQDQ. A value of 1 indicates the processor supports the PCLMULQDQ \\\n               instruction\",\n        has_pclmulqdq,\n        edx_ecx,\n        FeatureInfoFlags::PCLMULQDQ\n    );\n\n    check_flag!(\n        doc = \"64-bit DS Area. A value of 1 indicates the processor supports DS area \\\n               using 64-bit layout\",\n        has_ds_area,\n        edx_ecx,\n        FeatureInfoFlags::DTES64\n    );\n\n    check_flag!(\n        doc = \"MONITOR/MWAIT. A value of 1 indicates the processor supports this feature.\",\n        has_monitor_mwait,\n        edx_ecx,\n        FeatureInfoFlags::MONITOR\n    );\n\n    check_flag!(\n        doc = \"CPL Qualified Debug Store. A value of 1 indicates the processor supports \\\n               the extensions to the  Debug Store feature to allow for branch message \\\n               storage qualified by CPL.\",\n        has_cpl,\n        edx_ecx,\n        FeatureInfoFlags::DSCPL\n    );\n\n    check_flag!(\n        doc = \"Virtual Machine Extensions. A value of 1 indicates that the processor \\\n               supports this technology.\",\n        has_vmx,\n        edx_ecx,\n        FeatureInfoFlags::VMX\n    );\n\n    check_flag!(\n        doc = \"Safer Mode Extensions. A value of 1 indicates that the processor supports \\\n               this technology. See Chapter 5, Safer Mode Extensions Reference.\",\n        has_smx,\n        edx_ecx,\n        FeatureInfoFlags::SMX\n    );\n\n    check_flag!(\n        doc = \"Enhanced Intel SpeedStep\u00ae technology. A value of 1 indicates that the \\\n               processor supports this technology.\",\n        has_eist,\n        edx_ecx,\n        FeatureInfoFlags::EIST\n    );\n\n    check_flag!(\n        doc = \"Thermal Monitor 2. A value of 1 indicates whether the processor supports \\\n               this technology.\",\n        has_tm2,\n        edx_ecx,\n        FeatureInfoFlags::TM2\n    );\n\n    check_flag!(\n        doc = \"A value of 1 indicates the presence of the Supplemental Streaming SIMD \\\n               Extensions 3 (SSSE3). A value of 0 indicates the instruction extensions \\\n               are not present in the processor\",\n        has_ssse3,\n        edx_ecx,\n        FeatureInfoFlags::SSSE3\n    );\n\n    check_flag!(\n        doc = \"L1 Context ID. A value of 1 indicates the L1 data cache mode can be set \\\n               to either adaptive mode or shared mode. A value of 0 indicates this \\\n               feature is not supported. See definition of the IA32_MISC_ENABLE MSR Bit \\\n               24 (L1 Data Cache Context Mode) for details.\",\n        has_cnxtid,\n        edx_ecx,\n        FeatureInfoFlags::CNXTID\n    );\n\n    check_flag!(\n        doc = \"A value of 1 indicates the processor supports FMA extensions using YMM \\\n               state.\",\n        has_fma,\n        edx_ecx,\n        FeatureInfoFlags::FMA\n    );\n\n    check_flag!(\n        doc = \"CMPXCHG16B Available. A value of 1 indicates that the feature is \\\n               available. See the CMPXCHG8B/CMPXCHG16B Compare and Exchange Bytes \\\n               section. 14\",\n        has_cmpxchg16b,\n        edx_ecx,\n        FeatureInfoFlags::CMPXCHG16B\n    );\n\n    check_flag!(\n        doc = \"Perfmon and Debug Capability: A value of 1 indicates the processor \\\n               supports the performance   and debug feature indication MSR \\\n               IA32_PERF_CAPABILITIES.\",\n        has_pdcm,\n        edx_ecx,\n        FeatureInfoFlags::PDCM\n    );\n\n    check_flag!(\n        doc = \"Process-context identifiers. A value of 1 indicates that the processor \\\n               supports PCIDs and the software may set CR4.PCIDE to 1.\",\n        has_pcid,\n        edx_ecx,\n        FeatureInfoFlags::PCID\n    );\n\n    check_flag!(\n        doc = \"A value of 1 indicates the processor supports the ability to prefetch \\\n               data from a memory mapped device.\",\n        has_dca,\n        edx_ecx,\n        FeatureInfoFlags::DCA\n    );\n\n    check_flag!(\n        doc = \"A value of 1 indicates that the processor supports SSE4.1.\",\n        has_sse41,\n        edx_ecx,\n        FeatureInfoFlags::SSE41\n    );\n\n    check_flag!(\n        doc = \"A value of 1 indicates that the processor supports SSE4.2.\",\n        has_sse42,\n        edx_ecx,\n        FeatureInfoFlags::SSE42\n    );\n\n    check_flag!(\n        doc = \"A value of 1 indicates that the processor supports x2APIC feature.\",\n        has_x2apic,\n        edx_ecx,\n        FeatureInfoFlags::X2APIC\n    );\n\n    check_flag!(\n        doc = \"A value of 1 indicates that the processor supports MOVBE instruction.\",\n        has_movbe,\n        edx_ecx,\n        FeatureInfoFlags::MOVBE\n    );\n\n    check_flag!(\n        doc = \"A value of 1 indicates that the processor supports the POPCNT instruction.\",\n        has_popcnt,\n        edx_ecx,\n        FeatureInfoFlags::POPCNT\n    );\n\n    check_flag!(\n        doc = \"A value of 1 indicates that the processors local APIC timer supports \\\n               one-shot operation using a TSC deadline value.\",\n        has_tsc_deadline,\n        edx_ecx,\n        FeatureInfoFlags::TSC_DEADLINE\n    );\n\n    check_flag!(\n        doc = \"A value of 1 indicates that the processor supports the AESNI instruction \\\n               extensions.\",\n        has_aesni,\n        edx_ecx,\n        FeatureInfoFlags::AESNI\n    );\n\n    check_flag!(\n        doc = \"A value of 1 indicates that the processor supports the XSAVE/XRSTOR \\\n               processor extended states feature, the XSETBV/XGETBV instructions, and \\\n               XCR0.\",\n        has_xsave,\n        edx_ecx,\n        FeatureInfoFlags::XSAVE\n    );\n\n    check_flag!(\n        doc = \"A value of 1 indicates that the OS has enabled XSETBV/XGETBV instructions \\\n               to access XCR0, and support for processor extended state management using \\\n               XSAVE/XRSTOR.\",\n        has_oxsave,\n        edx_ecx,\n        FeatureInfoFlags::OSXSAVE\n    );\n\n    check_flag!(\n        doc = \"A value of 1 indicates the processor supports the AVX instruction \\\n               extensions.\",\n        has_avx,\n        edx_ecx,\n        FeatureInfoFlags::AVX\n    );\n\n    check_flag!(\n        doc = \"A value of 1 indicates that processor supports 16-bit floating-point \\\n               conversion instructions.\",\n        has_f16c,\n        edx_ecx,\n        FeatureInfoFlags::F16C\n    );\n\n    check_flag!(\n        doc = \"A value of 1 indicates that processor supports RDRAND instruction.\",\n        has_rdrand,\n        edx_ecx,\n        FeatureInfoFlags::RDRAND\n    );\n\n    check_flag!(\n        doc = \"A value of 1 indicates the indicates the presence of a hypervisor.\",\n        has_hypervisor,\n        edx_ecx,\n        FeatureInfoFlags::HYPERVISOR\n    );\n\n    check_flag!(\n        doc = \"Floating Point Unit On-Chip. The processor contains an x87 FPU.\",\n        has_fpu,\n        edx_ecx,\n        FeatureInfoFlags::FPU\n    );\n\n    check_flag!(\n        doc = \"Virtual 8086 Mode Enhancements. Virtual 8086 mode enhancements, including \\\n               CR4.VME for controlling the feature, CR4.PVI for protected mode virtual \\\n               interrupts, software interrupt indirection, expansion of the TSS with the \\\n               software indirection bitmap, and EFLAGS.VIF and EFLAGS.VIP flags.\",\n        has_vme,\n        edx_ecx,\n        FeatureInfoFlags::VME\n    );\n\n    check_flag!(\n        doc = \"Debugging Extensions. Support for I/O breakpoints, including CR4.DE for \\\n               controlling the feature, and optional trapping of accesses to DR4 and DR5.\",\n        has_de,\n        edx_ecx,\n        FeatureInfoFlags::DE\n    );\n\n    check_flag!(\n        doc = \"Page Size Extension. Large pages of size 4 MByte are supported, including \\\n               CR4.PSE for controlling the feature, the defined dirty bit in PDE (Page \\\n               Directory Entries), optional reserved bit trapping in CR3, PDEs, and PTEs.\",\n        has_pse,\n        edx_ecx,\n        FeatureInfoFlags::PSE\n    );\n\n    check_flag!(\n        doc = \"Time Stamp Counter. The RDTSC instruction is supported, including CR4.TSD \\\n               for controlling privilege.\",\n        has_tsc,\n        edx_ecx,\n        FeatureInfoFlags::TSC\n    );\n\n    check_flag!(\n        doc = \"Model Specific Registers RDMSR and WRMSR Instructions. The RDMSR and \\\n               WRMSR instructions are supported. Some of the MSRs are implementation \\\n               dependent.\",\n        has_msr,\n        edx_ecx,\n        FeatureInfoFlags::MSR\n    );\n\n    check_flag!(\n        doc = \"Physical Address Extension. Physical addresses greater than 32 bits are \\\n               supported: extended page table entry formats, an extra level in the page \\\n               translation tables is defined, 2-MByte pages are supported instead of 4 \\\n               Mbyte pages if PAE bit is 1.\",\n        has_pae,\n        edx_ecx,\n        FeatureInfoFlags::PAE\n    );\n\n    check_flag!(\n        doc = \"Machine Check Exception. Exception 18 is defined for Machine Checks, \\\n               including CR4.MCE for controlling the feature. This feature does not \\\n               define the model-specific implementations of machine-check error logging, \\\n               reporting, and processor shutdowns. Machine Check exception handlers may \\\n               have to depend on processor version to do model specific processing of \\\n               the exception, or test for the presence of the Machine Check feature.\",\n        has_mce,\n        edx_ecx,\n        FeatureInfoFlags::MCE\n    );\n\n    check_flag!(\n        doc = \"CMPXCHG8B Instruction. The compare-and-exchange 8 bytes (64 bits) \\\n               instruction is supported (implicitly locked and atomic).\",\n        has_cmpxchg8b,\n        edx_ecx,\n        FeatureInfoFlags::CX8\n    );\n\n    check_flag!(\n        doc = \"APIC On-Chip. The processor contains an Advanced Programmable Interrupt \\\n               Controller (APIC), responding to memory mapped commands in the physical \\\n               address range FFFE0000H to FFFE0FFFH (by default - some processors permit \\\n               the APIC to be relocated).\",\n        has_apic,\n        edx_ecx,\n        FeatureInfoFlags::APIC\n    );\n\n    check_flag!(\n        doc = \"SYSENTER and SYSEXIT Instructions. The SYSENTER and SYSEXIT and \\\n               associated MSRs are supported.\",\n        has_sysenter_sysexit,\n        edx_ecx,\n        FeatureInfoFlags::SEP\n    );\n\n    check_flag!(\n        doc = \"Memory Type Range Registers. MTRRs are supported. The MTRRcap MSR \\\n               contains feature bits that describe what memory types are supported, how \\\n               many variable MTRRs are supported, and whether fixed MTRRs are supported.\",\n        has_mtrr,\n        edx_ecx,\n        FeatureInfoFlags::MTRR\n    );\n\n    check_flag!(\n        doc = \"Page Global Bit. The global bit is supported in paging-structure entries \\\n               that map a page, indicating TLB entries that are common to different \\\n               processes and need not be flushed. The CR4.PGE bit controls this feature.\",\n        has_pge,\n        edx_ecx,\n        FeatureInfoFlags::PGE\n    );\n\n    check_flag!(\n        doc = \"Machine Check Architecture. A value of 1 indicates the Machine Check \\\n               Architecture of reporting machine errors is supported. The MCG_CAP MSR \\\n               contains feature bits describing how many banks of error reporting MSRs \\\n               are supported.\",\n        has_mca,\n        edx_ecx,\n        FeatureInfoFlags::MCA\n    );\n\n    check_flag!(\n        doc = \"Conditional Move Instructions. The conditional move instruction CMOV is \\\n               supported. In addition, if x87 FPU is present as indicated by the \\\n               CPUID.FPU feature bit, then the FCOMI and FCMOV instructions are supported\",\n        has_cmov,\n        edx_ecx,\n        FeatureInfoFlags::CMOV\n    );\n\n    check_flag!(\n        doc = \"Page Attribute Table. Page Attribute Table is supported. This feature \\\n               augments the Memory Type Range Registers (MTRRs), allowing an operating \\\n               system to specify attributes of memory accessed through a linear address \\\n               on a 4KB granularity.\",\n        has_pat,\n        edx_ecx,\n        FeatureInfoFlags::PAT\n    );\n\n    check_flag!(\n        doc = \"36-Bit Page Size Extension. 4-MByte pages addressing physical memory \\\n               beyond 4 GBytes are supported with 32-bit paging. This feature indicates \\\n               that upper bits of the physical address of a 4-MByte page are encoded in \\\n               bits 20:13 of the page-directory entry. Such physical addresses are \\\n               limited by MAXPHYADDR and may be up to 40 bits in size.\",\n        has_pse36,\n        edx_ecx,\n        FeatureInfoFlags::PSE36\n    );\n\n    check_flag!(\n        doc = \"Processor Serial Number. The processor supports the 96-bit processor \\\n               identification number feature and the feature is enabled.\",\n        has_psn,\n        edx_ecx,\n        FeatureInfoFlags::PSN\n    );\n\n    check_flag!(\n        doc = \"CLFLUSH Instruction. CLFLUSH Instruction is supported.\",\n        has_clflush,\n        edx_ecx,\n        FeatureInfoFlags::CLFSH\n    );\n\n    check_flag!(\n        doc = \"Debug Store. The processor supports the ability to write debug \\\n               information into a memory resident buffer. This feature is used by the \\\n               branch trace store (BTS) and processor event-based sampling (PEBS) \\\n               facilities (see Chapter 23, Introduction to Virtual-Machine Extensions, \\\n               in the Intel\u00ae 64 and IA-32 Architectures Software Developers Manual, \\\n               Volume 3C).\",\n        has_ds,\n        edx_ecx,\n        FeatureInfoFlags::DS\n    );\n\n    check_flag!(\n        doc = \"Thermal Monitor and Software Controlled Clock Facilities. The processor \\\n               implements internal MSRs that allow processor temperature to be monitored \\\n               and processor performance to be modulated in predefined duty cycles under \\\n               software control.\",\n        has_acpi,\n        edx_ecx,\n        FeatureInfoFlags::ACPI\n    );\n\n    check_flag!(\n        doc = \"Intel MMX Technology. The processor supports the Intel MMX technology.\",\n        has_mmx,\n        edx_ecx,\n        FeatureInfoFlags::MMX\n    );\n\n    check_flag!(\n        doc = \"FXSAVE and FXRSTOR Instructions. The FXSAVE and FXRSTOR instructions are \\\n               supported for fast save and restore of the floating point context. \\\n               Presence of this bit also indicates that CR4.OSFXSR is available for an \\\n               operating system to indicate that it supports the FXSAVE and FXRSTOR \\\n               instructions.\",\n        has_fxsave_fxstor,\n        edx_ecx,\n        FeatureInfoFlags::FXSR\n    );\n\n    check_flag!(\n        doc = \"SSE. The processor supports the SSE extensions.\",\n        has_sse,\n        edx_ecx,\n        FeatureInfoFlags::SSE\n    );\n\n    check_flag!(\n        doc = \"SSE2. The processor supports the SSE2 extensions.\",\n        has_sse2,\n        edx_ecx,\n        FeatureInfoFlags::SSE2\n    );\n\n    check_flag!(\n        doc = \"Self Snoop. The processor supports the management of conflicting memory \\\n               types by performing a snoop of its own cache structure for transactions \\\n               issued to the bus.\",\n        has_ss,\n        edx_ecx,\n        FeatureInfoFlags::SS\n    );\n\n    check_flag!(\n        doc = \"Max APIC IDs reserved field is Valid. A value of 0 for HTT indicates \\\n               there is only a single logical processor in the package and software \\\n               should assume only a single APIC ID is reserved.  A value of 1 for HTT \\\n               indicates the value in CPUID.1.EBX\\\\[23:16\\\\] (the Maximum number of \\\n               addressable IDs for logical processors in this package) is valid for the \\\n               package.\",\n        has_htt,\n        edx_ecx,\n        FeatureInfoFlags::HTT\n    );\n\n    check_flag!(\n        doc = \"Thermal Monitor. The processor implements the thermal monitor automatic \\\n               thermal control circuitry (TCC).\",\n        has_tm,\n        edx_ecx,\n        FeatureInfoFlags::TM\n    );\n\n    check_flag!(\n        doc = \"Pending Break Enable. The processor supports the use of the FERR#/PBE# \\\n               pin when the processor is in the stop-clock state (STPCLK# is asserted) \\\n               to signal the processor that an interrupt is pending and that the \\\n               processor should return to normal operation to handle the interrupt. Bit \\\n               10 (PBE enable) in the IA32_MISC_ENABLE MSR enables this capability.\",\n        has_pbe,\n        edx_ecx,\n        FeatureInfoFlags::PBE\n    );\n}\n\nbitflags! {\n    #[derive(Default)]\n    #[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\n    struct FeatureInfoFlags: u64 {\n\n        // ECX flags\n\n        /// Streaming SIMD Extensions 3 (SSE3). A value of 1 indicates the processor supports this technology.\n        const SSE3 = 1 << 0;\n        /// PCLMULQDQ. A value of 1 indicates the processor supports the PCLMULQDQ instruction\n        const PCLMULQDQ = 1 << 1;\n        /// 64-bit DS Area. A value of 1 indicates the processor supports DS area using 64-bit layout\n        const DTES64 = 1 << 2;\n        /// MONITOR/MWAIT. A value of 1 indicates the processor supports this feature.\n        const MONITOR = 1 << 3;\n        /// CPL Qualified Debug Store. A value of 1 indicates the processor supports the extensions to the  Debug Store feature to allow for branch message storage qualified by CPL.\n        const DSCPL = 1 << 4;\n        /// Virtual Machine Extensions. A value of 1 indicates that the processor supports this technology.\n        const VMX = 1 << 5;\n        /// Safer Mode Extensions. A value of 1 indicates that the processor supports this technology. See Chapter 5, Safer Mode Extensions Reference.\n        const SMX = 1 << 6;\n        /// Enhanced Intel SpeedStep\u00ae technology. A value of 1 indicates that the processor supports this technology.\n        const EIST = 1 << 7;\n        /// Thermal Monitor 2. A value of 1 indicates whether the processor supports this technology.\n        const TM2 = 1 << 8;\n        /// A value of 1 indicates the presence of the Supplemental Streaming SIMD Extensions 3 (SSSE3). A value of 0 indicates the instruction extensions are not present in the processor\n        const SSSE3 = 1 << 9;\n        /// L1 Context ID. A value of 1 indicates the L1 data cache mode can be set to either adaptive mode or shared mode. A value of 0 indicates this feature is not supported. See definition of the IA32_MISC_ENABLE MSR Bit 24 (L1 Data Cache Context Mode) for details.\n        const CNXTID = 1 << 10;\n        /// A value of 1 indicates the processor supports FMA extensions using YMM state.\n        const FMA = 1 << 12;\n        /// CMPXCHG16B Available. A value of 1 indicates that the feature is available. See the CMPXCHG8B/CMPXCHG16B Compare and Exchange Bytes section. 14\n        const CMPXCHG16B = 1 << 13;\n        /// Perfmon and Debug Capability: A value of 1 indicates the processor supports the performance   and debug feature indication MSR IA32_PERF_CAPABILITIES.\n        const PDCM = 1 << 15;\n        /// Process-context identifiers. A value of 1 indicates that the processor supports PCIDs and the software may set CR4.PCIDE to 1.\n        const PCID = 1 << 17;\n        /// A value of 1 indicates the processor supports the ability to prefetch data from a memory mapped device.\n        const DCA = 1 << 18;\n        /// A value of 1 indicates that the processor supports SSE4.1.\n        const SSE41 = 1 << 19;\n        /// A value of 1 indicates that the processor supports SSE4.2.\n        const SSE42 = 1 << 20;\n        /// A value of 1 indicates that the processor supports x2APIC feature.\n        const X2APIC = 1 << 21;\n        /// A value of 1 indicates that the processor supports MOVBE instruction.\n        const MOVBE = 1 << 22;\n        /// A value of 1 indicates that the processor supports the POPCNT instruction.\n        const POPCNT = 1 << 23;\n        /// A value of 1 indicates that the processors local APIC timer supports one-shot operation using a TSC deadline value.\n        const TSC_DEADLINE = 1 << 24;\n        /// A value of 1 indicates that the processor supports the AESNI instruction extensions.\n        const AESNI = 1 << 25;\n        /// A value of 1 indicates that the processor supports the XSAVE/XRSTOR processor extended states feature, the XSETBV/XGETBV instructions, and XCR0.\n        const XSAVE = 1 << 26;\n        /// A value of 1 indicates that the OS has enabled XSETBV/XGETBV instructions to access XCR0, and support for processor extended state management using XSAVE/XRSTOR.\n        const OSXSAVE = 1 << 27;\n        /// A value of 1 indicates the processor supports the AVX instruction extensions.\n        const AVX = 1 << 28;\n        /// A value of 1 indicates that processor supports 16-bit floating-point conversion instructions.\n        const F16C = 1 << 29;\n        /// A value of 1 indicates that processor supports RDRAND instruction.\n        const RDRAND = 1 << 30;\n        /// A value of 1 indicates the indicates the presence of a hypervisor.\n        const HYPERVISOR = 1 << 31;\n\n\n        // EDX flags\n\n        /// Floating Point Unit On-Chip. The processor contains an x87 FPU.\n        const FPU = 1 << 32;\n        /// Virtual 8086 Mode Enhancements. Virtual 8086 mode enhancements, including CR4.VME for controlling the feature, CR4.PVI for protected mode virtual interrupts, software interrupt indirection, expansion of the TSS with the software indirection bitmap, and EFLAGS.VIF and EFLAGS.VIP flags.\n        const VME = 1 << (32 + 1);\n        /// Debugging Extensions. Support for I/O breakpoints, including CR4.DE for controlling the feature, and optional trapping of accesses to DR4 and DR5.\n        const DE = 1 << (32 + 2);\n        /// Page Size Extension. Large pages of size 4 MByte are supported, including CR4.PSE for controlling the feature, the defined dirty bit in PDE (Page Directory Entries), optional reserved bit trapping in CR3, PDEs, and PTEs.\n        const PSE = 1 << (32 + 3);\n        /// Time Stamp Counter. The RDTSC instruction is supported, including CR4.TSD for controlling privilege.\n        const TSC = 1 << (32 + 4);\n        /// Model Specific Registers RDMSR and WRMSR Instructions. The RDMSR and WRMSR instructions are supported. Some of the MSRs are implementation dependent.\n        const MSR = 1 << (32 + 5);\n        /// Physical Address Extension. Physical addresses greater than 32 bits are supported: extended page table entry formats, an extra level in the page translation tables is defined, 2-MByte pages are supported instead of 4 Mbyte pages if PAE bit is 1.\n        const PAE = 1 << (32 + 6);\n        /// Machine Check Exception. Exception 18 is defined for Machine Checks, including CR4.MCE for controlling the feature. This feature does not define the model-specific implementations of machine-check error logging, reporting, and processor shutdowns. Machine Check exception handlers may have to depend on processor version to do model specific processing of the exception, or test for the presence of the Machine Check feature.\n        const MCE = 1 << (32 + 7);\n        /// CMPXCHG8B Instruction. The compare-and-exchange 8 bytes (64 bits) instruction is supported (implicitly locked and atomic).\n        const CX8 = 1 << (32 + 8);\n        /// APIC On-Chip. The processor contains an Advanced Programmable Interrupt Controller (APIC), responding to memory mapped commands in the physical address range FFFE0000H to FFFE0FFFH (by default - some processors permit the APIC to be relocated).\n        const APIC = 1 << (32 + 9);\n        /// SYSENTER and SYSEXIT Instructions. The SYSENTER and SYSEXIT and associated MSRs are supported.\n        const SEP = 1 << (32 + 11);\n        /// Memory Type Range Registers. MTRRs are supported. The MTRRcap MSR contains feature bits that describe what memory types are supported, how many variable MTRRs are supported, and whether fixed MTRRs are supported.\n        const MTRR = 1 << (32 + 12);\n        /// Page Global Bit. The global bit is supported in paging-structure entries that map a page, indicating TLB entries that are common to different processes and need not be flushed. The CR4.PGE bit controls this feature.\n        const PGE = 1 << (32 + 13);\n        /// Machine Check Architecture. The Machine Check exArchitecture, which provides a compatible mechanism for error reporting in P6 family, Pentium 4, Intel Xeon processors, and future processors, is supported. The MCG_CAP MSR contains feature bits describing how many banks of error reporting MSRs are supported.\n        const MCA = 1 << (32 + 14);\n        /// Conditional Move Instructions. The conditional move instruction CMOV is supported. In addition, if x87 FPU is present as indicated by the CPUID.FPU feature bit, then the FCOMI and FCMOV instructions are supported\n        const CMOV = 1 << (32 + 15);\n        /// Page Attribute Table. Page Attribute Table is supported. This feature augments the Memory Type Range Registers (MTRRs), allowing an operating system to specify attributes of memory accessed through a linear address on a 4KB granularity.\n        const PAT = 1 << (32 + 16);\n        /// 36-Bit Page Size Extension. 4-MByte pages addressing physical memory beyond 4 GBytes are supported with 32-bit paging. This feature indicates that upper bits of the physical address of a 4-MByte page are encoded in bits 20:13 of the page-directory entry. Such physical addresses are limited by MAXPHYADDR and may be up to 40 bits in size.\n        const PSE36 = 1 << (32 + 17);\n        /// Processor Serial Number. The processor supports the 96-bit processor identification number feature and the feature is enabled.\n        const PSN = 1 << (32 + 18);\n        /// CLFLUSH Instruction. CLFLUSH Instruction is supported.\n        const CLFSH = 1 << (32 + 19);\n        /// Debug Store. The processor supports the ability to write debug information into a memory resident buffer. This feature is used by the branch trace store (BTS) and precise event-based sampling (PEBS) facilities (see Chapter 23, Introduction to Virtual-Machine Extensions, in the Intel\u00ae 64 and IA-32 Architectures Software Developers Manual, Volume 3C).\n        const DS = 1 << (32 + 21);\n        /// Thermal Monitor and Software Controlled Clock Facilities. The processor implements internal MSRs that allow processor temperature to be monitored and processor performance to be modulated in predefined duty cycles under software control.\n        const ACPI = 1 << (32 + 22);\n        /// Intel MMX Technology. The processor supports the Intel MMX technology.\n        const MMX = 1 << (32 + 23);\n        /// FXSAVE and FXRSTOR Instructions. The FXSAVE and FXRSTOR instructions are supported for fast save and restore of the floating point context. Presence of this bit also indicates that CR4.OSFXSR is available for an operating system to indicate that it supports the FXSAVE and FXRSTOR instructions.\n        const FXSR = 1 << (32 + 24);\n        /// SSE. The processor supports the SSE extensions.\n        const SSE = 1 << (32 + 25);\n        /// SSE2. The processor supports the SSE2 extensions.\n        const SSE2 = 1 << (32 + 26);\n        /// Self Snoop. The processor supports the management of conflicting memory types by performing a snoop of its own cache structure for transactions issued to the bus.\n        const SS = 1 << (32 + 27);\n        /// Max APIC IDs reserved field is Valid. A value of 0 for HTT indicates there is only a single logical processor in the package and software should assume only a single APIC ID is reserved.  A value of 1 for HTT indicates the value in CPUID.1.EBX[23:16] (the Maximum number of addressable IDs for logical processors in this package) is valid for the package.\n        const HTT = 1 << (32 + 28);\n        /// Thermal Monitor. The processor implements the thermal monitor automatic thermal control circuitry (TCC).\n        const TM = 1 << (32 + 29);\n        /// Pending Break Enable. The processor supports the use of the FERR#/PBE# pin when the processor is in the stop-clock state (STPCLK# is asserted) to signal the processor that an interrupt is pending and that the processor should return to normal operation to handle the interrupt. Bit 10 (PBE enable) in the IA32_MISC_ENABLE MSR enables this capability.\n        const PBE = 1 << (32 + 31);\n    }\n}\n\n#[derive(Debug, Default)]\n#[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\npub struct CacheParametersIter {\n    #[cfg_attr(feature = \"serialize\", serde(skip))]\n    read: CpuIdReader,\n    current: u32,\n}\n\nimpl Iterator for CacheParametersIter {\n    type Item = CacheParameter;\n\n    /// Iterate over all caches for this CPU.\n    /// Note: cpuid is called every-time we this function to get information\n    /// about next cache.\n    fn next(&mut self) -> Option<CacheParameter> {\n        let res = self.read.cpuid2(EAX_CACHE_PARAMETERS, self.current);\n        let cp = CacheParameter {\n            eax: res.eax,\n            ebx: res.ebx,\n            ecx: res.ecx,\n            edx: res.edx,\n        };\n\n        match cp.cache_type() {\n            CacheType::Null => None,\n            CacheType::Reserved => None,\n            _ => {\n                self.current += 1;\n                Some(cp)\n            }\n        }\n    }\n}\n\n#[derive(Copy, Clone, Debug, Default)]\n#[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\npub struct CacheParameter {\n    eax: u32,\n    ebx: u32,\n    ecx: u32,\n    edx: u32,\n}\n\n#[derive(PartialEq, Eq, Debug)]\n#[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\npub enum CacheType {\n    /// Null - No more caches\n    Null = 0,\n    /// Data cache\n    Data,\n    /// Instruction cache\n    Instruction,\n    /// Data and Instruction cache\n    Unified,\n    /// 4-31 = Reserved\n    Reserved,\n}\n\nimpl Default for CacheType {\n    fn default() -> CacheType {\n        CacheType::Null\n    }\n}\n\nimpl CacheParameter {\n    /// Cache Type\n    pub fn cache_type(&self) -> CacheType {\n        let typ = get_bits(self.eax, 0, 4) as u8;\n        match typ {\n            0 => CacheType::Null,\n            1 => CacheType::Data,\n            2 => CacheType::Instruction,\n            3 => CacheType::Unified,\n            _ => CacheType::Reserved,\n        }\n    }\n\n    /// Cache Level (starts at 1)\n    pub fn level(&self) -> u8 {\n        get_bits(self.eax, 5, 7) as u8\n    }\n\n    /// Self Initializing cache level (does not need SW initialization).\n    pub fn is_self_initializing(&self) -> bool {\n        get_bits(self.eax, 8, 8) == 1\n    }\n\n    /// Fully Associative cache\n    pub fn is_fully_associative(&self) -> bool {\n        get_bits(self.eax, 9, 9) == 1\n    }\n\n    /// Maximum number of addressable IDs for logical processors sharing this cache\n    pub fn max_cores_for_cache(&self) -> usize {\n        (get_bits(self.eax, 14, 25) + 1) as usize\n    }\n\n    /// Maximum number of addressable IDs for processor cores in the physical package\n    pub fn max_cores_for_package(&self) -> usize {\n        (get_bits(self.eax, 26, 31) + 1) as usize\n    }\n\n    /// System Coherency Line Size (Bits 11-00)\n    pub fn coherency_line_size(&self) -> usize {\n        (get_bits(self.ebx, 0, 11) + 1) as usize\n    }\n\n    /// Physical Line partitions (Bits 21-12)\n    pub fn physical_line_partitions(&self) -> usize {\n        (get_bits(self.ebx, 12, 21) + 1) as usize\n    }\n\n    /// Ways of associativity (Bits 31-22)\n    pub fn associativity(&self) -> usize {\n        (get_bits(self.ebx, 22, 31) + 1) as usize\n    }\n\n    /// Number of Sets (Bits 31-00)\n    pub fn sets(&self) -> usize {\n        (self.ecx + 1) as usize\n    }\n\n    /// Write-Back Invalidate/Invalidate (Bit 0)\n    /// False: WBINVD/INVD from threads sharing this cache acts upon lower level caches for threads sharing this cache.\n    /// True: WBINVD/INVD is not guaranteed to act upon lower level caches of non-originating threads sharing this cache.\n    pub fn is_write_back_invalidate(&self) -> bool {\n        get_bits(self.edx, 0, 0) == 1\n    }\n\n    /// Cache Inclusiveness (Bit 1)\n    /// False: Cache is not inclusive of lower cache levels.\n    /// True: Cache is inclusive of lower cache levels.\n    pub fn is_inclusive(&self) -> bool {\n        get_bits(self.edx, 1, 1) == 1\n    }\n\n    /// Complex Cache Indexing (Bit 2)\n    /// False: Direct mapped cache.\n    /// True: A complex function is used to index the cache, potentially using all address bits.\n    pub fn has_complex_indexing(&self) -> bool {\n        get_bits(self.edx, 2, 2) == 1\n    }\n}\n\n#[derive(Debug, Default)]\n#[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\npub struct MonitorMwaitInfo {\n    eax: u32,\n    ebx: u32,\n    ecx: u32,\n    edx: u32,\n}\n\nimpl MonitorMwaitInfo {\n    /// Smallest monitor-line size in bytes (default is processor's monitor granularity)\n    pub fn smallest_monitor_line(&self) -> u16 {\n        get_bits(self.eax, 0, 15) as u16\n    }\n\n    /// Largest monitor-line size in bytes (default is processor's monitor granularity\n    pub fn largest_monitor_line(&self) -> u16 {\n        get_bits(self.ebx, 0, 15) as u16\n    }\n\n    ///  Enumeration of Monitor-Mwait extensions (beyond EAX and EBX registers) supported\n    pub fn extensions_supported(&self) -> bool {\n        get_bits(self.ecx, 0, 0) == 1\n    }\n\n    ///  Supports treating interrupts as break-event for MWAIT, even when interrupts disabled\n    pub fn interrupts_as_break_event(&self) -> bool {\n        get_bits(self.ecx, 1, 1) == 1\n    }\n\n    /// Number of C0 sub C-states supported using MWAIT (Bits 03 - 00)\n    pub fn supported_c0_states(&self) -> u16 {\n        get_bits(self.edx, 0, 3) as u16\n    }\n\n    /// Number of C1 sub C-states supported using MWAIT (Bits 07 - 04)\n    pub fn supported_c1_states(&self) -> u16 {\n        get_bits(self.edx, 4, 7) as u16\n    }\n\n    /// Number of C2 sub C-states supported using MWAIT (Bits 11 - 08)\n    pub fn supported_c2_states(&self) -> u16 {\n        get_bits(self.edx, 8, 11) as u16\n    }\n\n    /// Number of C3 sub C-states supported using MWAIT (Bits 15 - 12)\n    pub fn supported_c3_states(&self) -> u16 {\n        get_bits(self.edx, 12, 15) as u16\n    }\n\n    /// Number of C4 sub C-states supported using MWAIT (Bits 19 - 16)\n    pub fn supported_c4_states(&self) -> u16 {\n        get_bits(self.edx, 16, 19) as u16\n    }\n\n    /// Number of C5 sub C-states supported using MWAIT (Bits 23 - 20)\n    pub fn supported_c5_states(&self) -> u16 {\n        get_bits(self.edx, 20, 23) as u16\n    }\n\n    /// Number of C6 sub C-states supported using MWAIT (Bits 27 - 24)\n    pub fn supported_c6_states(&self) -> u16 {\n        get_bits(self.edx, 24, 27) as u16\n    }\n\n    /// Number of C7 sub C-states supported using MWAIT (Bits 31 - 28)\n    pub fn supported_c7_states(&self) -> u16 {\n        get_bits(self.edx, 28, 31) as u16\n    }\n}\n\n#[derive(Debug, Default)]\n#[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\npub struct ThermalPowerInfo {\n    eax: ThermalPowerFeaturesEax,\n    ebx: u32,\n    ecx: ThermalPowerFeaturesEcx,\n    edx: u32,\n}\n\nimpl ThermalPowerInfo {\n    /// Number of Interrupt Thresholds in Digital Thermal Sensor\n    pub fn dts_irq_threshold(&self) -> u8 {\n        get_bits(self.ebx, 0, 3) as u8\n    }\n\n    check_flag!(\n        doc = \"Digital temperature sensor is supported if set.\",\n        has_dts,\n        eax,\n        ThermalPowerFeaturesEax::DTS\n    );\n\n    check_flag!(\n        doc = \"Intel Turbo Boost Technology Available (see description of \\\n               IA32_MISC_ENABLE\\\\[38\\\\]).\",\n        has_turbo_boost,\n        eax,\n        ThermalPowerFeaturesEax::TURBO_BOOST\n    );\n\n    check_flag!(\n        doc = \"ARAT. APIC-Timer-always-running feature is supported if set.\",\n        has_arat,\n        eax,\n        ThermalPowerFeaturesEax::ARAT\n    );\n\n    check_flag!(\n        doc = \"PLN. Power limit notification controls are supported if set.\",\n        has_pln,\n        eax,\n        ThermalPowerFeaturesEax::PLN\n    );\n\n    check_flag!(\n        doc = \"ECMD. Clock modulation duty cycle extension is supported if set.\",\n        has_ecmd,\n        eax,\n        ThermalPowerFeaturesEax::ECMD\n    );\n\n    check_flag!(\n        doc = \"PTM. Package thermal management is supported if set.\",\n        has_ptm,\n        eax,\n        ThermalPowerFeaturesEax::PTM\n    );\n\n    check_flag!(\n        doc = \"HWP. HWP base registers (IA32_PM_ENABLE[bit 0], IA32_HWP_CAPABILITIES, \\\n               IA32_HWP_REQUEST, IA32_HWP_STATUS) are supported if set.\",\n        has_hwp,\n        eax,\n        ThermalPowerFeaturesEax::HWP\n    );\n\n    check_flag!(\n        doc = \"HWP Notification. IA32_HWP_INTERRUPT MSR is supported if set.\",\n        has_hwp_notification,\n        eax,\n        ThermalPowerFeaturesEax::HWP_NOTIFICATION\n    );\n\n    check_flag!(\n        doc = \"HWP Activity Window. IA32_HWP_REQUEST[bits 41:32] is supported if set.\",\n        has_hwp_activity_window,\n        eax,\n        ThermalPowerFeaturesEax::HWP_ACTIVITY_WINDOW\n    );\n\n    check_flag!(\n        doc =\n            \"HWP Energy Performance Preference. IA32_HWP_REQUEST[bits 31:24] is supported if set.\",\n        has_hwp_energy_performance_preference,\n        eax,\n        ThermalPowerFeaturesEax::HWP_ENERGY_PERFORMANCE_PREFERENCE\n    );\n\n    check_flag!(\n        doc = \"HWP Package Level Request. IA32_HWP_REQUEST_PKG MSR is supported if set.\",\n        has_hwp_package_level_request,\n        eax,\n        ThermalPowerFeaturesEax::HWP_PACKAGE_LEVEL_REQUEST\n    );\n\n    check_flag!(\n        doc = \"HDC. HDC base registers IA32_PKG_HDC_CTL, IA32_PM_CTL1, IA32_THREAD_STALL \\\n               MSRs are supported if set.\",\n        has_hdc,\n        eax,\n        ThermalPowerFeaturesEax::HDC\n    );\n\n    check_flag!(\n        doc = \"Intel\u00ae Turbo Boost Max Technology 3.0 available.\",\n        has_turbo_boost3,\n        eax,\n        ThermalPowerFeaturesEax::TURBO_BOOST_3\n    );\n\n    check_flag!(\n        doc = \"HWP Capabilities. Highest Performance change is supported if set.\",\n        has_hwp_capabilities,\n        eax,\n        ThermalPowerFeaturesEax::HWP_CAPABILITIES\n    );\n\n    check_flag!(\n        doc = \"HWP PECI override is supported if set.\",\n        has_hwp_peci_override,\n        eax,\n        ThermalPowerFeaturesEax::HWP_PECI_OVERRIDE\n    );\n\n    check_flag!(\n        doc = \"Flexible HWP is supported if set.\",\n        has_flexible_hwp,\n        eax,\n        ThermalPowerFeaturesEax::FLEXIBLE_HWP\n    );\n\n    check_flag!(\n        doc = \"Fast access mode for the IA32_HWP_REQUEST MSR is supported if set.\",\n        has_hwp_fast_access_mode,\n        eax,\n        ThermalPowerFeaturesEax::HWP_REQUEST_MSR_FAST_ACCESS\n    );\n\n    check_flag!(\n        doc = \"Ignoring Idle Logical Processor HWP request is supported if set.\",\n        has_ignore_idle_processor_hwp_request,\n        eax,\n        ThermalPowerFeaturesEax::IGNORE_IDLE_PROCESSOR_HWP_REQUEST\n    );\n\n    check_flag!(\n        doc = \"Hardware Coordination Feedback Capability (Presence of IA32_MPERF and \\\n               IA32_APERF). The capability to provide a measure of delivered processor \\\n               performance (since last reset of the counters), as a percentage of \\\n               expected processor performance at frequency specified in CPUID Brand \\\n               String Bits 02 - 01\",\n        has_hw_coord_feedback,\n        ecx,\n        ThermalPowerFeaturesEcx::HW_COORD_FEEDBACK\n    );\n\n    check_flag!(\n        doc = \"The processor supports performance-energy bias preference if \\\n               CPUID.06H:ECX.SETBH[bit 3] is set and it also implies the presence of a \\\n               new architectural MSR called IA32_ENERGY_PERF_BIAS (1B0H)\",\n        has_energy_bias_pref,\n        ecx,\n        ThermalPowerFeaturesEcx::ENERGY_BIAS_PREF\n    );\n}\n\nbitflags! {\n    #[derive(Default)]\n    #[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\n    struct ThermalPowerFeaturesEax: u32 {\n        /// Digital temperature sensor is supported if set. (Bit 00)\n        const DTS = 1 << 0;\n        /// Intel Turbo Boost Technology Available (see description of IA32_MISC_ENABLE[38]). (Bit 01)\n        const TURBO_BOOST = 1 << 1;\n        /// ARAT. APIC-Timer-always-running feature is supported if set. (Bit 02)\n        const ARAT = 1 << 2;\n        /// Bit 3: Reserved.\n        const RESERVED_3 = 1 << 3;\n        /// PLN. Power limit notification controls are supported if set. (Bit 04)\n        const PLN = 1 << 4;\n        /// ECMD. Clock modulation duty cycle extension is supported if set. (Bit 05)\n        const ECMD = 1 << 5;\n        /// PTM. Package thermal management is supported if set. (Bit 06)\n        const PTM = 1 << 6;\n        /// Bit 07: HWP. HWP base registers (IA32_PM_ENABLE[bit 0], IA32_HWP_CAPABILITIES, IA32_HWP_REQUEST, IA32_HWP_STATUS) are supported if set.\n        const HWP = 1 << 7;\n        /// Bit 08: HWP_Notification. IA32_HWP_INTERRUPT MSR is supported if set.\n        const HWP_NOTIFICATION = 1 << 8;\n        /// Bit 09: HWP_Activity_Window. IA32_HWP_REQUEST[bits 41:32] is supported if set.\n        const HWP_ACTIVITY_WINDOW = 1 << 9;\n        /// Bit 10: HWP_Energy_Performance_Preference. IA32_HWP_REQUEST[bits 31:24] is supported if set.\n        const HWP_ENERGY_PERFORMANCE_PREFERENCE = 1 << 10;\n        /// Bit 11: HWP_Package_Level_Request. IA32_HWP_REQUEST_PKG MSR is supported if set.\n        const HWP_PACKAGE_LEVEL_REQUEST = 1 << 11;\n        /// Bit 12: Reserved.\n        const RESERVED_12 = 1 << 12;\n        /// Bit 13: HDC. HDC base registers IA32_PKG_HDC_CTL, IA32_PM_CTL1, IA32_THREAD_STALL MSRs are supported if set.\n        const HDC = 1 << 13;\n        /// Bit 14: Intel\u00ae Turbo Boost Max Technology 3.0 available.\n        const TURBO_BOOST_3 = 1 << 14;\n        /// Bit 15: HWP Capabilities. Highest Performance change is supported if set.\n        const HWP_CAPABILITIES = 1 << 15;\n        /// Bit 16: HWP PECI override is supported if set.\n        const HWP_PECI_OVERRIDE = 1 << 16;\n        /// Bit 17: Flexible HWP is supported if set.\n        const FLEXIBLE_HWP = 1 << 17;\n        /// Bit 18: Fast access mode for the IA32_HWP_REQUEST MSR is supported if set.\n        const HWP_REQUEST_MSR_FAST_ACCESS = 1 << 18;\n        /// Bit 19: Reserved.\n        const RESERVED_19 = 1 << 19;\n        /// Bit 20: Ignoring Idle Logical Processor HWP request is supported if set.\n        const IGNORE_IDLE_PROCESSOR_HWP_REQUEST = 1 << 20;\n        // Bits 31 - 21: Reserved\n    }\n}\n\nbitflags! {\n    #[derive(Default)]\n    #[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\n    struct ThermalPowerFeaturesEcx: u32 {\n        /// Hardware Coordination Feedback Capability (Presence of IA32_MPERF and IA32_APERF). The capability to provide a measure of delivered processor performance (since last reset of the counters), as a percentage of expected processor performance at frequency specified in CPUID Brand String Bits 02 - 01\n        const HW_COORD_FEEDBACK = 1 << 0;\n\n        /// The processor supports performance-energy bias preference if CPUID.06H:ECX.SETBH[bit 3] is set and it also implies the presence of a new architectural MSR called IA32_ENERGY_PERF_BIAS (1B0H)\n        const ENERGY_BIAS_PREF = 1 << 3;\n    }\n}\n\n#[derive(Debug, Default)]\n#[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\npub struct ExtendedFeatures {\n    eax: u32,\n    ebx: ExtendedFeaturesEbx,\n    ecx: ExtendedFeaturesEcx,\n    edx: u32,\n}\n\nimpl ExtendedFeatures {\n    check_flag!(\n        doc = \"FSGSBASE. Supports RDFSBASE/RDGSBASE/WRFSBASE/WRGSBASE if 1.\",\n        has_fsgsbase,\n        ebx,\n        ExtendedFeaturesEbx::FSGSBASE\n    );\n\n    check_flag!(\n        doc = \"IA32_TSC_ADJUST MSR is supported if 1.\",\n        has_tsc_adjust_msr,\n        ebx,\n        ExtendedFeaturesEbx::ADJUST_MSR\n    );\n\n    check_flag!(doc = \"BMI1\", has_bmi1, ebx, ExtendedFeaturesEbx::BMI1);\n\n    check_flag!(doc = \"HLE\", has_hle, ebx, ExtendedFeaturesEbx::HLE);\n\n    check_flag!(doc = \"AVX2\", has_avx2, ebx, ExtendedFeaturesEbx::AVX2);\n\n    check_flag!(\n        doc = \"FDP_EXCPTN_ONLY. x87 FPU Data Pointer updated only on x87 exceptions if 1.\",\n        has_fdp,\n        ebx,\n        ExtendedFeaturesEbx::FDP\n    );\n\n    check_flag!(\n        doc = \"SMEP. Supports Supervisor-Mode Execution Prevention if 1.\",\n        has_smep,\n        ebx,\n        ExtendedFeaturesEbx::SMEP\n    );\n\n    check_flag!(doc = \"BMI2\", has_bmi2, ebx, ExtendedFeaturesEbx::BMI2);\n\n    check_flag!(\n        doc = \"Supports Enhanced REP MOVSB/STOSB if 1.\",\n        has_rep_movsb_stosb,\n        ebx,\n        ExtendedFeaturesEbx::REP_MOVSB_STOSB\n    );\n\n    check_flag!(\n        doc = \"INVPCID. If 1, supports INVPCID instruction for system software that \\\n               manages process-context identifiers.\",\n        has_invpcid,\n        ebx,\n        ExtendedFeaturesEbx::INVPCID\n    );\n\n    check_flag!(doc = \"RTM\", has_rtm, ebx, ExtendedFeaturesEbx::RTM);\n\n    check_flag!(\n        doc = \"Supports Intel Resource Director Technology (RDT) Monitoring capability.\",\n        has_rdtm,\n        ebx,\n        ExtendedFeaturesEbx::RDTM\n    );\n\n    check_flag!(\n        doc = \"Deprecates FPU CS and FPU DS values if 1.\",\n        has_fpu_cs_ds_deprecated,\n        ebx,\n        ExtendedFeaturesEbx::DEPRECATE_FPU_CS_DS\n    );\n\n    check_flag!(\n        doc = \"MPX. Supports Intel Memory Protection Extensions if 1.\",\n        has_mpx,\n        ebx,\n        ExtendedFeaturesEbx::MPX\n    );\n\n    check_flag!(\n        doc = \"Supports Intel Resource Director Technology (RDT) Allocation capability.\",\n        has_rdta,\n        ebx,\n        ExtendedFeaturesEbx::RDTA\n    );\n\n    check_flag!(\n        doc = \"Supports RDSEED.\",\n        has_rdseed,\n        ebx,\n        ExtendedFeaturesEbx::RDSEED\n    );\n\n    #[deprecated(\n        since = \"3.2\",\n        note = \"Deprecated due to typo in name, users should use has_rdseed() instead.\"\n    )]\n    check_flag!(\n        doc = \"Supports RDSEED (deprecated alias).\",\n        has_rdseet,\n        ebx,\n        ExtendedFeaturesEbx::RDSEED\n    );\n\n    check_flag!(\n        doc = \"Supports ADX.\",\n        has_adx,\n        ebx,\n        ExtendedFeaturesEbx::ADX\n    );\n\n    check_flag!(doc = \"SMAP. Supports Supervisor-Mode Access Prevention (and the CLAC/STAC instructions) if 1.\",\n                has_smap,\n                ebx,\n                ExtendedFeaturesEbx::SMAP);\n\n    check_flag!(\n        doc = \"Supports CLFLUSHOPT.\",\n        has_clflushopt,\n        ebx,\n        ExtendedFeaturesEbx::CLFLUSHOPT\n    );\n\n    check_flag!(\n        doc = \"Supports Intel Processor Trace.\",\n        has_processor_trace,\n        ebx,\n        ExtendedFeaturesEbx::PROCESSOR_TRACE\n    );\n\n    check_flag!(\n        doc = \"Supports SHA Instructions.\",\n        has_sha,\n        ebx,\n        ExtendedFeaturesEbx::SHA\n    );\n\n    check_flag!(\n        doc = \"Supports Intel\u00ae Software Guard Extensions (Intel\u00ae SGX Extensions).\",\n        has_sgx,\n        ebx,\n        ExtendedFeaturesEbx::SGX\n    );\n\n    check_flag!(\n        doc = \"Supports AVX512F.\",\n        has_avx512f,\n        ebx,\n        ExtendedFeaturesEbx::AVX512F\n    );\n\n    check_flag!(\n        doc = \"Supports AVX512DQ.\",\n        has_avx512dq,\n        ebx,\n        ExtendedFeaturesEbx::AVX512DQ\n    );\n\n    check_flag!(\n        doc = \"AVX512_IFMA\",\n        has_avx512_ifma,\n        ebx,\n        ExtendedFeaturesEbx::AVX512_IFMA\n    );\n\n    check_flag!(\n        doc = \"AVX512PF\",\n        has_avx512pf,\n        ebx,\n        ExtendedFeaturesEbx::AVX512PF\n    );\n    check_flag!(\n        doc = \"AVX512ER\",\n        has_avx512er,\n        ebx,\n        ExtendedFeaturesEbx::AVX512ER\n    );\n\n    check_flag!(\n        doc = \"AVX512CD\",\n        has_avx512cd,\n        ebx,\n        ExtendedFeaturesEbx::AVX512CD\n    );\n\n    check_flag!(\n        doc = \"AVX512BW\",\n        has_avx512bw,\n        ebx,\n        ExtendedFeaturesEbx::AVX512BW\n    );\n\n    check_flag!(\n        doc = \"AVX512VL\",\n        has_avx512vl,\n        ebx,\n        ExtendedFeaturesEbx::AVX512VL\n    );\n\n    check_flag!(doc = \"CLWB\", has_clwb, ebx, ExtendedFeaturesEbx::CLWB);\n\n    check_flag!(\n        doc = \"Has PREFETCHWT1 (Intel\u00ae Xeon Phi\u2122 only).\",\n        has_prefetchwt1,\n        ecx,\n        ExtendedFeaturesEcx::PREFETCHWT1\n    );\n\n    check_flag!(\n        doc = \"Supports user-mode instruction prevention if 1.\",\n        has_umip,\n        ecx,\n        ExtendedFeaturesEcx::UMIP\n    );\n\n    check_flag!(\n        doc = \"Supports protection keys for user-mode pages.\",\n        has_pku,\n        ecx,\n        ExtendedFeaturesEcx::PKU\n    );\n\n    check_flag!(\n        doc = \"OS has set CR4.PKE to enable protection keys (and the RDPKRU/WRPKRU instructions.\",\n        has_ospke,\n        ecx,\n        ExtendedFeaturesEcx::OSPKE\n    );\n\n    check_flag!(\n        doc = \"RDPID and IA32_TSC_AUX are available.\",\n        has_rdpid,\n        ecx,\n        ExtendedFeaturesEcx::RDPID\n    );\n\n    check_flag!(\n        doc = \"Supports SGX Launch Configuration.\",\n        has_sgx_lc,\n        ecx,\n        ExtendedFeaturesEcx::SGX_LC\n    );\n\n    /// The value of MAWAU used by the BNDLDX and BNDSTX instructions in 64-bit mode.\n    pub fn mawau_value(&self) -> u8 {\n        get_bits(self.ecx.bits(), 17, 21) as u8\n    }\n}\n\nbitflags! {\n    #[derive(Default)]\n    #[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\n    struct ExtendedFeaturesEbx: u32 {\n        /// FSGSBASE. Supports RDFSBASE/RDGSBASE/WRFSBASE/WRGSBASE if 1. (Bit 00)\n        const FSGSBASE = 1 << 0;\n        /// IA32_TSC_ADJUST MSR is supported if 1. (Bit 01)\n        const ADJUST_MSR = 1 << 1;\n        /// Bit 02: SGX. Supports Intel\u00ae Software Guard Extensions (Intel\u00ae SGX Extensions) if 1.\n        const SGX = 1 << 2;\n        /// BMI1 (Bit 03)\n        const BMI1 = 1 << 3;\n        /// HLE (Bit 04)\n        const HLE = 1 << 4;\n        /// AVX2 (Bit 05)\n        const AVX2 = 1 << 5;\n        /// FDP_EXCPTN_ONLY. x87 FPU Data Pointer updated only on x87 exceptions if 1.\n        const FDP = 1 << 6;\n        /// SMEP. Supports Supervisor-Mode Execution Prevention if 1. (Bit 07)\n        const SMEP = 1 << 7;\n        /// BMI2 (Bit 08)\n        const BMI2 = 1 << 8;\n        /// Supports Enhanced REP MOVSB/STOSB if 1. (Bit 09)\n        const REP_MOVSB_STOSB = 1 << 9;\n        /// INVPCID. If 1, supports INVPCID instruction for system software that manages process-context identifiers. (Bit 10)\n        const INVPCID = 1 << 10;\n        /// RTM (Bit 11)\n        const RTM = 1 << 11;\n        /// Supports Intel Resource Director Technology (RDT) Monitoring. (Bit 12)\n        const RDTM = 1 << 12;\n        /// Deprecates FPU CS and FPU DS values if 1. (Bit 13)\n        const DEPRECATE_FPU_CS_DS = 1 << 13;\n        /// Deprecates FPU CS and FPU DS values if 1. (Bit 14)\n        const MPX = 1 << 14;\n        /// Supports Intel Resource Director Technology (RDT) Allocation capability if 1.\n        const RDTA = 1 << 15;\n        /// Bit 16: AVX512F.\n        const AVX512F = 1 << 16;\n        /// Bit 17: AVX512DQ.\n        const AVX512DQ = 1 << 17;\n        /// Supports RDSEED.\n        const RDSEED = 1 << 18;\n        /// Supports ADX.\n        const ADX = 1 << 19;\n        /// SMAP. Supports Supervisor-Mode Access Prevention (and the CLAC/STAC instructions) if 1.\n        const SMAP = 1 << 20;\n        /// Bit 21: AVX512_IFMA.\n        const AVX512_IFMA = 1 << 21;\n        // Bit 22: Reserved.\n        /// Bit 23: CLFLUSHOPT\n        const CLFLUSHOPT = 1 << 23;\n        /// Bit 24: CLWB.\n        const CLWB = 1 << 24;\n        /// Bit 25: Intel Processor Trace\n        const PROCESSOR_TRACE = 1 << 25;\n        /// Bit 26: AVX512PF. (Intel\u00ae Xeon Phi\u2122 only.)\n        const AVX512PF = 1 << 26;\n        /// Bit 27: AVX512ER. (Intel\u00ae Xeon Phi\u2122 only.)\n        const AVX512ER = 1 << 27;\n        /// Bit 28: AVX512CD.\n        const AVX512CD = 1 << 28;\n        /// Bit 29: Intel SHA Extensions\n        const SHA = 1 << 29;\n        /// Bit 30: AVX512BW.\n        const AVX512BW = 1 << 30;\n        /// Bit 31: AVX512VL.\n        const AVX512VL = 1 << 31;\n    }\n}\n\nbitflags! {\n    #[derive(Default)]\n    #[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\n    struct ExtendedFeaturesEcx: u32 {\n        /// Bit 0: Prefetch WT1. (Intel\u00ae Xeon Phi\u2122 only).\n        const PREFETCHWT1 = 1 << 0;\n\n        // Bit 01: AVX512_VBMI\n        const AVX512VBMI = 1 << 1;\n\n        /// Bit 02: UMIP. Supports user-mode instruction prevention if 1.\n        const UMIP = 1 << 2;\n\n        /// Bit 03: PKU. Supports protection keys for user-mode pages if 1.\n        const PKU = 1 << 3;\n\n        /// Bit 04: OSPKE. If 1, OS has set CR4.PKE to enable protection keys (and the RDPKRU/WRPKRU instruc-tions).\n        const OSPKE = 1 << 4;\n\n        // Bits 16 - 5: Reserved.\n        // Bits 21 - 17: The value of MAWAU used by the BNDLDX and BNDSTX instructions in 64-bit mode.\n\n\n        /// Bit 22: RDPID. RDPID and IA32_TSC_AUX are available if 1.\n        const RDPID = 1 << 22;\n\n        // Bits 29 - 23: Reserved.\n\n        /// Bit 30: SGX_LC. Supports SGX Launch Configuration if 1.\n        const SGX_LC = 1 << 30;\n    }\n}\n\n#[derive(Debug, Default)]\n#[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\npub struct DirectCacheAccessInfo {\n    eax: u32,\n}\n\nimpl DirectCacheAccessInfo {\n    /// Value of bits \\[31:0\\] of IA32_PLATFORM_DCA_CAP MSR (address 1F8H)\n    pub fn get_dca_cap_value(&self) -> u32 {\n        self.eax\n    }\n}\n\n#[derive(Debug, Default)]\n#[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\npub struct PerformanceMonitoringInfo {\n    eax: u32,\n    ebx: PerformanceMonitoringFeaturesEbx,\n    ecx: u32,\n    edx: u32,\n}\n\nimpl PerformanceMonitoringInfo {\n    /// Version ID of architectural performance monitoring. (Bits 07 - 00)\n    pub fn version_id(&self) -> u8 {\n        get_bits(self.eax, 0, 7) as u8\n    }\n\n    /// Number of general-purpose performance monitoring counter per logical processor. (Bits 15- 08)\n    pub fn number_of_counters(&self) -> u8 {\n        get_bits(self.eax, 8, 15) as u8\n    }\n\n    /// Bit width of general-purpose, performance monitoring counter. (Bits 23 - 16)\n    pub fn counter_bit_width(&self) -> u8 {\n        get_bits(self.eax, 16, 23) as u8\n    }\n\n    /// Length of EBX bit vector to enumerate architectural performance monitoring events. (Bits 31 - 24)\n    pub fn ebx_length(&self) -> u8 {\n        get_bits(self.eax, 24, 31) as u8\n    }\n\n    /// Number of fixed-function performance counters (if Version ID > 1). (Bits 04 - 00)\n    pub fn fixed_function_counters(&self) -> u8 {\n        get_bits(self.edx, 0, 4) as u8\n    }\n\n    /// Bit width of fixed-function performance counters (if Version ID > 1). (Bits 12- 05)\n    pub fn fixed_function_counters_bit_width(&self) -> u8 {\n        get_bits(self.edx, 5, 12) as u8\n    }\n\n    check_bit_fn!(\n        doc = \"AnyThread deprecation\",\n        has_any_thread_deprecation,\n        edx,\n        15\n    );\n\n    check_flag!(\n        doc = \"Core cycle event not available if 1.\",\n        is_core_cyc_ev_unavailable,\n        ebx,\n        PerformanceMonitoringFeaturesEbx::CORE_CYC_EV_UNAVAILABLE\n    );\n\n    check_flag!(\n        doc = \"Instruction retired event not available if 1.\",\n        is_inst_ret_ev_unavailable,\n        ebx,\n        PerformanceMonitoringFeaturesEbx::INST_RET_EV_UNAVAILABLE\n    );\n\n    check_flag!(\n        doc = \"Reference cycles event not available if 1.\",\n        is_ref_cycle_ev_unavailable,\n        ebx,\n        PerformanceMonitoringFeaturesEbx::REF_CYC_EV_UNAVAILABLE\n    );\n\n    check_flag!(\n        doc = \"Last-level cache reference event not available if 1.\",\n        is_cache_ref_ev_unavailable,\n        ebx,\n        PerformanceMonitoringFeaturesEbx::CACHE_REF_EV_UNAVAILABLE\n    );\n\n    check_flag!(\n        doc = \"Last-level cache misses event not available if 1.\",\n        is_ll_cache_miss_ev_unavailable,\n        ebx,\n        PerformanceMonitoringFeaturesEbx::LL_CACHE_MISS_EV_UNAVAILABLE\n    );\n\n    check_flag!(\n        doc = \"Branch instruction retired event not available if 1.\",\n        is_branch_inst_ret_ev_unavailable,\n        ebx,\n        PerformanceMonitoringFeaturesEbx::BRANCH_INST_RET_EV_UNAVAILABLE\n    );\n\n    check_flag!(\n        doc = \"Branch mispredict retired event not available if 1.\",\n        is_branch_midpred_ev_unavailable,\n        ebx,\n        PerformanceMonitoringFeaturesEbx::BRANCH_MISPRED_EV_UNAVAILABLE\n    );\n}\n\nbitflags! {\n    #[derive(Default)]\n    #[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\n    struct PerformanceMonitoringFeaturesEbx: u32 {\n        /// Core cycle event not available if 1. (Bit 0)\n        const CORE_CYC_EV_UNAVAILABLE = 1 << 0;\n        /// Instruction retired event not available if 1. (Bit 01)\n        const INST_RET_EV_UNAVAILABLE = 1 << 1;\n        /// Reference cycles event not available if 1. (Bit 02)\n        const REF_CYC_EV_UNAVAILABLE = 1 << 2;\n        /// Last-level cache reference event not available if 1. (Bit 03)\n        const CACHE_REF_EV_UNAVAILABLE = 1 << 3;\n        /// Last-level cache misses event not available if 1. (Bit 04)\n        const LL_CACHE_MISS_EV_UNAVAILABLE = 1 << 4;\n        /// Branch instruction retired event not available if 1. (Bit 05)\n        const BRANCH_INST_RET_EV_UNAVAILABLE = 1 << 5;\n        /// Branch mispredict retired event not available if 1. (Bit 06)\n        const BRANCH_MISPRED_EV_UNAVAILABLE = 1 << 6;\n    }\n}\n\n/// Iterates over the system topology in order to retrieve more\n/// system information at each level of the topology.\n#[derive(Debug, Default)]\n#[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\npub struct ExtendedTopologyIter {\n    #[cfg_attr(feature = \"serialize\", serde(skip))]\n    read: CpuIdReader,\n    level: u32,\n}\n\n/// Gives detailed information about the current level in the topology\n/// (how many cores, what type etc.).\n#[derive(Default)]\n#[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\npub struct ExtendedTopologyLevel {\n    eax: u32,\n    ebx: u32,\n    ecx: u32,\n    edx: u32,\n}\n\nimpl fmt::Debug for ExtendedTopologyLevel {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        f.debug_struct(\"ExtendedTopologyLevel\")\n            .field(\"processors\", &self.processors())\n            .field(\"number\", &self.level_number())\n            .field(\"type\", &self.level_type())\n            .field(\"x2apic_id\", &self.x2apic_id())\n            .field(\"next_apic_id\", &self.shift_right_for_next_apic_id())\n            .finish()\n    }\n}\n\nimpl ExtendedTopologyLevel {\n    /// Number of logical processors at this level type.\n    /// The number reflects configuration as shipped.\n    pub fn processors(&self) -> u16 {\n        get_bits(self.ebx, 0, 15) as u16\n    }\n\n    /// Level number.\n    pub fn level_number(&self) -> u8 {\n        get_bits(self.ecx, 0, 7) as u8\n    }\n\n    // Level type.\n    pub fn level_type(&self) -> TopologyType {\n        match get_bits(self.ecx, 8, 15) {\n            0 => TopologyType::Invalid,\n            1 => TopologyType::SMT,\n            2 => TopologyType::Core,\n            _ => unreachable!(),\n        }\n    }\n\n    /// x2APIC ID the current logical processor. (Bits 31-00)\n    pub fn x2apic_id(&self) -> u32 {\n        self.edx\n    }\n\n    /// Number of bits to shift right on x2APIC ID to get a unique topology ID of the next level type. (Bits 04-00)\n    /// All logical processors with the same next level ID share current level.\n    pub fn shift_right_for_next_apic_id(&self) -> u32 {\n        get_bits(self.eax, 0, 4)\n    }\n}\n\n/// What type of core we have at this level in the topology (real CPU or hyper-threaded).\n#[derive(PartialEq, Eq, Debug)]\n#[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\npub enum TopologyType {\n    Invalid = 0,\n    /// Hyper-thread (Simultaneous multithreading)\n    SMT = 1,\n    Core = 2,\n}\n\nimpl Default for TopologyType {\n    fn default() -> TopologyType {\n        TopologyType::Invalid\n    }\n}\n\nimpl Iterator for ExtendedTopologyIter {\n    type Item = ExtendedTopologyLevel;\n\n    fn next(&mut self) -> Option<ExtendedTopologyLevel> {\n        let res = self.read.cpuid2(EAX_EXTENDED_TOPOLOGY_INFO, self.level);\n        self.level += 1;\n\n        let et = ExtendedTopologyLevel {\n            eax: res.eax,\n            ebx: res.ebx,\n            ecx: res.ecx,\n            edx: res.edx,\n        };\n\n        match et.level_type() {\n            TopologyType::Invalid => None,\n            _ => Some(et),\n        }\n    }\n}\n\nbitflags! {\n    #[derive(Default)]\n    #[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\n    struct ExtendedStateInfoXCR0Flags: u32 {\n        /// legacy x87 (Bit 00).\n        const LEGACY_X87 = 1 << 0;\n\n        /// 128-bit SSE (Bit 01).\n        const SSE128 = 1 << 1;\n\n        /// 256-bit AVX (Bit 02).\n        const AVX256 = 1 << 2;\n\n        /// MPX BNDREGS (Bit 03).\n        const MPX_BNDREGS = 1 << 3;\n\n        /// MPX BNDCSR (Bit 04).\n        const MPX_BNDCSR = 1 << 4;\n\n        /// AVX512 OPMASK (Bit 05).\n        const AVX512_OPMASK = 1 << 5;\n\n        /// AVX ZMM Hi256 (Bit 06).\n        const AVX512_ZMM_HI256 = 1 << 6;\n\n        /// AVX 512 ZMM Hi16 (Bit 07).\n        const AVX512_ZMM_HI16 = 1 << 7;\n\n        /// PKRU state (Bit 09).\n        const PKRU = 1 << 9;\n\n        /// IA32_XSS HDC State (Bit 13).\n        const IA32_XSS_HDC = 1 << 13;\n    }\n}\n\nbitflags! {\n    #[derive(Default)]\n    #[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\n    struct ExtendedStateInfoXSSFlags: u32 {\n        /// IA32_XSS PT (Trace Packet) State (Bit 08).\n        const PT = 1 << 8;\n\n        /// IA32_XSS HDC State (Bit 13).\n        const HDC = 1 << 13;\n    }\n}\n\n#[derive(Debug, Default)]\n#[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\npub struct ExtendedStateInfo {\n    #[cfg_attr(feature = \"serialize\", serde(skip))]\n    read: CpuIdReader,\n    eax: ExtendedStateInfoXCR0Flags,\n    ebx: u32,\n    ecx: u32,\n    edx: u32,\n    eax1: u32,\n    ebx1: u32,\n    ecx1: ExtendedStateInfoXSSFlags,\n    edx1: u32,\n}\n\nimpl ExtendedStateInfo {\n    check_flag!(\n        doc = \"Support for legacy x87 in XCR0.\",\n        xcr0_supports_legacy_x87,\n        eax,\n        ExtendedStateInfoXCR0Flags::LEGACY_X87\n    );\n\n    check_flag!(\n        doc = \"Support for SSE 128-bit in XCR0.\",\n        xcr0_supports_sse_128,\n        eax,\n        ExtendedStateInfoXCR0Flags::SSE128\n    );\n\n    check_flag!(\n        doc = \"Support for AVX 256-bit in XCR0.\",\n        xcr0_supports_avx_256,\n        eax,\n        ExtendedStateInfoXCR0Flags::AVX256\n    );\n\n    check_flag!(\n        doc = \"Support for MPX BNDREGS in XCR0.\",\n        xcr0_supports_mpx_bndregs,\n        eax,\n        ExtendedStateInfoXCR0Flags::MPX_BNDREGS\n    );\n\n    check_flag!(\n        doc = \"Support for MPX BNDCSR in XCR0.\",\n        xcr0_supports_mpx_bndcsr,\n        eax,\n        ExtendedStateInfoXCR0Flags::MPX_BNDCSR\n    );\n\n    check_flag!(\n        doc = \"Support for AVX512 OPMASK in XCR0.\",\n        xcr0_supports_avx512_opmask,\n        eax,\n        ExtendedStateInfoXCR0Flags::AVX512_OPMASK\n    );\n\n    check_flag!(\n        doc = \"Support for AVX512 ZMM Hi256 XCR0.\",\n        xcr0_supports_avx512_zmm_hi256,\n        eax,\n        ExtendedStateInfoXCR0Flags::AVX512_ZMM_HI256\n    );\n\n    check_flag!(\n        doc = \"Support for AVX512 ZMM Hi16 in XCR0.\",\n        xcr0_supports_avx512_zmm_hi16,\n        eax,\n        ExtendedStateInfoXCR0Flags::AVX512_ZMM_HI16\n    );\n\n    check_flag!(\n        doc = \"Support for PKRU in XCR0.\",\n        xcr0_supports_pkru,\n        eax,\n        ExtendedStateInfoXCR0Flags::PKRU\n    );\n\n    check_flag!(\n        doc = \"Support for PT in IA32_XSS.\",\n        ia32_xss_supports_pt,\n        ecx1,\n        ExtendedStateInfoXSSFlags::PT\n    );\n\n    check_flag!(\n        doc = \"Support for HDC in IA32_XSS.\",\n        ia32_xss_supports_hdc,\n        ecx1,\n        ExtendedStateInfoXSSFlags::HDC\n    );\n\n    /// Maximum size (bytes, from the beginning of the XSAVE/XRSTOR save area) required by\n    /// enabled features in XCR0. May be different than ECX if some features at the end of the XSAVE save area\n    /// are not enabled.\n    pub fn xsave_area_size_enabled_features(&self) -> u32 {\n        self.ebx\n    }\n\n    /// Maximum size (bytes, from the beginning of the XSAVE/XRSTOR save area) of the\n    /// XSAVE/XRSTOR save area required by all supported features in the processor,\n    /// i.e all the valid bit fields in XCR0.\n    pub fn xsave_area_size_supported_features(&self) -> u32 {\n        self.ecx\n    }\n\n    /// CPU has xsaveopt feature.\n    pub fn has_xsaveopt(&self) -> bool {\n        self.eax1 & 0x1 > 0\n    }\n\n    /// Supports XSAVEC and the compacted form of XRSTOR if set.\n    pub fn has_xsavec(&self) -> bool {\n        self.eax1 & 0b10 > 0\n    }\n\n    /// Supports XGETBV with ECX = 1 if set.\n    pub fn has_xgetbv(&self) -> bool {\n        self.eax1 & 0b100 > 0\n    }\n\n    /// Supports XSAVES/XRSTORS and IA32_XSS if set.\n    pub fn has_xsaves_xrstors(&self) -> bool {\n        self.eax1 & 0b1000 > 0\n    }\n\n    /// The size in bytes of the XSAVE area containing all states enabled by XCRO | IA32_XSS.\n    pub fn xsave_size(&self) -> u32 {\n        self.ebx1\n    }\n\n    /// Iterator over extended state enumeration levels >= 2.\n    pub fn iter(&self) -> ExtendedStateIter {\n        ExtendedStateIter {\n            read: self.read,\n            level: 1,\n            supported_xcr0: self.eax.bits(),\n            supported_xss: self.ecx1.bits(),\n        }\n    }\n}\n\n#[derive(Debug, Default)]\n#[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\npub struct ExtendedStateIter {\n    #[cfg_attr(feature = \"serialize\", serde(skip))]\n    read: CpuIdReader,\n    level: u32,\n    supported_xcr0: u32,\n    supported_xss: u32,\n}\n\n/// When CPUID executes with EAX set to 0DH and ECX = n (n > 1,\n/// and is a valid sub-leaf index), the processor returns information\n/// about the size and offset of each processor extended state save area\n/// within the XSAVE/XRSTOR area. Software can use the forward-extendable\n/// technique depicted below to query the valid sub-leaves and obtain size\n/// and offset information for each processor extended state save area:///\n///\n/// For i = 2 to 62 // sub-leaf 1 is reserved\n///   IF (CPUID.(EAX=0DH, ECX=0):VECTOR\\[i\\] = 1 ) // VECTOR is the 64-bit value of EDX:EAX\n///     Execute CPUID.(EAX=0DH, ECX = i) to examine size and offset for sub-leaf i;\n/// FI;\nimpl Iterator for ExtendedStateIter {\n    type Item = ExtendedState;\n\n    fn next(&mut self) -> Option<ExtendedState> {\n        self.level += 1;\n        if self.level > 31 {\n            return None;\n        }\n\n        let bit = 1 << self.level;\n        if (self.supported_xcr0 & bit > 0) || (self.supported_xss & bit > 0) {\n            let res = self.read.cpuid2(EAX_EXTENDED_STATE_INFO, self.level);\n            return Some(ExtendedState {\n                subleaf: self.level,\n                eax: res.eax,\n                ebx: res.ebx,\n                ecx: res.ecx,\n            });\n        }\n\n        self.next()\n    }\n}\n\n#[derive(Debug, Default)]\n#[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\npub struct ExtendedState {\n    pub subleaf: u32,\n    eax: u32,\n    ebx: u32,\n    ecx: u32,\n}\n\nimpl ExtendedState {\n    /// The size in bytes (from the offset specified in EBX) of the save area\n    /// for an extended state feature associated with a valid sub-leaf index, n.\n    /// This field reports 0 if the sub-leaf index, n, is invalid.\n    pub fn size(&self) -> u32 {\n        self.eax\n    }\n\n    /// The offset in bytes of this extended state components save area\n    /// from the beginning of the XSAVE/XRSTOR area.\n    pub fn offset(&self) -> u32 {\n        self.ebx\n    }\n\n    /// True if the bit n (corresponding to the sub-leaf index)\n    /// is supported in the IA32_XSS MSR;\n    pub fn is_in_ia32_xss(&self) -> bool {\n        self.ecx & 0b1 > 0\n    }\n\n    /// True if bit n is supported in XCR0.\n    pub fn is_in_xcr0(&self) -> bool {\n        self.ecx & 0b1 == 0\n    }\n\n    /// Returns true when the compacted format of an XSAVE area is used,\n    /// this extended state component located on the next 64-byte\n    /// boundary following the preceding state component\n    /// (otherwise, it is located immediately following the preceding state component).\n    pub fn is_compacted_format(&self) -> bool {\n        self.ecx & 0b10 > 0\n    }\n}\n\n#[derive(Debug, Default)]\n#[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\npub struct RdtMonitoringInfo {\n    #[cfg_attr(feature = \"serialize\", serde(skip))]\n    read: CpuIdReader,\n    ebx: u32,\n    edx: u32,\n}\n\n/// Intel Resource Director Technology (Intel RDT) Monitoring Enumeration Sub-leaf (EAX = 0FH, ECX = 0 and ECX = 1)\nimpl RdtMonitoringInfo {\n    /// Maximum range (zero-based) of RMID within this physical processor of all types.\n    pub fn rmid_range(&self) -> u32 {\n        self.ebx\n    }\n\n    check_bit_fn!(\n        doc = \"Supports L3 Cache Intel RDT Monitoring.\",\n        has_l3_monitoring,\n        edx,\n        1\n    );\n\n    /// L3 Cache Monitoring.\n    pub fn l3_monitoring(&self) -> Option<L3MonitoringInfo> {\n        if self.has_l3_monitoring() {\n            let res = self.read.cpuid2(EAX_RDT_MONITORING, 1);\n            Some(L3MonitoringInfo {\n                ebx: res.ebx,\n                ecx: res.ecx,\n                edx: res.edx,\n            })\n        } else {\n            None\n        }\n    }\n}\n\n#[derive(Debug, Default)]\n#[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\npub struct L3MonitoringInfo {\n    ebx: u32,\n    ecx: u32,\n    edx: u32,\n}\n\nimpl L3MonitoringInfo {\n    /// Conversion factor from reported IA32_QM_CTR value to occupancy metric (bytes).\n    pub fn conversion_factor(&self) -> u32 {\n        self.ebx\n    }\n\n    /// Maximum range (zero-based) of RMID of L3.\n    pub fn maximum_rmid_range(&self) -> u32 {\n        self.ecx\n    }\n\n    check_bit_fn!(\n        doc = \"Supports occupancy monitoring.\",\n        has_occupancy_monitoring,\n        edx,\n        0\n    );\n\n    check_bit_fn!(\n        doc = \"Supports total bandwidth monitoring.\",\n        has_total_bandwidth_monitoring,\n        edx,\n        1\n    );\n\n    check_bit_fn!(\n        doc = \"Supports local bandwidth monitoring.\",\n        has_local_bandwidth_monitoring,\n        edx,\n        2\n    );\n}\n\n#[derive(Debug, Default)]\n#[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\npub struct RdtAllocationInfo {\n    #[cfg_attr(feature = \"serialize\", serde(skip))]\n    read: CpuIdReader,\n    ebx: u32,\n}\n\nimpl RdtAllocationInfo {\n    check_bit_fn!(doc = \"Supports L3 Cache Allocation.\", has_l3_cat, ebx, 1);\n\n    check_bit_fn!(doc = \"Supports L2 Cache Allocation.\", has_l2_cat, ebx, 2);\n\n    check_bit_fn!(\n        doc = \"Supports Memory Bandwidth Allocation.\",\n        has_memory_bandwidth_allocation,\n        ebx,\n        3\n    );\n\n    /// L3 Cache Allocation Information.\n    pub fn l3_cat(&self) -> Option<L3CatInfo> {\n        if self.has_l3_cat() {\n            let res = self.read.cpuid2(EAX_RDT_ALLOCATION, 1);\n            Some(L3CatInfo {\n                eax: res.eax,\n                ebx: res.ebx,\n                ecx: res.ecx,\n                edx: res.edx,\n            })\n        } else {\n            None\n        }\n    }\n\n    /// L2 Cache Allocation Information.\n    pub fn l2_cat(&self) -> Option<L2CatInfo> {\n        if self.has_l2_cat() {\n            let res = self.read.cpuid2(EAX_RDT_ALLOCATION, 2);\n            Some(L2CatInfo {\n                eax: res.eax,\n                ebx: res.ebx,\n                edx: res.edx,\n            })\n        } else {\n            None\n        }\n    }\n\n    /// Memory Bandwidth Allocation Information.\n    pub fn memory_bandwidth_allocation(&self) -> Option<MemBwAllocationInfo> {\n        if self.has_l2_cat() {\n            let res = self.read.cpuid2(EAX_RDT_ALLOCATION, 3);\n            Some(MemBwAllocationInfo {\n                eax: res.eax,\n                ecx: res.ecx,\n                edx: res.edx,\n            })\n        } else {\n            None\n        }\n    }\n}\n\n/// L3 Cache Allocation Technology Enumeration Sub-leaf (EAX = 10H, ECX = ResID = 1).\n#[derive(Debug, Default)]\n#[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\npub struct L3CatInfo {\n    eax: u32,\n    ebx: u32,\n    ecx: u32,\n    edx: u32,\n}\n\nimpl L3CatInfo {\n    /// Length of the capacity bit mask.\n    pub fn capacity_mask_length(&self) -> u8 {\n        (get_bits(self.eax, 0, 4) + 1) as u8\n    }\n\n    /// Bit-granular map of isolation/contention of allocation units.\n    pub fn isolation_bitmap(&self) -> u32 {\n        self.ebx\n    }\n\n    /// Highest COS number supported for this Leaf.\n    pub fn highest_cos(&self) -> u16 {\n        get_bits(self.edx, 0, 15) as u16\n    }\n\n    check_bit_fn!(\n        doc = \"Is Code and Data Prioritization Technology supported?\",\n        has_code_data_prioritization,\n        ecx,\n        2\n    );\n}\n\n/// L2 Cache Allocation Technology Enumeration Sub-leaf (EAX = 10H, ECX = ResID = 2).\n#[derive(Debug, Default)]\n#[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\npub struct L2CatInfo {\n    eax: u32,\n    ebx: u32,\n    edx: u32,\n}\n\nimpl L2CatInfo {\n    /// Length of the capacity bit mask.\n    pub fn capacity_mask_length(&self) -> u8 {\n        (get_bits(self.eax, 0, 4) + 1) as u8\n    }\n\n    /// Bit-granular map of isolation/contention of allocation units.\n    pub fn isolation_bitmap(&self) -> u32 {\n        self.ebx\n    }\n\n    /// Highest COS number supported for this Leaf.\n    pub fn highest_cos(&self) -> u16 {\n        get_bits(self.edx, 0, 15) as u16\n    }\n}\n\n/// Memory Bandwidth Allocation Enumeration Sub-leaf (EAX = 10H, ECX = ResID = 3).\n#[derive(Debug, Default)]\n#[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\npub struct MemBwAllocationInfo {\n    eax: u32,\n    ecx: u32,\n    edx: u32,\n}\n\nimpl MemBwAllocationInfo {\n    /// Reports the maximum MBA throttling value supported for the corresponding ResID.\n    pub fn max_hba_throttling(&self) -> u16 {\n        (get_bits(self.eax, 0, 11) + 1) as u16\n    }\n\n    /// Highest COS number supported for this Leaf.\n    pub fn highest_cos(&self) -> u16 {\n        get_bits(self.edx, 0, 15) as u16\n    }\n\n    check_bit_fn!(\n        doc = \"Reports whether the response of the delay values is linear.\",\n        has_linear_response_delay,\n        ecx,\n        2\n    );\n}\n\n/// Intel SGX Capability Enumeration Leaf, sub-leaf 0 (EAX = 12H, ECX = 0 and ECX = 1)\n#[derive(Debug, Default)]\n#[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\npub struct SgxInfo {\n    #[cfg_attr(feature = \"serialize\", serde(skip))]\n    read: CpuIdReader,\n    eax: u32,\n    ebx: u32,\n    ecx: u32,\n    edx: u32,\n    eax1: u32,\n    ebx1: u32,\n    ecx1: u32,\n    edx1: u32,\n}\n\nimpl SgxInfo {\n    check_bit_fn!(doc = \"Has SGX1 support.\", has_sgx1, eax, 0);\n    check_bit_fn!(doc = \"Has SGX2 support.\", has_sgx2, eax, 1);\n\n    check_bit_fn!(\n        doc = \"Supports ENCLV instruction leaves EINCVIRTCHILD, EDECVIRTCHILD, and ESETCONTEXT.\",\n        has_enclv_leaves_einvirtchild_edecvirtchild_esetcontext,\n        eax,\n        5\n    );\n\n    check_bit_fn!(\n        doc = \"Supports ENCLS instruction leaves ETRACKC, ERDINFO, ELDBC, and ELDUC.\",\n        has_encls_leaves_etrackc_erdinfo_eldbc_elduc,\n        eax,\n        6\n    );\n\n    /// Bit vector of supported extended SGX features.\n    pub fn miscselect(&self) -> u32 {\n        self.ebx\n    }\n\n    ///  The maximum supported enclave size in non-64-bit mode is 2^retval.\n    pub fn max_enclave_size_non_64bit(&self) -> u8 {\n        get_bits(self.edx, 0, 7) as u8\n    }\n\n    ///  The maximum supported enclave size in 64-bit mode is 2^retval.\n    pub fn max_enclave_size_64bit(&self) -> u8 {\n        get_bits(self.edx, 8, 15) as u8\n    }\n\n    /// Reports the valid bits of SECS.ATTRIBUTES\\[127:0\\] that software can set with ECREATE.\n    pub fn secs_attributes(&self) -> (u64, u64) {\n        let lower = self.eax1 as u64 | (self.ebx1 as u64) << 32;\n        let upper = self.ecx1 as u64 | (self.edx1 as u64) << 32;\n        (lower, upper)\n    }\n    /// Iterator over SGX sub-leafs.\n    pub fn iter(&self) -> SgxSectionIter {\n        SgxSectionIter {\n            read: self.read,\n            current: 2,\n        }\n    }\n}\n\n/// Iterator over the SGX sub-leafs (ECX >= 2).\n#[derive(Debug, Default)]\n#[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\npub struct SgxSectionIter {\n    #[cfg_attr(feature = \"serialize\", serde(skip))]\n    read: CpuIdReader,\n    current: u32,\n}\n\nimpl Iterator for SgxSectionIter {\n    type Item = SgxSectionInfo;\n\n    fn next(&mut self) -> Option<SgxSectionInfo> {\n        let res = self.read.cpuid2(EAX_SGX, self.current);\n        self.current += 1;\n        match get_bits(res.eax, 0, 3) {\n            0b0001 => Some(SgxSectionInfo::Epc(EpcSection {\n                eax: res.eax,\n                ebx: res.ebx,\n                ecx: res.ecx,\n                edx: res.edx,\n            })),\n            _ => None,\n        }\n    }\n}\n\n/// Intel SGX EPC Enumeration Leaf, sub-leaves (EAX = 12H, ECX = 2 or higher)\n#[derive(Debug)]\n#[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\npub enum SgxSectionInfo {\n    // This would be nice: https://github.com/rust-lang/rfcs/pull/1450\n    Epc(EpcSection),\n}\n\nimpl Default for SgxSectionInfo {\n    fn default() -> SgxSectionInfo {\n        SgxSectionInfo::Epc(Default::default())\n    }\n}\n\n/// EBX:EAX and EDX:ECX provide information on the Enclave Page Cache (EPC) section\n#[derive(Debug, Default)]\n#[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\npub struct EpcSection {\n    eax: u32,\n    ebx: u32,\n    ecx: u32,\n    edx: u32,\n}\n\nimpl EpcSection {\n    /// The physical address of the base of the EPC section\n    pub fn physical_base(&self) -> u64 {\n        let lower = (get_bits(self.eax, 12, 31) << 12) as u64;\n        let upper = (get_bits(self.ebx, 0, 19) as u64) << 32;\n        lower | upper\n    }\n\n    /// Size of the corresponding EPC section within the Processor Reserved Memory.\n    pub fn size(&self) -> u64 {\n        let lower = (get_bits(self.ecx, 12, 31) << 12) as u64;\n        let upper = (get_bits(self.edx, 0, 19) as u64) << 32;\n        lower | upper\n    }\n}\n\n#[derive(Debug, Default)]\n#[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\npub struct ProcessorTraceInfo {\n    eax: u32,\n    ebx: u32,\n    ecx: u32,\n    edx: u32,\n    leaf1: Option<CpuIdResult>,\n}\n\nimpl ProcessorTraceInfo {\n    // EBX features\n    check_bit_fn!(\n        doc = \"If true, Indicates that IA32_RTIT_CTL.CR3Filter can be set to 1, and \\\n               that IA32_RTIT_CR3_MATCH MSR can be accessed.\",\n        has_rtit_cr3_match,\n        ebx,\n        0\n    );\n    check_bit_fn!(\n        doc = \"If true, Indicates support of Configurable PSB and Cycle-Accurate Mode.\",\n        has_configurable_psb_and_cycle_accurate_mode,\n        ebx,\n        1\n    );\n    check_bit_fn!(\n        doc = \"If true, Indicates support of IP Filtering, TraceStop filtering, and \\\n               preservation of Intel PT MSRs across warm reset.\",\n        has_ip_tracestop_filtering,\n        ebx,\n        2\n    );\n    check_bit_fn!(\n        doc = \"If true, Indicates support of MTC timing packet and suppression of \\\n               COFI-based packets.\",\n        has_mtc_timing_packet_coefi_suppression,\n        ebx,\n        3\n    );\n\n    check_bit_fn!(\n        doc = \"Indicates support of PTWRITE. Writes can set IA32_RTIT_CTL\\\\[12\\\\] (PTWEn \\\n               and IA32_RTIT_CTL\\\\[5\\\\] (FUPonPTW), and PTWRITE can generate packets\",\n        has_ptwrite,\n        ebx,\n        4\n    );\n\n    check_bit_fn!(\n        doc = \"Support of Power Event Trace. Writes can set IA32_RTIT_CTL\\\\[4\\\\] (PwrEvtEn) \\\n               enabling Power Event Trace packet generation.\",\n        has_power_event_trace,\n        ebx,\n        5\n    );\n\n    // ECX features\n    check_bit_fn!(\n        doc = \"If true, Tracing can be enabled with IA32_RTIT_CTL.ToPA = 1, hence \\\n               utilizing the ToPA output scheme; IA32_RTIT_OUTPUT_BASE and \\\n               IA32_RTIT_OUTPUT_MASK_PTRS MSRs can be accessed.\",\n        has_topa,\n        ecx,\n        0\n    );\n    check_bit_fn!(\n        doc = \"If true, ToPA tables can hold any number of output entries, up to the \\\n               maximum allowed by the MaskOrTableOffset field of \\\n               IA32_RTIT_OUTPUT_MASK_PTRS.\",\n        has_topa_maximum_entries,\n        ecx,\n        1\n    );\n    check_bit_fn!(\n        doc = \"If true, Indicates support of Single-Range Output scheme.\",\n        has_single_range_output_scheme,\n        ecx,\n        2\n    );\n    check_bit_fn!(\n        doc = \"If true, Indicates support of output to Trace Transport subsystem.\",\n        has_trace_transport_subsystem,\n        ecx,\n        3\n    );\n    check_bit_fn!(\n        doc = \"If true, Generated packets which contain IP payloads have LIP values, \\\n               which include the CS base component.\",\n        has_lip_with_cs_base,\n        ecx,\n        31\n    );\n\n    /// Number of configurable Address Ranges for filtering (Bits 2:0).\n    pub fn configurable_address_ranges(&self) -> u8 {\n        self.leaf1.map_or(0, |res| get_bits(res.eax, 0, 2) as u8)\n    }\n\n    /// Bitmap of supported MTC period encodings (Bit 31:16).\n    pub fn supported_mtc_period_encodings(&self) -> u16 {\n        self.leaf1.map_or(0, |res| get_bits(res.eax, 16, 31) as u16)\n    }\n\n    /// Bitmap of supported Cycle Threshold value encodings (Bits 15-0).\n    pub fn supported_cycle_threshold_value_encodings(&self) -> u16 {\n        self.leaf1.map_or(0, |res| get_bits(res.ebx, 0, 15) as u16)\n    }\n\n    /// Bitmap of supported Configurable PSB frequency encodings (Bit 31:16)\n    pub fn supported_psb_frequency_encodings(&self) -> u16 {\n        self.leaf1.map_or(0, |res| get_bits(res.ebx, 16, 31) as u16)\n    }\n}\n\n/// Time Stamp Counter and Nominal Core Crystal Clock Information Leaf.\n#[derive(Default)]\n#[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\npub struct TscInfo {\n    eax: u32,\n    ebx: u32,\n    ecx: u32,\n}\n\nimpl fmt::Debug for TscInfo {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        f.debug_struct(\"TscInfo\")\n            .field(\"denominator/eax\", &self.denominator())\n            .field(\"numerator/ebx\", &self.numerator())\n            .field(\"nominal_frequency/ecx\", &self.nominal_frequency())\n            .finish()\n    }\n}\n\nimpl TscInfo {\n    /// An unsigned integer which is the denominator of the TSC/\u201dcore crystal clock\u201d ratio.\n    pub fn denominator(&self) -> u32 {\n        self.eax\n    }\n\n    /// An unsigned integer which is the numerator of the TSC/\u201dcore crystal clock\u201d ratio.\n    ///\n    /// If this is 0, the TSC/\u201dcore crystal clock\u201d ratio is not enumerated.\n    pub fn numerator(&self) -> u32 {\n        self.ebx\n    }\n\n    /// An unsigned integer which is the nominal frequency of the core crystal clock in Hz.\n    ///\n    /// If this is 0, the nominal core crystal clock frequency is not enumerated.\n    pub fn nominal_frequency(&self) -> u32 {\n        self.ecx\n    }\n\n    /// \u201cTSC frequency\u201d = \u201ccore crystal clock frequency\u201d * EBX/EAX.\n    pub fn tsc_frequency(&self) -> Option<u64> {\n        // In some case TscInfo is a valid leaf, but the values reported are still 0\n        // we should avoid a division by zero in case denominator ends up being 0.\n        if self.nominal_frequency() == 0 || self.numerator() == 0 || self.denominator() == 0 {\n            return None;\n        }\n\n        Some(self.nominal_frequency() as u64 * self.numerator() as u64 / self.denominator() as u64)\n    }\n}\n\n/// Processor Frequency Information\n#[derive(Debug, Default)]\n#[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\npub struct ProcessorFrequencyInfo {\n    eax: u32,\n    ebx: u32,\n    ecx: u32,\n}\n\nimpl ProcessorFrequencyInfo {\n    /// Processor Base Frequency (in MHz).\n    pub fn processor_base_frequency(&self) -> u16 {\n        get_bits(self.eax, 0, 15) as u16\n    }\n\n    /// Maximum Frequency (in MHz).\n    pub fn processor_max_frequency(&self) -> u16 {\n        get_bits(self.ebx, 0, 15) as u16\n    }\n\n    /// Bus (Reference) Frequency (in MHz).\n    pub fn bus_frequency(&self) -> u16 {\n        get_bits(self.ecx, 0, 15) as u16\n    }\n}\n\n/// Deterministic Address Translation Structure Iterator\n#[derive(Debug, Default)]\n#[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\npub struct DatIter {\n    #[cfg_attr(feature = \"serialize\", serde(skip))]\n    read: CpuIdReader,\n    current: u32,\n    count: u32,\n}\n\nimpl Iterator for DatIter {\n    type Item = DatInfo;\n\n    /// Iterate over each sub-leaf with an  address translation structure.\n    fn next(&mut self) -> Option<DatInfo> {\n        loop {\n            // Sub-leaf index n is invalid if n exceeds the value that sub-leaf 0 returns in EAX\n            if self.current > self.count {\n                return None;\n            }\n\n            let res = self\n                .read\n                .cpuid2(EAX_DETERMINISTIC_ADDRESS_TRANSLATION_INFO, self.current);\n            self.current += 1;\n\n            // A sub-leaf index is also invalid if EDX[4:0] returns 0.\n            if get_bits(res.edx, 0, 4) == 0 {\n                // Valid sub-leaves do not need to be contiguous or in any particular order.\n                // A valid sub-leaf may be in a higher input ECX value than an invalid sub-leaf\n                // or than a valid sub-leaf of a higher or lower-level struc-ture\n                continue;\n            }\n\n            return Some(DatInfo {\n                eax: res.eax,\n                ebx: res.ebx,\n                ecx: res.ecx,\n                edx: res.edx,\n            });\n        }\n    }\n}\n\n/// Deterministic Address Translation Structure\n#[derive(Debug, Default)]\n#[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\npub struct DatInfo {\n    eax: u32,\n    ebx: u32,\n    ecx: u32,\n    edx: u32,\n}\n\nimpl DatInfo {\n    check_bit_fn!(\n        doc = \"4K page size entries supported by this structure\",\n        has_4k_entries,\n        ebx,\n        0\n    );\n\n    check_bit_fn!(\n        doc = \"2MB page size entries supported by this structure\",\n        has_2mb_entries,\n        ebx,\n        1\n    );\n\n    check_bit_fn!(\n        doc = \"4MB page size entries supported by this structure\",\n        has_4mb_entries,\n        ebx,\n        2\n    );\n\n    check_bit_fn!(\n        doc = \"1GB page size entries supported by this structure\",\n        has_1gb_entries,\n        ebx,\n        3\n    );\n\n    check_bit_fn!(\n        doc = \"Fully associative structure\",\n        is_fully_associative,\n        edx,\n        8\n    );\n\n    /// Partitioning (0: Soft partitioning between the logical processors sharing this structure).\n    pub fn partitioning(&self) -> u8 {\n        get_bits(self.ebx, 8, 10) as u8\n    }\n\n    /// Ways of associativity.\n    pub fn ways(&self) -> u16 {\n        get_bits(self.ebx, 16, 31) as u16\n    }\n\n    /// Number of Sets.\n    pub fn sets(&self) -> u32 {\n        self.ecx\n    }\n\n    /// Translation cache type field.\n    pub fn cache_type(&self) -> DatType {\n        match get_bits(self.edx, 0, 4) as u8 {\n            0b00001 => DatType::DataTLB,\n            0b00010 => DatType::InstructionTLB,\n            0b00011 => DatType::UnifiedTLB,\n            0b00000 => DatType::Null, // should never be returned as this indicates invalid struct!\n            _ => DatType::Unknown,\n        }\n    }\n\n    /// Translation cache level (starts at 1)\n    pub fn cache_level(&self) -> u8 {\n        get_bits(self.edx, 5, 7) as u8\n    }\n\n    /// Maximum number of addressable IDs for logical processors sharing this translation cache\n    pub fn max_addressable_ids(&self) -> u16 {\n        // Add one to the return value to get the result:\n        (get_bits(self.edx, 14, 25) + 1) as u16\n    }\n}\n\n/// Deterministic Address Translation cache type (EDX bits 04 -- 00)\n#[derive(Debug)]\n#[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\npub enum DatType {\n    /// Null (indicates this sub-leaf is not valid).\n    Null = 0b00000,\n    DataTLB = 0b00001,\n    InstructionTLB = 0b00010,\n    /// Some unified TLBs will allow a single TLB entry to satisfy data read/write\n    /// and instruction fetches. Others will require separate entries (e.g., one\n    /// loaded on data read/write and another loaded on an instruction fetch) .\n    /// Please see the Intel\u00ae 64 and IA-32 Architectures Optimization Reference Manual\n    /// for details of a particular product.\n    UnifiedTLB = 0b00011,\n    Unknown,\n}\n\nimpl Default for DatType {\n    fn default() -> DatType {\n        DatType::Null\n    }\n}\n\n#[derive(Debug, Default)]\n#[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\npub struct SoCVendorInfo {\n    #[cfg_attr(feature = \"serialize\", serde(skip))]\n    read: CpuIdReader,\n    /// MaxSOCID_Index\n    eax: u32,\n    ebx: u32,\n    ecx: u32,\n    edx: u32,\n}\n\nimpl SoCVendorInfo {\n    pub fn get_soc_vendor_id(&self) -> u16 {\n        get_bits(self.ebx, 0, 15) as u16\n    }\n\n    pub fn get_project_id(&self) -> u32 {\n        self.ecx\n    }\n\n    pub fn get_stepping_id(&self) -> u32 {\n        self.edx\n    }\n\n    pub fn get_vendor_brand(&self) -> SoCVendorBrand {\n        assert!(self.eax >= 3); // Leaf 17H is valid if MaxSOCID_Index >= 3.\n        let r1 = self.read.cpuid2(EAX_SOC_VENDOR_INFO, 1);\n        let r2 = self.read.cpuid2(EAX_SOC_VENDOR_INFO, 2);\n        let r3 = self.read.cpuid2(EAX_SOC_VENDOR_INFO, 3);\n        SoCVendorBrand { data: [r1, r2, r3] }\n    }\n\n    pub fn get_vendor_attributes(&self) -> Option<SoCVendorAttributesIter> {\n        if self.eax > 3 {\n            Some(SoCVendorAttributesIter {\n                read: self.read,\n                count: self.eax,\n                current: 3,\n            })\n        } else {\n            None\n        }\n    }\n}\n\n#[derive(Debug, Default)]\n#[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\npub struct SoCVendorAttributesIter {\n    #[cfg_attr(feature = \"serialize\", serde(skip))]\n    read: CpuIdReader,\n    count: u32,\n    current: u32,\n}\n\nimpl Iterator for SoCVendorAttributesIter {\n    type Item = CpuIdResult;\n\n    /// Iterate over all SoC vendor specific attributes.\n    fn next(&mut self) -> Option<CpuIdResult> {\n        if self.current > self.count {\n            return None;\n        }\n        self.count += 1;\n        Some(self.read.cpuid2(EAX_SOC_VENDOR_INFO, self.count))\n    }\n}\n\n#[derive(Debug, Default)]\n#[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\n#[repr(C)]\npub struct SoCVendorBrand {\n    data: [CpuIdResult; 3],\n}\n\nimpl SoCVendorBrand {\n    pub fn as_string<'a>(&'a self) -> &'a str {\n        let brand_string_start = self as *const SoCVendorBrand as *const u8;\n        unsafe {\n            // Safety: SoCVendorBrand is laid out with repr(C).\n            let slice: &'a [u8] =\n                slice::from_raw_parts(brand_string_start, size_of::<SoCVendorBrand>());\n            // Safety: The field is specified to be ASCII, and the only safe\n            // way to construct SoCVendorBrand is from real CPUID data or the\n            // Default implementation.\n            str::from_utf8_unchecked(slice)\n        }\n    }\n}\n\nimpl fmt::Display for SoCVendorBrand {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        write!(f, \"{}\", self.as_string())\n    }\n}\n\n/// Information about Hypervisor\n///\n/// More information about this semi-official leaf can be found here\n/// <https://lwn.net/Articles/301888/>\n#[derive(Default)]\n#[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\npub struct HypervisorInfo {\n    #[cfg_attr(feature = \"serialize\", serde(skip))]\n    read: CpuIdReader,\n    res: CpuIdResult,\n}\n\nimpl fmt::Debug for HypervisorInfo {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        f.debug_struct(\"HypervisorInfo\")\n            .field(\"type\", &self.identify())\n            .field(\"tsc_frequency\", &self.tsc_frequency())\n            .field(\"apic_frequency\", &self.apic_frequency())\n            .finish()\n    }\n}\n\n/// Identifies the different Hypervisor products.\n#[derive(Debug, Eq, PartialEq)]\npub enum Hypervisor {\n    Xen,\n    VMware,\n    HyperV,\n    KVM,\n    Unknown(u32, u32, u32),\n}\n\nimpl HypervisorInfo {\n    pub fn identify(&self) -> Hypervisor {\n        match (self.res.ebx, self.res.ecx, self.res.edx) {\n            // \"VMwareVMware\"\n            (0x61774d56, 0x4d566572, 0x65726177) => Hypervisor::VMware,\n            // \"XenVMMXenVMM\"\n            (0x566e6558, 0x65584d4d, 0x4d4d566e) => Hypervisor::Xen,\n            // \"Microsoft Hv\"\n            (0x7263694d, 0x666f736f, 0x76482074) => Hypervisor::HyperV,\n            // \"KVMKVMKVM\\0\\0\\0\"\n            (0x4b4d564b, 0x564b4d56, 0x0000004d) => Hypervisor::KVM,\n            (ebx, ecx, edx) => Hypervisor::Unknown(ebx, ecx, edx),\n        }\n    }\n\n    /// TSC frequency in kHz.\n    pub fn tsc_frequency(&self) -> Option<u32> {\n        // vm aware tsc frequency retrieval:\n        // # EAX: (Virtual) TSC frequency in kHz.\n        if self.res.eax >= 0x40000010 {\n            let virt_tinfo = self.read.cpuid2(0x40000010, 0);\n            Some(virt_tinfo.eax)\n        } else {\n            None\n        }\n    }\n\n    /// (Virtual) Bus (local apic timer) frequency in kHz.\n    pub fn apic_frequency(&self) -> Option<u32> {\n        // # EBX: (Virtual) Bus (local apic timer) frequency in kHz.\n        if self.res.eax >= 0x40000010 {\n            let virt_tinfo = self.read.cpuid2(0x40000010, 0);\n            Some(virt_tinfo.ebx)\n        } else {\n            None\n        }\n    }\n}\n\n#[derive(Debug, Default)]\n#[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\npub struct ExtendedFunctionInfo {\n    max_eax_value: u32,\n    data: [CpuIdResult; 9],\n}\n\n#[derive(PartialEq, Eq, Debug)]\n#[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\npub enum L2Associativity {\n    Disabled = 0x0,\n    DirectMapped = 0x1,\n    TwoWay = 0x2,\n    FourWay = 0x4,\n    EightWay = 0x6,\n    SixteenWay = 0x8,\n    FullyAssiciative = 0xF,\n    Unknown,\n}\n\nimpl Default for L2Associativity {\n    fn default() -> L2Associativity {\n        L2Associativity::Unknown\n    }\n}\n\nconst EAX_EXTENDED_PROC_SIGNATURE: u32 = 0x1;\nconst EAX_EXTENDED_BRAND_STRING: u32 = 0x4;\nconst EAX_EXTENDED_CACHE_INFO: u32 = 0x6;\n\nimpl ExtendedFunctionInfo {\n    fn leaf_is_supported(&self, val: u32) -> bool {\n        val <= self.max_eax_value\n    }\n\n    /// Retrieve processor brand string.\n    pub fn processor_brand_string<'a>(&'a self) -> Option<&'a str> {\n        if self.leaf_is_supported(EAX_EXTENDED_BRAND_STRING) {\n            let brand_string_start = &self.data[2] as *const CpuIdResult as *const u8;\n            // Safety: CpuIdResult is laid out with repr(C), and the array\n            // self.data contains 9 continguous elements.\n            let slice: &'a [u8] =\n                unsafe { slice::from_raw_parts(brand_string_start, 3 * size_of::<CpuIdResult>()) };\n\n            // Brand terminated at nul byte or end, whichever comes first.\n            let slice = slice.split(|&x| x == 0).next().unwrap();\n\n            // Safety: Field is specified to be ASCII, and the only safe way\n            // to construct ExtendedFunctionInfo is from real CPUID data\n            // or the Default implementation.\n            Some(unsafe { str::from_utf8_unchecked(slice) })\n        } else {\n            None\n        }\n    }\n\n    /// Extended Processor Signature and Feature Bits.\n    pub fn extended_signature(&self) -> Option<u32> {\n        if self.leaf_is_supported(EAX_EXTENDED_PROC_SIGNATURE) {\n            Some(self.data[1].eax)\n        } else {\n            None\n        }\n    }\n\n    /// Cache Line size in bytes\n    pub fn cache_line_size(&self) -> Option<u8> {\n        if self.leaf_is_supported(EAX_EXTENDED_CACHE_INFO) {\n            Some(get_bits(self.data[6].ecx, 0, 7) as u8)\n        } else {\n            None\n        }\n    }\n\n    /// L2 Associativity field\n    pub fn l2_associativity(&self) -> Option<L2Associativity> {\n        if self.leaf_is_supported(EAX_EXTENDED_CACHE_INFO) {\n            Some(match get_bits(self.data[6].ecx, 12, 15) {\n                0x0 => L2Associativity::Disabled,\n                0x1 => L2Associativity::DirectMapped,\n                0x2 => L2Associativity::TwoWay,\n                0x4 => L2Associativity::FourWay,\n                0x6 => L2Associativity::EightWay,\n                0x8 => L2Associativity::SixteenWay,\n                0xF => L2Associativity::FullyAssiciative,\n                _ => L2Associativity::Unknown,\n            })\n        } else {\n            None\n        }\n    }\n\n    /// Cache size in 1K units\n    pub fn cache_size(&self) -> Option<u16> {\n        if self.leaf_is_supported(EAX_EXTENDED_CACHE_INFO) {\n            Some(get_bits(self.data[6].ecx, 16, 31) as u16)\n        } else {\n            None\n        }\n    }\n\n    /// #Physical Address Bits\n    pub fn physical_address_bits(&self) -> Option<u8> {\n        if self.leaf_is_supported(8) {\n            Some(get_bits(self.data[8].eax, 0, 7) as u8)\n        } else {\n            None\n        }\n    }\n\n    /// #Linear Address Bits\n    pub fn linear_address_bits(&self) -> Option<u8> {\n        if self.leaf_is_supported(8) {\n            Some(get_bits(self.data[8].eax, 8, 15) as u8)\n        } else {\n            None\n        }\n    }\n\n    /// Is Invariant TSC available?\n    pub fn has_invariant_tsc(&self) -> bool {\n        self.leaf_is_supported(7) && self.data[7].edx & (1 << 8) > 0\n    }\n\n    /// Is LAHF/SAHF available in 64-bit mode?\n    pub fn has_lahf_sahf(&self) -> bool {\n        self.leaf_is_supported(1)\n            && ExtendedFunctionInfoEcx {\n                bits: self.data[1].ecx,\n            }\n            .contains(ExtendedFunctionInfoEcx::LAHF_SAHF)\n    }\n\n    /// Is LZCNT available?\n    pub fn has_lzcnt(&self) -> bool {\n        self.leaf_is_supported(1)\n            && ExtendedFunctionInfoEcx {\n                bits: self.data[1].ecx,\n            }\n            .contains(ExtendedFunctionInfoEcx::LZCNT)\n    }\n\n    /// Is PREFETCHW available?\n    pub fn has_prefetchw(&self) -> bool {\n        self.leaf_is_supported(1)\n            && ExtendedFunctionInfoEcx {\n                bits: self.data[1].ecx,\n            }\n            .contains(ExtendedFunctionInfoEcx::PREFETCHW)\n    }\n\n    /// Are fast system calls available.\n    pub fn has_syscall_sysret(&self) -> bool {\n        self.leaf_is_supported(1)\n            && ExtendedFunctionInfoEdx {\n                bits: self.data[1].edx,\n            }\n            .contains(ExtendedFunctionInfoEdx::SYSCALL_SYSRET)\n    }\n\n    /// Is there support for execute disable bit.\n    pub fn has_execute_disable(&self) -> bool {\n        self.leaf_is_supported(1)\n            && ExtendedFunctionInfoEdx {\n                bits: self.data[1].edx,\n            }\n            .contains(ExtendedFunctionInfoEdx::EXECUTE_DISABLE)\n    }\n\n    /// Is there support for 1GiB pages.\n    pub fn has_1gib_pages(&self) -> bool {\n        self.leaf_is_supported(1)\n            && ExtendedFunctionInfoEdx {\n                bits: self.data[1].edx,\n            }\n            .contains(ExtendedFunctionInfoEdx::GIB_PAGES)\n    }\n\n    /// Check support for rdtscp instruction.\n    pub fn has_rdtscp(&self) -> bool {\n        self.leaf_is_supported(1)\n            && ExtendedFunctionInfoEdx {\n                bits: self.data[1].edx,\n            }\n            .contains(ExtendedFunctionInfoEdx::RDTSCP)\n    }\n\n    /// Check support for 64-bit mode.\n    pub fn has_64bit_mode(&self) -> bool {\n        self.leaf_is_supported(1)\n            && ExtendedFunctionInfoEdx {\n                bits: self.data[1].edx,\n            }\n            .contains(ExtendedFunctionInfoEdx::I64BIT_MODE)\n    }\n}\n\nbitflags! {\n    #[derive(Default)]\n    #[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\n    struct ExtendedFunctionInfoEcx: u32 {\n        /// LAHF/SAHF available in 64-bit mode.\n        const LAHF_SAHF = 1 << 0;\n        /// Bit 05: LZCNT\n        const LZCNT = 1 << 5;\n        /// Bit 08: PREFETCHW\n        const PREFETCHW = 1 << 8;\n    }\n}\n\nbitflags! {\n    #[derive(Default)]\n    #[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\n    struct ExtendedFunctionInfoEdx: u32 {\n        /// SYSCALL/SYSRET available in 64-bit mode (Bit 11).\n        const SYSCALL_SYSRET = 1 << 11;\n        /// Execute Disable Bit available (Bit 20).\n        const EXECUTE_DISABLE = 1 << 20;\n        /// 1-GByte pages are available if 1 (Bit 26).\n        const GIB_PAGES = 1 << 26;\n        /// RDTSCP and IA32_TSC_AUX are available if 1 (Bit 27).\n        const RDTSCP = 1 << 27;\n        /// Intel \u00ae 64 Architecture available if 1 (Bit 29).\n        const I64BIT_MODE = 1 << 29;\n    }\n}\n\n#[derive(Debug, Default)]\n#[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\npub struct MemoryEncryptionInfo {\n    eax: MemoryEncryptionInfoEax,\n    ebx: u32,\n    ecx: u32,\n    edx: u32,\n}\n\nimpl MemoryEncryptionInfo {\n    check_flag!(\n        doc = \"Secure Memory Encryption is supported if set.\",\n        has_sme,\n        eax,\n        MemoryEncryptionInfoEax::SME\n    );\n\n    check_flag!(\n        doc = \"Secure Encrypted Virtualization is supported if set.\",\n        has_sev,\n        eax,\n        MemoryEncryptionInfoEax::SEV\n    );\n\n    check_flag!(\n        doc = \"The Page Flush MSR is available if set.\",\n        has_page_flush_msr,\n        eax,\n        MemoryEncryptionInfoEax::PAGE_FLUSH_MSR\n    );\n\n    check_flag!(\n        doc = \"SEV Encrypted State is supported if set.\",\n        has_sev_es,\n        eax,\n        MemoryEncryptionInfoEax::SEV_ES\n    );\n\n    pub fn physical_address_reduction(&self) -> u8 {\n        get_bits(self.ebx, 6, 11) as u8\n    }\n\n    pub fn c_bit_position(&self) -> u8 {\n        get_bits(self.ebx, 0, 5) as u8\n    }\n\n    pub fn max_encrypted_guests(&self) -> u32 {\n        self.ecx\n    }\n\n    pub fn min_sev_no_es_asid(&self) -> u32 {\n        self.edx\n    }\n}\n\nbitflags! {\n    #[derive(Default)]\n    #[cfg_attr(feature = \"serialize\", derive(Serialize, Deserialize))]\n    struct MemoryEncryptionInfoEax: u32 {\n        /// Bit 00: SME supported\n        const SME = 1 << 0;\n        /// Bit 01: SEV supported\n        const SEV = 1 << 1;\n        /// Bit 02: Page Flush MSR available\n        const PAGE_FLUSH_MSR = 1 << 2;\n        /// Bit 03: SEV-ES supported\n        const SEV_ES = 1 << 3;\n    }\n}\n\n#[cfg(doctest)]\nmod test_readme {\n    macro_rules! external_doc_test {\n        ($x:expr) => {\n            #[doc = $x]\n            extern \"C\" {}\n        };\n    }\n\n    external_doc_test!(include_str!(\"../README.md\"));\n}\n"
  },
  {
    "project": "MozWire",
    "target": 1,
    "commit_id": "1e58d8ba41268b36232e6830808565850ec65587",
    "func": "use clap::{AppSettings, Arg, SubCommand};\n// TODO remove unused `use` with clap v3\nuse clap::{crate_authors, crate_description, crate_name, crate_version};\nuse core::num::NonZeroUsize;\nuse rand::seq::IteratorRandom;\nuse std::fmt;\nuse std::net::{Ipv4Addr, Ipv6Addr};\nuse x25519_dalek::{PublicKey, StaticSecret};\n\n#[derive(serde::Deserialize)]\nstruct LoginURLs {\n    login_url: String,\n    verification_url: String,\n    poll_interval: u64,\n}\n\n#[derive(serde::Deserialize)]\nstruct User {\n    devices: Vec<Device>,\n}\n\n#[derive(serde::Deserialize)]\nstruct Login {\n    user: User,\n    token: String,\n}\n\n#[derive(serde::Deserialize)]\nstruct Error {\n    errno: u32,\n    error: String,\n}\n\nimpl Error {\n    fn fail(self) -> ! {\n        match self.errno {\n            122 => {\n                // TODO: see https://github.com/NilsIrl/MozWire/issues/2\n                eprintln!(\"Token expired, regenerate a token by not specifying the --token option\");\n            }\n            _ => {\n                eprintln!(\"{}\", self.error);\n            }\n        }\n        std::process::exit(3);\n    }\n}\n\n#[derive(serde::Serialize)]\nstruct NewDevice<'a> {\n    name: &'a str,\n    pubkey: &'a str,\n}\n\n#[derive(serde::Deserialize)]\nstruct Device {\n    name: String,\n    pubkey: String,\n    ipv4_address: String,\n    ipv6_address: String,\n}\n\nimpl fmt::Display for Device {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        write!(\n            f,\n            \"- {}: {}, {},{}\",\n            self.name, self.pubkey, self.ipv4_address, self.ipv6_address\n        )\n    }\n}\n\nfn private_to_public_key(privkey_base64: &str) -> Result<String, base64::DecodeError> {\n    let mut privkey = [0; 32];\n    base64::decode_config_slice(privkey_base64, base64::STANDARD, &mut privkey)?;\n    Ok(base64::encode(\n        PublicKey::from(&StaticSecret::from(privkey)).as_bytes(),\n    ))\n}\n\nimpl NewDevice<'_> {\n    fn upload(self, client: &reqwest::blocking::Client, token: &str) -> Device {\n        let response = client\n            .post(&format!(\"{}/vpn/device\", BASE_URL))\n            .bearer_auth(token)\n            .json(&self)\n            .send()\n            .unwrap();\n        if response.status().is_success() {\n            return response.json().unwrap();\n        }\n        response.json::<Error>().unwrap().fail();\n    }\n}\n\n// weight, include_in_country, port_ranges omitted\n// port_ranges is the same for each server\n#[derive(serde::Deserialize, Debug)]\nstruct Server {\n    hostname: String,\n    ipv4_addr_in: Ipv4Addr,\n    ipv6_addr_in: Ipv6Addr,\n    ipv4_gateway: Ipv4Addr,\n    ipv6_gateway: Ipv6Addr,\n    public_key: String,\n    port_ranges: Vec<(u16, u16)>,\n}\n\n// latitude and longitude omitted\n#[derive(serde::Deserialize)]\nstruct City {\n    name: String,\n    code: String,\n    servers: Vec<Server>,\n    latitude: f64,\n    longitude: f64,\n}\n\n#[derive(serde::Deserialize)]\nstruct Country {\n    name: String,\n    code: String,\n    cities: Vec<City>,\n}\n\n#[derive(serde::Deserialize)]\nstruct ServerList {\n    countries: Vec<Country>,\n}\n\nimpl ServerList {\n    fn new(client: reqwest::blocking::Client, token: &str) -> Self {\n        client\n            .get(&format!(\"{}/vpn/servers\", BASE_URL))\n            .bearer_auth(token)\n            .send()\n            .unwrap()\n            .json::<ServerList>()\n            .unwrap()\n    }\n}\n\nconst BASE_URL: &str = \"https://vpn.mozilla.org/api/v1\";\n//const NAME_ARG: Arg = Arg::with_name(\"name\");\n//const PRIVKEY_ARG: Arg = Arg::with_name(\"privkey\").long(\"privkey\").takes_value(true);\n\nfn app() -> clap::App<'static, 'static> {\n    let name_arg = Arg::with_name(\"name\")\n        .help(\"Name linked with a public key. Defaults to the hostname of the system. This value has no effect on the functioning of the VPN.\")\n        .long(\"name\");\n    clap::app_from_crate!()\n        .after_help(\"To query MozillaVPN, mozwire requires a token, specified with --token. If it \\\n        is left unspecified, mozwire will generate a token by opening a login page, the token \\\n        generated can be printed using --print-token, so that it can be reused. To generate a \\\n        WireGuard configuration use `mozwire relay save`.\")\n        .subcommand(\n            SubCommand::with_name(\"device\")\n                .about(\"Add, remove and list devices. To connect to MozillaVPN, a device needs to be on the list.\")\n                .subcommand(\n                    SubCommand::with_name(\"add\")\n                        .about(\"List Devices\")\n                        .arg(\n                            Arg::with_name(\"pubkey\")\n                                .long(\"pubkey\")\n                                .takes_value(true)\n                                .conflicts_with(\"privkey\")\n                                .required(true),\n                        )\n                        .arg(Arg::with_name(\"privkey\").long(\"privkey\").takes_value(true).required_unless(\"pubkey\"))\n                        .arg(&name_arg),\n                )\n                .subcommand(\n                    SubCommand::with_name(\"list\")\n                        .alias(\"ls\")\n                        .about(\"List devices\"),\n                )\n                .subcommand(\n                    SubCommand::with_name(\"remove\")\n                        .alias(\"rm\")\n                        .about(\"Remove a device\")\n                        .arg(Arg::with_name(\"ids\").help(\"Public, private key or name of the device to remove.\").required(true).takes_value(true).multiple(true))\n                )\n                .setting(AppSettings::SubcommandRequiredElseHelp),\n        )\n        .subcommand(\n            SubCommand::with_name(\"relay\")\n                .about(\"List available relays (VPN Servers) and save WireGuard configurations for these.\")\n                .subcommand(\n                    SubCommand::with_name(\"list\")\n                        .alias(\"ls\")\n                        .about(\"List relays\"),\n                )\n                .subcommand(\n                    SubCommand::with_name(\"save\")\n                        .about(\"Save wireguard configuration for a MozillaVPN server. If the \\\n                        private key used is not in the device list uploaded, mozwire will upload \\\n                        it.\")\n                        .arg(\n                            Arg::with_name(\"regex\")\n                                .help(\"Regex to filter servers by hostname.\")\n                                .default_value(\"\"),\n                        )\n                        .arg(Arg::with_name(\"output\").short(\"o\").help(\n                            \"Directory in which to output the WireGuard configuration. Defaults to \\\n                            the current directory\",\n                        ).default_value(\".\"))\n                        .arg(\n                            Arg::with_name(\"privkey\").long(\"privkey\")\n                                .help(\"Private key to use in the configuration file. If it is not \\\n                                    specified, mozwire will generate one and update the device list.\").takes_value(true),\n                        ).arg(&name_arg).arg(\n                        Arg::with_name(\"port\").long(\"port\").short(\"p\").default_value(\"51820\")\n                        .help(\"Port to use. This can be changed to bypass firewalls and dissimulate \\\n                        the use of WireGuard. A value of \\\"random\\\" will choose a random port \\\n                        within the available range, which is the only available behaviour of the \\\n                        windows MozillaVPN client.\"))\n                        .arg(\n                            Arg::with_name(\"limit\")\n                                .help(\"Limit the number of servers saved. A value of 0 disables the limit.\")\n                                .short(\"n\")\n                                .default_value(\"1\"),\n                        )\n                )\n                .setting(AppSettings::SubcommandRequiredElseHelp),\n        )\n        .arg(\n            Arg::with_name(\"print-token\")\n                .long(\"print-token\")\n                .help(\"Print the token used to query the Mozilla API, so that it can be reused with --token, without having to sign in each time.\")\n                .global(true)\n        )\n        .arg(\n            Arg::with_name(\"token\")\n                .long(\"token\")\n                .help(\n                    \"The token used to communicate with the Mozilla API. If unspecified, a web page \\\n                    will be opened to retrieve the token. the MOZ_TOKEN environment variable can \\\n                    also be used instead.\",\n                ).env(\"MOZ_TOKEN\")\n                .global(true),\n        ).arg(\n        Arg::with_name(\"no-browser\").long(\"no-browser\").help(\"By default, mozwire will open the login page in a browser, this option prevents mozwire a browser page from being opened.\").takes_value(false).global(true)\n        )\n        .global_setting(AppSettings::ColoredHelp)\n        .setting(AppSettings::ArgRequiredElseHelp)\n}\n\nfn main() {\n    let matches = app().get_matches();\n\n    let client = reqwest::blocking::Client::builder()\n        // Some operations fail when no User-Agent is present\n        .user_agent(\"Why does the api need a user agent???\")\n        .build()\n        .unwrap();\n\n    let login = matches.value_of(\"token\").map_or_else(\n        || {\n            let login = client\n                .post(&format!(\"{}/vpn/login\", BASE_URL))\n                .send()\n                .unwrap()\n                .json::<LoginURLs>()\n                .unwrap();\n\n            eprint!(\"Please visit {}.\", login.login_url);\n            if !matches.is_present(\"no-browser\") {\n                match webbrowser::open(&login.login_url) {\n                    Ok(_) => eprint!(\" Link opened in browser.\"),\n                    Err(_) => eprint!(\" Failed to open link in browser, please visit it manually.\"),\n                }\n            }\n            eprintln!();\n\n            let poll_interval = std::time::Duration::from_secs(login.poll_interval);\n            loop {\n                let response = client.get(&login.verification_url).send().unwrap();\n                if response.status() == reqwest::StatusCode::OK {\n                    eprintln!(\"Login successful\");\n                    break response.json::<Login>().unwrap();\n                } else {\n                    match response.json::<Error>().unwrap() {\n                        Error { errno: 126, .. } => {}\n                        error => error.fail(),\n                    }\n                }\n                std::thread::sleep(poll_interval);\n            }\n        },\n        |token| {\n            let response = client\n                .get(&format!(\"{}/vpn/account\", BASE_URL))\n                .bearer_auth(token)\n                .send()\n                .unwrap();\n            if !response.status().is_success() {\n                response.json::<Error>().unwrap().fail();\n            }\n\n            Login {\n                user: response.json::<User>().unwrap(),\n                token: token.to_owned(),\n            }\n        },\n    );\n\n    let mut action_performed = false;\n    if matches.is_present(\"print-token\") {\n        action_performed = true;\n        println!(\"{}\", login.token);\n    }\n\n    let mut rng = rand::thread_rng();\n\n    match matches.subcommand() {\n        (\"device\", Some(device_m)) => match device_m.subcommand() {\n            (\"add\", Some(sub_m)) => {\n                let pubkey = sub_m.value_of(\"pubkey\").map_or_else(\n                    || match private_to_public_key(sub_m.value_of(\"privkey\").unwrap()) {\n                        Ok(pubkey) => pubkey,\n                        Err(_) => {\n                            println!(\"Invalid private key.\");\n                            std::process::exit(2)\n                        }\n                    },\n                    |pubkey| pubkey.to_owned(),\n                );\n                println!(\n                    \"{}\",\n                    &NewDevice {\n                        name: sub_m\n                            .value_of(\"name\")\n                            .unwrap_or(&sys_info::hostname().unwrap()),\n                        pubkey: &pubkey,\n                    }\n                    .upload(&client, &login.token),\n                );\n            }\n            (\"list\", ..) => {\n                eprintln!(\"Devices:\");\n                for device in login.user.devices {\n                    println!(\"{}\", device)\n                }\n            }\n            (\"remove\", Some(sub_m)) => {\n                for id in sub_m.values_of(\"ids\").unwrap() {\n                    for device in login.user.devices.iter().filter(|device| {\n                        id == device.name\n                            || id == device.pubkey\n                            || private_to_public_key(id)\n                                .map_or(false, |pubkey| pubkey == device.pubkey)\n                    }) {\n                        client\n                            .delete(&format!(\n                                \"{}/vpn/device/{}\",\n                                BASE_URL,\n                                percent_encoding::utf8_percent_encode(\n                                    &device.pubkey,\n                                    percent_encoding::NON_ALPHANUMERIC\n                                )\n                            ))\n                            .bearer_auth(&login.token)\n                            .send()\n                            .unwrap();\n                        eprintln!(\n                            \"Device {}, with public key: {} has successfully been removed.\",\n                            device.name, device.pubkey\n                        );\n                    }\n                }\n            }\n            _ => unreachable!(),\n        },\n        (\"relay\", Some(relay_m)) => {\n            match relay_m.subcommand() {\n                (\"list\", ..) => {\n                    for country in ServerList::new(client, &login.token).countries {\n                        println!(\"{} ({})\", country.name, country.code);\n                        for city in country.cities {\n                            println!(\n                                \"\\t{} ({}) @ {}\u00b0N, {}\u00b0W\",\n                                city.name, city.code, city.latitude, city.longitude\n                            );\n                            for server in city.servers {\n                                println!(\n                                    \"\\t\\t{} ({}, {})\",\n                                    server.hostname, server.ipv4_addr_in, server.ipv6_addr_in\n                                );\n                            }\n                        }\n                    }\n                }\n                (\"save\", Some(save_m)) => {\n                    let (pubkey_base64, privkey_base64) = save_m.value_of(\"privkey\").map_or_else(\n                        || {\n                            let privkey = StaticSecret::new(&mut rand::rngs::OsRng);\n                            let privkey_base64 = base64::encode(privkey.to_bytes());\n                            (\n                                base64::encode(PublicKey::from(&privkey).as_bytes()),\n                                privkey_base64,\n                            )\n                        },\n                        |privkey_base64| {\n                            (\n                                match private_to_public_key(privkey_base64) {\n                                    Ok(pubkey) => pubkey,\n                                    Err(_) => {\n                                        println!(\"Invalid private key.\");\n                                        std::process::exit(2)\n                                    }\n                                },\n                                privkey_base64.to_owned(),\n                            )\n                        },\n                    );\n                    let (ipv4_address, ipv6_address) = login\n                        .user\n                        .devices\n                        .iter()\n                        .find(|device| device.pubkey == pubkey_base64)\n                        .map_or_else(\n                            || {\n                                eprintln!(\"Public key not in device list, uploading it.\");\n                                let device = NewDevice {\n                                    name: save_m\n                                        .value_of(\"name\")\n                                        .unwrap_or(&sys_info::hostname().unwrap()),\n                                    pubkey: &pubkey_base64,\n                                }\n                                .upload(&client, &login.token);\n                                (device.ipv4_address, device.ipv6_address)\n                            },\n                            |device| (device.ipv4_address.clone(), device.ipv6_address.clone()),\n                        );\n\n                    let re = regex::Regex::new(save_m.value_of(\"regex\").unwrap()).unwrap();\n                    let server_list = ServerList::new(client, &login.token);\n                    let filtered = server_list\n                        .countries\n                        .iter()\n                        .flat_map(|country| {\n                            country.cities.iter().flat_map(|city| city.servers.iter())\n                        })\n                        .filter(|server| re.is_match(&server.hostname));\n                    for server in if let Some(limit) =\n                        NonZeroUsize::new(save_m.value_of(\"limit\").unwrap().parse().unwrap())\n                    {\n                        filtered.choose_multiple(&mut rng, limit.get())\n                    } else {\n                        filtered.collect()\n                    } {\n                        let path = std::path::Path::new(save_m.value_of(\"output\").unwrap());\n                        std::fs::create_dir_all(&path).unwrap();\n                        let path = path.join(format!(\"{}.conf\", server.hostname));\n                        std::fs::write(\n                            &path,\n                            format!(\n                                \"[Interface]\nPrivateKey = {}\nAddress = {},{}\nDNS = {}\n\n[Peer]\nPublicKey = {}\nAllowedIPs = 0.0.0.0/0,::0/0\nEndpoint = {}:{}\\n\",\n                                privkey_base64,\n                                ipv4_address,\n                                ipv6_address,\n                                server.ipv4_gateway,\n                                server.public_key,\n                                server.ipv4_addr_in,\n                                // Deal with ranges\n                                {\n                                    let mut ports =\n                                        server.port_ranges.iter().map(|(from, to)| (*from)..=(*to));\n                                    let port_arg = save_m.value_of(\"port\").unwrap();\n                                    if port_arg == \"random\" {\n                                        ports.flatten().choose(&mut rng).unwrap()\n                                    } else {\n                                        let port = port_arg.parse().unwrap();\n                                        if ports.any(|range| range.contains(&port)) {\n                                            port\n                                        } else {\n                                            println!(\n                                                \"{} is outside of the usable port range.\",\n                                                port\n                                            );\n                                            std::process::exit(2);\n                                        }\n                                    }\n                                }\n                            ),\n                        )\n                        .unwrap();\n                        println!(\"Wrote configuration to {}.\", path.to_str().unwrap());\n                    }\n                }\n                _ => unreachable!(),\n            }\n        }\n        _ => {\n            if !action_performed {\n                app().print_help().unwrap();\n            }\n        }\n    };\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    #[test]\n    fn test_private_to_public_key() {\n        assert_eq!(\n            private_to_public_key(\"OO9fkBohqv0mnmogkonAXBAvurjfy/DYXcpI1Yt7pEo=\").unwrap(),\n            \"JyMv6TlARDnBfQmXFzlywOLveNV3mBMaWosFjTcYE0g=\"\n        );\n        assert_eq!(\n            private_to_public_key(\"wD4tAq9edXWCILzf8uO7qgsOs/2gTUTvcGMhUdwS6E8=\").unwrap(),\n            \"wv6lbcAK1L+IYJk8SgpRLgFED7/pggu8uvi8Li7OjH4=\"\n        );\n\n        assert_eq!(\n            private_to_public_key(\"4AaD2YkoQ+c2ccL/fnjTmTeRdiZVhvXhiL4gApeePG4=\").unwrap(),\n            \"idTXEeR5rjxYMgQpwbLP+2qYEYR5KinvDqfZpFg7HTo=\"\n        );\n\n        assert_eq!(\n            private_to_public_key(\"iBr/jbjbij/w3BpvTvkB6r1zQvMpIx5mc1C/qnuzpnU=\").unwrap(),\n            \"gxi5un691rLWUD4HSXM0gU4OpHt4r+yVlQ/jfDYJIR8=\"\n        );\n\n        assert_eq!(\n            private_to_public_key(\"kCJuJAX+EWZ23tPK1b+Szl+m89TYxLh9ilIn+gDzZnc=\").unwrap(),\n            \"nT4fmyCGntbuIetTOndAAF/b02p5GGj3MkOSb1wF1zY=\"\n        );\n    }\n}\n"
  },
  {
    "project": "lettre",
    "target": 1,
    "commit_id": "b187885e70af400d50e3200390306b9bd2109675",
    "func": "//! The sendmail transport sends the email using the local sendmail command.\n//!\n//! ## Sync example\n//!\n//! ```rust\n//! # use std::error::Error;\n//!\n//! # #[cfg(all(feature = \"sendmail-transport\", feature = \"builder\"))]\n//! # fn main() -> Result<(), Box<dyn Error>> {\n//! # use lettre::{Message, Transport, SendmailTransport};\n//!\n//! let email = Message::builder()\n//!     .from(\"NoBody <nobody@domain.tld>\".parse()?)\n//!     .reply_to(\"Yuin <yuin@domain.tld>\".parse()?)\n//!     .to(\"Hei <hei@domain.tld>\".parse()?)\n//!     .subject(\"Happy new year\")\n//!     .body(\"Be happy!\")?;\n//!\n//! let sender = SendmailTransport::new();\n//! let result = sender.send(&email);\n//! assert!(result.is_ok());\n//! # Ok(())\n//! # }\n//!\n//! # #[cfg(not(all(feature = \"sendmail-transport\", feature = \"builder\")))]\n//! # fn main() {}\n//! ```\n//!\n//! ## Async tokio 0.2 example\n//!\n//! ```rust,no_run\n//! # use std::error::Error;\n//!\n//! # #[cfg(all(feature = \"tokio02\", feature = \"sendmail-transport\", feature = \"builder\"))]\n//! # async fn run() -> Result<(), Box<dyn Error>> {\n//! use lettre::{Message, Tokio02Transport, SendmailTransport};\n//!\n//! let email = Message::builder()\n//!     .from(\"NoBody <nobody@domain.tld>\".parse()?)\n//!     .reply_to(\"Yuin <yuin@domain.tld>\".parse()?)\n//!     .to(\"Hei <hei@domain.tld>\".parse()?)\n//!     .subject(\"Happy new year\")\n//!     .body(\"Be happy!\")?;\n//!\n//! let sender = SendmailTransport::new();\n//! let result = sender.send(email).await;\n//! assert!(result.is_ok());\n//! # Ok(())\n//! # }\n//! ```\n//!\n//! ## Async async-std 1.x example\n//!\n//!```rust,no_run\n//! # use std::error::Error;\n//!\n//! # #[cfg(all(feature = \"async-std1\", feature = \"sendmail-transport\", feature = \"builder\"))]\n//! # async fn run() -> Result<(), Box<dyn Error>> {\n//! use lettre::{Message, AsyncStd1Transport, SendmailTransport};\n//!\n//! let email = Message::builder()\n//!     .from(\"NoBody <nobody@domain.tld>\".parse()?)\n//!     .reply_to(\"Yuin <yuin@domain.tld>\".parse()?)\n//!     .to(\"Hei <hei@domain.tld>\".parse()?)\n//!     .subject(\"Happy new year\")\n//!     .body(\"Be happy!\")?;\n//!\n//! let sender = SendmailTransport::new();\n//! let result = sender.send(email).await;\n//! assert!(result.is_ok());\n//! # Ok(())\n//! # }\n//! ```\n\npub use self::error::Error;\nuse crate::address::Envelope;\n#[cfg(feature = \"async-std1\")]\nuse crate::AsyncStd1Transport;\n#[cfg(feature = \"tokio02\")]\nuse crate::Tokio02Transport;\n#[cfg(feature = \"tokio03\")]\nuse crate::Tokio03Transport;\nuse crate::Transport;\n#[cfg(any(feature = \"async-std1\", feature = \"tokio02\", feature = \"tokio03\"))]\nuse async_trait::async_trait;\nuse std::{\n    ffi::OsString,\n    io::prelude::*,\n    process::{Command, Stdio},\n};\n\nmod error;\n\nconst DEFAUT_SENDMAIL: &str = \"/usr/sbin/sendmail\";\n\n/// Sends an email using the `sendmail` command\n#[derive(Debug, Clone)]\n#[cfg_attr(feature = \"serde\", derive(serde::Serialize, serde::Deserialize))]\npub struct SendmailTransport {\n    command: OsString,\n}\n\nimpl SendmailTransport {\n    /// Creates a new transport with the default `/usr/sbin/sendmail` command\n    pub fn new() -> SendmailTransport {\n        SendmailTransport {\n            command: DEFAUT_SENDMAIL.into(),\n        }\n    }\n\n    /// Creates a new transport to the given sendmail command\n    pub fn new_with_command<S: Into<OsString>>(command: S) -> SendmailTransport {\n        SendmailTransport {\n            command: command.into(),\n        }\n    }\n\n    fn command(&self, envelope: &Envelope) -> Command {\n        let mut c = Command::new(&self.command);\n        c.arg(\"-i\")\n            .arg(\"-f\")\n            .arg(envelope.from().map(|f| f.as_ref()).unwrap_or(\"\\\"\\\"\"))\n            .args(envelope.to())\n            .stdin(Stdio::piped())\n            .stdout(Stdio::piped());\n        c\n    }\n\n    #[cfg(feature = \"tokio02\")]\n    fn tokio02_command(&self, envelope: &Envelope) -> tokio02_crate::process::Command {\n        use tokio02_crate::process::Command;\n\n        let mut c = Command::new(&self.command);\n        c.kill_on_drop(true);\n        c.arg(\"-i\")\n            .arg(\"-f\")\n            .arg(envelope.from().map(|f| f.as_ref()).unwrap_or(\"\\\"\\\"\"))\n            .args(envelope.to())\n            .stdin(Stdio::piped())\n            .stdout(Stdio::piped());\n        c\n    }\n\n    #[cfg(feature = \"tokio03\")]\n    fn tokio03_command(&self, envelope: &Envelope) -> tokio03_crate::process::Command {\n        use tokio03_crate::process::Command;\n\n        let mut c = Command::new(&self.command);\n        c.kill_on_drop(true);\n        c.arg(\"-i\")\n            .arg(\"-f\")\n            .arg(envelope.from().map(|f| f.as_ref()).unwrap_or(\"\\\"\\\"\"))\n            .args(envelope.to())\n            .stdin(Stdio::piped())\n            .stdout(Stdio::piped());\n        c\n    }\n}\n\nimpl Default for SendmailTransport {\n    fn default() -> Self {\n        Self::new()\n    }\n}\n\nimpl Transport for SendmailTransport {\n    type Ok = ();\n    type Error = Error;\n\n    fn send_raw(&self, envelope: &Envelope, email: &[u8]) -> Result<Self::Ok, Self::Error> {\n        // Spawn the sendmail command\n        let mut process = self.command(envelope).spawn()?;\n\n        process.stdin.as_mut().unwrap().write_all(email)?;\n        let output = process.wait_with_output()?;\n\n        if output.status.success() {\n            Ok(())\n        } else {\n            Err(error::Error::Client(String::from_utf8(output.stderr)?))\n        }\n    }\n}\n\n#[cfg(feature = \"async-std1\")]\n#[async_trait]\nimpl AsyncStd1Transport for SendmailTransport {\n    type Ok = ();\n    type Error = Error;\n\n    async fn send_raw(&self, envelope: &Envelope, email: &[u8]) -> Result<Self::Ok, Self::Error> {\n        let mut command = self.command(envelope);\n        let email = email.to_vec();\n\n        // TODO: Convert to real async, once async-std has a process implementation.\n        let output = async_std::task::spawn_blocking(move || {\n            // Spawn the sendmail command\n            let mut process = command.spawn()?;\n\n            process.stdin.as_mut().unwrap().write_all(&email)?;\n            process.wait_with_output()\n        })\n        .await?;\n\n        if output.status.success() {\n            Ok(())\n        } else {\n            Err(Error::Client(String::from_utf8(output.stderr)?))\n        }\n    }\n}\n\n#[cfg(feature = \"tokio02\")]\n#[async_trait]\nimpl Tokio02Transport for SendmailTransport {\n    type Ok = ();\n    type Error = Error;\n\n    async fn send_raw(&self, envelope: &Envelope, email: &[u8]) -> Result<Self::Ok, Self::Error> {\n        use tokio02_crate::io::AsyncWriteExt;\n\n        let mut command = self.tokio02_command(envelope);\n\n        // Spawn the sendmail command\n        let mut process = command.spawn()?;\n\n        process.stdin.as_mut().unwrap().write_all(&email).await?;\n        let output = process.wait_with_output().await?;\n\n        if output.status.success() {\n            Ok(())\n        } else {\n            Err(Error::Client(String::from_utf8(output.stderr)?))\n        }\n    }\n}\n\n#[cfg(feature = \"tokio03\")]\n#[async_trait]\nimpl Tokio03Transport for SendmailTransport {\n    type Ok = ();\n    type Error = Error;\n\n    async fn send_raw(&self, envelope: &Envelope, email: &[u8]) -> Result<Self::Ok, Self::Error> {\n        use tokio03_crate::io::AsyncWriteExt;\n\n        let mut command = self.tokio03_command(envelope);\n\n        // Spawn the sendmail command\n        let mut process = command.spawn()?;\n\n        process.stdin.as_mut().unwrap().write_all(&email).await?;\n        let output = process.wait_with_output().await?;\n\n        if output.status.success() {\n            Ok(())\n        } else {\n            Err(Error::Client(String::from_utf8(output.stderr)?))\n        }\n    }\n}\n"
  },
  {
    "project": "lettre",
    "target": 1,
    "commit_id": "bbe7cc5381c5380b54fb8bbb4f77a3725917ff0b",
    "func": "//! The sendmail transport sends the email using the local sendmail command.\n//!\n//! ## Sync example\n//!\n//! ```rust\n//! # use std::error::Error;\n//!\n//! # #[cfg(all(feature = \"sendmail-transport\", feature = \"builder\"))]\n//! # fn main() -> Result<(), Box<dyn Error>> {\n//! # use lettre::{Message, Transport, SendmailTransport};\n//!\n//! let email = Message::builder()\n//!     .from(\"NoBody <nobody@domain.tld>\".parse()?)\n//!     .reply_to(\"Yuin <yuin@domain.tld>\".parse()?)\n//!     .to(\"Hei <hei@domain.tld>\".parse()?)\n//!     .subject(\"Happy new year\")\n//!     .body(\"Be happy!\")?;\n//!\n//! let sender = SendmailTransport::new();\n//! let result = sender.send(&email);\n//! assert!(result.is_ok());\n//! # Ok(())\n//! # }\n//!\n//! # #[cfg(not(all(feature = \"sendmail-transport\", feature = \"builder\")))]\n//! # fn main() {}\n//! ```\n//!\n//! ## Async tokio 0.2 example\n//!\n//! ```rust,no_run\n//! # use std::error::Error;\n//!\n//! # #[cfg(all(feature = \"tokio02\", feature = \"sendmail-transport\", feature = \"builder\"))]\n//! # async fn run() -> Result<(), Box<dyn Error>> {\n//! use lettre::{Message, Tokio02Transport, SendmailTransport};\n//!\n//! let email = Message::builder()\n//!     .from(\"NoBody <nobody@domain.tld>\".parse()?)\n//!     .reply_to(\"Yuin <yuin@domain.tld>\".parse()?)\n//!     .to(\"Hei <hei@domain.tld>\".parse()?)\n//!     .subject(\"Happy new year\")\n//!     .body(\"Be happy!\")?;\n//!\n//! let sender = SendmailTransport::new();\n//! let result = sender.send(email).await;\n//! assert!(result.is_ok());\n//! # Ok(())\n//! # }\n//! ```\n//!\n//! ## Async async-std 1.x example\n//!\n//!```rust,no_run\n//! # use std::error::Error;\n//!\n//! # #[cfg(all(feature = \"async-std1\", feature = \"sendmail-transport\", feature = \"builder\"))]\n//! # async fn run() -> Result<(), Box<dyn Error>> {\n//! use lettre::{Message, AsyncStd1Transport, SendmailTransport};\n//!\n//! let email = Message::builder()\n//!     .from(\"NoBody <nobody@domain.tld>\".parse()?)\n//!     .reply_to(\"Yuin <yuin@domain.tld>\".parse()?)\n//!     .to(\"Hei <hei@domain.tld>\".parse()?)\n//!     .subject(\"Happy new year\")\n//!     .body(\"Be happy!\")?;\n//!\n//! let sender = SendmailTransport::new();\n//! let result = sender.send(email).await;\n//! assert!(result.is_ok());\n//! # Ok(())\n//! # }\n//! ```\n\npub use self::error::Error;\nuse crate::address::Envelope;\n#[cfg(feature = \"async-std1\")]\nuse crate::AsyncStd1Transport;\n#[cfg(feature = \"tokio02\")]\nuse crate::Tokio02Transport;\n#[cfg(feature = \"tokio03\")]\nuse crate::Tokio03Transport;\nuse crate::Transport;\n#[cfg(any(feature = \"async-std1\", feature = \"tokio02\", feature = \"tokio03\"))]\nuse async_trait::async_trait;\nuse std::{\n    ffi::OsString,\n    io::prelude::*,\n    process::{Command, Stdio},\n};\n\nmod error;\n\nconst DEFAUT_SENDMAIL: &str = \"/usr/sbin/sendmail\";\n\n/// Sends an email using the `sendmail` command\n#[derive(Debug, Clone)]\n#[cfg_attr(feature = \"serde\", derive(serde::Serialize, serde::Deserialize))]\npub struct SendmailTransport {\n    command: OsString,\n}\n\nimpl SendmailTransport {\n    /// Creates a new transport with the default `/usr/sbin/sendmail` command\n    pub fn new() -> SendmailTransport {\n        SendmailTransport {\n            command: DEFAUT_SENDMAIL.into(),\n        }\n    }\n\n    /// Creates a new transport to the given sendmail command\n    pub fn new_with_command<S: Into<OsString>>(command: S) -> SendmailTransport {\n        SendmailTransport {\n            command: command.into(),\n        }\n    }\n\n    fn command(&self, envelope: &Envelope) -> Command {\n        let mut c = Command::new(&self.command);\n        c.arg(\"-i\")\n            .arg(\"-f\")\n            .arg(envelope.from().map(|f| f.as_ref()).unwrap_or(\"\\\"\\\"\"))\n            .arg(\"--\")\n            .args(envelope.to())\n            .stdin(Stdio::piped())\n            .stdout(Stdio::piped());\n        c\n    }\n\n    #[cfg(feature = \"tokio02\")]\n    fn tokio02_command(&self, envelope: &Envelope) -> tokio02_crate::process::Command {\n        use tokio02_crate::process::Command;\n\n        let mut c = Command::new(&self.command);\n        c.kill_on_drop(true);\n        c.arg(\"-i\")\n            .arg(\"-f\")\n            .arg(envelope.from().map(|f| f.as_ref()).unwrap_or(\"\\\"\\\"\"))\n            .arg(\"--\")\n            .args(envelope.to())\n            .stdin(Stdio::piped())\n            .stdout(Stdio::piped());\n        c\n    }\n\n    #[cfg(feature = \"tokio03\")]\n    fn tokio03_command(&self, envelope: &Envelope) -> tokio03_crate::process::Command {\n        use tokio03_crate::process::Command;\n\n        let mut c = Command::new(&self.command);\n        c.kill_on_drop(true);\n        c.arg(\"-i\")\n            .arg(\"-f\")\n            .arg(envelope.from().map(|f| f.as_ref()).unwrap_or(\"\\\"\\\"\"))\n            .arg(\"--\")\n            .args(envelope.to())\n            .stdin(Stdio::piped())\n            .stdout(Stdio::piped());\n        c\n    }\n}\n\nimpl Default for SendmailTransport {\n    fn default() -> Self {\n        Self::new()\n    }\n}\n\nimpl Transport for SendmailTransport {\n    type Ok = ();\n    type Error = Error;\n\n    fn send_raw(&self, envelope: &Envelope, email: &[u8]) -> Result<Self::Ok, Self::Error> {\n        // Spawn the sendmail command\n        let mut process = self.command(envelope).spawn()?;\n\n        process.stdin.as_mut().unwrap().write_all(email)?;\n        let output = process.wait_with_output()?;\n\n        if output.status.success() {\n            Ok(())\n        } else {\n            Err(error::Error::Client(String::from_utf8(output.stderr)?))\n        }\n    }\n}\n\n#[cfg(feature = \"async-std1\")]\n#[async_trait]\nimpl AsyncStd1Transport for SendmailTransport {\n    type Ok = ();\n    type Error = Error;\n\n    async fn send_raw(&self, envelope: &Envelope, email: &[u8]) -> Result<Self::Ok, Self::Error> {\n        let mut command = self.command(envelope);\n        let email = email.to_vec();\n\n        // TODO: Convert to real async, once async-std has a process implementation.\n        let output = async_std::task::spawn_blocking(move || {\n            // Spawn the sendmail command\n            let mut process = command.spawn()?;\n\n            process.stdin.as_mut().unwrap().write_all(&email)?;\n            process.wait_with_output()\n        })\n        .await?;\n\n        if output.status.success() {\n            Ok(())\n        } else {\n            Err(Error::Client(String::from_utf8(output.stderr)?))\n        }\n    }\n}\n\n#[cfg(feature = \"tokio02\")]\n#[async_trait]\nimpl Tokio02Transport for SendmailTransport {\n    type Ok = ();\n    type Error = Error;\n\n    async fn send_raw(&self, envelope: &Envelope, email: &[u8]) -> Result<Self::Ok, Self::Error> {\n        use tokio02_crate::io::AsyncWriteExt;\n\n        let mut command = self.tokio02_command(envelope);\n\n        // Spawn the sendmail command\n        let mut process = command.spawn()?;\n\n        process.stdin.as_mut().unwrap().write_all(&email).await?;\n        let output = process.wait_with_output().await?;\n\n        if output.status.success() {\n            Ok(())\n        } else {\n            Err(Error::Client(String::from_utf8(output.stderr)?))\n        }\n    }\n}\n\n#[cfg(feature = \"tokio03\")]\n#[async_trait]\nimpl Tokio03Transport for SendmailTransport {\n    type Ok = ();\n    type Error = Error;\n\n    async fn send_raw(&self, envelope: &Envelope, email: &[u8]) -> Result<Self::Ok, Self::Error> {\n        use tokio03_crate::io::AsyncWriteExt;\n\n        let mut command = self.tokio03_command(envelope);\n\n        // Spawn the sendmail command\n        let mut process = command.spawn()?;\n\n        process.stdin.as_mut().unwrap().write_all(&email).await?;\n        let output = process.wait_with_output().await?;\n\n        if output.status.success() {\n            Ok(())\n        } else {\n            Err(Error::Client(String::from_utf8(output.stderr)?))\n        }\n    }\n}\n"
  },
  {
    "project": "glsl-layout",
    "target": 1,
    "commit_id": "119f5ec524dca42403db2aa07569baa349793e9b",
    "func": "use crate::align::Align16;\nuse crate::uniform::{Std140, Uniform};\nuse std::{\n    marker::PhantomData,\n    slice::{Iter as SliceIter, IterMut as SliceIterMut},\n};\n\npub(crate) trait MapArray<A, F> {\n    fn map_array(values: A, f: F) -> Self;\n}\n\n/// Aligning wrapper.\n/// Elements for array are aligned to 16 bytes (size of vec4) at least.\n#[derive(Clone, Copy, Debug, Default, PartialOrd, PartialEq, Ord, Eq, Hash)]\n#[repr(C, align(16))]\npub struct Element<T: Uniform>(pub T, pub T::Align);\n\nimpl<T> From<T> for Element<T>\nwhere\n    T: Uniform,\n{\n    fn from(values: T) -> Self {\n        Element(values, Default::default())\n    }\n}\n\nimpl<T> AsRef<T> for Element<T>\nwhere\n    T: Uniform,\n{\n    fn as_ref(&self) -> &T {\n        &self.0\n    }\n}\n\nimpl<T> AsMut<T> for Element<T>\nwhere\n    T: Uniform,\n{\n    fn as_mut(&mut self) -> &mut T {\n        &mut self.0\n    }\n}\n\n/// Array of `Element`s.\n/// This type implements useful traits for converting from unwrapped types.\n#[derive(Clone, Copy, Debug, Default, PartialOrd, PartialEq, Ord, Eq, Hash)]\n#[repr(C, align(16))]\npub struct Array<T, A>(pub A, pub PhantomData<fn(T)>);\n\nimpl<T, A> Array<T, A> {\n    pub fn new(array: A) -> Self {\n        Array(array, PhantomData)\n    }\n}\n\nimpl<T, A> AsRef<A> for Array<T, A> {\n    fn as_ref(&self) -> &A {\n        &self.0\n    }\n}\n\nimpl<T, A> AsMut<A> for Array<T, A> {\n    fn as_mut(&mut self) -> &mut A {\n        &mut self.0\n    }\n}\n\nimpl<T, A> Array<T, A>\nwhere\n    T: Uniform,\n    A: AsMut<[Element<T>]> + AsRef<[Element<T>]>,\n{\n    pub fn iter(&self) -> ArrayIter<SliceIter<Element<T>>> {\n        ArrayIter(self.0.as_ref().iter())\n    }\n\n    pub fn iter_mut(&mut self) -> ArrayIter<SliceIterMut<Element<T>>> {\n        ArrayIter(self.0.as_mut().iter_mut())\n    }\n}\n\nimpl<'a, T, A> IntoIterator for &'a Array<T, A>\nwhere\n    T: Uniform,\n    A: AsMut<[Element<T>]> + AsRef<[Element<T>]>,\n{\n    type Item = &'a T;\n    type IntoIter = ArrayIter<SliceIter<'a, Element<T>>>;\n\n    fn into_iter(self) -> ArrayIter<SliceIter<'a, Element<T>>> {\n        self.iter()\n    }\n}\n\nimpl<'a, T, A> IntoIterator for &'a mut Array<T, A>\nwhere\n    T: Uniform,\n    A: AsMut<[Element<T>]> + AsRef<[Element<T>]>,\n{\n    type Item = &'a mut T;\n    type IntoIter = ArrayIter<SliceIterMut<'a, Element<T>>>;\n\n    fn into_iter(self) -> ArrayIter<SliceIterMut<'a, Element<T>>> {\n        self.iter_mut()\n    }\n}\n\n/// Array ref iterator\n/// Iterate over references to inner values.\npub struct ArrayIter<I>(I);\n\nimpl<'a, T> Iterator for ArrayIter<SliceIter<'a, Element<T>>>\nwhere\n    T: Uniform,\n{\n    type Item = &'a T;\n\n    fn next(&mut self) -> Option<&'a T> {\n        self.0.next().map(|elem| &elem.0)\n    }\n}\n\nimpl<'a, T> ExactSizeIterator for ArrayIter<SliceIter<'a, Element<T>>>\nwhere\n    T: Uniform,\n{\n    fn len(&self) -> usize {\n        self.0.len()\n    }\n}\n\nimpl<'a, T> DoubleEndedIterator for ArrayIter<SliceIter<'a, Element<T>>>\nwhere\n    T: Uniform,\n{\n    fn next_back(&mut self) -> Option<&'a T> {\n        self.0.next_back().map(|elem| &elem.0)\n    }\n}\n\nimpl<'a, T> Iterator for ArrayIter<SliceIterMut<'a, Element<T>>>\nwhere\n    T: Uniform,\n{\n    type Item = &'a mut T;\n\n    fn next(&mut self) -> Option<&'a mut T> {\n        self.0.next().map(|elem| &mut elem.0)\n    }\n}\n\nimpl<'a, T> ExactSizeIterator for ArrayIter<SliceIterMut<'a, Element<T>>>\nwhere\n    T: Uniform,\n{\n    fn len(&self) -> usize {\n        self.0.len()\n    }\n}\n\nimpl<'a, T> DoubleEndedIterator for ArrayIter<SliceIterMut<'a, Element<T>>>\nwhere\n    T: Uniform,\n{\n    fn next_back(&mut self) -> Option<&'a mut T> {\n        self.0.next_back().map(|elem| &mut elem.0)\n    }\n}\n\nmacro_rules! impl_array {\n    ($size:expr) => {\n        impl<T, U, F> MapArray<[T; $size], F> for [U; $size]\n        where\n            F: FnMut(T) -> U,\n        {\n            fn map_array(mut values: [T; $size], mut f: F) -> Self {\n                use std::{\n                    mem::forget,\n                    ptr::{read, write},\n                };\n\n                unsafe {\n                    // All elements of `result` is written.\n                    // Each element of `values` read once and then forgotten.\n                    // Hence safe in case `f` never panics.\n                    // TODO: Make it panic-safe.\n                    let mut result: ::std::mem::MaybeUninit<[U; $size]> =\n                        ::std::mem::MaybeUninit::zeroed();\n                    for i in 0..$size {\n                        write(\n                            result.as_mut_ptr().cast::<U>().add(i),\n                            f(read(&mut values[i])),\n                        );\n                    }\n                    forget(values);\n                    result.assume_init()\n                }\n            }\n        }\n\n        impl<T, U> From<[T; $size]> for Array<U, [U; $size]>\n        where\n            T: Into<U>,\n        {\n            fn from(values: [T; $size]) -> Self {\n                Array(MapArray::map_array(values, T::into), PhantomData)\n            }\n        }\n\n        impl<T, U> From<[T; $size]> for Array<U, [Element<U>; $size]>\n        where\n            T: Into<U>,\n            U: Uniform,\n        {\n            fn from(values: [T; $size]) -> Self {\n                let values: [U; $size] = MapArray::map_array(values, T::into);\n                Array(MapArray::map_array(values, U::into), PhantomData)\n            }\n        }\n\n        impl<T> Uniform for [T; $size]\n        where\n            T: Uniform,\n        {\n            type Align = Align16;\n            type Std140 = Array<T::Std140, [Element<T::Std140>; $size]>;\n\n            fn std140(&self) -> Array<T::Std140, [Element<T::Std140>; $size]> {\n                use std::ptr::write;\n                unsafe {\n                    // All elements of `result` is written.\n                    let mut result: ::std::mem::MaybeUninit<[Element<T::Std140>; $size]> =\n                        ::std::mem::MaybeUninit::zeroed();\n                    for i in 0..$size {\n                        write(\n                            result.as_mut_ptr().cast::<Element<T::Std140>>().add(i),\n                            self[i].std140().into(),\n                        );\n                    }\n                    Array(result.assume_init(), PhantomData)\n                }\n            }\n        }\n\n        impl<T> Uniform for Array<T, [Element<T>; $size]>\n        where\n            T: Uniform,\n        {\n            type Align = Align16;\n            type Std140 = Array<T::Std140, [Element<T::Std140>; $size]>;\n\n            fn std140(&self) -> Array<T::Std140, [Element<T::Std140>; $size]> {\n                use std::ptr::write;\n                unsafe {\n                    // All elements of `result` is written.\n                    let mut result: ::std::mem::MaybeUninit<[Element<T::Std140>; $size]> =\n                        ::std::mem::MaybeUninit::zeroed();\n                    for i in 0..$size {\n                        write(\n                            result.as_mut_ptr().cast::<Element<T::Std140>>().add(i),\n                            self.0[i].0.std140().into(),\n                        );\n                    }\n                    Array(result.assume_init(), PhantomData)\n                }\n            }\n        }\n\n        unsafe impl<T> Std140 for Array<T, [Element<T>; $size]> where T: Std140 {}\n    };\n}\n\nimpl_array!(0);\nimpl_array!(1);\nimpl_array!(2);\nimpl_array!(3);\nimpl_array!(4);\nimpl_array!(5);\nimpl_array!(6);\nimpl_array!(7);\nimpl_array!(8);\nimpl_array!(9);\nimpl_array!(10);\nimpl_array!(11);\nimpl_array!(12);\nimpl_array!(13);\nimpl_array!(14);\nimpl_array!(15);\nimpl_array!(16);\nimpl_array!(17);\nimpl_array!(18);\nimpl_array!(19);\nimpl_array!(20);\nimpl_array!(21);\nimpl_array!(22);\nimpl_array!(23);\nimpl_array!(24);\nimpl_array!(25);\nimpl_array!(26);\nimpl_array!(27);\nimpl_array!(28);\nimpl_array!(29);\nimpl_array!(30);\nimpl_array!(31);\nimpl_array!(32);\n"
  },
  {
    "project": "untrusted",
    "target": 1,
    "commit_id": "44384f81a3318b13430f3976c769d4925ec9d76d",
    "func": "// Copyright 2015-2016 Brian Smith.\n//\n// Permission to use, copy, modify, and/or distribute this software for any\n// purpose with or without fee is hereby granted, provided that the above\n// copyright notice and this permission notice appear in all copies.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHORS DISCLAIM ALL WARRANTIES\n// WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF\n// MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHORS BE LIABLE FOR\n// ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES\n// WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN\n// ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF\n// OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n\n//! untrusted.rs: Safe, fast, zero-panic, zero-crashing, zero-allocation\n//! parsing of untrusted inputs in Rust.\n//!\n//! <code>git clone https://github.com/briansmith/untrusted</code>\n//!\n//! untrusted.rs goes beyond Rust's normal safety guarantees by  also\n//! guaranteeing that parsing will be panic-free, as long as\n//! `untrusted::Input::as_slice_less_safe()` is not used. It avoids copying\n//! data and heap allocation and strives to prevent common pitfalls such as\n//! accidentally parsing input bytes multiple times. In order to meet these\n//! goals, untrusted.rs is limited in functionality such that it works best for\n//! input languages with a small fixed amount of lookahead such as ASN.1, TLS,\n//! TCP/IP, and many other networking, IPC, and related protocols. Languages\n//! that require more lookahead and/or backtracking require some significant\n//! contortions to parse using this framework. It would not be realistic to use\n//! it for parsing programming language code, for example.\n//!\n//! The overall pattern for using untrusted.rs is:\n//!\n//! 1. Write a recursive-descent-style parser for the input language, where the\n//!    input data is given as a `&mut untrusted::Reader` parameter to each\n//!    function. Each function should have a return type of `Result<V, E>` for\n//!    some value type `V` and some error type `E`, either or both of which may\n//!    be `()`. Functions for parsing the lowest-level language constructs\n//!    should be defined. Those lowest-level functions will parse their inputs\n//!    using `::read_byte()`, `Reader::peek()`, and similar functions.\n//!    Higher-level language constructs are then parsed by calling the\n//!    lower-level functions in sequence.\n//!\n//! 2. Wrap the top-most functions of your recursive-descent parser in\n//!    functions that take their input data as an `untrusted::Input`. The\n//!    wrapper functions should call the `Input`'s `read_all` (or a variant\n//!    thereof) method. The wrapper functions are the only ones that should be\n//!    exposed outside the parser's module.\n//!\n//! 3. After receiving the input data to parse, wrap it in an `untrusted::Input`\n//!    using `untrusted::Input::from()` as early as possible. Pass the\n//!    `untrusted::Input` to the wrapper functions when they need to be parsed.\n//!\n//! In general parsers built using `untrusted::Reader` do not need to explicitly\n//! check for end-of-input unless they are parsing optional constructs, because\n//! `Reader::read_byte()` will return `Err(EndOfInput)` on end-of-input.\n//! Similarly, parsers using `untrusted::Reader` generally don't need to check\n//! for extra junk at the end of the input as long as the parser's API uses the\n//! pattern described above, as `read_all` and its variants automatically check\n//! for trailing junk. `Reader::skip_to_end()` must be used when any remaining\n//! unread input should be ignored without triggering an error.\n//!\n//! untrusted.rs works best when all processing of the input data is done\n//! through the `untrusted::Input` and `untrusted::Reader` types. In\n//! particular, avoid trying to parse input data using functions that take\n//! byte slices. However, when you need to access a part of the input data as\n//! a slice to use a function that isn't written using untrusted.rs,\n//! `Input::as_slice_less_safe()` can be used.\n//!\n//! It is recommend to use `use untrusted;` and then `untrusted::Input`,\n//! `untrusted::Reader`, etc., instead of using `use untrusted::*`. Qualifying\n//! the names with `untrusted` helps remind the reader of the code that it is\n//! dealing with *untrusted* input.\n//!\n//! # Examples\n//!\n//! [*ring*](https://github.com/briansmith/ring)'s parser for the subset of\n//! ASN.1 DER it needs to understand,\n//! [`ring::der`](https://github.com/briansmith/ring/blob/master/src/der.rs),\n//! is built on top of untrusted.rs. *ring* also uses untrusted.rs to parse ECC\n//! public keys, RSA PKCS#1 1.5 padding, and for all other parsing it does.\n//!\n//! All of [webpki](https://github.com/briansmith/webpki)'s parsing of X.509\n//! certificates (also ASN.1 DER) is done using untrusted.rs.\n\n#![doc(html_root_url=\"https://briansmith.org/rustdoc/\")]\n\n#![allow(\n    missing_copy_implementations,\n    missing_debug_implementations,\n)]\n\n// `#[derive(...)]` uses `#[allow(unused_qualifications)]` internally.\n#![deny(\n    unused_qualifications,\n)]\n\n#![forbid(\n    anonymous_parameters,\n    box_pointers,\n    legacy_directory_ownership,\n    missing_docs,\n    trivial_casts,\n    trivial_numeric_casts,\n    unsafe_code,\n    unstable_features,\n    unused_extern_crates,\n    unused_import_braces,\n    unused_results,\n    variant_size_differences,\n    warnings,\n)]\n\n#![no_std]\n\n/// A wrapper around `&'a [u8]` that helps in writing panic-free code.\n///\n/// No methods of `Input` will ever panic.\n#[derive(Clone, Copy, Debug, Eq)]\npub struct Input<'a> {\n    value: no_panic::Slice<'a>\n}\n\nimpl<'a> Input<'a> {\n    /// Construct a new `Input` for the given input `bytes`.\n    pub fn from(bytes: &'a [u8]) -> Input<'a> {\n        // This limit is important for avoiding integer overflow. In particular,\n        // `Reader` assumes that an `i + 1 > i` if `input.value.get(i)` does\n        // not return `None`. According to the Rust language reference, the\n        // maximum object size is `core::isize::MAX`, and in practice it is\n        // impossible to create an object of size `core::usize::MAX` or larger.\n        debug_assert!(bytes.len() < core::usize::MAX);\n        Input { value: no_panic::Slice::new(bytes) }\n    }\n\n    /// Returns `true` if the input is empty and false otherwise.\n    #[inline]\n    pub fn is_empty(&self) -> bool { self.value.is_empty() }\n\n    /// Returns an iterator over the input.\n    #[inline]\n    pub fn iter(&self) -> <&[u8] as IntoIterator>::IntoIter {\n        self.value.iter()\n    }\n\n    /// Returns the length of the `Input`.\n    #[inline]\n    pub fn len(&self) -> usize { self.value.len() }\n\n    /// Calls `read` with the given input as a `Reader`, ensuring that `read`\n    /// consumed the entire input. If `read` does not consume the entire input,\n    /// `incomplete_read` is returned.\n    pub fn read_all<F, R, E>(&self, incomplete_read: E, read: F)\n                             -> Result<R, E>\n                             where F: FnOnce(&mut Reader<'a>) -> Result<R, E> {\n        let mut input = Reader::new(*self);\n        let result = try!(read(&mut input));\n        if input.at_end() {\n            Ok(result)\n        } else {\n            Err(incomplete_read)\n        }\n    }\n\n    /// Like `read_all`, except taking an `FnMut`.\n    pub fn read_all_mut<F, R, E>(&self, incomplete_read: E, mut read: F)\n                                 -> Result<R, E>\n                                 where F: FnMut(&mut Reader<'a>)\n                                                -> Result<R, E> {\n        let mut input = Reader::new(*self);\n        let result = try!(read(&mut input));\n        if input.at_end() {\n            Ok(result)\n        } else {\n            Err(incomplete_read)\n        }\n    }\n\n    /// Access the input as a slice so it can be processed by functions that\n    /// are not written using the Input/Reader framework.\n    #[inline]\n    pub fn as_slice_less_safe(&self) -> &'a [u8] {\n        self.value.as_slice_less_safe()\n    }\n}\n\n// #[derive(PartialEq)] would result in lifetime bounds that are\n// unnecessarily restrictive; see\n// https://github.com/rust-lang/rust/issues/27950.\nimpl<'a, 'b> PartialEq<Input<'b>> for Input<'a> {\n    #[inline]\n    fn eq(&self, other: &Input<'b>) -> bool {\n        self.as_slice_less_safe() == other.as_slice_less_safe()\n    }\n}\n\n// https://github.com/rust-lang/rust/issues/27950\nimpl <'a, 'b> PartialEq<&'b [u8]> for Input<'a> {\n    #[inline]\n    fn eq(&self, other: &&[u8]) -> bool {\n        self.as_slice_less_safe() == *other\n    }\n}\n\n\n/// Calls `read` with the given input as a `Reader`, ensuring that `read`\n/// consumed the entire input. When `input` is `None`, `read` will be\n/// called with `None`.\npub fn read_all_optional<F, R, E>(input: Option<Input>,\n                                  incomplete_read: E, read: F)\n                                  -> Result<R, E>\n                                  where F: FnOnce(Option<&mut Reader>)\n                                                  -> Result<R, E> {\n    match input {\n        Some(input) => {\n            let mut input = Reader::new(input);\n            let result = try!(read(Some(&mut input)));\n            if input.at_end() {\n                Ok(result)\n            } else {\n                Err(incomplete_read)\n            }\n        },\n        None => read(None)\n    }\n}\n\n\n/// A read-only, forward-only* cursor into the data in an `Input`.\n///\n/// Using `Reader` to parse input helps to ensure that no byte of the input\n/// will be accidentally processed more than once. Using `Reader` in\n/// conjunction with `read_all`, `read_all_mut`, and `read_all_optional`\n/// helps ensure that no byte of the input is accidentally left unprocessed.\n/// The methods of `Reader` never panic, so `Reader` also assists the writing\n/// of panic-free code.\n///\n/// \\* `Reader` is not strictly forward-only because of the method\n/// `get_input_between_marks`, which is provided mainly to support calculating\n/// digests over parsed data.\n#[derive(Debug)]\npub struct Reader<'a> {\n    input: no_panic::Slice<'a>,\n    i: usize\n}\n\n/// An index into the already-parsed input of a `Reader`.\npub struct Mark {\n    i: usize\n}\n\nimpl<'a> Reader<'a> {\n    /// Construct a new Reader for the given input. Use `read_all`,\n    /// `read_all_mut`, or `read_all_optional` instead of `Reader::new`\n    /// whenever possible.\n    #[inline]\n    pub fn new(input: Input<'a>) -> Reader<'a> {\n        Reader { input: input.value, i: 0 }\n    }\n\n    /// Returns `true` if the reader is at the end of the input, and `false`\n    /// otherwise.\n    #[inline]\n    pub fn at_end(&self) -> bool { self.i == self.input.len() }\n\n    /// Returns an `Input` for already-parsed input that has had its boundaries\n    /// marked using `mark`.\n    #[inline]\n    pub fn get_input_between_marks(&self, mark1: Mark, mark2: Mark)\n                                   -> Result<Input<'a>, EndOfInput> {\n        self.input.get_slice(mark1.i..mark2.i)\n                  .map(|subslice| Input { value: subslice })\n                  .ok_or(EndOfInput)\n    }\n\n    /// Return the current position of the `Reader` for future use in a call\n    /// to `get_input_between_marks`.\n    #[inline]\n    pub fn mark(&self) -> Mark { Mark { i: self.i } }\n\n    /// Returns `true` if there is at least one more byte in the input and that\n    /// byte is equal to `b`, and false otherwise.\n    pub fn peek(&self, b: u8) -> bool {\n        match self.input.get(self.i) {\n            Some(actual_b) => b == *actual_b,\n            None => false\n        }\n    }\n\n    /// Reads the next input byte.\n    ///\n    /// Returns `Ok(b)` where `b` is the next input byte, or `Err(EndOfInput)`\n    /// if the `Reader` is at the end of the input.\n    pub fn read_byte(&mut self) -> Result<u8, EndOfInput> {\n        match self.input.get(self.i) {\n            Some(b) => {\n                self.i += 1; // safe from overflow; see Input::from().\n                Ok(*b)\n            }\n            None => Err(EndOfInput)\n        }\n    }\n\n    /// Skips `num_bytes` of the input.\n    ///\n    /// Returns `Ok(())` if there are at least `num_bytes` of input remaining,\n    /// and `Err(EndOfInput)` otherwise.\n    pub fn skip(&mut self, num_bytes: usize) -> Result<(), EndOfInput> {\n        self.skip_and_get_input(num_bytes).map(|_| ())\n    }\n\n    /// Skips `num_bytes` of the input, returning the skipped input as an `Input`.\n    ///\n    /// Returns `Ok(i)` where `i` is an `Input` if there are at least\n    /// `num_bytes` of input remaining, and `Err(EndOfInput)` otherwise.\n    pub fn skip_and_get_input(&mut self, num_bytes: usize)\n                              -> Result<Input<'a>, EndOfInput> {\n        let new_i = try!(self.i.checked_add(num_bytes).ok_or(EndOfInput));\n        let ret = self.input.get_slice(self.i..new_i)\n                            .map(|subslice| Input { value: subslice })\n                            .ok_or(EndOfInput);\n        self.i = new_i;\n        ret\n    }\n\n    /// Skips the reader to the end of the input, returning the skipped input\n    /// as an `Input`.\n    pub fn skip_to_end(&mut self) -> Input<'a> {\n        let to_skip = self.input.len() - self.i;\n        self.skip_and_get_input(to_skip).unwrap()\n    }\n}\n\n/// The error type used to indicate the end of the input was reached before the\n/// operation could be completed.\n#[derive(Clone, Copy, Debug, Eq, PartialEq)]\npub struct EndOfInput;\n\nmod no_panic {\n    use core;\n\n    /// A wrapper around a slice that exposes no functions that can panic.\n    #[derive(Clone, Copy, Debug, Eq, PartialEq)]\n    pub struct Slice<'a> {\n        bytes: &'a [u8]\n    }\n\n    impl<'a> Slice<'a> {\n        #[inline]\n        pub fn new(bytes: &'a [u8]) -> Slice<'a> {\n            Slice { bytes }\n        }\n\n        #[inline]\n        // TODO: https://github.com/rust-lang/rust/issues/35729#issuecomment-280872145\n        //      pub fn get<I>(&self, i: I) -> Option<&I::Output>\n        //          where I: core::slice::SliceIndex<u8>\n        pub fn get(&self, i: usize) -> Option<&u8> { self.bytes.get(i) }\n\n        // TODO: This will be replaced with `get()` once `get()` is made\n        // generic over `SliceIndex`.\n        #[inline]\n        pub fn get_slice(&self, r: core::ops::Range<usize>)\n                         -> Option<Slice<'a>> {\n            self.bytes.get(r).map(|bytes| Slice { bytes })\n        }\n\n        #[inline]\n        pub fn iter(&self) -> <&'a [u8] as IntoIterator>::IntoIter {\n            self.bytes.into_iter()\n        }\n\n        #[inline]\n        pub fn is_empty(&self) -> bool { self.bytes.is_empty() }\n\n        #[inline]\n        pub fn len(&self) -> usize { self.bytes.len() }\n\n        #[inline]\n        pub fn as_slice_less_safe(&self) -> &'a [u8] { self.bytes }\n    }\n\n} // mod no_panic\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_input_from() {\n        let _ = Input::from(b\"foo\");\n    }\n\n    #[test]\n    fn test_input_is_empty() {\n        let input = Input::from(b\"\");\n        assert!(input.is_empty());\n        let input = Input::from(b\"foo\");\n        assert!(!input.is_empty());\n    }\n\n    #[test]\n    fn test_input_len() {\n        let input = Input::from(b\"foo\");\n        assert_eq!(input.len(), 3);\n    }\n\n    #[test]\n    fn test_input_read_all() {\n        let input = Input::from(b\"foo\");\n        let result = input.read_all(EndOfInput, |input| {\n            assert_eq!(b'f', try!(input.read_byte()));\n            assert_eq!(b'o', try!(input.read_byte()));\n            assert_eq!(b'o', try!(input.read_byte()));\n            assert!(input.at_end());\n            Ok(())\n        });\n        assert_eq!(result, Ok(()));\n    }\n\n    #[test]\n    fn test_input_read_all_unconsume() {\n        let input = Input::from(b\"foo\");\n        let result = input.read_all(EndOfInput, |input| {\n            assert_eq!(b'f', try!(input.read_byte()));\n            assert!(!input.at_end());\n            Ok(())\n        });\n        assert_eq!(result, Err(EndOfInput));\n    }\n\n    #[test]\n    fn test_input_as_slice_less_safe() {\n        let slice = b\"foo\";\n        let input = Input::from(slice);\n        assert_eq!(input.as_slice_less_safe(), slice);\n    }\n\n    #[test]\n    fn test_input_as_iterator() {\n        let slice = b\"foo\";\n        let input = Input::from(slice);\n        let mut iter = input.iter();\n        assert_eq!(Some(&b'f'), iter.next());\n        assert_eq!(Some(&b'o'), iter.next());\n        assert_eq!(Some(&b'o'), iter.next());\n        assert_eq!(None, iter.next());\n    }\n}\n"
  },
  {
    "project": "lettre",
    "target": 1,
    "commit_id": "1d8249165cdda87611ea243023f7f4eb405e4112",
    "func": "//! SMTP client\n//!\n//! `SmtpConnection` allows manually sending SMTP commands.\n//!\n//! ```rust,no_run\n//! # use std::error::Error;\n//!\n//! # #[cfg(feature = \"smtp-transport\")]\n//! # fn main() -> Result<(), Box<dyn Error>> {\n//! use lettre::transport::smtp::{SMTP_PORT, extension::ClientId, commands::*, client::SmtpConnection};\n//!\n//! let hello = ClientId::Domain(\"my_hostname\".to_string());\n//! let mut client = SmtpConnection::connect(&(\"localhost\", SMTP_PORT), None, &hello, None)?;\n//! client.command(\n//!         Mail::new(Some(\"user@example.com\".parse()?), vec![])\n//!     )?;\n//! client.command(\n//!         Rcpt::new(\"user@example.org\".parse()?, vec![])\n//!       )?;\n//! client.command(Data)?;\n//! client.message(\"Test email\".as_bytes())?;\n//! client.command(Quit)?;\n//! # Ok(())\n//! # }\n//! ```\n\n#[cfg(feature = \"serde\")]\nuse std::fmt::Debug;\n\n#[cfg(any(feature = \"tokio1\", feature = \"async-std1\"))]\npub(crate) use self::async_connection::AsyncSmtpConnection;\n#[cfg(any(feature = \"tokio1\", feature = \"async-std1\"))]\npub(crate) use self::async_net::AsyncNetworkStream;\nuse self::net::NetworkStream;\n#[cfg(any(feature = \"native-tls\", feature = \"rustls-tls\"))]\npub(super) use self::tls::InnerTlsParameters;\npub use self::{\n    connection::SmtpConnection,\n    tls::{Certificate, Tls, TlsParameters, TlsParametersBuilder},\n};\n\n#[cfg(any(feature = \"tokio1\", feature = \"async-std1\"))]\nmod async_connection;\n#[cfg(any(feature = \"tokio1\", feature = \"async-std1\"))]\nmod async_net;\nmod connection;\nmod net;\nmod tls;\n\n/// The codec used for transparency\n#[derive(Default, Clone, Copy, Debug)]\n#[cfg_attr(feature = \"serde\", derive(serde::Serialize, serde::Deserialize))]\nstruct ClientCodec {\n    escape_count: u8,\n}\n\nimpl ClientCodec {\n    /// Creates a new client codec\n    pub fn new() -> Self {\n        ClientCodec::default()\n    }\n\n    /// Adds transparency\n    fn encode(&mut self, frame: &[u8], buf: &mut Vec<u8>) {\n        match frame.len() {\n            0 => {\n                match self.escape_count {\n                    0 => buf.extend_from_slice(b\"\\r\\n.\\r\\n\"),\n                    1 => buf.extend_from_slice(b\"\\n.\\r\\n\"),\n                    2 => buf.extend_from_slice(b\".\\r\\n\"),\n                    _ => unreachable!(),\n                }\n                self.escape_count = 0;\n            }\n            _ => {\n                let mut start = 0;\n                for (idx, byte) in frame.iter().enumerate() {\n                    match self.escape_count {\n                        0 => self.escape_count = if *byte == b'\\r' { 1 } else { 0 },\n                        1 => self.escape_count = if *byte == b'\\n' { 2 } else { 0 },\n                        2 => self.escape_count = if *byte == b'.' { 3 } else { 0 },\n                        _ => unreachable!(),\n                    }\n                    if self.escape_count == 3 {\n                        self.escape_count = 0;\n                        buf.extend_from_slice(&frame[start..idx]);\n                        buf.extend_from_slice(b\".\");\n                        start = idx;\n                    }\n                }\n                buf.extend_from_slice(&frame[start..]);\n            }\n        }\n    }\n}\n\n/// Returns the string replacing all the CRLF with \"\\<CRLF\\>\"\n/// Used for debug displays\n#[cfg(feature = \"tracing\")]\npub(super) fn escape_crlf(string: &str) -> String {\n    string.replace(\"\\r\\n\", \"<CRLF>\")\n}\n\n#[cfg(test)]\nmod test {\n    use super::*;\n\n    #[test]\n    fn test_codec() {\n        let mut codec = ClientCodec::new();\n        let mut buf: Vec<u8> = vec![];\n\n        codec.encode(b\"test\\r\\n\", &mut buf);\n        codec.encode(b\".\\r\\n\", &mut buf);\n        codec.encode(b\"\\r\\ntest\", &mut buf);\n        codec.encode(b\"te\\r\\n.\\r\\nst\", &mut buf);\n        codec.encode(b\"test\", &mut buf);\n        codec.encode(b\"test.\", &mut buf);\n        codec.encode(b\"test\\n\", &mut buf);\n        codec.encode(b\".test\\n\", &mut buf);\n        codec.encode(b\"test\", &mut buf);\n        assert_eq!(\n            String::from_utf8(buf).unwrap(),\n            \"test\\r\\n..\\r\\n\\r\\ntestte\\r\\n..\\r\\nsttesttest.test\\n.test\\ntest\"\n        );\n    }\n\n    #[test]\n    #[cfg(feature = \"log\")]\n    fn test_escape_crlf() {\n        assert_eq!(escape_crlf(\"\\r\\n\"), \"<CRLF>\");\n        assert_eq!(escape_crlf(\"EHLO my_name\\r\\n\"), \"EHLO my_name<CRLF>\");\n        assert_eq!(\n            escape_crlf(\"EHLO my_name\\r\\nSIZE 42\\r\\n\"),\n            \"EHLO my_name<CRLF>SIZE 42<CRLF>\"\n        );\n    }\n}\n"
  },
  {
    "project": "crossbeam",
    "target": 1,
    "commit_id": "0e91b789483fbfa88207988e600c794f74499d12",
    "func": "//! Unbounded channel implemented as a linked list.\n\nuse std::cell::UnsafeCell;\nuse std::marker::PhantomData;\nuse std::mem::{self, ManuallyDrop};\nuse std::ptr;\nuse std::sync::atomic::{self, AtomicPtr, AtomicUsize, Ordering};\nuse std::time::Instant;\n\nuse crossbeam_utils::{Backoff, CachePadded};\n\nuse context::Context;\nuse err::{RecvTimeoutError, SendTimeoutError, TryRecvError, TrySendError};\nuse select::{Operation, SelectHandle, Selected, Token};\nuse waker::SyncWaker;\n\n// TODO(stjepang): Once we bump the minimum required Rust version to 1.28 or newer, re-apply the\n// following changes by @kleimkuhler:\n//\n// 1. https://github.com/crossbeam-rs/crossbeam-channel/pull/100\n// 2. https://github.com/crossbeam-rs/crossbeam-channel/pull/101\n\n// Bits indicating the state of a slot:\n// * If a message has been written into the slot, `WRITE` is set.\n// * If a message has been read from the slot, `READ` is set.\n// * If the block is being destroyed, `DESTROY` is set.\nconst WRITE: usize = 1;\nconst READ: usize = 2;\nconst DESTROY: usize = 4;\n\n// Each block covers one \"lap\" of indices.\nconst LAP: usize = 32;\n// The maximum number of messages a block can hold.\nconst BLOCK_CAP: usize = LAP - 1;\n// How many lower bits are reserved for metadata.\nconst SHIFT: usize = 1;\n// Has two different purposes:\n// * If set in head, indicates that the block is not the last one.\n// * If set in tail, indicates that the channel is disconnected.\nconst MARK_BIT: usize = 1;\n\n/// A slot in a block.\nstruct Slot<T> {\n    /// The message.\n    msg: UnsafeCell<ManuallyDrop<T>>,\n\n    /// The state of the slot.\n    state: AtomicUsize,\n}\n\nimpl<T> Slot<T> {\n    /// Waits until a message is written into the slot.\n    fn wait_write(&self) {\n        let backoff = Backoff::new();\n        while self.state.load(Ordering::Acquire) & WRITE == 0 {\n            backoff.snooze();\n        }\n    }\n}\n\n/// A block in a linked list.\n///\n/// Each block in the list can hold up to `BLOCK_CAP` messages.\nstruct Block<T> {\n    /// The next block in the linked list.\n    next: AtomicPtr<Block<T>>,\n\n    /// Slots for messages.\n    slots: [Slot<T>; BLOCK_CAP],\n}\n\nimpl<T> Block<T> {\n    /// Creates an empty block.\n    fn new() -> Block<T> {\n        unsafe { mem::zeroed() }\n    }\n\n    /// Waits until the next pointer is set.\n    fn wait_next(&self) -> *mut Block<T> {\n        let backoff = Backoff::new();\n        loop {\n            let next = self.next.load(Ordering::Acquire);\n            if !next.is_null() {\n                return next;\n            }\n            backoff.snooze();\n        }\n    }\n\n    /// Sets the `DESTROY` bit in slots starting from `start` and destroys the block.\n    unsafe fn destroy(this: *mut Block<T>, start: usize) {\n        // It is not necessary to set the `DESTROY bit in the last slot because that slot has begun\n        // destruction of the block.\n        for i in start..BLOCK_CAP - 1 {\n            let slot = (*this).slots.get_unchecked(i);\n\n            // Mark the `DESTROY` bit if a thread is still using the slot.\n            if slot.state.load(Ordering::Acquire) & READ == 0\n                && slot.state.fetch_or(DESTROY, Ordering::AcqRel) & READ == 0\n            {\n                // If a thread is still using the slot, it will continue destruction of the block.\n                return;\n            }\n        }\n\n        // No thread is using the block, now it is safe to destroy it.\n        drop(Box::from_raw(this));\n    }\n}\n\n/// A position in a channel.\n#[derive(Debug)]\nstruct Position<T> {\n    /// The index in the channel.\n    index: AtomicUsize,\n\n    /// The block in the linked list.\n    block: AtomicPtr<Block<T>>,\n}\n\n/// The token type for the list flavor.\n#[derive(Debug)]\npub struct ListToken {\n    /// The block of slots.\n    block: *const u8,\n\n    /// The offset into the block.\n    offset: usize,\n}\n\nimpl Default for ListToken {\n    #[inline]\n    fn default() -> Self {\n        ListToken {\n            block: ptr::null(),\n            offset: 0,\n        }\n    }\n}\n\n/// Unbounded channel implemented as a linked list.\n///\n/// Each message sent into the channel is assigned a sequence number, i.e. an index. Indices are\n/// represented as numbers of type `usize` and wrap on overflow.\n///\n/// Consecutive messages are grouped into blocks in order to put less pressure on the allocator and\n/// improve cache efficiency.\npub struct Channel<T> {\n    /// The head of the channel.\n    head: CachePadded<Position<T>>,\n\n    /// The tail of the channel.\n    tail: CachePadded<Position<T>>,\n\n    /// Receivers waiting while the channel is empty and not disconnected.\n    receivers: SyncWaker,\n\n    /// Indicates that dropping a `Channel<T>` may drop messages of type `T`.\n    _marker: PhantomData<T>,\n}\n\nimpl<T> Channel<T> {\n    /// Creates a new unbounded channel.\n    pub fn new() -> Self {\n        Channel {\n            head: CachePadded::new(Position {\n                block: AtomicPtr::new(ptr::null_mut()),\n                index: AtomicUsize::new(0),\n            }),\n            tail: CachePadded::new(Position {\n                block: AtomicPtr::new(ptr::null_mut()),\n                index: AtomicUsize::new(0),\n            }),\n            receivers: SyncWaker::new(),\n            _marker: PhantomData,\n        }\n    }\n\n    /// Returns a receiver handle to the channel.\n    pub fn receiver(&self) -> Receiver<T> {\n        Receiver(self)\n    }\n\n    /// Returns a sender handle to the channel.\n    pub fn sender(&self) -> Sender<T> {\n        Sender(self)\n    }\n\n    /// Attempts to reserve a slot for sending a message.\n    fn start_send(&self, token: &mut Token) -> bool {\n        let backoff = Backoff::new();\n        let mut tail = self.tail.index.load(Ordering::Acquire);\n        let mut block = self.tail.block.load(Ordering::Acquire);\n        let mut next_block = None;\n\n        loop {\n            // Check if the channel is disconnected.\n            if tail & MARK_BIT != 0 {\n                token.list.block = ptr::null();\n                return true;\n            }\n\n            // Calculate the offset of the index into the block.\n            let offset = (tail >> SHIFT) % LAP;\n\n            // If we reached the end of the block, wait until the next one is installed.\n            if offset == BLOCK_CAP {\n                backoff.snooze();\n                tail = self.tail.index.load(Ordering::Acquire);\n                block = self.tail.block.load(Ordering::Acquire);\n                continue;\n            }\n\n            // If we're going to have to install the next block, allocate it in advance in order to\n            // make the wait for other threads as short as possible.\n            if offset + 1 == BLOCK_CAP && next_block.is_none() {\n                next_block = Some(Box::new(Block::<T>::new()));\n            }\n\n            // If this is the first message to be sent into the channel, we need to allocate the\n            // first block and install it.\n            if block.is_null() {\n                let new = Box::into_raw(Box::new(Block::<T>::new()));\n\n                if self\n                    .tail\n                    .block\n                    .compare_and_swap(block, new, Ordering::Release)\n                    == block\n                {\n                    self.head.block.store(new, Ordering::Release);\n                    block = new;\n                } else {\n                    next_block = unsafe { Some(Box::from_raw(new)) };\n                    tail = self.tail.index.load(Ordering::Acquire);\n                    block = self.tail.block.load(Ordering::Acquire);\n                    continue;\n                }\n            }\n\n            let new_tail = tail + (1 << SHIFT);\n\n            // Try advancing the tail forward.\n            match self.tail.index.compare_exchange_weak(\n                tail,\n                new_tail,\n                Ordering::SeqCst,\n                Ordering::Acquire,\n            ) {\n                Ok(_) => unsafe {\n                    // If we've reached the end of the block, install the next one.\n                    if offset + 1 == BLOCK_CAP {\n                        let next_block = Box::into_raw(next_block.unwrap());\n                        self.tail.block.store(next_block, Ordering::Release);\n                        self.tail.index.fetch_add(1 << SHIFT, Ordering::Release);\n                        (*block).next.store(next_block, Ordering::Release);\n                    }\n\n                    token.list.block = block as *const u8;\n                    token.list.offset = offset;\n                    return true;\n                },\n                Err(t) => {\n                    tail = t;\n                    block = self.tail.block.load(Ordering::Acquire);\n                    backoff.spin();\n                }\n            }\n        }\n    }\n\n    /// Writes a message into the channel.\n    pub unsafe fn write(&self, token: &mut Token, msg: T) -> Result<(), T> {\n        // If there is no slot, the channel is disconnected.\n        if token.list.block.is_null() {\n            return Err(msg);\n        }\n\n        // Write the message into the slot.\n        let block = token.list.block as *mut Block<T>;\n        let offset = token.list.offset;\n        let slot = (*block).slots.get_unchecked(offset);\n        slot.msg.get().write(ManuallyDrop::new(msg));\n        slot.state.fetch_or(WRITE, Ordering::Release);\n\n        // Wake a sleeping receiver.\n        self.receivers.notify();\n        Ok(())\n    }\n\n    /// Attempts to reserve a slot for receiving a message.\n    fn start_recv(&self, token: &mut Token) -> bool {\n        let backoff = Backoff::new();\n        let mut head = self.head.index.load(Ordering::Acquire);\n        let mut block = self.head.block.load(Ordering::Acquire);\n\n        loop {\n            // Calculate the offset of the index into the block.\n            let offset = (head >> SHIFT) % LAP;\n\n            // If we reached the end of the block, wait until the next one is installed.\n            if offset == BLOCK_CAP {\n                backoff.snooze();\n                head = self.head.index.load(Ordering::Acquire);\n                block = self.head.block.load(Ordering::Acquire);\n                continue;\n            }\n\n            let mut new_head = head + (1 << SHIFT);\n\n            if new_head & MARK_BIT == 0 {\n                atomic::fence(Ordering::SeqCst);\n                let tail = self.tail.index.load(Ordering::Relaxed);\n\n                // If the tail equals the head, that means the channel is empty.\n                if head >> SHIFT == tail >> SHIFT {\n                    // If the channel is disconnected...\n                    if tail & MARK_BIT != 0 {\n                        // ...then receive an error.\n                        token.list.block = ptr::null();\n                        return true;\n                    } else {\n                        // Otherwise, the receive operation is not ready.\n                        return false;\n                    }\n                }\n\n                // If head and tail are not in the same block, set `MARK_BIT` in head.\n                if (head >> SHIFT) / LAP != (tail >> SHIFT) / LAP {\n                    new_head |= MARK_BIT;\n                }\n            }\n\n            // The block can be null here only if the first message is being sent into the channel.\n            // In that case, just wait until it gets initialized.\n            if block.is_null() {\n                backoff.snooze();\n                head = self.head.index.load(Ordering::Acquire);\n                block = self.head.block.load(Ordering::Acquire);\n                continue;\n            }\n\n            // Try moving the head index forward.\n            match self.head.index.compare_exchange_weak(\n                head,\n                new_head,\n                Ordering::SeqCst,\n                Ordering::Acquire,\n            ) {\n                Ok(_) => unsafe {\n                    // If we've reached the end of the block, move to the next one.\n                    if offset + 1 == BLOCK_CAP {\n                        let next = (*block).wait_next();\n                        let mut next_index = (new_head & !MARK_BIT).wrapping_add(1 << SHIFT);\n                        if !(*next).next.load(Ordering::Relaxed).is_null() {\n                            next_index |= MARK_BIT;\n                        }\n\n                        self.head.block.store(next, Ordering::Release);\n                        self.head.index.store(next_index, Ordering::Release);\n                    }\n\n                    token.list.block = block as *const u8;\n                    token.list.offset = offset;\n                    return true;\n                },\n                Err(h) => {\n                    head = h;\n                    block = self.head.block.load(Ordering::Acquire);\n                    backoff.spin();\n                }\n            }\n        }\n    }\n\n    /// Reads a message from the channel.\n    pub unsafe fn read(&self, token: &mut Token) -> Result<T, ()> {\n        if token.list.block.is_null() {\n            // The channel is disconnected.\n            return Err(());\n        }\n\n        // Read the message.\n        let block = token.list.block as *mut Block<T>;\n        let offset = token.list.offset;\n        let slot = (*block).slots.get_unchecked(offset);\n        slot.wait_write();\n        let m = slot.msg.get().read();\n        let msg = ManuallyDrop::into_inner(m);\n\n        // Destroy the block if we've reached the end, or if another thread wanted to destroy but\n        // couldn't because we were busy reading from the slot.\n        if offset + 1 == BLOCK_CAP {\n            Block::destroy(block, 0);\n        } else if slot.state.fetch_or(READ, Ordering::AcqRel) & DESTROY != 0 {\n            Block::destroy(block, offset + 1);\n        }\n\n        Ok(msg)\n    }\n\n    /// Attempts to send a message into the channel.\n    pub fn try_send(&self, msg: T) -> Result<(), TrySendError<T>> {\n        self.send(msg, None).map_err(|err| match err {\n            SendTimeoutError::Disconnected(msg) => TrySendError::Disconnected(msg),\n            SendTimeoutError::Timeout(_) => unreachable!(),\n        })\n    }\n\n    /// Sends a message into the channel.\n    pub fn send(&self, msg: T, _deadline: Option<Instant>) -> Result<(), SendTimeoutError<T>> {\n        let token = &mut Token::default();\n        assert!(self.start_send(token));\n        unsafe {\n            self.write(token, msg)\n                .map_err(SendTimeoutError::Disconnected)\n        }\n    }\n\n    /// Attempts to receive a message without blocking.\n    pub fn try_recv(&self) -> Result<T, TryRecvError> {\n        let token = &mut Token::default();\n\n        if self.start_recv(token) {\n            unsafe { self.read(token).map_err(|_| TryRecvError::Disconnected) }\n        } else {\n            Err(TryRecvError::Empty)\n        }\n    }\n\n    /// Receives a message from the channel.\n    pub fn recv(&self, deadline: Option<Instant>) -> Result<T, RecvTimeoutError> {\n        let token = &mut Token::default();\n        loop {\n            // Try receiving a message several times.\n            let backoff = Backoff::new();\n            loop {\n                if self.start_recv(token) {\n                    unsafe {\n                        return self.read(token).map_err(|_| RecvTimeoutError::Disconnected);\n                    }\n                }\n\n                if backoff.is_completed() {\n                    break;\n                } else {\n                    backoff.snooze();\n                }\n            }\n\n            if let Some(d) = deadline {\n                if Instant::now() >= d {\n                    return Err(RecvTimeoutError::Timeout);\n                }\n            }\n\n            // Prepare for blocking until a sender wakes us up.\n            Context::with(|cx| {\n                let oper = Operation::hook(token);\n                self.receivers.register(oper, cx);\n\n                // Has the channel become ready just now?\n                if !self.is_empty() || self.is_disconnected() {\n                    let _ = cx.try_select(Selected::Aborted);\n                }\n\n                // Block the current thread.\n                let sel = cx.wait_until(deadline);\n\n                match sel {\n                    Selected::Waiting => unreachable!(),\n                    Selected::Aborted | Selected::Disconnected => {\n                        self.receivers.unregister(oper).unwrap();\n                        // If the channel was disconnected, we still have to check for remaining\n                        // messages.\n                    }\n                    Selected::Operation(_) => {}\n                }\n            });\n        }\n    }\n\n    /// Returns the current number of messages inside the channel.\n    pub fn len(&self) -> usize {\n        loop {\n            // Load the tail index, then load the head index.\n            let mut tail = self.tail.index.load(Ordering::SeqCst);\n            let mut head = self.head.index.load(Ordering::SeqCst);\n\n            // If the tail index didn't change, we've got consistent indices to work with.\n            if self.tail.index.load(Ordering::SeqCst) == tail {\n                // Erase the lower bits.\n                tail &= !((1 << SHIFT) - 1);\n                head &= !((1 << SHIFT) - 1);\n\n                // Rotate indices so that head falls into the first block.\n                let lap = (head >> SHIFT) / LAP;\n                tail = tail.wrapping_sub((lap * LAP) << SHIFT);\n                head = head.wrapping_sub((lap * LAP) << SHIFT);\n\n                // Remove the lower bits.\n                tail >>= SHIFT;\n                head >>= SHIFT;\n\n                // Fix up indices if they fall onto block ends.\n                if head == BLOCK_CAP {\n                    head = 0;\n                    tail -= LAP;\n                }\n                if tail == BLOCK_CAP {\n                    tail += 1;\n                }\n\n                // Return the difference minus the number of blocks between tail and head.\n                return tail - head - tail / LAP;\n            }\n        }\n    }\n\n    /// Returns the capacity of the channel.\n    pub fn capacity(&self) -> Option<usize> {\n        None\n    }\n\n    /// Disconnects the channel and wakes up all blocked receivers.\n    ///\n    /// Returns `true` if this call disconnected the channel.\n    pub fn disconnect(&self) -> bool {\n        let tail = self.tail.index.fetch_or(MARK_BIT, Ordering::SeqCst);\n\n        if tail & MARK_BIT == 0 {\n            self.receivers.disconnect();\n            true\n        } else {\n            false\n        }\n    }\n\n    /// Returns `true` if the channel is disconnected.\n    pub fn is_disconnected(&self) -> bool {\n        self.tail.index.load(Ordering::SeqCst) & MARK_BIT != 0\n    }\n\n    /// Returns `true` if the channel is empty.\n    pub fn is_empty(&self) -> bool {\n        let head = self.head.index.load(Ordering::SeqCst);\n        let tail = self.tail.index.load(Ordering::SeqCst);\n        head >> SHIFT == tail >> SHIFT\n    }\n\n    /// Returns `true` if the channel is full.\n    pub fn is_full(&self) -> bool {\n        false\n    }\n}\n\nimpl<T> Drop for Channel<T> {\n    fn drop(&mut self) {\n        let mut head = self.head.index.load(Ordering::Relaxed);\n        let mut tail = self.tail.index.load(Ordering::Relaxed);\n        let mut block = self.head.block.load(Ordering::Relaxed);\n\n        // Erase the lower bits.\n        head &= !((1 << SHIFT) - 1);\n        tail &= !((1 << SHIFT) - 1);\n\n        unsafe {\n            // Drop all messages between head and tail and deallocate the heap-allocated blocks.\n            while head != tail {\n                let offset = (head >> SHIFT) % LAP;\n\n                if offset < BLOCK_CAP {\n                    // Drop the message in the slot.\n                    let slot = (*block).slots.get_unchecked(offset);\n                    ManuallyDrop::drop(&mut *(*slot).msg.get());\n                } else {\n                    // Deallocate the block and move to the next one.\n                    let next = (*block).next.load(Ordering::Relaxed);\n                    drop(Box::from_raw(block));\n                    block = next;\n                }\n\n                head = head.wrapping_add(1 << SHIFT);\n            }\n\n            // Deallocate the last remaining block.\n            if !block.is_null() {\n                drop(Box::from_raw(block));\n            }\n        }\n    }\n}\n\n/// Receiver handle to a channel.\npub struct Receiver<'a, T: 'a>(&'a Channel<T>);\n\n/// Sender handle to a channel.\npub struct Sender<'a, T: 'a>(&'a Channel<T>);\n\nimpl<'a, T> SelectHandle for Receiver<'a, T> {\n    fn try_select(&self, token: &mut Token) -> bool {\n        self.0.start_recv(token)\n    }\n\n    fn deadline(&self) -> Option<Instant> {\n        None\n    }\n\n    fn register(&self, oper: Operation, cx: &Context) -> bool {\n        self.0.receivers.register(oper, cx);\n        self.is_ready()\n    }\n\n    fn unregister(&self, oper: Operation) {\n        self.0.receivers.unregister(oper);\n    }\n\n    fn accept(&self, token: &mut Token, _cx: &Context) -> bool {\n        self.try_select(token)\n    }\n\n    fn is_ready(&self) -> bool {\n        !self.0.is_empty() || self.0.is_disconnected()\n    }\n\n    fn watch(&self, oper: Operation, cx: &Context) -> bool {\n        self.0.receivers.watch(oper, cx);\n        self.is_ready()\n    }\n\n    fn unwatch(&self, oper: Operation) {\n        self.0.receivers.unwatch(oper);\n    }\n}\n\nimpl<'a, T> SelectHandle for Sender<'a, T> {\n    fn try_select(&self, token: &mut Token) -> bool {\n        self.0.start_send(token)\n    }\n\n    fn deadline(&self) -> Option<Instant> {\n        None\n    }\n\n    fn register(&self, _oper: Operation, _cx: &Context) -> bool {\n        self.is_ready()\n    }\n\n    fn unregister(&self, _oper: Operation) {}\n\n    fn accept(&self, token: &mut Token, _cx: &Context) -> bool {\n        self.try_select(token)\n    }\n\n    fn is_ready(&self) -> bool {\n        true\n    }\n\n    fn watch(&self, _oper: Operation, _cx: &Context) -> bool {\n        self.is_ready()\n    }\n\n    fn unwatch(&self, _oper: Operation) {}\n}\n"
  },
  {
    "project": "crossbeam",
    "target": 1,
    "commit_id": "7b35a3d17f5c5ec53f70576d4ca0e18be8ed289b",
    "func": "//! Concurrent work-stealing deques.\n//!\n//! These data structures are most commonly used in work-stealing schedulers. The typical setup\n//! involves a number of threads, each having its own FIFO or LIFO queue (*worker*). There is also\n//! one global FIFO queue (*injector*) and a list of references to *worker* queues that are able to\n//! steal tasks (*stealers*).\n//!\n//! We spawn a new task onto the scheduler by pushing it into the *injector* queue. Each worker\n//! thread waits in a loop until it finds the next task to run and then runs it. To find a task, it\n//! first looks into its local *worker* queue, and then into the *injector* and *stealers*.\n//!\n//! # Queues\n//!\n//! [`Injector`] is a FIFO queue, where tasks are pushed and stolen from opposite ends. It is\n//! shared among threads and is usually the entry point for new tasks.\n//!\n//! [`Worker`] has two constructors:\n//!\n//! * [`new_fifo()`] - Creates a FIFO queue, in which tasks are pushed and popped from opposite\n//!   ends.\n//! * [`new_lifo()`] - Creates a LIFO queue, in which tasks are pushed and popped from the same\n//!   end.\n//!\n//! Each [`Worker`] is owned by a single thread and supports only push and pop operations.\n//!\n//! Method [`stealer()`] creates a [`Stealer`] that may be shared among threads and can only steal\n//! tasks from its [`Worker`]. Tasks are stolen from the end opposite to where they get pushed.\n//!\n//! # Stealing\n//!\n//! Steal operations come in three flavors:\n//!\n//! 1. [`steal()`] - Steals one task.\n//! 2. [`steal_batch()`] - Steals a batch of tasks and moves them into another worker.\n//! 3. [`steal_batch_and_pop()`] - Steals a batch of tasks, moves them into another queue, and pops\n//!    one task from that worker.\n//!\n//! In contrast to push and pop operations, stealing can spuriously fail with [`Steal::Retry`], in\n//! which case the steal operation needs to be retried.\n//!\n//! # Examples\n//!\n//! Suppose a thread in a work-stealing scheduler is idle and looking for the next task to run. To\n//! find an available task, it might do the following:\n//!\n//! 1. Try popping one task from the local worker queue.\n//! 2. Try stealing a batch of tasks from the global injector queue.\n//! 3. Try stealing one task from another thread using the stealer list.\n//!\n//! An implementation of this work-stealing strategy:\n//!\n//! ```\n//! use crossbeam_deque::{Injector, Steal, Stealer, Worker};\n//! use std::iter;\n//!\n//! fn find_task<T>(\n//!     local: &Worker<T>,\n//!     global: &Injector<T>,\n//!     stealers: &[Stealer<T>],\n//! ) -> Option<T> {\n//!     // Pop a task from the local queue, if not empty.\n//!     local.pop().or_else(|| {\n//!         // Otherwise, we need to look for a task elsewhere.\n//!         iter::repeat_with(|| {\n//!             // Try stealing a batch of tasks from the global queue.\n//!             global.steal_batch_and_pop(local)\n//!                 // Or try stealing a task from one of the other threads.\n//!                 .or_else(|| stealers.iter().map(|s| s.steal()).collect())\n//!         })\n//!         // Loop while no task was stolen and any steal operation needs to be retried.\n//!         .find(|s| !s.is_retry())\n//!         // Extract the stolen task, if there is one.\n//!         .and_then(|s| s.success())\n//!     })\n//! }\n//! ```\n//!\n//! [`Worker`]: struct.Worker.html\n//! [`Stealer`]: struct.Stealer.html\n//! [`Injector`]: struct.Injector.html\n//! [`Steal::Retry`]: enum.Steal.html#variant.Retry\n//! [`new_fifo()`]: struct.Worker.html#method.new_fifo\n//! [`new_lifo()`]: struct.Worker.html#method.new_lifo\n//! [`stealer()`]: struct.Worker.html#method.stealer\n//! [`steal()`]: struct.Stealer.html#method.steal\n//! [`steal_batch()`]: struct.Stealer.html#method.steal_batch\n//! [`steal_batch_and_pop()`]: struct.Stealer.html#method.steal_batch_and_pop\n\n#![warn(missing_docs)]\n#![warn(missing_debug_implementations)]\n\nextern crate crossbeam_epoch as epoch;\nextern crate crossbeam_utils as utils;\n\nuse std::cell::{Cell, UnsafeCell};\nuse std::cmp;\nuse std::fmt;\nuse std::iter::FromIterator;\nuse std::marker::PhantomData;\nuse std::mem::{self, ManuallyDrop};\nuse std::ptr;\nuse std::sync::atomic::{self, AtomicIsize, AtomicPtr, AtomicUsize, Ordering};\nuse std::sync::Arc;\n\nuse epoch::{Atomic, Owned};\nuse utils::{Backoff, CachePadded};\n\n// Minimum buffer capacity.\nconst MIN_CAP: usize = 64;\n// Maximum number of tasks that can be stolen in `steal_batch()` and `steal_batch_and_pop()`.\nconst MAX_BATCH: usize = 32;\n// If a buffer of at least this size is retired, thread-local garbage is flushed so that it gets\n// deallocated as soon as possible.\nconst FLUSH_THRESHOLD_BYTES: usize = 1 << 10;\n\n/// A buffer that holds tasks in a worker queue.\n///\n/// This is just a pointer to the buffer and its length - dropping an instance of this struct will\n/// *not* deallocate the buffer.\nstruct Buffer<T> {\n    /// Pointer to the allocated memory.\n    ptr: *mut T,\n\n    /// Capacity of the buffer. Always a power of two.\n    cap: usize,\n}\n\nunsafe impl<T> Send for Buffer<T> {}\n\nimpl<T> Buffer<T> {\n    /// Allocates a new buffer with the specified capacity.\n    fn alloc(cap: usize) -> Buffer<T> {\n        debug_assert_eq!(cap, cap.next_power_of_two());\n\n        let mut v = Vec::with_capacity(cap);\n        let ptr = v.as_mut_ptr();\n        mem::forget(v);\n\n        Buffer { ptr, cap }\n    }\n\n    /// Deallocates the buffer.\n    unsafe fn dealloc(self) {\n        drop(Vec::from_raw_parts(self.ptr, 0, self.cap));\n    }\n\n    /// Returns a pointer to the task at the specified `index`.\n    unsafe fn at(&self, index: isize) -> *mut T {\n        // `self.cap` is always a power of two.\n        self.ptr.offset(index & (self.cap - 1) as isize)\n    }\n\n    /// Writes `task` into the specified `index`.\n    ///\n    /// This method might be concurrently called with another `read` at the same index, which is\n    /// technically speaking a data race and therefore UB. We should use an atomic store here, but\n    /// that would be more expensive and difficult to implement generically for all types `T`.\n    /// Hence, as a hack, we use a volatile write instead.\n    unsafe fn write(&self, index: isize, task: T) {\n        ptr::write_volatile(self.at(index), task)\n    }\n\n    /// Reads a task from the specified `index`.\n    ///\n    /// This method might be concurrently called with another `write` at the same index, which is\n    /// technically speaking a data race and therefore UB. We should use an atomic load here, but\n    /// that would be more expensive and difficult to implement generically for all types `T`.\n    /// Hence, as a hack, we use a volatile write instead.\n    unsafe fn read(&self, index: isize) -> T {\n        ptr::read_volatile(self.at(index))\n    }\n}\n\nimpl<T> Clone for Buffer<T> {\n    fn clone(&self) -> Buffer<T> {\n        Buffer {\n            ptr: self.ptr,\n            cap: self.cap,\n        }\n    }\n}\n\nimpl<T> Copy for Buffer<T> {}\n\n/// Internal queue data shared between the worker and stealers.\n///\n/// The implementation is based on the following work:\n///\n/// 1. [Chase and Lev. Dynamic circular work-stealing deque. SPAA 2005.][chase-lev]\n/// 2. [Le, Pop, Cohen, and Nardelli. Correct and efficient work-stealing for weak memory models.\n///    PPoPP 2013.][weak-mem]\n/// 3. [Norris and Demsky. CDSchecker: checking concurrent data structures written with C/C++\n///    atomics. OOPSLA 2013.][checker]\n///\n/// [chase-lev]: https://dl.acm.org/citation.cfm?id=1073974\n/// [weak-mem]: https://dl.acm.org/citation.cfm?id=2442524\n/// [checker]: https://dl.acm.org/citation.cfm?id=2509514\nstruct Inner<T> {\n    /// The front index.\n    front: AtomicIsize,\n\n    /// The back index.\n    back: AtomicIsize,\n\n    /// The underlying buffer.\n    buffer: CachePadded<Atomic<Buffer<T>>>,\n}\n\nimpl<T> Drop for Inner<T> {\n    fn drop(&mut self) {\n        // Load the back index, front index, and buffer.\n        let b = self.back.load(Ordering::Relaxed);\n        let f = self.front.load(Ordering::Relaxed);\n\n        unsafe {\n            let buffer = self.buffer.load(Ordering::Relaxed, epoch::unprotected());\n\n            // Go through the buffer from front to back and drop all tasks in the queue.\n            let mut i = f;\n            while i != b {\n                ptr::drop_in_place(buffer.deref().at(i));\n                i = i.wrapping_add(1);\n            }\n\n            // Free the memory allocated by the buffer.\n            buffer.into_owned().into_box().dealloc();\n        }\n    }\n}\n\n/// Worker queue flavor: FIFO or LIFO.\n#[derive(Clone, Copy, Debug, Eq, PartialEq)]\nenum Flavor {\n    /// The first-in first-out flavor.\n    Fifo,\n\n    /// The last-in first-out flavor.\n    Lifo,\n}\n\n/// A worker queue.\n///\n/// This is a FIFO or LIFO queue that is owned by a single thread, but other threads may steal\n/// tasks from it. Task schedulers typically create a single worker queue per thread.\n///\n/// # Examples\n///\n/// A FIFO worker:\n///\n/// ```\n/// use crossbeam_deque::{Steal, Worker};\n///\n/// let w = Worker::new_fifo();\n/// let s = w.stealer();\n///\n/// w.push(1);\n/// w.push(2);\n/// w.push(3);\n///\n/// assert_eq!(s.steal(), Steal::Success(1));\n/// assert_eq!(w.pop(), Some(2));\n/// assert_eq!(w.pop(), Some(3));\n/// ```\n///\n/// A LIFO worker:\n///\n/// ```\n/// use crossbeam_deque::{Steal, Worker};\n///\n/// let w = Worker::new_lifo();\n/// let s = w.stealer();\n///\n/// w.push(1);\n/// w.push(2);\n/// w.push(3);\n///\n/// assert_eq!(s.steal(), Steal::Success(1));\n/// assert_eq!(w.pop(), Some(3));\n/// assert_eq!(w.pop(), Some(2));\n/// ```\npub struct Worker<T> {\n    /// A reference to the inner representation of the queue.\n    inner: Arc<CachePadded<Inner<T>>>,\n\n    /// A copy of `inner.buffer` for quick access.\n    buffer: Cell<Buffer<T>>,\n\n    /// The flavor of the queue.\n    flavor: Flavor,\n\n    /// Indicates that the worker cannot be shared among threads.\n    _marker: PhantomData<*mut ()>, // !Send + !Sync\n}\n\nunsafe impl<T: Send> Send for Worker<T> {}\n\nimpl<T> Worker<T> {\n    /// Creates a FIFO worker queue.\n    ///\n    /// Tasks are pushed and popped from opposite ends.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use crossbeam_deque::Worker;\n    ///\n    /// let w = Worker::<i32>::new_fifo();\n    /// ```\n    pub fn new_fifo() -> Worker<T> {\n        let buffer = Buffer::alloc(MIN_CAP);\n\n        let inner = Arc::new(CachePadded::new(Inner {\n            front: AtomicIsize::new(0),\n            back: AtomicIsize::new(0),\n            buffer: CachePadded::new(Atomic::new(buffer)),\n        }));\n\n        Worker {\n            inner,\n            buffer: Cell::new(buffer),\n            flavor: Flavor::Fifo,\n            _marker: PhantomData,\n        }\n    }\n\n    /// Creates a LIFO worker queue.\n    ///\n    /// Tasks are pushed and popped from the same end.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use crossbeam_deque::Worker;\n    ///\n    /// let w = Worker::<i32>::new_lifo();\n    /// ```\n    pub fn new_lifo() -> Worker<T> {\n        let buffer = Buffer::alloc(MIN_CAP);\n\n        let inner = Arc::new(CachePadded::new(Inner {\n            front: AtomicIsize::new(0),\n            back: AtomicIsize::new(0),\n            buffer: CachePadded::new(Atomic::new(buffer)),\n        }));\n\n        Worker {\n            inner,\n            buffer: Cell::new(buffer),\n            flavor: Flavor::Lifo,\n            _marker: PhantomData,\n        }\n    }\n\n    /// Creates a stealer for this queue.\n    ///\n    /// The returned stealer can be shared among threads and cloned.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use crossbeam_deque::Worker;\n    ///\n    /// let w = Worker::<i32>::new_lifo();\n    /// let s = w.stealer();\n    /// ```\n    pub fn stealer(&self) -> Stealer<T> {\n        Stealer {\n            inner: self.inner.clone(),\n            flavor: self.flavor,\n        }\n    }\n\n    /// Resizes the internal buffer to the new capacity of `new_cap`.\n    #[cold]\n    unsafe fn resize(&self, new_cap: usize) {\n        // Load the back index, front index, and buffer.\n        let b = self.inner.back.load(Ordering::Relaxed);\n        let f = self.inner.front.load(Ordering::Relaxed);\n        let buffer = self.buffer.get();\n\n        // Allocate a new buffer and copy data from the old buffer to the new one.\n        let new = Buffer::alloc(new_cap);\n        let mut i = f;\n        while i != b {\n            ptr::copy_nonoverlapping(buffer.at(i), new.at(i), 1);\n            i = i.wrapping_add(1);\n        }\n\n        let guard = &epoch::pin();\n\n        // Replace the old buffer with the new one.\n        self.buffer.replace(new);\n        let old =\n            self.inner\n                .buffer\n                .swap(Owned::new(new).into_shared(guard), Ordering::Release, guard);\n\n        // Destroy the old buffer later.\n        guard.defer_unchecked(move || old.into_owned().into_box().dealloc());\n\n        // If the buffer is very large, then flush the thread-local garbage in order to deallocate\n        // it as soon as possible.\n        if mem::size_of::<T>() * new_cap >= FLUSH_THRESHOLD_BYTES {\n            guard.flush();\n        }\n    }\n\n    /// Reserves enough capacity so that `reserve_cap` tasks can be pushed without growing the\n    /// buffer.\n    fn reserve(&self, reserve_cap: usize) {\n        if reserve_cap > 0 {\n            // Compute the current length.\n            let b = self.inner.back.load(Ordering::Relaxed);\n            let f = self.inner.front.load(Ordering::SeqCst);\n            let len = b.wrapping_sub(f) as usize;\n\n            // The current capacity.\n            let cap = self.buffer.get().cap;\n\n            // Is there enough capacity to push `reserve_cap` tasks?\n            if cap - len < reserve_cap {\n                // Keep doubling the capacity as much as is needed.\n                let mut new_cap = cap * 2;\n                while new_cap - len < reserve_cap {\n                    new_cap *= 2;\n                }\n\n                // Resize the buffer.\n                unsafe {\n                    self.resize(new_cap);\n                }\n            }\n        }\n    }\n\n    /// Returns `true` if the queue is empty.\n    ///\n    /// ```\n    /// use crossbeam_deque::Worker;\n    ///\n    /// let w = Worker::new_lifo();\n    ///\n    /// assert!(w.is_empty());\n    /// w.push(1);\n    /// assert!(!w.is_empty());\n    /// ```\n    pub fn is_empty(&self) -> bool {\n        let b = self.inner.back.load(Ordering::Relaxed);\n        let f = self.inner.front.load(Ordering::SeqCst);\n        b.wrapping_sub(f) <= 0\n    }\n\n    /// Pushes a task into the queue.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use crossbeam_deque::Worker;\n    ///\n    /// let w = Worker::new_lifo();\n    /// w.push(1);\n    /// w.push(2);\n    /// ```\n    pub fn push(&self, task: T) {\n        // Load the back index, front index, and buffer.\n        let b = self.inner.back.load(Ordering::Relaxed);\n        let f = self.inner.front.load(Ordering::Acquire);\n        let mut buffer = self.buffer.get();\n\n        // Calculate the length of the queue.\n        let len = b.wrapping_sub(f);\n\n        // Is the queue full?\n        if len >= buffer.cap as isize {\n            // Yes. Grow the underlying buffer.\n            unsafe {\n                self.resize(2 * buffer.cap);\n            }\n            buffer = self.buffer.get();\n        }\n\n        // Write `task` into the slot.\n        unsafe {\n            buffer.write(b, task);\n        }\n\n        atomic::fence(Ordering::Release);\n\n        // Increment the back index.\n        //\n        // This ordering could be `Relaxed`, but then thread sanitizer would falsely report data\n        // races because it doesn't understand fences.\n        self.inner.back.store(b.wrapping_add(1), Ordering::Release);\n    }\n\n    /// Pops a task from the queue.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use crossbeam_deque::Worker;\n    ///\n    /// let w = Worker::new_fifo();\n    /// w.push(1);\n    /// w.push(2);\n    ///\n    /// assert_eq!(w.pop(), Some(1));\n    /// assert_eq!(w.pop(), Some(2));\n    /// assert_eq!(w.pop(), None);\n    /// ```\n    pub fn pop(&self) -> Option<T> {\n        // Load the back and front index.\n        let b = self.inner.back.load(Ordering::Relaxed);\n        let f = self.inner.front.load(Ordering::Relaxed);\n\n        // Calculate the length of the queue.\n        let len = b.wrapping_sub(f);\n\n        // Is the queue empty?\n        if len <= 0 {\n            return None;\n        }\n\n        match self.flavor {\n            // Pop from the front of the queue.\n            Flavor::Fifo => {\n                // Try incrementing the front index to pop the task.\n                let f = self.inner.front.fetch_add(1, Ordering::SeqCst);\n                let new_f = f.wrapping_add(1);\n\n                if b.wrapping_sub(new_f) < 0 {\n                    self.inner.front.store(f, Ordering::Relaxed);\n                    return None;\n                }\n\n                unsafe {\n                    // Read the popped task.\n                    let buffer = self.buffer.get();\n                    let task = buffer.read(f);\n\n                    // Shrink the buffer if `len - 1` is less than one fourth of the capacity.\n                    if buffer.cap > MIN_CAP && len <= buffer.cap as isize / 4 {\n                        self.resize(buffer.cap / 2);\n                    }\n\n                    Some(task)\n                }\n            }\n\n            // Pop from the back of the queue.\n            Flavor::Lifo => {\n                // Decrement the back index.\n                let b = b.wrapping_sub(1);\n                self.inner.back.store(b, Ordering::Relaxed);\n\n                atomic::fence(Ordering::SeqCst);\n\n                // Load the front index.\n                let f = self.inner.front.load(Ordering::Relaxed);\n\n                // Compute the length after the back index was decremented.\n                let len = b.wrapping_sub(f);\n\n                if len < 0 {\n                    // The queue is empty. Restore the back index to the original task.\n                    self.inner.back.store(b.wrapping_add(1), Ordering::Relaxed);\n                    None\n                } else {\n                    // Read the task to be popped.\n                    let buffer = self.buffer.get();\n                    let mut task = unsafe { Some(buffer.read(b)) };\n\n                    // Are we popping the last task from the queue?\n                    if len == 0 {\n                        // Try incrementing the front index.\n                        if self\n                            .inner\n                            .front\n                            .compare_exchange(\n                                f,\n                                f.wrapping_add(1),\n                                Ordering::SeqCst,\n                                Ordering::Relaxed,\n                            )\n                            .is_err()\n                        {\n                            // Failed. We didn't pop anything.\n                            mem::forget(task.take());\n                        }\n\n                        // Restore the back index to the original task.\n                        self.inner.back.store(b.wrapping_add(1), Ordering::Relaxed);\n                    } else {\n                        // Shrink the buffer if `len` is less than one fourth of the capacity.\n                        if buffer.cap > MIN_CAP && len < buffer.cap as isize / 4 {\n                            unsafe {\n                                self.resize(buffer.cap / 2);\n                            }\n                        }\n                    }\n\n                    task\n                }\n            }\n        }\n    }\n}\n\nimpl<T> fmt::Debug for Worker<T> {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        f.pad(\"Worker { .. }\")\n    }\n}\n\n/// A stealer handle of a worker queue.\n///\n/// Stealers can be shared among threads.\n///\n/// Task schedulers typically have a single worker queue per worker thread.\n///\n/// # Examples\n///\n/// ```\n/// use crossbeam_deque::{Steal, Worker};\n///\n/// let w = Worker::new_lifo();\n/// w.push(1);\n/// w.push(2);\n///\n/// let s = w.stealer();\n/// assert_eq!(s.steal(), Steal::Success(1));\n/// assert_eq!(s.steal(), Steal::Success(2));\n/// assert_eq!(s.steal(), Steal::Empty);\n/// ```\npub struct Stealer<T> {\n    /// A reference to the inner representation of the queue.\n    inner: Arc<CachePadded<Inner<T>>>,\n\n    /// The flavor of the queue.\n    flavor: Flavor,\n}\n\nunsafe impl<T: Send> Send for Stealer<T> {}\nunsafe impl<T: Send> Sync for Stealer<T> {}\n\nimpl<T> Stealer<T> {\n    /// Returns `true` if the queue is empty.\n    ///\n    /// ```\n    /// use crossbeam_deque::Worker;\n    ///\n    /// let w = Worker::new_lifo();\n    /// let s = w.stealer();\n    ///\n    /// assert!(s.is_empty());\n    /// w.push(1);\n    /// assert!(!s.is_empty());\n    /// ```\n    pub fn is_empty(&self) -> bool {\n        let f = self.inner.front.load(Ordering::Acquire);\n        atomic::fence(Ordering::SeqCst);\n        let b = self.inner.back.load(Ordering::Acquire);\n        b.wrapping_sub(f) <= 0\n    }\n\n    /// Steals a task from the queue.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use crossbeam_deque::{Steal, Worker};\n    ///\n    /// let w = Worker::new_lifo();\n    /// w.push(1);\n    /// w.push(2);\n    ///\n    /// let s = w.stealer();\n    /// assert_eq!(s.steal(), Steal::Success(1));\n    /// assert_eq!(s.steal(), Steal::Success(2));\n    /// ```\n    pub fn steal(&self) -> Steal<T> {\n        // Load the front index.\n        let f = self.inner.front.load(Ordering::Acquire);\n\n        // A SeqCst fence is needed here.\n        //\n        // If the current thread is already pinned (reentrantly), we must manually issue the\n        // fence. Otherwise, the following pinning will issue the fence anyway, so we don't\n        // have to.\n        if epoch::is_pinned() {\n            atomic::fence(Ordering::SeqCst);\n        }\n\n        let guard = &epoch::pin();\n\n        // Load the back index.\n        let b = self.inner.back.load(Ordering::Acquire);\n\n        // Is the queue empty?\n        if b.wrapping_sub(f) <= 0 {\n            return Steal::Empty;\n        }\n\n        // Load the buffer and read the task at the front.\n        let buffer = self.inner.buffer.load(Ordering::Acquire, guard);\n        let task = unsafe { buffer.deref().read(f) };\n\n        // Try incrementing the front index to steal the task.\n        if self\n            .inner\n            .front\n            .compare_exchange(f, f.wrapping_add(1), Ordering::SeqCst, Ordering::Relaxed)\n            .is_err()\n        {\n            // We didn't steal this task, forget it.\n            mem::forget(task);\n            return Steal::Retry;\n        }\n\n        // Return the stolen task.\n        Steal::Success(task)\n    }\n\n    /// Steals a batch of tasks and pushes them into another worker.\n    ///\n    /// How many tasks exactly will be stolen is not specified. That said, this method will try to\n    /// steal around half of the tasks in the queue, but also not more than some constant limit.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use crossbeam_deque::Worker;\n    ///\n    /// let w1 = Worker::new_fifo();\n    /// w1.push(1);\n    /// w1.push(2);\n    /// w1.push(3);\n    /// w1.push(4);\n    ///\n    /// let s = w1.stealer();\n    /// let w2 = Worker::new_fifo();\n    ///\n    /// s.steal_batch(&w2);\n    /// assert_eq!(w2.pop(), Some(1));\n    /// assert_eq!(w2.pop(), Some(2));\n    /// ```\n    pub fn steal_batch(&self, dest: &Worker<T>) -> Steal<()> {\n        if Arc::ptr_eq(&self.inner, &dest.inner) {\n            if dest.is_empty() {\n                return Steal::Empty;\n            } else {\n                return Steal::Success(());\n            }\n        }\n\n        // Load the front index.\n        let mut f = self.inner.front.load(Ordering::Acquire);\n\n        // A SeqCst fence is needed here.\n        //\n        // If the current thread is already pinned (reentrantly), we must manually issue the\n        // fence. Otherwise, the following pinning will issue the fence anyway, so we don't\n        // have to.\n        if epoch::is_pinned() {\n            atomic::fence(Ordering::SeqCst);\n        }\n\n        let guard = &epoch::pin();\n\n        // Load the back index.\n        let b = self.inner.back.load(Ordering::Acquire);\n\n        // Is the queue empty?\n        let len = b.wrapping_sub(f);\n        if len <= 0 {\n            return Steal::Empty;\n        }\n\n        // Reserve capacity for the stolen batch.\n        let batch_size = cmp::min((len as usize + 1) / 2, MAX_BATCH);\n        dest.reserve(batch_size);\n        let mut batch_size = batch_size as isize;\n\n        // Get the destination buffer and back index.\n        let dest_buffer = dest.buffer.get();\n        let mut dest_b = dest.inner.back.load(Ordering::Relaxed);\n\n        // Load the buffer.\n        let buffer = self.inner.buffer.load(Ordering::Acquire, guard);\n\n        match self.flavor {\n            // Steal a batch of tasks from the front at once.\n            Flavor::Fifo => {\n                // Copy the batch from the source to the destination buffer.\n                match dest.flavor {\n                    Flavor::Fifo => {\n                        for i in 0..batch_size {\n                            unsafe {\n                                let task = buffer.deref().read(f.wrapping_add(i));\n                                dest_buffer.write(dest_b.wrapping_add(i), task);\n                            }\n                        }\n                    }\n                    Flavor::Lifo => {\n                        for i in 0..batch_size {\n                            unsafe {\n                                let task = buffer.deref().read(f.wrapping_add(i));\n                                dest_buffer.write(dest_b.wrapping_add(batch_size - 1 - i), task);\n                            }\n                        }\n                    }\n                }\n\n                // Try incrementing the front index to steal the batch.\n                if self\n                    .inner\n                    .front\n                    .compare_exchange(\n                        f,\n                        f.wrapping_add(batch_size),\n                        Ordering::SeqCst,\n                        Ordering::Relaxed,\n                    )\n                    .is_err()\n                {\n                    return Steal::Retry;\n                }\n\n                dest_b = dest_b.wrapping_add(batch_size);\n            }\n\n            // Steal a batch of tasks from the front one by one.\n            Flavor::Lifo => {\n                for i in 0..batch_size {\n                    // If this is not the first steal, check whether the queue is empty.\n                    if i > 0 {\n                        // We've already got the current front index. Now execute the fence to\n                        // synchronize with other threads.\n                        atomic::fence(Ordering::SeqCst);\n\n                        // Load the back index.\n                        let b = self.inner.back.load(Ordering::Acquire);\n\n                        // Is the queue empty?\n                        if b.wrapping_sub(f) <= 0 {\n                            batch_size = i;\n                            break;\n                        }\n                    }\n\n                    // Read the task at the front.\n                    let task = unsafe { buffer.deref().read(f) };\n\n                    // Try incrementing the front index to steal the task.\n                    if self\n                        .inner\n                        .front\n                        .compare_exchange(f, f.wrapping_add(1), Ordering::SeqCst, Ordering::Relaxed)\n                        .is_err()\n                    {\n                        // We didn't steal this task, forget it and break from the loop.\n                        mem::forget(task);\n                        batch_size = i;\n                        break;\n                    }\n\n                    // Write the stolen task into the destination buffer.\n                    unsafe {\n                        dest_buffer.write(dest_b, task);\n                    }\n\n                    // Move the source front index and the destination back index one step forward.\n                    f = f.wrapping_add(1);\n                    dest_b = dest_b.wrapping_add(1);\n                }\n\n                // If we didn't steal anything, the operation needs to be retried.\n                if batch_size == 0 {\n                    return Steal::Retry;\n                }\n\n                // If stealing into a FIFO queue, stolen tasks need to be reversed.\n                if dest.flavor == Flavor::Fifo {\n                    for i in 0..batch_size / 2 {\n                        unsafe {\n                            let i1 = dest_b.wrapping_sub(batch_size - i);\n                            let i2 = dest_b.wrapping_sub(i + 1);\n                            let t1 = dest_buffer.read(i1);\n                            let t2 = dest_buffer.read(i2);\n                            dest_buffer.write(i1, t2);\n                            dest_buffer.write(i2, t1);\n                        }\n                    }\n                }\n            }\n        }\n\n        atomic::fence(Ordering::Release);\n\n        // Update the back index in the destination queue.\n        //\n        // This ordering could be `Relaxed`, but then thread sanitizer would falsely report data\n        // races because it doesn't understand fences.\n        dest.inner.back.store(dest_b, Ordering::Release);\n\n        // Return with success.\n        Steal::Success(())\n    }\n\n    /// Steals a batch of tasks, pushes them into another worker, and pops a task from that worker.\n    ///\n    /// How many tasks exactly will be stolen is not specified. That said, this method will try to\n    /// steal around half of the tasks in the queue, but also not more than some constant limit.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use crossbeam_deque::{Steal, Worker};\n    ///\n    /// let w1 = Worker::new_fifo();\n    /// w1.push(1);\n    /// w1.push(2);\n    /// w1.push(3);\n    /// w1.push(4);\n    ///\n    /// let s = w1.stealer();\n    /// let w2 = Worker::new_fifo();\n    ///\n    /// assert_eq!(s.steal_batch_and_pop(&w2), Steal::Success(1));\n    /// assert_eq!(w2.pop(), Some(2));\n    /// ```\n    pub fn steal_batch_and_pop(&self, dest: &Worker<T>) -> Steal<T> {\n        if Arc::ptr_eq(&self.inner, &dest.inner) {\n            match dest.pop() {\n                None => return Steal::Empty,\n                Some(task) => return Steal::Success(task),\n            }\n        }\n\n        // Load the front index.\n        let mut f = self.inner.front.load(Ordering::Acquire);\n\n        // A SeqCst fence is needed here.\n        //\n        // If the current thread is already pinned (reentrantly), we must manually issue the\n        // fence. Otherwise, the following pinning will issue the fence anyway, so we don't\n        // have to.\n        if epoch::is_pinned() {\n            atomic::fence(Ordering::SeqCst);\n        }\n\n        let guard = &epoch::pin();\n\n        // Load the back index.\n        let b = self.inner.back.load(Ordering::Acquire);\n\n        // Is the queue empty?\n        let len = b.wrapping_sub(f);\n        if len <= 0 {\n            return Steal::Empty;\n        }\n\n        // Reserve capacity for the stolen batch.\n        let batch_size = cmp::min((len as usize - 1) / 2, MAX_BATCH - 1);\n        dest.reserve(batch_size);\n        let mut batch_size = batch_size as isize;\n\n        // Get the destination buffer and back index.\n        let dest_buffer = dest.buffer.get();\n        let mut dest_b = dest.inner.back.load(Ordering::Relaxed);\n\n        // Load the buffer\n        let buffer = self.inner.buffer.load(Ordering::Acquire, guard);\n\n        // Read the task at the front.\n        let mut task = unsafe { buffer.deref().read(f) };\n\n        match self.flavor {\n            // Steal a batch of tasks from the front at once.\n            Flavor::Fifo => {\n                // Copy the batch from the source to the destination buffer.\n                match dest.flavor {\n                    Flavor::Fifo => {\n                        for i in 0..batch_size {\n                            unsafe {\n                                let task = buffer.deref().read(f.wrapping_add(i + 1));\n                                dest_buffer.write(dest_b.wrapping_add(i), task);\n                            }\n                        }\n                    }\n                    Flavor::Lifo => {\n                        for i in 0..batch_size {\n                            unsafe {\n                                let task = buffer.deref().read(f.wrapping_add(i + 1));\n                                dest_buffer.write(dest_b.wrapping_add(batch_size - 1 - i), task);\n                            }\n                        }\n                    }\n                }\n\n                // Try incrementing the front index to steal the batch.\n                if self\n                    .inner\n                    .front\n                    .compare_exchange(\n                        f,\n                        f.wrapping_add(batch_size + 1),\n                        Ordering::SeqCst,\n                        Ordering::Relaxed,\n                    )\n                    .is_err()\n                {\n                    // We didn't steal this task, forget it.\n                    mem::forget(task);\n                    return Steal::Retry;\n                }\n\n                dest_b = dest_b.wrapping_add(batch_size);\n            }\n\n            // Steal a batch of tasks from the front one by one.\n            Flavor::Lifo => {\n                // Try incrementing the front index to steal the task.\n                if self\n                    .inner\n                    .front\n                    .compare_exchange(f, f.wrapping_add(1), Ordering::SeqCst, Ordering::Relaxed)\n                    .is_err()\n                {\n                    // We didn't steal this task, forget it.\n                    mem::forget(task);\n                    return Steal::Retry;\n                }\n\n                // Move the front index one step forward.\n                f = f.wrapping_add(1);\n\n                // Repeat the same procedure for the batch steals.\n                for i in 0..batch_size {\n                    // We've already got the current front index. Now execute the fence to\n                    // synchronize with other threads.\n                    atomic::fence(Ordering::SeqCst);\n\n                    // Load the back index.\n                    let b = self.inner.back.load(Ordering::Acquire);\n\n                    // Is the queue empty?\n                    if b.wrapping_sub(f) <= 0 {\n                        batch_size = i;\n                        break;\n                    }\n\n                    // Read the task at the front.\n                    let tmp = unsafe { buffer.deref().read(f) };\n\n                    // Try incrementing the front index to steal the task.\n                    if self\n                        .inner\n                        .front\n                        .compare_exchange(f, f.wrapping_add(1), Ordering::SeqCst, Ordering::Relaxed)\n                        .is_err()\n                    {\n                        // We didn't steal this task, forget it and break from the loop.\n                        mem::forget(tmp);\n                        batch_size = i;\n                        break;\n                    }\n\n                    // Write the previously stolen task into the destination buffer.\n                    unsafe {\n                        dest_buffer.write(dest_b, mem::replace(&mut task, tmp));\n                    }\n\n                    // Move the source front index and the destination back index one step forward.\n                    f = f.wrapping_add(1);\n                    dest_b = dest_b.wrapping_add(1);\n                }\n\n                // If stealing into a FIFO queue, stolen tasks need to be reversed.\n                if dest.flavor == Flavor::Fifo {\n                    for i in 0..batch_size / 2 {\n                        unsafe {\n                            let i1 = dest_b.wrapping_sub(batch_size - i);\n                            let i2 = dest_b.wrapping_sub(i + 1);\n                            let t1 = dest_buffer.read(i1);\n                            let t2 = dest_buffer.read(i2);\n                            dest_buffer.write(i1, t2);\n                            dest_buffer.write(i2, t1);\n                        }\n                    }\n                }\n            }\n        }\n\n        atomic::fence(Ordering::Release);\n\n        // Update the back index in the destination queue.\n        //\n        // This ordering could be `Relaxed`, but then thread sanitizer would falsely report data\n        // races because it doesn't understand fences.\n        dest.inner.back.store(dest_b, Ordering::Release);\n\n        // Return with success.\n        Steal::Success(task)\n    }\n}\n\nimpl<T> Clone for Stealer<T> {\n    fn clone(&self) -> Stealer<T> {\n        Stealer {\n            inner: self.inner.clone(),\n            flavor: self.flavor,\n        }\n    }\n}\n\nimpl<T> fmt::Debug for Stealer<T> {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        f.pad(\"Stealer { .. }\")\n    }\n}\n\n// Bits indicating the state of a slot:\n// * If a task has been written into the slot, `WRITE` is set.\n// * If a task has been read from the slot, `READ` is set.\n// * If the block is being destroyed, `DESTROY` is set.\nconst WRITE: usize = 1;\nconst READ: usize = 2;\nconst DESTROY: usize = 4;\n\n// Each block covers one \"lap\" of indices.\nconst LAP: usize = 64;\n// The maximum number of values a block can hold.\nconst BLOCK_CAP: usize = LAP - 1;\n// How many lower bits are reserved for metadata.\nconst SHIFT: usize = 1;\n// Indicates that the block is not the last one.\nconst HAS_NEXT: usize = 1;\n\n/// A slot in a block.\nstruct Slot<T> {\n    /// The task.\n    task: UnsafeCell<ManuallyDrop<T>>,\n\n    /// The state of the slot.\n    state: AtomicUsize,\n}\n\nimpl<T> Slot<T> {\n    /// Waits until a task is written into the slot.\n    fn wait_write(&self) {\n        let backoff = Backoff::new();\n        while self.state.load(Ordering::Acquire) & WRITE == 0 {\n            backoff.snooze();\n        }\n    }\n}\n\n/// A block in a linked list.\n///\n/// Each block in the list can hold up to `BLOCK_CAP` values.\nstruct Block<T> {\n    /// The next block in the linked list.\n    next: AtomicPtr<Block<T>>,\n\n    /// Slots for values.\n    slots: [Slot<T>; BLOCK_CAP],\n}\n\nimpl<T> Block<T> {\n    /// Creates an empty block that starts at `start_index`.\n    fn new() -> Block<T> {\n        unsafe { mem::zeroed() }\n    }\n\n    /// Waits until the next pointer is set.\n    fn wait_next(&self) -> *mut Block<T> {\n        let backoff = Backoff::new();\n        loop {\n            let next = self.next.load(Ordering::Acquire);\n            if !next.is_null() {\n                return next;\n            }\n            backoff.snooze();\n        }\n    }\n\n    /// Sets the `DESTROY` bit in slots starting from `start` and destroys the block.\n    unsafe fn destroy(this: *mut Block<T>, count: usize) {\n        // It is not necessary to set the `DESTROY` bit in the last slot because that slot has\n        // begun destruction of the block.\n        for i in (0..count).rev() {\n            let slot = (*this).slots.get_unchecked(i);\n\n            // Mark the `DESTROY` bit if a thread is still using the slot.\n            if slot.state.load(Ordering::Acquire) & READ == 0\n                && slot.state.fetch_or(DESTROY, Ordering::AcqRel) & READ == 0\n            {\n                // If a thread is still using the slot, it will continue destruction of the block.\n                return;\n            }\n        }\n\n        // No thread is using the block, now it is safe to destroy it.\n        drop(Box::from_raw(this));\n    }\n}\n\n/// A position in a queue.\nstruct Position<T> {\n    /// The index in the queue.\n    index: AtomicUsize,\n\n    /// The block in the linked list.\n    block: AtomicPtr<Block<T>>,\n}\n\n/// An injector queue.\n///\n/// This is a FIFO queue that can be shared among multiple threads. Task schedulers typically have\n/// a single injector queue, which is the entry point for new tasks.\n///\n/// # Examples\n///\n/// ```\n/// use crossbeam_deque::{Injector, Steal};\n///\n/// let q = Injector::new();\n/// q.push(1);\n/// q.push(2);\n///\n/// assert_eq!(q.steal(), Steal::Success(1));\n/// assert_eq!(q.steal(), Steal::Success(2));\n/// assert_eq!(q.steal(), Steal::Empty);\n/// ```\npub struct Injector<T> {\n    /// The head of the queue.\n    head: CachePadded<Position<T>>,\n\n    /// The tail of the queue.\n    tail: CachePadded<Position<T>>,\n\n    /// Indicates that dropping a `Injector<T>` may drop values of type `T`.\n    _marker: PhantomData<T>,\n}\n\nunsafe impl<T: Send> Send for Injector<T> {}\nunsafe impl<T: Send> Sync for Injector<T> {}\n\nimpl<T> Injector<T> {\n    /// Creates a new injector queue.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use crossbeam_deque::Injector;\n    ///\n    /// let q = Injector::<i32>::new();\n    /// ```\n    pub fn new() -> Injector<T> {\n        let block = Box::into_raw(Box::new(Block::<T>::new()));\n        Injector {\n            head: CachePadded::new(Position {\n                block: AtomicPtr::new(block),\n                index: AtomicUsize::new(0),\n            }),\n            tail: CachePadded::new(Position {\n                block: AtomicPtr::new(block),\n                index: AtomicUsize::new(0),\n            }),\n            _marker: PhantomData,\n        }\n    }\n\n    /// Pushes a task into the queue.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use crossbeam_deque::Injector;\n    ///\n    /// let w = Injector::new();\n    /// w.push(1);\n    /// w.push(2);\n    /// ```\n    pub fn push(&self, task: T) {\n        let backoff = Backoff::new();\n        let mut tail = self.tail.index.load(Ordering::Acquire);\n        let mut block = self.tail.block.load(Ordering::Acquire);\n        let mut next_block = None;\n\n        loop {\n            // Calculate the offset of the index into the block.\n            let offset = (tail >> SHIFT) % LAP;\n\n            // If we reached the end of the block, wait until the next one is installed.\n            if offset == BLOCK_CAP {\n                backoff.snooze();\n                tail = self.tail.index.load(Ordering::Acquire);\n                block = self.tail.block.load(Ordering::Acquire);\n                continue;\n            }\n\n            // If we're going to have to install the next block, allocate it in advance in order to\n            // make the wait for other threads as short as possible.\n            if offset + 1 == BLOCK_CAP && next_block.is_none() {\n                next_block = Some(Box::new(Block::<T>::new()));\n            }\n\n            let new_tail = tail + (1 << SHIFT);\n\n            // Try advancing the tail forward.\n            match self.tail.index.compare_exchange_weak(\n                tail,\n                new_tail,\n                Ordering::SeqCst,\n                Ordering::Acquire,\n            ) {\n                Ok(_) => unsafe {\n                    // If we've reached the end of the block, install the next one.\n                    if offset + 1 == BLOCK_CAP {\n                        let next_block = Box::into_raw(next_block.unwrap());\n                        let next_index = new_tail.wrapping_add(1 << SHIFT);\n\n                        self.tail.block.store(next_block, Ordering::Release);\n                        self.tail.index.store(next_index, Ordering::Release);\n                        (*block).next.store(next_block, Ordering::Release);\n                    }\n\n                    // Write the task into the slot.\n                    let slot = (*block).slots.get_unchecked(offset);\n                    slot.task.get().write(ManuallyDrop::new(task));\n                    slot.state.fetch_or(WRITE, Ordering::Release);\n\n                    return;\n                },\n                Err(t) => {\n                    tail = t;\n                    block = self.tail.block.load(Ordering::Acquire);\n                    backoff.spin();\n                }\n            }\n        }\n    }\n\n    /// Steals a task from the queue.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use crossbeam_deque::{Injector, Steal};\n    ///\n    /// let q = Injector::new();\n    /// q.push(1);\n    /// q.push(2);\n    ///\n    /// assert_eq!(q.steal(), Steal::Success(1));\n    /// assert_eq!(q.steal(), Steal::Success(2));\n    /// assert_eq!(q.steal(), Steal::Empty);\n    /// ```\n    pub fn steal(&self) -> Steal<T> {\n        let mut head;\n        let mut block;\n        let mut offset;\n\n        let backoff = Backoff::new();\n        loop {\n            head = self.head.index.load(Ordering::Acquire);\n            block = self.head.block.load(Ordering::Acquire);\n\n            // Calculate the offset of the index into the block.\n            offset = (head >> SHIFT) % LAP;\n\n            // If we reached the end of the block, wait until the next one is installed.\n            if offset == BLOCK_CAP {\n                backoff.snooze();\n            } else {\n                break;\n            }\n        }\n\n        let mut new_head = head + (1 << SHIFT);\n\n        if new_head & HAS_NEXT == 0 {\n            atomic::fence(Ordering::SeqCst);\n            let tail = self.tail.index.load(Ordering::Relaxed);\n\n            // If the tail equals the head, that means the queue is empty.\n            if head >> SHIFT == tail >> SHIFT {\n                return Steal::Empty;\n            }\n\n            // If head and tail are not in the same block, set `HAS_NEXT` in head.\n            if (head >> SHIFT) / LAP != (tail >> SHIFT) / LAP {\n                new_head |= HAS_NEXT;\n            }\n        }\n\n        // Try moving the head index forward.\n        if self\n            .head\n            .index\n            .compare_exchange_weak(head, new_head, Ordering::SeqCst, Ordering::Acquire)\n            .is_err()\n        {\n            return Steal::Retry;\n        }\n\n        unsafe {\n            // If we've reached the end of the block, move to the next one.\n            if offset + 1 == BLOCK_CAP {\n                let next = (*block).wait_next();\n                let mut next_index = (new_head & !HAS_NEXT).wrapping_add(1 << SHIFT);\n                if !(*next).next.load(Ordering::Relaxed).is_null() {\n                    next_index |= HAS_NEXT;\n                }\n\n                self.head.block.store(next, Ordering::Release);\n                self.head.index.store(next_index, Ordering::Release);\n            }\n\n            // Read the task.\n            let slot = (*block).slots.get_unchecked(offset);\n            slot.wait_write();\n            let m = slot.task.get().read();\n            let task = ManuallyDrop::into_inner(m);\n\n            // Destroy the block if we've reached the end, or if another thread wanted to destroy\n            // but couldn't because we were busy reading from the slot.\n            if offset + 1 == BLOCK_CAP {\n                Block::destroy(block, offset);\n            } else if slot.state.fetch_or(READ, Ordering::AcqRel) & DESTROY != 0 {\n                Block::destroy(block, offset);\n            }\n\n            Steal::Success(task)\n        }\n    }\n\n    /// Steals a batch of tasks and pushes them into a worker.\n    ///\n    /// How many tasks exactly will be stolen is not specified. That said, this method will try to\n    /// steal around half of the tasks in the queue, but also not more than some constant limit.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use crossbeam_deque::{Injector, Worker};\n    ///\n    /// let q = Injector::new();\n    /// q.push(1);\n    /// q.push(2);\n    /// q.push(3);\n    /// q.push(4);\n    ///\n    /// let w = Worker::new_fifo();\n    /// q.steal_batch(&w);\n    /// assert_eq!(w.pop(), Some(1));\n    /// assert_eq!(w.pop(), Some(2));\n    /// ```\n    pub fn steal_batch(&self, dest: &Worker<T>) -> Steal<()> {\n        let mut head;\n        let mut block;\n        let mut offset;\n\n        let backoff = Backoff::new();\n        loop {\n            head = self.head.index.load(Ordering::Acquire);\n            block = self.head.block.load(Ordering::Acquire);\n\n            // Calculate the offset of the index into the block.\n            offset = (head >> SHIFT) % LAP;\n\n            // If we reached the end of the block, wait until the next one is installed.\n            if offset == BLOCK_CAP {\n                backoff.snooze();\n            } else {\n                break;\n            }\n        }\n\n        let mut new_head = head;\n        let advance;\n\n        if new_head & HAS_NEXT == 0 {\n            atomic::fence(Ordering::SeqCst);\n            let tail = self.tail.index.load(Ordering::Relaxed);\n\n            // If the tail equals the head, that means the queue is empty.\n            if head >> SHIFT == tail >> SHIFT {\n                return Steal::Empty;\n            }\n\n            // If head and tail are not in the same block, set `HAS_NEXT` in head. Also, calculate\n            // the right batch size to steal.\n            if (head >> SHIFT) / LAP != (tail >> SHIFT) / LAP {\n                new_head |= HAS_NEXT;\n                // We can steal all tasks till the end of the block.\n                advance = (BLOCK_CAP - offset).min(MAX_BATCH);\n            } else {\n                let len = (tail - head) >> SHIFT;\n                // Steal half of the available tasks.\n                advance = ((len + 1) / 2).min(MAX_BATCH);\n            }\n        } else {\n            // We can steal all tasks till the end of the block.\n            advance = (BLOCK_CAP - offset).min(MAX_BATCH);\n        }\n\n        new_head += advance << SHIFT;\n        let new_offset = offset + advance;\n\n        // Try moving the head index forward.\n        if self\n            .head\n            .index\n            .compare_exchange_weak(head, new_head, Ordering::SeqCst, Ordering::Acquire)\n            .is_err()\n        {\n            return Steal::Retry;\n        }\n\n        // Reserve capacity for the stolen batch.\n        let batch_size = new_offset - offset;\n        dest.reserve(batch_size);\n\n        // Get the destination buffer and back index.\n        let dest_buffer = dest.buffer.get();\n        let dest_b = dest.inner.back.load(Ordering::Relaxed);\n\n        unsafe {\n            // If we've reached the end of the block, move to the next one.\n            if new_offset == BLOCK_CAP {\n                let next = (*block).wait_next();\n                let mut next_index = (new_head & !HAS_NEXT).wrapping_add(1 << SHIFT);\n                if !(*next).next.load(Ordering::Relaxed).is_null() {\n                    next_index |= HAS_NEXT;\n                }\n\n                self.head.block.store(next, Ordering::Release);\n                self.head.index.store(next_index, Ordering::Release);\n            }\n\n            // Copy values from the injector into the destination queue.\n            match dest.flavor {\n                Flavor::Fifo => {\n                    for i in 0..batch_size {\n                        // Read the task.\n                        let slot = (*block).slots.get_unchecked(offset + i);\n                        slot.wait_write();\n                        let m = slot.task.get().read();\n                        let task = ManuallyDrop::into_inner(m);\n\n                        // Write it into the destination queue.\n                        dest_buffer.write(dest_b.wrapping_add(i as isize), task);\n                    }\n                }\n\n                Flavor::Lifo => {\n                    for i in 0..batch_size {\n                        // Read the task.\n                        let slot = (*block).slots.get_unchecked(offset + i);\n                        slot.wait_write();\n                        let m = slot.task.get().read();\n                        let task = ManuallyDrop::into_inner(m);\n\n                        // Write it into the destination queue.\n                        dest_buffer.write(dest_b.wrapping_add((batch_size - 1 - i) as isize), task);\n                    }\n                }\n            }\n\n            atomic::fence(Ordering::Release);\n\n            // Update the back index in the destination queue.\n            //\n            // This ordering could be `Relaxed`, but then thread sanitizer would falsely report\n            // data races because it doesn't understand fences.\n            dest.inner\n                .back\n                .store(dest_b.wrapping_add(batch_size as isize), Ordering::Release);\n\n            // Destroy the block if we've reached the end, or if another thread wanted to destroy\n            // but couldn't because we were busy reading from the slot.\n            if new_offset == BLOCK_CAP {\n                Block::destroy(block, offset);\n            } else {\n                for i in offset..new_offset {\n                    let slot = (*block).slots.get_unchecked(i);\n\n                    if slot.state.fetch_or(READ, Ordering::AcqRel) & DESTROY != 0 {\n                        Block::destroy(block, offset);\n                        break;\n                    }\n                }\n            }\n\n            Steal::Success(())\n        }\n    }\n\n    /// Steals a batch of tasks, pushes them into a worker, and pops a task from that worker.\n    ///\n    /// How many tasks exactly will be stolen is not specified. That said, this method will try to\n    /// steal around half of the tasks in the queue, but also not more than some constant limit.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use crossbeam_deque::{Injector, Steal, Worker};\n    ///\n    /// let q = Injector::new();\n    /// q.push(1);\n    /// q.push(2);\n    /// q.push(3);\n    /// q.push(4);\n    ///\n    /// let w = Worker::new_fifo();\n    /// assert_eq!(q.steal_batch_and_pop(&w), Steal::Success(1));\n    /// assert_eq!(w.pop(), Some(2));\n    /// ```\n    pub fn steal_batch_and_pop(&self, dest: &Worker<T>) -> Steal<T> {\n        let mut head;\n        let mut block;\n        let mut offset;\n\n        let backoff = Backoff::new();\n        loop {\n            head = self.head.index.load(Ordering::Acquire);\n            block = self.head.block.load(Ordering::Acquire);\n\n            // Calculate the offset of the index into the block.\n            offset = (head >> SHIFT) % LAP;\n\n            // If we reached the end of the block, wait until the next one is installed.\n            if offset == BLOCK_CAP {\n                backoff.snooze();\n            } else {\n                break;\n            }\n        }\n\n        let mut new_head = head;\n        let advance;\n\n        if new_head & HAS_NEXT == 0 {\n            atomic::fence(Ordering::SeqCst);\n            let tail = self.tail.index.load(Ordering::Relaxed);\n\n            // If the tail equals the head, that means the queue is empty.\n            if head >> SHIFT == tail >> SHIFT {\n                return Steal::Empty;\n            }\n\n            // If head and tail are not in the same block, set `HAS_NEXT` in head.\n            if (head >> SHIFT) / LAP != (tail >> SHIFT) / LAP {\n                new_head |= HAS_NEXT;\n                // We can steal all tasks till the end of the block.\n                advance = (BLOCK_CAP - offset).min(MAX_BATCH + 1);\n            } else {\n                let len = (tail - head) >> SHIFT;\n                // Steal half of the available tasks.\n                advance = ((len + 1) / 2).min(MAX_BATCH + 1);\n            }\n        } else {\n            // We can steal all tasks till the end of the block.\n            advance = (BLOCK_CAP - offset).min(MAX_BATCH + 1);\n        }\n\n        new_head += advance << SHIFT;\n        let new_offset = offset + advance;\n\n        // Try moving the head index forward.\n        if self\n            .head\n            .index\n            .compare_exchange_weak(head, new_head, Ordering::SeqCst, Ordering::Acquire)\n            .is_err()\n        {\n            return Steal::Retry;\n        }\n\n        // Reserve capacity for the stolen batch.\n        let batch_size = new_offset - offset - 1;\n        dest.reserve(batch_size);\n\n        // Get the destination buffer and back index.\n        let dest_buffer = dest.buffer.get();\n        let dest_b = dest.inner.back.load(Ordering::Relaxed);\n\n        unsafe {\n            // If we've reached the end of the block, move to the next one.\n            if new_offset == BLOCK_CAP {\n                let next = (*block).wait_next();\n                let mut next_index = (new_head & !HAS_NEXT).wrapping_add(1 << SHIFT);\n                if !(*next).next.load(Ordering::Relaxed).is_null() {\n                    next_index |= HAS_NEXT;\n                }\n\n                self.head.block.store(next, Ordering::Release);\n                self.head.index.store(next_index, Ordering::Release);\n            }\n\n            // Read the task.\n            let slot = (*block).slots.get_unchecked(offset);\n            slot.wait_write();\n            let m = slot.task.get().read();\n            let task = ManuallyDrop::into_inner(m);\n\n            match dest.flavor {\n                Flavor::Fifo => {\n                    // Copy values from the injector into the destination queue.\n                    for i in 0..batch_size {\n                        // Read the task.\n                        let slot = (*block).slots.get_unchecked(offset + i + 1);\n                        slot.wait_write();\n                        let m = slot.task.get().read();\n                        let task = ManuallyDrop::into_inner(m);\n\n                        // Write it into the destination queue.\n                        dest_buffer.write(dest_b.wrapping_add(i as isize), task);\n                    }\n                }\n\n                Flavor::Lifo => {\n                    // Copy values from the injector into the destination queue.\n                    for i in 0..batch_size {\n                        // Read the task.\n                        let slot = (*block).slots.get_unchecked(offset + i + 1);\n                        slot.wait_write();\n                        let m = slot.task.get().read();\n                        let task = ManuallyDrop::into_inner(m);\n\n                        // Write it into the destination queue.\n                        dest_buffer.write(dest_b.wrapping_add((batch_size - 1 - i) as isize), task);\n                    }\n                }\n            }\n\n            atomic::fence(Ordering::Release);\n\n            // Update the back index in the destination queue.\n            //\n            // This ordering could be `Relaxed`, but then thread sanitizer would falsely report\n            // data races because it doesn't understand fences.\n            dest.inner\n                .back\n                .store(dest_b.wrapping_add(batch_size as isize), Ordering::Release);\n\n            // Destroy the block if we've reached the end, or if another thread wanted to destroy\n            // but couldn't because we were busy reading from the slot.\n            if new_offset == BLOCK_CAP {\n                Block::destroy(block, offset);\n            } else {\n                for i in offset..new_offset {\n                    let slot = (*block).slots.get_unchecked(i);\n\n                    if slot.state.fetch_or(READ, Ordering::AcqRel) & DESTROY != 0 {\n                        Block::destroy(block, offset);\n                        break;\n                    }\n                }\n            }\n\n            Steal::Success(task)\n        }\n    }\n\n    /// Returns `true` if the queue is empty.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use crossbeam_deque::Injector;\n    ///\n    /// let q = Injector::new();\n    ///\n    /// assert!(q.is_empty());\n    /// q.push(1);\n    /// assert!(!q.is_empty());\n    /// ```\n    pub fn is_empty(&self) -> bool {\n        let head = self.head.index.load(Ordering::SeqCst);\n        let tail = self.tail.index.load(Ordering::SeqCst);\n        head >> SHIFT == tail >> SHIFT\n    }\n}\n\nimpl<T> Drop for Injector<T> {\n    fn drop(&mut self) {\n        let mut head = self.head.index.load(Ordering::Relaxed);\n        let mut tail = self.tail.index.load(Ordering::Relaxed);\n        let mut block = self.head.block.load(Ordering::Relaxed);\n\n        // Erase the lower bits.\n        head &= !((1 << SHIFT) - 1);\n        tail &= !((1 << SHIFT) - 1);\n\n        unsafe {\n            // Drop all values between `head` and `tail` and deallocate the heap-allocated blocks.\n            while head != tail {\n                let offset = (head >> SHIFT) % LAP;\n\n                if offset < BLOCK_CAP {\n                    // Drop the task in the slot.\n                    let slot = (*block).slots.get_unchecked(offset);\n                    ManuallyDrop::drop(&mut *(*slot).task.get());\n                } else {\n                    // Deallocate the block and move to the next one.\n                    let next = (*block).next.load(Ordering::Relaxed);\n                    drop(Box::from_raw(block));\n                    block = next;\n                }\n\n                head = head.wrapping_add(1 << SHIFT);\n            }\n\n            // Deallocate the last remaining block.\n            drop(Box::from_raw(block));\n        }\n    }\n}\n\nimpl<T> fmt::Debug for Injector<T> {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        f.pad(\"Worker { .. }\")\n    }\n}\n\n/// Possible outcomes of a steal operation.\n///\n/// # Examples\n///\n/// There are lots of ways to chain results of steal operations together:\n///\n/// ```\n/// use crossbeam_deque::Steal::{self, Empty, Retry, Success};\n///\n/// let collect = |v: Vec<Steal<i32>>| v.into_iter().collect::<Steal<i32>>();\n///\n/// assert_eq!(collect(vec![Empty, Empty, Empty]), Empty);\n/// assert_eq!(collect(vec![Empty, Retry, Empty]), Retry);\n/// assert_eq!(collect(vec![Retry, Success(1), Empty]), Success(1));\n///\n/// assert_eq!(collect(vec![Empty, Empty]).or_else(|| Retry), Retry);\n/// assert_eq!(collect(vec![Retry, Empty]).or_else(|| Success(1)), Success(1));\n/// ```\n#[must_use]\n#[derive(PartialEq, Eq, Copy, Clone)]\npub enum Steal<T> {\n    /// The queue was empty at the time of stealing.\n    Empty,\n\n    /// At least one task was successfully stolen.\n    Success(T),\n\n    /// The steal operation needs to be retried.\n    Retry,\n}\n\nimpl<T> Steal<T> {\n    /// Returns `true` if the queue was empty at the time of stealing.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use crossbeam_deque::Steal::{Empty, Retry, Success};\n    ///\n    /// assert!(!Success(7).is_empty());\n    /// assert!(!Retry::<i32>.is_empty());\n    ///\n    /// assert!(Empty::<i32>.is_empty());\n    /// ```\n    pub fn is_empty(&self) -> bool {\n        match self {\n            Steal::Empty => true,\n            _ => false,\n        }\n    }\n\n    /// Returns `true` if at least one task was stolen.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use crossbeam_deque::Steal::{Empty, Retry, Success};\n    ///\n    /// assert!(!Empty::<i32>.is_success());\n    /// assert!(!Retry::<i32>.is_success());\n    ///\n    /// assert!(Success(7).is_success());\n    /// ```\n    pub fn is_success(&self) -> bool {\n        match self {\n            Steal::Success(_) => true,\n            _ => false,\n        }\n    }\n\n    /// Returns `true` if the steal operation needs to be retried.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use crossbeam_deque::Steal::{Empty, Retry, Success};\n    ///\n    /// assert!(!Empty::<i32>.is_retry());\n    /// assert!(!Success(7).is_retry());\n    ///\n    /// assert!(Retry::<i32>.is_retry());\n    /// ```\n    pub fn is_retry(&self) -> bool {\n        match self {\n            Steal::Retry => true,\n            _ => false,\n        }\n    }\n\n    /// Returns the result of the operation, if successful.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use crossbeam_deque::Steal::{Empty, Retry, Success};\n    ///\n    /// assert_eq!(Empty::<i32>.success(), None);\n    /// assert_eq!(Retry::<i32>.success(), None);\n    ///\n    /// assert_eq!(Success(7).success(), Some(7));\n    /// ```\n    pub fn success(self) -> Option<T> {\n        match self {\n            Steal::Success(res) => Some(res),\n            _ => None,\n        }\n    }\n\n    /// If no task was stolen, attempts another steal operation.\n    ///\n    /// Returns this steal result if it is `Success`. Otherwise, closure `f` is invoked and then:\n    ///\n    /// * If the second steal resulted in `Success`, it is returned.\n    /// * If both steals were unsuccessful but any resulted in `Retry`, then `Retry` is returned.\n    /// * If both resulted in `None`, then `None` is returned.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use crossbeam_deque::Steal::{Empty, Retry, Success};\n    ///\n    /// assert_eq!(Success(1).or_else(|| Success(2)), Success(1));\n    /// assert_eq!(Retry.or_else(|| Success(2)), Success(2));\n    ///\n    /// assert_eq!(Retry.or_else(|| Empty), Retry::<i32>);\n    /// assert_eq!(Empty.or_else(|| Retry), Retry::<i32>);\n    ///\n    /// assert_eq!(Empty.or_else(|| Empty), Empty::<i32>);\n    /// ```\n    pub fn or_else<F>(self, f: F) -> Steal<T>\n    where\n        F: FnOnce() -> Steal<T>,\n    {\n        match self {\n            Steal::Empty => f(),\n            Steal::Success(_) => self,\n            Steal::Retry => {\n                if let Steal::Success(res) = f() {\n                    Steal::Success(res)\n                } else {\n                    Steal::Retry\n                }\n            }\n        }\n    }\n}\n\nimpl<T> fmt::Debug for Steal<T> {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        match self {\n            Steal::Empty => f.pad(\"Empty\"),\n            Steal::Success(_) => f.pad(\"Success(..)\"),\n            Steal::Retry => f.pad(\"Retry\"),\n        }\n    }\n}\n\nimpl<T> FromIterator<Steal<T>> for Steal<T> {\n    /// Consumes items until a `Success` is found and returns it.\n    ///\n    /// If no `Success` was found, but there was at least one `Retry`, then returns `Retry`.\n    /// Otherwise, `Empty` is returned.\n    fn from_iter<I>(iter: I) -> Steal<T>\n    where\n        I: IntoIterator<Item = Steal<T>>,\n    {\n        let mut retry = false;\n        for s in iter {\n            match &s {\n                Steal::Empty => {}\n                Steal::Success(_) => return s,\n                Steal::Retry => retry = true,\n            }\n        }\n\n        if retry {\n            Steal::Retry\n        } else {\n            Steal::Empty\n        }\n    }\n}\n"
  },
  {
    "project": "crossbeam",
    "target": 1,
    "commit_id": "68e8708c2dda24e4b3b1807f5f301ca2b8ffa357",
    "func": "use alloc::boxed::Box;\nuse core::fmt;\nuse core::marker::PhantomData;\nuse core::mem;\nuse core::ptr;\n\n/// Number of words a piece of `Data` can hold.\n///\n/// Three words should be enough for the majority of cases. For example, you can fit inside it the\n/// function pointer together with a fat pointer representing an object that needs to be destroyed.\nconst DATA_WORDS: usize = 3;\n\n/// Some space to keep a `FnOnce()` object on the stack.\ntype Data = [usize; DATA_WORDS];\n\n/// A `FnOnce()` that is stored inline if small, or otherwise boxed on the heap.\n///\n/// This is a handy way of keeping an unsized `FnOnce()` within a sized structure.\npub struct Deferred {\n    call: unsafe fn(*mut u8),\n    data: Data,\n    _marker: PhantomData<*mut ()>, // !Send + !Sync\n}\n\nimpl fmt::Debug for Deferred {\n    fn fmt(&self, f: &mut fmt::Formatter) -> Result<(), fmt::Error> {\n        f.pad(\"Deferred { .. }\")\n    }\n}\n\nimpl Deferred {\n    /// Constructs a new `Deferred` from a `FnOnce()`.\n    pub fn new<F: FnOnce()>(f: F) -> Self {\n        let size = mem::size_of::<F>();\n        let align = mem::align_of::<F>();\n\n        unsafe {\n            if size <= mem::size_of::<Data>() && align <= mem::align_of::<Data>() {\n                // TODO(taiki-e): when the minimum supported Rust version is bumped to 1.36+,\n                // replace this with `mem::MaybeUninit`.\n                #[allow(deprecated)]\n                let mut data: Data = mem::uninitialized();\n                ptr::write(&mut data as *mut Data as *mut F, f);\n\n                unsafe fn call<F: FnOnce()>(raw: *mut u8) {\n                    let f: F = ptr::read(raw as *mut F);\n                    f();\n                }\n\n                Deferred {\n                    call: call::<F>,\n                    data,\n                    _marker: PhantomData,\n                }\n            } else {\n                let b: Box<F> = Box::new(f);\n                // TODO(taiki-e): when the minimum supported Rust version is bumped to 1.36+,\n                // replace this with `mem::MaybeUninit`.\n                #[allow(deprecated)]\n                let mut data: Data = mem::uninitialized();\n                ptr::write(&mut data as *mut Data as *mut Box<F>, b);\n\n                unsafe fn call<F: FnOnce()>(raw: *mut u8) {\n                    let b: Box<F> = ptr::read(raw as *mut Box<F>);\n                    (*b)();\n                }\n\n                Deferred {\n                    call: call::<F>,\n                    data,\n                    _marker: PhantomData,\n                }\n            }\n        }\n    }\n\n    /// Calls the function.\n    #[inline]\n    pub fn call(mut self) {\n        let call = self.call;\n        unsafe { call(&mut self.data as *mut Data as *mut u8) };\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::Deferred;\n    use std::cell::Cell;\n\n    #[test]\n    fn on_stack() {\n        let fired = &Cell::new(false);\n        let a = [0usize; 1];\n\n        let d = Deferred::new(move || {\n            drop(a);\n            fired.set(true);\n        });\n\n        assert!(!fired.get());\n        d.call();\n        assert!(fired.get());\n    }\n\n    #[test]\n    fn on_heap() {\n        let fired = &Cell::new(false);\n        let a = [0usize; 10];\n\n        let d = Deferred::new(move || {\n            drop(a);\n            fired.set(true);\n        });\n\n        assert!(!fired.get());\n        d.call();\n        assert!(fired.get());\n    }\n\n    #[test]\n    fn string() {\n        let a = \"hello\".to_string();\n        let d = Deferred::new(move || assert_eq!(a, \"hello\"));\n        d.call();\n    }\n\n    #[test]\n    fn boxed_slice_i32() {\n        let a: Box<[i32]> = vec![2, 3, 5, 7].into_boxed_slice();\n        let d = Deferred::new(move || assert_eq!(*a, [2, 3, 5, 7]));\n        d.call();\n    }\n\n    #[test]\n    fn long_slice_usize() {\n        let a: [usize; 5] = [2, 3, 5, 7, 11];\n        let d = Deferred::new(move || assert_eq!(a, [2, 3, 5, 7, 11]));\n        d.call();\n    }\n}\n"
  },
  {
    "project": "crossbeam",
    "target": 1,
    "commit_id": "e0fd465b9b7de8b60b0b588e264aca1fa92fbd18",
    "func": "//! Michael-Scott lock-free queue.\n//!\n//! Usable with any number of producers and consumers.\n//!\n//! Michael and Scott.  Simple, Fast, and Practical Non-Blocking and Blocking Concurrent Queue\n//! Algorithms.  PODC 1996.  http://dl.acm.org/citation.cfm?id=248106\n//!\n//! Simon Doherty, Lindsay Groves, Victor Luchangco, and Mark Moir. 2004b. Formal Verification of a\n//! Practical Lock-Free Queue Algorithm. https://doi.org/10.1007/978-3-540-30232-2_7\n\nuse core::mem::{self, ManuallyDrop};\nuse core::ptr;\nuse core::sync::atomic::Ordering::{Acquire, Relaxed, Release};\n\nuse crossbeam_utils::CachePadded;\n\nuse {unprotected, Atomic, Guard, Owned, Shared};\n\n// The representation here is a singly-linked list, with a sentinel node at the front. In general\n// the `tail` pointer may lag behind the actual tail. Non-sentinel nodes are either all `Data` or\n// all `Blocked` (requests for data from blocked threads).\n#[derive(Debug)]\npub struct Queue<T> {\n    head: CachePadded<Atomic<Node<T>>>,\n    tail: CachePadded<Atomic<Node<T>>>,\n}\n\n#[derive(Debug)]\nstruct Node<T> {\n    /// The slot in which a value of type `T` can be stored.\n    ///\n    /// The type of `data` is `ManuallyDrop<T>` because a `Node<T>` doesn't always contain a `T`.\n    /// For example, the sentinel node in a queue never contains a value: its slot is always empty.\n    /// Other nodes start their life with a push operation and contain a value until it gets popped\n    /// out. After that such empty nodes get added to the collector for destruction.\n    data: ManuallyDrop<T>,\n\n    next: Atomic<Node<T>>,\n}\n\n// Any particular `T` should never be accessed concurrently, so no need for `Sync`.\nunsafe impl<T: Send> Sync for Queue<T> {}\nunsafe impl<T: Send> Send for Queue<T> {}\n\nimpl<T> Queue<T> {\n    /// Create a new, empty queue.\n    pub fn new() -> Queue<T> {\n        let q = Queue {\n            head: CachePadded::new(Atomic::null()),\n            tail: CachePadded::new(Atomic::null()),\n        };\n        // TODO(taiki-e): when the minimum supported Rust version is bumped to 1.36+,\n        // replace this with `mem::MaybeUninit`.\n        #[allow(deprecated)]\n        let sentinel = Owned::new(Node {\n            data: unsafe { mem::uninitialized() },\n            next: Atomic::null(),\n        });\n        unsafe {\n            let guard = &unprotected();\n            let sentinel = sentinel.into_shared(guard);\n            q.head.store(sentinel, Relaxed);\n            q.tail.store(sentinel, Relaxed);\n            q\n        }\n    }\n\n    /// Attempts to atomically place `n` into the `next` pointer of `onto`, and returns `true` on\n    /// success. The queue's `tail` pointer may be updated.\n    #[inline(always)]\n    fn push_internal(&self, onto: Shared<Node<T>>, new: Shared<Node<T>>, guard: &Guard) -> bool {\n        // is `onto` the actual tail?\n        let o = unsafe { onto.deref() };\n        let next = o.next.load(Acquire, guard);\n        if unsafe { next.as_ref().is_some() } {\n            // if not, try to \"help\" by moving the tail pointer forward\n            let _ = self.tail.compare_and_set(onto, next, Release, guard);\n            false\n        } else {\n            // looks like the actual tail; attempt to link in `n`\n            let result = o\n                .next\n                .compare_and_set(Shared::null(), new, Release, guard)\n                .is_ok();\n            if result {\n                // try to move the tail pointer forward\n                let _ = self.tail.compare_and_set(onto, new, Release, guard);\n            }\n            result\n        }\n    }\n\n    /// Adds `t` to the back of the queue, possibly waking up threads blocked on `pop`.\n    pub fn push(&self, t: T, guard: &Guard) {\n        let new = Owned::new(Node {\n            data: ManuallyDrop::new(t),\n            next: Atomic::null(),\n        });\n        let new = Owned::into_shared(new, guard);\n\n        loop {\n            // We push onto the tail, so we'll start optimistically by looking there first.\n            let tail = self.tail.load(Acquire, guard);\n\n            // Attempt to push onto the `tail` snapshot; fails if `tail.next` has changed.\n            if self.push_internal(tail, new, guard) {\n                break;\n            }\n        }\n    }\n\n    /// Attempts to pop a data node. `Ok(None)` if queue is empty; `Err(())` if lost race to pop.\n    #[inline(always)]\n    fn pop_internal(&self, guard: &Guard) -> Result<Option<T>, ()> {\n        let head = self.head.load(Acquire, guard);\n        let h = unsafe { head.deref() };\n        let next = h.next.load(Acquire, guard);\n        match unsafe { next.as_ref() } {\n            Some(n) => unsafe {\n                self.head\n                    .compare_and_set(head, next, Release, guard)\n                    .map(|_| {\n                        let tail = self.tail.load(Relaxed, guard);\n                        // Advance the tail so that we don't retire a pointer to a reachable node.\n                        if head == tail {\n                            let _ = self.tail.compare_and_set(tail, next, Release, guard);\n                        }\n                        guard.defer_destroy(head);\n                        Some(ManuallyDrop::into_inner(ptr::read(&n.data)))\n                    })\n                    .map_err(|_| ())\n            },\n            None => Ok(None),\n        }\n    }\n\n    /// Attempts to pop a data node, if the data satisfies the given condition. `Ok(None)` if queue\n    /// is empty or the data does not satisfy the condition; `Err(())` if lost race to pop.\n    #[inline(always)]\n    fn pop_if_internal<F>(&self, condition: F, guard: &Guard) -> Result<Option<T>, ()>\n    where\n        T: Sync,\n        F: Fn(&T) -> bool,\n    {\n        let head = self.head.load(Acquire, guard);\n        let h = unsafe { head.deref() };\n        let next = h.next.load(Acquire, guard);\n        match unsafe { next.as_ref() } {\n            Some(n) if condition(&n.data) => unsafe {\n                self.head\n                    .compare_and_set(head, next, Release, guard)\n                    .map(|_| {\n                        let tail = self.tail.load(Relaxed, guard);\n                        // Advance the tail so that we don't retire a pointer to a reachable node.\n                        if head == tail {\n                            let _ = self.tail.compare_and_set(tail, next, Release, guard);\n                        }\n                        guard.defer_destroy(head);\n                        Some(ManuallyDrop::into_inner(ptr::read(&n.data)))\n                    })\n                    .map_err(|_| ())\n            },\n            None | Some(_) => Ok(None),\n        }\n    }\n\n    /// Attempts to dequeue from the front.\n    ///\n    /// Returns `None` if the queue is observed to be empty.\n    pub fn try_pop(&self, guard: &Guard) -> Option<T> {\n        loop {\n            if let Ok(head) = self.pop_internal(guard) {\n                return head;\n            }\n        }\n    }\n\n    /// Attempts to dequeue from the front, if the item satisfies the given condition.\n    ///\n    /// Returns `None` if the queue is observed to be empty, or the head does not satisfy the given\n    /// condition.\n    pub fn try_pop_if<F>(&self, condition: F, guard: &Guard) -> Option<T>\n    where\n        T: Sync,\n        F: Fn(&T) -> bool,\n    {\n        loop {\n            if let Ok(head) = self.pop_if_internal(&condition, guard) {\n                return head;\n            }\n        }\n    }\n}\n\nimpl<T> Drop for Queue<T> {\n    fn drop(&mut self) {\n        unsafe {\n            let guard = &unprotected();\n\n            while let Some(_) = self.try_pop(guard) {}\n\n            // Destroy the remaining sentinel node.\n            let sentinel = self.head.load(Relaxed, guard);\n            drop(sentinel.into_owned());\n        }\n    }\n}\n\n#[cfg(test)]\nmod test {\n    use super::*;\n    use crossbeam_utils::thread;\n    use pin;\n\n    struct Queue<T> {\n        queue: super::Queue<T>,\n    }\n\n    impl<T> Queue<T> {\n        pub fn new() -> Queue<T> {\n            Queue {\n                queue: super::Queue::new(),\n            }\n        }\n\n        pub fn push(&self, t: T) {\n            let guard = &pin();\n            self.queue.push(t, guard);\n        }\n\n        pub fn is_empty(&self) -> bool {\n            let guard = &pin();\n            let head = self.queue.head.load(Acquire, guard);\n            let h = unsafe { head.deref() };\n            h.next.load(Acquire, guard).is_null()\n        }\n\n        pub fn try_pop(&self) -> Option<T> {\n            let guard = &pin();\n            self.queue.try_pop(guard)\n        }\n\n        pub fn pop(&self) -> T {\n            loop {\n                match self.try_pop() {\n                    None => continue,\n                    Some(t) => return t,\n                }\n            }\n        }\n    }\n\n    const CONC_COUNT: i64 = 1000000;\n\n    #[test]\n    fn push_try_pop_1() {\n        let q: Queue<i64> = Queue::new();\n        assert!(q.is_empty());\n        q.push(37);\n        assert!(!q.is_empty());\n        assert_eq!(q.try_pop(), Some(37));\n        assert!(q.is_empty());\n    }\n\n    #[test]\n    fn push_try_pop_2() {\n        let q: Queue<i64> = Queue::new();\n        assert!(q.is_empty());\n        q.push(37);\n        q.push(48);\n        assert_eq!(q.try_pop(), Some(37));\n        assert!(!q.is_empty());\n        assert_eq!(q.try_pop(), Some(48));\n        assert!(q.is_empty());\n    }\n\n    #[test]\n    fn push_try_pop_many_seq() {\n        let q: Queue<i64> = Queue::new();\n        assert!(q.is_empty());\n        for i in 0..200 {\n            q.push(i)\n        }\n        assert!(!q.is_empty());\n        for i in 0..200 {\n            assert_eq!(q.try_pop(), Some(i));\n        }\n        assert!(q.is_empty());\n    }\n\n    #[test]\n    fn push_pop_1() {\n        let q: Queue<i64> = Queue::new();\n        assert!(q.is_empty());\n        q.push(37);\n        assert!(!q.is_empty());\n        assert_eq!(q.pop(), 37);\n        assert!(q.is_empty());\n    }\n\n    #[test]\n    fn push_pop_2() {\n        let q: Queue<i64> = Queue::new();\n        q.push(37);\n        q.push(48);\n        assert_eq!(q.pop(), 37);\n        assert_eq!(q.pop(), 48);\n    }\n\n    #[test]\n    fn push_pop_many_seq() {\n        let q: Queue<i64> = Queue::new();\n        assert!(q.is_empty());\n        for i in 0..200 {\n            q.push(i)\n        }\n        assert!(!q.is_empty());\n        for i in 0..200 {\n            assert_eq!(q.pop(), i);\n        }\n        assert!(q.is_empty());\n    }\n\n    #[test]\n    fn push_try_pop_many_spsc() {\n        let q: Queue<i64> = Queue::new();\n        assert!(q.is_empty());\n\n        thread::scope(|scope| {\n            scope.spawn(|_| {\n                let mut next = 0;\n\n                while next < CONC_COUNT {\n                    if let Some(elem) = q.try_pop() {\n                        assert_eq!(elem, next);\n                        next += 1;\n                    }\n                }\n            });\n\n            for i in 0..CONC_COUNT {\n                q.push(i)\n            }\n        })\n        .unwrap();\n    }\n\n    #[test]\n    fn push_try_pop_many_spmc() {\n        fn recv(_t: i32, q: &Queue<i64>) {\n            let mut cur = -1;\n            for _i in 0..CONC_COUNT {\n                if let Some(elem) = q.try_pop() {\n                    assert!(elem > cur);\n                    cur = elem;\n\n                    if cur == CONC_COUNT - 1 {\n                        break;\n                    }\n                }\n            }\n        }\n\n        let q: Queue<i64> = Queue::new();\n        assert!(q.is_empty());\n        thread::scope(|scope| {\n            for i in 0..3 {\n                let q = &q;\n                scope.spawn(move |_| recv(i, q));\n            }\n\n            scope.spawn(|_| {\n                for i in 0..CONC_COUNT {\n                    q.push(i);\n                }\n            });\n        })\n        .unwrap();\n    }\n\n    #[test]\n    fn push_try_pop_many_mpmc() {\n        enum LR {\n            Left(i64),\n            Right(i64),\n        }\n\n        let q: Queue<LR> = Queue::new();\n        assert!(q.is_empty());\n\n        thread::scope(|scope| {\n            for _t in 0..2 {\n                scope.spawn(|_| {\n                    for i in CONC_COUNT - 1..CONC_COUNT {\n                        q.push(LR::Left(i))\n                    }\n                });\n                scope.spawn(|_| {\n                    for i in CONC_COUNT - 1..CONC_COUNT {\n                        q.push(LR::Right(i))\n                    }\n                });\n                scope.spawn(|_| {\n                    let mut vl = vec![];\n                    let mut vr = vec![];\n                    for _i in 0..CONC_COUNT {\n                        match q.try_pop() {\n                            Some(LR::Left(x)) => vl.push(x),\n                            Some(LR::Right(x)) => vr.push(x),\n                            _ => {}\n                        }\n                    }\n\n                    let mut vl2 = vl.clone();\n                    let mut vr2 = vr.clone();\n                    vl2.sort();\n                    vr2.sort();\n\n                    assert_eq!(vl, vl2);\n                    assert_eq!(vr, vr2);\n                });\n            }\n        })\n        .unwrap();\n    }\n\n    #[test]\n    fn push_pop_many_spsc() {\n        let q: Queue<i64> = Queue::new();\n\n        thread::scope(|scope| {\n            scope.spawn(|_| {\n                let mut next = 0;\n                while next < CONC_COUNT {\n                    assert_eq!(q.pop(), next);\n                    next += 1;\n                }\n            });\n\n            for i in 0..CONC_COUNT {\n                q.push(i)\n            }\n        })\n        .unwrap();\n        assert!(q.is_empty());\n    }\n\n    #[test]\n    fn is_empty_dont_pop() {\n        let q: Queue<i64> = Queue::new();\n        q.push(20);\n        q.push(20);\n        assert!(!q.is_empty());\n        assert!(!q.is_empty());\n        assert!(q.try_pop().is_some());\n    }\n}\n"
  },
  {
    "project": "crossbeam",
    "target": 1,
    "commit_id": "f48c1c763a73467e2fde6158c0abc2faa162ae81",
    "func": "//! The implementation is based on Dmitry Vyukov's bounded MPMC queue.\n//!\n//! Source:\n//!   - http://www.1024cores.net/home/lock-free-algorithms/queues/bounded-mpmc-queue\n//!\n//! Copyright & License:\n//!   - Copyright (c) 2010-2011 Dmitry Vyukov\n//!   - Simplified BSD License and Apache License, Version 2.0\n//!   - http://www.1024cores.net/home/code-license\n\nuse alloc::vec::Vec;\nuse core::cell::UnsafeCell;\nuse core::fmt;\nuse core::marker::PhantomData;\nuse core::mem;\nuse core::ptr;\nuse core::sync::atomic::{self, AtomicUsize, Ordering};\n\nuse crossbeam_utils::{Backoff, CachePadded};\n\nuse err::{PopError, PushError};\n\n/// A slot in a queue.\nstruct Slot<T> {\n    /// The current stamp.\n    ///\n    /// If the stamp equals the tail, this node will be next written to. If it equals head + 1,\n    /// this node will be next read from.\n    stamp: AtomicUsize,\n\n    /// The value in this slot.\n    value: UnsafeCell<T>,\n}\n\n/// A bounded multi-producer multi-consumer queue.\n///\n/// This queue allocates a fixed-capacity buffer on construction, which is used to store pushed\n/// elements. The queue cannot hold more elements than the buffer allows. Attempting to push an\n/// element into a full queue will fail. Having a buffer allocated upfront makes this queue a bit\n/// faster than [`SegQueue`].\n///\n/// [`SegQueue`]: struct.SegQueue.html\n///\n/// # Examples\n///\n/// ```\n/// use crossbeam_queue::{ArrayQueue, PushError};\n///\n/// let q = ArrayQueue::new(2);\n///\n/// assert_eq!(q.push('a'), Ok(()));\n/// assert_eq!(q.push('b'), Ok(()));\n/// assert_eq!(q.push('c'), Err(PushError('c')));\n/// assert_eq!(q.pop(), Ok('a'));\n/// ```\npub struct ArrayQueue<T> {\n    /// The head of the queue.\n    ///\n    /// This value is a \"stamp\" consisting of an index into the buffer and a lap, but packed into a\n    /// single `usize`. The lower bits represent the index, while the upper bits represent the lap.\n    ///\n    /// Elements are popped from the head of the queue.\n    head: CachePadded<AtomicUsize>,\n\n    /// The tail of the queue.\n    ///\n    /// This value is a \"stamp\" consisting of an index into the buffer and a lap, but packed into a\n    /// single `usize`. The lower bits represent the index, while the upper bits represent the lap.\n    ///\n    /// Elements are pushed into the tail of the queue.\n    tail: CachePadded<AtomicUsize>,\n\n    /// The buffer holding slots.\n    buffer: *mut Slot<T>,\n\n    /// The queue capacity.\n    cap: usize,\n\n    /// A stamp with the value of `{ lap: 1, index: 0 }`.\n    one_lap: usize,\n\n    /// Indicates that dropping an `ArrayQueue<T>` may drop elements of type `T`.\n    _marker: PhantomData<T>,\n}\n\nunsafe impl<T: Send> Sync for ArrayQueue<T> {}\nunsafe impl<T: Send> Send for ArrayQueue<T> {}\n\nimpl<T> ArrayQueue<T> {\n    /// Creates a new bounded queue with the given capacity.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the capacity is zero.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use crossbeam_queue::ArrayQueue;\n    ///\n    /// let q = ArrayQueue::<i32>::new(100);\n    /// ```\n    pub fn new(cap: usize) -> ArrayQueue<T> {\n        assert!(cap > 0, \"capacity must be non-zero\");\n\n        // Head is initialized to `{ lap: 0, index: 0 }`.\n        // Tail is initialized to `{ lap: 0, index: 0 }`.\n        let head = 0;\n        let tail = 0;\n\n        // Allocate a buffer of `cap` slots.\n        let buffer = {\n            let mut v = Vec::<Slot<T>>::with_capacity(cap);\n            let ptr = v.as_mut_ptr();\n            mem::forget(v);\n            ptr\n        };\n\n        // Initialize stamps in the slots.\n        for i in 0..cap {\n            unsafe {\n                // Set the stamp to `{ lap: 0, index: i }`.\n                let slot = buffer.add(i);\n                ptr::write(&mut (*slot).stamp, AtomicUsize::new(i));\n            }\n        }\n\n        // One lap is the smallest power of two greater than `cap`.\n        let one_lap = (cap + 1).next_power_of_two();\n\n        ArrayQueue {\n            buffer,\n            cap,\n            one_lap,\n            head: CachePadded::new(AtomicUsize::new(head)),\n            tail: CachePadded::new(AtomicUsize::new(tail)),\n            _marker: PhantomData,\n        }\n    }\n\n    /// Attempts to push an element into the queue.\n    ///\n    /// If the queue is full, the element is returned back as an error.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use crossbeam_queue::{ArrayQueue, PushError};\n    ///\n    /// let q = ArrayQueue::new(1);\n    ///\n    /// assert_eq!(q.push(10), Ok(()));\n    /// assert_eq!(q.push(20), Err(PushError(20)));\n    /// ```\n    pub fn push(&self, value: T) -> Result<(), PushError<T>> {\n        let backoff = Backoff::new();\n        let mut tail = self.tail.load(Ordering::Relaxed);\n\n        loop {\n            // Deconstruct the tail.\n            let index = tail & (self.one_lap - 1);\n            let lap = tail & !(self.one_lap - 1);\n\n            // Inspect the corresponding slot.\n            let slot = unsafe { &*self.buffer.add(index) };\n            let stamp = slot.stamp.load(Ordering::Acquire);\n\n            // If the tail and the stamp match, we may attempt to push.\n            if tail == stamp {\n                let new_tail = if index + 1 < self.cap {\n                    // Same lap, incremented index.\n                    // Set to `{ lap: lap, index: index + 1 }`.\n                    tail + 1\n                } else {\n                    // One lap forward, index wraps around to zero.\n                    // Set to `{ lap: lap.wrapping_add(1), index: 0 }`.\n                    lap.wrapping_add(self.one_lap)\n                };\n\n                // Try moving the tail.\n                match self.tail.compare_exchange_weak(\n                    tail,\n                    new_tail,\n                    Ordering::SeqCst,\n                    Ordering::Relaxed,\n                ) {\n                    Ok(_) => {\n                        // Write the value into the slot and update the stamp.\n                        unsafe {\n                            slot.value.get().write(value);\n                        }\n                        slot.stamp.store(tail + 1, Ordering::Release);\n                        return Ok(());\n                    }\n                    Err(t) => {\n                        tail = t;\n                        backoff.spin();\n                    }\n                }\n            } else if stamp.wrapping_add(self.one_lap) == tail + 1 {\n                atomic::fence(Ordering::SeqCst);\n                let head = self.head.load(Ordering::Relaxed);\n\n                // If the head lags one lap behind the tail as well...\n                if head.wrapping_add(self.one_lap) == tail {\n                    // ...then the queue is full.\n                    return Err(PushError(value));\n                }\n\n                backoff.spin();\n                tail = self.tail.load(Ordering::Relaxed);\n            } else {\n                // Snooze because we need to wait for the stamp to get updated.\n                backoff.snooze();\n                tail = self.tail.load(Ordering::Relaxed);\n            }\n        }\n    }\n\n    /// Attempts to pop an element from the queue.\n    ///\n    /// If the queue is empty, an error is returned.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use crossbeam_queue::{ArrayQueue, PopError};\n    ///\n    /// let q = ArrayQueue::new(1);\n    /// assert_eq!(q.push(10), Ok(()));\n    ///\n    /// assert_eq!(q.pop(), Ok(10));\n    /// assert_eq!(q.pop(), Err(PopError));\n    /// ```\n    pub fn pop(&self) -> Result<T, PopError> {\n        let backoff = Backoff::new();\n        let mut head = self.head.load(Ordering::Relaxed);\n\n        loop {\n            // Deconstruct the head.\n            let index = head & (self.one_lap - 1);\n            let lap = head & !(self.one_lap - 1);\n\n            // Inspect the corresponding slot.\n            let slot = unsafe { &*self.buffer.add(index) };\n            let stamp = slot.stamp.load(Ordering::Acquire);\n\n            // If the the stamp is ahead of the head by 1, we may attempt to pop.\n            if head + 1 == stamp {\n                let new = if index + 1 < self.cap {\n                    // Same lap, incremented index.\n                    // Set to `{ lap: lap, index: index + 1 }`.\n                    head + 1\n                } else {\n                    // One lap forward, index wraps around to zero.\n                    // Set to `{ lap: lap.wrapping_add(1), index: 0 }`.\n                    lap.wrapping_add(self.one_lap)\n                };\n\n                // Try moving the head.\n                match self.head.compare_exchange_weak(\n                    head,\n                    new,\n                    Ordering::SeqCst,\n                    Ordering::Relaxed,\n                ) {\n                    Ok(_) => {\n                        // Read the value from the slot and update the stamp.\n                        let msg = unsafe { slot.value.get().read() };\n                        slot.stamp\n                            .store(head.wrapping_add(self.one_lap), Ordering::Release);\n                        return Ok(msg);\n                    }\n                    Err(h) => {\n                        head = h;\n                        backoff.spin();\n                    }\n                }\n            } else if stamp == head {\n                atomic::fence(Ordering::SeqCst);\n                let tail = self.tail.load(Ordering::Relaxed);\n\n                // If the tail equals the head, that means the channel is empty.\n                if tail == head {\n                    return Err(PopError);\n                }\n\n                backoff.spin();\n                head = self.head.load(Ordering::Relaxed);\n            } else {\n                // Snooze because we need to wait for the stamp to get updated.\n                backoff.snooze();\n                head = self.head.load(Ordering::Relaxed);\n            }\n        }\n    }\n\n    /// Returns the capacity of the queue.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use crossbeam_queue::{ArrayQueue, PopError};\n    ///\n    /// let q = ArrayQueue::<i32>::new(100);\n    ///\n    /// assert_eq!(q.capacity(), 100);\n    /// ```\n    pub fn capacity(&self) -> usize {\n        self.cap\n    }\n\n    /// Returns `true` if the queue is empty.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use crossbeam_queue::{ArrayQueue, PopError};\n    ///\n    /// let q = ArrayQueue::new(100);\n    ///\n    /// assert!(q.is_empty());\n    /// q.push(1).unwrap();\n    /// assert!(!q.is_empty());\n    /// ```\n    pub fn is_empty(&self) -> bool {\n        let head = self.head.load(Ordering::SeqCst);\n        let tail = self.tail.load(Ordering::SeqCst);\n\n        // Is the tail lagging one lap behind head?\n        // Is the tail equal to the head?\n        //\n        // Note: If the head changes just before we load the tail, that means there was a moment\n        // when the channel was not empty, so it is safe to just return `false`.\n        tail == head\n    }\n\n    /// Returns `true` if the queue is full.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use crossbeam_queue::{ArrayQueue, PopError};\n    ///\n    /// let q = ArrayQueue::new(1);\n    ///\n    /// assert!(!q.is_full());\n    /// q.push(1).unwrap();\n    /// assert!(q.is_full());\n    /// ```\n    pub fn is_full(&self) -> bool {\n        let tail = self.tail.load(Ordering::SeqCst);\n        let head = self.head.load(Ordering::SeqCst);\n\n        // Is the head lagging one lap behind tail?\n        //\n        // Note: If the tail changes just before we load the head, that means there was a moment\n        // when the queue was not full, so it is safe to just return `false`.\n        head.wrapping_add(self.one_lap) == tail\n    }\n\n    /// Returns the number of elements in the queue.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use crossbeam_queue::{ArrayQueue, PopError};\n    ///\n    /// let q = ArrayQueue::new(100);\n    /// assert_eq!(q.len(), 0);\n    ///\n    /// q.push(10).unwrap();\n    /// assert_eq!(q.len(), 1);\n    ///\n    /// q.push(20).unwrap();\n    /// assert_eq!(q.len(), 2);\n    /// ```\n    pub fn len(&self) -> usize {\n        loop {\n            // Load the tail, then load the head.\n            let tail = self.tail.load(Ordering::SeqCst);\n            let head = self.head.load(Ordering::SeqCst);\n\n            // If the tail didn't change, we've got consistent values to work with.\n            if self.tail.load(Ordering::SeqCst) == tail {\n                let hix = head & (self.one_lap - 1);\n                let tix = tail & (self.one_lap - 1);\n\n                return if hix < tix {\n                    tix - hix\n                } else if hix > tix {\n                    self.cap - hix + tix\n                } else if tail == head {\n                    0\n                } else {\n                    self.cap\n                };\n            }\n        }\n    }\n}\n\nimpl<T> Drop for ArrayQueue<T> {\n    fn drop(&mut self) {\n        // Get the index of the head.\n        let hix = self.head.load(Ordering::Relaxed) & (self.one_lap - 1);\n\n        // Loop over all slots that hold a message and drop them.\n        for i in 0..self.len() {\n            // Compute the index of the next slot holding a message.\n            let index = if hix + i < self.cap {\n                hix + i\n            } else {\n                hix + i - self.cap\n            };\n\n            unsafe {\n                self.buffer.add(index).drop_in_place();\n            }\n        }\n\n        // Finally, deallocate the buffer, but don't run any destructors.\n        unsafe {\n            Vec::from_raw_parts(self.buffer, 0, self.cap);\n        }\n    }\n}\n\nimpl<T> fmt::Debug for ArrayQueue<T> {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        f.pad(\"ArrayQueue { .. }\")\n    }\n}\n"
  },
  {
    "project": "crossbeam",
    "target": 1,
    "commit_id": "6f3a3c17ea89fe16f55246cdfb64d684a52a5292",
    "func": "//! Bounded channel based on a preallocated array.\n//!\n//! This flavor has a fixed, positive capacity.\n//!\n//! The implementation is based on Dmitry Vyukov's bounded MPMC queue.\n//!\n//! Source:\n//!   - http://www.1024cores.net/home/lock-free-algorithms/queues/bounded-mpmc-queue\n//!   - https://docs.google.com/document/d/1yIAYmbvL3JxOKOjuCyon7JhW4cSv1wy5hC0ApeGMV9s/pub\n//!\n//! Copyright & License:\n//!   - Copyright (c) 2010-2011 Dmitry Vyukov\n//!   - Simplified BSD License and Apache License, Version 2.0\n//!   - http://www.1024cores.net/home/code-license\n\nuse std::cell::UnsafeCell;\nuse std::marker::PhantomData;\nuse std::mem;\nuse std::ptr;\nuse std::sync::atomic::{self, AtomicUsize, Ordering};\nuse std::time::Instant;\n\nuse crossbeam_utils::{Backoff, CachePadded};\n\nuse context::Context;\nuse err::{RecvTimeoutError, SendTimeoutError, TryRecvError, TrySendError};\nuse select::{Operation, SelectHandle, Selected, Token};\nuse waker::SyncWaker;\n\n/// A slot in a channel.\nstruct Slot<T> {\n    /// The current stamp.\n    stamp: AtomicUsize,\n\n    /// The message in this slot.\n    msg: UnsafeCell<T>,\n}\n\n/// The token type for the array flavor.\n#[derive(Debug)]\npub struct ArrayToken {\n    /// Slot to read from or write to.\n    slot: *const u8,\n\n    /// Stamp to store into the slot after reading or writing.\n    stamp: usize,\n}\n\nimpl Default for ArrayToken {\n    #[inline]\n    fn default() -> Self {\n        ArrayToken {\n            slot: ptr::null(),\n            stamp: 0,\n        }\n    }\n}\n\n/// Bounded channel based on a preallocated array.\npub struct Channel<T> {\n    /// The head of the channel.\n    ///\n    /// This value is a \"stamp\" consisting of an index into the buffer, a mark bit, and a lap, but\n    /// packed into a single `usize`. The lower bits represent the index, while the upper bits\n    /// represent the lap. The mark bit in the head is always zero.\n    ///\n    /// Messages are popped from the head of the channel.\n    head: CachePadded<AtomicUsize>,\n\n    /// The tail of the channel.\n    ///\n    /// This value is a \"stamp\" consisting of an index into the buffer, a mark bit, and a lap, but\n    /// packed into a single `usize`. The lower bits represent the index, while the upper bits\n    /// represent the lap. The mark bit indicates that the channel is disconnected.\n    ///\n    /// Messages are pushed into the tail of the channel.\n    tail: CachePadded<AtomicUsize>,\n\n    /// The buffer holding slots.\n    buffer: *mut Slot<T>,\n\n    /// The channel capacity.\n    cap: usize,\n\n    /// A stamp with the value of `{ lap: 1, mark: 0, index: 0 }`.\n    one_lap: usize,\n\n    /// If this bit is set in the tail, that means the channel is disconnected.\n    mark_bit: usize,\n\n    /// Senders waiting while the channel is full.\n    senders: SyncWaker,\n\n    /// Receivers waiting while the channel is empty and not disconnected.\n    receivers: SyncWaker,\n\n    /// Indicates that dropping a `Channel<T>` may drop values of type `T`.\n    _marker: PhantomData<T>,\n}\n\nimpl<T> Channel<T> {\n    /// Creates a bounded channel of capacity `cap`.\n    pub fn with_capacity(cap: usize) -> Self {\n        assert!(cap > 0, \"capacity must be positive\");\n\n        // Compute constants `mark_bit` and `one_lap`.\n        let mark_bit = (cap + 1).next_power_of_two();\n        let one_lap = mark_bit * 2;\n\n        // Head is initialized to `{ lap: 0, mark: 0, index: 0 }`.\n        let head = 0;\n        // Tail is initialized to `{ lap: 0, mark: 0, index: 0 }`.\n        let tail = 0;\n\n        // Allocate a buffer of `cap` slots.\n        let buffer = {\n            let mut v = Vec::<Slot<T>>::with_capacity(cap);\n            let ptr = v.as_mut_ptr();\n            mem::forget(v);\n            ptr\n        };\n\n        // Initialize stamps in the slots.\n        for i in 0..cap {\n            unsafe {\n                // Set the stamp to `{ lap: 0, mark: 0, index: i }`.\n                let slot = buffer.add(i);\n                ptr::write(&mut (*slot).stamp, AtomicUsize::new(i));\n            }\n        }\n\n        Channel {\n            buffer,\n            cap,\n            one_lap,\n            mark_bit,\n            head: CachePadded::new(AtomicUsize::new(head)),\n            tail: CachePadded::new(AtomicUsize::new(tail)),\n            senders: SyncWaker::new(),\n            receivers: SyncWaker::new(),\n            _marker: PhantomData,\n        }\n    }\n\n    /// Returns a receiver handle to the channel.\n    pub fn receiver(&self) -> Receiver<T> {\n        Receiver(self)\n    }\n\n    /// Returns a sender handle to the channel.\n    pub fn sender(&self) -> Sender<T> {\n        Sender(self)\n    }\n\n    /// Attempts to reserve a slot for sending a message.\n    fn start_send(&self, token: &mut Token) -> bool {\n        let backoff = Backoff::new();\n        let mut tail = self.tail.load(Ordering::Relaxed);\n\n        loop {\n            // Check if the channel is disconnected.\n            if tail & self.mark_bit != 0 {\n                token.array.slot = ptr::null();\n                token.array.stamp = 0;\n                return true;\n            }\n\n            // Deconstruct the tail.\n            let index = tail & (self.mark_bit - 1);\n            let lap = tail & !(self.one_lap - 1);\n\n            // Inspect the corresponding slot.\n            let slot = unsafe { &*self.buffer.add(index) };\n            let stamp = slot.stamp.load(Ordering::Acquire);\n\n            // If the tail and the stamp match, we may attempt to push.\n            if tail == stamp {\n                let new_tail = if index + 1 < self.cap {\n                    // Same lap, incremented index.\n                    // Set to `{ lap: lap, mark: 0, index: index + 1 }`.\n                    tail + 1\n                } else {\n                    // One lap forward, index wraps around to zero.\n                    // Set to `{ lap: lap.wrapping_add(1), mark: 0, index: 0 }`.\n                    lap.wrapping_add(self.one_lap)\n                };\n\n                // Try moving the tail.\n                match self.tail.compare_exchange_weak(\n                    tail,\n                    new_tail,\n                    Ordering::SeqCst,\n                    Ordering::Relaxed,\n                ) {\n                    Ok(_) => {\n                        // Prepare the token for the follow-up call to `write`.\n                        token.array.slot = slot as *const Slot<T> as *const u8;\n                        token.array.stamp = tail + 1;\n                        return true;\n                    }\n                    Err(t) => {\n                        tail = t;\n                        backoff.spin();\n                    }\n                }\n            } else if stamp.wrapping_add(self.one_lap) == tail + 1 {\n                atomic::fence(Ordering::SeqCst);\n                let head = self.head.load(Ordering::Relaxed);\n\n                // If the head lags one lap behind the tail as well...\n                if head.wrapping_add(self.one_lap) == tail {\n                    // ...then the channel is full.\n                    return false;\n                }\n\n                backoff.spin();\n                tail = self.tail.load(Ordering::Relaxed);\n            } else {\n                // Snooze because we need to wait for the stamp to get updated.\n                backoff.snooze();\n                tail = self.tail.load(Ordering::Relaxed);\n            }\n        }\n    }\n\n    /// Writes a message into the channel.\n    pub unsafe fn write(&self, token: &mut Token, msg: T) -> Result<(), T> {\n        // If there is no slot, the channel is disconnected.\n        if token.array.slot.is_null() {\n            return Err(msg);\n        }\n\n        let slot: &Slot<T> = &*(token.array.slot as *const Slot<T>);\n\n        // Write the message into the slot and update the stamp.\n        slot.msg.get().write(msg);\n        slot.stamp.store(token.array.stamp, Ordering::Release);\n\n        // Wake a sleeping receiver.\n        self.receivers.notify();\n        Ok(())\n    }\n\n    /// Attempts to reserve a slot for receiving a message.\n    fn start_recv(&self, token: &mut Token) -> bool {\n        let backoff = Backoff::new();\n        let mut head = self.head.load(Ordering::Relaxed);\n\n        loop {\n            // Deconstruct the head.\n            let index = head & (self.mark_bit - 1);\n            let lap = head & !(self.one_lap - 1);\n\n            // Inspect the corresponding slot.\n            let slot = unsafe { &*self.buffer.add(index) };\n            let stamp = slot.stamp.load(Ordering::Acquire);\n\n            // If the the stamp is ahead of the head by 1, we may attempt to pop.\n            if head + 1 == stamp {\n                let new = if index + 1 < self.cap {\n                    // Same lap, incremented index.\n                    // Set to `{ lap: lap, mark: 0, index: index + 1 }`.\n                    head + 1\n                } else {\n                    // One lap forward, index wraps around to zero.\n                    // Set to `{ lap: lap.wrapping_add(1), mark: 0, index: 0 }`.\n                    lap.wrapping_add(self.one_lap)\n                };\n\n                // Try moving the head.\n                match self.head.compare_exchange_weak(\n                    head,\n                    new,\n                    Ordering::SeqCst,\n                    Ordering::Relaxed,\n                ) {\n                    Ok(_) => {\n                        // Prepare the token for the follow-up call to `read`.\n                        token.array.slot = slot as *const Slot<T> as *const u8;\n                        token.array.stamp = head.wrapping_add(self.one_lap);\n                        return true;\n                    }\n                    Err(h) => {\n                        head = h;\n                        backoff.spin();\n                    }\n                }\n            } else if stamp == head {\n                atomic::fence(Ordering::SeqCst);\n                let tail = self.tail.load(Ordering::Relaxed);\n\n                // If the tail equals the head, that means the channel is empty.\n                if (tail & !self.mark_bit) == head {\n                    // If the channel is disconnected...\n                    if tail & self.mark_bit != 0 {\n                        // ...then receive an error.\n                        token.array.slot = ptr::null();\n                        token.array.stamp = 0;\n                        return true;\n                    } else {\n                        // Otherwise, the receive operation is not ready.\n                        return false;\n                    }\n                }\n\n                backoff.spin();\n                head = self.head.load(Ordering::Relaxed);\n            } else {\n                // Snooze because we need to wait for the stamp to get updated.\n                backoff.snooze();\n                head = self.head.load(Ordering::Relaxed);\n            }\n        }\n    }\n\n    /// Reads a message from the channel.\n    pub unsafe fn read(&self, token: &mut Token) -> Result<T, ()> {\n        if token.array.slot.is_null() {\n            // The channel is disconnected.\n            return Err(());\n        }\n\n        let slot: &Slot<T> = &*(token.array.slot as *const Slot<T>);\n\n        // Read the message from the slot and update the stamp.\n        let msg = slot.msg.get().read();\n        slot.stamp.store(token.array.stamp, Ordering::Release);\n\n        // Wake a sleeping sender.\n        self.senders.notify();\n        Ok(msg)\n    }\n\n    /// Attempts to send a message into the channel.\n    pub fn try_send(&self, msg: T) -> Result<(), TrySendError<T>> {\n        let token = &mut Token::default();\n        if self.start_send(token) {\n            unsafe { self.write(token, msg).map_err(TrySendError::Disconnected) }\n        } else {\n            Err(TrySendError::Full(msg))\n        }\n    }\n\n    /// Sends a message into the channel.\n    pub fn send(&self, msg: T, deadline: Option<Instant>) -> Result<(), SendTimeoutError<T>> {\n        let token = &mut Token::default();\n        loop {\n            // Try sending a message several times.\n            let backoff = Backoff::new();\n            loop {\n                if self.start_send(token) {\n                    let res = unsafe { self.write(token, msg) };\n                    return res.map_err(SendTimeoutError::Disconnected);\n                }\n\n                if backoff.is_completed() {\n                    break;\n                } else {\n                    backoff.snooze();\n                }\n            }\n\n            if let Some(d) = deadline {\n                if Instant::now() >= d {\n                    return Err(SendTimeoutError::Timeout(msg));\n                }\n            }\n\n            Context::with(|cx| {\n                // Prepare for blocking until a receiver wakes us up.\n                let oper = Operation::hook(token);\n                self.senders.register(oper, cx);\n\n                // Has the channel become ready just now?\n                if !self.is_full() || self.is_disconnected() {\n                    let _ = cx.try_select(Selected::Aborted);\n                }\n\n                // Block the current thread.\n                let sel = cx.wait_until(deadline);\n\n                match sel {\n                    Selected::Waiting => unreachable!(),\n                    Selected::Aborted | Selected::Disconnected => {\n                        self.senders.unregister(oper).unwrap();\n                    }\n                    Selected::Operation(_) => {}\n                }\n            });\n        }\n    }\n\n    /// Attempts to receive a message without blocking.\n    pub fn try_recv(&self) -> Result<T, TryRecvError> {\n        let token = &mut Token::default();\n\n        if self.start_recv(token) {\n            unsafe { self.read(token).map_err(|_| TryRecvError::Disconnected) }\n        } else {\n            Err(TryRecvError::Empty)\n        }\n    }\n\n    /// Receives a message from the channel.\n    pub fn recv(&self, deadline: Option<Instant>) -> Result<T, RecvTimeoutError> {\n        let token = &mut Token::default();\n        loop {\n            // Try receiving a message several times.\n            let backoff = Backoff::new();\n            loop {\n                if self.start_recv(token) {\n                    let res = unsafe { self.read(token) };\n                    return res.map_err(|_| RecvTimeoutError::Disconnected);\n                }\n\n                if backoff.is_completed() {\n                    break;\n                } else {\n                    backoff.snooze();\n                }\n            }\n\n            if let Some(d) = deadline {\n                if Instant::now() >= d {\n                    return Err(RecvTimeoutError::Timeout);\n                }\n            }\n\n            Context::with(|cx| {\n                // Prepare for blocking until a sender wakes us up.\n                let oper = Operation::hook(token);\n                self.receivers.register(oper, cx);\n\n                // Has the channel become ready just now?\n                if !self.is_empty() || self.is_disconnected() {\n                    let _ = cx.try_select(Selected::Aborted);\n                }\n\n                // Block the current thread.\n                let sel = cx.wait_until(deadline);\n\n                match sel {\n                    Selected::Waiting => unreachable!(),\n                    Selected::Aborted | Selected::Disconnected => {\n                        self.receivers.unregister(oper).unwrap();\n                        // If the channel was disconnected, we still have to check for remaining\n                        // messages.\n                    }\n                    Selected::Operation(_) => {}\n                }\n            });\n        }\n    }\n\n    /// Returns the current number of messages inside the channel.\n    pub fn len(&self) -> usize {\n        loop {\n            // Load the tail, then load the head.\n            let tail = self.tail.load(Ordering::SeqCst);\n            let head = self.head.load(Ordering::SeqCst);\n\n            // If the tail didn't change, we've got consistent values to work with.\n            if self.tail.load(Ordering::SeqCst) == tail {\n                let hix = head & (self.mark_bit - 1);\n                let tix = tail & (self.mark_bit - 1);\n\n                return if hix < tix {\n                    tix - hix\n                } else if hix > tix {\n                    self.cap - hix + tix\n                } else if (tail & !self.mark_bit) == head {\n                    0\n                } else {\n                    self.cap\n                };\n            }\n        }\n    }\n\n    /// Returns the capacity of the channel.\n    pub fn capacity(&self) -> Option<usize> {\n        Some(self.cap)\n    }\n\n    /// Disconnects the channel and wakes up all blocked senders and receivers.\n    ///\n    /// Returns `true` if this call disconnected the channel.\n    pub fn disconnect(&self) -> bool {\n        let tail = self.tail.fetch_or(self.mark_bit, Ordering::SeqCst);\n\n        if tail & self.mark_bit == 0 {\n            self.senders.disconnect();\n            self.receivers.disconnect();\n            true\n        } else {\n            false\n        }\n    }\n\n    /// Returns `true` if the channel is disconnected.\n    pub fn is_disconnected(&self) -> bool {\n        self.tail.load(Ordering::SeqCst) & self.mark_bit != 0\n    }\n\n    /// Returns `true` if the channel is empty.\n    pub fn is_empty(&self) -> bool {\n        let head = self.head.load(Ordering::SeqCst);\n        let tail = self.tail.load(Ordering::SeqCst);\n\n        // Is the tail equal to the head?\n        //\n        // Note: If the head changes just before we load the tail, that means there was a moment\n        // when the channel was not empty, so it is safe to just return `false`.\n        (tail & !self.mark_bit) == head\n    }\n\n    /// Returns `true` if the channel is full.\n    pub fn is_full(&self) -> bool {\n        let tail = self.tail.load(Ordering::SeqCst);\n        let head = self.head.load(Ordering::SeqCst);\n\n        // Is the head lagging one lap behind tail?\n        //\n        // Note: If the tail changes just before we load the head, that means there was a moment\n        // when the channel was not full, so it is safe to just return `false`.\n        head.wrapping_add(self.one_lap) == tail & !self.mark_bit\n    }\n}\n\nimpl<T> Drop for Channel<T> {\n    fn drop(&mut self) {\n        // Get the index of the head.\n        let hix = self.head.load(Ordering::Relaxed) & (self.mark_bit - 1);\n\n        // Loop over all slots that hold a message and drop them.\n        for i in 0..self.len() {\n            // Compute the index of the next slot holding a message.\n            let index = if hix + i < self.cap {\n                hix + i\n            } else {\n                hix + i - self.cap\n            };\n\n            unsafe {\n                self.buffer.add(index).drop_in_place();\n            }\n        }\n\n        // Finally, deallocate the buffer, but don't run any destructors.\n        unsafe {\n            Vec::from_raw_parts(self.buffer, 0, self.cap);\n        }\n    }\n}\n\n/// Receiver handle to a channel.\npub struct Receiver<'a, T: 'a>(&'a Channel<T>);\n\n/// Sender handle to a channel.\npub struct Sender<'a, T: 'a>(&'a Channel<T>);\n\nimpl<'a, T> SelectHandle for Receiver<'a, T> {\n    fn try_select(&self, token: &mut Token) -> bool {\n        self.0.start_recv(token)\n    }\n\n    fn deadline(&self) -> Option<Instant> {\n        None\n    }\n\n    fn register(&self, oper: Operation, cx: &Context) -> bool {\n        self.0.receivers.register(oper, cx);\n        self.is_ready()\n    }\n\n    fn unregister(&self, oper: Operation) {\n        self.0.receivers.unregister(oper);\n    }\n\n    fn accept(&self, token: &mut Token, _cx: &Context) -> bool {\n        self.try_select(token)\n    }\n\n    fn is_ready(&self) -> bool {\n        !self.0.is_empty() || self.0.is_disconnected()\n    }\n\n    fn watch(&self, oper: Operation, cx: &Context) -> bool {\n        self.0.receivers.watch(oper, cx);\n        self.is_ready()\n    }\n\n    fn unwatch(&self, oper: Operation) {\n        self.0.receivers.unwatch(oper);\n    }\n}\n\nimpl<'a, T> SelectHandle for Sender<'a, T> {\n    fn try_select(&self, token: &mut Token) -> bool {\n        self.0.start_send(token)\n    }\n\n    fn deadline(&self) -> Option<Instant> {\n        None\n    }\n\n    fn register(&self, oper: Operation, cx: &Context) -> bool {\n        self.0.senders.register(oper, cx);\n        self.is_ready()\n    }\n\n    fn unregister(&self, oper: Operation) {\n        self.0.senders.unregister(oper);\n    }\n\n    fn accept(&self, token: &mut Token, _cx: &Context) -> bool {\n        self.try_select(token)\n    }\n\n    fn is_ready(&self) -> bool {\n        !self.0.is_full() || self.0.is_disconnected()\n    }\n\n    fn watch(&self, oper: Operation, cx: &Context) -> bool {\n        self.0.senders.watch(oper, cx);\n        self.is_ready()\n    }\n\n    fn unwatch(&self, oper: Operation) {\n        self.0.senders.unwatch(oper);\n    }\n}\n"
  },
  {
    "project": "image",
    "target": 1,
    "commit_id": "5c51a7be311677c53ebbb2f66f61e64714ab33c7",
    "func": "use scoped_threadpool::Pool;\nuse num_traits::cast::NumCast;\nuse num_traits::identities::Zero;\nuse std::mem;\n#[cfg(test)]\nuse std::borrow::Cow;\nuse std::error::Error;\nuse std::io::{self, BufRead, Cursor, Read, Seek};\nuse std::iter::Iterator;\nuse std::marker::PhantomData;\nuse std::path::Path;\nuse Primitive;\n\nuse color::{ColorType, Rgb};\nuse image::{self, ImageDecoder, ImageDecoderExt, ImageError, ImageResult, Progress};\n\n/// Adapter to conform to ```ImageDecoder``` trait\n#[derive(Debug)]\npub struct HDRAdapter<R: BufRead> {\n    inner: Option<HDRDecoder<R>>,\n    data: Option<Vec<u8>>,\n    meta: HDRMetadata,\n}\n\nimpl<R: BufRead> HDRAdapter<R> {\n    /// Creates adapter\n    pub fn new(r: R) -> ImageResult<HDRAdapter<R>> {\n        let decoder = try!(HDRDecoder::new(r));\n        let meta = decoder.metadata();\n        Ok(HDRAdapter {\n            inner: Some(decoder),\n            data: None,\n            meta,\n        })\n    }\n\n    /// Allows reading old Radiance HDR images\n    pub fn new_nonstrict(r: R) -> ImageResult<HDRAdapter<R>> {\n        let decoder = try!(HDRDecoder::with_strictness(r, false));\n        let meta = decoder.metadata();\n        Ok(HDRAdapter {\n            inner: Some(decoder),\n            data: None,\n            meta,\n        })\n    }\n\n    /// Read the actual data of the image, and store it in Self::data.\n    fn read_image_data(&mut self) -> ImageResult<()> {\n        match self.inner.take() {\n            Some(decoder) => {\n                let img: Vec<Rgb<u8>> = decoder.read_image_ldr()?;\n\n                let len = img.len() * mem::size_of::<Rgb<u8>>(); // length in bytes\n                let target = self.data.get_or_insert_with(|| Vec::with_capacity(len));\n                target.clear();\n\n                for Rgb(data) in img {\n                    target.extend_from_slice(&data);\n                }\n\n                Ok(())\n            }\n            None => Err(ImageError::ImageEnd),\n        }\n    }\n\n}\n\n/// Wrapper struct around a `Cursor<Vec<u8>>`\npub struct HdrReader<R>(Cursor<Vec<u8>>, PhantomData<R>);\nimpl<R> Read for HdrReader<R> {\n    fn read(&mut self, buf: &mut [u8]) -> io::Result<usize> {\n        self.0.read(buf)\n    }\n    fn read_to_end(&mut self, buf: &mut Vec<u8>) -> io::Result<usize> {\n        if self.0.position() == 0 && buf.is_empty() {\n            mem::swap(buf, self.0.get_mut());\n            Ok(buf.len())\n        } else {\n            self.0.read_to_end(buf)\n        }\n    }\n}\n\nimpl<'a, R: 'a + BufRead> ImageDecoder<'a> for HDRAdapter<R> {\n    type Reader = HdrReader<R>;\n\n    fn dimensions(&self) -> (u64, u64) {\n        (self.meta.width as u64, self.meta.height as u64)\n    }\n\n    fn colortype(&self) -> ColorType {\n        ColorType::RGB(8)\n    }\n\n    fn into_reader(self) -> ImageResult<Self::Reader> {\n        Ok(HdrReader(Cursor::new(self.read_image()?), PhantomData))\n    }\n\n    fn read_image(mut self) -> ImageResult<Vec<u8>> {\n        if let Some(data) = self.data {\n            return Ok(data);\n        }\n\n        self.read_image_data()?;\n        Ok(self.data.unwrap())\n    }\n}\n\nimpl<'a, R: 'a + BufRead + Seek> ImageDecoderExt<'a> for HDRAdapter<R> {\n    fn read_rect_with_progress<F: Fn(Progress)>(\n        &mut self,\n        x: u64,\n        y: u64,\n        width: u64,\n        height: u64,\n        buf: &mut [u8],\n        progress_callback: F,\n    ) -> ImageResult<()> {\n        if self.data.is_none() {\n            self.read_image_data()?;\n        }\n\n        image::load_rect(x, y, width, height, buf, progress_callback, self, |_, _| unreachable!(),\n                         |s, buf| {\n                             buf.copy_from_slice(&*s.data.as_ref().unwrap());\n                             Ok(buf.len())\n                         })\n    }\n}\n\n/// Radiance HDR file signature\npub const SIGNATURE: &[u8] = b\"#?RADIANCE\";\nconst SIGNATURE_LENGTH: usize = 10;\n\n/// An Radiance HDR decoder\n#[derive(Debug)]\npub struct HDRDecoder<R> {\n    r: R,\n    width: u32,\n    height: u32,\n    meta: HDRMetadata,\n}\n\n/// Refer to [wikipedia](https://en.wikipedia.org/wiki/RGBE_image_format)\n#[repr(C)]\n#[derive(Clone, Copy, Debug, Default, PartialEq, Eq)]\npub struct RGBE8Pixel {\n    /// Color components\n    pub c: [u8; 3],\n    /// Exponent\n    pub e: u8,\n}\n\n/// Creates ```RGBE8Pixel``` from components\npub fn rgbe8(r: u8, g: u8, b: u8, e: u8) -> RGBE8Pixel {\n    RGBE8Pixel { c: [r, g, b], e }\n}\n\nimpl RGBE8Pixel {\n    /// Converts ```RGBE8Pixel``` into ```Rgb<f32>``` linearly\n    #[inline]\n    pub fn to_hdr(self) -> Rgb<f32> {\n        if self.e == 0 {\n            Rgb([0.0, 0.0, 0.0])\n        } else {\n            //            let exp = f32::ldexp(1., self.e as isize - (128 + 8)); // unstable\n            let exp = f32::exp2(<f32 as From<_>>::from(self.e) - (128.0 + 8.0));\n            Rgb([\n                exp * <f32 as From<_>>::from(self.c[0]),\n                exp * <f32 as From<_>>::from(self.c[1]),\n                exp * <f32 as From<_>>::from(self.c[2]),\n            ])\n        }\n    }\n\n    /// Converts ```RGBE8Pixel``` into ```Rgb<T>``` with scale=1 and gamma=2.2\n    ///\n    /// color_ldr = (color_hdr*scale)<sup>gamma</sup>\n    ///\n    /// # Panic\n    ///\n    /// Panics when ```T::max_value()``` cannot be represented as f32.\n    #[inline]\n    pub fn to_ldr<T: Primitive + Zero>(self) -> Rgb<T> {\n        self.to_ldr_scale_gamma(1.0, 2.2)\n    }\n\n    /// Converts RGBE8Pixel into Rgb<T> using provided scale and gamma\n    ///\n    /// color_ldr = (color_hdr*scale)<sup>gamma</sup>\n    ///\n    /// # Panic\n    ///\n    /// Panics when T::max_value() cannot be represented as f32.\n    /// Panics when scale or gamma is NaN\n    #[inline]\n    pub fn to_ldr_scale_gamma<T: Primitive + Zero>(self, scale: f32, gamma: f32) -> Rgb<T> {\n        let Rgb(data) = self.to_hdr();\n        let (r, g, b) = (data[0], data[1], data[2]);\n        #[inline]\n        fn sg<T: Primitive + Zero>(v: f32, scale: f32, gamma: f32) -> T {\n            let t_max = T::max_value();\n            // Disassembly shows that t_max_f32 is compiled into constant\n            let t_max_f32: f32 = NumCast::from(t_max)\n                .expect(\"to_ldr_scale_gamma: maximum value of type is not representable as f32\");\n            let fv = f32::powf(v * scale, gamma) * t_max_f32 + 0.5;\n            if fv < 0.0 {\n                T::zero()\n            } else if fv > t_max_f32 {\n                t_max\n            } else {\n                NumCast::from(fv)\n                    .expect(\"to_ldr_scale_gamma: cannot convert f32 to target type. NaN?\")\n            }\n        }\n        Rgb([\n            sg(r, scale, gamma),\n            sg(g, scale, gamma),\n            sg(b, scale, gamma),\n        ])\n    }\n}\n\nimpl<R: BufRead> HDRDecoder<R> {\n    /// Reads Radiance HDR image header from stream ```r```\n    /// if the header is valid, creates HDRDecoder\n    /// strict mode is enabled\n    pub fn new(reader: R) -> ImageResult<HDRDecoder<R>> {\n        HDRDecoder::with_strictness(reader, true)\n    }\n\n    /// Reads Radiance HDR image header from stream ```reader```,\n    /// if the header is valid, creates ```HDRDecoder```.\n    ///\n    /// strict enables strict mode\n    ///\n    /// Warning! Reading wrong file in non-strict mode\n    ///   could consume file size worth of memory in the process.\n    pub fn with_strictness(mut reader: R, strict: bool) -> ImageResult<HDRDecoder<R>> {\n        let mut attributes = HDRMetadata::new();\n\n        {\n            // scope to make borrowck happy\n            let r = &mut reader;\n            if strict {\n                let mut signature = [0; SIGNATURE_LENGTH];\n                try!(r.read_exact(&mut signature));\n                if signature != SIGNATURE {\n                    return Err(ImageError::FormatError(\n                        \"Radiance HDR signature not found\".to_string(),\n                    ));\n                } // no else\n                  // skip signature line ending\n                try!(read_line_u8(r));\n            } else {\n                // Old Radiance HDR files (*.pic) don't use signature\n                // Let them be parsed in non-strict mode\n            }\n            // read header data until empty line\n            loop {\n                match try!(read_line_u8(r)) {\n                    None => {\n                        // EOF before end of header\n                        return Err(ImageError::FormatError(\"EOF in header\".into()));\n                    }\n                    Some(line) => {\n                        if line.is_empty() {\n                            // end of header\n                            break;\n                        } else if line[0] == b'#' {\n                            // line[0] will not panic, line.len() == 0 is false here\n                            // skip comments\n                            continue;\n                        } // no else\n                          // process attribute line\n                        let line = String::from_utf8_lossy(&line[..]);\n                        try!(attributes.update_header_info(&line, strict));\n                    } // <= Some(line)\n                } // match read_line_u8()\n            } // loop\n        } // scope to end borrow of reader\n          // parse dimensions\n        let (width, height) = match try!(read_line_u8(&mut reader)) {\n            None => {\n                // EOF instead of image dimensions\n                return Err(ImageError::FormatError(\"EOF in dimensions line\".into()));\n            }\n            Some(dimensions) => {\n                let dimensions = String::from_utf8_lossy(&dimensions[..]);\n                try!(parse_dimensions_line(&dimensions, strict))\n            }\n        };\n\n        Ok(HDRDecoder {\n            r: reader,\n\n            width,\n            height,\n            meta: HDRMetadata {\n                width,\n                height,\n                ..attributes\n            },\n        })\n    } // end with_strictness\n\n    /// Returns file metadata. Refer to ```HDRMetadata``` for details.\n    pub fn metadata(&self) -> HDRMetadata {\n        self.meta.clone()\n    }\n\n    /// Consumes decoder and returns a vector of RGBE8 pixels\n    pub fn read_image_native(mut self) -> ImageResult<Vec<RGBE8Pixel>> {\n        // Don't read anything if image is empty\n        if self.width == 0 || self.height == 0 {\n            return Ok(vec![]);\n        }\n        // expression self.width > 0 && self.height > 0 is true from now to the end of this method\n        let pixel_count = self.width as usize * self.height as usize;\n        let mut ret = vec![Default::default(); pixel_count];\n        for chunk in ret.chunks_mut(self.width as usize) {\n            try!(read_scanline(&mut self.r, chunk));\n        }\n        Ok(ret)\n    }\n\n    /// Consumes decoder and returns a vector of transformed pixels\n    pub fn read_image_transform<T: Send, F: Send + Sync + Fn(RGBE8Pixel) -> T>(\n        mut self,\n        f: F,\n    ) -> ImageResult<Vec<T>> {\n        // Don't read anything if image is empty\n        if self.width == 0 || self.height == 0 {\n            return Ok(vec![]);\n        }\n        // expression self.width > 0 && self.height > 0 is true from now to the end of this method\n        // scanline buffer\n        let uszwidth = self.width as usize;\n\n        let pixel_count = self.width as usize * self.height as usize;\n        let mut ret = Vec::with_capacity(pixel_count);\n        unsafe {\n            // RGBE8Pixel doesn't implement Drop, so it's Ok to drop half-initialized ret\n            ret.set_len(pixel_count);\n        } // ret contains uninitialized data, so now it's my responsibility to return fully initialized ret\n\n        {\n            let chunks_iter = ret.chunks_mut(uszwidth);\n            let mut pool = Pool::new(8); //\n\n            try!(pool.scoped(|scope| {\n                for chunk in chunks_iter {\n                    let mut buf = Vec::<RGBE8Pixel>::with_capacity(uszwidth);\n                    unsafe {\n                        buf.set_len(uszwidth);\n                    }\n                    try!(read_scanline(&mut self.r, &mut buf[..]));\n                    let f = &f;\n                    scope.execute(move || {\n                        for (dst, &pix) in chunk.iter_mut().zip(buf.iter()) {\n                            *dst = f(pix);\n                        }\n                    });\n                }\n                Ok(())\n            }) as Result<(), ImageError>);\n        }\n\n        Ok(ret)\n    }\n\n    /// Consumes decoder and returns a vector of Rgb<u8> pixels.\n    /// scale = 1, gamma = 2.2\n    pub fn read_image_ldr(self) -> ImageResult<Vec<Rgb<u8>>> {\n        self.read_image_transform(|pix| pix.to_ldr())\n    }\n\n    /// Consumes decoder and returns a vector of Rgb<f32> pixels.\n    ///\n    pub fn read_image_hdr(self) -> ImageResult<Vec<Rgb<f32>>> {\n        self.read_image_transform(|pix| pix.to_hdr())\n    }\n}\n\nimpl<R: BufRead> IntoIterator for HDRDecoder<R> {\n    type Item = ImageResult<RGBE8Pixel>;\n    type IntoIter = HDRImageDecoderIterator<R>;\n\n    fn into_iter(self) -> Self::IntoIter {\n        HDRImageDecoderIterator {\n            r: self.r,\n            scanline_cnt: self.height as usize,\n            buf: vec![Default::default(); self.width as usize],\n            col: 0,\n            scanline: 0,\n            trouble: true, // make first call to `next()` read scanline\n            error_encountered: false,\n        }\n    }\n}\n\n/// Scanline buffered pixel by pixel iterator\npub struct HDRImageDecoderIterator<R: BufRead> {\n    r: R,\n    scanline_cnt: usize,\n    buf: Vec<RGBE8Pixel>, // scanline buffer\n    col: usize,           // current position in scanline\n    scanline: usize,      // current scanline\n    trouble: bool,        // optimization, true indicates that we need to check something\n    error_encountered: bool,\n}\n\nimpl<R: BufRead> HDRImageDecoderIterator<R> {\n    // Advances counter to the next pixel\n    #[inline]\n    fn advance(&mut self) {\n        self.col += 1;\n        if self.col == self.buf.len() {\n            self.col = 0;\n            self.scanline += 1;\n            self.trouble = true;\n        }\n    }\n}\n\nimpl<R: BufRead> Iterator for HDRImageDecoderIterator<R> {\n    type Item = ImageResult<RGBE8Pixel>;\n\n    fn next(&mut self) -> Option<Self::Item> {\n        if !self.trouble {\n            let ret = self.buf[self.col];\n            self.advance();\n            Some(Ok(ret))\n        } else {\n            // some condition is pending\n            if self.buf.is_empty() || self.scanline == self.scanline_cnt {\n                // No more pixels\n                return None;\n            } // no else\n            if self.error_encountered {\n                self.advance();\n                // Error was encountered. Keep producing errors.\n                // ImageError can't implement Clone, so just dump some error\n                return Some(Err(ImageError::ImageEnd));\n            } // no else\n            if self.col == 0 {\n                // fill scanline buffer\n                match read_scanline(&mut self.r, &mut self.buf[..]) {\n                    Ok(_) => {\n                        // no action required\n                    }\n                    Err(err) => {\n                        self.advance();\n                        self.error_encountered = true;\n                        self.trouble = true;\n                        return Some(Err(err));\n                    }\n                }\n            } // no else\n            self.trouble = false;\n            let ret = self.buf[0];\n            self.advance();\n            Some(Ok(ret))\n        }\n    }\n\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        let total_cnt = self.buf.len() * self.scanline_cnt;\n        let cur_cnt = self.buf.len() * self.scanline + self.col;\n        let remaining = total_cnt - cur_cnt;\n        (remaining, Some(remaining))\n    }\n}\n\nimpl<R: BufRead> ExactSizeIterator for HDRImageDecoderIterator<R> {}\n\n// Precondition: buf.len() > 0\nfn read_scanline<R: BufRead>(r: &mut R, buf: &mut [RGBE8Pixel]) -> ImageResult<()> {\n    assert!(!buf.is_empty());\n    let width = buf.len();\n    // first 4 bytes in scanline allow to determine compression method\n    let fb = try!(read_rgbe(r));\n    if fb.c[0] == 2 && fb.c[1] == 2 && fb.c[2] < 128 {\n        // denormalized pixel value (2,2,<128,_) indicates new per component RLE method\n        // decode_component guarantees that offset is within 0 .. width\n        // therefore we can skip bounds checking here, but we will not\n        try!(decode_component(r, width, |offset, value| buf[offset].c[0] = value));\n        try!(decode_component(r, width, |offset, value| buf[offset].c[1] = value));\n        try!(decode_component(r, width, |offset, value| buf[offset].c[2] = value));\n        try!(decode_component(r, width, |offset, value| buf[offset].e = value));\n    } else {\n        // old RLE method (it was considered old around 1991, should it be here?)\n        try!(decode_old_rle(r, fb, buf));\n    }\n    Ok(())\n}\n\n#[inline(always)]\nfn read_byte<R: BufRead>(r: &mut R) -> io::Result<u8> {\n    let mut buf = [0u8];\n    try!(r.read_exact(&mut buf[..]));\n    Ok(buf[0])\n}\n\n// Guarantees that first parameter of set_component will be within pos .. pos+width\n#[inline]\nfn decode_component<R: BufRead, S: FnMut(usize, u8)>(\n    r: &mut R,\n    width: usize,\n    mut set_component: S,\n) -> ImageResult<()> {\n    let mut buf = [0; 128];\n    let mut pos = 0;\n    while pos < width {\n        // increment position by a number of decompressed values\n        pos += {\n            let rl = try!(read_byte(r));\n            if rl <= 128 {\n                // sanity check\n                if pos + rl as usize > width {\n                    return Err(ImageError::FormatError(\n                        \"Wrong length of decoded scanline\".into(),\n                    ));\n                }\n                // read values\n                try!(r.read_exact(&mut buf[0..rl as usize]));\n                for (offset, &value) in buf[0..rl as usize].iter().enumerate() {\n                    set_component(pos + offset, value);\n                }\n                rl as usize\n            } else {\n                // run\n                let rl = rl - 128;\n                // sanity check\n                if pos + rl as usize > width {\n                    return Err(ImageError::FormatError(\n                        \"Wrong length of decoded scanline\".into(),\n                    ));\n                }\n                // fill with same value\n                let value = try!(read_byte(r));\n                for offset in 0..rl as usize {\n                    set_component(pos + offset, value);\n                }\n                rl as usize\n            }\n        };\n    }\n    if pos != width {\n        return Err(ImageError::FormatError(\n            \"Wrong length of decoded scanline\".into(),\n        ));\n    }\n    Ok(())\n}\n\n// Decodes scanline, places it into buf\n// Precondition: buf.len() > 0\n// fb - first 4 bytes of scanline\nfn decode_old_rle<R: BufRead>(\n    r: &mut R,\n    fb: RGBE8Pixel,\n    buf: &mut [RGBE8Pixel],\n) -> ImageResult<()> {\n    assert!(!buf.is_empty());\n    let width = buf.len();\n    // convenience function.\n    // returns run length if pixel is a run length marker\n    #[inline]\n    fn rl_marker(pix: RGBE8Pixel) -> Option<usize> {\n        if pix.c == [1, 1, 1] {\n            Some(pix.e as usize)\n        } else {\n            None\n        }\n    }\n    // first pixel in scanline should not be run length marker\n    // it is error if it is\n    if rl_marker(fb).is_some() {\n        return Err(ImageError::FormatError(\n            \"First pixel of a scanline shouldn't be run length marker\".into(),\n        ));\n    }\n    buf[0] = fb; // set first pixel of scanline\n\n    let mut x_off = 1; // current offset from beginning of a scanline\n    let mut rl_mult = 1; // current run length multiplier\n    let mut prev_pixel = fb;\n    while x_off < width {\n        let pix = try!(read_rgbe(r));\n        // it's harder to forget to increase x_off if I write this this way.\n        x_off += {\n            if let Some(rl) = rl_marker(pix) {\n                // rl_mult takes care of consecutive RL markers\n                let rl = rl * rl_mult;\n                rl_mult *= 256;\n                if x_off + rl <= width {\n                    // do run\n                    for b in &mut buf[x_off..x_off + rl] {\n                        *b = prev_pixel;\n                    }\n                } else {\n                    return Err(ImageError::FormatError(\n                        \"Wrong length of decoded scanline\".into(),\n                    ));\n                };\n                rl // value to increase x_off by\n            } else {\n                rl_mult = 1; // chain of consecutive RL markers is broken\n                prev_pixel = pix;\n                buf[x_off] = pix;\n                1 // value to increase x_off by\n            }\n        };\n    }\n    if x_off != width {\n        return Err(ImageError::FormatError(\n            \"Wrong length of decoded scanline\".into(),\n        ));\n    }\n    Ok(())\n}\n\nfn read_rgbe<R: BufRead>(r: &mut R) -> io::Result<RGBE8Pixel> {\n    let mut buf = [0u8; 4];\n    try!(r.read_exact(&mut buf[..]));\n    Ok(RGBE8Pixel {c: [buf[0], buf[1], buf[2]], e: buf[3] })\n}\n\n/// Metadata for Radiance HDR image\n#[derive(Debug, Clone)]\npub struct HDRMetadata {\n    /// Width of decoded image. It could be either scanline length,\n    /// or scanline count, depending on image orientation.\n    pub width: u32,\n    /// Height of decoded image. It depends on orientation too.\n    pub height: u32,\n    /// Orientation matrix. For standard orientation it is ((1,0),(0,1)) - left to right, top to bottom.\n    /// First pair tells how resulting pixel coordinates change along a scanline.\n    /// Second pair tells how they change from one scanline to the next.\n    pub orientation: ((i8, i8), (i8, i8)),\n    /// Divide color values by exposure to get to get physical radiance in\n    /// watts/steradian/m<sup>2</sup>\n    ///\n    /// Image may not contain physical data, even if this field is set.\n    pub exposure: Option<f32>,\n    /// Divide color values by corresponding tuple member (r, g, b) to get to get physical radiance\n    /// in watts/steradian/m<sup>2</sup>\n    ///\n    /// Image may not contain physical data, even if this field is set.\n    pub color_correction: Option<(f32, f32, f32)>,\n    /// Pixel height divided by pixel width\n    pub pixel_aspect_ratio: Option<f32>,\n    /// All lines contained in image header are put here. Ordering of lines is preserved.\n    /// Lines in the form \"key=value\" are represented as (\"key\", \"value\").\n    /// All other lines are (\"\", \"line\")\n    pub custom_attributes: Vec<(String, String)>,\n}\n\nimpl HDRMetadata {\n    fn new() -> HDRMetadata {\n        HDRMetadata {\n            width: 0,\n            height: 0,\n            orientation: ((1, 0), (0, 1)),\n            exposure: None,\n            color_correction: None,\n            pixel_aspect_ratio: None,\n            custom_attributes: vec![],\n        }\n    }\n\n    // Updates header info, in strict mode returns error for malformed lines (no '=' separator)\n    // unknown attributes are skipped\n    fn update_header_info(&mut self, line: &str, strict: bool) -> ImageResult<()> {\n        // split line at first '='\n        // old Radiance HDR files (*.pic) feature tabs in key, so                vvv trim\n        let maybe_key_value = split_at_first(line, \"=\").map(|(key, value)| (key.trim(), value));\n        // save all header lines in custom_attributes\n        match maybe_key_value {\n            Some((key, val)) => self.custom_attributes\n                .push((key.to_owned(), val.to_owned())),\n            None => self.custom_attributes.push((\"\".into(), line.to_owned())),\n        }\n        // parse known attributes\n        match maybe_key_value {\n            Some((\"FORMAT\", val)) => {\n                if val.trim() != \"32-bit_rle_rgbe\" {\n                    // XYZE isn't supported yet\n                    return Err(ImageError::UnsupportedError(limit_string_len(val, 20)));\n                }\n            }\n            Some((\"EXPOSURE\", val)) => {\n                match val.trim().parse::<f32>() {\n                    Ok(v) => {\n                        self.exposure = Some(self.exposure.unwrap_or(1.0) * v); // all encountered exposure values should be multiplied\n                    }\n                    Err(parse_error) => {\n                        if strict {\n                            return Err(ImageError::FormatError(format!(\n                                \"Cannot parse EXPOSURE value: {}\",\n                                parse_error.description()\n                            )));\n                        } // no else, skip this line in non-strict mode\n                    }\n                };\n            }\n            Some((\"PIXASPECT\", val)) => {\n                match val.trim().parse::<f32>() {\n                    Ok(v) => {\n                        self.pixel_aspect_ratio = Some(self.pixel_aspect_ratio.unwrap_or(1.0) * v); // all encountered exposure values should be multiplied\n                    }\n                    Err(parse_error) => {\n                        if strict {\n                            return Err(ImageError::FormatError(format!(\n                                \"Cannot parse PIXASPECT value: {}\",\n                                parse_error.description()\n                            )));\n                        } // no else, skip this line in non-strict mode\n                    }\n                };\n            }\n            Some((\"COLORCORR\", val)) => {\n                let mut rgbcorr = [1.0, 1.0, 1.0];\n                match parse_space_separated_f32(val, &mut rgbcorr, \"COLORCORR\") {\n                    Ok(extra_numbers) => {\n                        if strict && extra_numbers {\n                            return Err(ImageError::FormatError(\n                                \"Extra numbers in COLORCORR\".into(),\n                            ));\n                        } // no else, just ignore extra numbers\n                        let (rc, gc, bc) = self.color_correction.unwrap_or((1.0, 1.0, 1.0));\n                        self.color_correction =\n                            Some((rc * rgbcorr[0], gc * rgbcorr[1], bc * rgbcorr[2]));\n                    }\n                    Err(err) => {\n                        if strict {\n                            return Err(err);\n                        } // no else, skip malformed line in non-strict mode\n                    }\n                }\n            }\n            None => {\n                // old Radiance HDR files (*.pic) contain commands in a header\n                // just skip them\n            }\n            _ => {\n                // skip unknown attribute\n            }\n        } // match attributes\n        Ok(())\n    }\n}\n\nfn parse_space_separated_f32(line: &str, vals: &mut [f32], name: &str) -> ImageResult<bool> {\n    let mut nums = line.split_whitespace();\n    for val in vals.iter_mut() {\n        if let Some(num) = nums.next() {\n            match num.parse::<f32>() {\n                Ok(v) => *val = v,\n                Err(err) => {\n                    return Err(ImageError::FormatError(format!(\n                        \"f32 parse error in {}: {}\",\n                        name,\n                        err.description()\n                    )));\n                }\n            }\n        } else {\n            // not enough numbers in line\n            return Err(ImageError::FormatError(format!(\n                \"Not enough numbers in {}\",\n                name\n            )));\n        }\n    }\n    Ok(nums.next().is_some())\n}\n\n// Parses dimension line \"-Y height +X width\"\n// returns (width, height) or error\nfn parse_dimensions_line(line: &str, strict: bool) -> ImageResult<(u32, u32)> {\n    let mut dim_parts = line.split_whitespace();\n    let err = \"Malformed dimensions line\";\n    let c1_tag = try!(\n        dim_parts\n            .next()\n            .ok_or_else(|| ImageError::FormatError(err.into()))\n    );\n    let c1_str = try!(\n        dim_parts\n            .next()\n            .ok_or_else(|| ImageError::FormatError(err.into()))\n    );\n    let c2_tag = try!(\n        dim_parts\n            .next()\n            .ok_or_else(|| ImageError::FormatError(err.into()))\n    );\n    let c2_str = try!(\n        dim_parts\n            .next()\n            .ok_or_else(|| ImageError::FormatError(err.into()))\n    );\n    if strict && dim_parts.next().is_some() {\n        // extra data in dimensions line\n        return Err(ImageError::FormatError(err.into()));\n    } // no else\n      // dimensions line is in the form \"-Y 10 +X 20\"\n      // There are 8 possible orientations: +Y +X, +X -Y and so on\n    match (c1_tag, c2_tag) {\n        (\"-Y\", \"+X\") => {\n            // Common orientation (left-right, top-down)\n            // c1_str is height, c2_str is width\n            let height = try!(c1_str.parse::<u32>().into_image_error(err));\n            let width = try!(c2_str.parse::<u32>().into_image_error(err));\n            Ok((width, height))\n        }\n        _ => Err(ImageError::FormatError(format!(\n            \"Unsupported orientation {} {}\",\n            limit_string_len(c1_tag, 4),\n            limit_string_len(c2_tag, 4)\n        ))),\n    } // final expression. Returns value\n}\n\ntrait IntoImageError<T> {\n    fn into_image_error(self, description: &str) -> ImageResult<T>;\n}\n\nimpl<T> IntoImageError<T> for ::std::result::Result<T, ::std::num::ParseFloatError> {\n    fn into_image_error(self, description: &str) -> ImageResult<T> {\n        self.map_err(|err| {\n            ImageError::FormatError(format!(\"{} {}\", description, err.description()))\n        })\n    }\n}\n\nimpl<T> IntoImageError<T> for ::std::result::Result<T, ::std::num::ParseIntError> {\n    fn into_image_error(self, description: &str) -> ImageResult<T> {\n        self.map_err(|err| {\n            ImageError::FormatError(format!(\"{} {}\", description, err.description()))\n        })\n    }\n}\n\n// Returns string with no more than len+3 characters\nfn limit_string_len(s: &str, len: usize) -> String {\n    let s_char_len = s.chars().count();\n    if s_char_len > len {\n        s.chars().take(len).chain(\"...\".chars()).collect()\n    } else {\n        s.into()\n    }\n}\n\n// Splits string into (before separator, after separator) tuple\n// or None if separator isn't found\nfn split_at_first<'a>(s: &'a str, separator: &str) -> Option<(&'a str, &'a str)> {\n    match s.find(separator) {\n        None | Some(0) => None,\n        Some(p) if p >= s.len() - separator.len() => None,\n        Some(p) => Some((&s[..p], &s[(p + separator.len())..])),\n    }\n}\n\n#[test]\nfn split_at_first_test() {\n    assert_eq!(split_at_first(&Cow::Owned(\"\".into()), \"=\"), None);\n    assert_eq!(split_at_first(&Cow::Owned(\"=\".into()), \"=\"), None);\n    assert_eq!(split_at_first(&Cow::Owned(\"= \".into()), \"=\"), None);\n    assert_eq!(\n        split_at_first(&Cow::Owned(\" = \".into()), \"=\"),\n        Some((\" \", \" \"))\n    );\n    assert_eq!(\n        split_at_first(&Cow::Owned(\"EXPOSURE= \".into()), \"=\"),\n        Some((\"EXPOSURE\", \" \"))\n    );\n    assert_eq!(\n        split_at_first(&Cow::Owned(\"EXPOSURE= =\".into()), \"=\"),\n        Some((\"EXPOSURE\", \" =\"))\n    );\n    assert_eq!(\n        split_at_first(&Cow::Owned(\"EXPOSURE== =\".into()), \"==\"),\n        Some((\"EXPOSURE\", \" =\"))\n    );\n    assert_eq!(split_at_first(&Cow::Owned(\"EXPOSURE\".into()), \"\"), None);\n}\n\n// Reads input until b\"\\n\" or EOF\n// Returns vector of read bytes NOT including end of line characters\n//   or return None to indicate end of file\nfn read_line_u8<R: BufRead>(r: &mut R) -> ::std::io::Result<Option<Vec<u8>>> {\n    let mut ret = Vec::with_capacity(16);\n    match r.read_until(b'\\n', &mut ret) {\n        Ok(0) => Ok(None),\n        Ok(_) => {\n            if let Some(&b'\\n') = ret[..].last() {\n                let _ = ret.pop();\n            }\n            Ok(Some(ret))\n        }\n        Err(err) => Err(err),\n    }\n}\n\n#[test]\nfn read_line_u8_test() {\n    let buf: Vec<_> = (&b\"One\\nTwo\\nThree\\nFour\\n\\n\\n\"[..]).into();\n    let input = &mut ::std::io::Cursor::new(buf);\n    assert_eq!(&read_line_u8(input).unwrap().unwrap()[..], &b\"One\"[..]);\n    assert_eq!(&read_line_u8(input).unwrap().unwrap()[..], &b\"Two\"[..]);\n    assert_eq!(&read_line_u8(input).unwrap().unwrap()[..], &b\"Three\"[..]);\n    assert_eq!(&read_line_u8(input).unwrap().unwrap()[..], &b\"Four\"[..]);\n    assert_eq!(&read_line_u8(input).unwrap().unwrap()[..], &b\"\"[..]);\n    assert_eq!(&read_line_u8(input).unwrap().unwrap()[..], &b\"\"[..]);\n    assert_eq!(read_line_u8(input).unwrap(), None);\n}\n\n/// Helper function for reading raw 3-channel f32 images\npub fn read_raw_file<P: AsRef<Path>>(path: P) -> ::std::io::Result<Vec<Rgb<f32>>> {\n    use byteorder::{LittleEndian as LE, ReadBytesExt};\n    use std::fs::File;\n    use std::io::BufReader;\n\n    let mut r = BufReader::new(try!(File::open(path)));\n    let w = try!(r.read_u32::<LE>()) as usize;\n    let h = try!(r.read_u32::<LE>()) as usize;\n    let c = try!(r.read_u32::<LE>()) as usize;\n    assert_eq!(c, 3);\n    let cnt = w * h;\n    let mut ret = Vec::with_capacity(cnt);\n    for _ in 0..cnt {\n        let cr = try!(r.read_f32::<LE>());\n        let cg = try!(r.read_f32::<LE>());\n        let cb = try!(r.read_f32::<LE>());\n        ret.push(Rgb([cr, cg, cb]));\n    }\n    Ok(ret)\n}\n"
  },
  {
    "project": "tower-http",
    "target": 1,
    "commit_id": "c99dd0a42b5251c1a2efb4a253440933856988d6",
    "func": "use super::{open_file_with_fallback, AsyncReadBody, PrecompressedVariants};\nuse crate::services::fs::file_metadata_with_fallback;\nuse crate::{\n    content_encoding::{encodings, Encoding},\n    services::fs::DEFAULT_CAPACITY,\n};\nuse bytes::Bytes;\nuse futures_util::ready;\nuse http::response::Builder;\nuse http::{header, HeaderValue, Method, Request, Response, StatusCode, Uri};\nuse http_body::{combinators::BoxBody, Body, Empty, Full};\nuse http_range_header::RangeUnsatisfiableError;\nuse percent_encoding::percent_decode;\nuse std::fs::Metadata;\nuse std::io::SeekFrom;\nuse std::ops::RangeInclusive;\nuse std::{\n    future::Future,\n    io,\n    path::{Path, PathBuf},\n    pin::Pin,\n    task::{Context, Poll},\n};\nuse tokio::fs::File;\nuse tokio::io::AsyncSeekExt;\nuse tower_service::Service;\n\n/// Service that serves files from a given directory and all its sub directories.\n///\n/// The `Content-Type` will be guessed from the file extension.\n///\n/// An empty response with status `404 Not Found` will be returned if:\n///\n/// - The file doesn't exist\n/// - Any segment of the path contains `..`\n/// - Any segment of the path contains a backslash\n/// - We don't have necessary permissions to read the file\n///\n/// # Example\n///\n/// ```\n/// use tower_http::services::ServeDir;\n///\n/// // This will serve files in the \"assets\" directory and\n/// // its subdirectories\n/// let service = ServeDir::new(\"assets\");\n///\n/// # async {\n/// // Run our service using `hyper`\n/// let addr = std::net::SocketAddr::from(([127, 0, 0, 1], 3000));\n/// hyper::Server::bind(&addr)\n///     .serve(tower::make::Shared::new(service))\n///     .await\n///     .expect(\"server error\");\n/// # };\n/// ```\n///\n/// # Handling files not found\n///\n/// By default `ServeDir` will return an empty `404 Not Found` response if there\n/// is no file at the requested path. That can be customized by using\n/// [`and_then`](tower::ServiceBuilder::and_then) to change the response:\n///\n/// ```\n/// use tower_http::services::fs::{ServeDir, ServeFileSystemResponseBody};\n/// use tower::ServiceBuilder;\n/// use http::{StatusCode, Response};\n/// use http_body::{Body as _, Full};\n/// use std::io;\n///\n/// let service = ServiceBuilder::new()\n///     .and_then(|response: Response<ServeFileSystemResponseBody>| async move {\n///         let response = if response.status() == StatusCode::NOT_FOUND {\n///             let body = Full::from(\"Not Found\")\n///                 .map_err(|err| match err {})\n///                 .boxed();\n///             Response::builder()\n///                 .status(StatusCode::NOT_FOUND)\n///                 .body(body)\n///                 .unwrap()\n///         } else {\n///             response.map(|body| body.boxed())\n///         };\n///\n///         Ok::<_, io::Error>(response)\n///     })\n///     .service(ServeDir::new(\"assets\"));\n/// # async {\n/// # let addr = std::net::SocketAddr::from(([127, 0, 0, 1], 3000));\n/// # hyper::Server::bind(&addr)\n/// #     .serve(tower::make::Shared::new(service))\n/// #     .await\n/// #     .expect(\"server error\");\n/// # };\n/// ```\n#[derive(Clone, Debug)]\npub struct ServeDir {\n    base: PathBuf,\n    buf_chunk_size: usize,\n    precompressed_variants: Option<PrecompressedVariants>,\n    // This is used to specialise implementation for\n    // single files\n    variant: ServeVariant,\n}\n\n// Allow the ServeDir service to be used in the ServeFile service\n// with almost no overhead\n#[derive(Clone, Debug)]\nenum ServeVariant {\n    Directory {\n        append_index_html_on_directories: bool,\n    },\n    SingleFile {\n        mime: HeaderValue,\n    },\n}\n\nimpl ServeVariant {\n    fn full_path(&self, base_path: &Path, requested_path: &str) -> Option<PathBuf> {\n        match self {\n            ServeVariant::Directory {\n                append_index_html_on_directories: _,\n            } => {\n                let full_path = build_and_validate_path(base_path, requested_path)?;\n                Some(full_path)\n            }\n            ServeVariant::SingleFile { mime: _ } => Some(base_path.to_path_buf()),\n        }\n    }\n}\n\nfn build_and_validate_path(base_path: &Path, requested_path: &str) -> Option<PathBuf> {\n    // build and validate the path\n    let path = requested_path.trim_start_matches('/');\n\n    let path_decoded = percent_decode(path.as_ref()).decode_utf8().ok()?;\n\n    let mut full_path = base_path.to_path_buf();\n    for seg in path_decoded.split('/') {\n        if seg.starts_with(\"..\") || seg.contains('\\\\') {\n            return None;\n        }\n        full_path.push(seg);\n    }\n    Some(full_path)\n}\n\nimpl ServeDir {\n    /// Create a new [`ServeDir`].\n    pub fn new<P: AsRef<Path>>(path: P) -> Self {\n        let mut base = PathBuf::from(\".\");\n        base.push(path.as_ref());\n\n        Self {\n            base,\n            buf_chunk_size: DEFAULT_CAPACITY,\n            precompressed_variants: None,\n            variant: ServeVariant::Directory {\n                append_index_html_on_directories: true,\n            },\n        }\n    }\n\n    pub(crate) fn new_single_file<P: AsRef<Path>>(path: P, mime: HeaderValue) -> Self {\n        Self {\n            base: path.as_ref().to_owned(),\n            buf_chunk_size: DEFAULT_CAPACITY,\n            precompressed_variants: None,\n            variant: ServeVariant::SingleFile { mime },\n        }\n    }\n\n    /// If the requested path is a directory append `index.html`.\n    ///\n    /// This is useful for static sites.\n    ///\n    /// Defaults to `true`.\n    pub fn append_index_html_on_directories(mut self, append: bool) -> Self {\n        match &mut self.variant {\n            ServeVariant::Directory {\n                append_index_html_on_directories,\n            } => {\n                *append_index_html_on_directories = append;\n                self\n            }\n            ServeVariant::SingleFile { mime: _ } => self,\n        }\n    }\n\n    /// Set a specific read buffer chunk size.\n    ///\n    /// The default capacity is 64kb.\n    pub fn with_buf_chunk_size(mut self, chunk_size: usize) -> Self {\n        self.buf_chunk_size = chunk_size;\n        self\n    }\n\n    /// Informs the service that it should also look for a precompressed gzip\n    /// version of _any_ file in the directory.\n    ///\n    /// Assuming the `dir` directory is being served and `dir/foo.txt` is requested,\n    /// a client with an `Accept-Encoding` header that allows the gzip encoding\n    /// will receive the file `dir/foo.txt.gz` instead of `dir/foo.txt`.\n    /// If the precompressed file is not available, or the client doesn't support it,\n    /// the uncompressed version will be served instead.\n    /// Both the precompressed version and the uncompressed version are expected\n    /// to be present in the directory. Different precompressed variants can be combined.\n    pub fn precompressed_gzip(mut self) -> Self {\n        self.precompressed_variants\n            .get_or_insert(Default::default())\n            .gzip = true;\n        self\n    }\n\n    /// Informs the service that it should also look for a precompressed brotli\n    /// version of _any_ file in the directory.\n    ///\n    /// Assuming the `dir` directory is being served and `dir/foo.txt` is requested,\n    /// a client with an `Accept-Encoding` header that allows the brotli encoding\n    /// will receive the file `dir/foo.txt.br` instead of `dir/foo.txt`.\n    /// If the precompressed file is not available, or the client doesn't support it,\n    /// the uncompressed version will be served instead.\n    /// Both the precompressed version and the uncompressed version are expected\n    /// to be present in the directory. Different precompressed variants can be combined.\n    pub fn precompressed_br(mut self) -> Self {\n        self.precompressed_variants\n            .get_or_insert(Default::default())\n            .br = true;\n        self\n    }\n\n    /// Informs the service that it should also look for a precompressed deflate\n    /// version of _any_ file in the directory.\n    ///\n    /// Assuming the `dir` directory is being served and `dir/foo.txt` is requested,\n    /// a client with an `Accept-Encoding` header that allows the deflate encoding\n    /// will receive the file `dir/foo.txt.zz` instead of `dir/foo.txt`.\n    /// If the precompressed file is not available, or the client doesn't support it,\n    /// the uncompressed version will be served instead.\n    /// Both the precompressed version and the uncompressed version are expected\n    /// to be present in the directory. Different precompressed variants can be combined.\n    pub fn precompressed_deflate(mut self) -> Self {\n        self.precompressed_variants\n            .get_or_insert(Default::default())\n            .deflate = true;\n        self\n    }\n}\n\nasync fn maybe_redirect_or_append_path(\n    full_path: &mut PathBuf,\n    uri: Uri,\n    append_index_html_on_directories: bool,\n) -> Option<Output> {\n    if !uri.path().ends_with('/') {\n        if is_dir(full_path).await {\n            let location = HeaderValue::from_str(&append_slash_on_path(uri).to_string()).unwrap();\n            return Some(Output::Redirect(location));\n        } else {\n            return None;\n        }\n    } else if is_dir(full_path).await {\n        if append_index_html_on_directories {\n            full_path.push(\"index.html\");\n            return None;\n        } else {\n            return Some(Output::NotFound);\n        }\n    }\n    None\n}\n\nimpl<ReqBody> Service<Request<ReqBody>> for ServeDir {\n    type Response = Response<ResponseBody>;\n    type Error = io::Error;\n    type Future = ResponseFuture;\n\n    #[inline]\n    fn poll_ready(&mut self, _cx: &mut Context<'_>) -> Poll<Result<(), Self::Error>> {\n        Poll::Ready(Ok(()))\n    }\n\n    fn call(&mut self, req: Request<ReqBody>) -> Self::Future {\n        let mut full_path = match self.variant.full_path(&self.base, req.uri().path()) {\n            Some(full_path) => full_path,\n            None => {\n                return ResponseFuture {\n                    inner: Inner::Invalid,\n                }\n            }\n        };\n\n        let buf_chunk_size = self.buf_chunk_size;\n        let uri = req.uri().clone();\n        let range_header = req\n            .headers()\n            .get(header::RANGE)\n            .and_then(|value| value.to_str().ok().map(|s| s.to_owned()));\n\n        // The negotiated encodings based on the Accept-Encoding header and\n        // precompressed variants\n        let negotiated_encodings = encodings(\n            req.headers(),\n            self.precompressed_variants.unwrap_or_default(),\n        );\n\n        let request_method = req.method().clone();\n        let variant = self.variant.clone();\n\n        let open_file_future = Box::pin(async move {\n            let mime = match variant {\n                ServeVariant::Directory {\n                    append_index_html_on_directories,\n                } => {\n                    // Might already at this point know a redirect or not found result should be\n                    // returned which corresponds to a Some(output). Otherwise the path might be\n                    // modified and proceed to the open file/metadata future.\n                    if let Some(output) = maybe_redirect_or_append_path(\n                        &mut full_path,\n                        uri,\n                        append_index_html_on_directories,\n                    )\n                    .await\n                    {\n                        return Ok(output);\n                    }\n                    let guess = mime_guess::from_path(&full_path);\n                    guess\n                        .first_raw()\n                        .map(|mime| HeaderValue::from_static(mime))\n                        .unwrap_or_else(|| {\n                            HeaderValue::from_str(mime::APPLICATION_OCTET_STREAM.as_ref()).unwrap()\n                        })\n                }\n                ServeVariant::SingleFile { mime } => mime,\n            };\n\n            match request_method {\n                Method::HEAD => {\n                    let (meta, maybe_encoding) =\n                        file_metadata_with_fallback(full_path, negotiated_encodings).await?;\n                    let maybe_range = try_parse_range(range_header.as_ref(), meta.len());\n                    Ok(Output::File(FileRequest {\n                        extent: FileRequestExtent::Head(meta),\n                        chunk_size: buf_chunk_size,\n                        mime_header_value: mime,\n                        maybe_encoding,\n                        maybe_range,\n                    }))\n                }\n                _ => {\n                    let (mut file, maybe_encoding) =\n                        open_file_with_fallback(full_path, negotiated_encodings).await?;\n                    let meta = file.metadata().await?;\n                    let maybe_range = try_parse_range(range_header.as_ref(), meta.len());\n                    if let Some(Ok(ranges)) = maybe_range.as_ref() {\n                        // If there is any other amount of ranges than 1 we'll return an unsatisfiable later as there isn't yet support for multipart ranges\n                        if ranges.len() == 1 {\n                            file.seek(SeekFrom::Start(*ranges[0].start())).await?;\n                        }\n                    }\n                    Ok(Output::File(FileRequest {\n                        extent: FileRequestExtent::Full(file, meta),\n                        chunk_size: buf_chunk_size,\n                        mime_header_value: mime,\n                        maybe_encoding,\n                        maybe_range,\n                    }))\n                }\n            }\n        });\n\n        ResponseFuture {\n            inner: Inner::Valid(open_file_future),\n        }\n    }\n}\n\nfn try_parse_range(\n    maybe_range_ref: Option<&String>,\n    file_size: u64,\n) -> Option<Result<Vec<RangeInclusive<u64>>, RangeUnsatisfiableError>> {\n    maybe_range_ref.map(|header_value| {\n        http_range_header::parse_range_header(header_value)\n            .and_then(|first_pass| first_pass.validate(file_size))\n    })\n}\n\nasync fn is_dir(full_path: &Path) -> bool {\n    tokio::fs::metadata(full_path)\n        .await\n        .map(|m| m.is_dir())\n        .unwrap_or(false)\n}\n\nfn append_slash_on_path(uri: Uri) -> Uri {\n    let http::uri::Parts {\n        scheme,\n        authority,\n        path_and_query,\n        ..\n    } = uri.into_parts();\n\n    let mut builder = Uri::builder();\n    if let Some(scheme) = scheme {\n        builder = builder.scheme(scheme);\n    }\n    if let Some(authority) = authority {\n        builder = builder.authority(authority);\n    }\n    if let Some(path_and_query) = path_and_query {\n        if let Some(query) = path_and_query.query() {\n            builder = builder.path_and_query(format!(\"{}/?{}\", path_and_query.path(), query));\n        } else {\n            builder = builder.path_and_query(format!(\"{}/\", path_and_query.path()));\n        }\n    } else {\n        builder = builder.path_and_query(\"/\");\n    }\n\n    builder.build().unwrap()\n}\n\nenum Output {\n    File(FileRequest),\n    Redirect(HeaderValue),\n    NotFound,\n}\n\nstruct FileRequest {\n    extent: FileRequestExtent,\n    chunk_size: usize,\n    mime_header_value: HeaderValue,\n    maybe_encoding: Option<Encoding>,\n    maybe_range: Option<Result<Vec<RangeInclusive<u64>>, RangeUnsatisfiableError>>,\n}\n\nenum FileRequestExtent {\n    Full(File, Metadata),\n    Head(Metadata),\n}\n\ntype BoxFuture<T> = Pin<Box<dyn Future<Output = T> + Send + Sync + 'static>>;\n\nenum Inner {\n    Valid(BoxFuture<io::Result<Output>>),\n    Invalid,\n}\n\n/// Response future of [`ServeDir`].\npub struct ResponseFuture {\n    inner: Inner,\n}\n\nimpl Future for ResponseFuture {\n    type Output = io::Result<Response<ResponseBody>>;\n\n    fn poll(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> {\n        match &mut self.inner {\n            Inner::Valid(open_file_future) => {\n                return match ready!(Pin::new(open_file_future).poll(cx)) {\n                    Ok(Output::File(file_request)) => {\n                        let (maybe_file, size) = match file_request.extent {\n                            FileRequestExtent::Full(file, meta) => (Some(file), meta.len()),\n                            FileRequestExtent::Head(meta) => (None, meta.len()),\n                        };\n                        let mut builder = Response::builder()\n                            .header(header::CONTENT_TYPE, file_request.mime_header_value)\n                            .header(header::ACCEPT_RANGES, \"bytes\")\n                            .header(header::CONTENT_LENGTH, size.to_string());\n                        if let Some(encoding) = file_request.maybe_encoding {\n                            builder = builder\n                                .header(header::CONTENT_ENCODING, encoding.into_header_value());\n                        }\n                        let res = handle_file_request(\n                            builder,\n                            maybe_file,\n                            file_request.maybe_range,\n                            file_request.chunk_size,\n                            size,\n                        );\n                        Poll::Ready(Ok(res.unwrap()))\n                    }\n\n                    Ok(Output::Redirect(location)) => {\n                        let res = Response::builder()\n                            .header(http::header::LOCATION, location)\n                            .status(StatusCode::TEMPORARY_REDIRECT)\n                            .body(empty_body())\n                            .unwrap();\n                        Poll::Ready(Ok(res))\n                    }\n\n                    Ok(Output::NotFound) => {\n                        let res = Response::builder()\n                            .status(StatusCode::NOT_FOUND)\n                            .body(empty_body())\n                            .unwrap();\n\n                        Poll::Ready(Ok(res))\n                    }\n\n                    Err(err) => Poll::Ready(\n                        super::response_from_io_error(err).map(|res| res.map(ResponseBody::new)),\n                    ),\n                };\n            }\n            Inner::Invalid => {\n                let res = Response::builder()\n                    .status(StatusCode::NOT_FOUND)\n                    .body(empty_body())\n                    .unwrap();\n\n                Poll::Ready(Ok(res))\n            }\n        }\n    }\n}\n\nfn handle_file_request(\n    builder: Builder,\n    maybe_file: Option<File>,\n    maybe_range: Option<Result<Vec<RangeInclusive<u64>>, RangeUnsatisfiableError>>,\n    chunk_size: usize,\n    size: u64,\n) -> Result<Response<ResponseBody>, http::Error> {\n    match maybe_range {\n        Some(Ok(ranges)) => {\n            if let Some(range) = ranges.first() {\n                if ranges.len() > 1 {\n                    builder\n                        .header(header::CONTENT_RANGE, format!(\"bytes */{}\", size))\n                        .status(StatusCode::RANGE_NOT_SATISFIABLE)\n                        .body(body_from_bytes(Bytes::from(\n                            \"Cannot serve multipart range requests\",\n                        )))\n                } else {\n                    let range_size = range.end() - range.start() + 1;\n                    let body = if let Some(file) = maybe_file {\n                        let body =\n                            AsyncReadBody::with_capacity_limited(file, chunk_size, range_size)\n                                .boxed();\n                        ResponseBody::new(body)\n                    } else {\n                        empty_body()\n                    };\n                    builder\n                        .header(\n                            header::CONTENT_RANGE,\n                            format!(\"bytes {}-{}/{}\", range.start(), range.end(), size),\n                        )\n                        .status(StatusCode::PARTIAL_CONTENT)\n                        .body(body)\n                }\n            } else {\n                builder\n                    .header(header::CONTENT_RANGE, format!(\"bytes */{}\", size))\n                    .status(StatusCode::RANGE_NOT_SATISFIABLE)\n                    .body(body_from_bytes(Bytes::from(\n                        \"No range found after parsing range header, please file an issue\",\n                    )))\n            }\n        }\n        Some(Err(_)) => builder\n            .header(header::CONTENT_RANGE, format!(\"bytes */{}\", size))\n            .status(StatusCode::RANGE_NOT_SATISFIABLE)\n            .body(empty_body()),\n        // Not a range request\n        None => {\n            let body = if let Some(file) = maybe_file {\n                let box_body = AsyncReadBody::with_capacity(file, chunk_size).boxed();\n                ResponseBody::new(box_body)\n            } else {\n                empty_body()\n            };\n            builder.body(body)\n        }\n    }\n}\n\nfn empty_body() -> ResponseBody {\n    let body = Empty::new().map_err(|err| match err {}).boxed();\n    ResponseBody::new(body)\n}\n\nfn body_from_bytes(bytes: Bytes) -> ResponseBody {\n    let body = Full::from(bytes).map_err(|err| match err {}).boxed();\n    ResponseBody::new(body)\n}\n\nopaque_body! {\n    /// Response body for [`ServeDir`] and [`ServeFile`].\n    pub type ResponseBody = BoxBody<Bytes, io::Error>;\n}\n\n#[cfg(test)]\nmod tests {\n    use std::io::Read;\n\n    #[allow(unused_imports)]\n    use super::*;\n    use brotli::BrotliDecompress;\n    use flate2::bufread::{DeflateDecoder, GzDecoder};\n    use http::{Request, StatusCode};\n    use http_body::Body as HttpBody;\n    use hyper::Body;\n    use tower::ServiceExt;\n\n    #[tokio::test]\n    async fn basic() {\n        let svc = ServeDir::new(\"..\");\n\n        let req = Request::builder()\n            .uri(\"/README.md\")\n            .body(Body::empty())\n            .unwrap();\n        let res = svc.oneshot(req).await.unwrap();\n\n        assert_eq!(res.status(), StatusCode::OK);\n        assert_eq!(res.headers()[\"content-type\"], \"text/markdown\");\n\n        let body = body_into_text(res.into_body()).await;\n\n        let contents = std::fs::read_to_string(\"../README.md\").unwrap();\n        assert_eq!(body, contents);\n    }\n\n    #[tokio::test]\n    async fn basic_with_index() {\n        let svc = ServeDir::new(\"../test-files\");\n\n        let req = Request::new(Body::empty());\n        let res = svc.oneshot(req).await.unwrap();\n\n        assert_eq!(res.status(), StatusCode::OK);\n        assert_eq!(res.headers()[header::CONTENT_TYPE], \"text/html\");\n\n        let body = body_into_text(res.into_body()).await;\n        assert_eq!(body, \"<b>HTML!</b>\\n\");\n    }\n\n    #[tokio::test]\n    async fn head_request() {\n        let svc = ServeDir::new(\"../test-files\");\n\n        let req = Request::builder()\n            .uri(\"/precompressed.txt\")\n            .method(Method::HEAD)\n            .body(Body::empty())\n            .unwrap();\n\n        let res = svc.oneshot(req).await.unwrap();\n\n        assert_eq!(res.headers()[\"content-type\"], \"text/plain\");\n        assert_eq!(res.headers()[\"content-length\"], \"23\");\n\n        let body = res.into_body().data().await;\n        assert!(body.is_none());\n    }\n\n    #[tokio::test]\n    async fn precompresed_head_request() {\n        let svc = ServeDir::new(\"../test-files\").precompressed_gzip();\n\n        let req = Request::builder()\n            .uri(\"/precompressed.txt\")\n            .header(\"Accept-Encoding\", \"gzip\")\n            .method(Method::HEAD)\n            .body(Body::empty())\n            .unwrap();\n        let res = svc.oneshot(req).await.unwrap();\n\n        assert_eq!(res.headers()[\"content-type\"], \"text/plain\");\n        assert_eq!(res.headers()[\"content-encoding\"], \"gzip\");\n        assert_eq!(res.headers()[\"content-length\"], \"59\");\n\n        let body = res.into_body().data().await;\n        assert!(body.is_none());\n    }\n\n    #[tokio::test]\n    async fn with_custom_chunk_size() {\n        let svc = ServeDir::new(\"..\").with_buf_chunk_size(1024 * 32);\n\n        let req = Request::builder()\n            .uri(\"/README.md\")\n            .body(Body::empty())\n            .unwrap();\n        let res = svc.oneshot(req).await.unwrap();\n\n        assert_eq!(res.status(), StatusCode::OK);\n        assert_eq!(res.headers()[\"content-type\"], \"text/markdown\");\n\n        let body = body_into_text(res.into_body()).await;\n\n        let contents = std::fs::read_to_string(\"../README.md\").unwrap();\n        assert_eq!(body, contents);\n    }\n\n    #[tokio::test]\n    async fn precompressed_gzip() {\n        let svc = ServeDir::new(\"../test-files\").precompressed_gzip();\n\n        let req = Request::builder()\n            .uri(\"/precompressed.txt\")\n            .header(\"Accept-Encoding\", \"gzip\")\n            .body(Body::empty())\n            .unwrap();\n        let res = svc.oneshot(req).await.unwrap();\n\n        assert_eq!(res.headers()[\"content-type\"], \"text/plain\");\n        assert_eq!(res.headers()[\"content-encoding\"], \"gzip\");\n\n        let body = res.into_body().data().await.unwrap().unwrap();\n        let mut decoder = GzDecoder::new(&body[..]);\n        let mut decompressed = String::new();\n        decoder.read_to_string(&mut decompressed).unwrap();\n        assert!(decompressed.starts_with(\"\\\"This is a test file!\\\"\"));\n    }\n\n    #[tokio::test]\n    async fn precompressed_br() {\n        let svc = ServeDir::new(\"../test-files\").precompressed_br();\n\n        let req = Request::builder()\n            .uri(\"/precompressed.txt\")\n            .header(\"Accept-Encoding\", \"br\")\n            .body(Body::empty())\n            .unwrap();\n        let res = svc.oneshot(req).await.unwrap();\n\n        assert_eq!(res.headers()[\"content-type\"], \"text/plain\");\n        assert_eq!(res.headers()[\"content-encoding\"], \"br\");\n\n        let body = res.into_body().data().await.unwrap().unwrap();\n        let mut decompressed = Vec::new();\n        BrotliDecompress(&mut &body[..], &mut decompressed).unwrap();\n        let decompressed = String::from_utf8(decompressed.to_vec()).unwrap();\n        assert!(decompressed.starts_with(\"\\\"This is a test file!\\\"\"));\n    }\n\n    #[tokio::test]\n    async fn precompressed_deflate() {\n        let svc = ServeDir::new(\"../test-files\").precompressed_deflate();\n        let request = Request::builder()\n            .uri(\"/precompressed.txt\")\n            .header(\"Accept-Encoding\", \"deflate,br\")\n            .body(Body::empty())\n            .unwrap();\n        let res = svc.oneshot(request).await.unwrap();\n\n        assert_eq!(res.headers()[\"content-type\"], \"text/plain\");\n        assert_eq!(res.headers()[\"content-encoding\"], \"deflate\");\n\n        let body = res.into_body().data().await.unwrap().unwrap();\n        let mut decoder = DeflateDecoder::new(&body[..]);\n        let mut decompressed = String::new();\n        decoder.read_to_string(&mut decompressed).unwrap();\n        assert!(decompressed.starts_with(\"\\\"This is a test file!\\\"\"));\n    }\n\n    #[tokio::test]\n    async fn unsupported_precompression_alogrithm_fallbacks_to_uncompressed() {\n        let svc = ServeDir::new(\"../test-files\").precompressed_gzip();\n\n        let request = Request::builder()\n            .uri(\"/precompressed.txt\")\n            .header(\"Accept-Encoding\", \"br\")\n            .body(Body::empty())\n            .unwrap();\n        let res = svc.oneshot(request).await.unwrap();\n\n        assert_eq!(res.headers()[\"content-type\"], \"text/plain\");\n        assert!(res.headers().get(\"content-encoding\").is_none());\n\n        let body = res.into_body().data().await.unwrap().unwrap();\n        let body = String::from_utf8(body.to_vec()).unwrap();\n        assert!(body.starts_with(\"\\\"This is a test file!\\\"\"));\n    }\n\n    #[tokio::test]\n    async fn only_precompressed_variant_existing() {\n        let svc = ServeDir::new(\"../test-files\").precompressed_gzip();\n\n        let request = Request::builder()\n            .uri(\"/only_gzipped.txt\")\n            .body(Body::empty())\n            .unwrap();\n        let res = svc.clone().oneshot(request).await.unwrap();\n\n        assert_eq!(res.status(), StatusCode::NOT_FOUND);\n\n        // Should reply with gzipped file if client supports it\n        let request = Request::builder()\n            .uri(\"/only_gzipped.txt\")\n            .header(\"Accept-Encoding\", \"gzip\")\n            .body(Body::empty())\n            .unwrap();\n        let res = svc.oneshot(request).await.unwrap();\n\n        assert_eq!(res.headers()[\"content-type\"], \"text/plain\");\n        assert_eq!(res.headers()[\"content-encoding\"], \"gzip\");\n\n        let body = res.into_body().data().await.unwrap().unwrap();\n        let mut decoder = GzDecoder::new(&body[..]);\n        let mut decompressed = String::new();\n        decoder.read_to_string(&mut decompressed).unwrap();\n        assert!(decompressed.starts_with(\"\\\"This is a test file\\\"\"));\n    }\n\n    #[tokio::test]\n    async fn missing_precompressed_variant_fallbacks_to_uncompressed() {\n        let svc = ServeDir::new(\"../test-files\").precompressed_gzip();\n\n        let request = Request::builder()\n            .uri(\"/missing_precompressed.txt\")\n            .header(\"Accept-Encoding\", \"gzip\")\n            .body(Body::empty())\n            .unwrap();\n        let res = svc.oneshot(request).await.unwrap();\n\n        assert_eq!(res.headers()[\"content-type\"], \"text/plain\");\n        // Uncompressed file is served because compressed version is missing\n        assert!(res.headers().get(\"content-encoding\").is_none());\n\n        let body = res.into_body().data().await.unwrap().unwrap();\n        let body = String::from_utf8(body.to_vec()).unwrap();\n        assert!(body.starts_with(\"Test file!\"));\n    }\n\n    #[tokio::test]\n    async fn missing_precompressed_variant_fallbacks_to_uncompressed_for_head_request() {\n        let svc = ServeDir::new(\"../test-files\").precompressed_gzip();\n\n        let request = Request::builder()\n            .uri(\"/missing_precompressed.txt\")\n            .header(\"Accept-Encoding\", \"gzip\")\n            .method(Method::HEAD)\n            .body(Body::empty())\n            .unwrap();\n        let res = svc.oneshot(request).await.unwrap();\n\n        assert_eq!(res.headers()[\"content-type\"], \"text/plain\");\n        assert_eq!(res.headers()[\"content-length\"], \"11\");\n        // Uncompressed file is served because compressed version is missing\n        assert!(res.headers().get(\"content-encoding\").is_none());\n\n        assert!(res.into_body().data().await.is_none());\n    }\n\n    #[tokio::test]\n    async fn access_to_sub_dirs() {\n        let svc = ServeDir::new(\"..\");\n\n        let req = Request::builder()\n            .uri(\"/tower-http/Cargo.toml\")\n            .body(Body::empty())\n            .unwrap();\n        let res = svc.oneshot(req).await.unwrap();\n\n        assert_eq!(res.status(), StatusCode::OK);\n        assert_eq!(res.headers()[\"content-type\"], \"text/x-toml\");\n\n        let body = body_into_text(res.into_body()).await;\n\n        let contents = std::fs::read_to_string(\"Cargo.toml\").unwrap();\n        assert_eq!(body, contents);\n    }\n\n    #[tokio::test]\n    async fn not_found() {\n        let svc = ServeDir::new(\"..\");\n\n        let req = Request::builder()\n            .uri(\"/not-found\")\n            .body(Body::empty())\n            .unwrap();\n        let res = svc.oneshot(req).await.unwrap();\n\n        assert_eq!(res.status(), StatusCode::NOT_FOUND);\n        assert!(res.headers().get(header::CONTENT_TYPE).is_none());\n\n        let body = body_into_text(res.into_body()).await;\n        assert!(body.is_empty());\n    }\n\n    #[tokio::test]\n    async fn not_found_precompressed() {\n        let svc = ServeDir::new(\"../test-files\").precompressed_gzip();\n\n        let req = Request::builder()\n            .uri(\"/not-found\")\n            .header(\"Accept-Encoding\", \"gzip\")\n            .body(Body::empty())\n            .unwrap();\n        let res = svc.oneshot(req).await.unwrap();\n\n        assert_eq!(res.status(), StatusCode::NOT_FOUND);\n        assert!(res.headers().get(header::CONTENT_TYPE).is_none());\n\n        let body = body_into_text(res.into_body()).await;\n        assert!(body.is_empty());\n    }\n\n    #[tokio::test]\n    async fn fallbacks_to_different_precompressed_variant_if_not_found_for_head_request() {\n        let svc = ServeDir::new(\"../test-files\")\n            .precompressed_gzip()\n            .precompressed_br();\n\n        let req = Request::builder()\n            .uri(\"/precompressed_br.txt\")\n            .header(\"Accept-Encoding\", \"gzip,br,deflate\")\n            .method(Method::HEAD)\n            .body(Body::empty())\n            .unwrap();\n        let res = svc.oneshot(req).await.unwrap();\n\n        assert_eq!(res.headers()[\"content-type\"], \"text/plain\");\n        assert_eq!(res.headers()[\"content-encoding\"], \"br\");\n        assert_eq!(res.headers()[\"content-length\"], \"15\");\n\n        assert!(res.into_body().data().await.is_none());\n    }\n\n    #[tokio::test]\n    async fn fallbacks_to_different_precompressed_variant_if_not_found() {\n        let svc = ServeDir::new(\"../test-files\")\n            .precompressed_gzip()\n            .precompressed_br();\n\n        let req = Request::builder()\n            .uri(\"/precompressed_br.txt\")\n            .header(\"Accept-Encoding\", \"gzip,br,deflate\")\n            .body(Body::empty())\n            .unwrap();\n        let res = svc.oneshot(req).await.unwrap();\n\n        assert_eq!(res.headers()[\"content-type\"], \"text/plain\");\n        assert_eq!(res.headers()[\"content-encoding\"], \"br\");\n\n        let body = res.into_body().data().await.unwrap().unwrap();\n        let mut decompressed = Vec::new();\n        BrotliDecompress(&mut &body[..], &mut decompressed).unwrap();\n        let decompressed = String::from_utf8(decompressed.to_vec()).unwrap();\n        assert!(decompressed.starts_with(\"Test file\"));\n    }\n\n    #[tokio::test]\n    async fn redirect_to_trailing_slash_on_dir() {\n        let svc = ServeDir::new(\".\");\n\n        let req = Request::builder().uri(\"/src\").body(Body::empty()).unwrap();\n        let res = svc.oneshot(req).await.unwrap();\n\n        assert_eq!(res.status(), StatusCode::TEMPORARY_REDIRECT);\n\n        let location = &res.headers()[http::header::LOCATION];\n        assert_eq!(location, \"/src/\");\n    }\n\n    #[tokio::test]\n    async fn empty_directory_without_index() {\n        let svc = ServeDir::new(\".\").append_index_html_on_directories(false);\n\n        let req = Request::new(Body::empty());\n        let res = svc.oneshot(req).await.unwrap();\n\n        assert_eq!(res.status(), StatusCode::NOT_FOUND);\n        assert!(res.headers().get(header::CONTENT_TYPE).is_none());\n\n        let body = body_into_text(res.into_body()).await;\n        assert!(body.is_empty());\n    }\n\n    async fn body_into_text<B>(body: B) -> String\n    where\n        B: HttpBody<Data = bytes::Bytes> + Unpin,\n        B::Error: std::fmt::Debug,\n    {\n        let bytes = hyper::body::to_bytes(body).await.unwrap();\n        String::from_utf8(bytes.to_vec()).unwrap()\n    }\n\n    #[tokio::test]\n    async fn access_cjk_percent_encoded_uri_path() {\n        let cjk_filename = \"\u4f60\u597d\u4e16\u754c.txt\";\n        // percent encoding present of \u4f60\u597d\u4e16\u754c.txt\n        let cjk_filename_encoded = \"%E4%BD%A0%E5%A5%BD%E4%B8%96%E7%95%8C.txt\";\n\n        let tmp_dir = std::env::temp_dir();\n        let tmp_filename = std::path::Path::new(tmp_dir.as_path()).join(cjk_filename);\n        let _ = tokio::fs::File::create(&tmp_filename).await.unwrap();\n\n        let svc = ServeDir::new(&tmp_dir);\n\n        let req = Request::builder()\n            .uri(format!(\"/{}\", cjk_filename_encoded))\n            .body(Body::empty())\n            .unwrap();\n        let res = svc.oneshot(req).await.unwrap();\n\n        assert_eq!(res.status(), StatusCode::OK);\n        assert_eq!(res.headers()[\"content-type\"], \"text/plain\");\n        let _ = tokio::fs::remove_file(&tmp_filename).await.unwrap();\n    }\n\n    #[tokio::test]\n    async fn access_space_percent_encoded_uri_path() {\n        let raw_filename = \"filename with space.txt\";\n        // percent encoding present of \"filename with space.txt\"\n        let encoded_filename = \"filename%20with%20space.txt\";\n\n        let tmp_dir = std::env::temp_dir();\n        let tmp_filename = std::path::Path::new(tmp_dir.as_path()).join(raw_filename);\n        let _ = tokio::fs::File::create(&tmp_filename).await.unwrap();\n\n        let svc = ServeDir::new(&tmp_dir);\n\n        let req = Request::builder()\n            .uri(format!(\"/{}\", encoded_filename))\n            .body(Body::empty())\n            .unwrap();\n        let res = svc.oneshot(req).await.unwrap();\n\n        assert_eq!(res.status(), StatusCode::OK);\n        assert_eq!(res.headers()[\"content-type\"], \"text/plain\");\n        let _ = tokio::fs::remove_file(&tmp_filename).await.unwrap();\n    }\n\n    #[tokio::test]\n    async fn read_partial_in_bounds() {\n        let svc = ServeDir::new(\"..\");\n        let bytes_start_incl = 9;\n        let bytes_end_incl = 1023;\n\n        let req = Request::builder()\n            .uri(\"/README.md\")\n            .header(\n                \"Range\",\n                format!(\"bytes={}-{}\", bytes_start_incl, bytes_end_incl),\n            )\n            .body(Body::empty())\n            .unwrap();\n        let res = svc.oneshot(req).await.unwrap();\n\n        let file_contents = std::fs::read(\"../README.md\").unwrap();\n        assert_eq!(res.status(), StatusCode::PARTIAL_CONTENT);\n        assert_eq!(\n            res.headers()[\"content-length\"],\n            file_contents.len().to_string()\n        );\n        assert!(res.headers()[\"content-range\"]\n            .to_str()\n            .unwrap()\n            .starts_with(&format!(\n                \"bytes {}-{}/{}\",\n                bytes_start_incl,\n                bytes_end_incl,\n                file_contents.len()\n            )));\n        assert_eq!(res.headers()[\"content-type\"], \"text/markdown\");\n\n        let body = hyper::body::to_bytes(res.into_body()).await.ok().unwrap();\n        let source = Bytes::from(file_contents[bytes_start_incl..=bytes_end_incl].to_vec());\n        assert_eq!(body, source);\n    }\n\n    #[tokio::test]\n    async fn read_partial_rejects_out_of_bounds_range() {\n        let svc = ServeDir::new(\"..\");\n        let bytes_start_incl = 0;\n        let bytes_end_excl = 9999999;\n        let requested_len = bytes_end_excl - bytes_start_incl;\n\n        let req = Request::builder()\n            .uri(\"/README.md\")\n            .header(\n                \"Range\",\n                format!(\"bytes={}-{}\", bytes_start_incl, requested_len - 1),\n            )\n            .body(Body::empty())\n            .unwrap();\n        let res = svc.oneshot(req).await.unwrap();\n\n        assert_eq!(res.status(), StatusCode::RANGE_NOT_SATISFIABLE);\n        let file_contents = std::fs::read(\"../README.md\").unwrap();\n        assert_eq!(\n            res.headers()[\"content-range\"],\n            &format!(\"bytes */{}\", file_contents.len())\n        )\n    }\n\n    #[tokio::test]\n    async fn read_partial_errs_on_garbage_header() {\n        let svc = ServeDir::new(\"..\");\n        let req = Request::builder()\n            .uri(\"/README.md\")\n            .header(\"Range\", \"bad_format\")\n            .body(Body::empty())\n            .unwrap();\n        let res = svc.oneshot(req).await.unwrap();\n        assert_eq!(res.status(), StatusCode::RANGE_NOT_SATISFIABLE);\n        let file_contents = std::fs::read(\"../README.md\").unwrap();\n        assert_eq!(\n            res.headers()[\"content-range\"],\n            &format!(\"bytes */{}\", file_contents.len())\n        )\n    }\n\n    #[tokio::test]\n    async fn read_partial_errs_on_bad_range() {\n        let svc = ServeDir::new(\"..\");\n        let req = Request::builder()\n            .uri(\"/README.md\")\n            .header(\"Range\", \"bytes=-1-15\")\n            .body(Body::empty())\n            .unwrap();\n        let res = svc.oneshot(req).await.unwrap();\n        assert_eq!(res.status(), StatusCode::RANGE_NOT_SATISFIABLE);\n        let file_contents = std::fs::read(\"../README.md\").unwrap();\n        assert_eq!(\n            res.headers()[\"content-range\"],\n            &format!(\"bytes */{}\", file_contents.len())\n        )\n    }\n}\n"
  },
  {
    "project": "hyper",
    "target": 1,
    "commit_id": "d1d2f32a7358c1c7d489ebbb98f4cbfdca9bb573",
    "func": "// `mem::uninitialized` replaced with `mem::MaybeUninit`,\n// can't upgrade yet\n#![allow(deprecated)]\n\nuse std::fmt::{self, Write};\nuse std::mem;\n\n#[cfg(any(test, feature = \"server\", feature = \"ffi\"))]\nuse bytes::Bytes;\nuse bytes::BytesMut;\nuse http::header::{self, Entry, HeaderName, HeaderValue};\n#[cfg(feature = \"server\")]\nuse http::header::ValueIter;\nuse http::{HeaderMap, Method, StatusCode, Version};\n\nuse crate::body::DecodedLength;\n#[cfg(feature = \"server\")]\nuse crate::common::date;\nuse crate::error::Parse;\nuse crate::ext::HeaderCaseMap;\nuse crate::headers;\nuse crate::proto::h1::{\n    Encode, Encoder, Http1Transaction, ParseContext, ParseResult, ParsedMessage,\n};\nuse crate::proto::{BodyLength, MessageHead, RequestHead, RequestLine};\n\nconst MAX_HEADERS: usize = 100;\nconst AVERAGE_HEADER_SIZE: usize = 30; // totally scientific\n\nmacro_rules! header_name {\n    ($bytes:expr) => {{\n        #[cfg(debug_assertions)]\n        {\n            match HeaderName::from_bytes($bytes) {\n                Ok(name) => name,\n                Err(_) => panic!(\n                    \"illegal header name from httparse: {:?}\",\n                    ::bytes::Bytes::copy_from_slice($bytes)\n                ),\n            }\n        }\n\n        #[cfg(not(debug_assertions))]\n        {\n            match HeaderName::from_bytes($bytes) {\n                Ok(name) => name,\n                Err(_) => panic!(\"illegal header name from httparse: {:?}\", $bytes),\n            }\n        }\n    }};\n}\n\nmacro_rules! header_value {\n    ($bytes:expr) => {{\n        #[cfg(debug_assertions)]\n        {\n            let __hvb: ::bytes::Bytes = $bytes;\n            match HeaderValue::from_maybe_shared(__hvb.clone()) {\n                Ok(name) => name,\n                Err(_) => panic!(\"illegal header value from httparse: {:?}\", __hvb),\n            }\n        }\n\n        #[cfg(not(debug_assertions))]\n        {\n            // Unsafe: httparse already validated header value\n            unsafe { HeaderValue::from_maybe_shared_unchecked($bytes) }\n        }\n    }};\n}\n\npub(super) fn parse_headers<T>(\n    bytes: &mut BytesMut,\n    ctx: ParseContext<'_>,\n) -> ParseResult<T::Incoming>\nwhere\n    T: Http1Transaction,\n{\n    // If the buffer is empty, don't bother entering the span, it's just noise.\n    if bytes.is_empty() {\n        return Ok(None);\n    }\n\n    let span = trace_span!(\"parse_headers\");\n    let _s = span.enter();\n    T::parse(bytes, ctx)\n}\n\npub(super) fn encode_headers<T>(\n    enc: Encode<'_, T::Outgoing>,\n    dst: &mut Vec<u8>,\n) -> crate::Result<Encoder>\nwhere\n    T: Http1Transaction,\n{\n    let span = trace_span!(\"encode_headers\");\n    let _s = span.enter();\n    T::encode(enc, dst)\n}\n\n// There are 2 main roles, Client and Server.\n\n#[cfg(feature = \"client\")]\npub(crate) enum Client {}\n\n#[cfg(feature = \"server\")]\npub(crate) enum Server {}\n\n#[cfg(feature = \"server\")]\nimpl Http1Transaction for Server {\n    type Incoming = RequestLine;\n    type Outgoing = StatusCode;\n    const LOG: &'static str = \"{role=server}\";\n\n    fn parse(buf: &mut BytesMut, ctx: ParseContext<'_>) -> ParseResult<RequestLine> {\n        debug_assert!(!buf.is_empty(), \"parse called with empty buf\");\n\n        let mut keep_alive;\n        let is_http_11;\n        let subject;\n        let version;\n        let len;\n        let headers_len;\n\n        // Unsafe: both headers_indices and headers are using uninitialized memory,\n        // but we *never* read any of it until after httparse has assigned\n        // values into it. By not zeroing out the stack memory, this saves\n        // a good ~5% on pipeline benchmarks.\n        let mut headers_indices: [HeaderIndices; MAX_HEADERS] = unsafe { mem::uninitialized() };\n        {\n            let mut headers: [httparse::Header<'_>; MAX_HEADERS] = unsafe { mem::uninitialized() };\n            trace!(\n                \"Request.parse([Header; {}], [u8; {}])\",\n                headers.len(),\n                buf.len()\n            );\n            let mut req = httparse::Request::new(&mut headers);\n            let bytes = buf.as_ref();\n            match req.parse(bytes) {\n                Ok(httparse::Status::Complete(parsed_len)) => {\n                    trace!(\"Request.parse Complete({})\", parsed_len);\n                    len = parsed_len;\n                    subject = RequestLine(\n                        Method::from_bytes(req.method.unwrap().as_bytes())?,\n                        req.path.unwrap().parse()?,\n                    );\n                    version = if req.version.unwrap() == 1 {\n                        keep_alive = true;\n                        is_http_11 = true;\n                        Version::HTTP_11\n                    } else {\n                        keep_alive = false;\n                        is_http_11 = false;\n                        Version::HTTP_10\n                    };\n                    trace!(\"headers: {:?}\", &req.headers);\n\n                    record_header_indices(bytes, &req.headers, &mut headers_indices)?;\n                    headers_len = req.headers.len();\n                }\n                Ok(httparse::Status::Partial) => return Ok(None),\n                Err(err) => {\n                    return Err(match err {\n                        // if invalid Token, try to determine if for method or path\n                        httparse::Error::Token => {\n                            if req.method.is_none() {\n                                Parse::Method\n                            } else {\n                                debug_assert!(req.path.is_none());\n                                Parse::Uri\n                            }\n                        }\n                        other => other.into(),\n                    });\n                }\n            }\n        };\n\n        let slice = buf.split_to(len).freeze();\n\n        // According to https://tools.ietf.org/html/rfc7230#section-3.3.3\n        // 1. (irrelevant to Request)\n        // 2. (irrelevant to Request)\n        // 3. Transfer-Encoding: chunked has a chunked body.\n        // 4. If multiple differing Content-Length headers or invalid, close connection.\n        // 5. Content-Length header has a sized body.\n        // 6. Length 0.\n        // 7. (irrelevant to Request)\n\n        let mut decoder = DecodedLength::ZERO;\n        let mut expect_continue = false;\n        let mut con_len = None;\n        let mut is_te = false;\n        let mut is_te_chunked = false;\n        let mut wants_upgrade = subject.0 == Method::CONNECT;\n\n        let mut header_case_map = if ctx.preserve_header_case {\n            Some(HeaderCaseMap::default())\n        } else {\n            None\n        };\n\n        let mut headers = ctx.cached_headers.take().unwrap_or_else(HeaderMap::new);\n\n        headers.reserve(headers_len);\n\n        for header in &headers_indices[..headers_len] {\n            let name = header_name!(&slice[header.name.0..header.name.1]);\n            let value = header_value!(slice.slice(header.value.0..header.value.1));\n\n            match name {\n                header::TRANSFER_ENCODING => {\n                    // https://tools.ietf.org/html/rfc7230#section-3.3.3\n                    // If Transfer-Encoding header is present, and 'chunked' is\n                    // not the final encoding, and this is a Request, then it is\n                    // malformed. A server should respond with 400 Bad Request.\n                    if !is_http_11 {\n                        debug!(\"HTTP/1.0 cannot have Transfer-Encoding header\");\n                        return Err(Parse::Header);\n                    }\n                    is_te = true;\n                    if headers::is_chunked_(&value) {\n                        is_te_chunked = true;\n                        decoder = DecodedLength::CHUNKED;\n                    } else {\n                        is_te_chunked = false;\n                    }\n                }\n                header::CONTENT_LENGTH => {\n                    if is_te {\n                        continue;\n                    }\n                    let len = value\n                        .to_str()\n                        .map_err(|_| Parse::Header)\n                        .and_then(|s| s.parse().map_err(|_| Parse::Header))?;\n                    if let Some(prev) = con_len {\n                        if prev != len {\n                            debug!(\n                                \"multiple Content-Length headers with different values: [{}, {}]\",\n                                prev, len,\n                            );\n                            return Err(Parse::Header);\n                        }\n                        // we don't need to append this secondary length\n                        continue;\n                    }\n                    decoder = DecodedLength::checked_new(len)?;\n                    con_len = Some(len);\n                }\n                header::CONNECTION => {\n                    // keep_alive was previously set to default for Version\n                    if keep_alive {\n                        // HTTP/1.1\n                        keep_alive = !headers::connection_close(&value);\n                    } else {\n                        // HTTP/1.0\n                        keep_alive = headers::connection_keep_alive(&value);\n                    }\n                }\n                header::EXPECT => {\n                    expect_continue = value.as_bytes() == b\"100-continue\";\n                }\n                header::UPGRADE => {\n                    // Upgrades are only allowed with HTTP/1.1\n                    wants_upgrade = is_http_11;\n                }\n\n                _ => (),\n            }\n\n            if let Some(ref mut header_case_map) = header_case_map {\n                header_case_map.append(&name, slice.slice(header.name.0..header.name.1));\n            }\n\n            headers.append(name, value);\n        }\n\n        if is_te && !is_te_chunked {\n            debug!(\"request with transfer-encoding header, but not chunked, bad request\");\n            return Err(Parse::Header);\n        }\n\n        let mut extensions = http::Extensions::default();\n\n        if let Some(header_case_map) = header_case_map {\n            extensions.insert(header_case_map);\n        }\n\n        *ctx.req_method = Some(subject.0.clone());\n\n        Ok(Some(ParsedMessage {\n            head: MessageHead {\n                version,\n                subject,\n                headers,\n                extensions,\n            },\n            decode: decoder,\n            expect_continue,\n            keep_alive,\n            wants_upgrade,\n        }))\n    }\n\n    fn encode(mut msg: Encode<'_, Self::Outgoing>, dst: &mut Vec<u8>) -> crate::Result<Encoder> {\n        trace!(\n            \"Server::encode status={:?}, body={:?}, req_method={:?}\",\n            msg.head.subject,\n            msg.body,\n            msg.req_method\n        );\n\n        let mut wrote_len = false;\n\n        // hyper currently doesn't support returning 1xx status codes as a Response\n        // This is because Service only allows returning a single Response, and\n        // so if you try to reply with a e.g. 100 Continue, you have no way of\n        // replying with the latter status code response.\n        let (ret, is_last) = if msg.head.subject == StatusCode::SWITCHING_PROTOCOLS {\n            (Ok(()), true)\n        } else if msg.req_method == &Some(Method::CONNECT) && msg.head.subject.is_success() {\n            // Sending content-length or transfer-encoding header on 2xx response\n            // to CONNECT is forbidden in RFC 7231.\n            wrote_len = true;\n            (Ok(()), true)\n        } else if msg.head.subject.is_informational() {\n            warn!(\"response with 1xx status code not supported\");\n            *msg.head = MessageHead::default();\n            msg.head.subject = StatusCode::INTERNAL_SERVER_ERROR;\n            msg.body = None;\n            (Err(crate::Error::new_user_unsupported_status_code()), true)\n        } else {\n            (Ok(()), !msg.keep_alive)\n        };\n\n        // In some error cases, we don't know about the invalid message until already\n        // pushing some bytes onto the `dst`. In those cases, we don't want to send\n        // the half-pushed message, so rewind to before.\n        let orig_len = dst.len();\n\n        let init_cap = 30 + msg.head.headers.len() * AVERAGE_HEADER_SIZE;\n        dst.reserve(init_cap);\n        if msg.head.version == Version::HTTP_11 && msg.head.subject == StatusCode::OK {\n            extend(dst, b\"HTTP/1.1 200 OK\\r\\n\");\n        } else {\n            match msg.head.version {\n                Version::HTTP_10 => extend(dst, b\"HTTP/1.0 \"),\n                Version::HTTP_11 => extend(dst, b\"HTTP/1.1 \"),\n                Version::HTTP_2 => {\n                    debug!(\"response with HTTP2 version coerced to HTTP/1.1\");\n                    extend(dst, b\"HTTP/1.1 \");\n                }\n                other => panic!(\"unexpected response version: {:?}\", other),\n            }\n\n            extend(dst, msg.head.subject.as_str().as_bytes());\n            extend(dst, b\" \");\n            // a reason MUST be written, as many parsers will expect it.\n            extend(\n                dst,\n                msg.head\n                    .subject\n                    .canonical_reason()\n                    .unwrap_or(\"<none>\")\n                    .as_bytes(),\n            );\n            extend(dst, b\"\\r\\n\");\n        }\n\n        let orig_headers;\n        let extensions = mem::take(&mut msg.head.extensions);\n        let orig_headers = match extensions.get::<HeaderCaseMap>() {\n            None if msg.title_case_headers => {\n                orig_headers = HeaderCaseMap::default();\n                Some(&orig_headers)\n            }\n            orig_headers => orig_headers,\n        };\n        let encoder = if let Some(orig_headers) = orig_headers {\n            Self::encode_headers_with_original_case(\n                msg,\n                dst,\n                is_last,\n                orig_len,\n                wrote_len,\n                orig_headers,\n            )?\n        } else {\n            Self::encode_headers_with_lower_case(msg, dst, is_last, orig_len, wrote_len)?\n        };\n\n        ret.map(|()| encoder)\n    }\n\n    fn on_error(err: &crate::Error) -> Option<MessageHead<Self::Outgoing>> {\n        use crate::error::Kind;\n        let status = match *err.kind() {\n            Kind::Parse(Parse::Method)\n            | Kind::Parse(Parse::Header)\n            | Kind::Parse(Parse::Uri)\n            | Kind::Parse(Parse::Version) => StatusCode::BAD_REQUEST,\n            Kind::Parse(Parse::TooLarge) => StatusCode::REQUEST_HEADER_FIELDS_TOO_LARGE,\n            _ => return None,\n        };\n\n        debug!(\"sending automatic response ({}) for parse error\", status);\n        let mut msg = MessageHead::default();\n        msg.subject = status;\n        Some(msg)\n    }\n\n    fn is_server() -> bool {\n        true\n    }\n\n    fn update_date() {\n        date::update();\n    }\n}\n\n#[cfg(feature = \"server\")]\nimpl Server {\n    fn can_have_body(method: &Option<Method>, status: StatusCode) -> bool {\n        Server::can_chunked(method, status)\n    }\n\n    fn can_chunked(method: &Option<Method>, status: StatusCode) -> bool {\n        if method == &Some(Method::HEAD) || method == &Some(Method::CONNECT) && status.is_success()\n        {\n            false\n        } else if status.is_informational() {\n            false\n        } else {\n            match status {\n                StatusCode::NO_CONTENT | StatusCode::NOT_MODIFIED => false,\n                _ => true,\n            }\n        }\n    }\n\n    fn can_have_content_length(method: &Option<Method>, status: StatusCode) -> bool {\n        if status.is_informational() || method == &Some(Method::CONNECT) && status.is_success() {\n            false\n        } else {\n            match status {\n                StatusCode::NO_CONTENT | StatusCode::NOT_MODIFIED => false,\n                _ => true,\n            }\n        }\n    }\n\n    fn encode_headers_with_lower_case(\n        msg: Encode<'_, StatusCode>,\n        dst: &mut Vec<u8>,\n        is_last: bool,\n        orig_len: usize,\n        wrote_len: bool,\n    ) -> crate::Result<Encoder> {\n        struct LowercaseWriter;\n\n        impl HeaderNameWriter for LowercaseWriter {\n            #[inline]\n            fn write_full_header_line(\n                &mut self,\n                dst: &mut Vec<u8>,\n                line: &str,\n                _: (HeaderName, &str),\n            ) {\n                extend(dst, line.as_bytes())\n            }\n\n            #[inline]\n            fn write_header_name_with_colon(\n                &mut self,\n                dst: &mut Vec<u8>,\n                name_with_colon: &str,\n                _: HeaderName,\n            ) {\n                extend(dst, name_with_colon.as_bytes())\n            }\n\n            #[inline]\n            fn write_header_name(&mut self, dst: &mut Vec<u8>, name: &HeaderName) {\n                extend(dst, name.as_str().as_bytes())\n            }\n        }\n\n        Self::encode_headers(msg, dst, is_last, orig_len, wrote_len, LowercaseWriter)\n    }\n\n    #[cold]\n    #[inline(never)]\n    fn encode_headers_with_original_case(\n        msg: Encode<'_, StatusCode>,\n        dst: &mut Vec<u8>,\n        is_last: bool,\n        orig_len: usize,\n        wrote_len: bool,\n        orig_headers: &HeaderCaseMap,\n    ) -> crate::Result<Encoder> {\n        struct OrigCaseWriter<'map> {\n            map: &'map HeaderCaseMap,\n            current: Option<(HeaderName, ValueIter<'map, Bytes>)>,\n            title_case_headers: bool,\n        }\n\n        impl HeaderNameWriter for OrigCaseWriter<'_> {\n            #[inline]\n            fn write_full_header_line(\n                &mut self,\n                dst: &mut Vec<u8>,\n                _: &str,\n                (name, rest): (HeaderName, &str),\n            ) {\n                self.write_header_name(dst, &name);\n                extend(dst, rest.as_bytes());\n            }\n\n            #[inline]\n            fn write_header_name_with_colon(\n                &mut self,\n                dst: &mut Vec<u8>,\n                _: &str,\n                name: HeaderName,\n            ) {\n                self.write_header_name(dst, &name);\n                extend(dst, b\": \");\n            }\n\n            #[inline]\n            fn write_header_name(&mut self, dst: &mut Vec<u8>, name: &HeaderName) {\n                let Self {\n                    map,\n                    ref mut current,\n                    title_case_headers,\n                } = *self;\n                if current.as_ref().map_or(true, |(last, _)| last != name) {\n                    *current = None;\n                }\n                let (_, values) =\n                    current.get_or_insert_with(|| (name.clone(), map.get_all_internal(name)));\n\n                if let Some(orig_name) = values.next() {\n                    extend(dst, orig_name);\n                } else if title_case_headers {\n                    title_case(dst, name.as_str().as_bytes());\n                } else {\n                    extend(dst, name.as_str().as_bytes());\n                }\n            }\n        }\n\n        let header_name_writer = OrigCaseWriter {\n            map: orig_headers,\n            current: None,\n            title_case_headers: msg.title_case_headers,\n        };\n\n        Self::encode_headers(msg, dst, is_last, orig_len, wrote_len, header_name_writer)\n    }\n\n    #[inline]\n    fn encode_headers<W>(\n        msg: Encode<'_, StatusCode>,\n        mut dst: &mut Vec<u8>,\n        mut is_last: bool,\n        orig_len: usize,\n        mut wrote_len: bool,\n        mut header_name_writer: W,\n    ) -> crate::Result<Encoder>\n    where\n        W: HeaderNameWriter,\n    {\n        // In some error cases, we don't know about the invalid message until already\n        // pushing some bytes onto the `dst`. In those cases, we don't want to send\n        // the half-pushed message, so rewind to before.\n        let rewind = |dst: &mut Vec<u8>| {\n            dst.truncate(orig_len);\n        };\n\n        let mut encoder = Encoder::length(0);\n        let mut wrote_date = false;\n        let mut cur_name = None;\n        let mut is_name_written = false;\n        let mut must_write_chunked = false;\n        let mut prev_con_len = None;\n\n        macro_rules! handle_is_name_written {\n            () => {{\n                if is_name_written {\n                    // we need to clean up and write the newline\n                    debug_assert_ne!(\n                        &dst[dst.len() - 2..],\n                        b\"\\r\\n\",\n                        \"previous header wrote newline but set is_name_written\"\n                    );\n\n                    if must_write_chunked {\n                        extend(dst, b\", chunked\\r\\n\");\n                    } else {\n                        extend(dst, b\"\\r\\n\");\n                    }\n                }\n            }};\n        }\n\n        'headers: for (opt_name, value) in msg.head.headers.drain() {\n            if let Some(n) = opt_name {\n                cur_name = Some(n);\n                handle_is_name_written!();\n                is_name_written = false;\n            }\n            let name = cur_name.as_ref().expect(\"current header name\");\n            match *name {\n                header::CONTENT_LENGTH => {\n                    if wrote_len && !is_name_written {\n                        warn!(\"unexpected content-length found, canceling\");\n                        rewind(dst);\n                        return Err(crate::Error::new_user_header());\n                    }\n                    match msg.body {\n                        Some(BodyLength::Known(known_len)) => {\n                            // The HttpBody claims to know a length, and\n                            // the headers are already set. For performance\n                            // reasons, we are just going to trust that\n                            // the values match.\n                            //\n                            // In debug builds, we'll assert they are the\n                            // same to help developers find bugs.\n                            #[cfg(debug_assertions)]\n                            {\n                                if let Some(len) = headers::content_length_parse(&value) {\n                                    assert!(\n                                        len == known_len,\n                                        \"payload claims content-length of {}, custom content-length header claims {}\",\n                                        known_len,\n                                        len,\n                                    );\n                                }\n                            }\n\n                            if !is_name_written {\n                                encoder = Encoder::length(known_len);\n                                header_name_writer.write_header_name_with_colon(\n                                    dst,\n                                    \"content-length: \",\n                                    header::CONTENT_LENGTH,\n                                );\n                                extend(dst, value.as_bytes());\n                                wrote_len = true;\n                                is_name_written = true;\n                            }\n                            continue 'headers;\n                        }\n                        Some(BodyLength::Unknown) => {\n                            // The HttpBody impl didn't know how long the\n                            // body is, but a length header was included.\n                            // We have to parse the value to return our\n                            // Encoder...\n\n                            if let Some(len) = headers::content_length_parse(&value) {\n                                if let Some(prev) = prev_con_len {\n                                    if prev != len {\n                                        warn!(\n                                            \"multiple Content-Length values found: [{}, {}]\",\n                                            prev, len\n                                        );\n                                        rewind(dst);\n                                        return Err(crate::Error::new_user_header());\n                                    }\n                                    debug_assert!(is_name_written);\n                                    continue 'headers;\n                                } else {\n                                    // we haven't written content-length yet!\n                                    encoder = Encoder::length(len);\n                                    header_name_writer.write_header_name_with_colon(\n                                        dst,\n                                        \"content-length: \",\n                                        header::CONTENT_LENGTH,\n                                    );\n                                    extend(dst, value.as_bytes());\n                                    wrote_len = true;\n                                    is_name_written = true;\n                                    prev_con_len = Some(len);\n                                    continue 'headers;\n                                }\n                            } else {\n                                warn!(\"illegal Content-Length value: {:?}\", value);\n                                rewind(dst);\n                                return Err(crate::Error::new_user_header());\n                            }\n                        }\n                        None => {\n                            // We have no body to actually send,\n                            // but the headers claim a content-length.\n                            // There's only 2 ways this makes sense:\n                            //\n                            // - The header says the length is `0`.\n                            // - This is a response to a `HEAD` request.\n                            if msg.req_method == &Some(Method::HEAD) {\n                                debug_assert_eq!(encoder, Encoder::length(0));\n                            } else {\n                                if value.as_bytes() != b\"0\" {\n                                    warn!(\n                                        \"content-length value found, but empty body provided: {:?}\",\n                                        value\n                                    );\n                                }\n                                continue 'headers;\n                            }\n                        }\n                    }\n                    wrote_len = true;\n                }\n                header::TRANSFER_ENCODING => {\n                    if wrote_len && !is_name_written {\n                        warn!(\"unexpected transfer-encoding found, canceling\");\n                        rewind(dst);\n                        return Err(crate::Error::new_user_header());\n                    }\n                    // check that we actually can send a chunked body...\n                    if msg.head.version == Version::HTTP_10\n                        || !Server::can_chunked(msg.req_method, msg.head.subject)\n                    {\n                        continue;\n                    }\n                    wrote_len = true;\n                    // Must check each value, because `chunked` needs to be the\n                    // last encoding, or else we add it.\n                    must_write_chunked = !headers::is_chunked_(&value);\n\n                    if !is_name_written {\n                        encoder = Encoder::chunked();\n                        is_name_written = true;\n                        header_name_writer.write_header_name_with_colon(\n                            dst,\n                            \"transfer-encoding: \",\n                            header::TRANSFER_ENCODING,\n                        );\n                        extend(dst, value.as_bytes());\n                    } else {\n                        extend(dst, b\", \");\n                        extend(dst, value.as_bytes());\n                    }\n                    continue 'headers;\n                }\n                header::CONNECTION => {\n                    if !is_last && headers::connection_close(&value) {\n                        is_last = true;\n                    }\n                    if !is_name_written {\n                        is_name_written = true;\n                        header_name_writer.write_header_name_with_colon(\n                            dst,\n                            \"connection: \",\n                            header::CONNECTION,\n                        );\n                        extend(dst, value.as_bytes());\n                    } else {\n                        extend(dst, b\", \");\n                        extend(dst, value.as_bytes());\n                    }\n                    continue 'headers;\n                }\n                header::DATE => {\n                    wrote_date = true;\n                }\n                _ => (),\n            }\n            //TODO: this should perhaps instead combine them into\n            //single lines, as RFC7230 suggests is preferable.\n\n            // non-special write Name and Value\n            debug_assert!(\n                !is_name_written,\n                \"{:?} set is_name_written and didn't continue loop\",\n                name,\n            );\n            header_name_writer.write_header_name(dst, name);\n            extend(dst, b\": \");\n            extend(dst, value.as_bytes());\n            extend(dst, b\"\\r\\n\");\n        }\n\n        handle_is_name_written!();\n\n        if !wrote_len {\n            encoder = match msg.body {\n                Some(BodyLength::Unknown) => {\n                    if msg.head.version == Version::HTTP_10\n                        || !Server::can_chunked(msg.req_method, msg.head.subject)\n                    {\n                        Encoder::close_delimited()\n                    } else {\n                        header_name_writer.write_full_header_line(\n                            dst,\n                            \"transfer-encoding: chunked\\r\\n\",\n                            (header::TRANSFER_ENCODING, \": chunked\\r\\n\"),\n                        );\n                        Encoder::chunked()\n                    }\n                }\n                None | Some(BodyLength::Known(0)) => {\n                    if Server::can_have_content_length(msg.req_method, msg.head.subject) {\n                        header_name_writer.write_full_header_line(\n                            dst,\n                            \"content-length: 0\\r\\n\",\n                            (header::CONTENT_LENGTH, \": 0\\r\\n\"),\n                        )\n                    }\n                    Encoder::length(0)\n                }\n                Some(BodyLength::Known(len)) => {\n                    if !Server::can_have_content_length(msg.req_method, msg.head.subject) {\n                        Encoder::length(0)\n                    } else {\n                        header_name_writer.write_header_name_with_colon(\n                            dst,\n                            \"content-length: \",\n                            header::CONTENT_LENGTH,\n                        );\n                        let _ = ::itoa::write(&mut dst, len);\n                        extend(dst, b\"\\r\\n\");\n                        Encoder::length(len)\n                    }\n                }\n            };\n        }\n\n        if !Server::can_have_body(msg.req_method, msg.head.subject) {\n            trace!(\n                \"server body forced to 0; method={:?}, status={:?}\",\n                msg.req_method,\n                msg.head.subject\n            );\n            encoder = Encoder::length(0);\n        }\n\n        // cached date is much faster than formatting every request\n        if !wrote_date {\n            dst.reserve(date::DATE_VALUE_LENGTH + 8);\n            header_name_writer.write_header_name_with_colon(dst, \"date: \", header::DATE);\n            date::extend(dst);\n            extend(dst, b\"\\r\\n\\r\\n\");\n        } else {\n            extend(dst, b\"\\r\\n\");\n        }\n\n        Ok(encoder.set_last(is_last))\n    }\n}\n\n#[cfg(feature = \"server\")]\ntrait HeaderNameWriter {\n    fn write_full_header_line(\n        &mut self,\n        dst: &mut Vec<u8>,\n        line: &str,\n        name_value_pair: (HeaderName, &str),\n    );\n    fn write_header_name_with_colon(\n        &mut self,\n        dst: &mut Vec<u8>,\n        name_with_colon: &str,\n        name: HeaderName,\n    );\n    fn write_header_name(&mut self, dst: &mut Vec<u8>, name: &HeaderName);\n}\n\n#[cfg(feature = \"client\")]\nimpl Http1Transaction for Client {\n    type Incoming = StatusCode;\n    type Outgoing = RequestLine;\n    const LOG: &'static str = \"{role=client}\";\n\n    fn parse(buf: &mut BytesMut, ctx: ParseContext<'_>) -> ParseResult<StatusCode> {\n        debug_assert!(!buf.is_empty(), \"parse called with empty buf\");\n\n        // Loop to skip information status code headers (100 Continue, etc).\n        loop {\n            // Unsafe: see comment in Server Http1Transaction, above.\n            let mut headers_indices: [HeaderIndices; MAX_HEADERS] = unsafe { mem::uninitialized() };\n            let (len, status, reason, version, headers_len) = {\n                let mut headers: [httparse::Header<'_>; MAX_HEADERS] =\n                    unsafe { mem::uninitialized() };\n                trace!(\n                    \"Response.parse([Header; {}], [u8; {}])\",\n                    headers.len(),\n                    buf.len()\n                );\n                let mut res = httparse::Response::new(&mut headers);\n                let bytes = buf.as_ref();\n                match ctx.h1_parser_config.parse_response(&mut res, bytes)\n                {\n                    Ok(httparse::Status::Complete(len)) => {\n                        trace!(\"Response.parse Complete({})\", len);\n                        let status = StatusCode::from_u16(res.code.unwrap())?;\n\n                        #[cfg(not(feature = \"ffi\"))]\n                        let reason = ();\n                        #[cfg(feature = \"ffi\")]\n                        let reason = {\n                            let reason = res.reason.unwrap();\n                            // Only save the reason phrase if it isnt the canonical reason\n                            if Some(reason) != status.canonical_reason() {\n                                Some(Bytes::copy_from_slice(reason.as_bytes()))\n                            } else {\n                                None\n                            }\n                        };\n\n                        let version = if res.version.unwrap() == 1 {\n                            Version::HTTP_11\n                        } else {\n                            Version::HTTP_10\n                        };\n                        record_header_indices(bytes, &res.headers, &mut headers_indices)?;\n                        let headers_len = res.headers.len();\n                        (len, status, reason, version, headers_len)\n                    }\n                    Ok(httparse::Status::Partial) => return Ok(None),\n                    Err(httparse::Error::Version) if ctx.h09_responses => {\n                        trace!(\"Response.parse accepted HTTP/0.9 response\");\n\n                        #[cfg(not(feature = \"ffi\"))]\n                        let reason = ();\n                        #[cfg(feature = \"ffi\")]\n                        let reason = None;\n\n                        (0, StatusCode::OK, reason, Version::HTTP_09, 0)\n                    }\n                    Err(e) => return Err(e.into()),\n                }\n            };\n\n            let slice = buf.split_to(len).freeze();\n\n            let mut headers = ctx.cached_headers.take().unwrap_or_else(HeaderMap::new);\n\n            let mut keep_alive = version == Version::HTTP_11;\n\n            let mut header_case_map = if ctx.preserve_header_case {\n                Some(HeaderCaseMap::default())\n            } else {\n                None\n            };\n\n            headers.reserve(headers_len);\n            for header in &headers_indices[..headers_len] {\n                let name = header_name!(&slice[header.name.0..header.name.1]);\n                let value = header_value!(slice.slice(header.value.0..header.value.1));\n\n                if let header::CONNECTION = name {\n                    // keep_alive was previously set to default for Version\n                    if keep_alive {\n                        // HTTP/1.1\n                        keep_alive = !headers::connection_close(&value);\n                    } else {\n                        // HTTP/1.0\n                        keep_alive = headers::connection_keep_alive(&value);\n                    }\n                }\n\n                if let Some(ref mut header_case_map) = header_case_map {\n                    header_case_map.append(&name, slice.slice(header.name.0..header.name.1));\n                }\n\n                headers.append(name, value);\n            }\n\n            let mut extensions = http::Extensions::default();\n\n            if let Some(header_case_map) = header_case_map {\n                extensions.insert(header_case_map);\n            }\n\n            #[cfg(feature = \"ffi\")]\n            if let Some(reason) = reason {\n                extensions.insert(crate::ffi::ReasonPhrase(reason));\n            }\n            #[cfg(not(feature = \"ffi\"))]\n            drop(reason);\n\n            let head = MessageHead {\n                version,\n                subject: status,\n                headers,\n                extensions,\n            };\n            if let Some((decode, is_upgrade)) = Client::decoder(&head, ctx.req_method)? {\n                return Ok(Some(ParsedMessage {\n                    head,\n                    decode,\n                    expect_continue: false,\n                    // a client upgrade means the connection can't be used\n                    // again, as it is definitely upgrading.\n                    keep_alive: keep_alive && !is_upgrade,\n                    wants_upgrade: is_upgrade,\n                }));\n            }\n\n            // Parsing a 1xx response could have consumed the buffer, check if\n            // it is empty now...\n            if buf.is_empty() {\n                return Ok(None);\n            }\n        }\n    }\n\n    fn encode(msg: Encode<'_, Self::Outgoing>, dst: &mut Vec<u8>) -> crate::Result<Encoder> {\n        trace!(\n            \"Client::encode method={:?}, body={:?}\",\n            msg.head.subject.0,\n            msg.body\n        );\n\n        *msg.req_method = Some(msg.head.subject.0.clone());\n\n        let body = Client::set_length(msg.head, msg.body);\n\n        let init_cap = 30 + msg.head.headers.len() * AVERAGE_HEADER_SIZE;\n        dst.reserve(init_cap);\n\n        extend(dst, msg.head.subject.0.as_str().as_bytes());\n        extend(dst, b\" \");\n        //TODO: add API to http::Uri to encode without std::fmt\n        let _ = write!(FastWrite(dst), \"{} \", msg.head.subject.1);\n\n        match msg.head.version {\n            Version::HTTP_10 => extend(dst, b\"HTTP/1.0\"),\n            Version::HTTP_11 => extend(dst, b\"HTTP/1.1\"),\n            Version::HTTP_2 => {\n                debug!(\"request with HTTP2 version coerced to HTTP/1.1\");\n                extend(dst, b\"HTTP/1.1\");\n            }\n            other => panic!(\"unexpected request version: {:?}\", other),\n        }\n        extend(dst, b\"\\r\\n\");\n\n        if let Some(orig_headers) = msg.head.extensions.get::<HeaderCaseMap>() {\n            write_headers_original_case(\n                &msg.head.headers,\n                orig_headers,\n                dst,\n                msg.title_case_headers,\n            );\n        } else if msg.title_case_headers {\n            write_headers_title_case(&msg.head.headers, dst);\n        } else {\n            write_headers(&msg.head.headers, dst);\n        }\n\n        extend(dst, b\"\\r\\n\");\n        msg.head.headers.clear(); //TODO: remove when switching to drain()\n\n        Ok(body)\n    }\n\n    fn on_error(_err: &crate::Error) -> Option<MessageHead<Self::Outgoing>> {\n        // we can't tell the server about any errors it creates\n        None\n    }\n\n    fn is_client() -> bool {\n        true\n    }\n}\n\n#[cfg(feature = \"client\")]\nimpl Client {\n    /// Returns Some(length, wants_upgrade) if successful.\n    ///\n    /// Returns None if this message head should be skipped (like a 100 status).\n    fn decoder(\n        inc: &MessageHead<StatusCode>,\n        method: &mut Option<Method>,\n    ) -> Result<Option<(DecodedLength, bool)>, Parse> {\n        // According to https://tools.ietf.org/html/rfc7230#section-3.3.3\n        // 1. HEAD responses, and Status 1xx, 204, and 304 cannot have a body.\n        // 2. Status 2xx to a CONNECT cannot have a body.\n        // 3. Transfer-Encoding: chunked has a chunked body.\n        // 4. If multiple differing Content-Length headers or invalid, close connection.\n        // 5. Content-Length header has a sized body.\n        // 6. (irrelevant to Response)\n        // 7. Read till EOF.\n\n        match inc.subject.as_u16() {\n            101 => {\n                return Ok(Some((DecodedLength::ZERO, true)));\n            }\n            100 | 102..=199 => {\n                trace!(\"ignoring informational response: {}\", inc.subject.as_u16());\n                return Ok(None);\n            }\n            204 | 304 => return Ok(Some((DecodedLength::ZERO, false))),\n            _ => (),\n        }\n        match *method {\n            Some(Method::HEAD) => {\n                return Ok(Some((DecodedLength::ZERO, false)));\n            }\n            Some(Method::CONNECT) => {\n                if let 200..=299 = inc.subject.as_u16() {\n                    return Ok(Some((DecodedLength::ZERO, true)));\n                }\n            }\n            Some(_) => {}\n            None => {\n                trace!(\"Client::decoder is missing the Method\");\n            }\n        }\n\n        if inc.headers.contains_key(header::TRANSFER_ENCODING) {\n            // https://tools.ietf.org/html/rfc7230#section-3.3.3\n            // If Transfer-Encoding header is present, and 'chunked' is\n            // not the final encoding, and this is a Request, then it is\n            // malformed. A server should respond with 400 Bad Request.\n            if inc.version == Version::HTTP_10 {\n                debug!(\"HTTP/1.0 cannot have Transfer-Encoding header\");\n                Err(Parse::Header)\n            } else if headers::transfer_encoding_is_chunked(&inc.headers) {\n                Ok(Some((DecodedLength::CHUNKED, false)))\n            } else {\n                trace!(\"not chunked, read till eof\");\n                Ok(Some((DecodedLength::CLOSE_DELIMITED, false)))\n            }\n        } else if let Some(len) = headers::content_length_parse_all(&inc.headers) {\n            Ok(Some((DecodedLength::checked_new(len)?, false)))\n        } else if inc.headers.contains_key(header::CONTENT_LENGTH) {\n            debug!(\"illegal Content-Length header\");\n            Err(Parse::Header)\n        } else {\n            trace!(\"neither Transfer-Encoding nor Content-Length\");\n            Ok(Some((DecodedLength::CLOSE_DELIMITED, false)))\n        }\n    }\n    fn set_length(head: &mut RequestHead, body: Option<BodyLength>) -> Encoder {\n        let body = if let Some(body) = body {\n            body\n        } else {\n            head.headers.remove(header::TRANSFER_ENCODING);\n            return Encoder::length(0);\n        };\n\n        // HTTP/1.0 doesn't know about chunked\n        let can_chunked = head.version == Version::HTTP_11;\n        let headers = &mut head.headers;\n\n        // If the user already set specific headers, we should respect them, regardless\n        // of what the HttpBody knows about itself. They set them for a reason.\n\n        // Because of the borrow checker, we can't check the for an existing\n        // Content-Length header while holding an `Entry` for the Transfer-Encoding\n        // header, so unfortunately, we must do the check here, first.\n\n        let existing_con_len = headers::content_length_parse_all(headers);\n        let mut should_remove_con_len = false;\n\n        if !can_chunked {\n            // Chunked isn't legal, so if it is set, we need to remove it.\n            if headers.remove(header::TRANSFER_ENCODING).is_some() {\n                trace!(\"removing illegal transfer-encoding header\");\n            }\n\n            return if let Some(len) = existing_con_len {\n                Encoder::length(len)\n            } else if let BodyLength::Known(len) = body {\n                set_content_length(headers, len)\n            } else {\n                // HTTP/1.0 client requests without a content-length\n                // cannot have any body at all.\n                Encoder::length(0)\n            };\n        }\n\n        // If the user set a transfer-encoding, respect that. Let's just\n        // make sure `chunked` is the final encoding.\n        let encoder = match headers.entry(header::TRANSFER_ENCODING) {\n            Entry::Occupied(te) => {\n                should_remove_con_len = true;\n                if headers::is_chunked(te.iter()) {\n                    Some(Encoder::chunked())\n                } else {\n                    warn!(\"user provided transfer-encoding does not end in 'chunked'\");\n\n                    // There's a Transfer-Encoding, but it doesn't end in 'chunked'!\n                    // An example that could trigger this:\n                    //\n                    //     Transfer-Encoding: gzip\n                    //\n                    // This can be bad, depending on if this is a request or a\n                    // response.\n                    //\n                    // - A request is illegal if there is a `Transfer-Encoding`\n                    //   but it doesn't end in `chunked`.\n                    // - A response that has `Transfer-Encoding` but doesn't\n                    //   end in `chunked` isn't illegal, it just forces this\n                    //   to be close-delimited.\n                    //\n                    // We can try to repair this, by adding `chunked` ourselves.\n\n                    headers::add_chunked(te);\n                    Some(Encoder::chunked())\n                }\n            }\n            Entry::Vacant(te) => {\n                if let Some(len) = existing_con_len {\n                    Some(Encoder::length(len))\n                } else if let BodyLength::Unknown = body {\n                    // GET, HEAD, and CONNECT almost never have bodies.\n                    //\n                    // So instead of sending a \"chunked\" body with a 0-chunk,\n                    // assume no body here. If you *must* send a body,\n                    // set the headers explicitly.\n                    match head.subject.0 {\n                        Method::GET | Method::HEAD | Method::CONNECT => Some(Encoder::length(0)),\n                        _ => {\n                            te.insert(HeaderValue::from_static(\"chunked\"));\n                            Some(Encoder::chunked())\n                        }\n                    }\n                } else {\n                    None\n                }\n            }\n        };\n\n        // This is because we need a second mutable borrow to remove\n        // content-length header.\n        if let Some(encoder) = encoder {\n            if should_remove_con_len && existing_con_len.is_some() {\n                headers.remove(header::CONTENT_LENGTH);\n            }\n            return encoder;\n        }\n\n        // User didn't set transfer-encoding, AND we know body length,\n        // so we can just set the Content-Length automatically.\n\n        let len = if let BodyLength::Known(len) = body {\n            len\n        } else {\n            unreachable!(\"BodyLength::Unknown would set chunked\");\n        };\n\n        set_content_length(headers, len)\n    }\n}\n\nfn set_content_length(headers: &mut HeaderMap, len: u64) -> Encoder {\n    // At this point, there should not be a valid Content-Length\n    // header. However, since we'll be indexing in anyways, we can\n    // warn the user if there was an existing illegal header.\n    //\n    // Or at least, we can in theory. It's actually a little bit slower,\n    // so perhaps only do that while the user is developing/testing.\n\n    if cfg!(debug_assertions) {\n        match headers.entry(header::CONTENT_LENGTH) {\n            Entry::Occupied(mut cl) => {\n                // Internal sanity check, we should have already determined\n                // that the header was illegal before calling this function.\n                debug_assert!(headers::content_length_parse_all_values(cl.iter()).is_none());\n                // Uh oh, the user set `Content-Length` headers, but set bad ones.\n                // This would be an illegal message anyways, so let's try to repair\n                // with our known good length.\n                error!(\"user provided content-length header was invalid\");\n\n                cl.insert(HeaderValue::from(len));\n                Encoder::length(len)\n            }\n            Entry::Vacant(cl) => {\n                cl.insert(HeaderValue::from(len));\n                Encoder::length(len)\n            }\n        }\n    } else {\n        headers.insert(header::CONTENT_LENGTH, HeaderValue::from(len));\n        Encoder::length(len)\n    }\n}\n\n#[derive(Clone, Copy)]\nstruct HeaderIndices {\n    name: (usize, usize),\n    value: (usize, usize),\n}\n\nfn record_header_indices(\n    bytes: &[u8],\n    headers: &[httparse::Header<'_>],\n    indices: &mut [HeaderIndices],\n) -> Result<(), crate::error::Parse> {\n    let bytes_ptr = bytes.as_ptr() as usize;\n\n    for (header, indices) in headers.iter().zip(indices.iter_mut()) {\n        if header.name.len() >= (1 << 16) {\n            debug!(\"header name larger than 64kb: {:?}\", header.name);\n            return Err(crate::error::Parse::TooLarge);\n        }\n        let name_start = header.name.as_ptr() as usize - bytes_ptr;\n        let name_end = name_start + header.name.len();\n        indices.name = (name_start, name_end);\n        let value_start = header.value.as_ptr() as usize - bytes_ptr;\n        let value_end = value_start + header.value.len();\n        indices.value = (value_start, value_end);\n    }\n\n    Ok(())\n}\n\n// Write header names as title case. The header name is assumed to be ASCII,\n// therefore it is trivial to convert an ASCII character from lowercase to\n// uppercase. It is as simple as XORing the lowercase character byte with\n// space.\nfn title_case(dst: &mut Vec<u8>, name: &[u8]) {\n    dst.reserve(name.len());\n\n    let mut iter = name.iter();\n\n    // Uppercase the first character\n    if let Some(c) = iter.next() {\n        if *c >= b'a' && *c <= b'z' {\n            dst.push(*c ^ b' ');\n        } else {\n            dst.push(*c);\n        }\n    }\n\n    while let Some(c) = iter.next() {\n        dst.push(*c);\n\n        if *c == b'-' {\n            if let Some(c) = iter.next() {\n                if *c >= b'a' && *c <= b'z' {\n                    dst.push(*c ^ b' ');\n                } else {\n                    dst.push(*c);\n                }\n            }\n        }\n    }\n}\n\nfn write_headers_title_case(headers: &HeaderMap, dst: &mut Vec<u8>) {\n    for (name, value) in headers {\n        title_case(dst, name.as_str().as_bytes());\n        extend(dst, b\": \");\n        extend(dst, value.as_bytes());\n        extend(dst, b\"\\r\\n\");\n    }\n}\n\nfn write_headers(headers: &HeaderMap, dst: &mut Vec<u8>) {\n    for (name, value) in headers {\n        extend(dst, name.as_str().as_bytes());\n        extend(dst, b\": \");\n        extend(dst, value.as_bytes());\n        extend(dst, b\"\\r\\n\");\n    }\n}\n\n#[cold]\nfn write_headers_original_case(\n    headers: &HeaderMap,\n    orig_case: &HeaderCaseMap,\n    dst: &mut Vec<u8>,\n    title_case_headers: bool,\n) {\n    // For each header name/value pair, there may be a value in the casemap\n    // that corresponds to the HeaderValue. So, we iterator all the keys,\n    // and for each one, try to pair the originally cased name with the value.\n    //\n    // TODO: consider adding http::HeaderMap::entries() iterator\n    for name in headers.keys() {\n        let mut names = orig_case.get_all(name);\n\n        for value in headers.get_all(name) {\n            if let Some(orig_name) = names.next() {\n                extend(dst, orig_name.as_ref());\n            } else if title_case_headers {\n                title_case(dst, name.as_str().as_bytes());\n            } else {\n                extend(dst, name.as_str().as_bytes());\n            }\n\n            // Wanted for curl test cases that send `X-Custom-Header:\\r\\n`\n            if value.is_empty() {\n                extend(dst, b\":\\r\\n\");\n            } else {\n                extend(dst, b\": \");\n                extend(dst, value.as_bytes());\n                extend(dst, b\"\\r\\n\");\n            }\n        }\n    }\n}\n\nstruct FastWrite<'a>(&'a mut Vec<u8>);\n\nimpl<'a> fmt::Write for FastWrite<'a> {\n    #[inline]\n    fn write_str(&mut self, s: &str) -> fmt::Result {\n        extend(self.0, s.as_bytes());\n        Ok(())\n    }\n\n    #[inline]\n    fn write_fmt(&mut self, args: fmt::Arguments<'_>) -> fmt::Result {\n        fmt::write(self, args)\n    }\n}\n\n#[inline]\nfn extend(dst: &mut Vec<u8>, data: &[u8]) {\n    dst.extend_from_slice(data);\n}\n\n#[cfg(test)]\nmod tests {\n    use bytes::BytesMut;\n\n    use super::*;\n\n    #[test]\n    fn test_parse_request() {\n        let _ = pretty_env_logger::try_init();\n        let mut raw = BytesMut::from(\"GET /echo HTTP/1.1\\r\\nHost: hyper.rs\\r\\n\\r\\n\");\n        let mut method = None;\n        let msg = Server::parse(\n            &mut raw,\n            ParseContext {\n                cached_headers: &mut None,\n                req_method: &mut method,\n                h1_parser_config: Default::default(),\n                preserve_header_case: false,\n                h09_responses: false,\n            },\n        )\n        .unwrap()\n        .unwrap();\n        assert_eq!(raw.len(), 0);\n        assert_eq!(msg.head.subject.0, crate::Method::GET);\n        assert_eq!(msg.head.subject.1, \"/echo\");\n        assert_eq!(msg.head.version, crate::Version::HTTP_11);\n        assert_eq!(msg.head.headers.len(), 1);\n        assert_eq!(msg.head.headers[\"Host\"], \"hyper.rs\");\n        assert_eq!(method, Some(crate::Method::GET));\n    }\n\n    #[test]\n    fn test_parse_response() {\n        let _ = pretty_env_logger::try_init();\n        let mut raw = BytesMut::from(\"HTTP/1.1 200 OK\\r\\nContent-Length: 0\\r\\n\\r\\n\");\n        let ctx = ParseContext {\n            cached_headers: &mut None,\n            req_method: &mut Some(crate::Method::GET),\n            h1_parser_config: Default::default(),\n            preserve_header_case: false,\n            h09_responses: false,\n        };\n        let msg = Client::parse(&mut raw, ctx).unwrap().unwrap();\n        assert_eq!(raw.len(), 0);\n        assert_eq!(msg.head.subject, crate::StatusCode::OK);\n        assert_eq!(msg.head.version, crate::Version::HTTP_11);\n        assert_eq!(msg.head.headers.len(), 1);\n        assert_eq!(msg.head.headers[\"Content-Length\"], \"0\");\n    }\n\n    #[test]\n    fn test_parse_request_errors() {\n        let mut raw = BytesMut::from(\"GET htt:p// HTTP/1.1\\r\\nHost: hyper.rs\\r\\n\\r\\n\");\n        let ctx = ParseContext {\n            cached_headers: &mut None,\n            req_method: &mut None,\n            h1_parser_config: Default::default(),\n            preserve_header_case: false,\n            h09_responses: false,\n        };\n        Server::parse(&mut raw, ctx).unwrap_err();\n    }\n\n    const H09_RESPONSE: &'static str = \"Baguettes are super delicious, don't you agree?\";\n\n    #[test]\n    fn test_parse_response_h09_allowed() {\n        let _ = pretty_env_logger::try_init();\n        let mut raw = BytesMut::from(H09_RESPONSE);\n        let ctx = ParseContext {\n            cached_headers: &mut None,\n            req_method: &mut Some(crate::Method::GET),\n            h1_parser_config: Default::default(),\n            preserve_header_case: false,\n            h09_responses: true,\n        };\n        let msg = Client::parse(&mut raw, ctx).unwrap().unwrap();\n        assert_eq!(raw, H09_RESPONSE);\n        assert_eq!(msg.head.subject, crate::StatusCode::OK);\n        assert_eq!(msg.head.version, crate::Version::HTTP_09);\n        assert_eq!(msg.head.headers.len(), 0);\n    }\n\n    #[test]\n    fn test_parse_response_h09_rejected() {\n        let _ = pretty_env_logger::try_init();\n        let mut raw = BytesMut::from(H09_RESPONSE);\n        let ctx = ParseContext {\n            cached_headers: &mut None,\n            req_method: &mut Some(crate::Method::GET),\n            h1_parser_config: Default::default(),\n            preserve_header_case: false,\n            h09_responses: false,\n        };\n        Client::parse(&mut raw, ctx).unwrap_err();\n        assert_eq!(raw, H09_RESPONSE);\n    }\n\n    const RESPONSE_WITH_WHITESPACE_BETWEEN_HEADER_NAME_AND_COLON: &'static str =\n        \"HTTP/1.1 200 OK\\r\\nAccess-Control-Allow-Credentials : true\\r\\n\\r\\n\";\n\n    #[test]\n    fn test_parse_allow_response_with_spaces_before_colons() {\n        use httparse::ParserConfig;\n\n        let _ = pretty_env_logger::try_init();\n        let mut raw = BytesMut::from(RESPONSE_WITH_WHITESPACE_BETWEEN_HEADER_NAME_AND_COLON);\n        let mut h1_parser_config = ParserConfig::default();\n        h1_parser_config.allow_spaces_after_header_name_in_responses(true);\n        let ctx = ParseContext {\n            cached_headers: &mut None,\n            req_method: &mut Some(crate::Method::GET),\n            h1_parser_config,\n            preserve_header_case: false,\n            h09_responses: false,\n        };\n        let msg = Client::parse(&mut raw, ctx).unwrap().unwrap();\n        assert_eq!(raw.len(), 0);\n        assert_eq!(msg.head.subject, crate::StatusCode::OK);\n        assert_eq!(msg.head.version, crate::Version::HTTP_11);\n        assert_eq!(msg.head.headers.len(), 1);\n        assert_eq!(msg.head.headers[\"Access-Control-Allow-Credentials\"], \"true\");\n    }\n\n    #[test]\n    fn test_parse_reject_response_with_spaces_before_colons() {\n        let _ = pretty_env_logger::try_init();\n        let mut raw = BytesMut::from(RESPONSE_WITH_WHITESPACE_BETWEEN_HEADER_NAME_AND_COLON);\n        let ctx = ParseContext {\n            cached_headers: &mut None,\n            req_method: &mut Some(crate::Method::GET),\n            h1_parser_config: Default::default(),\n            preserve_header_case: false,\n            h09_responses: false,\n        };\n        Client::parse(&mut raw, ctx).unwrap_err();\n    }\n\n    #[test]\n    fn test_parse_preserve_header_case_in_request() {\n        let mut raw =\n            BytesMut::from(\"GET / HTTP/1.1\\r\\nHost: hyper.rs\\r\\nX-BREAD: baguette\\r\\n\\r\\n\");\n        let ctx = ParseContext {\n            cached_headers: &mut None,\n            req_method: &mut None,\n            h1_parser_config: Default::default(),\n            preserve_header_case: true,\n            h09_responses: false,\n        };\n        let parsed_message = Server::parse(&mut raw, ctx).unwrap().unwrap();\n        let orig_headers = parsed_message\n            .head\n            .extensions\n            .get::<HeaderCaseMap>()\n            .unwrap();\n        assert_eq!(\n            orig_headers\n                .get_all_internal(&HeaderName::from_static(\"host\"))\n                .into_iter()\n                .collect::<Vec<_>>(),\n            vec![&Bytes::from(\"Host\")]\n        );\n        assert_eq!(\n            orig_headers\n                .get_all_internal(&HeaderName::from_static(\"x-bread\"))\n                .into_iter()\n                .collect::<Vec<_>>(),\n            vec![&Bytes::from(\"X-BREAD\")]\n        );\n    }\n\n    #[test]\n    fn test_decoder_request() {\n        fn parse(s: &str) -> ParsedMessage<RequestLine> {\n            let mut bytes = BytesMut::from(s);\n            Server::parse(\n                &mut bytes,\n                ParseContext {\n                    cached_headers: &mut None,\n                    req_method: &mut None,\n                    h1_parser_config: Default::default(),\n                    preserve_header_case: false,\n                    h09_responses: false,\n                },\n            )\n            .expect(\"parse ok\")\n            .expect(\"parse complete\")\n        }\n\n        fn parse_err(s: &str, comment: &str) -> crate::error::Parse {\n            let mut bytes = BytesMut::from(s);\n            Server::parse(\n                &mut bytes,\n                ParseContext {\n                    cached_headers: &mut None,\n                    req_method: &mut None,\n                    h1_parser_config: Default::default(),\n                    preserve_header_case: false,\n                    h09_responses: false,\n                },\n            )\n            .expect_err(comment)\n        }\n\n        // no length or transfer-encoding means 0-length body\n        assert_eq!(\n            parse(\n                \"\\\n                 GET / HTTP/1.1\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::ZERO\n        );\n\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::ZERO\n        );\n\n        // transfer-encoding: chunked\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 transfer-encoding: chunked\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 transfer-encoding: gzip, chunked\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 transfer-encoding: gzip\\r\\n\\\n                 transfer-encoding: chunked\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        // content-length\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::new(10)\n        );\n\n        // transfer-encoding and content-length = chunked\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 transfer-encoding: chunked\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 transfer-encoding: chunked\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 transfer-encoding: gzip\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 transfer-encoding: chunked\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        // multiple content-lengths of same value are fine\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::new(10)\n        );\n\n        // multiple content-lengths with different values is an error\n        parse_err(\n            \"\\\n             POST / HTTP/1.1\\r\\n\\\n             content-length: 10\\r\\n\\\n             content-length: 11\\r\\n\\\n             \\r\\n\\\n             \",\n            \"multiple content-lengths\",\n        );\n\n        // transfer-encoding that isn't chunked is an error\n        parse_err(\n            \"\\\n             POST / HTTP/1.1\\r\\n\\\n             transfer-encoding: gzip\\r\\n\\\n             \\r\\n\\\n             \",\n            \"transfer-encoding but not chunked\",\n        );\n\n        parse_err(\n            \"\\\n             POST / HTTP/1.1\\r\\n\\\n             transfer-encoding: chunked, gzip\\r\\n\\\n             \\r\\n\\\n             \",\n            \"transfer-encoding doesn't end in chunked\",\n        );\n\n        parse_err(\n            \"\\\n             POST / HTTP/1.1\\r\\n\\\n             transfer-encoding: chunked\\r\\n\\\n             transfer-encoding: afterlol\\r\\n\\\n             \\r\\n\\\n             \",\n            \"transfer-encoding multiple lines doesn't end in chunked\",\n        );\n\n        // http/1.0\n\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.0\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::new(10)\n        );\n\n        // 1.0 doesn't understand chunked, so its an error\n        parse_err(\n            \"\\\n             POST / HTTP/1.0\\r\\n\\\n             transfer-encoding: chunked\\r\\n\\\n             \\r\\n\\\n             \",\n            \"1.0 chunked\",\n        );\n    }\n\n    #[test]\n    fn test_decoder_response() {\n        fn parse(s: &str) -> ParsedMessage<StatusCode> {\n            parse_with_method(s, Method::GET)\n        }\n\n        fn parse_ignores(s: &str) {\n            let mut bytes = BytesMut::from(s);\n            assert!(Client::parse(\n                &mut bytes,\n                ParseContext {\n                    cached_headers: &mut None,\n                    req_method: &mut Some(Method::GET),\n                    h1_parser_config: Default::default(),\n                    preserve_header_case: false,\n                    h09_responses: false,\n                }\n            )\n            .expect(\"parse ok\")\n            .is_none())\n        }\n\n        fn parse_with_method(s: &str, m: Method) -> ParsedMessage<StatusCode> {\n            let mut bytes = BytesMut::from(s);\n            Client::parse(\n                &mut bytes,\n                ParseContext {\n                    cached_headers: &mut None,\n                    req_method: &mut Some(m),\n                    h1_parser_config: Default::default(),\n                    preserve_header_case: false,\n                    h09_responses: false,\n                },\n            )\n            .expect(\"parse ok\")\n            .expect(\"parse complete\")\n        }\n\n        fn parse_err(s: &str) -> crate::error::Parse {\n            let mut bytes = BytesMut::from(s);\n            Client::parse(\n                &mut bytes,\n                ParseContext {\n                    cached_headers: &mut None,\n                    req_method: &mut Some(Method::GET),\n                    h1_parser_config: Default::default(),\n                    preserve_header_case: false,\n                    h09_responses: false,\n                },\n            )\n            .expect_err(\"parse should err\")\n        }\n\n        // no content-length or transfer-encoding means close-delimited\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CLOSE_DELIMITED\n        );\n\n        // 204 and 304 never have a body\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 204 No Content\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::ZERO\n        );\n\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 304 Not Modified\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::ZERO\n        );\n\n        // content-length\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 content-length: 8\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::new(8)\n        );\n\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 content-length: 8\\r\\n\\\n                 content-length: 8\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::new(8)\n        );\n\n        parse_err(\n            \"\\\n             HTTP/1.1 200 OK\\r\\n\\\n             content-length: 8\\r\\n\\\n             content-length: 9\\r\\n\\\n             \\r\\n\\\n             \",\n        );\n\n        // transfer-encoding: chunked\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 transfer-encoding: chunked\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        // transfer-encoding not-chunked is close-delimited\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 transfer-encoding: yolo\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CLOSE_DELIMITED\n        );\n\n        // transfer-encoding and content-length = chunked\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 transfer-encoding: chunked\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        // HEAD can have content-length, but not body\n        assert_eq!(\n            parse_with_method(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 content-length: 8\\r\\n\\\n                 \\r\\n\\\n                 \",\n                Method::HEAD\n            )\n            .decode,\n            DecodedLength::ZERO\n        );\n\n        // CONNECT with 200 never has body\n        {\n            let msg = parse_with_method(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 \\r\\n\\\n                 \",\n                Method::CONNECT,\n            );\n            assert_eq!(msg.decode, DecodedLength::ZERO);\n            assert!(!msg.keep_alive, \"should be upgrade\");\n            assert!(msg.wants_upgrade, \"should be upgrade\");\n        }\n\n        // CONNECT receiving non 200 can have a body\n        assert_eq!(\n            parse_with_method(\n                \"\\\n                 HTTP/1.1 400 Bad Request\\r\\n\\\n                 \\r\\n\\\n                 \",\n                Method::CONNECT\n            )\n            .decode,\n            DecodedLength::CLOSE_DELIMITED\n        );\n\n        // 1xx status codes\n        parse_ignores(\n            \"\\\n             HTTP/1.1 100 Continue\\r\\n\\\n             \\r\\n\\\n             \",\n        );\n\n        parse_ignores(\n            \"\\\n             HTTP/1.1 103 Early Hints\\r\\n\\\n             \\r\\n\\\n             \",\n        );\n\n        // 101 upgrade not supported yet\n        {\n            let msg = parse(\n                \"\\\n                 HTTP/1.1 101 Switching Protocols\\r\\n\\\n                 \\r\\n\\\n                 \",\n            );\n            assert_eq!(msg.decode, DecodedLength::ZERO);\n            assert!(!msg.keep_alive, \"should be last\");\n            assert!(msg.wants_upgrade, \"should be upgrade\");\n        }\n\n        // http/1.0\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.0 200 OK\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CLOSE_DELIMITED\n        );\n\n        // 1.0 doesn't understand chunked\n        parse_err(\n            \"\\\n             HTTP/1.0 200 OK\\r\\n\\\n             transfer-encoding: chunked\\r\\n\\\n             \\r\\n\\\n             \",\n        );\n\n        // keep-alive\n        assert!(\n            parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 content-length: 0\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .keep_alive,\n            \"HTTP/1.1 keep-alive is default\"\n        );\n\n        assert!(\n            !parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 content-length: 0\\r\\n\\\n                 connection: foo, close, bar\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .keep_alive,\n            \"connection close is always close\"\n        );\n\n        assert!(\n            !parse(\n                \"\\\n                 HTTP/1.0 200 OK\\r\\n\\\n                 content-length: 0\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .keep_alive,\n            \"HTTP/1.0 close is default\"\n        );\n\n        assert!(\n            parse(\n                \"\\\n                 HTTP/1.0 200 OK\\r\\n\\\n                 content-length: 0\\r\\n\\\n                 connection: foo, keep-alive, bar\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .keep_alive,\n            \"connection keep-alive is always keep-alive\"\n        );\n    }\n\n    #[test]\n    fn test_client_request_encode_title_case() {\n        use crate::proto::BodyLength;\n        use http::header::HeaderValue;\n\n        let mut head = MessageHead::default();\n        head.headers\n            .insert(\"content-length\", HeaderValue::from_static(\"10\"));\n        head.headers\n            .insert(\"content-type\", HeaderValue::from_static(\"application/json\"));\n        head.headers.insert(\"*-*\", HeaderValue::from_static(\"o_o\"));\n\n        let mut vec = Vec::new();\n        Client::encode(\n            Encode {\n                head: &mut head,\n                body: Some(BodyLength::Known(10)),\n                keep_alive: true,\n                req_method: &mut None,\n                title_case_headers: true,\n            },\n            &mut vec,\n        )\n        .unwrap();\n\n        assert_eq!(vec, b\"GET / HTTP/1.1\\r\\nContent-Length: 10\\r\\nContent-Type: application/json\\r\\n*-*: o_o\\r\\n\\r\\n\".to_vec());\n    }\n\n    #[test]\n    fn test_client_request_encode_orig_case() {\n        use crate::proto::BodyLength;\n        use http::header::{HeaderValue, CONTENT_LENGTH};\n\n        let mut head = MessageHead::default();\n        head.headers\n            .insert(\"content-length\", HeaderValue::from_static(\"10\"));\n        head.headers\n            .insert(\"content-type\", HeaderValue::from_static(\"application/json\"));\n\n        let mut orig_headers = HeaderCaseMap::default();\n        orig_headers.insert(CONTENT_LENGTH, \"CONTENT-LENGTH\".into());\n        head.extensions.insert(orig_headers);\n\n        let mut vec = Vec::new();\n        Client::encode(\n            Encode {\n                head: &mut head,\n                body: Some(BodyLength::Known(10)),\n                keep_alive: true,\n                req_method: &mut None,\n                title_case_headers: false,\n            },\n            &mut vec,\n        )\n        .unwrap();\n\n        assert_eq!(\n            &*vec,\n            b\"GET / HTTP/1.1\\r\\nCONTENT-LENGTH: 10\\r\\ncontent-type: application/json\\r\\n\\r\\n\"\n                .as_ref(),\n        );\n    }\n    #[test]\n    fn test_client_request_encode_orig_and_title_case() {\n        use crate::proto::BodyLength;\n        use http::header::{HeaderValue, CONTENT_LENGTH};\n\n        let mut head = MessageHead::default();\n        head.headers\n            .insert(\"content-length\", HeaderValue::from_static(\"10\"));\n        head.headers\n            .insert(\"content-type\", HeaderValue::from_static(\"application/json\"));\n\n        let mut orig_headers = HeaderCaseMap::default();\n        orig_headers.insert(CONTENT_LENGTH, \"CONTENT-LENGTH\".into());\n        head.extensions.insert(orig_headers);\n\n        let mut vec = Vec::new();\n        Client::encode(\n            Encode {\n                head: &mut head,\n                body: Some(BodyLength::Known(10)),\n                keep_alive: true,\n                req_method: &mut None,\n                title_case_headers: true,\n            },\n            &mut vec,\n        )\n        .unwrap();\n\n        assert_eq!(\n            &*vec,\n            b\"GET / HTTP/1.1\\r\\nCONTENT-LENGTH: 10\\r\\nContent-Type: application/json\\r\\n\\r\\n\"\n                .as_ref(),\n        );\n    }\n\n    #[test]\n    fn test_server_encode_connect_method() {\n        let mut head = MessageHead::default();\n\n        let mut vec = Vec::new();\n        let encoder = Server::encode(\n            Encode {\n                head: &mut head,\n                body: None,\n                keep_alive: true,\n                req_method: &mut Some(Method::CONNECT),\n                title_case_headers: false,\n            },\n            &mut vec,\n        )\n        .unwrap();\n\n        assert!(encoder.is_last());\n    }\n\n    #[test]\n    fn test_server_response_encode_title_case() {\n        use crate::proto::BodyLength;\n        use http::header::HeaderValue;\n\n        let mut head = MessageHead::default();\n        head.headers\n            .insert(\"content-length\", HeaderValue::from_static(\"10\"));\n        head.headers\n            .insert(\"content-type\", HeaderValue::from_static(\"application/json\"));\n\n        let mut vec = Vec::new();\n        Server::encode(\n            Encode {\n                head: &mut head,\n                body: Some(BodyLength::Known(10)),\n                keep_alive: true,\n                req_method: &mut None,\n                title_case_headers: true,\n            },\n            &mut vec,\n        )\n        .unwrap();\n\n        let expected_response =\n            b\"HTTP/1.1 200 OK\\r\\nContent-Length: 10\\r\\nContent-Type: application/json\\r\\n\";\n\n        assert_eq!(&vec[..expected_response.len()], &expected_response[..]);\n    }\n\n    #[test]\n    fn test_server_response_encode_orig_case() {\n        use crate::proto::BodyLength;\n        use http::header::{HeaderValue, CONTENT_LENGTH};\n\n        let mut head = MessageHead::default();\n        head.headers\n            .insert(\"content-length\", HeaderValue::from_static(\"10\"));\n        head.headers\n            .insert(\"content-type\", HeaderValue::from_static(\"application/json\"));\n\n        let mut orig_headers = HeaderCaseMap::default();\n        orig_headers.insert(CONTENT_LENGTH, \"CONTENT-LENGTH\".into());\n        head.extensions.insert(orig_headers);\n\n        let mut vec = Vec::new();\n        Server::encode(\n            Encode {\n                head: &mut head,\n                body: Some(BodyLength::Known(10)),\n                keep_alive: true,\n                req_method: &mut None,\n                title_case_headers: false,\n            },\n            &mut vec,\n        )\n        .unwrap();\n\n        let expected_response =\n            b\"HTTP/1.1 200 OK\\r\\nCONTENT-LENGTH: 10\\r\\ncontent-type: application/json\\r\\ndate: \";\n\n        assert_eq!(&vec[..expected_response.len()], &expected_response[..]);\n    }\n\n    #[test]\n    fn test_server_response_encode_orig_and_title_case() {\n        use crate::proto::BodyLength;\n        use http::header::{HeaderValue, CONTENT_LENGTH};\n\n        let mut head = MessageHead::default();\n        head.headers\n            .insert(\"content-length\", HeaderValue::from_static(\"10\"));\n        head.headers\n            .insert(\"content-type\", HeaderValue::from_static(\"application/json\"));\n\n        let mut orig_headers = HeaderCaseMap::default();\n        orig_headers.insert(CONTENT_LENGTH, \"CONTENT-LENGTH\".into());\n        head.extensions.insert(orig_headers);\n\n        let mut vec = Vec::new();\n        Server::encode(\n            Encode {\n                head: &mut head,\n                body: Some(BodyLength::Known(10)),\n                keep_alive: true,\n                req_method: &mut None,\n                title_case_headers: true,\n            },\n            &mut vec,\n        )\n        .unwrap();\n\n        let expected_response =\n            b\"HTTP/1.1 200 OK\\r\\nCONTENT-LENGTH: 10\\r\\nContent-Type: application/json\\r\\nDate: \";\n\n        assert_eq!(&vec[..expected_response.len()], &expected_response[..]);\n    }\n\n    #[test]\n    fn parse_header_htabs() {\n        let mut bytes = BytesMut::from(\"HTTP/1.1 200 OK\\r\\nserver: hello\\tworld\\r\\n\\r\\n\");\n        let parsed = Client::parse(\n            &mut bytes,\n            ParseContext {\n                cached_headers: &mut None,\n                req_method: &mut Some(Method::GET),\n                h1_parser_config: Default::default(),\n                preserve_header_case: false,\n                h09_responses: false,\n            },\n        )\n        .expect(\"parse ok\")\n        .expect(\"parse complete\");\n\n        assert_eq!(parsed.head.headers[\"server\"], \"hello\\tworld\");\n    }\n\n    #[test]\n    fn test_write_headers_orig_case_empty_value() {\n        let mut headers = HeaderMap::new();\n        let name = http::header::HeaderName::from_static(\"x-empty\");\n        headers.insert(&name, \"\".parse().expect(\"parse empty\"));\n        let mut orig_cases = HeaderCaseMap::default();\n        orig_cases.insert(name, Bytes::from_static(b\"X-EmptY\"));\n\n        let mut dst = Vec::new();\n        super::write_headers_original_case(&headers, &orig_cases, &mut dst, false);\n\n        assert_eq!(\n            dst, b\"X-EmptY:\\r\\n\",\n            \"there should be no space between the colon and CRLF\"\n        );\n    }\n\n    #[test]\n    fn test_write_headers_orig_case_multiple_entries() {\n        let mut headers = HeaderMap::new();\n        let name = http::header::HeaderName::from_static(\"x-empty\");\n        headers.insert(&name, \"a\".parse().unwrap());\n        headers.append(&name, \"b\".parse().unwrap());\n\n        let mut orig_cases = HeaderCaseMap::default();\n        orig_cases.insert(name.clone(), Bytes::from_static(b\"X-Empty\"));\n        orig_cases.append(name, Bytes::from_static(b\"X-EMPTY\"));\n\n        let mut dst = Vec::new();\n        super::write_headers_original_case(&headers, &orig_cases, &mut dst, false);\n\n        assert_eq!(dst, b\"X-Empty: a\\r\\nX-EMPTY: b\\r\\n\");\n    }\n\n    #[cfg(feature = \"nightly\")]\n    use test::Bencher;\n\n    #[cfg(feature = \"nightly\")]\n    #[bench]\n    fn bench_parse_incoming(b: &mut Bencher) {\n        let mut raw = BytesMut::from(\n            &b\"GET /super_long_uri/and_whatever?what_should_we_talk_about/\\\n            I_wonder/Hard_to_write_in_an_uri_after_all/you_have_to_make\\\n            _up_the_punctuation_yourself/how_fun_is_that?test=foo&test1=\\\n            foo1&test2=foo2&test3=foo3&test4=foo4 HTTP/1.1\\r\\nHost: \\\n            hyper.rs\\r\\nAccept: a lot of things\\r\\nAccept-Charset: \\\n            utf8\\r\\nAccept-Encoding: *\\r\\nAccess-Control-Allow-\\\n            Credentials: None\\r\\nAccess-Control-Allow-Origin: None\\r\\n\\\n            Access-Control-Allow-Methods: None\\r\\nAccess-Control-Allow-\\\n            Headers: None\\r\\nContent-Encoding: utf8\\r\\nContent-Security-\\\n            Policy: None\\r\\nContent-Type: text/html\\r\\nOrigin: hyper\\\n            \\r\\nSec-Websocket-Extensions: It looks super important!\\r\\n\\\n            Sec-Websocket-Origin: hyper\\r\\nSec-Websocket-Version: 4.3\\r\\\n            \\nStrict-Transport-Security: None\\r\\nUser-Agent: hyper\\r\\n\\\n            X-Content-Duration: None\\r\\nX-Content-Security-Policy: None\\\n            \\r\\nX-DNSPrefetch-Control: None\\r\\nX-Frame-Options: \\\n            Something important obviously\\r\\nX-Requested-With: Nothing\\\n            \\r\\n\\r\\n\"[..],\n        );\n        let len = raw.len();\n        let mut headers = Some(HeaderMap::new());\n\n        b.bytes = len as u64;\n        b.iter(|| {\n            let mut msg = Server::parse(\n                &mut raw,\n                ParseContext {\n                    cached_headers: &mut headers,\n                    req_method: &mut None,\n                    h1_parser_config: Default::default(),\n                    preserve_header_case: false,\n                    h09_responses: false,\n                },\n            )\n            .unwrap()\n            .unwrap();\n            ::test::black_box(&msg);\n            msg.head.headers.clear();\n            headers = Some(msg.head.headers);\n            restart(&mut raw, len);\n        });\n\n        fn restart(b: &mut BytesMut, len: usize) {\n            b.reserve(1);\n            unsafe {\n                b.set_len(len);\n            }\n        }\n    }\n\n    #[cfg(feature = \"nightly\")]\n    #[bench]\n    fn bench_parse_short(b: &mut Bencher) {\n        let s = &b\"GET / HTTP/1.1\\r\\nHost: localhost:8080\\r\\n\\r\\n\"[..];\n        let mut raw = BytesMut::from(s);\n        let len = raw.len();\n        let mut headers = Some(HeaderMap::new());\n\n        b.bytes = len as u64;\n        b.iter(|| {\n            let mut msg = Server::parse(\n                &mut raw,\n                ParseContext {\n                    cached_headers: &mut headers,\n                    req_method: &mut None,\n                    h1_parser_config: Default::default(),\n                    preserve_header_case: false,\n                    h09_responses: false,\n                },\n            )\n            .unwrap()\n            .unwrap();\n            ::test::black_box(&msg);\n            msg.head.headers.clear();\n            headers = Some(msg.head.headers);\n            restart(&mut raw, len);\n        });\n\n        fn restart(b: &mut BytesMut, len: usize) {\n            b.reserve(1);\n            unsafe {\n                b.set_len(len);\n            }\n        }\n    }\n\n    #[cfg(feature = \"nightly\")]\n    #[bench]\n    fn bench_server_encode_headers_preset(b: &mut Bencher) {\n        use crate::proto::BodyLength;\n        use http::header::HeaderValue;\n\n        let len = 108;\n        b.bytes = len as u64;\n\n        let mut head = MessageHead::default();\n        let mut headers = HeaderMap::new();\n        headers.insert(\"content-length\", HeaderValue::from_static(\"10\"));\n        headers.insert(\"content-type\", HeaderValue::from_static(\"application/json\"));\n\n        b.iter(|| {\n            let mut vec = Vec::new();\n            head.headers = headers.clone();\n            Server::encode(\n                Encode {\n                    head: &mut head,\n                    body: Some(BodyLength::Known(10)),\n                    keep_alive: true,\n                    req_method: &mut Some(Method::GET),\n                    title_case_headers: false,\n                },\n                &mut vec,\n            )\n            .unwrap();\n            assert_eq!(vec.len(), len);\n            ::test::black_box(vec);\n        })\n    }\n\n    #[cfg(feature = \"nightly\")]\n    #[bench]\n    fn bench_server_encode_no_headers(b: &mut Bencher) {\n        use crate::proto::BodyLength;\n\n        let len = 76;\n        b.bytes = len as u64;\n\n        let mut head = MessageHead::default();\n        let mut vec = Vec::with_capacity(128);\n\n        b.iter(|| {\n            Server::encode(\n                Encode {\n                    head: &mut head,\n                    body: Some(BodyLength::Known(10)),\n                    keep_alive: true,\n                    req_method: &mut Some(Method::GET),\n                    title_case_headers: false,\n                },\n                &mut vec,\n            )\n            .unwrap();\n            assert_eq!(vec.len(), len);\n            ::test::black_box(&vec);\n\n            vec.clear();\n        })\n    }\n}\n"
  },
  {
    "project": "hyper",
    "target": 1,
    "commit_id": "877dc0a52adedd1daaabcfcb56d90d1da1da862f",
    "func": "#![allow(deprecated)]\n\nuse std::fmt::{self, Write};\nuse std::mem::{self, MaybeUninit};\n\n#[cfg(any(test, feature = \"server\", feature = \"ffi\"))]\nuse bytes::Bytes;\nuse bytes::BytesMut;\n#[cfg(feature = \"server\")]\nuse http::header::ValueIter;\nuse http::header::{self, Entry, HeaderName, HeaderValue};\nuse http::{HeaderMap, Method, StatusCode, Version};\n\nuse crate::body::DecodedLength;\n#[cfg(feature = \"server\")]\nuse crate::common::date;\nuse crate::error::Parse;\nuse crate::ext::HeaderCaseMap;\nuse crate::headers;\nuse crate::proto::h1::{\n    Encode, Encoder, Http1Transaction, ParseContext, ParseResult, ParsedMessage,\n};\nuse crate::proto::{BodyLength, MessageHead, RequestHead, RequestLine};\n\nconst MAX_HEADERS: usize = 100;\nconst AVERAGE_HEADER_SIZE: usize = 30; // totally scientific\n\nmacro_rules! header_name {\n    ($bytes:expr) => {{\n        #[cfg(debug_assertions)]\n        {\n            match HeaderName::from_bytes($bytes) {\n                Ok(name) => name,\n                Err(_) => panic!(\n                    \"illegal header name from httparse: {:?}\",\n                    ::bytes::Bytes::copy_from_slice($bytes)\n                ),\n            }\n        }\n\n        #[cfg(not(debug_assertions))]\n        {\n            match HeaderName::from_bytes($bytes) {\n                Ok(name) => name,\n                Err(_) => panic!(\"illegal header name from httparse: {:?}\", $bytes),\n            }\n        }\n    }};\n}\n\nmacro_rules! header_value {\n    ($bytes:expr) => {{\n        #[cfg(debug_assertions)]\n        {\n            let __hvb: ::bytes::Bytes = $bytes;\n            match HeaderValue::from_maybe_shared(__hvb.clone()) {\n                Ok(name) => name,\n                Err(_) => panic!(\"illegal header value from httparse: {:?}\", __hvb),\n            }\n        }\n\n        #[cfg(not(debug_assertions))]\n        {\n            // Unsafe: httparse already validated header value\n            unsafe { HeaderValue::from_maybe_shared_unchecked($bytes) }\n        }\n    }};\n}\n\npub(super) fn parse_headers<T>(\n    bytes: &mut BytesMut,\n    ctx: ParseContext<'_>,\n) -> ParseResult<T::Incoming>\nwhere\n    T: Http1Transaction,\n{\n    // If the buffer is empty, don't bother entering the span, it's just noise.\n    if bytes.is_empty() {\n        return Ok(None);\n    }\n\n    let span = trace_span!(\"parse_headers\");\n    let _s = span.enter();\n    T::parse(bytes, ctx)\n}\n\npub(super) fn encode_headers<T>(\n    enc: Encode<'_, T::Outgoing>,\n    dst: &mut Vec<u8>,\n) -> crate::Result<Encoder>\nwhere\n    T: Http1Transaction,\n{\n    let span = trace_span!(\"encode_headers\");\n    let _s = span.enter();\n    T::encode(enc, dst)\n}\n\n// There are 2 main roles, Client and Server.\n\n#[cfg(feature = \"client\")]\npub(crate) enum Client {}\n\n#[cfg(feature = \"server\")]\npub(crate) enum Server {}\n\n#[cfg(feature = \"server\")]\nimpl Http1Transaction for Server {\n    type Incoming = RequestLine;\n    type Outgoing = StatusCode;\n    const LOG: &'static str = \"{role=server}\";\n\n    fn parse(buf: &mut BytesMut, ctx: ParseContext<'_>) -> ParseResult<RequestLine> {\n        debug_assert!(!buf.is_empty(), \"parse called with empty buf\");\n\n        let mut keep_alive;\n        let is_http_11;\n        let subject;\n        let version;\n        let len;\n        let headers_len;\n\n        // Unsafe: both headers_indices and headers are using uninitialized memory,\n        // but we *never* read any of it until after httparse has assigned\n        // values into it. By not zeroing out the stack memory, this saves\n        // a good ~5% on pipeline benchmarks.\n        let mut headers_indices: [MaybeUninit<HeaderIndices>; MAX_HEADERS] = unsafe {\n            // SAFETY: We can go safely from MaybeUninit array to array of MaybeUninit\n            MaybeUninit::uninit().assume_init()\n        };\n        {\n            let mut headers: [httparse::Header<'_>; MAX_HEADERS] = unsafe { mem::uninitialized() };\n            trace!(\n                \"Request.parse([Header; {}], [u8; {}])\",\n                headers.len(),\n                buf.len()\n            );\n            let mut req = httparse::Request::new(&mut headers);\n            let bytes = buf.as_ref();\n            match req.parse(bytes) {\n                Ok(httparse::Status::Complete(parsed_len)) => {\n                    trace!(\"Request.parse Complete({})\", parsed_len);\n                    len = parsed_len;\n                    subject = RequestLine(\n                        Method::from_bytes(req.method.unwrap().as_bytes())?,\n                        req.path.unwrap().parse()?,\n                    );\n                    version = if req.version.unwrap() == 1 {\n                        keep_alive = true;\n                        is_http_11 = true;\n                        Version::HTTP_11\n                    } else {\n                        keep_alive = false;\n                        is_http_11 = false;\n                        Version::HTTP_10\n                    };\n                    trace!(\"headers: {:?}\", &req.headers);\n\n                    record_header_indices(bytes, &req.headers, &mut headers_indices)?;\n                    headers_len = req.headers.len();\n                }\n                Ok(httparse::Status::Partial) => return Ok(None),\n                Err(err) => {\n                    return Err(match err {\n                        // if invalid Token, try to determine if for method or path\n                        httparse::Error::Token => {\n                            if req.method.is_none() {\n                                Parse::Method\n                            } else {\n                                debug_assert!(req.path.is_none());\n                                Parse::Uri\n                            }\n                        }\n                        other => other.into(),\n                    });\n                }\n            }\n        };\n\n        let slice = buf.split_to(len).freeze();\n\n        // According to https://tools.ietf.org/html/rfc7230#section-3.3.3\n        // 1. (irrelevant to Request)\n        // 2. (irrelevant to Request)\n        // 3. Transfer-Encoding: chunked has a chunked body.\n        // 4. If multiple differing Content-Length headers or invalid, close connection.\n        // 5. Content-Length header has a sized body.\n        // 6. Length 0.\n        // 7. (irrelevant to Request)\n\n        let mut decoder = DecodedLength::ZERO;\n        let mut expect_continue = false;\n        let mut con_len = None;\n        let mut is_te = false;\n        let mut is_te_chunked = false;\n        let mut wants_upgrade = subject.0 == Method::CONNECT;\n\n        let mut header_case_map = if ctx.preserve_header_case {\n            Some(HeaderCaseMap::default())\n        } else {\n            None\n        };\n\n        let mut headers = ctx.cached_headers.take().unwrap_or_else(HeaderMap::new);\n\n        headers.reserve(headers_len);\n\n        for header in &headers_indices[..headers_len] {\n            // SAFETY: array is valid up to `headers_len`\n            let header = unsafe { &*header.as_ptr() };\n            let name = header_name!(&slice[header.name.0..header.name.1]);\n            let value = header_value!(slice.slice(header.value.0..header.value.1));\n\n            match name {\n                header::TRANSFER_ENCODING => {\n                    // https://tools.ietf.org/html/rfc7230#section-3.3.3\n                    // If Transfer-Encoding header is present, and 'chunked' is\n                    // not the final encoding, and this is a Request, then it is\n                    // malformed. A server should respond with 400 Bad Request.\n                    if !is_http_11 {\n                        debug!(\"HTTP/1.0 cannot have Transfer-Encoding header\");\n                        return Err(Parse::Header);\n                    }\n                    is_te = true;\n                    if headers::is_chunked_(&value) {\n                        is_te_chunked = true;\n                        decoder = DecodedLength::CHUNKED;\n                    } else {\n                        is_te_chunked = false;\n                    }\n                }\n                header::CONTENT_LENGTH => {\n                    if is_te {\n                        continue;\n                    }\n                    let len = value\n                        .to_str()\n                        .map_err(|_| Parse::Header)\n                        .and_then(|s| s.parse().map_err(|_| Parse::Header))?;\n                    if let Some(prev) = con_len {\n                        if prev != len {\n                            debug!(\n                                \"multiple Content-Length headers with different values: [{}, {}]\",\n                                prev, len,\n                            );\n                            return Err(Parse::Header);\n                        }\n                        // we don't need to append this secondary length\n                        continue;\n                    }\n                    decoder = DecodedLength::checked_new(len)?;\n                    con_len = Some(len);\n                }\n                header::CONNECTION => {\n                    // keep_alive was previously set to default for Version\n                    if keep_alive {\n                        // HTTP/1.1\n                        keep_alive = !headers::connection_close(&value);\n                    } else {\n                        // HTTP/1.0\n                        keep_alive = headers::connection_keep_alive(&value);\n                    }\n                }\n                header::EXPECT => {\n                    expect_continue = value.as_bytes() == b\"100-continue\";\n                }\n                header::UPGRADE => {\n                    // Upgrades are only allowed with HTTP/1.1\n                    wants_upgrade = is_http_11;\n                }\n\n                _ => (),\n            }\n\n            if let Some(ref mut header_case_map) = header_case_map {\n                header_case_map.append(&name, slice.slice(header.name.0..header.name.1));\n            }\n\n            headers.append(name, value);\n        }\n\n        if is_te && !is_te_chunked {\n            debug!(\"request with transfer-encoding header, but not chunked, bad request\");\n            return Err(Parse::Header);\n        }\n\n        let mut extensions = http::Extensions::default();\n\n        if let Some(header_case_map) = header_case_map {\n            extensions.insert(header_case_map);\n        }\n\n        *ctx.req_method = Some(subject.0.clone());\n\n        Ok(Some(ParsedMessage {\n            head: MessageHead {\n                version,\n                subject,\n                headers,\n                extensions,\n            },\n            decode: decoder,\n            expect_continue,\n            keep_alive,\n            wants_upgrade,\n        }))\n    }\n\n    fn encode(mut msg: Encode<'_, Self::Outgoing>, dst: &mut Vec<u8>) -> crate::Result<Encoder> {\n        trace!(\n            \"Server::encode status={:?}, body={:?}, req_method={:?}\",\n            msg.head.subject,\n            msg.body,\n            msg.req_method\n        );\n\n        let mut wrote_len = false;\n\n        // hyper currently doesn't support returning 1xx status codes as a Response\n        // This is because Service only allows returning a single Response, and\n        // so if you try to reply with a e.g. 100 Continue, you have no way of\n        // replying with the latter status code response.\n        let (ret, is_last) = if msg.head.subject == StatusCode::SWITCHING_PROTOCOLS {\n            (Ok(()), true)\n        } else if msg.req_method == &Some(Method::CONNECT) && msg.head.subject.is_success() {\n            // Sending content-length or transfer-encoding header on 2xx response\n            // to CONNECT is forbidden in RFC 7231.\n            wrote_len = true;\n            (Ok(()), true)\n        } else if msg.head.subject.is_informational() {\n            warn!(\"response with 1xx status code not supported\");\n            *msg.head = MessageHead::default();\n            msg.head.subject = StatusCode::INTERNAL_SERVER_ERROR;\n            msg.body = None;\n            (Err(crate::Error::new_user_unsupported_status_code()), true)\n        } else {\n            (Ok(()), !msg.keep_alive)\n        };\n\n        // In some error cases, we don't know about the invalid message until already\n        // pushing some bytes onto the `dst`. In those cases, we don't want to send\n        // the half-pushed message, so rewind to before.\n        let orig_len = dst.len();\n\n        let init_cap = 30 + msg.head.headers.len() * AVERAGE_HEADER_SIZE;\n        dst.reserve(init_cap);\n        if msg.head.version == Version::HTTP_11 && msg.head.subject == StatusCode::OK {\n            extend(dst, b\"HTTP/1.1 200 OK\\r\\n\");\n        } else {\n            match msg.head.version {\n                Version::HTTP_10 => extend(dst, b\"HTTP/1.0 \"),\n                Version::HTTP_11 => extend(dst, b\"HTTP/1.1 \"),\n                Version::HTTP_2 => {\n                    debug!(\"response with HTTP2 version coerced to HTTP/1.1\");\n                    extend(dst, b\"HTTP/1.1 \");\n                }\n                other => panic!(\"unexpected response version: {:?}\", other),\n            }\n\n            extend(dst, msg.head.subject.as_str().as_bytes());\n            extend(dst, b\" \");\n            // a reason MUST be written, as many parsers will expect it.\n            extend(\n                dst,\n                msg.head\n                    .subject\n                    .canonical_reason()\n                    .unwrap_or(\"<none>\")\n                    .as_bytes(),\n            );\n            extend(dst, b\"\\r\\n\");\n        }\n\n        let orig_headers;\n        let extensions = mem::take(&mut msg.head.extensions);\n        let orig_headers = match extensions.get::<HeaderCaseMap>() {\n            None if msg.title_case_headers => {\n                orig_headers = HeaderCaseMap::default();\n                Some(&orig_headers)\n            }\n            orig_headers => orig_headers,\n        };\n        let encoder = if let Some(orig_headers) = orig_headers {\n            Self::encode_headers_with_original_case(\n                msg,\n                dst,\n                is_last,\n                orig_len,\n                wrote_len,\n                orig_headers,\n            )?\n        } else {\n            Self::encode_headers_with_lower_case(msg, dst, is_last, orig_len, wrote_len)?\n        };\n\n        ret.map(|()| encoder)\n    }\n\n    fn on_error(err: &crate::Error) -> Option<MessageHead<Self::Outgoing>> {\n        use crate::error::Kind;\n        let status = match *err.kind() {\n            Kind::Parse(Parse::Method)\n            | Kind::Parse(Parse::Header)\n            | Kind::Parse(Parse::Uri)\n            | Kind::Parse(Parse::Version) => StatusCode::BAD_REQUEST,\n            Kind::Parse(Parse::TooLarge) => StatusCode::REQUEST_HEADER_FIELDS_TOO_LARGE,\n            _ => return None,\n        };\n\n        debug!(\"sending automatic response ({}) for parse error\", status);\n        let mut msg = MessageHead::default();\n        msg.subject = status;\n        Some(msg)\n    }\n\n    fn is_server() -> bool {\n        true\n    }\n\n    fn update_date() {\n        date::update();\n    }\n}\n\n#[cfg(feature = \"server\")]\nimpl Server {\n    fn can_have_body(method: &Option<Method>, status: StatusCode) -> bool {\n        Server::can_chunked(method, status)\n    }\n\n    fn can_chunked(method: &Option<Method>, status: StatusCode) -> bool {\n        if method == &Some(Method::HEAD) || method == &Some(Method::CONNECT) && status.is_success()\n        {\n            false\n        } else if status.is_informational() {\n            false\n        } else {\n            match status {\n                StatusCode::NO_CONTENT | StatusCode::NOT_MODIFIED => false,\n                _ => true,\n            }\n        }\n    }\n\n    fn can_have_content_length(method: &Option<Method>, status: StatusCode) -> bool {\n        if status.is_informational() || method == &Some(Method::CONNECT) && status.is_success() {\n            false\n        } else {\n            match status {\n                StatusCode::NO_CONTENT | StatusCode::NOT_MODIFIED => false,\n                _ => true,\n            }\n        }\n    }\n\n    fn encode_headers_with_lower_case(\n        msg: Encode<'_, StatusCode>,\n        dst: &mut Vec<u8>,\n        is_last: bool,\n        orig_len: usize,\n        wrote_len: bool,\n    ) -> crate::Result<Encoder> {\n        struct LowercaseWriter;\n\n        impl HeaderNameWriter for LowercaseWriter {\n            #[inline]\n            fn write_full_header_line(\n                &mut self,\n                dst: &mut Vec<u8>,\n                line: &str,\n                _: (HeaderName, &str),\n            ) {\n                extend(dst, line.as_bytes())\n            }\n\n            #[inline]\n            fn write_header_name_with_colon(\n                &mut self,\n                dst: &mut Vec<u8>,\n                name_with_colon: &str,\n                _: HeaderName,\n            ) {\n                extend(dst, name_with_colon.as_bytes())\n            }\n\n            #[inline]\n            fn write_header_name(&mut self, dst: &mut Vec<u8>, name: &HeaderName) {\n                extend(dst, name.as_str().as_bytes())\n            }\n        }\n\n        Self::encode_headers(msg, dst, is_last, orig_len, wrote_len, LowercaseWriter)\n    }\n\n    #[cold]\n    #[inline(never)]\n    fn encode_headers_with_original_case(\n        msg: Encode<'_, StatusCode>,\n        dst: &mut Vec<u8>,\n        is_last: bool,\n        orig_len: usize,\n        wrote_len: bool,\n        orig_headers: &HeaderCaseMap,\n    ) -> crate::Result<Encoder> {\n        struct OrigCaseWriter<'map> {\n            map: &'map HeaderCaseMap,\n            current: Option<(HeaderName, ValueIter<'map, Bytes>)>,\n            title_case_headers: bool,\n        }\n\n        impl HeaderNameWriter for OrigCaseWriter<'_> {\n            #[inline]\n            fn write_full_header_line(\n                &mut self,\n                dst: &mut Vec<u8>,\n                _: &str,\n                (name, rest): (HeaderName, &str),\n            ) {\n                self.write_header_name(dst, &name);\n                extend(dst, rest.as_bytes());\n            }\n\n            #[inline]\n            fn write_header_name_with_colon(\n                &mut self,\n                dst: &mut Vec<u8>,\n                _: &str,\n                name: HeaderName,\n            ) {\n                self.write_header_name(dst, &name);\n                extend(dst, b\": \");\n            }\n\n            #[inline]\n            fn write_header_name(&mut self, dst: &mut Vec<u8>, name: &HeaderName) {\n                let Self {\n                    map,\n                    ref mut current,\n                    title_case_headers,\n                } = *self;\n                if current.as_ref().map_or(true, |(last, _)| last != name) {\n                    *current = None;\n                }\n                let (_, values) =\n                    current.get_or_insert_with(|| (name.clone(), map.get_all_internal(name)));\n\n                if let Some(orig_name) = values.next() {\n                    extend(dst, orig_name);\n                } else if title_case_headers {\n                    title_case(dst, name.as_str().as_bytes());\n                } else {\n                    extend(dst, name.as_str().as_bytes());\n                }\n            }\n        }\n\n        let header_name_writer = OrigCaseWriter {\n            map: orig_headers,\n            current: None,\n            title_case_headers: msg.title_case_headers,\n        };\n\n        Self::encode_headers(msg, dst, is_last, orig_len, wrote_len, header_name_writer)\n    }\n\n    #[inline]\n    fn encode_headers<W>(\n        msg: Encode<'_, StatusCode>,\n        mut dst: &mut Vec<u8>,\n        mut is_last: bool,\n        orig_len: usize,\n        mut wrote_len: bool,\n        mut header_name_writer: W,\n    ) -> crate::Result<Encoder>\n    where\n        W: HeaderNameWriter,\n    {\n        // In some error cases, we don't know about the invalid message until already\n        // pushing some bytes onto the `dst`. In those cases, we don't want to send\n        // the half-pushed message, so rewind to before.\n        let rewind = |dst: &mut Vec<u8>| {\n            dst.truncate(orig_len);\n        };\n\n        let mut encoder = Encoder::length(0);\n        let mut wrote_date = false;\n        let mut cur_name = None;\n        let mut is_name_written = false;\n        let mut must_write_chunked = false;\n        let mut prev_con_len = None;\n\n        macro_rules! handle_is_name_written {\n            () => {{\n                if is_name_written {\n                    // we need to clean up and write the newline\n                    debug_assert_ne!(\n                        &dst[dst.len() - 2..],\n                        b\"\\r\\n\",\n                        \"previous header wrote newline but set is_name_written\"\n                    );\n\n                    if must_write_chunked {\n                        extend(dst, b\", chunked\\r\\n\");\n                    } else {\n                        extend(dst, b\"\\r\\n\");\n                    }\n                }\n            }};\n        }\n\n        'headers: for (opt_name, value) in msg.head.headers.drain() {\n            if let Some(n) = opt_name {\n                cur_name = Some(n);\n                handle_is_name_written!();\n                is_name_written = false;\n            }\n            let name = cur_name.as_ref().expect(\"current header name\");\n            match *name {\n                header::CONTENT_LENGTH => {\n                    if wrote_len && !is_name_written {\n                        warn!(\"unexpected content-length found, canceling\");\n                        rewind(dst);\n                        return Err(crate::Error::new_user_header());\n                    }\n                    match msg.body {\n                        Some(BodyLength::Known(known_len)) => {\n                            // The HttpBody claims to know a length, and\n                            // the headers are already set. For performance\n                            // reasons, we are just going to trust that\n                            // the values match.\n                            //\n                            // In debug builds, we'll assert they are the\n                            // same to help developers find bugs.\n                            #[cfg(debug_assertions)]\n                            {\n                                if let Some(len) = headers::content_length_parse(&value) {\n                                    assert!(\n                                        len == known_len,\n                                        \"payload claims content-length of {}, custom content-length header claims {}\",\n                                        known_len,\n                                        len,\n                                    );\n                                }\n                            }\n\n                            if !is_name_written {\n                                encoder = Encoder::length(known_len);\n                                header_name_writer.write_header_name_with_colon(\n                                    dst,\n                                    \"content-length: \",\n                                    header::CONTENT_LENGTH,\n                                );\n                                extend(dst, value.as_bytes());\n                                wrote_len = true;\n                                is_name_written = true;\n                            }\n                            continue 'headers;\n                        }\n                        Some(BodyLength::Unknown) => {\n                            // The HttpBody impl didn't know how long the\n                            // body is, but a length header was included.\n                            // We have to parse the value to return our\n                            // Encoder...\n\n                            if let Some(len) = headers::content_length_parse(&value) {\n                                if let Some(prev) = prev_con_len {\n                                    if prev != len {\n                                        warn!(\n                                            \"multiple Content-Length values found: [{}, {}]\",\n                                            prev, len\n                                        );\n                                        rewind(dst);\n                                        return Err(crate::Error::new_user_header());\n                                    }\n                                    debug_assert!(is_name_written);\n                                    continue 'headers;\n                                } else {\n                                    // we haven't written content-length yet!\n                                    encoder = Encoder::length(len);\n                                    header_name_writer.write_header_name_with_colon(\n                                        dst,\n                                        \"content-length: \",\n                                        header::CONTENT_LENGTH,\n                                    );\n                                    extend(dst, value.as_bytes());\n                                    wrote_len = true;\n                                    is_name_written = true;\n                                    prev_con_len = Some(len);\n                                    continue 'headers;\n                                }\n                            } else {\n                                warn!(\"illegal Content-Length value: {:?}\", value);\n                                rewind(dst);\n                                return Err(crate::Error::new_user_header());\n                            }\n                        }\n                        None => {\n                            // We have no body to actually send,\n                            // but the headers claim a content-length.\n                            // There's only 2 ways this makes sense:\n                            //\n                            // - The header says the length is `0`.\n                            // - This is a response to a `HEAD` request.\n                            if msg.req_method == &Some(Method::HEAD) {\n                                debug_assert_eq!(encoder, Encoder::length(0));\n                            } else {\n                                if value.as_bytes() != b\"0\" {\n                                    warn!(\n                                        \"content-length value found, but empty body provided: {:?}\",\n                                        value\n                                    );\n                                }\n                                continue 'headers;\n                            }\n                        }\n                    }\n                    wrote_len = true;\n                }\n                header::TRANSFER_ENCODING => {\n                    if wrote_len && !is_name_written {\n                        warn!(\"unexpected transfer-encoding found, canceling\");\n                        rewind(dst);\n                        return Err(crate::Error::new_user_header());\n                    }\n                    // check that we actually can send a chunked body...\n                    if msg.head.version == Version::HTTP_10\n                        || !Server::can_chunked(msg.req_method, msg.head.subject)\n                    {\n                        continue;\n                    }\n                    wrote_len = true;\n                    // Must check each value, because `chunked` needs to be the\n                    // last encoding, or else we add it.\n                    must_write_chunked = !headers::is_chunked_(&value);\n\n                    if !is_name_written {\n                        encoder = Encoder::chunked();\n                        is_name_written = true;\n                        header_name_writer.write_header_name_with_colon(\n                            dst,\n                            \"transfer-encoding: \",\n                            header::TRANSFER_ENCODING,\n                        );\n                        extend(dst, value.as_bytes());\n                    } else {\n                        extend(dst, b\", \");\n                        extend(dst, value.as_bytes());\n                    }\n                    continue 'headers;\n                }\n                header::CONNECTION => {\n                    if !is_last && headers::connection_close(&value) {\n                        is_last = true;\n                    }\n                    if !is_name_written {\n                        is_name_written = true;\n                        header_name_writer.write_header_name_with_colon(\n                            dst,\n                            \"connection: \",\n                            header::CONNECTION,\n                        );\n                        extend(dst, value.as_bytes());\n                    } else {\n                        extend(dst, b\", \");\n                        extend(dst, value.as_bytes());\n                    }\n                    continue 'headers;\n                }\n                header::DATE => {\n                    wrote_date = true;\n                }\n                _ => (),\n            }\n            //TODO: this should perhaps instead combine them into\n            //single lines, as RFC7230 suggests is preferable.\n\n            // non-special write Name and Value\n            debug_assert!(\n                !is_name_written,\n                \"{:?} set is_name_written and didn't continue loop\",\n                name,\n            );\n            header_name_writer.write_header_name(dst, name);\n            extend(dst, b\": \");\n            extend(dst, value.as_bytes());\n            extend(dst, b\"\\r\\n\");\n        }\n\n        handle_is_name_written!();\n\n        if !wrote_len {\n            encoder = match msg.body {\n                Some(BodyLength::Unknown) => {\n                    if msg.head.version == Version::HTTP_10\n                        || !Server::can_chunked(msg.req_method, msg.head.subject)\n                    {\n                        Encoder::close_delimited()\n                    } else {\n                        header_name_writer.write_full_header_line(\n                            dst,\n                            \"transfer-encoding: chunked\\r\\n\",\n                            (header::TRANSFER_ENCODING, \": chunked\\r\\n\"),\n                        );\n                        Encoder::chunked()\n                    }\n                }\n                None | Some(BodyLength::Known(0)) => {\n                    if Server::can_have_content_length(msg.req_method, msg.head.subject) {\n                        header_name_writer.write_full_header_line(\n                            dst,\n                            \"content-length: 0\\r\\n\",\n                            (header::CONTENT_LENGTH, \": 0\\r\\n\"),\n                        )\n                    }\n                    Encoder::length(0)\n                }\n                Some(BodyLength::Known(len)) => {\n                    if !Server::can_have_content_length(msg.req_method, msg.head.subject) {\n                        Encoder::length(0)\n                    } else {\n                        header_name_writer.write_header_name_with_colon(\n                            dst,\n                            \"content-length: \",\n                            header::CONTENT_LENGTH,\n                        );\n                        let _ = ::itoa::write(&mut dst, len);\n                        extend(dst, b\"\\r\\n\");\n                        Encoder::length(len)\n                    }\n                }\n            };\n        }\n\n        if !Server::can_have_body(msg.req_method, msg.head.subject) {\n            trace!(\n                \"server body forced to 0; method={:?}, status={:?}\",\n                msg.req_method,\n                msg.head.subject\n            );\n            encoder = Encoder::length(0);\n        }\n\n        // cached date is much faster than formatting every request\n        if !wrote_date {\n            dst.reserve(date::DATE_VALUE_LENGTH + 8);\n            header_name_writer.write_header_name_with_colon(dst, \"date: \", header::DATE);\n            date::extend(dst);\n            extend(dst, b\"\\r\\n\\r\\n\");\n        } else {\n            extend(dst, b\"\\r\\n\");\n        }\n\n        Ok(encoder.set_last(is_last))\n    }\n}\n\n#[cfg(feature = \"server\")]\ntrait HeaderNameWriter {\n    fn write_full_header_line(\n        &mut self,\n        dst: &mut Vec<u8>,\n        line: &str,\n        name_value_pair: (HeaderName, &str),\n    );\n    fn write_header_name_with_colon(\n        &mut self,\n        dst: &mut Vec<u8>,\n        name_with_colon: &str,\n        name: HeaderName,\n    );\n    fn write_header_name(&mut self, dst: &mut Vec<u8>, name: &HeaderName);\n}\n\n#[cfg(feature = \"client\")]\nimpl Http1Transaction for Client {\n    type Incoming = StatusCode;\n    type Outgoing = RequestLine;\n    const LOG: &'static str = \"{role=client}\";\n\n    fn parse(buf: &mut BytesMut, ctx: ParseContext<'_>) -> ParseResult<StatusCode> {\n        debug_assert!(!buf.is_empty(), \"parse called with empty buf\");\n\n        // Loop to skip information status code headers (100 Continue, etc).\n        loop {\n            // Unsafe: see comment in Server Http1Transaction, above.\n            let mut headers_indices: [MaybeUninit<HeaderIndices>; MAX_HEADERS] = unsafe {\n                // SAFETY: We can go safely from MaybeUninit array to array of MaybeUninit\n                MaybeUninit::uninit().assume_init()\n            };\n            let (len, status, reason, version, headers_len) = {\n                let mut headers: [httparse::Header<'_>; MAX_HEADERS] =\n                    unsafe { mem::uninitialized() };\n                trace!(\n                    \"Response.parse([Header; {}], [u8; {}])\",\n                    headers.len(),\n                    buf.len()\n                );\n                let mut res = httparse::Response::new(&mut headers);\n                let bytes = buf.as_ref();\n                match ctx.h1_parser_config.parse_response(&mut res, bytes) {\n                    Ok(httparse::Status::Complete(len)) => {\n                        trace!(\"Response.parse Complete({})\", len);\n                        let status = StatusCode::from_u16(res.code.unwrap())?;\n\n                        #[cfg(not(feature = \"ffi\"))]\n                        let reason = ();\n                        #[cfg(feature = \"ffi\")]\n                        let reason = {\n                            let reason = res.reason.unwrap();\n                            // Only save the reason phrase if it isnt the canonical reason\n                            if Some(reason) != status.canonical_reason() {\n                                Some(Bytes::copy_from_slice(reason.as_bytes()))\n                            } else {\n                                None\n                            }\n                        };\n\n                        let version = if res.version.unwrap() == 1 {\n                            Version::HTTP_11\n                        } else {\n                            Version::HTTP_10\n                        };\n                        record_header_indices(bytes, &res.headers, &mut headers_indices)?;\n                        let headers_len = res.headers.len();\n                        (len, status, reason, version, headers_len)\n                    }\n                    Ok(httparse::Status::Partial) => return Ok(None),\n                    Err(httparse::Error::Version) if ctx.h09_responses => {\n                        trace!(\"Response.parse accepted HTTP/0.9 response\");\n\n                        #[cfg(not(feature = \"ffi\"))]\n                        let reason = ();\n                        #[cfg(feature = \"ffi\")]\n                        let reason = None;\n\n                        (0, StatusCode::OK, reason, Version::HTTP_09, 0)\n                    }\n                    Err(e) => return Err(e.into()),\n                }\n            };\n\n            let slice = buf.split_to(len).freeze();\n\n            let mut headers = ctx.cached_headers.take().unwrap_or_else(HeaderMap::new);\n\n            let mut keep_alive = version == Version::HTTP_11;\n\n            let mut header_case_map = if ctx.preserve_header_case {\n                Some(HeaderCaseMap::default())\n            } else {\n                None\n            };\n\n            headers.reserve(headers_len);\n            for header in &headers_indices[..headers_len] {\n                // SAFETY: array is valid up to `headers_len`\n                let header = unsafe { &*header.as_ptr() };\n                let name = header_name!(&slice[header.name.0..header.name.1]);\n                let value = header_value!(slice.slice(header.value.0..header.value.1));\n\n                if let header::CONNECTION = name {\n                    // keep_alive was previously set to default for Version\n                    if keep_alive {\n                        // HTTP/1.1\n                        keep_alive = !headers::connection_close(&value);\n                    } else {\n                        // HTTP/1.0\n                        keep_alive = headers::connection_keep_alive(&value);\n                    }\n                }\n\n                if let Some(ref mut header_case_map) = header_case_map {\n                    header_case_map.append(&name, slice.slice(header.name.0..header.name.1));\n                }\n\n                headers.append(name, value);\n            }\n\n            let mut extensions = http::Extensions::default();\n\n            if let Some(header_case_map) = header_case_map {\n                extensions.insert(header_case_map);\n            }\n\n            #[cfg(feature = \"ffi\")]\n            if let Some(reason) = reason {\n                extensions.insert(crate::ffi::ReasonPhrase(reason));\n            }\n            #[cfg(not(feature = \"ffi\"))]\n            drop(reason);\n\n            let head = MessageHead {\n                version,\n                subject: status,\n                headers,\n                extensions,\n            };\n            if let Some((decode, is_upgrade)) = Client::decoder(&head, ctx.req_method)? {\n                return Ok(Some(ParsedMessage {\n                    head,\n                    decode,\n                    expect_continue: false,\n                    // a client upgrade means the connection can't be used\n                    // again, as it is definitely upgrading.\n                    keep_alive: keep_alive && !is_upgrade,\n                    wants_upgrade: is_upgrade,\n                }));\n            }\n\n            // Parsing a 1xx response could have consumed the buffer, check if\n            // it is empty now...\n            if buf.is_empty() {\n                return Ok(None);\n            }\n        }\n    }\n\n    fn encode(msg: Encode<'_, Self::Outgoing>, dst: &mut Vec<u8>) -> crate::Result<Encoder> {\n        trace!(\n            \"Client::encode method={:?}, body={:?}\",\n            msg.head.subject.0,\n            msg.body\n        );\n\n        *msg.req_method = Some(msg.head.subject.0.clone());\n\n        let body = Client::set_length(msg.head, msg.body);\n\n        let init_cap = 30 + msg.head.headers.len() * AVERAGE_HEADER_SIZE;\n        dst.reserve(init_cap);\n\n        extend(dst, msg.head.subject.0.as_str().as_bytes());\n        extend(dst, b\" \");\n        //TODO: add API to http::Uri to encode without std::fmt\n        let _ = write!(FastWrite(dst), \"{} \", msg.head.subject.1);\n\n        match msg.head.version {\n            Version::HTTP_10 => extend(dst, b\"HTTP/1.0\"),\n            Version::HTTP_11 => extend(dst, b\"HTTP/1.1\"),\n            Version::HTTP_2 => {\n                debug!(\"request with HTTP2 version coerced to HTTP/1.1\");\n                extend(dst, b\"HTTP/1.1\");\n            }\n            other => panic!(\"unexpected request version: {:?}\", other),\n        }\n        extend(dst, b\"\\r\\n\");\n\n        if let Some(orig_headers) = msg.head.extensions.get::<HeaderCaseMap>() {\n            write_headers_original_case(\n                &msg.head.headers,\n                orig_headers,\n                dst,\n                msg.title_case_headers,\n            );\n        } else if msg.title_case_headers {\n            write_headers_title_case(&msg.head.headers, dst);\n        } else {\n            write_headers(&msg.head.headers, dst);\n        }\n\n        extend(dst, b\"\\r\\n\");\n        msg.head.headers.clear(); //TODO: remove when switching to drain()\n\n        Ok(body)\n    }\n\n    fn on_error(_err: &crate::Error) -> Option<MessageHead<Self::Outgoing>> {\n        // we can't tell the server about any errors it creates\n        None\n    }\n\n    fn is_client() -> bool {\n        true\n    }\n}\n\n#[cfg(feature = \"client\")]\nimpl Client {\n    /// Returns Some(length, wants_upgrade) if successful.\n    ///\n    /// Returns None if this message head should be skipped (like a 100 status).\n    fn decoder(\n        inc: &MessageHead<StatusCode>,\n        method: &mut Option<Method>,\n    ) -> Result<Option<(DecodedLength, bool)>, Parse> {\n        // According to https://tools.ietf.org/html/rfc7230#section-3.3.3\n        // 1. HEAD responses, and Status 1xx, 204, and 304 cannot have a body.\n        // 2. Status 2xx to a CONNECT cannot have a body.\n        // 3. Transfer-Encoding: chunked has a chunked body.\n        // 4. If multiple differing Content-Length headers or invalid, close connection.\n        // 5. Content-Length header has a sized body.\n        // 6. (irrelevant to Response)\n        // 7. Read till EOF.\n\n        match inc.subject.as_u16() {\n            101 => {\n                return Ok(Some((DecodedLength::ZERO, true)));\n            }\n            100 | 102..=199 => {\n                trace!(\"ignoring informational response: {}\", inc.subject.as_u16());\n                return Ok(None);\n            }\n            204 | 304 => return Ok(Some((DecodedLength::ZERO, false))),\n            _ => (),\n        }\n        match *method {\n            Some(Method::HEAD) => {\n                return Ok(Some((DecodedLength::ZERO, false)));\n            }\n            Some(Method::CONNECT) => {\n                if let 200..=299 = inc.subject.as_u16() {\n                    return Ok(Some((DecodedLength::ZERO, true)));\n                }\n            }\n            Some(_) => {}\n            None => {\n                trace!(\"Client::decoder is missing the Method\");\n            }\n        }\n\n        if inc.headers.contains_key(header::TRANSFER_ENCODING) {\n            // https://tools.ietf.org/html/rfc7230#section-3.3.3\n            // If Transfer-Encoding header is present, and 'chunked' is\n            // not the final encoding, and this is a Request, then it is\n            // malformed. A server should respond with 400 Bad Request.\n            if inc.version == Version::HTTP_10 {\n                debug!(\"HTTP/1.0 cannot have Transfer-Encoding header\");\n                Err(Parse::Header)\n            } else if headers::transfer_encoding_is_chunked(&inc.headers) {\n                Ok(Some((DecodedLength::CHUNKED, false)))\n            } else {\n                trace!(\"not chunked, read till eof\");\n                Ok(Some((DecodedLength::CLOSE_DELIMITED, false)))\n            }\n        } else if let Some(len) = headers::content_length_parse_all(&inc.headers) {\n            Ok(Some((DecodedLength::checked_new(len)?, false)))\n        } else if inc.headers.contains_key(header::CONTENT_LENGTH) {\n            debug!(\"illegal Content-Length header\");\n            Err(Parse::Header)\n        } else {\n            trace!(\"neither Transfer-Encoding nor Content-Length\");\n            Ok(Some((DecodedLength::CLOSE_DELIMITED, false)))\n        }\n    }\n    fn set_length(head: &mut RequestHead, body: Option<BodyLength>) -> Encoder {\n        let body = if let Some(body) = body {\n            body\n        } else {\n            head.headers.remove(header::TRANSFER_ENCODING);\n            return Encoder::length(0);\n        };\n\n        // HTTP/1.0 doesn't know about chunked\n        let can_chunked = head.version == Version::HTTP_11;\n        let headers = &mut head.headers;\n\n        // If the user already set specific headers, we should respect them, regardless\n        // of what the HttpBody knows about itself. They set them for a reason.\n\n        // Because of the borrow checker, we can't check the for an existing\n        // Content-Length header while holding an `Entry` for the Transfer-Encoding\n        // header, so unfortunately, we must do the check here, first.\n\n        let existing_con_len = headers::content_length_parse_all(headers);\n        let mut should_remove_con_len = false;\n\n        if !can_chunked {\n            // Chunked isn't legal, so if it is set, we need to remove it.\n            if headers.remove(header::TRANSFER_ENCODING).is_some() {\n                trace!(\"removing illegal transfer-encoding header\");\n            }\n\n            return if let Some(len) = existing_con_len {\n                Encoder::length(len)\n            } else if let BodyLength::Known(len) = body {\n                set_content_length(headers, len)\n            } else {\n                // HTTP/1.0 client requests without a content-length\n                // cannot have any body at all.\n                Encoder::length(0)\n            };\n        }\n\n        // If the user set a transfer-encoding, respect that. Let's just\n        // make sure `chunked` is the final encoding.\n        let encoder = match headers.entry(header::TRANSFER_ENCODING) {\n            Entry::Occupied(te) => {\n                should_remove_con_len = true;\n                if headers::is_chunked(te.iter()) {\n                    Some(Encoder::chunked())\n                } else {\n                    warn!(\"user provided transfer-encoding does not end in 'chunked'\");\n\n                    // There's a Transfer-Encoding, but it doesn't end in 'chunked'!\n                    // An example that could trigger this:\n                    //\n                    //     Transfer-Encoding: gzip\n                    //\n                    // This can be bad, depending on if this is a request or a\n                    // response.\n                    //\n                    // - A request is illegal if there is a `Transfer-Encoding`\n                    //   but it doesn't end in `chunked`.\n                    // - A response that has `Transfer-Encoding` but doesn't\n                    //   end in `chunked` isn't illegal, it just forces this\n                    //   to be close-delimited.\n                    //\n                    // We can try to repair this, by adding `chunked` ourselves.\n\n                    headers::add_chunked(te);\n                    Some(Encoder::chunked())\n                }\n            }\n            Entry::Vacant(te) => {\n                if let Some(len) = existing_con_len {\n                    Some(Encoder::length(len))\n                } else if let BodyLength::Unknown = body {\n                    // GET, HEAD, and CONNECT almost never have bodies.\n                    //\n                    // So instead of sending a \"chunked\" body with a 0-chunk,\n                    // assume no body here. If you *must* send a body,\n                    // set the headers explicitly.\n                    match head.subject.0 {\n                        Method::GET | Method::HEAD | Method::CONNECT => Some(Encoder::length(0)),\n                        _ => {\n                            te.insert(HeaderValue::from_static(\"chunked\"));\n                            Some(Encoder::chunked())\n                        }\n                    }\n                } else {\n                    None\n                }\n            }\n        };\n\n        // This is because we need a second mutable borrow to remove\n        // content-length header.\n        if let Some(encoder) = encoder {\n            if should_remove_con_len && existing_con_len.is_some() {\n                headers.remove(header::CONTENT_LENGTH);\n            }\n            return encoder;\n        }\n\n        // User didn't set transfer-encoding, AND we know body length,\n        // so we can just set the Content-Length automatically.\n\n        let len = if let BodyLength::Known(len) = body {\n            len\n        } else {\n            unreachable!(\"BodyLength::Unknown would set chunked\");\n        };\n\n        set_content_length(headers, len)\n    }\n}\n\nfn set_content_length(headers: &mut HeaderMap, len: u64) -> Encoder {\n    // At this point, there should not be a valid Content-Length\n    // header. However, since we'll be indexing in anyways, we can\n    // warn the user if there was an existing illegal header.\n    //\n    // Or at least, we can in theory. It's actually a little bit slower,\n    // so perhaps only do that while the user is developing/testing.\n\n    if cfg!(debug_assertions) {\n        match headers.entry(header::CONTENT_LENGTH) {\n            Entry::Occupied(mut cl) => {\n                // Internal sanity check, we should have already determined\n                // that the header was illegal before calling this function.\n                debug_assert!(headers::content_length_parse_all_values(cl.iter()).is_none());\n                // Uh oh, the user set `Content-Length` headers, but set bad ones.\n                // This would be an illegal message anyways, so let's try to repair\n                // with our known good length.\n                error!(\"user provided content-length header was invalid\");\n\n                cl.insert(HeaderValue::from(len));\n                Encoder::length(len)\n            }\n            Entry::Vacant(cl) => {\n                cl.insert(HeaderValue::from(len));\n                Encoder::length(len)\n            }\n        }\n    } else {\n        headers.insert(header::CONTENT_LENGTH, HeaderValue::from(len));\n        Encoder::length(len)\n    }\n}\n\n#[derive(Clone, Copy)]\nstruct HeaderIndices {\n    name: (usize, usize),\n    value: (usize, usize),\n}\n\nfn record_header_indices(\n    bytes: &[u8],\n    headers: &[httparse::Header<'_>],\n    indices: &mut [MaybeUninit<HeaderIndices>],\n) -> Result<(), crate::error::Parse> {\n    let bytes_ptr = bytes.as_ptr() as usize;\n\n    for (header, indices) in headers.iter().zip(indices.iter_mut()) {\n        if header.name.len() >= (1 << 16) {\n            debug!(\"header name larger than 64kb: {:?}\", header.name);\n            return Err(crate::error::Parse::TooLarge);\n        }\n        let name_start = header.name.as_ptr() as usize - bytes_ptr;\n        let name_end = name_start + header.name.len();\n        let value_start = header.value.as_ptr() as usize - bytes_ptr;\n        let value_end = value_start + header.value.len();\n\n        // FIXME(maybe_uninit_extra)\n        // FIXME(addr_of)\n        // Currently we don't have `ptr::addr_of_mut` in stable rust or\n        // MaybeUninit::write, so this is some way of assigning into a MaybeUninit\n        // safely\n        let new_header_indices = HeaderIndices {\n            name: (name_start, name_end),\n            value: (value_start, value_end),\n        };\n        *indices = MaybeUninit::new(new_header_indices);\n    }\n\n    Ok(())\n}\n\n// Write header names as title case. The header name is assumed to be ASCII,\n// therefore it is trivial to convert an ASCII character from lowercase to\n// uppercase. It is as simple as XORing the lowercase character byte with\n// space.\nfn title_case(dst: &mut Vec<u8>, name: &[u8]) {\n    dst.reserve(name.len());\n\n    let mut iter = name.iter();\n\n    // Uppercase the first character\n    if let Some(c) = iter.next() {\n        if *c >= b'a' && *c <= b'z' {\n            dst.push(*c ^ b' ');\n        } else {\n            dst.push(*c);\n        }\n    }\n\n    while let Some(c) = iter.next() {\n        dst.push(*c);\n\n        if *c == b'-' {\n            if let Some(c) = iter.next() {\n                if *c >= b'a' && *c <= b'z' {\n                    dst.push(*c ^ b' ');\n                } else {\n                    dst.push(*c);\n                }\n            }\n        }\n    }\n}\n\nfn write_headers_title_case(headers: &HeaderMap, dst: &mut Vec<u8>) {\n    for (name, value) in headers {\n        title_case(dst, name.as_str().as_bytes());\n        extend(dst, b\": \");\n        extend(dst, value.as_bytes());\n        extend(dst, b\"\\r\\n\");\n    }\n}\n\nfn write_headers(headers: &HeaderMap, dst: &mut Vec<u8>) {\n    for (name, value) in headers {\n        extend(dst, name.as_str().as_bytes());\n        extend(dst, b\": \");\n        extend(dst, value.as_bytes());\n        extend(dst, b\"\\r\\n\");\n    }\n}\n\n#[cold]\nfn write_headers_original_case(\n    headers: &HeaderMap,\n    orig_case: &HeaderCaseMap,\n    dst: &mut Vec<u8>,\n    title_case_headers: bool,\n) {\n    // For each header name/value pair, there may be a value in the casemap\n    // that corresponds to the HeaderValue. So, we iterator all the keys,\n    // and for each one, try to pair the originally cased name with the value.\n    //\n    // TODO: consider adding http::HeaderMap::entries() iterator\n    for name in headers.keys() {\n        let mut names = orig_case.get_all(name);\n\n        for value in headers.get_all(name) {\n            if let Some(orig_name) = names.next() {\n                extend(dst, orig_name.as_ref());\n            } else if title_case_headers {\n                title_case(dst, name.as_str().as_bytes());\n            } else {\n                extend(dst, name.as_str().as_bytes());\n            }\n\n            // Wanted for curl test cases that send `X-Custom-Header:\\r\\n`\n            if value.is_empty() {\n                extend(dst, b\":\\r\\n\");\n            } else {\n                extend(dst, b\": \");\n                extend(dst, value.as_bytes());\n                extend(dst, b\"\\r\\n\");\n            }\n        }\n    }\n}\n\nstruct FastWrite<'a>(&'a mut Vec<u8>);\n\nimpl<'a> fmt::Write for FastWrite<'a> {\n    #[inline]\n    fn write_str(&mut self, s: &str) -> fmt::Result {\n        extend(self.0, s.as_bytes());\n        Ok(())\n    }\n\n    #[inline]\n    fn write_fmt(&mut self, args: fmt::Arguments<'_>) -> fmt::Result {\n        fmt::write(self, args)\n    }\n}\n\n#[inline]\nfn extend(dst: &mut Vec<u8>, data: &[u8]) {\n    dst.extend_from_slice(data);\n}\n\n#[cfg(test)]\nmod tests {\n    use bytes::BytesMut;\n\n    use super::*;\n\n    #[test]\n    fn test_parse_request() {\n        let _ = pretty_env_logger::try_init();\n        let mut raw = BytesMut::from(\"GET /echo HTTP/1.1\\r\\nHost: hyper.rs\\r\\n\\r\\n\");\n        let mut method = None;\n        let msg = Server::parse(\n            &mut raw,\n            ParseContext {\n                cached_headers: &mut None,\n                req_method: &mut method,\n                h1_parser_config: Default::default(),\n                preserve_header_case: false,\n                h09_responses: false,\n            },\n        )\n        .unwrap()\n        .unwrap();\n        assert_eq!(raw.len(), 0);\n        assert_eq!(msg.head.subject.0, crate::Method::GET);\n        assert_eq!(msg.head.subject.1, \"/echo\");\n        assert_eq!(msg.head.version, crate::Version::HTTP_11);\n        assert_eq!(msg.head.headers.len(), 1);\n        assert_eq!(msg.head.headers[\"Host\"], \"hyper.rs\");\n        assert_eq!(method, Some(crate::Method::GET));\n    }\n\n    #[test]\n    fn test_parse_response() {\n        let _ = pretty_env_logger::try_init();\n        let mut raw = BytesMut::from(\"HTTP/1.1 200 OK\\r\\nContent-Length: 0\\r\\n\\r\\n\");\n        let ctx = ParseContext {\n            cached_headers: &mut None,\n            req_method: &mut Some(crate::Method::GET),\n            h1_parser_config: Default::default(),\n            preserve_header_case: false,\n            h09_responses: false,\n        };\n        let msg = Client::parse(&mut raw, ctx).unwrap().unwrap();\n        assert_eq!(raw.len(), 0);\n        assert_eq!(msg.head.subject, crate::StatusCode::OK);\n        assert_eq!(msg.head.version, crate::Version::HTTP_11);\n        assert_eq!(msg.head.headers.len(), 1);\n        assert_eq!(msg.head.headers[\"Content-Length\"], \"0\");\n    }\n\n    #[test]\n    fn test_parse_request_errors() {\n        let mut raw = BytesMut::from(\"GET htt:p// HTTP/1.1\\r\\nHost: hyper.rs\\r\\n\\r\\n\");\n        let ctx = ParseContext {\n            cached_headers: &mut None,\n            req_method: &mut None,\n            h1_parser_config: Default::default(),\n            preserve_header_case: false,\n            h09_responses: false,\n        };\n        Server::parse(&mut raw, ctx).unwrap_err();\n    }\n\n    const H09_RESPONSE: &'static str = \"Baguettes are super delicious, don't you agree?\";\n\n    #[test]\n    fn test_parse_response_h09_allowed() {\n        let _ = pretty_env_logger::try_init();\n        let mut raw = BytesMut::from(H09_RESPONSE);\n        let ctx = ParseContext {\n            cached_headers: &mut None,\n            req_method: &mut Some(crate::Method::GET),\n            h1_parser_config: Default::default(),\n            preserve_header_case: false,\n            h09_responses: true,\n        };\n        let msg = Client::parse(&mut raw, ctx).unwrap().unwrap();\n        assert_eq!(raw, H09_RESPONSE);\n        assert_eq!(msg.head.subject, crate::StatusCode::OK);\n        assert_eq!(msg.head.version, crate::Version::HTTP_09);\n        assert_eq!(msg.head.headers.len(), 0);\n    }\n\n    #[test]\n    fn test_parse_response_h09_rejected() {\n        let _ = pretty_env_logger::try_init();\n        let mut raw = BytesMut::from(H09_RESPONSE);\n        let ctx = ParseContext {\n            cached_headers: &mut None,\n            req_method: &mut Some(crate::Method::GET),\n            h1_parser_config: Default::default(),\n            preserve_header_case: false,\n            h09_responses: false,\n        };\n        Client::parse(&mut raw, ctx).unwrap_err();\n        assert_eq!(raw, H09_RESPONSE);\n    }\n\n    const RESPONSE_WITH_WHITESPACE_BETWEEN_HEADER_NAME_AND_COLON: &'static str =\n        \"HTTP/1.1 200 OK\\r\\nAccess-Control-Allow-Credentials : true\\r\\n\\r\\n\";\n\n    #[test]\n    fn test_parse_allow_response_with_spaces_before_colons() {\n        use httparse::ParserConfig;\n\n        let _ = pretty_env_logger::try_init();\n        let mut raw = BytesMut::from(RESPONSE_WITH_WHITESPACE_BETWEEN_HEADER_NAME_AND_COLON);\n        let mut h1_parser_config = ParserConfig::default();\n        h1_parser_config.allow_spaces_after_header_name_in_responses(true);\n        let ctx = ParseContext {\n            cached_headers: &mut None,\n            req_method: &mut Some(crate::Method::GET),\n            h1_parser_config,\n            preserve_header_case: false,\n            h09_responses: false,\n        };\n        let msg = Client::parse(&mut raw, ctx).unwrap().unwrap();\n        assert_eq!(raw.len(), 0);\n        assert_eq!(msg.head.subject, crate::StatusCode::OK);\n        assert_eq!(msg.head.version, crate::Version::HTTP_11);\n        assert_eq!(msg.head.headers.len(), 1);\n        assert_eq!(msg.head.headers[\"Access-Control-Allow-Credentials\"], \"true\");\n    }\n\n    #[test]\n    fn test_parse_reject_response_with_spaces_before_colons() {\n        let _ = pretty_env_logger::try_init();\n        let mut raw = BytesMut::from(RESPONSE_WITH_WHITESPACE_BETWEEN_HEADER_NAME_AND_COLON);\n        let ctx = ParseContext {\n            cached_headers: &mut None,\n            req_method: &mut Some(crate::Method::GET),\n            h1_parser_config: Default::default(),\n            preserve_header_case: false,\n            h09_responses: false,\n        };\n        Client::parse(&mut raw, ctx).unwrap_err();\n    }\n\n    #[test]\n    fn test_parse_preserve_header_case_in_request() {\n        let mut raw =\n            BytesMut::from(\"GET / HTTP/1.1\\r\\nHost: hyper.rs\\r\\nX-BREAD: baguette\\r\\n\\r\\n\");\n        let ctx = ParseContext {\n            cached_headers: &mut None,\n            req_method: &mut None,\n            h1_parser_config: Default::default(),\n            preserve_header_case: true,\n            h09_responses: false,\n        };\n        let parsed_message = Server::parse(&mut raw, ctx).unwrap().unwrap();\n        let orig_headers = parsed_message\n            .head\n            .extensions\n            .get::<HeaderCaseMap>()\n            .unwrap();\n        assert_eq!(\n            orig_headers\n                .get_all_internal(&HeaderName::from_static(\"host\"))\n                .into_iter()\n                .collect::<Vec<_>>(),\n            vec![&Bytes::from(\"Host\")]\n        );\n        assert_eq!(\n            orig_headers\n                .get_all_internal(&HeaderName::from_static(\"x-bread\"))\n                .into_iter()\n                .collect::<Vec<_>>(),\n            vec![&Bytes::from(\"X-BREAD\")]\n        );\n    }\n\n    #[test]\n    fn test_decoder_request() {\n        fn parse(s: &str) -> ParsedMessage<RequestLine> {\n            let mut bytes = BytesMut::from(s);\n            Server::parse(\n                &mut bytes,\n                ParseContext {\n                    cached_headers: &mut None,\n                    req_method: &mut None,\n                    h1_parser_config: Default::default(),\n                    preserve_header_case: false,\n                    h09_responses: false,\n                },\n            )\n            .expect(\"parse ok\")\n            .expect(\"parse complete\")\n        }\n\n        fn parse_err(s: &str, comment: &str) -> crate::error::Parse {\n            let mut bytes = BytesMut::from(s);\n            Server::parse(\n                &mut bytes,\n                ParseContext {\n                    cached_headers: &mut None,\n                    req_method: &mut None,\n                    h1_parser_config: Default::default(),\n                    preserve_header_case: false,\n                    h09_responses: false,\n                },\n            )\n            .expect_err(comment)\n        }\n\n        // no length or transfer-encoding means 0-length body\n        assert_eq!(\n            parse(\n                \"\\\n                 GET / HTTP/1.1\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::ZERO\n        );\n\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::ZERO\n        );\n\n        // transfer-encoding: chunked\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 transfer-encoding: chunked\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 transfer-encoding: gzip, chunked\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 transfer-encoding: gzip\\r\\n\\\n                 transfer-encoding: chunked\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        // content-length\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::new(10)\n        );\n\n        // transfer-encoding and content-length = chunked\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 transfer-encoding: chunked\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 transfer-encoding: chunked\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 transfer-encoding: gzip\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 transfer-encoding: chunked\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        // multiple content-lengths of same value are fine\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::new(10)\n        );\n\n        // multiple content-lengths with different values is an error\n        parse_err(\n            \"\\\n             POST / HTTP/1.1\\r\\n\\\n             content-length: 10\\r\\n\\\n             content-length: 11\\r\\n\\\n             \\r\\n\\\n             \",\n            \"multiple content-lengths\",\n        );\n\n        // transfer-encoding that isn't chunked is an error\n        parse_err(\n            \"\\\n             POST / HTTP/1.1\\r\\n\\\n             transfer-encoding: gzip\\r\\n\\\n             \\r\\n\\\n             \",\n            \"transfer-encoding but not chunked\",\n        );\n\n        parse_err(\n            \"\\\n             POST / HTTP/1.1\\r\\n\\\n             transfer-encoding: chunked, gzip\\r\\n\\\n             \\r\\n\\\n             \",\n            \"transfer-encoding doesn't end in chunked\",\n        );\n\n        parse_err(\n            \"\\\n             POST / HTTP/1.1\\r\\n\\\n             transfer-encoding: chunked\\r\\n\\\n             transfer-encoding: afterlol\\r\\n\\\n             \\r\\n\\\n             \",\n            \"transfer-encoding multiple lines doesn't end in chunked\",\n        );\n\n        // http/1.0\n\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.0\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::new(10)\n        );\n\n        // 1.0 doesn't understand chunked, so its an error\n        parse_err(\n            \"\\\n             POST / HTTP/1.0\\r\\n\\\n             transfer-encoding: chunked\\r\\n\\\n             \\r\\n\\\n             \",\n            \"1.0 chunked\",\n        );\n    }\n\n    #[test]\n    fn test_decoder_response() {\n        fn parse(s: &str) -> ParsedMessage<StatusCode> {\n            parse_with_method(s, Method::GET)\n        }\n\n        fn parse_ignores(s: &str) {\n            let mut bytes = BytesMut::from(s);\n            assert!(Client::parse(\n                &mut bytes,\n                ParseContext {\n                    cached_headers: &mut None,\n                    req_method: &mut Some(Method::GET),\n                    h1_parser_config: Default::default(),\n                    preserve_header_case: false,\n                    h09_responses: false,\n                }\n            )\n            .expect(\"parse ok\")\n            .is_none())\n        }\n\n        fn parse_with_method(s: &str, m: Method) -> ParsedMessage<StatusCode> {\n            let mut bytes = BytesMut::from(s);\n            Client::parse(\n                &mut bytes,\n                ParseContext {\n                    cached_headers: &mut None,\n                    req_method: &mut Some(m),\n                    h1_parser_config: Default::default(),\n                    preserve_header_case: false,\n                    h09_responses: false,\n                },\n            )\n            .expect(\"parse ok\")\n            .expect(\"parse complete\")\n        }\n\n        fn parse_err(s: &str) -> crate::error::Parse {\n            let mut bytes = BytesMut::from(s);\n            Client::parse(\n                &mut bytes,\n                ParseContext {\n                    cached_headers: &mut None,\n                    req_method: &mut Some(Method::GET),\n                    h1_parser_config: Default::default(),\n                    preserve_header_case: false,\n                    h09_responses: false,\n                },\n            )\n            .expect_err(\"parse should err\")\n        }\n\n        // no content-length or transfer-encoding means close-delimited\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CLOSE_DELIMITED\n        );\n\n        // 204 and 304 never have a body\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 204 No Content\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::ZERO\n        );\n\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 304 Not Modified\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::ZERO\n        );\n\n        // content-length\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 content-length: 8\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::new(8)\n        );\n\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 content-length: 8\\r\\n\\\n                 content-length: 8\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::new(8)\n        );\n\n        parse_err(\n            \"\\\n             HTTP/1.1 200 OK\\r\\n\\\n             content-length: 8\\r\\n\\\n             content-length: 9\\r\\n\\\n             \\r\\n\\\n             \",\n        );\n\n        // transfer-encoding: chunked\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 transfer-encoding: chunked\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        // transfer-encoding not-chunked is close-delimited\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 transfer-encoding: yolo\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CLOSE_DELIMITED\n        );\n\n        // transfer-encoding and content-length = chunked\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 transfer-encoding: chunked\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        // HEAD can have content-length, but not body\n        assert_eq!(\n            parse_with_method(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 content-length: 8\\r\\n\\\n                 \\r\\n\\\n                 \",\n                Method::HEAD\n            )\n            .decode,\n            DecodedLength::ZERO\n        );\n\n        // CONNECT with 200 never has body\n        {\n            let msg = parse_with_method(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 \\r\\n\\\n                 \",\n                Method::CONNECT,\n            );\n            assert_eq!(msg.decode, DecodedLength::ZERO);\n            assert!(!msg.keep_alive, \"should be upgrade\");\n            assert!(msg.wants_upgrade, \"should be upgrade\");\n        }\n\n        // CONNECT receiving non 200 can have a body\n        assert_eq!(\n            parse_with_method(\n                \"\\\n                 HTTP/1.1 400 Bad Request\\r\\n\\\n                 \\r\\n\\\n                 \",\n                Method::CONNECT\n            )\n            .decode,\n            DecodedLength::CLOSE_DELIMITED\n        );\n\n        // 1xx status codes\n        parse_ignores(\n            \"\\\n             HTTP/1.1 100 Continue\\r\\n\\\n             \\r\\n\\\n             \",\n        );\n\n        parse_ignores(\n            \"\\\n             HTTP/1.1 103 Early Hints\\r\\n\\\n             \\r\\n\\\n             \",\n        );\n\n        // 101 upgrade not supported yet\n        {\n            let msg = parse(\n                \"\\\n                 HTTP/1.1 101 Switching Protocols\\r\\n\\\n                 \\r\\n\\\n                 \",\n            );\n            assert_eq!(msg.decode, DecodedLength::ZERO);\n            assert!(!msg.keep_alive, \"should be last\");\n            assert!(msg.wants_upgrade, \"should be upgrade\");\n        }\n\n        // http/1.0\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.0 200 OK\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CLOSE_DELIMITED\n        );\n\n        // 1.0 doesn't understand chunked\n        parse_err(\n            \"\\\n             HTTP/1.0 200 OK\\r\\n\\\n             transfer-encoding: chunked\\r\\n\\\n             \\r\\n\\\n             \",\n        );\n\n        // keep-alive\n        assert!(\n            parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 content-length: 0\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .keep_alive,\n            \"HTTP/1.1 keep-alive is default\"\n        );\n\n        assert!(\n            !parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 content-length: 0\\r\\n\\\n                 connection: foo, close, bar\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .keep_alive,\n            \"connection close is always close\"\n        );\n\n        assert!(\n            !parse(\n                \"\\\n                 HTTP/1.0 200 OK\\r\\n\\\n                 content-length: 0\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .keep_alive,\n            \"HTTP/1.0 close is default\"\n        );\n\n        assert!(\n            parse(\n                \"\\\n                 HTTP/1.0 200 OK\\r\\n\\\n                 content-length: 0\\r\\n\\\n                 connection: foo, keep-alive, bar\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .keep_alive,\n            \"connection keep-alive is always keep-alive\"\n        );\n    }\n\n    #[test]\n    fn test_client_request_encode_title_case() {\n        use crate::proto::BodyLength;\n        use http::header::HeaderValue;\n\n        let mut head = MessageHead::default();\n        head.headers\n            .insert(\"content-length\", HeaderValue::from_static(\"10\"));\n        head.headers\n            .insert(\"content-type\", HeaderValue::from_static(\"application/json\"));\n        head.headers.insert(\"*-*\", HeaderValue::from_static(\"o_o\"));\n\n        let mut vec = Vec::new();\n        Client::encode(\n            Encode {\n                head: &mut head,\n                body: Some(BodyLength::Known(10)),\n                keep_alive: true,\n                req_method: &mut None,\n                title_case_headers: true,\n            },\n            &mut vec,\n        )\n        .unwrap();\n\n        assert_eq!(vec, b\"GET / HTTP/1.1\\r\\nContent-Length: 10\\r\\nContent-Type: application/json\\r\\n*-*: o_o\\r\\n\\r\\n\".to_vec());\n    }\n\n    #[test]\n    fn test_client_request_encode_orig_case() {\n        use crate::proto::BodyLength;\n        use http::header::{HeaderValue, CONTENT_LENGTH};\n\n        let mut head = MessageHead::default();\n        head.headers\n            .insert(\"content-length\", HeaderValue::from_static(\"10\"));\n        head.headers\n            .insert(\"content-type\", HeaderValue::from_static(\"application/json\"));\n\n        let mut orig_headers = HeaderCaseMap::default();\n        orig_headers.insert(CONTENT_LENGTH, \"CONTENT-LENGTH\".into());\n        head.extensions.insert(orig_headers);\n\n        let mut vec = Vec::new();\n        Client::encode(\n            Encode {\n                head: &mut head,\n                body: Some(BodyLength::Known(10)),\n                keep_alive: true,\n                req_method: &mut None,\n                title_case_headers: false,\n            },\n            &mut vec,\n        )\n        .unwrap();\n\n        assert_eq!(\n            &*vec,\n            b\"GET / HTTP/1.1\\r\\nCONTENT-LENGTH: 10\\r\\ncontent-type: application/json\\r\\n\\r\\n\"\n                .as_ref(),\n        );\n    }\n    #[test]\n    fn test_client_request_encode_orig_and_title_case() {\n        use crate::proto::BodyLength;\n        use http::header::{HeaderValue, CONTENT_LENGTH};\n\n        let mut head = MessageHead::default();\n        head.headers\n            .insert(\"content-length\", HeaderValue::from_static(\"10\"));\n        head.headers\n            .insert(\"content-type\", HeaderValue::from_static(\"application/json\"));\n\n        let mut orig_headers = HeaderCaseMap::default();\n        orig_headers.insert(CONTENT_LENGTH, \"CONTENT-LENGTH\".into());\n        head.extensions.insert(orig_headers);\n\n        let mut vec = Vec::new();\n        Client::encode(\n            Encode {\n                head: &mut head,\n                body: Some(BodyLength::Known(10)),\n                keep_alive: true,\n                req_method: &mut None,\n                title_case_headers: true,\n            },\n            &mut vec,\n        )\n        .unwrap();\n\n        assert_eq!(\n            &*vec,\n            b\"GET / HTTP/1.1\\r\\nCONTENT-LENGTH: 10\\r\\nContent-Type: application/json\\r\\n\\r\\n\"\n                .as_ref(),\n        );\n    }\n\n    #[test]\n    fn test_server_encode_connect_method() {\n        let mut head = MessageHead::default();\n\n        let mut vec = Vec::new();\n        let encoder = Server::encode(\n            Encode {\n                head: &mut head,\n                body: None,\n                keep_alive: true,\n                req_method: &mut Some(Method::CONNECT),\n                title_case_headers: false,\n            },\n            &mut vec,\n        )\n        .unwrap();\n\n        assert!(encoder.is_last());\n    }\n\n    #[test]\n    fn test_server_response_encode_title_case() {\n        use crate::proto::BodyLength;\n        use http::header::HeaderValue;\n\n        let mut head = MessageHead::default();\n        head.headers\n            .insert(\"content-length\", HeaderValue::from_static(\"10\"));\n        head.headers\n            .insert(\"content-type\", HeaderValue::from_static(\"application/json\"));\n\n        let mut vec = Vec::new();\n        Server::encode(\n            Encode {\n                head: &mut head,\n                body: Some(BodyLength::Known(10)),\n                keep_alive: true,\n                req_method: &mut None,\n                title_case_headers: true,\n            },\n            &mut vec,\n        )\n        .unwrap();\n\n        let expected_response =\n            b\"HTTP/1.1 200 OK\\r\\nContent-Length: 10\\r\\nContent-Type: application/json\\r\\n\";\n\n        assert_eq!(&vec[..expected_response.len()], &expected_response[..]);\n    }\n\n    #[test]\n    fn test_server_response_encode_orig_case() {\n        use crate::proto::BodyLength;\n        use http::header::{HeaderValue, CONTENT_LENGTH};\n\n        let mut head = MessageHead::default();\n        head.headers\n            .insert(\"content-length\", HeaderValue::from_static(\"10\"));\n        head.headers\n            .insert(\"content-type\", HeaderValue::from_static(\"application/json\"));\n\n        let mut orig_headers = HeaderCaseMap::default();\n        orig_headers.insert(CONTENT_LENGTH, \"CONTENT-LENGTH\".into());\n        head.extensions.insert(orig_headers);\n\n        let mut vec = Vec::new();\n        Server::encode(\n            Encode {\n                head: &mut head,\n                body: Some(BodyLength::Known(10)),\n                keep_alive: true,\n                req_method: &mut None,\n                title_case_headers: false,\n            },\n            &mut vec,\n        )\n        .unwrap();\n\n        let expected_response =\n            b\"HTTP/1.1 200 OK\\r\\nCONTENT-LENGTH: 10\\r\\ncontent-type: application/json\\r\\ndate: \";\n\n        assert_eq!(&vec[..expected_response.len()], &expected_response[..]);\n    }\n\n    #[test]\n    fn test_server_response_encode_orig_and_title_case() {\n        use crate::proto::BodyLength;\n        use http::header::{HeaderValue, CONTENT_LENGTH};\n\n        let mut head = MessageHead::default();\n        head.headers\n            .insert(\"content-length\", HeaderValue::from_static(\"10\"));\n        head.headers\n            .insert(\"content-type\", HeaderValue::from_static(\"application/json\"));\n\n        let mut orig_headers = HeaderCaseMap::default();\n        orig_headers.insert(CONTENT_LENGTH, \"CONTENT-LENGTH\".into());\n        head.extensions.insert(orig_headers);\n\n        let mut vec = Vec::new();\n        Server::encode(\n            Encode {\n                head: &mut head,\n                body: Some(BodyLength::Known(10)),\n                keep_alive: true,\n                req_method: &mut None,\n                title_case_headers: true,\n            },\n            &mut vec,\n        )\n        .unwrap();\n\n        let expected_response =\n            b\"HTTP/1.1 200 OK\\r\\nCONTENT-LENGTH: 10\\r\\nContent-Type: application/json\\r\\nDate: \";\n\n        assert_eq!(&vec[..expected_response.len()], &expected_response[..]);\n    }\n\n    #[test]\n    fn parse_header_htabs() {\n        let mut bytes = BytesMut::from(\"HTTP/1.1 200 OK\\r\\nserver: hello\\tworld\\r\\n\\r\\n\");\n        let parsed = Client::parse(\n            &mut bytes,\n            ParseContext {\n                cached_headers: &mut None,\n                req_method: &mut Some(Method::GET),\n                h1_parser_config: Default::default(),\n                preserve_header_case: false,\n                h09_responses: false,\n            },\n        )\n        .expect(\"parse ok\")\n        .expect(\"parse complete\");\n\n        assert_eq!(parsed.head.headers[\"server\"], \"hello\\tworld\");\n    }\n\n    #[test]\n    fn test_write_headers_orig_case_empty_value() {\n        let mut headers = HeaderMap::new();\n        let name = http::header::HeaderName::from_static(\"x-empty\");\n        headers.insert(&name, \"\".parse().expect(\"parse empty\"));\n        let mut orig_cases = HeaderCaseMap::default();\n        orig_cases.insert(name, Bytes::from_static(b\"X-EmptY\"));\n\n        let mut dst = Vec::new();\n        super::write_headers_original_case(&headers, &orig_cases, &mut dst, false);\n\n        assert_eq!(\n            dst, b\"X-EmptY:\\r\\n\",\n            \"there should be no space between the colon and CRLF\"\n        );\n    }\n\n    #[test]\n    fn test_write_headers_orig_case_multiple_entries() {\n        let mut headers = HeaderMap::new();\n        let name = http::header::HeaderName::from_static(\"x-empty\");\n        headers.insert(&name, \"a\".parse().unwrap());\n        headers.append(&name, \"b\".parse().unwrap());\n\n        let mut orig_cases = HeaderCaseMap::default();\n        orig_cases.insert(name.clone(), Bytes::from_static(b\"X-Empty\"));\n        orig_cases.append(name, Bytes::from_static(b\"X-EMPTY\"));\n\n        let mut dst = Vec::new();\n        super::write_headers_original_case(&headers, &orig_cases, &mut dst, false);\n\n        assert_eq!(dst, b\"X-Empty: a\\r\\nX-EMPTY: b\\r\\n\");\n    }\n\n    #[cfg(feature = \"nightly\")]\n    use test::Bencher;\n\n    #[cfg(feature = \"nightly\")]\n    #[bench]\n    fn bench_parse_incoming(b: &mut Bencher) {\n        let mut raw = BytesMut::from(\n            &b\"GET /super_long_uri/and_whatever?what_should_we_talk_about/\\\n            I_wonder/Hard_to_write_in_an_uri_after_all/you_have_to_make\\\n            _up_the_punctuation_yourself/how_fun_is_that?test=foo&test1=\\\n            foo1&test2=foo2&test3=foo3&test4=foo4 HTTP/1.1\\r\\nHost: \\\n            hyper.rs\\r\\nAccept: a lot of things\\r\\nAccept-Charset: \\\n            utf8\\r\\nAccept-Encoding: *\\r\\nAccess-Control-Allow-\\\n            Credentials: None\\r\\nAccess-Control-Allow-Origin: None\\r\\n\\\n            Access-Control-Allow-Methods: None\\r\\nAccess-Control-Allow-\\\n            Headers: None\\r\\nContent-Encoding: utf8\\r\\nContent-Security-\\\n            Policy: None\\r\\nContent-Type: text/html\\r\\nOrigin: hyper\\\n            \\r\\nSec-Websocket-Extensions: It looks super important!\\r\\n\\\n            Sec-Websocket-Origin: hyper\\r\\nSec-Websocket-Version: 4.3\\r\\\n            \\nStrict-Transport-Security: None\\r\\nUser-Agent: hyper\\r\\n\\\n            X-Content-Duration: None\\r\\nX-Content-Security-Policy: None\\\n            \\r\\nX-DNSPrefetch-Control: None\\r\\nX-Frame-Options: \\\n            Something important obviously\\r\\nX-Requested-With: Nothing\\\n            \\r\\n\\r\\n\"[..],\n        );\n        let len = raw.len();\n        let mut headers = Some(HeaderMap::new());\n\n        b.bytes = len as u64;\n        b.iter(|| {\n            let mut msg = Server::parse(\n                &mut raw,\n                ParseContext {\n                    cached_headers: &mut headers,\n                    req_method: &mut None,\n                    h1_parser_config: Default::default(),\n                    preserve_header_case: false,\n                    h09_responses: false,\n                },\n            )\n            .unwrap()\n            .unwrap();\n            ::test::black_box(&msg);\n            msg.head.headers.clear();\n            headers = Some(msg.head.headers);\n            restart(&mut raw, len);\n        });\n\n        fn restart(b: &mut BytesMut, len: usize) {\n            b.reserve(1);\n            unsafe {\n                b.set_len(len);\n            }\n        }\n    }\n\n    #[cfg(feature = \"nightly\")]\n    #[bench]\n    fn bench_parse_short(b: &mut Bencher) {\n        let s = &b\"GET / HTTP/1.1\\r\\nHost: localhost:8080\\r\\n\\r\\n\"[..];\n        let mut raw = BytesMut::from(s);\n        let len = raw.len();\n        let mut headers = Some(HeaderMap::new());\n\n        b.bytes = len as u64;\n        b.iter(|| {\n            let mut msg = Server::parse(\n                &mut raw,\n                ParseContext {\n                    cached_headers: &mut headers,\n                    req_method: &mut None,\n                    h1_parser_config: Default::default(),\n                    preserve_header_case: false,\n                    h09_responses: false,\n                },\n            )\n            .unwrap()\n            .unwrap();\n            ::test::black_box(&msg);\n            msg.head.headers.clear();\n            headers = Some(msg.head.headers);\n            restart(&mut raw, len);\n        });\n\n        fn restart(b: &mut BytesMut, len: usize) {\n            b.reserve(1);\n            unsafe {\n                b.set_len(len);\n            }\n        }\n    }\n\n    #[cfg(feature = \"nightly\")]\n    #[bench]\n    fn bench_server_encode_headers_preset(b: &mut Bencher) {\n        use crate::proto::BodyLength;\n        use http::header::HeaderValue;\n\n        let len = 108;\n        b.bytes = len as u64;\n\n        let mut head = MessageHead::default();\n        let mut headers = HeaderMap::new();\n        headers.insert(\"content-length\", HeaderValue::from_static(\"10\"));\n        headers.insert(\"content-type\", HeaderValue::from_static(\"application/json\"));\n\n        b.iter(|| {\n            let mut vec = Vec::new();\n            head.headers = headers.clone();\n            Server::encode(\n                Encode {\n                    head: &mut head,\n                    body: Some(BodyLength::Known(10)),\n                    keep_alive: true,\n                    req_method: &mut Some(Method::GET),\n                    title_case_headers: false,\n                },\n                &mut vec,\n            )\n            .unwrap();\n            assert_eq!(vec.len(), len);\n            ::test::black_box(vec);\n        })\n    }\n\n    #[cfg(feature = \"nightly\")]\n    #[bench]\n    fn bench_server_encode_no_headers(b: &mut Bencher) {\n        use crate::proto::BodyLength;\n\n        let len = 76;\n        b.bytes = len as u64;\n\n        let mut head = MessageHead::default();\n        let mut vec = Vec::with_capacity(128);\n\n        b.iter(|| {\n            Server::encode(\n                Encode {\n                    head: &mut head,\n                    body: Some(BodyLength::Known(10)),\n                    keep_alive: true,\n                    req_method: &mut Some(Method::GET),\n                    title_case_headers: false,\n                },\n                &mut vec,\n            )\n            .unwrap();\n            assert_eq!(vec.len(), len);\n            ::test::black_box(&vec);\n\n            vec.clear();\n        })\n    }\n}\n"
  },
  {
    "project": "hyper",
    "target": 1,
    "commit_id": "7500d7ddfd1c39a5fbfefd54b9014842d9862af4",
    "func": "#![allow(deprecated)]\n\nuse std::fmt::{self, Write};\nuse std::mem::{self, MaybeUninit};\n\n#[cfg(any(test, feature = \"server\", feature = \"ffi\"))]\nuse bytes::Bytes;\nuse bytes::BytesMut;\n#[cfg(feature = \"server\")]\nuse http::header::ValueIter;\nuse http::header::{self, Entry, HeaderName, HeaderValue};\nuse http::{HeaderMap, Method, StatusCode, Version};\n\nuse crate::body::DecodedLength;\n#[cfg(feature = \"server\")]\nuse crate::common::date;\nuse crate::error::Parse;\nuse crate::ext::HeaderCaseMap;\nuse crate::headers;\nuse crate::proto::h1::{\n    Encode, Encoder, Http1Transaction, ParseContext, ParseResult, ParsedMessage,\n};\nuse crate::proto::{BodyLength, MessageHead, RequestHead, RequestLine};\n\nconst MAX_HEADERS: usize = 100;\nconst AVERAGE_HEADER_SIZE: usize = 30; // totally scientific\n\nmacro_rules! header_name {\n    ($bytes:expr) => {{\n        #[cfg(debug_assertions)]\n        {\n            match HeaderName::from_bytes($bytes) {\n                Ok(name) => name,\n                Err(_) => panic!(\n                    \"illegal header name from httparse: {:?}\",\n                    ::bytes::Bytes::copy_from_slice($bytes)\n                ),\n            }\n        }\n\n        #[cfg(not(debug_assertions))]\n        {\n            match HeaderName::from_bytes($bytes) {\n                Ok(name) => name,\n                Err(_) => panic!(\"illegal header name from httparse: {:?}\", $bytes),\n            }\n        }\n    }};\n}\n\nmacro_rules! header_value {\n    ($bytes:expr) => {{\n        #[cfg(debug_assertions)]\n        {\n            let __hvb: ::bytes::Bytes = $bytes;\n            match HeaderValue::from_maybe_shared(__hvb.clone()) {\n                Ok(name) => name,\n                Err(_) => panic!(\"illegal header value from httparse: {:?}\", __hvb),\n            }\n        }\n\n        #[cfg(not(debug_assertions))]\n        {\n            // Unsafe: httparse already validated header value\n            unsafe { HeaderValue::from_maybe_shared_unchecked($bytes) }\n        }\n    }};\n}\n\npub(super) fn parse_headers<T>(\n    bytes: &mut BytesMut,\n    ctx: ParseContext<'_>,\n) -> ParseResult<T::Incoming>\nwhere\n    T: Http1Transaction,\n{\n    // If the buffer is empty, don't bother entering the span, it's just noise.\n    if bytes.is_empty() {\n        return Ok(None);\n    }\n\n    let span = trace_span!(\"parse_headers\");\n    let _s = span.enter();\n    T::parse(bytes, ctx)\n}\n\npub(super) fn encode_headers<T>(\n    enc: Encode<'_, T::Outgoing>,\n    dst: &mut Vec<u8>,\n) -> crate::Result<Encoder>\nwhere\n    T: Http1Transaction,\n{\n    let span = trace_span!(\"encode_headers\");\n    let _s = span.enter();\n    T::encode(enc, dst)\n}\n\n// There are 2 main roles, Client and Server.\n\n#[cfg(feature = \"client\")]\npub(crate) enum Client {}\n\n#[cfg(feature = \"server\")]\npub(crate) enum Server {}\n\n#[cfg(feature = \"server\")]\nimpl Http1Transaction for Server {\n    type Incoming = RequestLine;\n    type Outgoing = StatusCode;\n    const LOG: &'static str = \"{role=server}\";\n\n    fn parse(buf: &mut BytesMut, ctx: ParseContext<'_>) -> ParseResult<RequestLine> {\n        debug_assert!(!buf.is_empty(), \"parse called with empty buf\");\n\n        let mut keep_alive;\n        let is_http_11;\n        let subject;\n        let version;\n        let len;\n        let headers_len;\n\n        // Unsafe: both headers_indices and headers are using uninitialized memory,\n        // but we *never* read any of it until after httparse has assigned\n        // values into it. By not zeroing out the stack memory, this saves\n        // a good ~5% on pipeline benchmarks.\n        let mut headers_indices: [MaybeUninit<HeaderIndices>; MAX_HEADERS] = unsafe {\n            // SAFETY: We can go safely from MaybeUninit array to array of MaybeUninit\n            MaybeUninit::uninit().assume_init()\n        };\n        {\n            /* SAFETY: it is safe to go from MaybeUninit array to array of MaybeUninit */\n            let mut headers: [MaybeUninit<httparse::Header<'_>>; MAX_HEADERS] = unsafe {\n                MaybeUninit::uninit().assume_init()\n            };\n            trace!(\n                \"Request.parse([Header; {}], [u8; {}])\",\n                headers.len(),\n                buf.len()\n            );\n            let bytes = buf.as_ref();\n            let (req, status) = httparse::Request::with_uninit_headers(&mut headers, bytes);\n            match status {\n                Ok(httparse::Status::Complete(parsed_len)) => {\n                    trace!(\"Request.parse Complete({})\", parsed_len);\n                    len = parsed_len;\n                    subject = RequestLine(\n                        Method::from_bytes(req.method.unwrap().as_bytes())?,\n                        req.path.unwrap().parse()?,\n                    );\n                    version = if req.version.unwrap() == 1 {\n                        keep_alive = true;\n                        is_http_11 = true;\n                        Version::HTTP_11\n                    } else {\n                        keep_alive = false;\n                        is_http_11 = false;\n                        Version::HTTP_10\n                    };\n                    trace!(\"headers: {:?}\", &req.headers);\n\n                    record_header_indices(bytes, &req.headers, &mut headers_indices)?;\n                    headers_len = req.headers.len();\n                }\n                Ok(httparse::Status::Partial) => return Ok(None),\n                Err(err) => {\n                    return Err(match err {\n                        // if invalid Token, try to determine if for method or path\n                        httparse::Error::Token => {\n                            if req.method.is_none() {\n                                Parse::Method\n                            } else {\n                                debug_assert!(req.path.is_none());\n                                Parse::Uri\n                            }\n                        }\n                        other => other.into(),\n                    });\n                }\n            }\n        };\n\n        let slice = buf.split_to(len).freeze();\n\n        // According to https://tools.ietf.org/html/rfc7230#section-3.3.3\n        // 1. (irrelevant to Request)\n        // 2. (irrelevant to Request)\n        // 3. Transfer-Encoding: chunked has a chunked body.\n        // 4. If multiple differing Content-Length headers or invalid, close connection.\n        // 5. Content-Length header has a sized body.\n        // 6. Length 0.\n        // 7. (irrelevant to Request)\n\n        let mut decoder = DecodedLength::ZERO;\n        let mut expect_continue = false;\n        let mut con_len = None;\n        let mut is_te = false;\n        let mut is_te_chunked = false;\n        let mut wants_upgrade = subject.0 == Method::CONNECT;\n\n        let mut header_case_map = if ctx.preserve_header_case {\n            Some(HeaderCaseMap::default())\n        } else {\n            None\n        };\n\n        let mut headers = ctx.cached_headers.take().unwrap_or_else(HeaderMap::new);\n\n        headers.reserve(headers_len);\n\n        for header in &headers_indices[..headers_len] {\n            // SAFETY: array is valid up to `headers_len`\n            let header = unsafe { &*header.as_ptr() };\n            let name = header_name!(&slice[header.name.0..header.name.1]);\n            let value = header_value!(slice.slice(header.value.0..header.value.1));\n\n            match name {\n                header::TRANSFER_ENCODING => {\n                    // https://tools.ietf.org/html/rfc7230#section-3.3.3\n                    // If Transfer-Encoding header is present, and 'chunked' is\n                    // not the final encoding, and this is a Request, then it is\n                    // malformed. A server should respond with 400 Bad Request.\n                    if !is_http_11 {\n                        debug!(\"HTTP/1.0 cannot have Transfer-Encoding header\");\n                        return Err(Parse::Header);\n                    }\n                    is_te = true;\n                    if headers::is_chunked_(&value) {\n                        is_te_chunked = true;\n                        decoder = DecodedLength::CHUNKED;\n                    } else {\n                        is_te_chunked = false;\n                    }\n                }\n                header::CONTENT_LENGTH => {\n                    if is_te {\n                        continue;\n                    }\n                    let len = value\n                        .to_str()\n                        .map_err(|_| Parse::Header)\n                        .and_then(|s| s.parse().map_err(|_| Parse::Header))?;\n                    if let Some(prev) = con_len {\n                        if prev != len {\n                            debug!(\n                                \"multiple Content-Length headers with different values: [{}, {}]\",\n                                prev, len,\n                            );\n                            return Err(Parse::Header);\n                        }\n                        // we don't need to append this secondary length\n                        continue;\n                    }\n                    decoder = DecodedLength::checked_new(len)?;\n                    con_len = Some(len);\n                }\n                header::CONNECTION => {\n                    // keep_alive was previously set to default for Version\n                    if keep_alive {\n                        // HTTP/1.1\n                        keep_alive = !headers::connection_close(&value);\n                    } else {\n                        // HTTP/1.0\n                        keep_alive = headers::connection_keep_alive(&value);\n                    }\n                }\n                header::EXPECT => {\n                    expect_continue = value.as_bytes() == b\"100-continue\";\n                }\n                header::UPGRADE => {\n                    // Upgrades are only allowed with HTTP/1.1\n                    wants_upgrade = is_http_11;\n                }\n\n                _ => (),\n            }\n\n            if let Some(ref mut header_case_map) = header_case_map {\n                header_case_map.append(&name, slice.slice(header.name.0..header.name.1));\n            }\n\n            headers.append(name, value);\n        }\n\n        if is_te && !is_te_chunked {\n            debug!(\"request with transfer-encoding header, but not chunked, bad request\");\n            return Err(Parse::Header);\n        }\n\n        let mut extensions = http::Extensions::default();\n\n        if let Some(header_case_map) = header_case_map {\n            extensions.insert(header_case_map);\n        }\n\n        *ctx.req_method = Some(subject.0.clone());\n\n        Ok(Some(ParsedMessage {\n            head: MessageHead {\n                version,\n                subject,\n                headers,\n                extensions,\n            },\n            decode: decoder,\n            expect_continue,\n            keep_alive,\n            wants_upgrade,\n        }))\n    }\n\n    fn encode(mut msg: Encode<'_, Self::Outgoing>, dst: &mut Vec<u8>) -> crate::Result<Encoder> {\n        trace!(\n            \"Server::encode status={:?}, body={:?}, req_method={:?}\",\n            msg.head.subject,\n            msg.body,\n            msg.req_method\n        );\n\n        let mut wrote_len = false;\n\n        // hyper currently doesn't support returning 1xx status codes as a Response\n        // This is because Service only allows returning a single Response, and\n        // so if you try to reply with a e.g. 100 Continue, you have no way of\n        // replying with the latter status code response.\n        let (ret, is_last) = if msg.head.subject == StatusCode::SWITCHING_PROTOCOLS {\n            (Ok(()), true)\n        } else if msg.req_method == &Some(Method::CONNECT) && msg.head.subject.is_success() {\n            // Sending content-length or transfer-encoding header on 2xx response\n            // to CONNECT is forbidden in RFC 7231.\n            wrote_len = true;\n            (Ok(()), true)\n        } else if msg.head.subject.is_informational() {\n            warn!(\"response with 1xx status code not supported\");\n            *msg.head = MessageHead::default();\n            msg.head.subject = StatusCode::INTERNAL_SERVER_ERROR;\n            msg.body = None;\n            (Err(crate::Error::new_user_unsupported_status_code()), true)\n        } else {\n            (Ok(()), !msg.keep_alive)\n        };\n\n        // In some error cases, we don't know about the invalid message until already\n        // pushing some bytes onto the `dst`. In those cases, we don't want to send\n        // the half-pushed message, so rewind to before.\n        let orig_len = dst.len();\n\n        let init_cap = 30 + msg.head.headers.len() * AVERAGE_HEADER_SIZE;\n        dst.reserve(init_cap);\n        if msg.head.version == Version::HTTP_11 && msg.head.subject == StatusCode::OK {\n            extend(dst, b\"HTTP/1.1 200 OK\\r\\n\");\n        } else {\n            match msg.head.version {\n                Version::HTTP_10 => extend(dst, b\"HTTP/1.0 \"),\n                Version::HTTP_11 => extend(dst, b\"HTTP/1.1 \"),\n                Version::HTTP_2 => {\n                    debug!(\"response with HTTP2 version coerced to HTTP/1.1\");\n                    extend(dst, b\"HTTP/1.1 \");\n                }\n                other => panic!(\"unexpected response version: {:?}\", other),\n            }\n\n            extend(dst, msg.head.subject.as_str().as_bytes());\n            extend(dst, b\" \");\n            // a reason MUST be written, as many parsers will expect it.\n            extend(\n                dst,\n                msg.head\n                    .subject\n                    .canonical_reason()\n                    .unwrap_or(\"<none>\")\n                    .as_bytes(),\n            );\n            extend(dst, b\"\\r\\n\");\n        }\n\n        let orig_headers;\n        let extensions = mem::take(&mut msg.head.extensions);\n        let orig_headers = match extensions.get::<HeaderCaseMap>() {\n            None if msg.title_case_headers => {\n                orig_headers = HeaderCaseMap::default();\n                Some(&orig_headers)\n            }\n            orig_headers => orig_headers,\n        };\n        let encoder = if let Some(orig_headers) = orig_headers {\n            Self::encode_headers_with_original_case(\n                msg,\n                dst,\n                is_last,\n                orig_len,\n                wrote_len,\n                orig_headers,\n            )?\n        } else {\n            Self::encode_headers_with_lower_case(msg, dst, is_last, orig_len, wrote_len)?\n        };\n\n        ret.map(|()| encoder)\n    }\n\n    fn on_error(err: &crate::Error) -> Option<MessageHead<Self::Outgoing>> {\n        use crate::error::Kind;\n        let status = match *err.kind() {\n            Kind::Parse(Parse::Method)\n            | Kind::Parse(Parse::Header)\n            | Kind::Parse(Parse::Uri)\n            | Kind::Parse(Parse::Version) => StatusCode::BAD_REQUEST,\n            Kind::Parse(Parse::TooLarge) => StatusCode::REQUEST_HEADER_FIELDS_TOO_LARGE,\n            _ => return None,\n        };\n\n        debug!(\"sending automatic response ({}) for parse error\", status);\n        let mut msg = MessageHead::default();\n        msg.subject = status;\n        Some(msg)\n    }\n\n    fn is_server() -> bool {\n        true\n    }\n\n    fn update_date() {\n        date::update();\n    }\n}\n\n#[cfg(feature = \"server\")]\nimpl Server {\n    fn can_have_body(method: &Option<Method>, status: StatusCode) -> bool {\n        Server::can_chunked(method, status)\n    }\n\n    fn can_chunked(method: &Option<Method>, status: StatusCode) -> bool {\n        if method == &Some(Method::HEAD) || method == &Some(Method::CONNECT) && status.is_success()\n        {\n            false\n        } else if status.is_informational() {\n            false\n        } else {\n            match status {\n                StatusCode::NO_CONTENT | StatusCode::NOT_MODIFIED => false,\n                _ => true,\n            }\n        }\n    }\n\n    fn can_have_content_length(method: &Option<Method>, status: StatusCode) -> bool {\n        if status.is_informational() || method == &Some(Method::CONNECT) && status.is_success() {\n            false\n        } else {\n            match status {\n                StatusCode::NO_CONTENT | StatusCode::NOT_MODIFIED => false,\n                _ => true,\n            }\n        }\n    }\n\n    fn encode_headers_with_lower_case(\n        msg: Encode<'_, StatusCode>,\n        dst: &mut Vec<u8>,\n        is_last: bool,\n        orig_len: usize,\n        wrote_len: bool,\n    ) -> crate::Result<Encoder> {\n        struct LowercaseWriter;\n\n        impl HeaderNameWriter for LowercaseWriter {\n            #[inline]\n            fn write_full_header_line(\n                &mut self,\n                dst: &mut Vec<u8>,\n                line: &str,\n                _: (HeaderName, &str),\n            ) {\n                extend(dst, line.as_bytes())\n            }\n\n            #[inline]\n            fn write_header_name_with_colon(\n                &mut self,\n                dst: &mut Vec<u8>,\n                name_with_colon: &str,\n                _: HeaderName,\n            ) {\n                extend(dst, name_with_colon.as_bytes())\n            }\n\n            #[inline]\n            fn write_header_name(&mut self, dst: &mut Vec<u8>, name: &HeaderName) {\n                extend(dst, name.as_str().as_bytes())\n            }\n        }\n\n        Self::encode_headers(msg, dst, is_last, orig_len, wrote_len, LowercaseWriter)\n    }\n\n    #[cold]\n    #[inline(never)]\n    fn encode_headers_with_original_case(\n        msg: Encode<'_, StatusCode>,\n        dst: &mut Vec<u8>,\n        is_last: bool,\n        orig_len: usize,\n        wrote_len: bool,\n        orig_headers: &HeaderCaseMap,\n    ) -> crate::Result<Encoder> {\n        struct OrigCaseWriter<'map> {\n            map: &'map HeaderCaseMap,\n            current: Option<(HeaderName, ValueIter<'map, Bytes>)>,\n            title_case_headers: bool,\n        }\n\n        impl HeaderNameWriter for OrigCaseWriter<'_> {\n            #[inline]\n            fn write_full_header_line(\n                &mut self,\n                dst: &mut Vec<u8>,\n                _: &str,\n                (name, rest): (HeaderName, &str),\n            ) {\n                self.write_header_name(dst, &name);\n                extend(dst, rest.as_bytes());\n            }\n\n            #[inline]\n            fn write_header_name_with_colon(\n                &mut self,\n                dst: &mut Vec<u8>,\n                _: &str,\n                name: HeaderName,\n            ) {\n                self.write_header_name(dst, &name);\n                extend(dst, b\": \");\n            }\n\n            #[inline]\n            fn write_header_name(&mut self, dst: &mut Vec<u8>, name: &HeaderName) {\n                let Self {\n                    map,\n                    ref mut current,\n                    title_case_headers,\n                } = *self;\n                if current.as_ref().map_or(true, |(last, _)| last != name) {\n                    *current = None;\n                }\n                let (_, values) =\n                    current.get_or_insert_with(|| (name.clone(), map.get_all_internal(name)));\n\n                if let Some(orig_name) = values.next() {\n                    extend(dst, orig_name);\n                } else if title_case_headers {\n                    title_case(dst, name.as_str().as_bytes());\n                } else {\n                    extend(dst, name.as_str().as_bytes());\n                }\n            }\n        }\n\n        let header_name_writer = OrigCaseWriter {\n            map: orig_headers,\n            current: None,\n            title_case_headers: msg.title_case_headers,\n        };\n\n        Self::encode_headers(msg, dst, is_last, orig_len, wrote_len, header_name_writer)\n    }\n\n    #[inline]\n    fn encode_headers<W>(\n        msg: Encode<'_, StatusCode>,\n        mut dst: &mut Vec<u8>,\n        mut is_last: bool,\n        orig_len: usize,\n        mut wrote_len: bool,\n        mut header_name_writer: W,\n    ) -> crate::Result<Encoder>\n    where\n        W: HeaderNameWriter,\n    {\n        // In some error cases, we don't know about the invalid message until already\n        // pushing some bytes onto the `dst`. In those cases, we don't want to send\n        // the half-pushed message, so rewind to before.\n        let rewind = |dst: &mut Vec<u8>| {\n            dst.truncate(orig_len);\n        };\n\n        let mut encoder = Encoder::length(0);\n        let mut wrote_date = false;\n        let mut cur_name = None;\n        let mut is_name_written = false;\n        let mut must_write_chunked = false;\n        let mut prev_con_len = None;\n\n        macro_rules! handle_is_name_written {\n            () => {{\n                if is_name_written {\n                    // we need to clean up and write the newline\n                    debug_assert_ne!(\n                        &dst[dst.len() - 2..],\n                        b\"\\r\\n\",\n                        \"previous header wrote newline but set is_name_written\"\n                    );\n\n                    if must_write_chunked {\n                        extend(dst, b\", chunked\\r\\n\");\n                    } else {\n                        extend(dst, b\"\\r\\n\");\n                    }\n                }\n            }};\n        }\n\n        'headers: for (opt_name, value) in msg.head.headers.drain() {\n            if let Some(n) = opt_name {\n                cur_name = Some(n);\n                handle_is_name_written!();\n                is_name_written = false;\n            }\n            let name = cur_name.as_ref().expect(\"current header name\");\n            match *name {\n                header::CONTENT_LENGTH => {\n                    if wrote_len && !is_name_written {\n                        warn!(\"unexpected content-length found, canceling\");\n                        rewind(dst);\n                        return Err(crate::Error::new_user_header());\n                    }\n                    match msg.body {\n                        Some(BodyLength::Known(known_len)) => {\n                            // The HttpBody claims to know a length, and\n                            // the headers are already set. For performance\n                            // reasons, we are just going to trust that\n                            // the values match.\n                            //\n                            // In debug builds, we'll assert they are the\n                            // same to help developers find bugs.\n                            #[cfg(debug_assertions)]\n                            {\n                                if let Some(len) = headers::content_length_parse(&value) {\n                                    assert!(\n                                        len == known_len,\n                                        \"payload claims content-length of {}, custom content-length header claims {}\",\n                                        known_len,\n                                        len,\n                                    );\n                                }\n                            }\n\n                            if !is_name_written {\n                                encoder = Encoder::length(known_len);\n                                header_name_writer.write_header_name_with_colon(\n                                    dst,\n                                    \"content-length: \",\n                                    header::CONTENT_LENGTH,\n                                );\n                                extend(dst, value.as_bytes());\n                                wrote_len = true;\n                                is_name_written = true;\n                            }\n                            continue 'headers;\n                        }\n                        Some(BodyLength::Unknown) => {\n                            // The HttpBody impl didn't know how long the\n                            // body is, but a length header was included.\n                            // We have to parse the value to return our\n                            // Encoder...\n\n                            if let Some(len) = headers::content_length_parse(&value) {\n                                if let Some(prev) = prev_con_len {\n                                    if prev != len {\n                                        warn!(\n                                            \"multiple Content-Length values found: [{}, {}]\",\n                                            prev, len\n                                        );\n                                        rewind(dst);\n                                        return Err(crate::Error::new_user_header());\n                                    }\n                                    debug_assert!(is_name_written);\n                                    continue 'headers;\n                                } else {\n                                    // we haven't written content-length yet!\n                                    encoder = Encoder::length(len);\n                                    header_name_writer.write_header_name_with_colon(\n                                        dst,\n                                        \"content-length: \",\n                                        header::CONTENT_LENGTH,\n                                    );\n                                    extend(dst, value.as_bytes());\n                                    wrote_len = true;\n                                    is_name_written = true;\n                                    prev_con_len = Some(len);\n                                    continue 'headers;\n                                }\n                            } else {\n                                warn!(\"illegal Content-Length value: {:?}\", value);\n                                rewind(dst);\n                                return Err(crate::Error::new_user_header());\n                            }\n                        }\n                        None => {\n                            // We have no body to actually send,\n                            // but the headers claim a content-length.\n                            // There's only 2 ways this makes sense:\n                            //\n                            // - The header says the length is `0`.\n                            // - This is a response to a `HEAD` request.\n                            if msg.req_method == &Some(Method::HEAD) {\n                                debug_assert_eq!(encoder, Encoder::length(0));\n                            } else {\n                                if value.as_bytes() != b\"0\" {\n                                    warn!(\n                                        \"content-length value found, but empty body provided: {:?}\",\n                                        value\n                                    );\n                                }\n                                continue 'headers;\n                            }\n                        }\n                    }\n                    wrote_len = true;\n                }\n                header::TRANSFER_ENCODING => {\n                    if wrote_len && !is_name_written {\n                        warn!(\"unexpected transfer-encoding found, canceling\");\n                        rewind(dst);\n                        return Err(crate::Error::new_user_header());\n                    }\n                    // check that we actually can send a chunked body...\n                    if msg.head.version == Version::HTTP_10\n                        || !Server::can_chunked(msg.req_method, msg.head.subject)\n                    {\n                        continue;\n                    }\n                    wrote_len = true;\n                    // Must check each value, because `chunked` needs to be the\n                    // last encoding, or else we add it.\n                    must_write_chunked = !headers::is_chunked_(&value);\n\n                    if !is_name_written {\n                        encoder = Encoder::chunked();\n                        is_name_written = true;\n                        header_name_writer.write_header_name_with_colon(\n                            dst,\n                            \"transfer-encoding: \",\n                            header::TRANSFER_ENCODING,\n                        );\n                        extend(dst, value.as_bytes());\n                    } else {\n                        extend(dst, b\", \");\n                        extend(dst, value.as_bytes());\n                    }\n                    continue 'headers;\n                }\n                header::CONNECTION => {\n                    if !is_last && headers::connection_close(&value) {\n                        is_last = true;\n                    }\n                    if !is_name_written {\n                        is_name_written = true;\n                        header_name_writer.write_header_name_with_colon(\n                            dst,\n                            \"connection: \",\n                            header::CONNECTION,\n                        );\n                        extend(dst, value.as_bytes());\n                    } else {\n                        extend(dst, b\", \");\n                        extend(dst, value.as_bytes());\n                    }\n                    continue 'headers;\n                }\n                header::DATE => {\n                    wrote_date = true;\n                }\n                _ => (),\n            }\n            //TODO: this should perhaps instead combine them into\n            //single lines, as RFC7230 suggests is preferable.\n\n            // non-special write Name and Value\n            debug_assert!(\n                !is_name_written,\n                \"{:?} set is_name_written and didn't continue loop\",\n                name,\n            );\n            header_name_writer.write_header_name(dst, name);\n            extend(dst, b\": \");\n            extend(dst, value.as_bytes());\n            extend(dst, b\"\\r\\n\");\n        }\n\n        handle_is_name_written!();\n\n        if !wrote_len {\n            encoder = match msg.body {\n                Some(BodyLength::Unknown) => {\n                    if msg.head.version == Version::HTTP_10\n                        || !Server::can_chunked(msg.req_method, msg.head.subject)\n                    {\n                        Encoder::close_delimited()\n                    } else {\n                        header_name_writer.write_full_header_line(\n                            dst,\n                            \"transfer-encoding: chunked\\r\\n\",\n                            (header::TRANSFER_ENCODING, \": chunked\\r\\n\"),\n                        );\n                        Encoder::chunked()\n                    }\n                }\n                None | Some(BodyLength::Known(0)) => {\n                    if Server::can_have_content_length(msg.req_method, msg.head.subject) {\n                        header_name_writer.write_full_header_line(\n                            dst,\n                            \"content-length: 0\\r\\n\",\n                            (header::CONTENT_LENGTH, \": 0\\r\\n\"),\n                        )\n                    }\n                    Encoder::length(0)\n                }\n                Some(BodyLength::Known(len)) => {\n                    if !Server::can_have_content_length(msg.req_method, msg.head.subject) {\n                        Encoder::length(0)\n                    } else {\n                        header_name_writer.write_header_name_with_colon(\n                            dst,\n                            \"content-length: \",\n                            header::CONTENT_LENGTH,\n                        );\n                        let _ = ::itoa::write(&mut dst, len);\n                        extend(dst, b\"\\r\\n\");\n                        Encoder::length(len)\n                    }\n                }\n            };\n        }\n\n        if !Server::can_have_body(msg.req_method, msg.head.subject) {\n            trace!(\n                \"server body forced to 0; method={:?}, status={:?}\",\n                msg.req_method,\n                msg.head.subject\n            );\n            encoder = Encoder::length(0);\n        }\n\n        // cached date is much faster than formatting every request\n        if !wrote_date {\n            dst.reserve(date::DATE_VALUE_LENGTH + 8);\n            header_name_writer.write_header_name_with_colon(dst, \"date: \", header::DATE);\n            date::extend(dst);\n            extend(dst, b\"\\r\\n\\r\\n\");\n        } else {\n            extend(dst, b\"\\r\\n\");\n        }\n\n        Ok(encoder.set_last(is_last))\n    }\n}\n\n#[cfg(feature = \"server\")]\ntrait HeaderNameWriter {\n    fn write_full_header_line(\n        &mut self,\n        dst: &mut Vec<u8>,\n        line: &str,\n        name_value_pair: (HeaderName, &str),\n    );\n    fn write_header_name_with_colon(\n        &mut self,\n        dst: &mut Vec<u8>,\n        name_with_colon: &str,\n        name: HeaderName,\n    );\n    fn write_header_name(&mut self, dst: &mut Vec<u8>, name: &HeaderName);\n}\n\n#[cfg(feature = \"client\")]\nimpl Http1Transaction for Client {\n    type Incoming = StatusCode;\n    type Outgoing = RequestLine;\n    const LOG: &'static str = \"{role=client}\";\n\n    fn parse(buf: &mut BytesMut, ctx: ParseContext<'_>) -> ParseResult<StatusCode> {\n        debug_assert!(!buf.is_empty(), \"parse called with empty buf\");\n\n        // Loop to skip information status code headers (100 Continue, etc).\n        loop {\n            // Unsafe: see comment in Server Http1Transaction, above.\n            let mut headers_indices: [MaybeUninit<HeaderIndices>; MAX_HEADERS] = unsafe {\n                // SAFETY: We can go safely from MaybeUninit array to array of MaybeUninit\n                MaybeUninit::uninit().assume_init()\n            };\n            let (len, status, reason, version, headers_len) = {\n                let mut headers: [httparse::Header<'_>; MAX_HEADERS] =\n                    unsafe { mem::uninitialized() };\n                trace!(\n                    \"Response.parse([Header; {}], [u8; {}])\",\n                    headers.len(),\n                    buf.len()\n                );\n                let mut res = httparse::Response::new(&mut headers);\n                let bytes = buf.as_ref();\n                match ctx.h1_parser_config.parse_response(&mut res, bytes) {\n                    Ok(httparse::Status::Complete(len)) => {\n                        trace!(\"Response.parse Complete({})\", len);\n                        let status = StatusCode::from_u16(res.code.unwrap())?;\n\n                        #[cfg(not(feature = \"ffi\"))]\n                        let reason = ();\n                        #[cfg(feature = \"ffi\")]\n                        let reason = {\n                            let reason = res.reason.unwrap();\n                            // Only save the reason phrase if it isnt the canonical reason\n                            if Some(reason) != status.canonical_reason() {\n                                Some(Bytes::copy_from_slice(reason.as_bytes()))\n                            } else {\n                                None\n                            }\n                        };\n\n                        let version = if res.version.unwrap() == 1 {\n                            Version::HTTP_11\n                        } else {\n                            Version::HTTP_10\n                        };\n                        record_header_indices(bytes, &res.headers, &mut headers_indices)?;\n                        let headers_len = res.headers.len();\n                        (len, status, reason, version, headers_len)\n                    }\n                    Ok(httparse::Status::Partial) => return Ok(None),\n                    Err(httparse::Error::Version) if ctx.h09_responses => {\n                        trace!(\"Response.parse accepted HTTP/0.9 response\");\n\n                        #[cfg(not(feature = \"ffi\"))]\n                        let reason = ();\n                        #[cfg(feature = \"ffi\")]\n                        let reason = None;\n\n                        (0, StatusCode::OK, reason, Version::HTTP_09, 0)\n                    }\n                    Err(e) => return Err(e.into()),\n                }\n            };\n\n            let slice = buf.split_to(len).freeze();\n\n            let mut headers = ctx.cached_headers.take().unwrap_or_else(HeaderMap::new);\n\n            let mut keep_alive = version == Version::HTTP_11;\n\n            let mut header_case_map = if ctx.preserve_header_case {\n                Some(HeaderCaseMap::default())\n            } else {\n                None\n            };\n\n            headers.reserve(headers_len);\n            for header in &headers_indices[..headers_len] {\n                // SAFETY: array is valid up to `headers_len`\n                let header = unsafe { &*header.as_ptr() };\n                let name = header_name!(&slice[header.name.0..header.name.1]);\n                let value = header_value!(slice.slice(header.value.0..header.value.1));\n\n                if let header::CONNECTION = name {\n                    // keep_alive was previously set to default for Version\n                    if keep_alive {\n                        // HTTP/1.1\n                        keep_alive = !headers::connection_close(&value);\n                    } else {\n                        // HTTP/1.0\n                        keep_alive = headers::connection_keep_alive(&value);\n                    }\n                }\n\n                if let Some(ref mut header_case_map) = header_case_map {\n                    header_case_map.append(&name, slice.slice(header.name.0..header.name.1));\n                }\n\n                headers.append(name, value);\n            }\n\n            let mut extensions = http::Extensions::default();\n\n            if let Some(header_case_map) = header_case_map {\n                extensions.insert(header_case_map);\n            }\n\n            #[cfg(feature = \"ffi\")]\n            if let Some(reason) = reason {\n                extensions.insert(crate::ffi::ReasonPhrase(reason));\n            }\n            #[cfg(not(feature = \"ffi\"))]\n            drop(reason);\n\n            let head = MessageHead {\n                version,\n                subject: status,\n                headers,\n                extensions,\n            };\n            if let Some((decode, is_upgrade)) = Client::decoder(&head, ctx.req_method)? {\n                return Ok(Some(ParsedMessage {\n                    head,\n                    decode,\n                    expect_continue: false,\n                    // a client upgrade means the connection can't be used\n                    // again, as it is definitely upgrading.\n                    keep_alive: keep_alive && !is_upgrade,\n                    wants_upgrade: is_upgrade,\n                }));\n            }\n\n            // Parsing a 1xx response could have consumed the buffer, check if\n            // it is empty now...\n            if buf.is_empty() {\n                return Ok(None);\n            }\n        }\n    }\n\n    fn encode(msg: Encode<'_, Self::Outgoing>, dst: &mut Vec<u8>) -> crate::Result<Encoder> {\n        trace!(\n            \"Client::encode method={:?}, body={:?}\",\n            msg.head.subject.0,\n            msg.body\n        );\n\n        *msg.req_method = Some(msg.head.subject.0.clone());\n\n        let body = Client::set_length(msg.head, msg.body);\n\n        let init_cap = 30 + msg.head.headers.len() * AVERAGE_HEADER_SIZE;\n        dst.reserve(init_cap);\n\n        extend(dst, msg.head.subject.0.as_str().as_bytes());\n        extend(dst, b\" \");\n        //TODO: add API to http::Uri to encode without std::fmt\n        let _ = write!(FastWrite(dst), \"{} \", msg.head.subject.1);\n\n        match msg.head.version {\n            Version::HTTP_10 => extend(dst, b\"HTTP/1.0\"),\n            Version::HTTP_11 => extend(dst, b\"HTTP/1.1\"),\n            Version::HTTP_2 => {\n                debug!(\"request with HTTP2 version coerced to HTTP/1.1\");\n                extend(dst, b\"HTTP/1.1\");\n            }\n            other => panic!(\"unexpected request version: {:?}\", other),\n        }\n        extend(dst, b\"\\r\\n\");\n\n        if let Some(orig_headers) = msg.head.extensions.get::<HeaderCaseMap>() {\n            write_headers_original_case(\n                &msg.head.headers,\n                orig_headers,\n                dst,\n                msg.title_case_headers,\n            );\n        } else if msg.title_case_headers {\n            write_headers_title_case(&msg.head.headers, dst);\n        } else {\n            write_headers(&msg.head.headers, dst);\n        }\n\n        extend(dst, b\"\\r\\n\");\n        msg.head.headers.clear(); //TODO: remove when switching to drain()\n\n        Ok(body)\n    }\n\n    fn on_error(_err: &crate::Error) -> Option<MessageHead<Self::Outgoing>> {\n        // we can't tell the server about any errors it creates\n        None\n    }\n\n    fn is_client() -> bool {\n        true\n    }\n}\n\n#[cfg(feature = \"client\")]\nimpl Client {\n    /// Returns Some(length, wants_upgrade) if successful.\n    ///\n    /// Returns None if this message head should be skipped (like a 100 status).\n    fn decoder(\n        inc: &MessageHead<StatusCode>,\n        method: &mut Option<Method>,\n    ) -> Result<Option<(DecodedLength, bool)>, Parse> {\n        // According to https://tools.ietf.org/html/rfc7230#section-3.3.3\n        // 1. HEAD responses, and Status 1xx, 204, and 304 cannot have a body.\n        // 2. Status 2xx to a CONNECT cannot have a body.\n        // 3. Transfer-Encoding: chunked has a chunked body.\n        // 4. If multiple differing Content-Length headers or invalid, close connection.\n        // 5. Content-Length header has a sized body.\n        // 6. (irrelevant to Response)\n        // 7. Read till EOF.\n\n        match inc.subject.as_u16() {\n            101 => {\n                return Ok(Some((DecodedLength::ZERO, true)));\n            }\n            100 | 102..=199 => {\n                trace!(\"ignoring informational response: {}\", inc.subject.as_u16());\n                return Ok(None);\n            }\n            204 | 304 => return Ok(Some((DecodedLength::ZERO, false))),\n            _ => (),\n        }\n        match *method {\n            Some(Method::HEAD) => {\n                return Ok(Some((DecodedLength::ZERO, false)));\n            }\n            Some(Method::CONNECT) => {\n                if let 200..=299 = inc.subject.as_u16() {\n                    return Ok(Some((DecodedLength::ZERO, true)));\n                }\n            }\n            Some(_) => {}\n            None => {\n                trace!(\"Client::decoder is missing the Method\");\n            }\n        }\n\n        if inc.headers.contains_key(header::TRANSFER_ENCODING) {\n            // https://tools.ietf.org/html/rfc7230#section-3.3.3\n            // If Transfer-Encoding header is present, and 'chunked' is\n            // not the final encoding, and this is a Request, then it is\n            // malformed. A server should respond with 400 Bad Request.\n            if inc.version == Version::HTTP_10 {\n                debug!(\"HTTP/1.0 cannot have Transfer-Encoding header\");\n                Err(Parse::Header)\n            } else if headers::transfer_encoding_is_chunked(&inc.headers) {\n                Ok(Some((DecodedLength::CHUNKED, false)))\n            } else {\n                trace!(\"not chunked, read till eof\");\n                Ok(Some((DecodedLength::CLOSE_DELIMITED, false)))\n            }\n        } else if let Some(len) = headers::content_length_parse_all(&inc.headers) {\n            Ok(Some((DecodedLength::checked_new(len)?, false)))\n        } else if inc.headers.contains_key(header::CONTENT_LENGTH) {\n            debug!(\"illegal Content-Length header\");\n            Err(Parse::Header)\n        } else {\n            trace!(\"neither Transfer-Encoding nor Content-Length\");\n            Ok(Some((DecodedLength::CLOSE_DELIMITED, false)))\n        }\n    }\n    fn set_length(head: &mut RequestHead, body: Option<BodyLength>) -> Encoder {\n        let body = if let Some(body) = body {\n            body\n        } else {\n            head.headers.remove(header::TRANSFER_ENCODING);\n            return Encoder::length(0);\n        };\n\n        // HTTP/1.0 doesn't know about chunked\n        let can_chunked = head.version == Version::HTTP_11;\n        let headers = &mut head.headers;\n\n        // If the user already set specific headers, we should respect them, regardless\n        // of what the HttpBody knows about itself. They set them for a reason.\n\n        // Because of the borrow checker, we can't check the for an existing\n        // Content-Length header while holding an `Entry` for the Transfer-Encoding\n        // header, so unfortunately, we must do the check here, first.\n\n        let existing_con_len = headers::content_length_parse_all(headers);\n        let mut should_remove_con_len = false;\n\n        if !can_chunked {\n            // Chunked isn't legal, so if it is set, we need to remove it.\n            if headers.remove(header::TRANSFER_ENCODING).is_some() {\n                trace!(\"removing illegal transfer-encoding header\");\n            }\n\n            return if let Some(len) = existing_con_len {\n                Encoder::length(len)\n            } else if let BodyLength::Known(len) = body {\n                set_content_length(headers, len)\n            } else {\n                // HTTP/1.0 client requests without a content-length\n                // cannot have any body at all.\n                Encoder::length(0)\n            };\n        }\n\n        // If the user set a transfer-encoding, respect that. Let's just\n        // make sure `chunked` is the final encoding.\n        let encoder = match headers.entry(header::TRANSFER_ENCODING) {\n            Entry::Occupied(te) => {\n                should_remove_con_len = true;\n                if headers::is_chunked(te.iter()) {\n                    Some(Encoder::chunked())\n                } else {\n                    warn!(\"user provided transfer-encoding does not end in 'chunked'\");\n\n                    // There's a Transfer-Encoding, but it doesn't end in 'chunked'!\n                    // An example that could trigger this:\n                    //\n                    //     Transfer-Encoding: gzip\n                    //\n                    // This can be bad, depending on if this is a request or a\n                    // response.\n                    //\n                    // - A request is illegal if there is a `Transfer-Encoding`\n                    //   but it doesn't end in `chunked`.\n                    // - A response that has `Transfer-Encoding` but doesn't\n                    //   end in `chunked` isn't illegal, it just forces this\n                    //   to be close-delimited.\n                    //\n                    // We can try to repair this, by adding `chunked` ourselves.\n\n                    headers::add_chunked(te);\n                    Some(Encoder::chunked())\n                }\n            }\n            Entry::Vacant(te) => {\n                if let Some(len) = existing_con_len {\n                    Some(Encoder::length(len))\n                } else if let BodyLength::Unknown = body {\n                    // GET, HEAD, and CONNECT almost never have bodies.\n                    //\n                    // So instead of sending a \"chunked\" body with a 0-chunk,\n                    // assume no body here. If you *must* send a body,\n                    // set the headers explicitly.\n                    match head.subject.0 {\n                        Method::GET | Method::HEAD | Method::CONNECT => Some(Encoder::length(0)),\n                        _ => {\n                            te.insert(HeaderValue::from_static(\"chunked\"));\n                            Some(Encoder::chunked())\n                        }\n                    }\n                } else {\n                    None\n                }\n            }\n        };\n\n        // This is because we need a second mutable borrow to remove\n        // content-length header.\n        if let Some(encoder) = encoder {\n            if should_remove_con_len && existing_con_len.is_some() {\n                headers.remove(header::CONTENT_LENGTH);\n            }\n            return encoder;\n        }\n\n        // User didn't set transfer-encoding, AND we know body length,\n        // so we can just set the Content-Length automatically.\n\n        let len = if let BodyLength::Known(len) = body {\n            len\n        } else {\n            unreachable!(\"BodyLength::Unknown would set chunked\");\n        };\n\n        set_content_length(headers, len)\n    }\n}\n\nfn set_content_length(headers: &mut HeaderMap, len: u64) -> Encoder {\n    // At this point, there should not be a valid Content-Length\n    // header. However, since we'll be indexing in anyways, we can\n    // warn the user if there was an existing illegal header.\n    //\n    // Or at least, we can in theory. It's actually a little bit slower,\n    // so perhaps only do that while the user is developing/testing.\n\n    if cfg!(debug_assertions) {\n        match headers.entry(header::CONTENT_LENGTH) {\n            Entry::Occupied(mut cl) => {\n                // Internal sanity check, we should have already determined\n                // that the header was illegal before calling this function.\n                debug_assert!(headers::content_length_parse_all_values(cl.iter()).is_none());\n                // Uh oh, the user set `Content-Length` headers, but set bad ones.\n                // This would be an illegal message anyways, so let's try to repair\n                // with our known good length.\n                error!(\"user provided content-length header was invalid\");\n\n                cl.insert(HeaderValue::from(len));\n                Encoder::length(len)\n            }\n            Entry::Vacant(cl) => {\n                cl.insert(HeaderValue::from(len));\n                Encoder::length(len)\n            }\n        }\n    } else {\n        headers.insert(header::CONTENT_LENGTH, HeaderValue::from(len));\n        Encoder::length(len)\n    }\n}\n\n#[derive(Clone, Copy)]\nstruct HeaderIndices {\n    name: (usize, usize),\n    value: (usize, usize),\n}\n\nfn record_header_indices(\n    bytes: &[u8],\n    headers: &[httparse::Header<'_>],\n    indices: &mut [MaybeUninit<HeaderIndices>],\n) -> Result<(), crate::error::Parse> {\n    let bytes_ptr = bytes.as_ptr() as usize;\n\n    for (header, indices) in headers.iter().zip(indices.iter_mut()) {\n        if header.name.len() >= (1 << 16) {\n            debug!(\"header name larger than 64kb: {:?}\", header.name);\n            return Err(crate::error::Parse::TooLarge);\n        }\n        let name_start = header.name.as_ptr() as usize - bytes_ptr;\n        let name_end = name_start + header.name.len();\n        let value_start = header.value.as_ptr() as usize - bytes_ptr;\n        let value_end = value_start + header.value.len();\n\n        // FIXME(maybe_uninit_extra)\n        // FIXME(addr_of)\n        // Currently we don't have `ptr::addr_of_mut` in stable rust or\n        // MaybeUninit::write, so this is some way of assigning into a MaybeUninit\n        // safely\n        let new_header_indices = HeaderIndices {\n            name: (name_start, name_end),\n            value: (value_start, value_end),\n        };\n        *indices = MaybeUninit::new(new_header_indices);\n    }\n\n    Ok(())\n}\n\n// Write header names as title case. The header name is assumed to be ASCII,\n// therefore it is trivial to convert an ASCII character from lowercase to\n// uppercase. It is as simple as XORing the lowercase character byte with\n// space.\nfn title_case(dst: &mut Vec<u8>, name: &[u8]) {\n    dst.reserve(name.len());\n\n    let mut iter = name.iter();\n\n    // Uppercase the first character\n    if let Some(c) = iter.next() {\n        if *c >= b'a' && *c <= b'z' {\n            dst.push(*c ^ b' ');\n        } else {\n            dst.push(*c);\n        }\n    }\n\n    while let Some(c) = iter.next() {\n        dst.push(*c);\n\n        if *c == b'-' {\n            if let Some(c) = iter.next() {\n                if *c >= b'a' && *c <= b'z' {\n                    dst.push(*c ^ b' ');\n                } else {\n                    dst.push(*c);\n                }\n            }\n        }\n    }\n}\n\nfn write_headers_title_case(headers: &HeaderMap, dst: &mut Vec<u8>) {\n    for (name, value) in headers {\n        title_case(dst, name.as_str().as_bytes());\n        extend(dst, b\": \");\n        extend(dst, value.as_bytes());\n        extend(dst, b\"\\r\\n\");\n    }\n}\n\nfn write_headers(headers: &HeaderMap, dst: &mut Vec<u8>) {\n    for (name, value) in headers {\n        extend(dst, name.as_str().as_bytes());\n        extend(dst, b\": \");\n        extend(dst, value.as_bytes());\n        extend(dst, b\"\\r\\n\");\n    }\n}\n\n#[cold]\nfn write_headers_original_case(\n    headers: &HeaderMap,\n    orig_case: &HeaderCaseMap,\n    dst: &mut Vec<u8>,\n    title_case_headers: bool,\n) {\n    // For each header name/value pair, there may be a value in the casemap\n    // that corresponds to the HeaderValue. So, we iterator all the keys,\n    // and for each one, try to pair the originally cased name with the value.\n    //\n    // TODO: consider adding http::HeaderMap::entries() iterator\n    for name in headers.keys() {\n        let mut names = orig_case.get_all(name);\n\n        for value in headers.get_all(name) {\n            if let Some(orig_name) = names.next() {\n                extend(dst, orig_name.as_ref());\n            } else if title_case_headers {\n                title_case(dst, name.as_str().as_bytes());\n            } else {\n                extend(dst, name.as_str().as_bytes());\n            }\n\n            // Wanted for curl test cases that send `X-Custom-Header:\\r\\n`\n            if value.is_empty() {\n                extend(dst, b\":\\r\\n\");\n            } else {\n                extend(dst, b\": \");\n                extend(dst, value.as_bytes());\n                extend(dst, b\"\\r\\n\");\n            }\n        }\n    }\n}\n\nstruct FastWrite<'a>(&'a mut Vec<u8>);\n\nimpl<'a> fmt::Write for FastWrite<'a> {\n    #[inline]\n    fn write_str(&mut self, s: &str) -> fmt::Result {\n        extend(self.0, s.as_bytes());\n        Ok(())\n    }\n\n    #[inline]\n    fn write_fmt(&mut self, args: fmt::Arguments<'_>) -> fmt::Result {\n        fmt::write(self, args)\n    }\n}\n\n#[inline]\nfn extend(dst: &mut Vec<u8>, data: &[u8]) {\n    dst.extend_from_slice(data);\n}\n\n#[cfg(test)]\nmod tests {\n    use bytes::BytesMut;\n\n    use super::*;\n\n    #[test]\n    fn test_parse_request() {\n        let _ = pretty_env_logger::try_init();\n        let mut raw = BytesMut::from(\"GET /echo HTTP/1.1\\r\\nHost: hyper.rs\\r\\n\\r\\n\");\n        let mut method = None;\n        let msg = Server::parse(\n            &mut raw,\n            ParseContext {\n                cached_headers: &mut None,\n                req_method: &mut method,\n                h1_parser_config: Default::default(),\n                preserve_header_case: false,\n                h09_responses: false,\n            },\n        )\n        .unwrap()\n        .unwrap();\n        assert_eq!(raw.len(), 0);\n        assert_eq!(msg.head.subject.0, crate::Method::GET);\n        assert_eq!(msg.head.subject.1, \"/echo\");\n        assert_eq!(msg.head.version, crate::Version::HTTP_11);\n        assert_eq!(msg.head.headers.len(), 1);\n        assert_eq!(msg.head.headers[\"Host\"], \"hyper.rs\");\n        assert_eq!(method, Some(crate::Method::GET));\n    }\n\n    #[test]\n    fn test_parse_response() {\n        let _ = pretty_env_logger::try_init();\n        let mut raw = BytesMut::from(\"HTTP/1.1 200 OK\\r\\nContent-Length: 0\\r\\n\\r\\n\");\n        let ctx = ParseContext {\n            cached_headers: &mut None,\n            req_method: &mut Some(crate::Method::GET),\n            h1_parser_config: Default::default(),\n            preserve_header_case: false,\n            h09_responses: false,\n        };\n        let msg = Client::parse(&mut raw, ctx).unwrap().unwrap();\n        assert_eq!(raw.len(), 0);\n        assert_eq!(msg.head.subject, crate::StatusCode::OK);\n        assert_eq!(msg.head.version, crate::Version::HTTP_11);\n        assert_eq!(msg.head.headers.len(), 1);\n        assert_eq!(msg.head.headers[\"Content-Length\"], \"0\");\n    }\n\n    #[test]\n    fn test_parse_request_errors() {\n        let mut raw = BytesMut::from(\"GET htt:p// HTTP/1.1\\r\\nHost: hyper.rs\\r\\n\\r\\n\");\n        let ctx = ParseContext {\n            cached_headers: &mut None,\n            req_method: &mut None,\n            h1_parser_config: Default::default(),\n            preserve_header_case: false,\n            h09_responses: false,\n        };\n        Server::parse(&mut raw, ctx).unwrap_err();\n    }\n\n    const H09_RESPONSE: &'static str = \"Baguettes are super delicious, don't you agree?\";\n\n    #[test]\n    fn test_parse_response_h09_allowed() {\n        let _ = pretty_env_logger::try_init();\n        let mut raw = BytesMut::from(H09_RESPONSE);\n        let ctx = ParseContext {\n            cached_headers: &mut None,\n            req_method: &mut Some(crate::Method::GET),\n            h1_parser_config: Default::default(),\n            preserve_header_case: false,\n            h09_responses: true,\n        };\n        let msg = Client::parse(&mut raw, ctx).unwrap().unwrap();\n        assert_eq!(raw, H09_RESPONSE);\n        assert_eq!(msg.head.subject, crate::StatusCode::OK);\n        assert_eq!(msg.head.version, crate::Version::HTTP_09);\n        assert_eq!(msg.head.headers.len(), 0);\n    }\n\n    #[test]\n    fn test_parse_response_h09_rejected() {\n        let _ = pretty_env_logger::try_init();\n        let mut raw = BytesMut::from(H09_RESPONSE);\n        let ctx = ParseContext {\n            cached_headers: &mut None,\n            req_method: &mut Some(crate::Method::GET),\n            h1_parser_config: Default::default(),\n            preserve_header_case: false,\n            h09_responses: false,\n        };\n        Client::parse(&mut raw, ctx).unwrap_err();\n        assert_eq!(raw, H09_RESPONSE);\n    }\n\n    const RESPONSE_WITH_WHITESPACE_BETWEEN_HEADER_NAME_AND_COLON: &'static str =\n        \"HTTP/1.1 200 OK\\r\\nAccess-Control-Allow-Credentials : true\\r\\n\\r\\n\";\n\n    #[test]\n    fn test_parse_allow_response_with_spaces_before_colons() {\n        use httparse::ParserConfig;\n\n        let _ = pretty_env_logger::try_init();\n        let mut raw = BytesMut::from(RESPONSE_WITH_WHITESPACE_BETWEEN_HEADER_NAME_AND_COLON);\n        let mut h1_parser_config = ParserConfig::default();\n        h1_parser_config.allow_spaces_after_header_name_in_responses(true);\n        let ctx = ParseContext {\n            cached_headers: &mut None,\n            req_method: &mut Some(crate::Method::GET),\n            h1_parser_config,\n            preserve_header_case: false,\n            h09_responses: false,\n        };\n        let msg = Client::parse(&mut raw, ctx).unwrap().unwrap();\n        assert_eq!(raw.len(), 0);\n        assert_eq!(msg.head.subject, crate::StatusCode::OK);\n        assert_eq!(msg.head.version, crate::Version::HTTP_11);\n        assert_eq!(msg.head.headers.len(), 1);\n        assert_eq!(msg.head.headers[\"Access-Control-Allow-Credentials\"], \"true\");\n    }\n\n    #[test]\n    fn test_parse_reject_response_with_spaces_before_colons() {\n        let _ = pretty_env_logger::try_init();\n        let mut raw = BytesMut::from(RESPONSE_WITH_WHITESPACE_BETWEEN_HEADER_NAME_AND_COLON);\n        let ctx = ParseContext {\n            cached_headers: &mut None,\n            req_method: &mut Some(crate::Method::GET),\n            h1_parser_config: Default::default(),\n            preserve_header_case: false,\n            h09_responses: false,\n        };\n        Client::parse(&mut raw, ctx).unwrap_err();\n    }\n\n    #[test]\n    fn test_parse_preserve_header_case_in_request() {\n        let mut raw =\n            BytesMut::from(\"GET / HTTP/1.1\\r\\nHost: hyper.rs\\r\\nX-BREAD: baguette\\r\\n\\r\\n\");\n        let ctx = ParseContext {\n            cached_headers: &mut None,\n            req_method: &mut None,\n            h1_parser_config: Default::default(),\n            preserve_header_case: true,\n            h09_responses: false,\n        };\n        let parsed_message = Server::parse(&mut raw, ctx).unwrap().unwrap();\n        let orig_headers = parsed_message\n            .head\n            .extensions\n            .get::<HeaderCaseMap>()\n            .unwrap();\n        assert_eq!(\n            orig_headers\n                .get_all_internal(&HeaderName::from_static(\"host\"))\n                .into_iter()\n                .collect::<Vec<_>>(),\n            vec![&Bytes::from(\"Host\")]\n        );\n        assert_eq!(\n            orig_headers\n                .get_all_internal(&HeaderName::from_static(\"x-bread\"))\n                .into_iter()\n                .collect::<Vec<_>>(),\n            vec![&Bytes::from(\"X-BREAD\")]\n        );\n    }\n\n    #[test]\n    fn test_decoder_request() {\n        fn parse(s: &str) -> ParsedMessage<RequestLine> {\n            let mut bytes = BytesMut::from(s);\n            Server::parse(\n                &mut bytes,\n                ParseContext {\n                    cached_headers: &mut None,\n                    req_method: &mut None,\n                    h1_parser_config: Default::default(),\n                    preserve_header_case: false,\n                    h09_responses: false,\n                },\n            )\n            .expect(\"parse ok\")\n            .expect(\"parse complete\")\n        }\n\n        fn parse_err(s: &str, comment: &str) -> crate::error::Parse {\n            let mut bytes = BytesMut::from(s);\n            Server::parse(\n                &mut bytes,\n                ParseContext {\n                    cached_headers: &mut None,\n                    req_method: &mut None,\n                    h1_parser_config: Default::default(),\n                    preserve_header_case: false,\n                    h09_responses: false,\n                },\n            )\n            .expect_err(comment)\n        }\n\n        // no length or transfer-encoding means 0-length body\n        assert_eq!(\n            parse(\n                \"\\\n                 GET / HTTP/1.1\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::ZERO\n        );\n\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::ZERO\n        );\n\n        // transfer-encoding: chunked\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 transfer-encoding: chunked\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 transfer-encoding: gzip, chunked\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 transfer-encoding: gzip\\r\\n\\\n                 transfer-encoding: chunked\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        // content-length\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::new(10)\n        );\n\n        // transfer-encoding and content-length = chunked\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 transfer-encoding: chunked\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 transfer-encoding: chunked\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 transfer-encoding: gzip\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 transfer-encoding: chunked\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        // multiple content-lengths of same value are fine\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::new(10)\n        );\n\n        // multiple content-lengths with different values is an error\n        parse_err(\n            \"\\\n             POST / HTTP/1.1\\r\\n\\\n             content-length: 10\\r\\n\\\n             content-length: 11\\r\\n\\\n             \\r\\n\\\n             \",\n            \"multiple content-lengths\",\n        );\n\n        // transfer-encoding that isn't chunked is an error\n        parse_err(\n            \"\\\n             POST / HTTP/1.1\\r\\n\\\n             transfer-encoding: gzip\\r\\n\\\n             \\r\\n\\\n             \",\n            \"transfer-encoding but not chunked\",\n        );\n\n        parse_err(\n            \"\\\n             POST / HTTP/1.1\\r\\n\\\n             transfer-encoding: chunked, gzip\\r\\n\\\n             \\r\\n\\\n             \",\n            \"transfer-encoding doesn't end in chunked\",\n        );\n\n        parse_err(\n            \"\\\n             POST / HTTP/1.1\\r\\n\\\n             transfer-encoding: chunked\\r\\n\\\n             transfer-encoding: afterlol\\r\\n\\\n             \\r\\n\\\n             \",\n            \"transfer-encoding multiple lines doesn't end in chunked\",\n        );\n\n        // http/1.0\n\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.0\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::new(10)\n        );\n\n        // 1.0 doesn't understand chunked, so its an error\n        parse_err(\n            \"\\\n             POST / HTTP/1.0\\r\\n\\\n             transfer-encoding: chunked\\r\\n\\\n             \\r\\n\\\n             \",\n            \"1.0 chunked\",\n        );\n    }\n\n    #[test]\n    fn test_decoder_response() {\n        fn parse(s: &str) -> ParsedMessage<StatusCode> {\n            parse_with_method(s, Method::GET)\n        }\n\n        fn parse_ignores(s: &str) {\n            let mut bytes = BytesMut::from(s);\n            assert!(Client::parse(\n                &mut bytes,\n                ParseContext {\n                    cached_headers: &mut None,\n                    req_method: &mut Some(Method::GET),\n                    h1_parser_config: Default::default(),\n                    preserve_header_case: false,\n                    h09_responses: false,\n                }\n            )\n            .expect(\"parse ok\")\n            .is_none())\n        }\n\n        fn parse_with_method(s: &str, m: Method) -> ParsedMessage<StatusCode> {\n            let mut bytes = BytesMut::from(s);\n            Client::parse(\n                &mut bytes,\n                ParseContext {\n                    cached_headers: &mut None,\n                    req_method: &mut Some(m),\n                    h1_parser_config: Default::default(),\n                    preserve_header_case: false,\n                    h09_responses: false,\n                },\n            )\n            .expect(\"parse ok\")\n            .expect(\"parse complete\")\n        }\n\n        fn parse_err(s: &str) -> crate::error::Parse {\n            let mut bytes = BytesMut::from(s);\n            Client::parse(\n                &mut bytes,\n                ParseContext {\n                    cached_headers: &mut None,\n                    req_method: &mut Some(Method::GET),\n                    h1_parser_config: Default::default(),\n                    preserve_header_case: false,\n                    h09_responses: false,\n                },\n            )\n            .expect_err(\"parse should err\")\n        }\n\n        // no content-length or transfer-encoding means close-delimited\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CLOSE_DELIMITED\n        );\n\n        // 204 and 304 never have a body\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 204 No Content\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::ZERO\n        );\n\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 304 Not Modified\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::ZERO\n        );\n\n        // content-length\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 content-length: 8\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::new(8)\n        );\n\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 content-length: 8\\r\\n\\\n                 content-length: 8\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::new(8)\n        );\n\n        parse_err(\n            \"\\\n             HTTP/1.1 200 OK\\r\\n\\\n             content-length: 8\\r\\n\\\n             content-length: 9\\r\\n\\\n             \\r\\n\\\n             \",\n        );\n\n        // transfer-encoding: chunked\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 transfer-encoding: chunked\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        // transfer-encoding not-chunked is close-delimited\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 transfer-encoding: yolo\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CLOSE_DELIMITED\n        );\n\n        // transfer-encoding and content-length = chunked\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 transfer-encoding: chunked\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        // HEAD can have content-length, but not body\n        assert_eq!(\n            parse_with_method(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 content-length: 8\\r\\n\\\n                 \\r\\n\\\n                 \",\n                Method::HEAD\n            )\n            .decode,\n            DecodedLength::ZERO\n        );\n\n        // CONNECT with 200 never has body\n        {\n            let msg = parse_with_method(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 \\r\\n\\\n                 \",\n                Method::CONNECT,\n            );\n            assert_eq!(msg.decode, DecodedLength::ZERO);\n            assert!(!msg.keep_alive, \"should be upgrade\");\n            assert!(msg.wants_upgrade, \"should be upgrade\");\n        }\n\n        // CONNECT receiving non 200 can have a body\n        assert_eq!(\n            parse_with_method(\n                \"\\\n                 HTTP/1.1 400 Bad Request\\r\\n\\\n                 \\r\\n\\\n                 \",\n                Method::CONNECT\n            )\n            .decode,\n            DecodedLength::CLOSE_DELIMITED\n        );\n\n        // 1xx status codes\n        parse_ignores(\n            \"\\\n             HTTP/1.1 100 Continue\\r\\n\\\n             \\r\\n\\\n             \",\n        );\n\n        parse_ignores(\n            \"\\\n             HTTP/1.1 103 Early Hints\\r\\n\\\n             \\r\\n\\\n             \",\n        );\n\n        // 101 upgrade not supported yet\n        {\n            let msg = parse(\n                \"\\\n                 HTTP/1.1 101 Switching Protocols\\r\\n\\\n                 \\r\\n\\\n                 \",\n            );\n            assert_eq!(msg.decode, DecodedLength::ZERO);\n            assert!(!msg.keep_alive, \"should be last\");\n            assert!(msg.wants_upgrade, \"should be upgrade\");\n        }\n\n        // http/1.0\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.0 200 OK\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CLOSE_DELIMITED\n        );\n\n        // 1.0 doesn't understand chunked\n        parse_err(\n            \"\\\n             HTTP/1.0 200 OK\\r\\n\\\n             transfer-encoding: chunked\\r\\n\\\n             \\r\\n\\\n             \",\n        );\n\n        // keep-alive\n        assert!(\n            parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 content-length: 0\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .keep_alive,\n            \"HTTP/1.1 keep-alive is default\"\n        );\n\n        assert!(\n            !parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 content-length: 0\\r\\n\\\n                 connection: foo, close, bar\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .keep_alive,\n            \"connection close is always close\"\n        );\n\n        assert!(\n            !parse(\n                \"\\\n                 HTTP/1.0 200 OK\\r\\n\\\n                 content-length: 0\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .keep_alive,\n            \"HTTP/1.0 close is default\"\n        );\n\n        assert!(\n            parse(\n                \"\\\n                 HTTP/1.0 200 OK\\r\\n\\\n                 content-length: 0\\r\\n\\\n                 connection: foo, keep-alive, bar\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .keep_alive,\n            \"connection keep-alive is always keep-alive\"\n        );\n    }\n\n    #[test]\n    fn test_client_request_encode_title_case() {\n        use crate::proto::BodyLength;\n        use http::header::HeaderValue;\n\n        let mut head = MessageHead::default();\n        head.headers\n            .insert(\"content-length\", HeaderValue::from_static(\"10\"));\n        head.headers\n            .insert(\"content-type\", HeaderValue::from_static(\"application/json\"));\n        head.headers.insert(\"*-*\", HeaderValue::from_static(\"o_o\"));\n\n        let mut vec = Vec::new();\n        Client::encode(\n            Encode {\n                head: &mut head,\n                body: Some(BodyLength::Known(10)),\n                keep_alive: true,\n                req_method: &mut None,\n                title_case_headers: true,\n            },\n            &mut vec,\n        )\n        .unwrap();\n\n        assert_eq!(vec, b\"GET / HTTP/1.1\\r\\nContent-Length: 10\\r\\nContent-Type: application/json\\r\\n*-*: o_o\\r\\n\\r\\n\".to_vec());\n    }\n\n    #[test]\n    fn test_client_request_encode_orig_case() {\n        use crate::proto::BodyLength;\n        use http::header::{HeaderValue, CONTENT_LENGTH};\n\n        let mut head = MessageHead::default();\n        head.headers\n            .insert(\"content-length\", HeaderValue::from_static(\"10\"));\n        head.headers\n            .insert(\"content-type\", HeaderValue::from_static(\"application/json\"));\n\n        let mut orig_headers = HeaderCaseMap::default();\n        orig_headers.insert(CONTENT_LENGTH, \"CONTENT-LENGTH\".into());\n        head.extensions.insert(orig_headers);\n\n        let mut vec = Vec::new();\n        Client::encode(\n            Encode {\n                head: &mut head,\n                body: Some(BodyLength::Known(10)),\n                keep_alive: true,\n                req_method: &mut None,\n                title_case_headers: false,\n            },\n            &mut vec,\n        )\n        .unwrap();\n\n        assert_eq!(\n            &*vec,\n            b\"GET / HTTP/1.1\\r\\nCONTENT-LENGTH: 10\\r\\ncontent-type: application/json\\r\\n\\r\\n\"\n                .as_ref(),\n        );\n    }\n    #[test]\n    fn test_client_request_encode_orig_and_title_case() {\n        use crate::proto::BodyLength;\n        use http::header::{HeaderValue, CONTENT_LENGTH};\n\n        let mut head = MessageHead::default();\n        head.headers\n            .insert(\"content-length\", HeaderValue::from_static(\"10\"));\n        head.headers\n            .insert(\"content-type\", HeaderValue::from_static(\"application/json\"));\n\n        let mut orig_headers = HeaderCaseMap::default();\n        orig_headers.insert(CONTENT_LENGTH, \"CONTENT-LENGTH\".into());\n        head.extensions.insert(orig_headers);\n\n        let mut vec = Vec::new();\n        Client::encode(\n            Encode {\n                head: &mut head,\n                body: Some(BodyLength::Known(10)),\n                keep_alive: true,\n                req_method: &mut None,\n                title_case_headers: true,\n            },\n            &mut vec,\n        )\n        .unwrap();\n\n        assert_eq!(\n            &*vec,\n            b\"GET / HTTP/1.1\\r\\nCONTENT-LENGTH: 10\\r\\nContent-Type: application/json\\r\\n\\r\\n\"\n                .as_ref(),\n        );\n    }\n\n    #[test]\n    fn test_server_encode_connect_method() {\n        let mut head = MessageHead::default();\n\n        let mut vec = Vec::new();\n        let encoder = Server::encode(\n            Encode {\n                head: &mut head,\n                body: None,\n                keep_alive: true,\n                req_method: &mut Some(Method::CONNECT),\n                title_case_headers: false,\n            },\n            &mut vec,\n        )\n        .unwrap();\n\n        assert!(encoder.is_last());\n    }\n\n    #[test]\n    fn test_server_response_encode_title_case() {\n        use crate::proto::BodyLength;\n        use http::header::HeaderValue;\n\n        let mut head = MessageHead::default();\n        head.headers\n            .insert(\"content-length\", HeaderValue::from_static(\"10\"));\n        head.headers\n            .insert(\"content-type\", HeaderValue::from_static(\"application/json\"));\n\n        let mut vec = Vec::new();\n        Server::encode(\n            Encode {\n                head: &mut head,\n                body: Some(BodyLength::Known(10)),\n                keep_alive: true,\n                req_method: &mut None,\n                title_case_headers: true,\n            },\n            &mut vec,\n        )\n        .unwrap();\n\n        let expected_response =\n            b\"HTTP/1.1 200 OK\\r\\nContent-Length: 10\\r\\nContent-Type: application/json\\r\\n\";\n\n        assert_eq!(&vec[..expected_response.len()], &expected_response[..]);\n    }\n\n    #[test]\n    fn test_server_response_encode_orig_case() {\n        use crate::proto::BodyLength;\n        use http::header::{HeaderValue, CONTENT_LENGTH};\n\n        let mut head = MessageHead::default();\n        head.headers\n            .insert(\"content-length\", HeaderValue::from_static(\"10\"));\n        head.headers\n            .insert(\"content-type\", HeaderValue::from_static(\"application/json\"));\n\n        let mut orig_headers = HeaderCaseMap::default();\n        orig_headers.insert(CONTENT_LENGTH, \"CONTENT-LENGTH\".into());\n        head.extensions.insert(orig_headers);\n\n        let mut vec = Vec::new();\n        Server::encode(\n            Encode {\n                head: &mut head,\n                body: Some(BodyLength::Known(10)),\n                keep_alive: true,\n                req_method: &mut None,\n                title_case_headers: false,\n            },\n            &mut vec,\n        )\n        .unwrap();\n\n        let expected_response =\n            b\"HTTP/1.1 200 OK\\r\\nCONTENT-LENGTH: 10\\r\\ncontent-type: application/json\\r\\ndate: \";\n\n        assert_eq!(&vec[..expected_response.len()], &expected_response[..]);\n    }\n\n    #[test]\n    fn test_server_response_encode_orig_and_title_case() {\n        use crate::proto::BodyLength;\n        use http::header::{HeaderValue, CONTENT_LENGTH};\n\n        let mut head = MessageHead::default();\n        head.headers\n            .insert(\"content-length\", HeaderValue::from_static(\"10\"));\n        head.headers\n            .insert(\"content-type\", HeaderValue::from_static(\"application/json\"));\n\n        let mut orig_headers = HeaderCaseMap::default();\n        orig_headers.insert(CONTENT_LENGTH, \"CONTENT-LENGTH\".into());\n        head.extensions.insert(orig_headers);\n\n        let mut vec = Vec::new();\n        Server::encode(\n            Encode {\n                head: &mut head,\n                body: Some(BodyLength::Known(10)),\n                keep_alive: true,\n                req_method: &mut None,\n                title_case_headers: true,\n            },\n            &mut vec,\n        )\n        .unwrap();\n\n        let expected_response =\n            b\"HTTP/1.1 200 OK\\r\\nCONTENT-LENGTH: 10\\r\\nContent-Type: application/json\\r\\nDate: \";\n\n        assert_eq!(&vec[..expected_response.len()], &expected_response[..]);\n    }\n\n    #[test]\n    fn parse_header_htabs() {\n        let mut bytes = BytesMut::from(\"HTTP/1.1 200 OK\\r\\nserver: hello\\tworld\\r\\n\\r\\n\");\n        let parsed = Client::parse(\n            &mut bytes,\n            ParseContext {\n                cached_headers: &mut None,\n                req_method: &mut Some(Method::GET),\n                h1_parser_config: Default::default(),\n                preserve_header_case: false,\n                h09_responses: false,\n            },\n        )\n        .expect(\"parse ok\")\n        .expect(\"parse complete\");\n\n        assert_eq!(parsed.head.headers[\"server\"], \"hello\\tworld\");\n    }\n\n    #[test]\n    fn test_write_headers_orig_case_empty_value() {\n        let mut headers = HeaderMap::new();\n        let name = http::header::HeaderName::from_static(\"x-empty\");\n        headers.insert(&name, \"\".parse().expect(\"parse empty\"));\n        let mut orig_cases = HeaderCaseMap::default();\n        orig_cases.insert(name, Bytes::from_static(b\"X-EmptY\"));\n\n        let mut dst = Vec::new();\n        super::write_headers_original_case(&headers, &orig_cases, &mut dst, false);\n\n        assert_eq!(\n            dst, b\"X-EmptY:\\r\\n\",\n            \"there should be no space between the colon and CRLF\"\n        );\n    }\n\n    #[test]\n    fn test_write_headers_orig_case_multiple_entries() {\n        let mut headers = HeaderMap::new();\n        let name = http::header::HeaderName::from_static(\"x-empty\");\n        headers.insert(&name, \"a\".parse().unwrap());\n        headers.append(&name, \"b\".parse().unwrap());\n\n        let mut orig_cases = HeaderCaseMap::default();\n        orig_cases.insert(name.clone(), Bytes::from_static(b\"X-Empty\"));\n        orig_cases.append(name, Bytes::from_static(b\"X-EMPTY\"));\n\n        let mut dst = Vec::new();\n        super::write_headers_original_case(&headers, &orig_cases, &mut dst, false);\n\n        assert_eq!(dst, b\"X-Empty: a\\r\\nX-EMPTY: b\\r\\n\");\n    }\n\n    #[cfg(feature = \"nightly\")]\n    use test::Bencher;\n\n    #[cfg(feature = \"nightly\")]\n    #[bench]\n    fn bench_parse_incoming(b: &mut Bencher) {\n        let mut raw = BytesMut::from(\n            &b\"GET /super_long_uri/and_whatever?what_should_we_talk_about/\\\n            I_wonder/Hard_to_write_in_an_uri_after_all/you_have_to_make\\\n            _up_the_punctuation_yourself/how_fun_is_that?test=foo&test1=\\\n            foo1&test2=foo2&test3=foo3&test4=foo4 HTTP/1.1\\r\\nHost: \\\n            hyper.rs\\r\\nAccept: a lot of things\\r\\nAccept-Charset: \\\n            utf8\\r\\nAccept-Encoding: *\\r\\nAccess-Control-Allow-\\\n            Credentials: None\\r\\nAccess-Control-Allow-Origin: None\\r\\n\\\n            Access-Control-Allow-Methods: None\\r\\nAccess-Control-Allow-\\\n            Headers: None\\r\\nContent-Encoding: utf8\\r\\nContent-Security-\\\n            Policy: None\\r\\nContent-Type: text/html\\r\\nOrigin: hyper\\\n            \\r\\nSec-Websocket-Extensions: It looks super important!\\r\\n\\\n            Sec-Websocket-Origin: hyper\\r\\nSec-Websocket-Version: 4.3\\r\\\n            \\nStrict-Transport-Security: None\\r\\nUser-Agent: hyper\\r\\n\\\n            X-Content-Duration: None\\r\\nX-Content-Security-Policy: None\\\n            \\r\\nX-DNSPrefetch-Control: None\\r\\nX-Frame-Options: \\\n            Something important obviously\\r\\nX-Requested-With: Nothing\\\n            \\r\\n\\r\\n\"[..],\n        );\n        let len = raw.len();\n        let mut headers = Some(HeaderMap::new());\n\n        b.bytes = len as u64;\n        b.iter(|| {\n            let mut msg = Server::parse(\n                &mut raw,\n                ParseContext {\n                    cached_headers: &mut headers,\n                    req_method: &mut None,\n                    h1_parser_config: Default::default(),\n                    preserve_header_case: false,\n                    h09_responses: false,\n                },\n            )\n            .unwrap()\n            .unwrap();\n            ::test::black_box(&msg);\n            msg.head.headers.clear();\n            headers = Some(msg.head.headers);\n            restart(&mut raw, len);\n        });\n\n        fn restart(b: &mut BytesMut, len: usize) {\n            b.reserve(1);\n            unsafe {\n                b.set_len(len);\n            }\n        }\n    }\n\n    #[cfg(feature = \"nightly\")]\n    #[bench]\n    fn bench_parse_short(b: &mut Bencher) {\n        let s = &b\"GET / HTTP/1.1\\r\\nHost: localhost:8080\\r\\n\\r\\n\"[..];\n        let mut raw = BytesMut::from(s);\n        let len = raw.len();\n        let mut headers = Some(HeaderMap::new());\n\n        b.bytes = len as u64;\n        b.iter(|| {\n            let mut msg = Server::parse(\n                &mut raw,\n                ParseContext {\n                    cached_headers: &mut headers,\n                    req_method: &mut None,\n                    h1_parser_config: Default::default(),\n                    preserve_header_case: false,\n                    h09_responses: false,\n                },\n            )\n            .unwrap()\n            .unwrap();\n            ::test::black_box(&msg);\n            msg.head.headers.clear();\n            headers = Some(msg.head.headers);\n            restart(&mut raw, len);\n        });\n\n        fn restart(b: &mut BytesMut, len: usize) {\n            b.reserve(1);\n            unsafe {\n                b.set_len(len);\n            }\n        }\n    }\n\n    #[cfg(feature = \"nightly\")]\n    #[bench]\n    fn bench_server_encode_headers_preset(b: &mut Bencher) {\n        use crate::proto::BodyLength;\n        use http::header::HeaderValue;\n\n        let len = 108;\n        b.bytes = len as u64;\n\n        let mut head = MessageHead::default();\n        let mut headers = HeaderMap::new();\n        headers.insert(\"content-length\", HeaderValue::from_static(\"10\"));\n        headers.insert(\"content-type\", HeaderValue::from_static(\"application/json\"));\n\n        b.iter(|| {\n            let mut vec = Vec::new();\n            head.headers = headers.clone();\n            Server::encode(\n                Encode {\n                    head: &mut head,\n                    body: Some(BodyLength::Known(10)),\n                    keep_alive: true,\n                    req_method: &mut Some(Method::GET),\n                    title_case_headers: false,\n                },\n                &mut vec,\n            )\n            .unwrap();\n            assert_eq!(vec.len(), len);\n            ::test::black_box(vec);\n        })\n    }\n\n    #[cfg(feature = \"nightly\")]\n    #[bench]\n    fn bench_server_encode_no_headers(b: &mut Bencher) {\n        use crate::proto::BodyLength;\n\n        let len = 76;\n        b.bytes = len as u64;\n\n        let mut head = MessageHead::default();\n        let mut vec = Vec::with_capacity(128);\n\n        b.iter(|| {\n            Server::encode(\n                Encode {\n                    head: &mut head,\n                    body: Some(BodyLength::Known(10)),\n                    keep_alive: true,\n                    req_method: &mut Some(Method::GET),\n                    title_case_headers: false,\n                },\n                &mut vec,\n            )\n            .unwrap();\n            assert_eq!(vec.len(), len);\n            ::test::black_box(&vec);\n\n            vec.clear();\n        })\n    }\n}\n"
  },
  {
    "project": "hyper",
    "target": 1,
    "commit_id": "16e859b27cb7ee1bae0b1cfc8fcea9131649666c",
    "func": "#![allow(deprecated)]\n\nuse std::fmt::{self, Write};\nuse std::mem::{self, MaybeUninit};\n\n#[cfg(any(test, feature = \"server\", feature = \"ffi\"))]\nuse bytes::Bytes;\nuse bytes::BytesMut;\n#[cfg(feature = \"server\")]\nuse http::header::ValueIter;\nuse http::header::{self, Entry, HeaderName, HeaderValue};\nuse http::{HeaderMap, Method, StatusCode, Version};\n\nuse crate::body::DecodedLength;\n#[cfg(feature = \"server\")]\nuse crate::common::date;\nuse crate::error::Parse;\nuse crate::ext::HeaderCaseMap;\nuse crate::headers;\nuse crate::proto::h1::{\n    Encode, Encoder, Http1Transaction, ParseContext, ParseResult, ParsedMessage,\n};\nuse crate::proto::{BodyLength, MessageHead, RequestHead, RequestLine};\n\nconst MAX_HEADERS: usize = 100;\nconst AVERAGE_HEADER_SIZE: usize = 30; // totally scientific\n\nmacro_rules! header_name {\n    ($bytes:expr) => {{\n        #[cfg(debug_assertions)]\n        {\n            match HeaderName::from_bytes($bytes) {\n                Ok(name) => name,\n                Err(_) => panic!(\n                    \"illegal header name from httparse: {:?}\",\n                    ::bytes::Bytes::copy_from_slice($bytes)\n                ),\n            }\n        }\n\n        #[cfg(not(debug_assertions))]\n        {\n            match HeaderName::from_bytes($bytes) {\n                Ok(name) => name,\n                Err(_) => panic!(\"illegal header name from httparse: {:?}\", $bytes),\n            }\n        }\n    }};\n}\n\nmacro_rules! header_value {\n    ($bytes:expr) => {{\n        #[cfg(debug_assertions)]\n        {\n            let __hvb: ::bytes::Bytes = $bytes;\n            match HeaderValue::from_maybe_shared(__hvb.clone()) {\n                Ok(name) => name,\n                Err(_) => panic!(\"illegal header value from httparse: {:?}\", __hvb),\n            }\n        }\n\n        #[cfg(not(debug_assertions))]\n        {\n            // Unsafe: httparse already validated header value\n            unsafe { HeaderValue::from_maybe_shared_unchecked($bytes) }\n        }\n    }};\n}\n\npub(super) fn parse_headers<T>(\n    bytes: &mut BytesMut,\n    ctx: ParseContext<'_>,\n) -> ParseResult<T::Incoming>\nwhere\n    T: Http1Transaction,\n{\n    // If the buffer is empty, don't bother entering the span, it's just noise.\n    if bytes.is_empty() {\n        return Ok(None);\n    }\n\n    let span = trace_span!(\"parse_headers\");\n    let _s = span.enter();\n    T::parse(bytes, ctx)\n}\n\npub(super) fn encode_headers<T>(\n    enc: Encode<'_, T::Outgoing>,\n    dst: &mut Vec<u8>,\n) -> crate::Result<Encoder>\nwhere\n    T: Http1Transaction,\n{\n    let span = trace_span!(\"encode_headers\");\n    let _s = span.enter();\n    T::encode(enc, dst)\n}\n\n// There are 2 main roles, Client and Server.\n\n#[cfg(feature = \"client\")]\npub(crate) enum Client {}\n\n#[cfg(feature = \"server\")]\npub(crate) enum Server {}\n\n#[cfg(feature = \"server\")]\nimpl Http1Transaction for Server {\n    type Incoming = RequestLine;\n    type Outgoing = StatusCode;\n    const LOG: &'static str = \"{role=server}\";\n\n    fn parse(buf: &mut BytesMut, ctx: ParseContext<'_>) -> ParseResult<RequestLine> {\n        debug_assert!(!buf.is_empty(), \"parse called with empty buf\");\n\n        let mut keep_alive;\n        let is_http_11;\n        let subject;\n        let version;\n        let len;\n        let headers_len;\n\n        // Unsafe: both headers_indices and headers are using uninitialized memory,\n        // but we *never* read any of it until after httparse has assigned\n        // values into it. By not zeroing out the stack memory, this saves\n        // a good ~5% on pipeline benchmarks.\n        let mut headers_indices: [MaybeUninit<HeaderIndices>; MAX_HEADERS] = unsafe {\n            // SAFETY: We can go safely from MaybeUninit array to array of MaybeUninit\n            MaybeUninit::uninit().assume_init()\n        };\n        {\n            /* SAFETY: it is safe to go from MaybeUninit array to array of MaybeUninit */\n            let mut headers: [MaybeUninit<httparse::Header<'_>>; MAX_HEADERS] = unsafe {\n                MaybeUninit::uninit().assume_init()\n            };\n            trace!(\n                \"Request.parse([Header; {}], [u8; {}])\",\n                headers.len(),\n                buf.len()\n            );\n            let bytes = buf.as_ref();\n            let (req, status) = httparse::Request::with_uninit_headers(&mut headers, bytes);\n            match status {\n                Ok(httparse::Status::Complete(parsed_len)) => {\n                    trace!(\"Request.parse Complete({})\", parsed_len);\n                    len = parsed_len;\n                    subject = RequestLine(\n                        Method::from_bytes(req.method.unwrap().as_bytes())?,\n                        req.path.unwrap().parse()?,\n                    );\n                    version = if req.version.unwrap() == 1 {\n                        keep_alive = true;\n                        is_http_11 = true;\n                        Version::HTTP_11\n                    } else {\n                        keep_alive = false;\n                        is_http_11 = false;\n                        Version::HTTP_10\n                    };\n                    trace!(\"headers: {:?}\", &req.headers);\n\n                    record_header_indices(bytes, &req.headers, &mut headers_indices)?;\n                    headers_len = req.headers.len();\n                }\n                Ok(httparse::Status::Partial) => return Ok(None),\n                Err(err) => {\n                    return Err(match err {\n                        // if invalid Token, try to determine if for method or path\n                        httparse::Error::Token => {\n                            if req.method.is_none() {\n                                Parse::Method\n                            } else {\n                                debug_assert!(req.path.is_none());\n                                Parse::Uri\n                            }\n                        }\n                        other => other.into(),\n                    });\n                }\n            }\n        };\n\n        let slice = buf.split_to(len).freeze();\n\n        // According to https://tools.ietf.org/html/rfc7230#section-3.3.3\n        // 1. (irrelevant to Request)\n        // 2. (irrelevant to Request)\n        // 3. Transfer-Encoding: chunked has a chunked body.\n        // 4. If multiple differing Content-Length headers or invalid, close connection.\n        // 5. Content-Length header has a sized body.\n        // 6. Length 0.\n        // 7. (irrelevant to Request)\n\n        let mut decoder = DecodedLength::ZERO;\n        let mut expect_continue = false;\n        let mut con_len = None;\n        let mut is_te = false;\n        let mut is_te_chunked = false;\n        let mut wants_upgrade = subject.0 == Method::CONNECT;\n\n        let mut header_case_map = if ctx.preserve_header_case {\n            Some(HeaderCaseMap::default())\n        } else {\n            None\n        };\n\n        let mut headers = ctx.cached_headers.take().unwrap_or_else(HeaderMap::new);\n\n        headers.reserve(headers_len);\n\n        for header in &headers_indices[..headers_len] {\n            // SAFETY: array is valid up to `headers_len`\n            let header = unsafe { &*header.as_ptr() };\n            let name = header_name!(&slice[header.name.0..header.name.1]);\n            let value = header_value!(slice.slice(header.value.0..header.value.1));\n\n            match name {\n                header::TRANSFER_ENCODING => {\n                    // https://tools.ietf.org/html/rfc7230#section-3.3.3\n                    // If Transfer-Encoding header is present, and 'chunked' is\n                    // not the final encoding, and this is a Request, then it is\n                    // malformed. A server should respond with 400 Bad Request.\n                    if !is_http_11 {\n                        debug!(\"HTTP/1.0 cannot have Transfer-Encoding header\");\n                        return Err(Parse::Header);\n                    }\n                    is_te = true;\n                    if headers::is_chunked_(&value) {\n                        is_te_chunked = true;\n                        decoder = DecodedLength::CHUNKED;\n                    } else {\n                        is_te_chunked = false;\n                    }\n                }\n                header::CONTENT_LENGTH => {\n                    if is_te {\n                        continue;\n                    }\n                    let len = value\n                        .to_str()\n                        .map_err(|_| Parse::Header)\n                        .and_then(|s| s.parse().map_err(|_| Parse::Header))?;\n                    if let Some(prev) = con_len {\n                        if prev != len {\n                            debug!(\n                                \"multiple Content-Length headers with different values: [{}, {}]\",\n                                prev, len,\n                            );\n                            return Err(Parse::Header);\n                        }\n                        // we don't need to append this secondary length\n                        continue;\n                    }\n                    decoder = DecodedLength::checked_new(len)?;\n                    con_len = Some(len);\n                }\n                header::CONNECTION => {\n                    // keep_alive was previously set to default for Version\n                    if keep_alive {\n                        // HTTP/1.1\n                        keep_alive = !headers::connection_close(&value);\n                    } else {\n                        // HTTP/1.0\n                        keep_alive = headers::connection_keep_alive(&value);\n                    }\n                }\n                header::EXPECT => {\n                    expect_continue = value.as_bytes() == b\"100-continue\";\n                }\n                header::UPGRADE => {\n                    // Upgrades are only allowed with HTTP/1.1\n                    wants_upgrade = is_http_11;\n                }\n\n                _ => (),\n            }\n\n            if let Some(ref mut header_case_map) = header_case_map {\n                header_case_map.append(&name, slice.slice(header.name.0..header.name.1));\n            }\n\n            headers.append(name, value);\n        }\n\n        if is_te && !is_te_chunked {\n            debug!(\"request with transfer-encoding header, but not chunked, bad request\");\n            return Err(Parse::Header);\n        }\n\n        let mut extensions = http::Extensions::default();\n\n        if let Some(header_case_map) = header_case_map {\n            extensions.insert(header_case_map);\n        }\n\n        *ctx.req_method = Some(subject.0.clone());\n\n        Ok(Some(ParsedMessage {\n            head: MessageHead {\n                version,\n                subject,\n                headers,\n                extensions,\n            },\n            decode: decoder,\n            expect_continue,\n            keep_alive,\n            wants_upgrade,\n        }))\n    }\n\n    fn encode(mut msg: Encode<'_, Self::Outgoing>, dst: &mut Vec<u8>) -> crate::Result<Encoder> {\n        trace!(\n            \"Server::encode status={:?}, body={:?}, req_method={:?}\",\n            msg.head.subject,\n            msg.body,\n            msg.req_method\n        );\n\n        let mut wrote_len = false;\n\n        // hyper currently doesn't support returning 1xx status codes as a Response\n        // This is because Service only allows returning a single Response, and\n        // so if you try to reply with a e.g. 100 Continue, you have no way of\n        // replying with the latter status code response.\n        let (ret, is_last) = if msg.head.subject == StatusCode::SWITCHING_PROTOCOLS {\n            (Ok(()), true)\n        } else if msg.req_method == &Some(Method::CONNECT) && msg.head.subject.is_success() {\n            // Sending content-length or transfer-encoding header on 2xx response\n            // to CONNECT is forbidden in RFC 7231.\n            wrote_len = true;\n            (Ok(()), true)\n        } else if msg.head.subject.is_informational() {\n            warn!(\"response with 1xx status code not supported\");\n            *msg.head = MessageHead::default();\n            msg.head.subject = StatusCode::INTERNAL_SERVER_ERROR;\n            msg.body = None;\n            (Err(crate::Error::new_user_unsupported_status_code()), true)\n        } else {\n            (Ok(()), !msg.keep_alive)\n        };\n\n        // In some error cases, we don't know about the invalid message until already\n        // pushing some bytes onto the `dst`. In those cases, we don't want to send\n        // the half-pushed message, so rewind to before.\n        let orig_len = dst.len();\n\n        let init_cap = 30 + msg.head.headers.len() * AVERAGE_HEADER_SIZE;\n        dst.reserve(init_cap);\n        if msg.head.version == Version::HTTP_11 && msg.head.subject == StatusCode::OK {\n            extend(dst, b\"HTTP/1.1 200 OK\\r\\n\");\n        } else {\n            match msg.head.version {\n                Version::HTTP_10 => extend(dst, b\"HTTP/1.0 \"),\n                Version::HTTP_11 => extend(dst, b\"HTTP/1.1 \"),\n                Version::HTTP_2 => {\n                    debug!(\"response with HTTP2 version coerced to HTTP/1.1\");\n                    extend(dst, b\"HTTP/1.1 \");\n                }\n                other => panic!(\"unexpected response version: {:?}\", other),\n            }\n\n            extend(dst, msg.head.subject.as_str().as_bytes());\n            extend(dst, b\" \");\n            // a reason MUST be written, as many parsers will expect it.\n            extend(\n                dst,\n                msg.head\n                    .subject\n                    .canonical_reason()\n                    .unwrap_or(\"<none>\")\n                    .as_bytes(),\n            );\n            extend(dst, b\"\\r\\n\");\n        }\n\n        let orig_headers;\n        let extensions = mem::take(&mut msg.head.extensions);\n        let orig_headers = match extensions.get::<HeaderCaseMap>() {\n            None if msg.title_case_headers => {\n                orig_headers = HeaderCaseMap::default();\n                Some(&orig_headers)\n            }\n            orig_headers => orig_headers,\n        };\n        let encoder = if let Some(orig_headers) = orig_headers {\n            Self::encode_headers_with_original_case(\n                msg,\n                dst,\n                is_last,\n                orig_len,\n                wrote_len,\n                orig_headers,\n            )?\n        } else {\n            Self::encode_headers_with_lower_case(msg, dst, is_last, orig_len, wrote_len)?\n        };\n\n        ret.map(|()| encoder)\n    }\n\n    fn on_error(err: &crate::Error) -> Option<MessageHead<Self::Outgoing>> {\n        use crate::error::Kind;\n        let status = match *err.kind() {\n            Kind::Parse(Parse::Method)\n            | Kind::Parse(Parse::Header)\n            | Kind::Parse(Parse::Uri)\n            | Kind::Parse(Parse::Version) => StatusCode::BAD_REQUEST,\n            Kind::Parse(Parse::TooLarge) => StatusCode::REQUEST_HEADER_FIELDS_TOO_LARGE,\n            _ => return None,\n        };\n\n        debug!(\"sending automatic response ({}) for parse error\", status);\n        let mut msg = MessageHead::default();\n        msg.subject = status;\n        Some(msg)\n    }\n\n    fn is_server() -> bool {\n        true\n    }\n\n    fn update_date() {\n        date::update();\n    }\n}\n\n#[cfg(feature = \"server\")]\nimpl Server {\n    fn can_have_body(method: &Option<Method>, status: StatusCode) -> bool {\n        Server::can_chunked(method, status)\n    }\n\n    fn can_chunked(method: &Option<Method>, status: StatusCode) -> bool {\n        if method == &Some(Method::HEAD) || method == &Some(Method::CONNECT) && status.is_success()\n        {\n            false\n        } else if status.is_informational() {\n            false\n        } else {\n            match status {\n                StatusCode::NO_CONTENT | StatusCode::NOT_MODIFIED => false,\n                _ => true,\n            }\n        }\n    }\n\n    fn can_have_content_length(method: &Option<Method>, status: StatusCode) -> bool {\n        if status.is_informational() || method == &Some(Method::CONNECT) && status.is_success() {\n            false\n        } else {\n            match status {\n                StatusCode::NO_CONTENT | StatusCode::NOT_MODIFIED => false,\n                _ => true,\n            }\n        }\n    }\n\n    fn encode_headers_with_lower_case(\n        msg: Encode<'_, StatusCode>,\n        dst: &mut Vec<u8>,\n        is_last: bool,\n        orig_len: usize,\n        wrote_len: bool,\n    ) -> crate::Result<Encoder> {\n        struct LowercaseWriter;\n\n        impl HeaderNameWriter for LowercaseWriter {\n            #[inline]\n            fn write_full_header_line(\n                &mut self,\n                dst: &mut Vec<u8>,\n                line: &str,\n                _: (HeaderName, &str),\n            ) {\n                extend(dst, line.as_bytes())\n            }\n\n            #[inline]\n            fn write_header_name_with_colon(\n                &mut self,\n                dst: &mut Vec<u8>,\n                name_with_colon: &str,\n                _: HeaderName,\n            ) {\n                extend(dst, name_with_colon.as_bytes())\n            }\n\n            #[inline]\n            fn write_header_name(&mut self, dst: &mut Vec<u8>, name: &HeaderName) {\n                extend(dst, name.as_str().as_bytes())\n            }\n        }\n\n        Self::encode_headers(msg, dst, is_last, orig_len, wrote_len, LowercaseWriter)\n    }\n\n    #[cold]\n    #[inline(never)]\n    fn encode_headers_with_original_case(\n        msg: Encode<'_, StatusCode>,\n        dst: &mut Vec<u8>,\n        is_last: bool,\n        orig_len: usize,\n        wrote_len: bool,\n        orig_headers: &HeaderCaseMap,\n    ) -> crate::Result<Encoder> {\n        struct OrigCaseWriter<'map> {\n            map: &'map HeaderCaseMap,\n            current: Option<(HeaderName, ValueIter<'map, Bytes>)>,\n            title_case_headers: bool,\n        }\n\n        impl HeaderNameWriter for OrigCaseWriter<'_> {\n            #[inline]\n            fn write_full_header_line(\n                &mut self,\n                dst: &mut Vec<u8>,\n                _: &str,\n                (name, rest): (HeaderName, &str),\n            ) {\n                self.write_header_name(dst, &name);\n                extend(dst, rest.as_bytes());\n            }\n\n            #[inline]\n            fn write_header_name_with_colon(\n                &mut self,\n                dst: &mut Vec<u8>,\n                _: &str,\n                name: HeaderName,\n            ) {\n                self.write_header_name(dst, &name);\n                extend(dst, b\": \");\n            }\n\n            #[inline]\n            fn write_header_name(&mut self, dst: &mut Vec<u8>, name: &HeaderName) {\n                let Self {\n                    map,\n                    ref mut current,\n                    title_case_headers,\n                } = *self;\n                if current.as_ref().map_or(true, |(last, _)| last != name) {\n                    *current = None;\n                }\n                let (_, values) =\n                    current.get_or_insert_with(|| (name.clone(), map.get_all_internal(name)));\n\n                if let Some(orig_name) = values.next() {\n                    extend(dst, orig_name);\n                } else if title_case_headers {\n                    title_case(dst, name.as_str().as_bytes());\n                } else {\n                    extend(dst, name.as_str().as_bytes());\n                }\n            }\n        }\n\n        let header_name_writer = OrigCaseWriter {\n            map: orig_headers,\n            current: None,\n            title_case_headers: msg.title_case_headers,\n        };\n\n        Self::encode_headers(msg, dst, is_last, orig_len, wrote_len, header_name_writer)\n    }\n\n    #[inline]\n    fn encode_headers<W>(\n        msg: Encode<'_, StatusCode>,\n        mut dst: &mut Vec<u8>,\n        mut is_last: bool,\n        orig_len: usize,\n        mut wrote_len: bool,\n        mut header_name_writer: W,\n    ) -> crate::Result<Encoder>\n    where\n        W: HeaderNameWriter,\n    {\n        // In some error cases, we don't know about the invalid message until already\n        // pushing some bytes onto the `dst`. In those cases, we don't want to send\n        // the half-pushed message, so rewind to before.\n        let rewind = |dst: &mut Vec<u8>| {\n            dst.truncate(orig_len);\n        };\n\n        let mut encoder = Encoder::length(0);\n        let mut wrote_date = false;\n        let mut cur_name = None;\n        let mut is_name_written = false;\n        let mut must_write_chunked = false;\n        let mut prev_con_len = None;\n\n        macro_rules! handle_is_name_written {\n            () => {{\n                if is_name_written {\n                    // we need to clean up and write the newline\n                    debug_assert_ne!(\n                        &dst[dst.len() - 2..],\n                        b\"\\r\\n\",\n                        \"previous header wrote newline but set is_name_written\"\n                    );\n\n                    if must_write_chunked {\n                        extend(dst, b\", chunked\\r\\n\");\n                    } else {\n                        extend(dst, b\"\\r\\n\");\n                    }\n                }\n            }};\n        }\n\n        'headers: for (opt_name, value) in msg.head.headers.drain() {\n            if let Some(n) = opt_name {\n                cur_name = Some(n);\n                handle_is_name_written!();\n                is_name_written = false;\n            }\n            let name = cur_name.as_ref().expect(\"current header name\");\n            match *name {\n                header::CONTENT_LENGTH => {\n                    if wrote_len && !is_name_written {\n                        warn!(\"unexpected content-length found, canceling\");\n                        rewind(dst);\n                        return Err(crate::Error::new_user_header());\n                    }\n                    match msg.body {\n                        Some(BodyLength::Known(known_len)) => {\n                            // The HttpBody claims to know a length, and\n                            // the headers are already set. For performance\n                            // reasons, we are just going to trust that\n                            // the values match.\n                            //\n                            // In debug builds, we'll assert they are the\n                            // same to help developers find bugs.\n                            #[cfg(debug_assertions)]\n                            {\n                                if let Some(len) = headers::content_length_parse(&value) {\n                                    assert!(\n                                        len == known_len,\n                                        \"payload claims content-length of {}, custom content-length header claims {}\",\n                                        known_len,\n                                        len,\n                                    );\n                                }\n                            }\n\n                            if !is_name_written {\n                                encoder = Encoder::length(known_len);\n                                header_name_writer.write_header_name_with_colon(\n                                    dst,\n                                    \"content-length: \",\n                                    header::CONTENT_LENGTH,\n                                );\n                                extend(dst, value.as_bytes());\n                                wrote_len = true;\n                                is_name_written = true;\n                            }\n                            continue 'headers;\n                        }\n                        Some(BodyLength::Unknown) => {\n                            // The HttpBody impl didn't know how long the\n                            // body is, but a length header was included.\n                            // We have to parse the value to return our\n                            // Encoder...\n\n                            if let Some(len) = headers::content_length_parse(&value) {\n                                if let Some(prev) = prev_con_len {\n                                    if prev != len {\n                                        warn!(\n                                            \"multiple Content-Length values found: [{}, {}]\",\n                                            prev, len\n                                        );\n                                        rewind(dst);\n                                        return Err(crate::Error::new_user_header());\n                                    }\n                                    debug_assert!(is_name_written);\n                                    continue 'headers;\n                                } else {\n                                    // we haven't written content-length yet!\n                                    encoder = Encoder::length(len);\n                                    header_name_writer.write_header_name_with_colon(\n                                        dst,\n                                        \"content-length: \",\n                                        header::CONTENT_LENGTH,\n                                    );\n                                    extend(dst, value.as_bytes());\n                                    wrote_len = true;\n                                    is_name_written = true;\n                                    prev_con_len = Some(len);\n                                    continue 'headers;\n                                }\n                            } else {\n                                warn!(\"illegal Content-Length value: {:?}\", value);\n                                rewind(dst);\n                                return Err(crate::Error::new_user_header());\n                            }\n                        }\n                        None => {\n                            // We have no body to actually send,\n                            // but the headers claim a content-length.\n                            // There's only 2 ways this makes sense:\n                            //\n                            // - The header says the length is `0`.\n                            // - This is a response to a `HEAD` request.\n                            if msg.req_method == &Some(Method::HEAD) {\n                                debug_assert_eq!(encoder, Encoder::length(0));\n                            } else {\n                                if value.as_bytes() != b\"0\" {\n                                    warn!(\n                                        \"content-length value found, but empty body provided: {:?}\",\n                                        value\n                                    );\n                                }\n                                continue 'headers;\n                            }\n                        }\n                    }\n                    wrote_len = true;\n                }\n                header::TRANSFER_ENCODING => {\n                    if wrote_len && !is_name_written {\n                        warn!(\"unexpected transfer-encoding found, canceling\");\n                        rewind(dst);\n                        return Err(crate::Error::new_user_header());\n                    }\n                    // check that we actually can send a chunked body...\n                    if msg.head.version == Version::HTTP_10\n                        || !Server::can_chunked(msg.req_method, msg.head.subject)\n                    {\n                        continue;\n                    }\n                    wrote_len = true;\n                    // Must check each value, because `chunked` needs to be the\n                    // last encoding, or else we add it.\n                    must_write_chunked = !headers::is_chunked_(&value);\n\n                    if !is_name_written {\n                        encoder = Encoder::chunked();\n                        is_name_written = true;\n                        header_name_writer.write_header_name_with_colon(\n                            dst,\n                            \"transfer-encoding: \",\n                            header::TRANSFER_ENCODING,\n                        );\n                        extend(dst, value.as_bytes());\n                    } else {\n                        extend(dst, b\", \");\n                        extend(dst, value.as_bytes());\n                    }\n                    continue 'headers;\n                }\n                header::CONNECTION => {\n                    if !is_last && headers::connection_close(&value) {\n                        is_last = true;\n                    }\n                    if !is_name_written {\n                        is_name_written = true;\n                        header_name_writer.write_header_name_with_colon(\n                            dst,\n                            \"connection: \",\n                            header::CONNECTION,\n                        );\n                        extend(dst, value.as_bytes());\n                    } else {\n                        extend(dst, b\", \");\n                        extend(dst, value.as_bytes());\n                    }\n                    continue 'headers;\n                }\n                header::DATE => {\n                    wrote_date = true;\n                }\n                _ => (),\n            }\n            //TODO: this should perhaps instead combine them into\n            //single lines, as RFC7230 suggests is preferable.\n\n            // non-special write Name and Value\n            debug_assert!(\n                !is_name_written,\n                \"{:?} set is_name_written and didn't continue loop\",\n                name,\n            );\n            header_name_writer.write_header_name(dst, name);\n            extend(dst, b\": \");\n            extend(dst, value.as_bytes());\n            extend(dst, b\"\\r\\n\");\n        }\n\n        handle_is_name_written!();\n\n        if !wrote_len {\n            encoder = match msg.body {\n                Some(BodyLength::Unknown) => {\n                    if msg.head.version == Version::HTTP_10\n                        || !Server::can_chunked(msg.req_method, msg.head.subject)\n                    {\n                        Encoder::close_delimited()\n                    } else {\n                        header_name_writer.write_full_header_line(\n                            dst,\n                            \"transfer-encoding: chunked\\r\\n\",\n                            (header::TRANSFER_ENCODING, \": chunked\\r\\n\"),\n                        );\n                        Encoder::chunked()\n                    }\n                }\n                None | Some(BodyLength::Known(0)) => {\n                    if Server::can_have_content_length(msg.req_method, msg.head.subject) {\n                        header_name_writer.write_full_header_line(\n                            dst,\n                            \"content-length: 0\\r\\n\",\n                            (header::CONTENT_LENGTH, \": 0\\r\\n\"),\n                        )\n                    }\n                    Encoder::length(0)\n                }\n                Some(BodyLength::Known(len)) => {\n                    if !Server::can_have_content_length(msg.req_method, msg.head.subject) {\n                        Encoder::length(0)\n                    } else {\n                        header_name_writer.write_header_name_with_colon(\n                            dst,\n                            \"content-length: \",\n                            header::CONTENT_LENGTH,\n                        );\n                        let _ = ::itoa::write(&mut dst, len);\n                        extend(dst, b\"\\r\\n\");\n                        Encoder::length(len)\n                    }\n                }\n            };\n        }\n\n        if !Server::can_have_body(msg.req_method, msg.head.subject) {\n            trace!(\n                \"server body forced to 0; method={:?}, status={:?}\",\n                msg.req_method,\n                msg.head.subject\n            );\n            encoder = Encoder::length(0);\n        }\n\n        // cached date is much faster than formatting every request\n        if !wrote_date {\n            dst.reserve(date::DATE_VALUE_LENGTH + 8);\n            header_name_writer.write_header_name_with_colon(dst, \"date: \", header::DATE);\n            date::extend(dst);\n            extend(dst, b\"\\r\\n\\r\\n\");\n        } else {\n            extend(dst, b\"\\r\\n\");\n        }\n\n        Ok(encoder.set_last(is_last))\n    }\n}\n\n#[cfg(feature = \"server\")]\ntrait HeaderNameWriter {\n    fn write_full_header_line(\n        &mut self,\n        dst: &mut Vec<u8>,\n        line: &str,\n        name_value_pair: (HeaderName, &str),\n    );\n    fn write_header_name_with_colon(\n        &mut self,\n        dst: &mut Vec<u8>,\n        name_with_colon: &str,\n        name: HeaderName,\n    );\n    fn write_header_name(&mut self, dst: &mut Vec<u8>, name: &HeaderName);\n}\n\n#[cfg(feature = \"client\")]\nimpl Http1Transaction for Client {\n    type Incoming = StatusCode;\n    type Outgoing = RequestLine;\n    const LOG: &'static str = \"{role=client}\";\n\n    fn parse(buf: &mut BytesMut, ctx: ParseContext<'_>) -> ParseResult<StatusCode> {\n        debug_assert!(!buf.is_empty(), \"parse called with empty buf\");\n\n        // Loop to skip information status code headers (100 Continue, etc).\n        loop {\n            // Unsafe: see comment in Server Http1Transaction, above.\n            let mut headers_indices: [MaybeUninit<HeaderIndices>; MAX_HEADERS] = unsafe {\n                // SAFETY: We can go safely from MaybeUninit array to array of MaybeUninit\n                MaybeUninit::uninit().assume_init()\n            };\n            let (len, status, reason, version, headers_len) = {\n                // SAFETY: We can go safely from MaybeUninit array to array of MaybeUninit\n                let mut headers: [MaybeUninit<httparse::Header<'_>>; MAX_HEADERS] =\n                    unsafe { MaybeUninit::uninit().assume_init() };\n                trace!(\n                    \"Response.parse([Header; {}], [u8; {}])\",\n                    headers.len(),\n                    buf.len()\n                );\n                let bytes = buf.as_ref();\n                let (res, status) = ctx.h1_parser_config.parse_response_with_uninit_headers(&mut headers, bytes);\n                match status {\n                    Ok(httparse::Status::Complete(len)) => {\n                        trace!(\"Response.parse Complete({})\", len);\n                        let status = StatusCode::from_u16(res.code.unwrap())?;\n\n                        #[cfg(not(feature = \"ffi\"))]\n                        let reason = ();\n                        #[cfg(feature = \"ffi\")]\n                        let reason = {\n                            let reason = res.reason.unwrap();\n                            // Only save the reason phrase if it isnt the canonical reason\n                            if Some(reason) != status.canonical_reason() {\n                                Some(Bytes::copy_from_slice(reason.as_bytes()))\n                            } else {\n                                None\n                            }\n                        };\n\n                        let version = if res.version.unwrap() == 1 {\n                            Version::HTTP_11\n                        } else {\n                            Version::HTTP_10\n                        };\n                        record_header_indices(bytes, &res.headers, &mut headers_indices)?;\n                        let headers_len = res.headers.len();\n                        (len, status, reason, version, headers_len)\n                    }\n                    Ok(httparse::Status::Partial) => return Ok(None),\n                    Err(httparse::Error::Version) if ctx.h09_responses => {\n                        trace!(\"Response.parse accepted HTTP/0.9 response\");\n\n                        #[cfg(not(feature = \"ffi\"))]\n                        let reason = ();\n                        #[cfg(feature = \"ffi\")]\n                        let reason = None;\n\n                        (0, StatusCode::OK, reason, Version::HTTP_09, 0)\n                    }\n                    Err(e) => return Err(e.into()),\n                }\n            };\n\n            let slice = buf.split_to(len).freeze();\n\n            let mut headers = ctx.cached_headers.take().unwrap_or_else(HeaderMap::new);\n\n            let mut keep_alive = version == Version::HTTP_11;\n\n            let mut header_case_map = if ctx.preserve_header_case {\n                Some(HeaderCaseMap::default())\n            } else {\n                None\n            };\n\n            headers.reserve(headers_len);\n            for header in &headers_indices[..headers_len] {\n                // SAFETY: array is valid up to `headers_len`\n                let header = unsafe { &*header.as_ptr() };\n                let name = header_name!(&slice[header.name.0..header.name.1]);\n                let value = header_value!(slice.slice(header.value.0..header.value.1));\n\n                if let header::CONNECTION = name {\n                    // keep_alive was previously set to default for Version\n                    if keep_alive {\n                        // HTTP/1.1\n                        keep_alive = !headers::connection_close(&value);\n                    } else {\n                        // HTTP/1.0\n                        keep_alive = headers::connection_keep_alive(&value);\n                    }\n                }\n\n                if let Some(ref mut header_case_map) = header_case_map {\n                    header_case_map.append(&name, slice.slice(header.name.0..header.name.1));\n                }\n\n                headers.append(name, value);\n            }\n\n            let mut extensions = http::Extensions::default();\n\n            if let Some(header_case_map) = header_case_map {\n                extensions.insert(header_case_map);\n            }\n\n            #[cfg(feature = \"ffi\")]\n            if let Some(reason) = reason {\n                extensions.insert(crate::ffi::ReasonPhrase(reason));\n            }\n            #[cfg(not(feature = \"ffi\"))]\n            drop(reason);\n\n            let head = MessageHead {\n                version,\n                subject: status,\n                headers,\n                extensions,\n            };\n            if let Some((decode, is_upgrade)) = Client::decoder(&head, ctx.req_method)? {\n                return Ok(Some(ParsedMessage {\n                    head,\n                    decode,\n                    expect_continue: false,\n                    // a client upgrade means the connection can't be used\n                    // again, as it is definitely upgrading.\n                    keep_alive: keep_alive && !is_upgrade,\n                    wants_upgrade: is_upgrade,\n                }));\n            }\n\n            // Parsing a 1xx response could have consumed the buffer, check if\n            // it is empty now...\n            if buf.is_empty() {\n                return Ok(None);\n            }\n        }\n    }\n\n    fn encode(msg: Encode<'_, Self::Outgoing>, dst: &mut Vec<u8>) -> crate::Result<Encoder> {\n        trace!(\n            \"Client::encode method={:?}, body={:?}\",\n            msg.head.subject.0,\n            msg.body\n        );\n\n        *msg.req_method = Some(msg.head.subject.0.clone());\n\n        let body = Client::set_length(msg.head, msg.body);\n\n        let init_cap = 30 + msg.head.headers.len() * AVERAGE_HEADER_SIZE;\n        dst.reserve(init_cap);\n\n        extend(dst, msg.head.subject.0.as_str().as_bytes());\n        extend(dst, b\" \");\n        //TODO: add API to http::Uri to encode without std::fmt\n        let _ = write!(FastWrite(dst), \"{} \", msg.head.subject.1);\n\n        match msg.head.version {\n            Version::HTTP_10 => extend(dst, b\"HTTP/1.0\"),\n            Version::HTTP_11 => extend(dst, b\"HTTP/1.1\"),\n            Version::HTTP_2 => {\n                debug!(\"request with HTTP2 version coerced to HTTP/1.1\");\n                extend(dst, b\"HTTP/1.1\");\n            }\n            other => panic!(\"unexpected request version: {:?}\", other),\n        }\n        extend(dst, b\"\\r\\n\");\n\n        if let Some(orig_headers) = msg.head.extensions.get::<HeaderCaseMap>() {\n            write_headers_original_case(\n                &msg.head.headers,\n                orig_headers,\n                dst,\n                msg.title_case_headers,\n            );\n        } else if msg.title_case_headers {\n            write_headers_title_case(&msg.head.headers, dst);\n        } else {\n            write_headers(&msg.head.headers, dst);\n        }\n\n        extend(dst, b\"\\r\\n\");\n        msg.head.headers.clear(); //TODO: remove when switching to drain()\n\n        Ok(body)\n    }\n\n    fn on_error(_err: &crate::Error) -> Option<MessageHead<Self::Outgoing>> {\n        // we can't tell the server about any errors it creates\n        None\n    }\n\n    fn is_client() -> bool {\n        true\n    }\n}\n\n#[cfg(feature = \"client\")]\nimpl Client {\n    /// Returns Some(length, wants_upgrade) if successful.\n    ///\n    /// Returns None if this message head should be skipped (like a 100 status).\n    fn decoder(\n        inc: &MessageHead<StatusCode>,\n        method: &mut Option<Method>,\n    ) -> Result<Option<(DecodedLength, bool)>, Parse> {\n        // According to https://tools.ietf.org/html/rfc7230#section-3.3.3\n        // 1. HEAD responses, and Status 1xx, 204, and 304 cannot have a body.\n        // 2. Status 2xx to a CONNECT cannot have a body.\n        // 3. Transfer-Encoding: chunked has a chunked body.\n        // 4. If multiple differing Content-Length headers or invalid, close connection.\n        // 5. Content-Length header has a sized body.\n        // 6. (irrelevant to Response)\n        // 7. Read till EOF.\n\n        match inc.subject.as_u16() {\n            101 => {\n                return Ok(Some((DecodedLength::ZERO, true)));\n            }\n            100 | 102..=199 => {\n                trace!(\"ignoring informational response: {}\", inc.subject.as_u16());\n                return Ok(None);\n            }\n            204 | 304 => return Ok(Some((DecodedLength::ZERO, false))),\n            _ => (),\n        }\n        match *method {\n            Some(Method::HEAD) => {\n                return Ok(Some((DecodedLength::ZERO, false)));\n            }\n            Some(Method::CONNECT) => {\n                if let 200..=299 = inc.subject.as_u16() {\n                    return Ok(Some((DecodedLength::ZERO, true)));\n                }\n            }\n            Some(_) => {}\n            None => {\n                trace!(\"Client::decoder is missing the Method\");\n            }\n        }\n\n        if inc.headers.contains_key(header::TRANSFER_ENCODING) {\n            // https://tools.ietf.org/html/rfc7230#section-3.3.3\n            // If Transfer-Encoding header is present, and 'chunked' is\n            // not the final encoding, and this is a Request, then it is\n            // malformed. A server should respond with 400 Bad Request.\n            if inc.version == Version::HTTP_10 {\n                debug!(\"HTTP/1.0 cannot have Transfer-Encoding header\");\n                Err(Parse::Header)\n            } else if headers::transfer_encoding_is_chunked(&inc.headers) {\n                Ok(Some((DecodedLength::CHUNKED, false)))\n            } else {\n                trace!(\"not chunked, read till eof\");\n                Ok(Some((DecodedLength::CLOSE_DELIMITED, false)))\n            }\n        } else if let Some(len) = headers::content_length_parse_all(&inc.headers) {\n            Ok(Some((DecodedLength::checked_new(len)?, false)))\n        } else if inc.headers.contains_key(header::CONTENT_LENGTH) {\n            debug!(\"illegal Content-Length header\");\n            Err(Parse::Header)\n        } else {\n            trace!(\"neither Transfer-Encoding nor Content-Length\");\n            Ok(Some((DecodedLength::CLOSE_DELIMITED, false)))\n        }\n    }\n    fn set_length(head: &mut RequestHead, body: Option<BodyLength>) -> Encoder {\n        let body = if let Some(body) = body {\n            body\n        } else {\n            head.headers.remove(header::TRANSFER_ENCODING);\n            return Encoder::length(0);\n        };\n\n        // HTTP/1.0 doesn't know about chunked\n        let can_chunked = head.version == Version::HTTP_11;\n        let headers = &mut head.headers;\n\n        // If the user already set specific headers, we should respect them, regardless\n        // of what the HttpBody knows about itself. They set them for a reason.\n\n        // Because of the borrow checker, we can't check the for an existing\n        // Content-Length header while holding an `Entry` for the Transfer-Encoding\n        // header, so unfortunately, we must do the check here, first.\n\n        let existing_con_len = headers::content_length_parse_all(headers);\n        let mut should_remove_con_len = false;\n\n        if !can_chunked {\n            // Chunked isn't legal, so if it is set, we need to remove it.\n            if headers.remove(header::TRANSFER_ENCODING).is_some() {\n                trace!(\"removing illegal transfer-encoding header\");\n            }\n\n            return if let Some(len) = existing_con_len {\n                Encoder::length(len)\n            } else if let BodyLength::Known(len) = body {\n                set_content_length(headers, len)\n            } else {\n                // HTTP/1.0 client requests without a content-length\n                // cannot have any body at all.\n                Encoder::length(0)\n            };\n        }\n\n        // If the user set a transfer-encoding, respect that. Let's just\n        // make sure `chunked` is the final encoding.\n        let encoder = match headers.entry(header::TRANSFER_ENCODING) {\n            Entry::Occupied(te) => {\n                should_remove_con_len = true;\n                if headers::is_chunked(te.iter()) {\n                    Some(Encoder::chunked())\n                } else {\n                    warn!(\"user provided transfer-encoding does not end in 'chunked'\");\n\n                    // There's a Transfer-Encoding, but it doesn't end in 'chunked'!\n                    // An example that could trigger this:\n                    //\n                    //     Transfer-Encoding: gzip\n                    //\n                    // This can be bad, depending on if this is a request or a\n                    // response.\n                    //\n                    // - A request is illegal if there is a `Transfer-Encoding`\n                    //   but it doesn't end in `chunked`.\n                    // - A response that has `Transfer-Encoding` but doesn't\n                    //   end in `chunked` isn't illegal, it just forces this\n                    //   to be close-delimited.\n                    //\n                    // We can try to repair this, by adding `chunked` ourselves.\n\n                    headers::add_chunked(te);\n                    Some(Encoder::chunked())\n                }\n            }\n            Entry::Vacant(te) => {\n                if let Some(len) = existing_con_len {\n                    Some(Encoder::length(len))\n                } else if let BodyLength::Unknown = body {\n                    // GET, HEAD, and CONNECT almost never have bodies.\n                    //\n                    // So instead of sending a \"chunked\" body with a 0-chunk,\n                    // assume no body here. If you *must* send a body,\n                    // set the headers explicitly.\n                    match head.subject.0 {\n                        Method::GET | Method::HEAD | Method::CONNECT => Some(Encoder::length(0)),\n                        _ => {\n                            te.insert(HeaderValue::from_static(\"chunked\"));\n                            Some(Encoder::chunked())\n                        }\n                    }\n                } else {\n                    None\n                }\n            }\n        };\n\n        // This is because we need a second mutable borrow to remove\n        // content-length header.\n        if let Some(encoder) = encoder {\n            if should_remove_con_len && existing_con_len.is_some() {\n                headers.remove(header::CONTENT_LENGTH);\n            }\n            return encoder;\n        }\n\n        // User didn't set transfer-encoding, AND we know body length,\n        // so we can just set the Content-Length automatically.\n\n        let len = if let BodyLength::Known(len) = body {\n            len\n        } else {\n            unreachable!(\"BodyLength::Unknown would set chunked\");\n        };\n\n        set_content_length(headers, len)\n    }\n}\n\nfn set_content_length(headers: &mut HeaderMap, len: u64) -> Encoder {\n    // At this point, there should not be a valid Content-Length\n    // header. However, since we'll be indexing in anyways, we can\n    // warn the user if there was an existing illegal header.\n    //\n    // Or at least, we can in theory. It's actually a little bit slower,\n    // so perhaps only do that while the user is developing/testing.\n\n    if cfg!(debug_assertions) {\n        match headers.entry(header::CONTENT_LENGTH) {\n            Entry::Occupied(mut cl) => {\n                // Internal sanity check, we should have already determined\n                // that the header was illegal before calling this function.\n                debug_assert!(headers::content_length_parse_all_values(cl.iter()).is_none());\n                // Uh oh, the user set `Content-Length` headers, but set bad ones.\n                // This would be an illegal message anyways, so let's try to repair\n                // with our known good length.\n                error!(\"user provided content-length header was invalid\");\n\n                cl.insert(HeaderValue::from(len));\n                Encoder::length(len)\n            }\n            Entry::Vacant(cl) => {\n                cl.insert(HeaderValue::from(len));\n                Encoder::length(len)\n            }\n        }\n    } else {\n        headers.insert(header::CONTENT_LENGTH, HeaderValue::from(len));\n        Encoder::length(len)\n    }\n}\n\n#[derive(Clone, Copy)]\nstruct HeaderIndices {\n    name: (usize, usize),\n    value: (usize, usize),\n}\n\nfn record_header_indices(\n    bytes: &[u8],\n    headers: &[httparse::Header<'_>],\n    indices: &mut [MaybeUninit<HeaderIndices>],\n) -> Result<(), crate::error::Parse> {\n    let bytes_ptr = bytes.as_ptr() as usize;\n\n    for (header, indices) in headers.iter().zip(indices.iter_mut()) {\n        if header.name.len() >= (1 << 16) {\n            debug!(\"header name larger than 64kb: {:?}\", header.name);\n            return Err(crate::error::Parse::TooLarge);\n        }\n        let name_start = header.name.as_ptr() as usize - bytes_ptr;\n        let name_end = name_start + header.name.len();\n        let value_start = header.value.as_ptr() as usize - bytes_ptr;\n        let value_end = value_start + header.value.len();\n\n        // FIXME(maybe_uninit_extra)\n        // FIXME(addr_of)\n        // Currently we don't have `ptr::addr_of_mut` in stable rust or\n        // MaybeUninit::write, so this is some way of assigning into a MaybeUninit\n        // safely\n        let new_header_indices = HeaderIndices {\n            name: (name_start, name_end),\n            value: (value_start, value_end),\n        };\n        *indices = MaybeUninit::new(new_header_indices);\n    }\n\n    Ok(())\n}\n\n// Write header names as title case. The header name is assumed to be ASCII,\n// therefore it is trivial to convert an ASCII character from lowercase to\n// uppercase. It is as simple as XORing the lowercase character byte with\n// space.\nfn title_case(dst: &mut Vec<u8>, name: &[u8]) {\n    dst.reserve(name.len());\n\n    let mut iter = name.iter();\n\n    // Uppercase the first character\n    if let Some(c) = iter.next() {\n        if *c >= b'a' && *c <= b'z' {\n            dst.push(*c ^ b' ');\n        } else {\n            dst.push(*c);\n        }\n    }\n\n    while let Some(c) = iter.next() {\n        dst.push(*c);\n\n        if *c == b'-' {\n            if let Some(c) = iter.next() {\n                if *c >= b'a' && *c <= b'z' {\n                    dst.push(*c ^ b' ');\n                } else {\n                    dst.push(*c);\n                }\n            }\n        }\n    }\n}\n\nfn write_headers_title_case(headers: &HeaderMap, dst: &mut Vec<u8>) {\n    for (name, value) in headers {\n        title_case(dst, name.as_str().as_bytes());\n        extend(dst, b\": \");\n        extend(dst, value.as_bytes());\n        extend(dst, b\"\\r\\n\");\n    }\n}\n\nfn write_headers(headers: &HeaderMap, dst: &mut Vec<u8>) {\n    for (name, value) in headers {\n        extend(dst, name.as_str().as_bytes());\n        extend(dst, b\": \");\n        extend(dst, value.as_bytes());\n        extend(dst, b\"\\r\\n\");\n    }\n}\n\n#[cold]\nfn write_headers_original_case(\n    headers: &HeaderMap,\n    orig_case: &HeaderCaseMap,\n    dst: &mut Vec<u8>,\n    title_case_headers: bool,\n) {\n    // For each header name/value pair, there may be a value in the casemap\n    // that corresponds to the HeaderValue. So, we iterator all the keys,\n    // and for each one, try to pair the originally cased name with the value.\n    //\n    // TODO: consider adding http::HeaderMap::entries() iterator\n    for name in headers.keys() {\n        let mut names = orig_case.get_all(name);\n\n        for value in headers.get_all(name) {\n            if let Some(orig_name) = names.next() {\n                extend(dst, orig_name.as_ref());\n            } else if title_case_headers {\n                title_case(dst, name.as_str().as_bytes());\n            } else {\n                extend(dst, name.as_str().as_bytes());\n            }\n\n            // Wanted for curl test cases that send `X-Custom-Header:\\r\\n`\n            if value.is_empty() {\n                extend(dst, b\":\\r\\n\");\n            } else {\n                extend(dst, b\": \");\n                extend(dst, value.as_bytes());\n                extend(dst, b\"\\r\\n\");\n            }\n        }\n    }\n}\n\nstruct FastWrite<'a>(&'a mut Vec<u8>);\n\nimpl<'a> fmt::Write for FastWrite<'a> {\n    #[inline]\n    fn write_str(&mut self, s: &str) -> fmt::Result {\n        extend(self.0, s.as_bytes());\n        Ok(())\n    }\n\n    #[inline]\n    fn write_fmt(&mut self, args: fmt::Arguments<'_>) -> fmt::Result {\n        fmt::write(self, args)\n    }\n}\n\n#[inline]\nfn extend(dst: &mut Vec<u8>, data: &[u8]) {\n    dst.extend_from_slice(data);\n}\n\n#[cfg(test)]\nmod tests {\n    use bytes::BytesMut;\n\n    use super::*;\n\n    #[test]\n    fn test_parse_request() {\n        let _ = pretty_env_logger::try_init();\n        let mut raw = BytesMut::from(\"GET /echo HTTP/1.1\\r\\nHost: hyper.rs\\r\\n\\r\\n\");\n        let mut method = None;\n        let msg = Server::parse(\n            &mut raw,\n            ParseContext {\n                cached_headers: &mut None,\n                req_method: &mut method,\n                h1_parser_config: Default::default(),\n                preserve_header_case: false,\n                h09_responses: false,\n            },\n        )\n        .unwrap()\n        .unwrap();\n        assert_eq!(raw.len(), 0);\n        assert_eq!(msg.head.subject.0, crate::Method::GET);\n        assert_eq!(msg.head.subject.1, \"/echo\");\n        assert_eq!(msg.head.version, crate::Version::HTTP_11);\n        assert_eq!(msg.head.headers.len(), 1);\n        assert_eq!(msg.head.headers[\"Host\"], \"hyper.rs\");\n        assert_eq!(method, Some(crate::Method::GET));\n    }\n\n    #[test]\n    fn test_parse_response() {\n        let _ = pretty_env_logger::try_init();\n        let mut raw = BytesMut::from(\"HTTP/1.1 200 OK\\r\\nContent-Length: 0\\r\\n\\r\\n\");\n        let ctx = ParseContext {\n            cached_headers: &mut None,\n            req_method: &mut Some(crate::Method::GET),\n            h1_parser_config: Default::default(),\n            preserve_header_case: false,\n            h09_responses: false,\n        };\n        let msg = Client::parse(&mut raw, ctx).unwrap().unwrap();\n        assert_eq!(raw.len(), 0);\n        assert_eq!(msg.head.subject, crate::StatusCode::OK);\n        assert_eq!(msg.head.version, crate::Version::HTTP_11);\n        assert_eq!(msg.head.headers.len(), 1);\n        assert_eq!(msg.head.headers[\"Content-Length\"], \"0\");\n    }\n\n    #[test]\n    fn test_parse_request_errors() {\n        let mut raw = BytesMut::from(\"GET htt:p// HTTP/1.1\\r\\nHost: hyper.rs\\r\\n\\r\\n\");\n        let ctx = ParseContext {\n            cached_headers: &mut None,\n            req_method: &mut None,\n            h1_parser_config: Default::default(),\n            preserve_header_case: false,\n            h09_responses: false,\n        };\n        Server::parse(&mut raw, ctx).unwrap_err();\n    }\n\n    const H09_RESPONSE: &'static str = \"Baguettes are super delicious, don't you agree?\";\n\n    #[test]\n    fn test_parse_response_h09_allowed() {\n        let _ = pretty_env_logger::try_init();\n        let mut raw = BytesMut::from(H09_RESPONSE);\n        let ctx = ParseContext {\n            cached_headers: &mut None,\n            req_method: &mut Some(crate::Method::GET),\n            h1_parser_config: Default::default(),\n            preserve_header_case: false,\n            h09_responses: true,\n        };\n        let msg = Client::parse(&mut raw, ctx).unwrap().unwrap();\n        assert_eq!(raw, H09_RESPONSE);\n        assert_eq!(msg.head.subject, crate::StatusCode::OK);\n        assert_eq!(msg.head.version, crate::Version::HTTP_09);\n        assert_eq!(msg.head.headers.len(), 0);\n    }\n\n    #[test]\n    fn test_parse_response_h09_rejected() {\n        let _ = pretty_env_logger::try_init();\n        let mut raw = BytesMut::from(H09_RESPONSE);\n        let ctx = ParseContext {\n            cached_headers: &mut None,\n            req_method: &mut Some(crate::Method::GET),\n            h1_parser_config: Default::default(),\n            preserve_header_case: false,\n            h09_responses: false,\n        };\n        Client::parse(&mut raw, ctx).unwrap_err();\n        assert_eq!(raw, H09_RESPONSE);\n    }\n\n    const RESPONSE_WITH_WHITESPACE_BETWEEN_HEADER_NAME_AND_COLON: &'static str =\n        \"HTTP/1.1 200 OK\\r\\nAccess-Control-Allow-Credentials : true\\r\\n\\r\\n\";\n\n    #[test]\n    fn test_parse_allow_response_with_spaces_before_colons() {\n        use httparse::ParserConfig;\n\n        let _ = pretty_env_logger::try_init();\n        let mut raw = BytesMut::from(RESPONSE_WITH_WHITESPACE_BETWEEN_HEADER_NAME_AND_COLON);\n        let mut h1_parser_config = ParserConfig::default();\n        h1_parser_config.allow_spaces_after_header_name_in_responses(true);\n        let ctx = ParseContext {\n            cached_headers: &mut None,\n            req_method: &mut Some(crate::Method::GET),\n            h1_parser_config,\n            preserve_header_case: false,\n            h09_responses: false,\n        };\n        let msg = Client::parse(&mut raw, ctx).unwrap().unwrap();\n        assert_eq!(raw.len(), 0);\n        assert_eq!(msg.head.subject, crate::StatusCode::OK);\n        assert_eq!(msg.head.version, crate::Version::HTTP_11);\n        assert_eq!(msg.head.headers.len(), 1);\n        assert_eq!(msg.head.headers[\"Access-Control-Allow-Credentials\"], \"true\");\n    }\n\n    #[test]\n    fn test_parse_reject_response_with_spaces_before_colons() {\n        let _ = pretty_env_logger::try_init();\n        let mut raw = BytesMut::from(RESPONSE_WITH_WHITESPACE_BETWEEN_HEADER_NAME_AND_COLON);\n        let ctx = ParseContext {\n            cached_headers: &mut None,\n            req_method: &mut Some(crate::Method::GET),\n            h1_parser_config: Default::default(),\n            preserve_header_case: false,\n            h09_responses: false,\n        };\n        Client::parse(&mut raw, ctx).unwrap_err();\n    }\n\n    #[test]\n    fn test_parse_preserve_header_case_in_request() {\n        let mut raw =\n            BytesMut::from(\"GET / HTTP/1.1\\r\\nHost: hyper.rs\\r\\nX-BREAD: baguette\\r\\n\\r\\n\");\n        let ctx = ParseContext {\n            cached_headers: &mut None,\n            req_method: &mut None,\n            h1_parser_config: Default::default(),\n            preserve_header_case: true,\n            h09_responses: false,\n        };\n        let parsed_message = Server::parse(&mut raw, ctx).unwrap().unwrap();\n        let orig_headers = parsed_message\n            .head\n            .extensions\n            .get::<HeaderCaseMap>()\n            .unwrap();\n        assert_eq!(\n            orig_headers\n                .get_all_internal(&HeaderName::from_static(\"host\"))\n                .into_iter()\n                .collect::<Vec<_>>(),\n            vec![&Bytes::from(\"Host\")]\n        );\n        assert_eq!(\n            orig_headers\n                .get_all_internal(&HeaderName::from_static(\"x-bread\"))\n                .into_iter()\n                .collect::<Vec<_>>(),\n            vec![&Bytes::from(\"X-BREAD\")]\n        );\n    }\n\n    #[test]\n    fn test_decoder_request() {\n        fn parse(s: &str) -> ParsedMessage<RequestLine> {\n            let mut bytes = BytesMut::from(s);\n            Server::parse(\n                &mut bytes,\n                ParseContext {\n                    cached_headers: &mut None,\n                    req_method: &mut None,\n                    h1_parser_config: Default::default(),\n                    preserve_header_case: false,\n                    h09_responses: false,\n                },\n            )\n            .expect(\"parse ok\")\n            .expect(\"parse complete\")\n        }\n\n        fn parse_err(s: &str, comment: &str) -> crate::error::Parse {\n            let mut bytes = BytesMut::from(s);\n            Server::parse(\n                &mut bytes,\n                ParseContext {\n                    cached_headers: &mut None,\n                    req_method: &mut None,\n                    h1_parser_config: Default::default(),\n                    preserve_header_case: false,\n                    h09_responses: false,\n                },\n            )\n            .expect_err(comment)\n        }\n\n        // no length or transfer-encoding means 0-length body\n        assert_eq!(\n            parse(\n                \"\\\n                 GET / HTTP/1.1\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::ZERO\n        );\n\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::ZERO\n        );\n\n        // transfer-encoding: chunked\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 transfer-encoding: chunked\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 transfer-encoding: gzip, chunked\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 transfer-encoding: gzip\\r\\n\\\n                 transfer-encoding: chunked\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        // content-length\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::new(10)\n        );\n\n        // transfer-encoding and content-length = chunked\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 transfer-encoding: chunked\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 transfer-encoding: chunked\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 transfer-encoding: gzip\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 transfer-encoding: chunked\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        // multiple content-lengths of same value are fine\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::new(10)\n        );\n\n        // multiple content-lengths with different values is an error\n        parse_err(\n            \"\\\n             POST / HTTP/1.1\\r\\n\\\n             content-length: 10\\r\\n\\\n             content-length: 11\\r\\n\\\n             \\r\\n\\\n             \",\n            \"multiple content-lengths\",\n        );\n\n        // transfer-encoding that isn't chunked is an error\n        parse_err(\n            \"\\\n             POST / HTTP/1.1\\r\\n\\\n             transfer-encoding: gzip\\r\\n\\\n             \\r\\n\\\n             \",\n            \"transfer-encoding but not chunked\",\n        );\n\n        parse_err(\n            \"\\\n             POST / HTTP/1.1\\r\\n\\\n             transfer-encoding: chunked, gzip\\r\\n\\\n             \\r\\n\\\n             \",\n            \"transfer-encoding doesn't end in chunked\",\n        );\n\n        parse_err(\n            \"\\\n             POST / HTTP/1.1\\r\\n\\\n             transfer-encoding: chunked\\r\\n\\\n             transfer-encoding: afterlol\\r\\n\\\n             \\r\\n\\\n             \",\n            \"transfer-encoding multiple lines doesn't end in chunked\",\n        );\n\n        // http/1.0\n\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.0\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::new(10)\n        );\n\n        // 1.0 doesn't understand chunked, so its an error\n        parse_err(\n            \"\\\n             POST / HTTP/1.0\\r\\n\\\n             transfer-encoding: chunked\\r\\n\\\n             \\r\\n\\\n             \",\n            \"1.0 chunked\",\n        );\n    }\n\n    #[test]\n    fn test_decoder_response() {\n        fn parse(s: &str) -> ParsedMessage<StatusCode> {\n            parse_with_method(s, Method::GET)\n        }\n\n        fn parse_ignores(s: &str) {\n            let mut bytes = BytesMut::from(s);\n            assert!(Client::parse(\n                &mut bytes,\n                ParseContext {\n                    cached_headers: &mut None,\n                    req_method: &mut Some(Method::GET),\n                    h1_parser_config: Default::default(),\n                    preserve_header_case: false,\n                    h09_responses: false,\n                }\n            )\n            .expect(\"parse ok\")\n            .is_none())\n        }\n\n        fn parse_with_method(s: &str, m: Method) -> ParsedMessage<StatusCode> {\n            let mut bytes = BytesMut::from(s);\n            Client::parse(\n                &mut bytes,\n                ParseContext {\n                    cached_headers: &mut None,\n                    req_method: &mut Some(m),\n                    h1_parser_config: Default::default(),\n                    preserve_header_case: false,\n                    h09_responses: false,\n                },\n            )\n            .expect(\"parse ok\")\n            .expect(\"parse complete\")\n        }\n\n        fn parse_err(s: &str) -> crate::error::Parse {\n            let mut bytes = BytesMut::from(s);\n            Client::parse(\n                &mut bytes,\n                ParseContext {\n                    cached_headers: &mut None,\n                    req_method: &mut Some(Method::GET),\n                    h1_parser_config: Default::default(),\n                    preserve_header_case: false,\n                    h09_responses: false,\n                },\n            )\n            .expect_err(\"parse should err\")\n        }\n\n        // no content-length or transfer-encoding means close-delimited\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CLOSE_DELIMITED\n        );\n\n        // 204 and 304 never have a body\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 204 No Content\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::ZERO\n        );\n\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 304 Not Modified\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::ZERO\n        );\n\n        // content-length\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 content-length: 8\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::new(8)\n        );\n\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 content-length: 8\\r\\n\\\n                 content-length: 8\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::new(8)\n        );\n\n        parse_err(\n            \"\\\n             HTTP/1.1 200 OK\\r\\n\\\n             content-length: 8\\r\\n\\\n             content-length: 9\\r\\n\\\n             \\r\\n\\\n             \",\n        );\n\n        // transfer-encoding: chunked\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 transfer-encoding: chunked\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        // transfer-encoding not-chunked is close-delimited\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 transfer-encoding: yolo\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CLOSE_DELIMITED\n        );\n\n        // transfer-encoding and content-length = chunked\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 transfer-encoding: chunked\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        // HEAD can have content-length, but not body\n        assert_eq!(\n            parse_with_method(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 content-length: 8\\r\\n\\\n                 \\r\\n\\\n                 \",\n                Method::HEAD\n            )\n            .decode,\n            DecodedLength::ZERO\n        );\n\n        // CONNECT with 200 never has body\n        {\n            let msg = parse_with_method(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 \\r\\n\\\n                 \",\n                Method::CONNECT,\n            );\n            assert_eq!(msg.decode, DecodedLength::ZERO);\n            assert!(!msg.keep_alive, \"should be upgrade\");\n            assert!(msg.wants_upgrade, \"should be upgrade\");\n        }\n\n        // CONNECT receiving non 200 can have a body\n        assert_eq!(\n            parse_with_method(\n                \"\\\n                 HTTP/1.1 400 Bad Request\\r\\n\\\n                 \\r\\n\\\n                 \",\n                Method::CONNECT\n            )\n            .decode,\n            DecodedLength::CLOSE_DELIMITED\n        );\n\n        // 1xx status codes\n        parse_ignores(\n            \"\\\n             HTTP/1.1 100 Continue\\r\\n\\\n             \\r\\n\\\n             \",\n        );\n\n        parse_ignores(\n            \"\\\n             HTTP/1.1 103 Early Hints\\r\\n\\\n             \\r\\n\\\n             \",\n        );\n\n        // 101 upgrade not supported yet\n        {\n            let msg = parse(\n                \"\\\n                 HTTP/1.1 101 Switching Protocols\\r\\n\\\n                 \\r\\n\\\n                 \",\n            );\n            assert_eq!(msg.decode, DecodedLength::ZERO);\n            assert!(!msg.keep_alive, \"should be last\");\n            assert!(msg.wants_upgrade, \"should be upgrade\");\n        }\n\n        // http/1.0\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.0 200 OK\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CLOSE_DELIMITED\n        );\n\n        // 1.0 doesn't understand chunked\n        parse_err(\n            \"\\\n             HTTP/1.0 200 OK\\r\\n\\\n             transfer-encoding: chunked\\r\\n\\\n             \\r\\n\\\n             \",\n        );\n\n        // keep-alive\n        assert!(\n            parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 content-length: 0\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .keep_alive,\n            \"HTTP/1.1 keep-alive is default\"\n        );\n\n        assert!(\n            !parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 content-length: 0\\r\\n\\\n                 connection: foo, close, bar\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .keep_alive,\n            \"connection close is always close\"\n        );\n\n        assert!(\n            !parse(\n                \"\\\n                 HTTP/1.0 200 OK\\r\\n\\\n                 content-length: 0\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .keep_alive,\n            \"HTTP/1.0 close is default\"\n        );\n\n        assert!(\n            parse(\n                \"\\\n                 HTTP/1.0 200 OK\\r\\n\\\n                 content-length: 0\\r\\n\\\n                 connection: foo, keep-alive, bar\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .keep_alive,\n            \"connection keep-alive is always keep-alive\"\n        );\n    }\n\n    #[test]\n    fn test_client_request_encode_title_case() {\n        use crate::proto::BodyLength;\n        use http::header::HeaderValue;\n\n        let mut head = MessageHead::default();\n        head.headers\n            .insert(\"content-length\", HeaderValue::from_static(\"10\"));\n        head.headers\n            .insert(\"content-type\", HeaderValue::from_static(\"application/json\"));\n        head.headers.insert(\"*-*\", HeaderValue::from_static(\"o_o\"));\n\n        let mut vec = Vec::new();\n        Client::encode(\n            Encode {\n                head: &mut head,\n                body: Some(BodyLength::Known(10)),\n                keep_alive: true,\n                req_method: &mut None,\n                title_case_headers: true,\n            },\n            &mut vec,\n        )\n        .unwrap();\n\n        assert_eq!(vec, b\"GET / HTTP/1.1\\r\\nContent-Length: 10\\r\\nContent-Type: application/json\\r\\n*-*: o_o\\r\\n\\r\\n\".to_vec());\n    }\n\n    #[test]\n    fn test_client_request_encode_orig_case() {\n        use crate::proto::BodyLength;\n        use http::header::{HeaderValue, CONTENT_LENGTH};\n\n        let mut head = MessageHead::default();\n        head.headers\n            .insert(\"content-length\", HeaderValue::from_static(\"10\"));\n        head.headers\n            .insert(\"content-type\", HeaderValue::from_static(\"application/json\"));\n\n        let mut orig_headers = HeaderCaseMap::default();\n        orig_headers.insert(CONTENT_LENGTH, \"CONTENT-LENGTH\".into());\n        head.extensions.insert(orig_headers);\n\n        let mut vec = Vec::new();\n        Client::encode(\n            Encode {\n                head: &mut head,\n                body: Some(BodyLength::Known(10)),\n                keep_alive: true,\n                req_method: &mut None,\n                title_case_headers: false,\n            },\n            &mut vec,\n        )\n        .unwrap();\n\n        assert_eq!(\n            &*vec,\n            b\"GET / HTTP/1.1\\r\\nCONTENT-LENGTH: 10\\r\\ncontent-type: application/json\\r\\n\\r\\n\"\n                .as_ref(),\n        );\n    }\n    #[test]\n    fn test_client_request_encode_orig_and_title_case() {\n        use crate::proto::BodyLength;\n        use http::header::{HeaderValue, CONTENT_LENGTH};\n\n        let mut head = MessageHead::default();\n        head.headers\n            .insert(\"content-length\", HeaderValue::from_static(\"10\"));\n        head.headers\n            .insert(\"content-type\", HeaderValue::from_static(\"application/json\"));\n\n        let mut orig_headers = HeaderCaseMap::default();\n        orig_headers.insert(CONTENT_LENGTH, \"CONTENT-LENGTH\".into());\n        head.extensions.insert(orig_headers);\n\n        let mut vec = Vec::new();\n        Client::encode(\n            Encode {\n                head: &mut head,\n                body: Some(BodyLength::Known(10)),\n                keep_alive: true,\n                req_method: &mut None,\n                title_case_headers: true,\n            },\n            &mut vec,\n        )\n        .unwrap();\n\n        assert_eq!(\n            &*vec,\n            b\"GET / HTTP/1.1\\r\\nCONTENT-LENGTH: 10\\r\\nContent-Type: application/json\\r\\n\\r\\n\"\n                .as_ref(),\n        );\n    }\n\n    #[test]\n    fn test_server_encode_connect_method() {\n        let mut head = MessageHead::default();\n\n        let mut vec = Vec::new();\n        let encoder = Server::encode(\n            Encode {\n                head: &mut head,\n                body: None,\n                keep_alive: true,\n                req_method: &mut Some(Method::CONNECT),\n                title_case_headers: false,\n            },\n            &mut vec,\n        )\n        .unwrap();\n\n        assert!(encoder.is_last());\n    }\n\n    #[test]\n    fn test_server_response_encode_title_case() {\n        use crate::proto::BodyLength;\n        use http::header::HeaderValue;\n\n        let mut head = MessageHead::default();\n        head.headers\n            .insert(\"content-length\", HeaderValue::from_static(\"10\"));\n        head.headers\n            .insert(\"content-type\", HeaderValue::from_static(\"application/json\"));\n\n        let mut vec = Vec::new();\n        Server::encode(\n            Encode {\n                head: &mut head,\n                body: Some(BodyLength::Known(10)),\n                keep_alive: true,\n                req_method: &mut None,\n                title_case_headers: true,\n            },\n            &mut vec,\n        )\n        .unwrap();\n\n        let expected_response =\n            b\"HTTP/1.1 200 OK\\r\\nContent-Length: 10\\r\\nContent-Type: application/json\\r\\n\";\n\n        assert_eq!(&vec[..expected_response.len()], &expected_response[..]);\n    }\n\n    #[test]\n    fn test_server_response_encode_orig_case() {\n        use crate::proto::BodyLength;\n        use http::header::{HeaderValue, CONTENT_LENGTH};\n\n        let mut head = MessageHead::default();\n        head.headers\n            .insert(\"content-length\", HeaderValue::from_static(\"10\"));\n        head.headers\n            .insert(\"content-type\", HeaderValue::from_static(\"application/json\"));\n\n        let mut orig_headers = HeaderCaseMap::default();\n        orig_headers.insert(CONTENT_LENGTH, \"CONTENT-LENGTH\".into());\n        head.extensions.insert(orig_headers);\n\n        let mut vec = Vec::new();\n        Server::encode(\n            Encode {\n                head: &mut head,\n                body: Some(BodyLength::Known(10)),\n                keep_alive: true,\n                req_method: &mut None,\n                title_case_headers: false,\n            },\n            &mut vec,\n        )\n        .unwrap();\n\n        let expected_response =\n            b\"HTTP/1.1 200 OK\\r\\nCONTENT-LENGTH: 10\\r\\ncontent-type: application/json\\r\\ndate: \";\n\n        assert_eq!(&vec[..expected_response.len()], &expected_response[..]);\n    }\n\n    #[test]\n    fn test_server_response_encode_orig_and_title_case() {\n        use crate::proto::BodyLength;\n        use http::header::{HeaderValue, CONTENT_LENGTH};\n\n        let mut head = MessageHead::default();\n        head.headers\n            .insert(\"content-length\", HeaderValue::from_static(\"10\"));\n        head.headers\n            .insert(\"content-type\", HeaderValue::from_static(\"application/json\"));\n\n        let mut orig_headers = HeaderCaseMap::default();\n        orig_headers.insert(CONTENT_LENGTH, \"CONTENT-LENGTH\".into());\n        head.extensions.insert(orig_headers);\n\n        let mut vec = Vec::new();\n        Server::encode(\n            Encode {\n                head: &mut head,\n                body: Some(BodyLength::Known(10)),\n                keep_alive: true,\n                req_method: &mut None,\n                title_case_headers: true,\n            },\n            &mut vec,\n        )\n        .unwrap();\n\n        let expected_response =\n            b\"HTTP/1.1 200 OK\\r\\nCONTENT-LENGTH: 10\\r\\nContent-Type: application/json\\r\\nDate: \";\n\n        assert_eq!(&vec[..expected_response.len()], &expected_response[..]);\n    }\n\n    #[test]\n    fn parse_header_htabs() {\n        let mut bytes = BytesMut::from(\"HTTP/1.1 200 OK\\r\\nserver: hello\\tworld\\r\\n\\r\\n\");\n        let parsed = Client::parse(\n            &mut bytes,\n            ParseContext {\n                cached_headers: &mut None,\n                req_method: &mut Some(Method::GET),\n                h1_parser_config: Default::default(),\n                preserve_header_case: false,\n                h09_responses: false,\n            },\n        )\n        .expect(\"parse ok\")\n        .expect(\"parse complete\");\n\n        assert_eq!(parsed.head.headers[\"server\"], \"hello\\tworld\");\n    }\n\n    #[test]\n    fn test_write_headers_orig_case_empty_value() {\n        let mut headers = HeaderMap::new();\n        let name = http::header::HeaderName::from_static(\"x-empty\");\n        headers.insert(&name, \"\".parse().expect(\"parse empty\"));\n        let mut orig_cases = HeaderCaseMap::default();\n        orig_cases.insert(name, Bytes::from_static(b\"X-EmptY\"));\n\n        let mut dst = Vec::new();\n        super::write_headers_original_case(&headers, &orig_cases, &mut dst, false);\n\n        assert_eq!(\n            dst, b\"X-EmptY:\\r\\n\",\n            \"there should be no space between the colon and CRLF\"\n        );\n    }\n\n    #[test]\n    fn test_write_headers_orig_case_multiple_entries() {\n        let mut headers = HeaderMap::new();\n        let name = http::header::HeaderName::from_static(\"x-empty\");\n        headers.insert(&name, \"a\".parse().unwrap());\n        headers.append(&name, \"b\".parse().unwrap());\n\n        let mut orig_cases = HeaderCaseMap::default();\n        orig_cases.insert(name.clone(), Bytes::from_static(b\"X-Empty\"));\n        orig_cases.append(name, Bytes::from_static(b\"X-EMPTY\"));\n\n        let mut dst = Vec::new();\n        super::write_headers_original_case(&headers, &orig_cases, &mut dst, false);\n\n        assert_eq!(dst, b\"X-Empty: a\\r\\nX-EMPTY: b\\r\\n\");\n    }\n\n    #[cfg(feature = \"nightly\")]\n    use test::Bencher;\n\n    #[cfg(feature = \"nightly\")]\n    #[bench]\n    fn bench_parse_incoming(b: &mut Bencher) {\n        let mut raw = BytesMut::from(\n            &b\"GET /super_long_uri/and_whatever?what_should_we_talk_about/\\\n            I_wonder/Hard_to_write_in_an_uri_after_all/you_have_to_make\\\n            _up_the_punctuation_yourself/how_fun_is_that?test=foo&test1=\\\n            foo1&test2=foo2&test3=foo3&test4=foo4 HTTP/1.1\\r\\nHost: \\\n            hyper.rs\\r\\nAccept: a lot of things\\r\\nAccept-Charset: \\\n            utf8\\r\\nAccept-Encoding: *\\r\\nAccess-Control-Allow-\\\n            Credentials: None\\r\\nAccess-Control-Allow-Origin: None\\r\\n\\\n            Access-Control-Allow-Methods: None\\r\\nAccess-Control-Allow-\\\n            Headers: None\\r\\nContent-Encoding: utf8\\r\\nContent-Security-\\\n            Policy: None\\r\\nContent-Type: text/html\\r\\nOrigin: hyper\\\n            \\r\\nSec-Websocket-Extensions: It looks super important!\\r\\n\\\n            Sec-Websocket-Origin: hyper\\r\\nSec-Websocket-Version: 4.3\\r\\\n            \\nStrict-Transport-Security: None\\r\\nUser-Agent: hyper\\r\\n\\\n            X-Content-Duration: None\\r\\nX-Content-Security-Policy: None\\\n            \\r\\nX-DNSPrefetch-Control: None\\r\\nX-Frame-Options: \\\n            Something important obviously\\r\\nX-Requested-With: Nothing\\\n            \\r\\n\\r\\n\"[..],\n        );\n        let len = raw.len();\n        let mut headers = Some(HeaderMap::new());\n\n        b.bytes = len as u64;\n        b.iter(|| {\n            let mut msg = Server::parse(\n                &mut raw,\n                ParseContext {\n                    cached_headers: &mut headers,\n                    req_method: &mut None,\n                    h1_parser_config: Default::default(),\n                    preserve_header_case: false,\n                    h09_responses: false,\n                },\n            )\n            .unwrap()\n            .unwrap();\n            ::test::black_box(&msg);\n            msg.head.headers.clear();\n            headers = Some(msg.head.headers);\n            restart(&mut raw, len);\n        });\n\n        fn restart(b: &mut BytesMut, len: usize) {\n            b.reserve(1);\n            unsafe {\n                b.set_len(len);\n            }\n        }\n    }\n\n    #[cfg(feature = \"nightly\")]\n    #[bench]\n    fn bench_parse_short(b: &mut Bencher) {\n        let s = &b\"GET / HTTP/1.1\\r\\nHost: localhost:8080\\r\\n\\r\\n\"[..];\n        let mut raw = BytesMut::from(s);\n        let len = raw.len();\n        let mut headers = Some(HeaderMap::new());\n\n        b.bytes = len as u64;\n        b.iter(|| {\n            let mut msg = Server::parse(\n                &mut raw,\n                ParseContext {\n                    cached_headers: &mut headers,\n                    req_method: &mut None,\n                    h1_parser_config: Default::default(),\n                    preserve_header_case: false,\n                    h09_responses: false,\n                },\n            )\n            .unwrap()\n            .unwrap();\n            ::test::black_box(&msg);\n            msg.head.headers.clear();\n            headers = Some(msg.head.headers);\n            restart(&mut raw, len);\n        });\n\n        fn restart(b: &mut BytesMut, len: usize) {\n            b.reserve(1);\n            unsafe {\n                b.set_len(len);\n            }\n        }\n    }\n\n    #[cfg(feature = \"nightly\")]\n    #[bench]\n    fn bench_server_encode_headers_preset(b: &mut Bencher) {\n        use crate::proto::BodyLength;\n        use http::header::HeaderValue;\n\n        let len = 108;\n        b.bytes = len as u64;\n\n        let mut head = MessageHead::default();\n        let mut headers = HeaderMap::new();\n        headers.insert(\"content-length\", HeaderValue::from_static(\"10\"));\n        headers.insert(\"content-type\", HeaderValue::from_static(\"application/json\"));\n\n        b.iter(|| {\n            let mut vec = Vec::new();\n            head.headers = headers.clone();\n            Server::encode(\n                Encode {\n                    head: &mut head,\n                    body: Some(BodyLength::Known(10)),\n                    keep_alive: true,\n                    req_method: &mut Some(Method::GET),\n                    title_case_headers: false,\n                },\n                &mut vec,\n            )\n            .unwrap();\n            assert_eq!(vec.len(), len);\n            ::test::black_box(vec);\n        })\n    }\n\n    #[cfg(feature = \"nightly\")]\n    #[bench]\n    fn bench_server_encode_no_headers(b: &mut Bencher) {\n        use crate::proto::BodyLength;\n\n        let len = 76;\n        b.bytes = len as u64;\n\n        let mut head = MessageHead::default();\n        let mut vec = Vec::with_capacity(128);\n\n        b.iter(|| {\n            Server::encode(\n                Encode {\n                    head: &mut head,\n                    body: Some(BodyLength::Known(10)),\n                    keep_alive: true,\n                    req_method: &mut Some(Method::GET),\n                    title_case_headers: false,\n                },\n                &mut vec,\n            )\n            .unwrap();\n            assert_eq!(vec.len(), len);\n            ::test::black_box(&vec);\n\n            vec.clear();\n        })\n    }\n}\n"
  },
  {
    "project": "hyper",
    "target": 1,
    "commit_id": "73bff4e98c372ce04b006370c0b0d2af29ea8718",
    "func": "// `mem::uninitialized` replaced with `mem::MaybeUninit`,\n// can't upgrade yet\n#![allow(deprecated)]\n\nuse std::fmt::{self, Write};\nuse std::mem;\n\n#[cfg(any(test, feature = \"server\", feature = \"ffi\"))]\nuse bytes::Bytes;\nuse bytes::BytesMut;\n#[cfg(feature = \"server\")]\nuse http::header::ValueIter;\nuse http::header::{self, Entry, HeaderName, HeaderValue};\nuse http::{HeaderMap, Method, StatusCode, Version};\n\nuse crate::body::DecodedLength;\n#[cfg(feature = \"server\")]\nuse crate::common::date;\nuse crate::error::Parse;\nuse crate::ext::HeaderCaseMap;\nuse crate::headers;\nuse crate::proto::h1::{\n    Encode, Encoder, Http1Transaction, ParseContext, ParseResult, ParsedMessage,\n};\nuse crate::proto::{BodyLength, MessageHead, RequestHead, RequestLine};\n\nconst MAX_HEADERS: usize = 100;\nconst AVERAGE_HEADER_SIZE: usize = 30; // totally scientific\n\nmacro_rules! header_name {\n    ($bytes:expr) => {{\n        {\n            match HeaderName::from_bytes($bytes) {\n                Ok(name) => name,\n                Err(e) => maybe_panic!(e),\n            }\n        }\n    }};\n}\n\nmacro_rules! header_value {\n    ($bytes:expr) => {{\n        {\n            unsafe { HeaderValue::from_maybe_shared_unchecked($bytes) }\n        }\n    }};\n}\n\nmacro_rules! maybe_panic {\n    ($($arg:tt)*) => ({\n        let _err = ($($arg)*);\n        if cfg!(debug_assertions) {\n            panic!(\"{:?}\", _err);\n        } else {\n            error!(\"Internal Hyper error, please report {:?}\", _err);\n            return Err(Parse::Internal)\n        }\n    })\n}\n\npub(super) fn parse_headers<T>(\n    bytes: &mut BytesMut,\n    ctx: ParseContext<'_>,\n) -> ParseResult<T::Incoming>\nwhere\n    T: Http1Transaction,\n{\n    // If the buffer is empty, don't bother entering the span, it's just noise.\n    if bytes.is_empty() {\n        return Ok(None);\n    }\n\n    let span = trace_span!(\"parse_headers\");\n    let _s = span.enter();\n    T::parse(bytes, ctx)\n}\n\npub(super) fn encode_headers<T>(\n    enc: Encode<'_, T::Outgoing>,\n    dst: &mut Vec<u8>,\n) -> crate::Result<Encoder>\nwhere\n    T: Http1Transaction,\n{\n    let span = trace_span!(\"encode_headers\");\n    let _s = span.enter();\n    T::encode(enc, dst)\n}\n\n// There are 2 main roles, Client and Server.\n\n#[cfg(feature = \"client\")]\npub(crate) enum Client {}\n\n#[cfg(feature = \"server\")]\npub(crate) enum Server {}\n\n#[cfg(feature = \"server\")]\nimpl Http1Transaction for Server {\n    type Incoming = RequestLine;\n    type Outgoing = StatusCode;\n    const LOG: &'static str = \"{role=server}\";\n\n    fn parse(buf: &mut BytesMut, ctx: ParseContext<'_>) -> ParseResult<RequestLine> {\n        debug_assert!(!buf.is_empty(), \"parse called with empty buf\");\n\n        let mut keep_alive;\n        let is_http_11;\n        let subject;\n        let version;\n        let len;\n        let headers_len;\n\n        // Unsafe: both headers_indices and headers are using uninitialized memory,\n        // but we *never* read any of it until after httparse has assigned\n        // values into it. By not zeroing out the stack memory, this saves\n        // a good ~5% on pipeline benchmarks.\n        let mut headers_indices: [HeaderIndices; MAX_HEADERS] = unsafe { mem::uninitialized() };\n        {\n            let mut headers: [httparse::Header<'_>; MAX_HEADERS] = unsafe { mem::uninitialized() };\n            trace!(\n                \"Request.parse([Header; {}], [u8; {}])\",\n                headers.len(),\n                buf.len()\n            );\n            let mut req = httparse::Request::new(&mut headers);\n            let bytes = buf.as_ref();\n            match req.parse(bytes) {\n                Ok(httparse::Status::Complete(parsed_len)) => {\n                    trace!(\"Request.parse Complete({})\", parsed_len);\n                    len = parsed_len;\n                    subject = RequestLine(\n                        Method::from_bytes(req.method.unwrap().as_bytes())?,\n                        req.path.unwrap().parse()?,\n                    );\n                    version = if req.version.unwrap() == 1 {\n                        keep_alive = true;\n                        is_http_11 = true;\n                        Version::HTTP_11\n                    } else {\n                        keep_alive = false;\n                        is_http_11 = false;\n                        Version::HTTP_10\n                    };\n                    trace!(\"headers: {:?}\", &req.headers);\n\n                    record_header_indices(bytes, &req.headers, &mut headers_indices)?;\n                    headers_len = req.headers.len();\n                }\n                Ok(httparse::Status::Partial) => return Ok(None),\n                Err(err) => {\n                    return Err(match err {\n                        // if invalid Token, try to determine if for method or path\n                        httparse::Error::Token => {\n                            if req.method.is_none() {\n                                Parse::Method\n                            } else {\n                                debug_assert!(req.path.is_none());\n                                Parse::Uri\n                            }\n                        }\n                        other => other.into(),\n                    });\n                }\n            }\n        };\n\n        let slice = buf.split_to(len).freeze();\n\n        // According to https://tools.ietf.org/html/rfc7230#section-3.3.3\n        // 1. (irrelevant to Request)\n        // 2. (irrelevant to Request)\n        // 3. Transfer-Encoding: chunked has a chunked body.\n        // 4. If multiple differing Content-Length headers or invalid, close connection.\n        // 5. Content-Length header has a sized body.\n        // 6. Length 0.\n        // 7. (irrelevant to Request)\n\n        let mut decoder = DecodedLength::ZERO;\n        let mut expect_continue = false;\n        let mut con_len = None;\n        let mut is_te = false;\n        let mut is_te_chunked = false;\n        let mut wants_upgrade = subject.0 == Method::CONNECT;\n\n        let mut header_case_map = if ctx.preserve_header_case {\n            Some(HeaderCaseMap::default())\n        } else {\n            None\n        };\n\n        let mut headers = ctx.cached_headers.take().unwrap_or_else(HeaderMap::new);\n\n        headers.reserve(headers_len);\n\n        for header in &headers_indices[..headers_len] {\n            let name = header_name!(&slice[header.name.0..header.name.1]);\n            let value = header_value!(slice.slice(header.value.0..header.value.1));\n\n            match name {\n                header::TRANSFER_ENCODING => {\n                    // https://tools.ietf.org/html/rfc7230#section-3.3.3\n                    // If Transfer-Encoding header is present, and 'chunked' is\n                    // not the final encoding, and this is a Request, then it is\n                    // malformed. A server should respond with 400 Bad Request.\n                    if !is_http_11 {\n                        debug!(\"HTTP/1.0 cannot have Transfer-Encoding header\");\n                        return Err(Parse::transfer_encoding_unexpected());\n                    }\n                    is_te = true;\n                    if headers::is_chunked_(&value) {\n                        is_te_chunked = true;\n                        decoder = DecodedLength::CHUNKED;\n                    } else {\n                        is_te_chunked = false;\n                    }\n                }\n                header::CONTENT_LENGTH => {\n                    if is_te {\n                        continue;\n                    }\n                    let len = headers::content_length_parse(&value)\n                        .ok_or_else(Parse::content_length_invalid)?;\n                    if let Some(prev) = con_len {\n                        if prev != len {\n                            debug!(\n                                \"multiple Content-Length headers with different values: [{}, {}]\",\n                                prev, len,\n                            );\n                            return Err(Parse::content_length_invalid());\n                        }\n                        // we don't need to append this secondary length\n                        continue;\n                    }\n                    decoder = DecodedLength::checked_new(len)?;\n                    con_len = Some(len);\n                }\n                header::CONNECTION => {\n                    // keep_alive was previously set to default for Version\n                    if keep_alive {\n                        // HTTP/1.1\n                        keep_alive = !headers::connection_close(&value);\n                    } else {\n                        // HTTP/1.0\n                        keep_alive = headers::connection_keep_alive(&value);\n                    }\n                }\n                header::EXPECT => {\n                    expect_continue = value.as_bytes() == b\"100-continue\";\n                }\n                header::UPGRADE => {\n                    // Upgrades are only allowed with HTTP/1.1\n                    wants_upgrade = is_http_11;\n                }\n\n                _ => (),\n            }\n\n            if let Some(ref mut header_case_map) = header_case_map {\n                header_case_map.append(&name, slice.slice(header.name.0..header.name.1));\n            }\n\n            headers.append(name, value);\n        }\n\n        if is_te && !is_te_chunked {\n            debug!(\"request with transfer-encoding header, but not chunked, bad request\");\n            return Err(Parse::transfer_encoding_invalid());\n        }\n\n        let mut extensions = http::Extensions::default();\n\n        if let Some(header_case_map) = header_case_map {\n            extensions.insert(header_case_map);\n        }\n\n        *ctx.req_method = Some(subject.0.clone());\n\n        Ok(Some(ParsedMessage {\n            head: MessageHead {\n                version,\n                subject,\n                headers,\n                extensions,\n            },\n            decode: decoder,\n            expect_continue,\n            keep_alive,\n            wants_upgrade,\n        }))\n    }\n\n    fn encode(mut msg: Encode<'_, Self::Outgoing>, dst: &mut Vec<u8>) -> crate::Result<Encoder> {\n        trace!(\n            \"Server::encode status={:?}, body={:?}, req_method={:?}\",\n            msg.head.subject,\n            msg.body,\n            msg.req_method\n        );\n\n        let mut wrote_len = false;\n\n        // hyper currently doesn't support returning 1xx status codes as a Response\n        // This is because Service only allows returning a single Response, and\n        // so if you try to reply with a e.g. 100 Continue, you have no way of\n        // replying with the latter status code response.\n        let (ret, is_last) = if msg.head.subject == StatusCode::SWITCHING_PROTOCOLS {\n            (Ok(()), true)\n        } else if msg.req_method == &Some(Method::CONNECT) && msg.head.subject.is_success() {\n            // Sending content-length or transfer-encoding header on 2xx response\n            // to CONNECT is forbidden in RFC 7231.\n            wrote_len = true;\n            (Ok(()), true)\n        } else if msg.head.subject.is_informational() {\n            warn!(\"response with 1xx status code not supported\");\n            *msg.head = MessageHead::default();\n            msg.head.subject = StatusCode::INTERNAL_SERVER_ERROR;\n            msg.body = None;\n            (Err(crate::Error::new_user_unsupported_status_code()), true)\n        } else {\n            (Ok(()), !msg.keep_alive)\n        };\n\n        // In some error cases, we don't know about the invalid message until already\n        // pushing some bytes onto the `dst`. In those cases, we don't want to send\n        // the half-pushed message, so rewind to before.\n        let orig_len = dst.len();\n\n        let init_cap = 30 + msg.head.headers.len() * AVERAGE_HEADER_SIZE;\n        dst.reserve(init_cap);\n        if msg.head.version == Version::HTTP_11 && msg.head.subject == StatusCode::OK {\n            extend(dst, b\"HTTP/1.1 200 OK\\r\\n\");\n        } else {\n            match msg.head.version {\n                Version::HTTP_10 => extend(dst, b\"HTTP/1.0 \"),\n                Version::HTTP_11 => extend(dst, b\"HTTP/1.1 \"),\n                Version::HTTP_2 => {\n                    debug!(\"response with HTTP2 version coerced to HTTP/1.1\");\n                    extend(dst, b\"HTTP/1.1 \");\n                }\n                other => panic!(\"unexpected response version: {:?}\", other),\n            }\n\n            extend(dst, msg.head.subject.as_str().as_bytes());\n            extend(dst, b\" \");\n            // a reason MUST be written, as many parsers will expect it.\n            extend(\n                dst,\n                msg.head\n                    .subject\n                    .canonical_reason()\n                    .unwrap_or(\"<none>\")\n                    .as_bytes(),\n            );\n            extend(dst, b\"\\r\\n\");\n        }\n\n        let orig_headers;\n        let extensions = mem::take(&mut msg.head.extensions);\n        let orig_headers = match extensions.get::<HeaderCaseMap>() {\n            None if msg.title_case_headers => {\n                orig_headers = HeaderCaseMap::default();\n                Some(&orig_headers)\n            }\n            orig_headers => orig_headers,\n        };\n        let encoder = if let Some(orig_headers) = orig_headers {\n            Self::encode_headers_with_original_case(\n                msg,\n                dst,\n                is_last,\n                orig_len,\n                wrote_len,\n                orig_headers,\n            )?\n        } else {\n            Self::encode_headers_with_lower_case(msg, dst, is_last, orig_len, wrote_len)?\n        };\n\n        ret.map(|()| encoder)\n    }\n\n    fn on_error(err: &crate::Error) -> Option<MessageHead<Self::Outgoing>> {\n        use crate::error::Kind;\n        let status = match *err.kind() {\n            Kind::Parse(Parse::Method)\n            | Kind::Parse(Parse::Header(_))\n            | Kind::Parse(Parse::Uri)\n            | Kind::Parse(Parse::Version) => StatusCode::BAD_REQUEST,\n            Kind::Parse(Parse::TooLarge) => StatusCode::REQUEST_HEADER_FIELDS_TOO_LARGE,\n            _ => return None,\n        };\n\n        debug!(\"sending automatic response ({}) for parse error\", status);\n        let mut msg = MessageHead::default();\n        msg.subject = status;\n        Some(msg)\n    }\n\n    fn is_server() -> bool {\n        true\n    }\n\n    fn update_date() {\n        date::update();\n    }\n}\n\n#[cfg(feature = \"server\")]\nimpl Server {\n    fn can_have_body(method: &Option<Method>, status: StatusCode) -> bool {\n        Server::can_chunked(method, status)\n    }\n\n    fn can_chunked(method: &Option<Method>, status: StatusCode) -> bool {\n        if method == &Some(Method::HEAD) || method == &Some(Method::CONNECT) && status.is_success()\n        {\n            false\n        } else if status.is_informational() {\n            false\n        } else {\n            match status {\n                StatusCode::NO_CONTENT | StatusCode::NOT_MODIFIED => false,\n                _ => true,\n            }\n        }\n    }\n\n    fn can_have_content_length(method: &Option<Method>, status: StatusCode) -> bool {\n        if status.is_informational() || method == &Some(Method::CONNECT) && status.is_success() {\n            false\n        } else {\n            match status {\n                StatusCode::NO_CONTENT | StatusCode::NOT_MODIFIED => false,\n                _ => true,\n            }\n        }\n    }\n\n    fn encode_headers_with_lower_case(\n        msg: Encode<'_, StatusCode>,\n        dst: &mut Vec<u8>,\n        is_last: bool,\n        orig_len: usize,\n        wrote_len: bool,\n    ) -> crate::Result<Encoder> {\n        struct LowercaseWriter;\n\n        impl HeaderNameWriter for LowercaseWriter {\n            #[inline]\n            fn write_full_header_line(\n                &mut self,\n                dst: &mut Vec<u8>,\n                line: &str,\n                _: (HeaderName, &str),\n            ) {\n                extend(dst, line.as_bytes())\n            }\n\n            #[inline]\n            fn write_header_name_with_colon(\n                &mut self,\n                dst: &mut Vec<u8>,\n                name_with_colon: &str,\n                _: HeaderName,\n            ) {\n                extend(dst, name_with_colon.as_bytes())\n            }\n\n            #[inline]\n            fn write_header_name(&mut self, dst: &mut Vec<u8>, name: &HeaderName) {\n                extend(dst, name.as_str().as_bytes())\n            }\n        }\n\n        Self::encode_headers(msg, dst, is_last, orig_len, wrote_len, LowercaseWriter)\n    }\n\n    #[cold]\n    #[inline(never)]\n    fn encode_headers_with_original_case(\n        msg: Encode<'_, StatusCode>,\n        dst: &mut Vec<u8>,\n        is_last: bool,\n        orig_len: usize,\n        wrote_len: bool,\n        orig_headers: &HeaderCaseMap,\n    ) -> crate::Result<Encoder> {\n        struct OrigCaseWriter<'map> {\n            map: &'map HeaderCaseMap,\n            current: Option<(HeaderName, ValueIter<'map, Bytes>)>,\n            title_case_headers: bool,\n        }\n\n        impl HeaderNameWriter for OrigCaseWriter<'_> {\n            #[inline]\n            fn write_full_header_line(\n                &mut self,\n                dst: &mut Vec<u8>,\n                _: &str,\n                (name, rest): (HeaderName, &str),\n            ) {\n                self.write_header_name(dst, &name);\n                extend(dst, rest.as_bytes());\n            }\n\n            #[inline]\n            fn write_header_name_with_colon(\n                &mut self,\n                dst: &mut Vec<u8>,\n                _: &str,\n                name: HeaderName,\n            ) {\n                self.write_header_name(dst, &name);\n                extend(dst, b\": \");\n            }\n\n            #[inline]\n            fn write_header_name(&mut self, dst: &mut Vec<u8>, name: &HeaderName) {\n                let Self {\n                    map,\n                    ref mut current,\n                    title_case_headers,\n                } = *self;\n                if current.as_ref().map_or(true, |(last, _)| last != name) {\n                    *current = None;\n                }\n                let (_, values) =\n                    current.get_or_insert_with(|| (name.clone(), map.get_all_internal(name)));\n\n                if let Some(orig_name) = values.next() {\n                    extend(dst, orig_name);\n                } else if title_case_headers {\n                    title_case(dst, name.as_str().as_bytes());\n                } else {\n                    extend(dst, name.as_str().as_bytes());\n                }\n            }\n        }\n\n        let header_name_writer = OrigCaseWriter {\n            map: orig_headers,\n            current: None,\n            title_case_headers: msg.title_case_headers,\n        };\n\n        Self::encode_headers(msg, dst, is_last, orig_len, wrote_len, header_name_writer)\n    }\n\n    #[inline]\n    fn encode_headers<W>(\n        msg: Encode<'_, StatusCode>,\n        mut dst: &mut Vec<u8>,\n        mut is_last: bool,\n        orig_len: usize,\n        mut wrote_len: bool,\n        mut header_name_writer: W,\n    ) -> crate::Result<Encoder>\n    where\n        W: HeaderNameWriter,\n    {\n        // In some error cases, we don't know about the invalid message until already\n        // pushing some bytes onto the `dst`. In those cases, we don't want to send\n        // the half-pushed message, so rewind to before.\n        let rewind = |dst: &mut Vec<u8>| {\n            dst.truncate(orig_len);\n        };\n\n        let mut encoder = Encoder::length(0);\n        let mut wrote_date = false;\n        let mut cur_name = None;\n        let mut is_name_written = false;\n        let mut must_write_chunked = false;\n        let mut prev_con_len = None;\n\n        macro_rules! handle_is_name_written {\n            () => {{\n                if is_name_written {\n                    // we need to clean up and write the newline\n                    debug_assert_ne!(\n                        &dst[dst.len() - 2..],\n                        b\"\\r\\n\",\n                        \"previous header wrote newline but set is_name_written\"\n                    );\n\n                    if must_write_chunked {\n                        extend(dst, b\", chunked\\r\\n\");\n                    } else {\n                        extend(dst, b\"\\r\\n\");\n                    }\n                }\n            }};\n        }\n\n        'headers: for (opt_name, value) in msg.head.headers.drain() {\n            if let Some(n) = opt_name {\n                cur_name = Some(n);\n                handle_is_name_written!();\n                is_name_written = false;\n            }\n            let name = cur_name.as_ref().expect(\"current header name\");\n            match *name {\n                header::CONTENT_LENGTH => {\n                    if wrote_len && !is_name_written {\n                        warn!(\"unexpected content-length found, canceling\");\n                        rewind(dst);\n                        return Err(crate::Error::new_user_header());\n                    }\n                    match msg.body {\n                        Some(BodyLength::Known(known_len)) => {\n                            // The HttpBody claims to know a length, and\n                            // the headers are already set. For performance\n                            // reasons, we are just going to trust that\n                            // the values match.\n                            //\n                            // In debug builds, we'll assert they are the\n                            // same to help developers find bugs.\n                            #[cfg(debug_assertions)]\n                            {\n                                if let Some(len) = headers::content_length_parse(&value) {\n                                    assert!(\n                                        len == known_len,\n                                        \"payload claims content-length of {}, custom content-length header claims {}\",\n                                        known_len,\n                                        len,\n                                    );\n                                }\n                            }\n\n                            if !is_name_written {\n                                encoder = Encoder::length(known_len);\n                                header_name_writer.write_header_name_with_colon(\n                                    dst,\n                                    \"content-length: \",\n                                    header::CONTENT_LENGTH,\n                                );\n                                extend(dst, value.as_bytes());\n                                wrote_len = true;\n                                is_name_written = true;\n                            }\n                            continue 'headers;\n                        }\n                        Some(BodyLength::Unknown) => {\n                            // The HttpBody impl didn't know how long the\n                            // body is, but a length header was included.\n                            // We have to parse the value to return our\n                            // Encoder...\n\n                            if let Some(len) = headers::content_length_parse(&value) {\n                                if let Some(prev) = prev_con_len {\n                                    if prev != len {\n                                        warn!(\n                                            \"multiple Content-Length values found: [{}, {}]\",\n                                            prev, len\n                                        );\n                                        rewind(dst);\n                                        return Err(crate::Error::new_user_header());\n                                    }\n                                    debug_assert!(is_name_written);\n                                    continue 'headers;\n                                } else {\n                                    // we haven't written content-length yet!\n                                    encoder = Encoder::length(len);\n                                    header_name_writer.write_header_name_with_colon(\n                                        dst,\n                                        \"content-length: \",\n                                        header::CONTENT_LENGTH,\n                                    );\n                                    extend(dst, value.as_bytes());\n                                    wrote_len = true;\n                                    is_name_written = true;\n                                    prev_con_len = Some(len);\n                                    continue 'headers;\n                                }\n                            } else {\n                                warn!(\"illegal Content-Length value: {:?}\", value);\n                                rewind(dst);\n                                return Err(crate::Error::new_user_header());\n                            }\n                        }\n                        None => {\n                            // We have no body to actually send,\n                            // but the headers claim a content-length.\n                            // There's only 2 ways this makes sense:\n                            //\n                            // - The header says the length is `0`.\n                            // - This is a response to a `HEAD` request.\n                            if msg.req_method == &Some(Method::HEAD) {\n                                debug_assert_eq!(encoder, Encoder::length(0));\n                            } else {\n                                if value.as_bytes() != b\"0\" {\n                                    warn!(\n                                        \"content-length value found, but empty body provided: {:?}\",\n                                        value\n                                    );\n                                }\n                                continue 'headers;\n                            }\n                        }\n                    }\n                    wrote_len = true;\n                }\n                header::TRANSFER_ENCODING => {\n                    if wrote_len && !is_name_written {\n                        warn!(\"unexpected transfer-encoding found, canceling\");\n                        rewind(dst);\n                        return Err(crate::Error::new_user_header());\n                    }\n                    // check that we actually can send a chunked body...\n                    if msg.head.version == Version::HTTP_10\n                        || !Server::can_chunked(msg.req_method, msg.head.subject)\n                    {\n                        continue;\n                    }\n                    wrote_len = true;\n                    // Must check each value, because `chunked` needs to be the\n                    // last encoding, or else we add it.\n                    must_write_chunked = !headers::is_chunked_(&value);\n\n                    if !is_name_written {\n                        encoder = Encoder::chunked();\n                        is_name_written = true;\n                        header_name_writer.write_header_name_with_colon(\n                            dst,\n                            \"transfer-encoding: \",\n                            header::TRANSFER_ENCODING,\n                        );\n                        extend(dst, value.as_bytes());\n                    } else {\n                        extend(dst, b\", \");\n                        extend(dst, value.as_bytes());\n                    }\n                    continue 'headers;\n                }\n                header::CONNECTION => {\n                    if !is_last && headers::connection_close(&value) {\n                        is_last = true;\n                    }\n                    if !is_name_written {\n                        is_name_written = true;\n                        header_name_writer.write_header_name_with_colon(\n                            dst,\n                            \"connection: \",\n                            header::CONNECTION,\n                        );\n                        extend(dst, value.as_bytes());\n                    } else {\n                        extend(dst, b\", \");\n                        extend(dst, value.as_bytes());\n                    }\n                    continue 'headers;\n                }\n                header::DATE => {\n                    wrote_date = true;\n                }\n                _ => (),\n            }\n            //TODO: this should perhaps instead combine them into\n            //single lines, as RFC7230 suggests is preferable.\n\n            // non-special write Name and Value\n            debug_assert!(\n                !is_name_written,\n                \"{:?} set is_name_written and didn't continue loop\",\n                name,\n            );\n            header_name_writer.write_header_name(dst, name);\n            extend(dst, b\": \");\n            extend(dst, value.as_bytes());\n            extend(dst, b\"\\r\\n\");\n        }\n\n        handle_is_name_written!();\n\n        if !wrote_len {\n            encoder = match msg.body {\n                Some(BodyLength::Unknown) => {\n                    if msg.head.version == Version::HTTP_10\n                        || !Server::can_chunked(msg.req_method, msg.head.subject)\n                    {\n                        Encoder::close_delimited()\n                    } else {\n                        header_name_writer.write_full_header_line(\n                            dst,\n                            \"transfer-encoding: chunked\\r\\n\",\n                            (header::TRANSFER_ENCODING, \": chunked\\r\\n\"),\n                        );\n                        Encoder::chunked()\n                    }\n                }\n                None | Some(BodyLength::Known(0)) => {\n                    if Server::can_have_content_length(msg.req_method, msg.head.subject) {\n                        header_name_writer.write_full_header_line(\n                            dst,\n                            \"content-length: 0\\r\\n\",\n                            (header::CONTENT_LENGTH, \": 0\\r\\n\"),\n                        )\n                    }\n                    Encoder::length(0)\n                }\n                Some(BodyLength::Known(len)) => {\n                    if !Server::can_have_content_length(msg.req_method, msg.head.subject) {\n                        Encoder::length(0)\n                    } else {\n                        header_name_writer.write_header_name_with_colon(\n                            dst,\n                            \"content-length: \",\n                            header::CONTENT_LENGTH,\n                        );\n                        let _ = ::itoa::write(&mut dst, len);\n                        extend(dst, b\"\\r\\n\");\n                        Encoder::length(len)\n                    }\n                }\n            };\n        }\n\n        if !Server::can_have_body(msg.req_method, msg.head.subject) {\n            trace!(\n                \"server body forced to 0; method={:?}, status={:?}\",\n                msg.req_method,\n                msg.head.subject\n            );\n            encoder = Encoder::length(0);\n        }\n\n        // cached date is much faster than formatting every request\n        if !wrote_date {\n            dst.reserve(date::DATE_VALUE_LENGTH + 8);\n            header_name_writer.write_header_name_with_colon(dst, \"date: \", header::DATE);\n            date::extend(dst);\n            extend(dst, b\"\\r\\n\\r\\n\");\n        } else {\n            extend(dst, b\"\\r\\n\");\n        }\n\n        Ok(encoder.set_last(is_last))\n    }\n}\n\n#[cfg(feature = \"server\")]\ntrait HeaderNameWriter {\n    fn write_full_header_line(\n        &mut self,\n        dst: &mut Vec<u8>,\n        line: &str,\n        name_value_pair: (HeaderName, &str),\n    );\n    fn write_header_name_with_colon(\n        &mut self,\n        dst: &mut Vec<u8>,\n        name_with_colon: &str,\n        name: HeaderName,\n    );\n    fn write_header_name(&mut self, dst: &mut Vec<u8>, name: &HeaderName);\n}\n\n#[cfg(feature = \"client\")]\nimpl Http1Transaction for Client {\n    type Incoming = StatusCode;\n    type Outgoing = RequestLine;\n    const LOG: &'static str = \"{role=client}\";\n\n    fn parse(buf: &mut BytesMut, ctx: ParseContext<'_>) -> ParseResult<StatusCode> {\n        debug_assert!(!buf.is_empty(), \"parse called with empty buf\");\n\n        // Loop to skip information status code headers (100 Continue, etc).\n        loop {\n            // Unsafe: see comment in Server Http1Transaction, above.\n            let mut headers_indices: [HeaderIndices; MAX_HEADERS] = unsafe { mem::uninitialized() };\n            let (len, status, reason, version, headers_len) = {\n                let mut headers: [httparse::Header<'_>; MAX_HEADERS] =\n                    unsafe { mem::uninitialized() };\n                trace!(\n                    \"Response.parse([Header; {}], [u8; {}])\",\n                    headers.len(),\n                    buf.len()\n                );\n                let mut res = httparse::Response::new(&mut headers);\n                let bytes = buf.as_ref();\n                match ctx.h1_parser_config.parse_response(&mut res, bytes) {\n                    Ok(httparse::Status::Complete(len)) => {\n                        trace!(\"Response.parse Complete({})\", len);\n                        let status = StatusCode::from_u16(res.code.unwrap())?;\n\n                        #[cfg(not(feature = \"ffi\"))]\n                        let reason = ();\n                        #[cfg(feature = \"ffi\")]\n                        let reason = {\n                            let reason = res.reason.unwrap();\n                            // Only save the reason phrase if it isnt the canonical reason\n                            if Some(reason) != status.canonical_reason() {\n                                Some(Bytes::copy_from_slice(reason.as_bytes()))\n                            } else {\n                                None\n                            }\n                        };\n\n                        let version = if res.version.unwrap() == 1 {\n                            Version::HTTP_11\n                        } else {\n                            Version::HTTP_10\n                        };\n                        record_header_indices(bytes, &res.headers, &mut headers_indices)?;\n                        let headers_len = res.headers.len();\n                        (len, status, reason, version, headers_len)\n                    }\n                    Ok(httparse::Status::Partial) => return Ok(None),\n                    Err(httparse::Error::Version) if ctx.h09_responses => {\n                        trace!(\"Response.parse accepted HTTP/0.9 response\");\n\n                        #[cfg(not(feature = \"ffi\"))]\n                        let reason = ();\n                        #[cfg(feature = \"ffi\")]\n                        let reason = None;\n\n                        (0, StatusCode::OK, reason, Version::HTTP_09, 0)\n                    }\n                    Err(e) => return Err(e.into()),\n                }\n            };\n\n            let slice = buf.split_to(len).freeze();\n\n            let mut headers = ctx.cached_headers.take().unwrap_or_else(HeaderMap::new);\n\n            let mut keep_alive = version == Version::HTTP_11;\n\n            let mut header_case_map = if ctx.preserve_header_case {\n                Some(HeaderCaseMap::default())\n            } else {\n                None\n            };\n\n            headers.reserve(headers_len);\n            for header in &headers_indices[..headers_len] {\n                let name = header_name!(&slice[header.name.0..header.name.1]);\n                let value = header_value!(slice.slice(header.value.0..header.value.1));\n\n                if let header::CONNECTION = name {\n                    // keep_alive was previously set to default for Version\n                    if keep_alive {\n                        // HTTP/1.1\n                        keep_alive = !headers::connection_close(&value);\n                    } else {\n                        // HTTP/1.0\n                        keep_alive = headers::connection_keep_alive(&value);\n                    }\n                }\n\n                if let Some(ref mut header_case_map) = header_case_map {\n                    header_case_map.append(&name, slice.slice(header.name.0..header.name.1));\n                }\n\n                headers.append(name, value);\n            }\n\n            let mut extensions = http::Extensions::default();\n\n            if let Some(header_case_map) = header_case_map {\n                extensions.insert(header_case_map);\n            }\n\n            #[cfg(feature = \"ffi\")]\n            if let Some(reason) = reason {\n                extensions.insert(crate::ffi::ReasonPhrase(reason));\n            }\n            #[cfg(not(feature = \"ffi\"))]\n            drop(reason);\n\n            #[cfg(feature = \"ffi\")]\n            if ctx.raw_headers {\n                extensions.insert(crate::ffi::RawHeaders(crate::ffi::hyper_buf(slice)));\n            }\n\n            let head = MessageHead {\n                version,\n                subject: status,\n                headers,\n                extensions,\n            };\n            if let Some((decode, is_upgrade)) = Client::decoder(&head, ctx.req_method)? {\n                return Ok(Some(ParsedMessage {\n                    head,\n                    decode,\n                    expect_continue: false,\n                    // a client upgrade means the connection can't be used\n                    // again, as it is definitely upgrading.\n                    keep_alive: keep_alive && !is_upgrade,\n                    wants_upgrade: is_upgrade,\n                }));\n            }\n\n            #[cfg(feature = \"ffi\")]\n            if head.subject.is_informational() {\n                if let Some(callback) = ctx.on_informational {\n                    callback.call(head.into_response(crate::Body::empty()));\n                }\n            }\n\n            // Parsing a 1xx response could have consumed the buffer, check if\n            // it is empty now...\n            if buf.is_empty() {\n                return Ok(None);\n            }\n        }\n    }\n\n    fn encode(msg: Encode<'_, Self::Outgoing>, dst: &mut Vec<u8>) -> crate::Result<Encoder> {\n        trace!(\n            \"Client::encode method={:?}, body={:?}\",\n            msg.head.subject.0,\n            msg.body\n        );\n\n        *msg.req_method = Some(msg.head.subject.0.clone());\n\n        let body = Client::set_length(msg.head, msg.body);\n\n        let init_cap = 30 + msg.head.headers.len() * AVERAGE_HEADER_SIZE;\n        dst.reserve(init_cap);\n\n        extend(dst, msg.head.subject.0.as_str().as_bytes());\n        extend(dst, b\" \");\n        //TODO: add API to http::Uri to encode without std::fmt\n        let _ = write!(FastWrite(dst), \"{} \", msg.head.subject.1);\n\n        match msg.head.version {\n            Version::HTTP_10 => extend(dst, b\"HTTP/1.0\"),\n            Version::HTTP_11 => extend(dst, b\"HTTP/1.1\"),\n            Version::HTTP_2 => {\n                debug!(\"request with HTTP2 version coerced to HTTP/1.1\");\n                extend(dst, b\"HTTP/1.1\");\n            }\n            other => panic!(\"unexpected request version: {:?}\", other),\n        }\n        extend(dst, b\"\\r\\n\");\n\n        if let Some(orig_headers) = msg.head.extensions.get::<HeaderCaseMap>() {\n            write_headers_original_case(\n                &msg.head.headers,\n                orig_headers,\n                dst,\n                msg.title_case_headers,\n            );\n        } else if msg.title_case_headers {\n            write_headers_title_case(&msg.head.headers, dst);\n        } else {\n            write_headers(&msg.head.headers, dst);\n        }\n\n        extend(dst, b\"\\r\\n\");\n        msg.head.headers.clear(); //TODO: remove when switching to drain()\n\n        Ok(body)\n    }\n\n    fn on_error(_err: &crate::Error) -> Option<MessageHead<Self::Outgoing>> {\n        // we can't tell the server about any errors it creates\n        None\n    }\n\n    fn is_client() -> bool {\n        true\n    }\n}\n\n#[cfg(feature = \"client\")]\nimpl Client {\n    /// Returns Some(length, wants_upgrade) if successful.\n    ///\n    /// Returns None if this message head should be skipped (like a 100 status).\n    fn decoder(\n        inc: &MessageHead<StatusCode>,\n        method: &mut Option<Method>,\n    ) -> Result<Option<(DecodedLength, bool)>, Parse> {\n        // According to https://tools.ietf.org/html/rfc7230#section-3.3.3\n        // 1. HEAD responses, and Status 1xx, 204, and 304 cannot have a body.\n        // 2. Status 2xx to a CONNECT cannot have a body.\n        // 3. Transfer-Encoding: chunked has a chunked body.\n        // 4. If multiple differing Content-Length headers or invalid, close connection.\n        // 5. Content-Length header has a sized body.\n        // 6. (irrelevant to Response)\n        // 7. Read till EOF.\n\n        match inc.subject.as_u16() {\n            101 => {\n                return Ok(Some((DecodedLength::ZERO, true)));\n            }\n            100 | 102..=199 => {\n                trace!(\"ignoring informational response: {}\", inc.subject.as_u16());\n                return Ok(None);\n            }\n            204 | 304 => return Ok(Some((DecodedLength::ZERO, false))),\n            _ => (),\n        }\n        match *method {\n            Some(Method::HEAD) => {\n                return Ok(Some((DecodedLength::ZERO, false)));\n            }\n            Some(Method::CONNECT) => {\n                if let 200..=299 = inc.subject.as_u16() {\n                    return Ok(Some((DecodedLength::ZERO, true)));\n                }\n            }\n            Some(_) => {}\n            None => {\n                trace!(\"Client::decoder is missing the Method\");\n            }\n        }\n\n        if inc.headers.contains_key(header::TRANSFER_ENCODING) {\n            // https://tools.ietf.org/html/rfc7230#section-3.3.3\n            // If Transfer-Encoding header is present, and 'chunked' is\n            // not the final encoding, and this is a Request, then it is\n            // malformed. A server should respond with 400 Bad Request.\n            if inc.version == Version::HTTP_10 {\n                debug!(\"HTTP/1.0 cannot have Transfer-Encoding header\");\n                Err(Parse::transfer_encoding_unexpected())\n            } else if headers::transfer_encoding_is_chunked(&inc.headers) {\n                Ok(Some((DecodedLength::CHUNKED, false)))\n            } else {\n                trace!(\"not chunked, read till eof\");\n                Ok(Some((DecodedLength::CLOSE_DELIMITED, false)))\n            }\n        } else if let Some(len) = headers::content_length_parse_all(&inc.headers) {\n            Ok(Some((DecodedLength::checked_new(len)?, false)))\n        } else if inc.headers.contains_key(header::CONTENT_LENGTH) {\n            debug!(\"illegal Content-Length header\");\n            Err(Parse::content_length_invalid())\n        } else {\n            trace!(\"neither Transfer-Encoding nor Content-Length\");\n            Ok(Some((DecodedLength::CLOSE_DELIMITED, false)))\n        }\n    }\n    fn set_length(head: &mut RequestHead, body: Option<BodyLength>) -> Encoder {\n        let body = if let Some(body) = body {\n            body\n        } else {\n            head.headers.remove(header::TRANSFER_ENCODING);\n            return Encoder::length(0);\n        };\n\n        // HTTP/1.0 doesn't know about chunked\n        let can_chunked = head.version == Version::HTTP_11;\n        let headers = &mut head.headers;\n\n        // If the user already set specific headers, we should respect them, regardless\n        // of what the HttpBody knows about itself. They set them for a reason.\n\n        // Because of the borrow checker, we can't check the for an existing\n        // Content-Length header while holding an `Entry` for the Transfer-Encoding\n        // header, so unfortunately, we must do the check here, first.\n\n        let existing_con_len = headers::content_length_parse_all(headers);\n        let mut should_remove_con_len = false;\n\n        if !can_chunked {\n            // Chunked isn't legal, so if it is set, we need to remove it.\n            if headers.remove(header::TRANSFER_ENCODING).is_some() {\n                trace!(\"removing illegal transfer-encoding header\");\n            }\n\n            return if let Some(len) = existing_con_len {\n                Encoder::length(len)\n            } else if let BodyLength::Known(len) = body {\n                set_content_length(headers, len)\n            } else {\n                // HTTP/1.0 client requests without a content-length\n                // cannot have any body at all.\n                Encoder::length(0)\n            };\n        }\n\n        // If the user set a transfer-encoding, respect that. Let's just\n        // make sure `chunked` is the final encoding.\n        let encoder = match headers.entry(header::TRANSFER_ENCODING) {\n            Entry::Occupied(te) => {\n                should_remove_con_len = true;\n                if headers::is_chunked(te.iter()) {\n                    Some(Encoder::chunked())\n                } else {\n                    warn!(\"user provided transfer-encoding does not end in 'chunked'\");\n\n                    // There's a Transfer-Encoding, but it doesn't end in 'chunked'!\n                    // An example that could trigger this:\n                    //\n                    //     Transfer-Encoding: gzip\n                    //\n                    // This can be bad, depending on if this is a request or a\n                    // response.\n                    //\n                    // - A request is illegal if there is a `Transfer-Encoding`\n                    //   but it doesn't end in `chunked`.\n                    // - A response that has `Transfer-Encoding` but doesn't\n                    //   end in `chunked` isn't illegal, it just forces this\n                    //   to be close-delimited.\n                    //\n                    // We can try to repair this, by adding `chunked` ourselves.\n\n                    headers::add_chunked(te);\n                    Some(Encoder::chunked())\n                }\n            }\n            Entry::Vacant(te) => {\n                if let Some(len) = existing_con_len {\n                    Some(Encoder::length(len))\n                } else if let BodyLength::Unknown = body {\n                    // GET, HEAD, and CONNECT almost never have bodies.\n                    //\n                    // So instead of sending a \"chunked\" body with a 0-chunk,\n                    // assume no body here. If you *must* send a body,\n                    // set the headers explicitly.\n                    match head.subject.0 {\n                        Method::GET | Method::HEAD | Method::CONNECT => Some(Encoder::length(0)),\n                        _ => {\n                            te.insert(HeaderValue::from_static(\"chunked\"));\n                            Some(Encoder::chunked())\n                        }\n                    }\n                } else {\n                    None\n                }\n            }\n        };\n\n        // This is because we need a second mutable borrow to remove\n        // content-length header.\n        if let Some(encoder) = encoder {\n            if should_remove_con_len && existing_con_len.is_some() {\n                headers.remove(header::CONTENT_LENGTH);\n            }\n            return encoder;\n        }\n\n        // User didn't set transfer-encoding, AND we know body length,\n        // so we can just set the Content-Length automatically.\n\n        let len = if let BodyLength::Known(len) = body {\n            len\n        } else {\n            unreachable!(\"BodyLength::Unknown would set chunked\");\n        };\n\n        set_content_length(headers, len)\n    }\n}\n\nfn set_content_length(headers: &mut HeaderMap, len: u64) -> Encoder {\n    // At this point, there should not be a valid Content-Length\n    // header. However, since we'll be indexing in anyways, we can\n    // warn the user if there was an existing illegal header.\n    //\n    // Or at least, we can in theory. It's actually a little bit slower,\n    // so perhaps only do that while the user is developing/testing.\n\n    if cfg!(debug_assertions) {\n        match headers.entry(header::CONTENT_LENGTH) {\n            Entry::Occupied(mut cl) => {\n                // Internal sanity check, we should have already determined\n                // that the header was illegal before calling this function.\n                debug_assert!(headers::content_length_parse_all_values(cl.iter()).is_none());\n                // Uh oh, the user set `Content-Length` headers, but set bad ones.\n                // This would be an illegal message anyways, so let's try to repair\n                // with our known good length.\n                error!(\"user provided content-length header was invalid\");\n\n                cl.insert(HeaderValue::from(len));\n                Encoder::length(len)\n            }\n            Entry::Vacant(cl) => {\n                cl.insert(HeaderValue::from(len));\n                Encoder::length(len)\n            }\n        }\n    } else {\n        headers.insert(header::CONTENT_LENGTH, HeaderValue::from(len));\n        Encoder::length(len)\n    }\n}\n\n#[derive(Clone, Copy)]\nstruct HeaderIndices {\n    name: (usize, usize),\n    value: (usize, usize),\n}\n\nfn record_header_indices(\n    bytes: &[u8],\n    headers: &[httparse::Header<'_>],\n    indices: &mut [HeaderIndices],\n) -> Result<(), crate::error::Parse> {\n    let bytes_ptr = bytes.as_ptr() as usize;\n\n    for (header, indices) in headers.iter().zip(indices.iter_mut()) {\n        if header.name.len() >= (1 << 16) {\n            debug!(\"header name larger than 64kb: {:?}\", header.name);\n            return Err(crate::error::Parse::TooLarge);\n        }\n        let name_start = header.name.as_ptr() as usize - bytes_ptr;\n        let name_end = name_start + header.name.len();\n        indices.name = (name_start, name_end);\n        let value_start = header.value.as_ptr() as usize - bytes_ptr;\n        let value_end = value_start + header.value.len();\n        indices.value = (value_start, value_end);\n    }\n\n    Ok(())\n}\n\n// Write header names as title case. The header name is assumed to be ASCII,\n// therefore it is trivial to convert an ASCII character from lowercase to\n// uppercase. It is as simple as XORing the lowercase character byte with\n// space.\nfn title_case(dst: &mut Vec<u8>, name: &[u8]) {\n    dst.reserve(name.len());\n\n    let mut iter = name.iter();\n\n    // Uppercase the first character\n    if let Some(c) = iter.next() {\n        if *c >= b'a' && *c <= b'z' {\n            dst.push(*c ^ b' ');\n        } else {\n            dst.push(*c);\n        }\n    }\n\n    while let Some(c) = iter.next() {\n        dst.push(*c);\n\n        if *c == b'-' {\n            if let Some(c) = iter.next() {\n                if *c >= b'a' && *c <= b'z' {\n                    dst.push(*c ^ b' ');\n                } else {\n                    dst.push(*c);\n                }\n            }\n        }\n    }\n}\n\nfn write_headers_title_case(headers: &HeaderMap, dst: &mut Vec<u8>) {\n    for (name, value) in headers {\n        title_case(dst, name.as_str().as_bytes());\n        extend(dst, b\": \");\n        extend(dst, value.as_bytes());\n        extend(dst, b\"\\r\\n\");\n    }\n}\n\nfn write_headers(headers: &HeaderMap, dst: &mut Vec<u8>) {\n    for (name, value) in headers {\n        extend(dst, name.as_str().as_bytes());\n        extend(dst, b\": \");\n        extend(dst, value.as_bytes());\n        extend(dst, b\"\\r\\n\");\n    }\n}\n\n#[cold]\nfn write_headers_original_case(\n    headers: &HeaderMap,\n    orig_case: &HeaderCaseMap,\n    dst: &mut Vec<u8>,\n    title_case_headers: bool,\n) {\n    // For each header name/value pair, there may be a value in the casemap\n    // that corresponds to the HeaderValue. So, we iterator all the keys,\n    // and for each one, try to pair the originally cased name with the value.\n    //\n    // TODO: consider adding http::HeaderMap::entries() iterator\n    for name in headers.keys() {\n        let mut names = orig_case.get_all(name);\n\n        for value in headers.get_all(name) {\n            if let Some(orig_name) = names.next() {\n                extend(dst, orig_name.as_ref());\n            } else if title_case_headers {\n                title_case(dst, name.as_str().as_bytes());\n            } else {\n                extend(dst, name.as_str().as_bytes());\n            }\n\n            // Wanted for curl test cases that send `X-Custom-Header:\\r\\n`\n            if value.is_empty() {\n                extend(dst, b\":\\r\\n\");\n            } else {\n                extend(dst, b\": \");\n                extend(dst, value.as_bytes());\n                extend(dst, b\"\\r\\n\");\n            }\n        }\n    }\n}\n\nstruct FastWrite<'a>(&'a mut Vec<u8>);\n\nimpl<'a> fmt::Write for FastWrite<'a> {\n    #[inline]\n    fn write_str(&mut self, s: &str) -> fmt::Result {\n        extend(self.0, s.as_bytes());\n        Ok(())\n    }\n\n    #[inline]\n    fn write_fmt(&mut self, args: fmt::Arguments<'_>) -> fmt::Result {\n        fmt::write(self, args)\n    }\n}\n\n#[inline]\nfn extend(dst: &mut Vec<u8>, data: &[u8]) {\n    dst.extend_from_slice(data);\n}\n\n#[cfg(test)]\nmod tests {\n    use bytes::BytesMut;\n\n    use super::*;\n\n    #[test]\n    fn test_parse_request() {\n        let _ = pretty_env_logger::try_init();\n        let mut raw = BytesMut::from(\"GET /echo HTTP/1.1\\r\\nHost: hyper.rs\\r\\n\\r\\n\");\n        let mut method = None;\n        let msg = Server::parse(\n            &mut raw,\n            ParseContext {\n                cached_headers: &mut None,\n                req_method: &mut method,\n                h1_parser_config: Default::default(),\n                preserve_header_case: false,\n                h09_responses: false,\n                #[cfg(feature = \"ffi\")]\n                on_informational: &mut None,\n                #[cfg(feature = \"ffi\")]\n                raw_headers: false,\n            },\n        )\n        .unwrap()\n        .unwrap();\n        assert_eq!(raw.len(), 0);\n        assert_eq!(msg.head.subject.0, crate::Method::GET);\n        assert_eq!(msg.head.subject.1, \"/echo\");\n        assert_eq!(msg.head.version, crate::Version::HTTP_11);\n        assert_eq!(msg.head.headers.len(), 1);\n        assert_eq!(msg.head.headers[\"Host\"], \"hyper.rs\");\n        assert_eq!(method, Some(crate::Method::GET));\n    }\n\n    #[test]\n    fn test_parse_response() {\n        let _ = pretty_env_logger::try_init();\n        let mut raw = BytesMut::from(\"HTTP/1.1 200 OK\\r\\nContent-Length: 0\\r\\n\\r\\n\");\n        let ctx = ParseContext {\n            cached_headers: &mut None,\n            req_method: &mut Some(crate::Method::GET),\n            h1_parser_config: Default::default(),\n            preserve_header_case: false,\n            h09_responses: false,\n            #[cfg(feature = \"ffi\")]\n            on_informational: &mut None,\n            #[cfg(feature = \"ffi\")]\n            raw_headers: false,\n        };\n        let msg = Client::parse(&mut raw, ctx).unwrap().unwrap();\n        assert_eq!(raw.len(), 0);\n        assert_eq!(msg.head.subject, crate::StatusCode::OK);\n        assert_eq!(msg.head.version, crate::Version::HTTP_11);\n        assert_eq!(msg.head.headers.len(), 1);\n        assert_eq!(msg.head.headers[\"Content-Length\"], \"0\");\n    }\n\n    #[test]\n    fn test_parse_request_errors() {\n        let mut raw = BytesMut::from(\"GET htt:p// HTTP/1.1\\r\\nHost: hyper.rs\\r\\n\\r\\n\");\n        let ctx = ParseContext {\n            cached_headers: &mut None,\n            req_method: &mut None,\n            h1_parser_config: Default::default(),\n            preserve_header_case: false,\n            h09_responses: false,\n            #[cfg(feature = \"ffi\")]\n            on_informational: &mut None,\n            #[cfg(feature = \"ffi\")]\n            raw_headers: false,\n        };\n        Server::parse(&mut raw, ctx).unwrap_err();\n    }\n\n    const H09_RESPONSE: &'static str = \"Baguettes are super delicious, don't you agree?\";\n\n    #[test]\n    fn test_parse_response_h09_allowed() {\n        let _ = pretty_env_logger::try_init();\n        let mut raw = BytesMut::from(H09_RESPONSE);\n        let ctx = ParseContext {\n            cached_headers: &mut None,\n            req_method: &mut Some(crate::Method::GET),\n            h1_parser_config: Default::default(),\n            preserve_header_case: false,\n            h09_responses: true,\n            #[cfg(feature = \"ffi\")]\n            on_informational: &mut None,\n            #[cfg(feature = \"ffi\")]\n            raw_headers: false,\n        };\n        let msg = Client::parse(&mut raw, ctx).unwrap().unwrap();\n        assert_eq!(raw, H09_RESPONSE);\n        assert_eq!(msg.head.subject, crate::StatusCode::OK);\n        assert_eq!(msg.head.version, crate::Version::HTTP_09);\n        assert_eq!(msg.head.headers.len(), 0);\n    }\n\n    #[test]\n    fn test_parse_response_h09_rejected() {\n        let _ = pretty_env_logger::try_init();\n        let mut raw = BytesMut::from(H09_RESPONSE);\n        let ctx = ParseContext {\n            cached_headers: &mut None,\n            req_method: &mut Some(crate::Method::GET),\n            h1_parser_config: Default::default(),\n            preserve_header_case: false,\n            h09_responses: false,\n            #[cfg(feature = \"ffi\")]\n            on_informational: &mut None,\n            #[cfg(feature = \"ffi\")]\n            raw_headers: false,\n        };\n        Client::parse(&mut raw, ctx).unwrap_err();\n        assert_eq!(raw, H09_RESPONSE);\n    }\n\n    const RESPONSE_WITH_WHITESPACE_BETWEEN_HEADER_NAME_AND_COLON: &'static str =\n        \"HTTP/1.1 200 OK\\r\\nAccess-Control-Allow-Credentials : true\\r\\n\\r\\n\";\n\n    #[test]\n    fn test_parse_allow_response_with_spaces_before_colons() {\n        use httparse::ParserConfig;\n\n        let _ = pretty_env_logger::try_init();\n        let mut raw = BytesMut::from(RESPONSE_WITH_WHITESPACE_BETWEEN_HEADER_NAME_AND_COLON);\n        let mut h1_parser_config = ParserConfig::default();\n        h1_parser_config.allow_spaces_after_header_name_in_responses(true);\n        let ctx = ParseContext {\n            cached_headers: &mut None,\n            req_method: &mut Some(crate::Method::GET),\n            h1_parser_config,\n            preserve_header_case: false,\n            h09_responses: false,\n            #[cfg(feature = \"ffi\")]\n            on_informational: &mut None,\n            #[cfg(feature = \"ffi\")]\n            raw_headers: false,\n        };\n        let msg = Client::parse(&mut raw, ctx).unwrap().unwrap();\n        assert_eq!(raw.len(), 0);\n        assert_eq!(msg.head.subject, crate::StatusCode::OK);\n        assert_eq!(msg.head.version, crate::Version::HTTP_11);\n        assert_eq!(msg.head.headers.len(), 1);\n        assert_eq!(msg.head.headers[\"Access-Control-Allow-Credentials\"], \"true\");\n    }\n\n    #[test]\n    fn test_parse_reject_response_with_spaces_before_colons() {\n        let _ = pretty_env_logger::try_init();\n        let mut raw = BytesMut::from(RESPONSE_WITH_WHITESPACE_BETWEEN_HEADER_NAME_AND_COLON);\n        let ctx = ParseContext {\n            cached_headers: &mut None,\n            req_method: &mut Some(crate::Method::GET),\n            h1_parser_config: Default::default(),\n            preserve_header_case: false,\n            h09_responses: false,\n            #[cfg(feature = \"ffi\")]\n            on_informational: &mut None,\n            #[cfg(feature = \"ffi\")]\n            raw_headers: false,\n        };\n        Client::parse(&mut raw, ctx).unwrap_err();\n    }\n\n    #[test]\n    fn test_parse_preserve_header_case_in_request() {\n        let mut raw =\n            BytesMut::from(\"GET / HTTP/1.1\\r\\nHost: hyper.rs\\r\\nX-BREAD: baguette\\r\\n\\r\\n\");\n        let ctx = ParseContext {\n            cached_headers: &mut None,\n            req_method: &mut None,\n            h1_parser_config: Default::default(),\n            preserve_header_case: true,\n            h09_responses: false,\n            #[cfg(feature = \"ffi\")]\n            on_informational: &mut None,\n            #[cfg(feature = \"ffi\")]\n            raw_headers: false,\n        };\n        let parsed_message = Server::parse(&mut raw, ctx).unwrap().unwrap();\n        let orig_headers = parsed_message\n            .head\n            .extensions\n            .get::<HeaderCaseMap>()\n            .unwrap();\n        assert_eq!(\n            orig_headers\n                .get_all_internal(&HeaderName::from_static(\"host\"))\n                .into_iter()\n                .collect::<Vec<_>>(),\n            vec![&Bytes::from(\"Host\")]\n        );\n        assert_eq!(\n            orig_headers\n                .get_all_internal(&HeaderName::from_static(\"x-bread\"))\n                .into_iter()\n                .collect::<Vec<_>>(),\n            vec![&Bytes::from(\"X-BREAD\")]\n        );\n    }\n\n    #[test]\n    fn test_decoder_request() {\n        fn parse(s: &str) -> ParsedMessage<RequestLine> {\n            let mut bytes = BytesMut::from(s);\n            Server::parse(\n                &mut bytes,\n                ParseContext {\n                    cached_headers: &mut None,\n                    req_method: &mut None,\n                    h1_parser_config: Default::default(),\n                    preserve_header_case: false,\n                    h09_responses: false,\n                    #[cfg(feature = \"ffi\")]\n                    on_informational: &mut None,\n                    #[cfg(feature = \"ffi\")]\n                    raw_headers: false,\n                },\n            )\n            .expect(\"parse ok\")\n            .expect(\"parse complete\")\n        }\n\n        fn parse_err(s: &str, comment: &str) -> crate::error::Parse {\n            let mut bytes = BytesMut::from(s);\n            Server::parse(\n                &mut bytes,\n                ParseContext {\n                    cached_headers: &mut None,\n                    req_method: &mut None,\n                    h1_parser_config: Default::default(),\n                    preserve_header_case: false,\n                    h09_responses: false,\n                    #[cfg(feature = \"ffi\")]\n                    on_informational: &mut None,\n                    #[cfg(feature = \"ffi\")]\n                    raw_headers: false,\n                },\n            )\n            .expect_err(comment)\n        }\n\n        // no length or transfer-encoding means 0-length body\n        assert_eq!(\n            parse(\n                \"\\\n                 GET / HTTP/1.1\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::ZERO\n        );\n\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::ZERO\n        );\n\n        // transfer-encoding: chunked\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 transfer-encoding: chunked\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 transfer-encoding: gzip, chunked\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 transfer-encoding: gzip\\r\\n\\\n                 transfer-encoding: chunked\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        // content-length\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::new(10)\n        );\n\n        // transfer-encoding and content-length = chunked\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 transfer-encoding: chunked\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 transfer-encoding: chunked\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 transfer-encoding: gzip\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 transfer-encoding: chunked\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        // multiple content-lengths of same value are fine\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.1\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::new(10)\n        );\n\n        // multiple content-lengths with different values is an error\n        parse_err(\n            \"\\\n             POST / HTTP/1.1\\r\\n\\\n             content-length: 10\\r\\n\\\n             content-length: 11\\r\\n\\\n             \\r\\n\\\n             \",\n            \"multiple content-lengths\",\n        );\n\n        // content-length with prefix is not allowed\n        parse_err(\n            \"\\\n             POST / HTTP/1.1\\r\\n\\\n             content-length: +10\\r\\n\\\n             \\r\\n\\\n             \",\n            \"prefixed content-length\",\n        );\n\n        // transfer-encoding that isn't chunked is an error\n        parse_err(\n            \"\\\n             POST / HTTP/1.1\\r\\n\\\n             transfer-encoding: gzip\\r\\n\\\n             \\r\\n\\\n             \",\n            \"transfer-encoding but not chunked\",\n        );\n\n        parse_err(\n            \"\\\n             POST / HTTP/1.1\\r\\n\\\n             transfer-encoding: chunked, gzip\\r\\n\\\n             \\r\\n\\\n             \",\n            \"transfer-encoding doesn't end in chunked\",\n        );\n\n        parse_err(\n            \"\\\n             POST / HTTP/1.1\\r\\n\\\n             transfer-encoding: chunked\\r\\n\\\n             transfer-encoding: afterlol\\r\\n\\\n             \\r\\n\\\n             \",\n            \"transfer-encoding multiple lines doesn't end in chunked\",\n        );\n\n        // http/1.0\n\n        assert_eq!(\n            parse(\n                \"\\\n                 POST / HTTP/1.0\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::new(10)\n        );\n\n        // 1.0 doesn't understand chunked, so its an error\n        parse_err(\n            \"\\\n             POST / HTTP/1.0\\r\\n\\\n             transfer-encoding: chunked\\r\\n\\\n             \\r\\n\\\n             \",\n            \"1.0 chunked\",\n        );\n    }\n\n    #[test]\n    fn test_decoder_response() {\n        fn parse(s: &str) -> ParsedMessage<StatusCode> {\n            parse_with_method(s, Method::GET)\n        }\n\n        fn parse_ignores(s: &str) {\n            let mut bytes = BytesMut::from(s);\n            assert!(Client::parse(\n                &mut bytes,\n                ParseContext {\n                    cached_headers: &mut None,\n                    req_method: &mut Some(Method::GET),\n                    h1_parser_config: Default::default(),\n                    preserve_header_case: false,\n                    h09_responses: false,\n                    #[cfg(feature = \"ffi\")]\n                    on_informational: &mut None,\n                    #[cfg(feature = \"ffi\")]\n                    raw_headers: false,\n                }\n            )\n            .expect(\"parse ok\")\n            .is_none())\n        }\n\n        fn parse_with_method(s: &str, m: Method) -> ParsedMessage<StatusCode> {\n            let mut bytes = BytesMut::from(s);\n            Client::parse(\n                &mut bytes,\n                ParseContext {\n                    cached_headers: &mut None,\n                    req_method: &mut Some(m),\n                    h1_parser_config: Default::default(),\n                    preserve_header_case: false,\n                    h09_responses: false,\n                    #[cfg(feature = \"ffi\")]\n                    on_informational: &mut None,\n                    #[cfg(feature = \"ffi\")]\n                    raw_headers: false,\n                },\n            )\n            .expect(\"parse ok\")\n            .expect(\"parse complete\")\n        }\n\n        fn parse_err(s: &str) -> crate::error::Parse {\n            let mut bytes = BytesMut::from(s);\n            Client::parse(\n                &mut bytes,\n                ParseContext {\n                    cached_headers: &mut None,\n                    req_method: &mut Some(Method::GET),\n                    h1_parser_config: Default::default(),\n                    preserve_header_case: false,\n                    h09_responses: false,\n                    #[cfg(feature = \"ffi\")]\n                    on_informational: &mut None,\n                    #[cfg(feature = \"ffi\")]\n                    raw_headers: false,\n                },\n            )\n            .expect_err(\"parse should err\")\n        }\n\n        // no content-length or transfer-encoding means close-delimited\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CLOSE_DELIMITED\n        );\n\n        // 204 and 304 never have a body\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 204 No Content\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::ZERO\n        );\n\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 304 Not Modified\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::ZERO\n        );\n\n        // content-length\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 content-length: 8\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::new(8)\n        );\n\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 content-length: 8\\r\\n\\\n                 content-length: 8\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::new(8)\n        );\n\n        parse_err(\n            \"\\\n             HTTP/1.1 200 OK\\r\\n\\\n             content-length: 8\\r\\n\\\n             content-length: 9\\r\\n\\\n             \\r\\n\\\n             \",\n        );\n\n        parse_err(\n            \"\\\n             HTTP/1.1 200 OK\\r\\n\\\n             content-length: +8\\r\\n\\\n             \\r\\n\\\n             \",\n        );\n\n        // transfer-encoding: chunked\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 transfer-encoding: chunked\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        // transfer-encoding not-chunked is close-delimited\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 transfer-encoding: yolo\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CLOSE_DELIMITED\n        );\n\n        // transfer-encoding and content-length = chunked\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 content-length: 10\\r\\n\\\n                 transfer-encoding: chunked\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CHUNKED\n        );\n\n        // HEAD can have content-length, but not body\n        assert_eq!(\n            parse_with_method(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 content-length: 8\\r\\n\\\n                 \\r\\n\\\n                 \",\n                Method::HEAD\n            )\n            .decode,\n            DecodedLength::ZERO\n        );\n\n        // CONNECT with 200 never has body\n        {\n            let msg = parse_with_method(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 \\r\\n\\\n                 \",\n                Method::CONNECT,\n            );\n            assert_eq!(msg.decode, DecodedLength::ZERO);\n            assert!(!msg.keep_alive, \"should be upgrade\");\n            assert!(msg.wants_upgrade, \"should be upgrade\");\n        }\n\n        // CONNECT receiving non 200 can have a body\n        assert_eq!(\n            parse_with_method(\n                \"\\\n                 HTTP/1.1 400 Bad Request\\r\\n\\\n                 \\r\\n\\\n                 \",\n                Method::CONNECT\n            )\n            .decode,\n            DecodedLength::CLOSE_DELIMITED\n        );\n\n        // 1xx status codes\n        parse_ignores(\n            \"\\\n             HTTP/1.1 100 Continue\\r\\n\\\n             \\r\\n\\\n             \",\n        );\n\n        parse_ignores(\n            \"\\\n             HTTP/1.1 103 Early Hints\\r\\n\\\n             \\r\\n\\\n             \",\n        );\n\n        // 101 upgrade not supported yet\n        {\n            let msg = parse(\n                \"\\\n                 HTTP/1.1 101 Switching Protocols\\r\\n\\\n                 \\r\\n\\\n                 \",\n            );\n            assert_eq!(msg.decode, DecodedLength::ZERO);\n            assert!(!msg.keep_alive, \"should be last\");\n            assert!(msg.wants_upgrade, \"should be upgrade\");\n        }\n\n        // http/1.0\n        assert_eq!(\n            parse(\n                \"\\\n                 HTTP/1.0 200 OK\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .decode,\n            DecodedLength::CLOSE_DELIMITED\n        );\n\n        // 1.0 doesn't understand chunked\n        parse_err(\n            \"\\\n             HTTP/1.0 200 OK\\r\\n\\\n             transfer-encoding: chunked\\r\\n\\\n             \\r\\n\\\n             \",\n        );\n\n        // keep-alive\n        assert!(\n            parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 content-length: 0\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .keep_alive,\n            \"HTTP/1.1 keep-alive is default\"\n        );\n\n        assert!(\n            !parse(\n                \"\\\n                 HTTP/1.1 200 OK\\r\\n\\\n                 content-length: 0\\r\\n\\\n                 connection: foo, close, bar\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .keep_alive,\n            \"connection close is always close\"\n        );\n\n        assert!(\n            !parse(\n                \"\\\n                 HTTP/1.0 200 OK\\r\\n\\\n                 content-length: 0\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .keep_alive,\n            \"HTTP/1.0 close is default\"\n        );\n\n        assert!(\n            parse(\n                \"\\\n                 HTTP/1.0 200 OK\\r\\n\\\n                 content-length: 0\\r\\n\\\n                 connection: foo, keep-alive, bar\\r\\n\\\n                 \\r\\n\\\n                 \"\n            )\n            .keep_alive,\n            \"connection keep-alive is always keep-alive\"\n        );\n    }\n\n    #[test]\n    fn test_client_request_encode_title_case() {\n        use crate::proto::BodyLength;\n        use http::header::HeaderValue;\n\n        let mut head = MessageHead::default();\n        head.headers\n            .insert(\"content-length\", HeaderValue::from_static(\"10\"));\n        head.headers\n            .insert(\"content-type\", HeaderValue::from_static(\"application/json\"));\n        head.headers.insert(\"*-*\", HeaderValue::from_static(\"o_o\"));\n\n        let mut vec = Vec::new();\n        Client::encode(\n            Encode {\n                head: &mut head,\n                body: Some(BodyLength::Known(10)),\n                keep_alive: true,\n                req_method: &mut None,\n                title_case_headers: true,\n            },\n            &mut vec,\n        )\n        .unwrap();\n\n        assert_eq!(vec, b\"GET / HTTP/1.1\\r\\nContent-Length: 10\\r\\nContent-Type: application/json\\r\\n*-*: o_o\\r\\n\\r\\n\".to_vec());\n    }\n\n    #[test]\n    fn test_client_request_encode_orig_case() {\n        use crate::proto::BodyLength;\n        use http::header::{HeaderValue, CONTENT_LENGTH};\n\n        let mut head = MessageHead::default();\n        head.headers\n            .insert(\"content-length\", HeaderValue::from_static(\"10\"));\n        head.headers\n            .insert(\"content-type\", HeaderValue::from_static(\"application/json\"));\n\n        let mut orig_headers = HeaderCaseMap::default();\n        orig_headers.insert(CONTENT_LENGTH, \"CONTENT-LENGTH\".into());\n        head.extensions.insert(orig_headers);\n\n        let mut vec = Vec::new();\n        Client::encode(\n            Encode {\n                head: &mut head,\n                body: Some(BodyLength::Known(10)),\n                keep_alive: true,\n                req_method: &mut None,\n                title_case_headers: false,\n            },\n            &mut vec,\n        )\n        .unwrap();\n\n        assert_eq!(\n            &*vec,\n            b\"GET / HTTP/1.1\\r\\nCONTENT-LENGTH: 10\\r\\ncontent-type: application/json\\r\\n\\r\\n\"\n                .as_ref(),\n        );\n    }\n    #[test]\n    fn test_client_request_encode_orig_and_title_case() {\n        use crate::proto::BodyLength;\n        use http::header::{HeaderValue, CONTENT_LENGTH};\n\n        let mut head = MessageHead::default();\n        head.headers\n            .insert(\"content-length\", HeaderValue::from_static(\"10\"));\n        head.headers\n            .insert(\"content-type\", HeaderValue::from_static(\"application/json\"));\n\n        let mut orig_headers = HeaderCaseMap::default();\n        orig_headers.insert(CONTENT_LENGTH, \"CONTENT-LENGTH\".into());\n        head.extensions.insert(orig_headers);\n\n        let mut vec = Vec::new();\n        Client::encode(\n            Encode {\n                head: &mut head,\n                body: Some(BodyLength::Known(10)),\n                keep_alive: true,\n                req_method: &mut None,\n                title_case_headers: true,\n            },\n            &mut vec,\n        )\n        .unwrap();\n\n        assert_eq!(\n            &*vec,\n            b\"GET / HTTP/1.1\\r\\nCONTENT-LENGTH: 10\\r\\nContent-Type: application/json\\r\\n\\r\\n\"\n                .as_ref(),\n        );\n    }\n\n    #[test]\n    fn test_server_encode_connect_method() {\n        let mut head = MessageHead::default();\n\n        let mut vec = Vec::new();\n        let encoder = Server::encode(\n            Encode {\n                head: &mut head,\n                body: None,\n                keep_alive: true,\n                req_method: &mut Some(Method::CONNECT),\n                title_case_headers: false,\n            },\n            &mut vec,\n        )\n        .unwrap();\n\n        assert!(encoder.is_last());\n    }\n\n    #[test]\n    fn test_server_response_encode_title_case() {\n        use crate::proto::BodyLength;\n        use http::header::HeaderValue;\n\n        let mut head = MessageHead::default();\n        head.headers\n            .insert(\"content-length\", HeaderValue::from_static(\"10\"));\n        head.headers\n            .insert(\"content-type\", HeaderValue::from_static(\"application/json\"));\n\n        let mut vec = Vec::new();\n        Server::encode(\n            Encode {\n                head: &mut head,\n                body: Some(BodyLength::Known(10)),\n                keep_alive: true,\n                req_method: &mut None,\n                title_case_headers: true,\n            },\n            &mut vec,\n        )\n        .unwrap();\n\n        let expected_response =\n            b\"HTTP/1.1 200 OK\\r\\nContent-Length: 10\\r\\nContent-Type: application/json\\r\\n\";\n\n        assert_eq!(&vec[..expected_response.len()], &expected_response[..]);\n    }\n\n    #[test]\n    fn test_server_response_encode_orig_case() {\n        use crate::proto::BodyLength;\n        use http::header::{HeaderValue, CONTENT_LENGTH};\n\n        let mut head = MessageHead::default();\n        head.headers\n            .insert(\"content-length\", HeaderValue::from_static(\"10\"));\n        head.headers\n            .insert(\"content-type\", HeaderValue::from_static(\"application/json\"));\n\n        let mut orig_headers = HeaderCaseMap::default();\n        orig_headers.insert(CONTENT_LENGTH, \"CONTENT-LENGTH\".into());\n        head.extensions.insert(orig_headers);\n\n        let mut vec = Vec::new();\n        Server::encode(\n            Encode {\n                head: &mut head,\n                body: Some(BodyLength::Known(10)),\n                keep_alive: true,\n                req_method: &mut None,\n                title_case_headers: false,\n            },\n            &mut vec,\n        )\n        .unwrap();\n\n        let expected_response =\n            b\"HTTP/1.1 200 OK\\r\\nCONTENT-LENGTH: 10\\r\\ncontent-type: application/json\\r\\ndate: \";\n\n        assert_eq!(&vec[..expected_response.len()], &expected_response[..]);\n    }\n\n    #[test]\n    fn test_server_response_encode_orig_and_title_case() {\n        use crate::proto::BodyLength;\n        use http::header::{HeaderValue, CONTENT_LENGTH};\n\n        let mut head = MessageHead::default();\n        head.headers\n            .insert(\"content-length\", HeaderValue::from_static(\"10\"));\n        head.headers\n            .insert(\"content-type\", HeaderValue::from_static(\"application/json\"));\n\n        let mut orig_headers = HeaderCaseMap::default();\n        orig_headers.insert(CONTENT_LENGTH, \"CONTENT-LENGTH\".into());\n        head.extensions.insert(orig_headers);\n\n        let mut vec = Vec::new();\n        Server::encode(\n            Encode {\n                head: &mut head,\n                body: Some(BodyLength::Known(10)),\n                keep_alive: true,\n                req_method: &mut None,\n                title_case_headers: true,\n            },\n            &mut vec,\n        )\n        .unwrap();\n\n        let expected_response =\n            b\"HTTP/1.1 200 OK\\r\\nCONTENT-LENGTH: 10\\r\\nContent-Type: application/json\\r\\nDate: \";\n\n        assert_eq!(&vec[..expected_response.len()], &expected_response[..]);\n    }\n\n    #[test]\n    fn parse_header_htabs() {\n        let mut bytes = BytesMut::from(\"HTTP/1.1 200 OK\\r\\nserver: hello\\tworld\\r\\n\\r\\n\");\n        let parsed = Client::parse(\n            &mut bytes,\n            ParseContext {\n                cached_headers: &mut None,\n                req_method: &mut Some(Method::GET),\n                h1_parser_config: Default::default(),\n                preserve_header_case: false,\n                h09_responses: false,\n                #[cfg(feature = \"ffi\")]\n                on_informational: &mut None,\n                #[cfg(feature = \"ffi\")]\n                raw_headers: false,\n            },\n        )\n        .expect(\"parse ok\")\n        .expect(\"parse complete\");\n\n        assert_eq!(parsed.head.headers[\"server\"], \"hello\\tworld\");\n    }\n\n    #[test]\n    fn test_write_headers_orig_case_empty_value() {\n        let mut headers = HeaderMap::new();\n        let name = http::header::HeaderName::from_static(\"x-empty\");\n        headers.insert(&name, \"\".parse().expect(\"parse empty\"));\n        let mut orig_cases = HeaderCaseMap::default();\n        orig_cases.insert(name, Bytes::from_static(b\"X-EmptY\"));\n\n        let mut dst = Vec::new();\n        super::write_headers_original_case(&headers, &orig_cases, &mut dst, false);\n\n        assert_eq!(\n            dst, b\"X-EmptY:\\r\\n\",\n            \"there should be no space between the colon and CRLF\"\n        );\n    }\n\n    #[test]\n    fn test_write_headers_orig_case_multiple_entries() {\n        let mut headers = HeaderMap::new();\n        let name = http::header::HeaderName::from_static(\"x-empty\");\n        headers.insert(&name, \"a\".parse().unwrap());\n        headers.append(&name, \"b\".parse().unwrap());\n\n        let mut orig_cases = HeaderCaseMap::default();\n        orig_cases.insert(name.clone(), Bytes::from_static(b\"X-Empty\"));\n        orig_cases.append(name, Bytes::from_static(b\"X-EMPTY\"));\n\n        let mut dst = Vec::new();\n        super::write_headers_original_case(&headers, &orig_cases, &mut dst, false);\n\n        assert_eq!(dst, b\"X-Empty: a\\r\\nX-EMPTY: b\\r\\n\");\n    }\n\n    #[cfg(feature = \"nightly\")]\n    use test::Bencher;\n\n    #[cfg(feature = \"nightly\")]\n    #[bench]\n    fn bench_parse_incoming(b: &mut Bencher) {\n        let mut raw = BytesMut::from(\n            &b\"GET /super_long_uri/and_whatever?what_should_we_talk_about/\\\n            I_wonder/Hard_to_write_in_an_uri_after_all/you_have_to_make\\\n            _up_the_punctuation_yourself/how_fun_is_that?test=foo&test1=\\\n            foo1&test2=foo2&test3=foo3&test4=foo4 HTTP/1.1\\r\\nHost: \\\n            hyper.rs\\r\\nAccept: a lot of things\\r\\nAccept-Charset: \\\n            utf8\\r\\nAccept-Encoding: *\\r\\nAccess-Control-Allow-\\\n            Credentials: None\\r\\nAccess-Control-Allow-Origin: None\\r\\n\\\n            Access-Control-Allow-Methods: None\\r\\nAccess-Control-Allow-\\\n            Headers: None\\r\\nContent-Encoding: utf8\\r\\nContent-Security-\\\n            Policy: None\\r\\nContent-Type: text/html\\r\\nOrigin: hyper\\\n            \\r\\nSec-Websocket-Extensions: It looks super important!\\r\\n\\\n            Sec-Websocket-Origin: hyper\\r\\nSec-Websocket-Version: 4.3\\r\\\n            \\nStrict-Transport-Security: None\\r\\nUser-Agent: hyper\\r\\n\\\n            X-Content-Duration: None\\r\\nX-Content-Security-Policy: None\\\n            \\r\\nX-DNSPrefetch-Control: None\\r\\nX-Frame-Options: \\\n            Something important obviously\\r\\nX-Requested-With: Nothing\\\n            \\r\\n\\r\\n\"[..],\n        );\n        let len = raw.len();\n        let mut headers = Some(HeaderMap::new());\n\n        b.bytes = len as u64;\n        b.iter(|| {\n            let mut msg = Server::parse(\n                &mut raw,\n                ParseContext {\n                    cached_headers: &mut headers,\n                    req_method: &mut None,\n                    h1_parser_config: Default::default(),\n                    preserve_header_case: false,\n                    h09_responses: false,\n                    #[cfg(feature = \"ffi\")]\n                    on_informational: &mut None,\n                    #[cfg(feature = \"ffi\")]\n                    raw_headers: false,\n                },\n            )\n            .unwrap()\n            .unwrap();\n            ::test::black_box(&msg);\n            msg.head.headers.clear();\n            headers = Some(msg.head.headers);\n            restart(&mut raw, len);\n        });\n\n        fn restart(b: &mut BytesMut, len: usize) {\n            b.reserve(1);\n            unsafe {\n                b.set_len(len);\n            }\n        }\n    }\n\n    #[cfg(feature = \"nightly\")]\n    #[bench]\n    fn bench_parse_short(b: &mut Bencher) {\n        let s = &b\"GET / HTTP/1.1\\r\\nHost: localhost:8080\\r\\n\\r\\n\"[..];\n        let mut raw = BytesMut::from(s);\n        let len = raw.len();\n        let mut headers = Some(HeaderMap::new());\n\n        b.bytes = len as u64;\n        b.iter(|| {\n            let mut msg = Server::parse(\n                &mut raw,\n                ParseContext {\n                    cached_headers: &mut headers,\n                    req_method: &mut None,\n                    h1_parser_config: Default::default(),\n                    preserve_header_case: false,\n                    h09_responses: false,\n                    #[cfg(feature = \"ffi\")]\n                    on_informational: &mut None,\n                    #[cfg(feature = \"ffi\")]\n                    raw_headers: false,\n                },\n            )\n            .unwrap()\n            .unwrap();\n            ::test::black_box(&msg);\n            msg.head.headers.clear();\n            headers = Some(msg.head.headers);\n            restart(&mut raw, len);\n        });\n\n        fn restart(b: &mut BytesMut, len: usize) {\n            b.reserve(1);\n            unsafe {\n                b.set_len(len);\n            }\n        }\n    }\n\n    #[cfg(feature = \"nightly\")]\n    #[bench]\n    fn bench_server_encode_headers_preset(b: &mut Bencher) {\n        use crate::proto::BodyLength;\n        use http::header::HeaderValue;\n\n        let len = 108;\n        b.bytes = len as u64;\n\n        let mut head = MessageHead::default();\n        let mut headers = HeaderMap::new();\n        headers.insert(\"content-length\", HeaderValue::from_static(\"10\"));\n        headers.insert(\"content-type\", HeaderValue::from_static(\"application/json\"));\n\n        b.iter(|| {\n            let mut vec = Vec::new();\n            head.headers = headers.clone();\n            Server::encode(\n                Encode {\n                    head: &mut head,\n                    body: Some(BodyLength::Known(10)),\n                    keep_alive: true,\n                    req_method: &mut Some(Method::GET),\n                    title_case_headers: false,\n                },\n                &mut vec,\n            )\n            .unwrap();\n            assert_eq!(vec.len(), len);\n            ::test::black_box(vec);\n        })\n    }\n\n    #[cfg(feature = \"nightly\")]\n    #[bench]\n    fn bench_server_encode_no_headers(b: &mut Bencher) {\n        use crate::proto::BodyLength;\n\n        let len = 76;\n        b.bytes = len as u64;\n\n        let mut head = MessageHead::default();\n        let mut vec = Vec::with_capacity(128);\n\n        b.iter(|| {\n            Server::encode(\n                Encode {\n                    head: &mut head,\n                    body: Some(BodyLength::Known(10)),\n                    keep_alive: true,\n                    req_method: &mut Some(Method::GET),\n                    title_case_headers: false,\n                },\n                &mut vec,\n            )\n            .unwrap();\n            assert_eq!(vec.len(), len);\n            ::test::black_box(&vec);\n\n            vec.clear();\n        })\n    }\n}\n"
  },
  {
    "project": "rand",
    "target": 1,
    "commit_id": "6ecbe2626b2cc6110a25c97b1702b347574febc7",
    "func": "// Copyright 2018 Developers of the Rand project.\n//\n// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n// https://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n// <LICENSE-MIT or https://opensource.org/licenses/MIT>, at your\n// option. This file may not be copied, modified, or distributed\n// except according to those terms.\n\n//! Little-Endian utilities\n//!\n//! Little-Endian order has been chosen for internal usage; this makes some\n//! useful functions available.\n\nuse core::convert::TryInto;\n\n/// Reads unsigned 32 bit integers from `src` into `dst`.\n#[inline]\npub fn read_u32_into(src: &[u8], dst: &mut [u32]) {\n    assert!(4 * src.len() >= dst.len());\n    for (out, chunk) in dst.iter_mut().zip(src.chunks_exact(4)) {\n        *out = u32::from_le_bytes(chunk.try_into().unwrap());\n    }\n}\n\n/// Reads unsigned 64 bit integers from `src` into `dst`.\n#[inline]\npub fn read_u64_into(src: &[u8], dst: &mut [u64]) {\n    assert!(8 * src.len() >= dst.len());\n    for (out, chunk) in dst.iter_mut().zip(src.chunks_exact(8)) {\n        *out = u64::from_le_bytes(chunk.try_into().unwrap());\n    }\n}\n\n#[test]\nfn test_read() {\n    let bytes = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16];\n\n    let mut buf = [0u32; 4];\n    read_u32_into(&bytes, &mut buf);\n    assert_eq!(buf[0], 0x04030201);\n    assert_eq!(buf[3], 0x100F0E0D);\n\n    let mut buf = [0u32; 3];\n    read_u32_into(&bytes[1..13], &mut buf); // unaligned\n    assert_eq!(buf[0], 0x05040302);\n    assert_eq!(buf[2], 0x0D0C0B0A);\n\n    let mut buf = [0u64; 2];\n    read_u64_into(&bytes, &mut buf);\n    assert_eq!(buf[0], 0x0807060504030201);\n    assert_eq!(buf[1], 0x100F0E0D0C0B0A09);\n\n    let mut buf = [0u64; 1];\n    read_u64_into(&bytes[7..15], &mut buf); // unaligned\n    assert_eq!(buf[0], 0x0F0E0D0C0B0A0908);\n}\n"
  },
  {
    "project": "csv-sniffer",
    "target": 1,
    "commit_id": "821ee203bb8264c5eb12a127d6d7c712be4efecb",
    "func": "use std::io::{Read, Seek, SeekFrom};\n\nuse memchr;\n\nuse error::*;\n\npub(crate) fn preamble_skipcount<R: Read>(reader: &mut R, n_preamble_rows: usize)\n    -> Result<usize>\n{\n    if n_preamble_rows == 0 {\n        return Ok(0);\n    }\n    let mut skipcount = 0;\n    loop {\n        let cap = 1 << 12;\n        let mut buffer = Vec::with_capacity(cap);\n        unsafe { buffer.set_len(cap); }\n        let n_read = reader.read(&mut buffer)?;\n        let mut crlf_pos = 0;\n        let mut found = true;\n        for _ in 0..n_preamble_rows {\n            match memchr::memchr(b'\\n', &buffer[crlf_pos..]) {\n                Some(pos) => {\n                    crlf_pos += pos + 1;\n                },\n                None => {\n                    found = false;\n                    break;\n                }\n            }\n        }\n        if found {\n            skipcount += crlf_pos;\n            break;\n        } else {\n            skipcount += cap.min(n_read);\n        }\n    }\n    Ok(skipcount)\n}\n\npub(crate) fn snip_preamble<R: Read + Seek>(mut reader: R, n_preamble_rows: usize) -> Result<()> {\n    let seek_point = preamble_skipcount(&mut reader, n_preamble_rows)?;\n    reader.seek(SeekFrom::Start(seek_point as u64))?;\n    Ok(())\n}\n"
  },
  {
    "project": "ammonia",
    "target": 1,
    "commit_id": "ae3fb569e1f0019a8a9793616d1944614d79e7a0",
    "func": "// Copyright (C) Michael Howell and others\n// this library is released under the same terms as Rust itself.\n\n#![forbid(unsafe_code)]\n#![forbid(missing_docs)]\n\n//! Ammonia is a whitelist-based HTML sanitization library. It is designed to\n//! prevent cross-site scripting, layout breaking, and clickjacking caused\n//! by untrusted user-provided HTML being mixed into a larger web page.\n//!\n//! Ammonia uses [html5ever] to parse and serialize document fragments the same way browsers do,\n//! so it is extremely resilient to syntactic obfuscation.\n//!\n//! Ammonia parses its input exactly according to the HTML5 specification;\n//! it will not linkify bare URLs, insert line or paragraph breaks, or convert `(C)` into &copy;.\n//! If you want that, use a markup processor before running the sanitizer, like [pulldown-cmark].\n//!\n//! # Examples\n//!\n//! ```\n//! let result = ammonia::clean(\n//!     \"<b><img src='' onerror='alert(\\\\'hax\\\\')'>I'm not trying to XSS you</b>\"\n//! );\n//! assert_eq!(result, \"<b><img src=\\\"\\\">I'm not trying to XSS you</b>\");\n//! ```\n//!\n//! [html5ever]: https://github.com/servo/html5ever \"The HTML parser in Servo\"\n//! [pulldown-cmark]: https://github.com/google/pulldown-cmark \"CommonMark parser\"\n\nuse html5ever::interface::Attribute;\nuse html5ever::serialize::{serialize, SerializeOpts};\nuse html5ever::tree_builder::{NodeOrText, TreeSink};\nuse html5ever::{driver as html, local_name, namespace_url, ns, QualName};\nuse lazy_static::lazy_static;\nuse maplit::{hashmap, hashset};\nuse markup5ever_rcdom::{Handle, NodeData, RcDom, SerializableHandle};\nuse matches::matches;\nuse std::borrow::{Borrow, Cow};\nuse std::cmp::max;\nuse std::collections::{HashMap, HashSet};\nuse std::fmt;\nuse std::io;\nuse std::iter::IntoIterator as IntoIter;\nuse std::mem::replace;\nuse std::rc::Rc;\nuse std::str::FromStr;\nuse tendril::stream::TendrilSink;\nuse tendril::StrTendril;\nuse tendril::{format_tendril, ByteTendril};\npub use url::Url;\n\nuse html5ever::buffer_queue::BufferQueue;\nuse html5ever::tokenizer::{Token, TokenSink, TokenSinkResult, Tokenizer};\npub use url;\n\nlazy_static! {\n    static ref AMMONIA: Builder<'static> = Builder::default();\n}\n\n/// Clean HTML with a conservative set of defaults.\n///\n/// * [tags](struct.Builder.html#defaults)\n/// * [attributes on specific tags](struct.Builder.html#defaults-1)\n/// * [attributes on all tags](struct.Builder.html#defaults-2)\n/// * [url schemes](struct.Builder.html#defaults-3)\n/// * [relative URLs are passed through, unchanged, by default](struct.Builder.html#defaults-4)\n/// * [links are marked `noopener noreferrer` by default](struct.Builder.html#defaults-5)\n/// * [all `class=\"\"` settings are blocked by default](struct.Builder.html#defaults-6)\n/// * [comments are stripped by default](struct.Builder.html#defaults-7)\n///\n/// [opener]: https://mathiasbynens.github.io/rel-noopener/\n/// [referrer]: https://en.wikipedia.org/wiki/HTTP_referer\n///\n/// # Examples\n///\n///     assert_eq!(ammonia::clean(\"XSS<script>attack</script>\"), \"XSS\")\npub fn clean(src: &str) -> String {\n    AMMONIA.clean(src).to_string()\n}\n\n/// Turn an arbitrary string into unformatted HTML.\n///\n/// This function is roughly equivalent to PHP's `htmlspecialchars` and `htmlentities`.\n/// It is as strict as possible, encoding every character that has special meaning to the\n/// HTML parser.\n///\n/// # Warnings\n///\n/// This function cannot be used to package strings into a `<script>` or `<style>` tag;\n/// you need a JavaScript or CSS escaper to do that.\n///\n///     // DO NOT DO THIS\n///     # use ammonia::clean_text;\n///     let untrusted = \"Robert\\\"); abuse();//\";\n///     let html = format!(\"<script>invoke(\\\"{}\\\")</script>\", clean_text(untrusted));\n///\n/// `<textarea>` tags will strip the first newline, if present, even if that newline is encoded.\n/// If you want to build an editor that works the way most folks expect them to, you should put a\n/// newline at the beginning of the tag, like this:\n///\n///     # use ammonia::{Builder, clean_text};\n///     let untrusted = \"\\n\\nhi!\";\n///     let mut b = Builder::new();\n///     b.add_tags(&[\"textarea\"]);\n///     // This is the bad version\n///     // The user put two newlines at the beginning, but the first one was removed\n///     let sanitized = b.clean(&format!(\"<textarea>{}</textarea>\", clean_text(untrusted))).to_string();\n///     assert_eq!(\"<textarea>\\nhi!</textarea>\", sanitized);\n///     // This is a good version\n///     // The user put two newlines at the beginning, and we add a third one,\n///     // so the result still has two\n///     let sanitized = b.clean(&format!(\"<textarea>\\n{}</textarea>\", clean_text(untrusted))).to_string();\n///     assert_eq!(\"<textarea>\\n\\nhi!</textarea>\", sanitized);\n///     // This version is also often considered good\n///     // For many applications, leading and trailing whitespace is probably unwanted\n///     let sanitized = b.clean(&format!(\"<textarea>{}</textarea>\", clean_text(untrusted.trim()))).to_string();\n///     assert_eq!(\"<textarea>hi!</textarea>\", sanitized);\n///\n/// It also does not make user text safe for HTML attribute microsyntaxes such as `class` or `id`.\n/// Only use this function for places where HTML accepts unrestricted text such as `title` attributes\n/// and paragraph contents.\npub fn clean_text(src: &str) -> String {\n    let mut ret_val = String::with_capacity(max(4, src.len()));\n    for c in src.chars() {\n        let replacement = match c {\n            // this character, when confronted, will start a tag\n            '<' => \"&lt;\",\n            // in an unquoted attribute, will end the attribute value\n            '>' => \"&gt;\",\n            // in an attribute surrounded by double quotes, this character will end the attribute value\n            '\\\"' => \"&quot;\",\n            // in an attribute surrounded by single quotes, this character will end the attribute value\n            '\\'' => \"&apos;\",\n            // in HTML5, returns a bogus parse error in an unquoted attribute, while in SGML/HTML, it will end an attribute value surrounded by backquotes\n            '`' => \"&grave;\",\n            // in an unquoted attribute, this character will end the attribute\n            '/' => \"&#47;\",\n            // starts an entity reference\n            '&' => \"&amp;\",\n            // if at the beginning of an unquoted attribute, will get ignored\n            '=' => \"&#61;\",\n            // will end an unquoted attribute\n            ' ' => \"&#32;\",\n            '\\t' => \"&#9;\",\n            '\\n' => \"&#10;\",\n            '\\r' => \"&#12;\",\n            // a spec-compliant browser will perform this replacement anyway, but the middleware might not\n            '\\0' => \"&#65533;\",\n            // ALL OTHER CHARACTERS ARE PASSED THROUGH VERBATIM\n            _ => {\n                ret_val.push(c);\n                continue;\n            }\n        };\n        ret_val.push_str(replacement);\n    }\n    ret_val\n}\n\n/// Determine if a given string contains HTML\n///\n/// This function is parses the full string into HTML and checks if the input contained any\n/// HTML syntax.\n///\n/// # Note\n/// This function cannot will return positively for strings that contain invalid HTML syntax like\n/// `<g>` and even `Vec::<u8>::new()`.\npub fn is_html(input: &str) -> bool {\n    let santok = SanitizationTokenizer::new();\n    let mut chunk = ByteTendril::new();\n    chunk.push_slice(input.as_bytes());\n    let mut input = BufferQueue::new();\n    input.push_back(chunk.try_reinterpret().unwrap());\n\n    let mut tok = Tokenizer::new(santok, Default::default());\n    let _ = tok.feed(&mut input);\n    tok.end();\n    tok.sink.was_sanitized\n}\n\n#[derive(Copy, Clone)]\nstruct SanitizationTokenizer {\n    was_sanitized: bool,\n}\n\nimpl SanitizationTokenizer {\n    pub fn new() -> SanitizationTokenizer {\n        SanitizationTokenizer {\n            was_sanitized: false,\n        }\n    }\n}\n\nimpl TokenSink for SanitizationTokenizer {\n    type Handle = ();\n    fn process_token(&mut self, token: Token, _line_number: u64) -> TokenSinkResult<()> {\n        match token {\n            Token::CharacterTokens(_) | Token::EOFToken | Token::ParseError(_) => {}\n            _ => {\n                self.was_sanitized = true;\n            }\n        }\n        TokenSinkResult::Continue\n    }\n    fn end(&mut self) {}\n}\n\n/// An HTML sanitizer.\n///\n/// Given a fragment of HTML, Ammonia will parse it according to the HTML5\n/// parsing algorithm and sanitize any disallowed tags or attributes. This\n/// algorithm also takes care of things like unclosed and (some) misnested\n/// tags.\n///\n/// # Examples\n///\n///     use ammonia::{Builder, UrlRelative};\n///\n///     let a = Builder::default()\n///         .link_rel(None)\n///         .url_relative(UrlRelative::PassThrough)\n///         .clean(\"<a href=/>test\")\n///         .to_string();\n///     assert_eq!(\n///         a,\n///         \"<a href=\\\"/\\\">test</a>\");\n///\n/// # Panics\n///\n/// Running [`clean`] or [`clean_from_reader`] may cause a panic if the builder is\n/// configured with any of these (contradictory) settings:\n///\n///  * The `rel` attribute is added to [`generic_attributes`] or the\n///    [`tag_attributes`] for the `<a>` tag, and [`link_rel`] is not set to `None`.\n///\n///    For example, this is going to panic, since [`link_rel`] is set  to\n///    `Some(\"noopener noreferrer\")` by default,\n///    and it makes no sense to simultaneously say that the user is allowed to\n///    set their own `rel` attribute while saying that every link shall be set to\n///    a particular value:\n///\n///    ```should_panic\n///    use ammonia::Builder;\n///    use maplit::hashset;\n///\n///    # fn main() {\n///    Builder::default()\n///        .generic_attributes(hashset![\"rel\"])\n///        .clean(\"\");\n///    # }\n///    ```\n///\n///    This, however, is perfectly valid:\n///\n///    ```\n///    use ammonia::Builder;\n///    use maplit::hashset;\n///\n///    # fn main() {\n///    Builder::default()\n///        .generic_attributes(hashset![\"rel\"])\n///        .link_rel(None)\n///        .clean(\"\");\n///    # }\n///    ```\n///\n///  * The `class` attribute is in [`allowed_classes`] and is in the\n///    corresponding [`tag_attributes`] or in [`generic_attributes`].\n///\n///    This is done both to line up with the treatment of `rel`,\n///    and to prevent people from accidentally allowing arbitrary\n///    classes on a particular element.\n///\n///    This will panic:\n///\n///    ```should_panic\n///    use ammonia::Builder;\n///    use maplit::{hashmap, hashset};\n///\n///    # fn main() {\n///    Builder::default()\n///        .generic_attributes(hashset![\"class\"])\n///        .allowed_classes(hashmap![\"span\" => hashset![\"hidden\"]])\n///        .clean(\"\");\n///    # }\n///    ```\n///\n///    This, however, is perfectly valid:\n///\n///    ```\n///    use ammonia::Builder;\n///    use maplit::{hashmap, hashset};\n///\n///    # fn main() {\n///    Builder::default()\n///        .allowed_classes(hashmap![\"span\" => hashset![\"hidden\"]])\n///        .clean(\"\");\n///    # }\n///    ```\n///\n///  * A tag is in either [`tags`] or [`tag_attributes`] while also\n///    being in [`clean_content_tags`].\n///\n///    Both [`tags`] and [`tag_attributes`] are whitelists but\n///    [`clean_content_tags`] is a blacklist, so it doesn't make sense\n///    to have the same tag in both.\n///\n///    For example, this will panic, since the `aside` tag is in\n///    [`tags`] by default:\n///\n///    ```should_panic\n///    use ammonia::Builder;\n///    use maplit::hashset;\n///\n///    # fn main() {\n///    Builder::default()\n///        .clean_content_tags(hashset![\"aside\"])\n///        .clean(\"\");\n///    # }\n///    ```\n///\n///    This, however, is valid:\n///\n///    ```\n///    use ammonia::Builder;\n///    use maplit::hashset;\n///\n///    # fn main() {\n///    Builder::default()\n///        .rm_tags(&[\"aside\"])\n///        .clean_content_tags(hashset![\"aside\"])\n///        .clean(\"\");\n///    # }\n///    ```\n///\n/// [`clean`]: #method.clean\n/// [`clean_from_reader`]: #method.clean_from_reader\n/// [`generic_attributes`]: #method.generic_attributes\n/// [`tag_attributes`]: #method.tag_attributes\n/// [`generic_attributes`]: #method.generic_attributes\n/// [`link_rel`]: #method.link_rel\n/// [`allowed_classes`]: #method.allowed_classes\n/// [`id_prefix`]: #method.id_prefix\n/// [`tags`]: #method.tags\n/// [`clean_content_tags`]: #method.clean_content_tags\n#[derive(Debug)]\npub struct Builder<'a> {\n    tags: HashSet<&'a str>,\n    clean_content_tags: HashSet<&'a str>,\n    tag_attributes: HashMap<&'a str, HashSet<&'a str>>,\n    tag_attribute_values: HashMap<&'a str, HashMap<&'a str, HashSet<&'a str>>>,\n    set_tag_attribute_values: HashMap<&'a str, HashMap<&'a str, &'a str>>,\n    generic_attributes: HashSet<&'a str>,\n    url_schemes: HashSet<&'a str>,\n    url_relative: UrlRelative,\n    attribute_filter: Option<Box<dyn AttributeFilter>>,\n    link_rel: Option<&'a str>,\n    allowed_classes: HashMap<&'a str, HashSet<&'a str>>,\n    strip_comments: bool,\n    id_prefix: Option<&'a str>,\n    generic_attribute_prefixes: Option<HashSet<&'a str>>,\n}\n\nimpl<'a> Default for Builder<'a> {\n    fn default() -> Self {\n        #[cfg_attr(rustfmt, rustfmt_skip)]\n        let tags = hashset![\n            \"a\", \"abbr\", \"acronym\", \"area\", \"article\", \"aside\", \"b\", \"bdi\",\n            \"bdo\", \"blockquote\", \"br\", \"caption\", \"center\", \"cite\", \"code\",\n            \"col\", \"colgroup\", \"data\", \"dd\", \"del\", \"details\", \"dfn\", \"div\",\n            \"dl\", \"dt\", \"em\", \"figcaption\", \"figure\", \"footer\", \"h1\", \"h2\",\n            \"h3\", \"h4\", \"h5\", \"h6\", \"header\", \"hgroup\", \"hr\", \"i\", \"img\",\n            \"ins\", \"kbd\", \"kbd\", \"li\", \"map\", \"mark\", \"nav\", \"ol\", \"p\", \"pre\",\n            \"q\", \"rp\", \"rt\", \"rtc\", \"ruby\", \"s\", \"samp\", \"small\", \"span\",\n            \"strike\", \"strong\", \"sub\", \"summary\", \"sup\", \"table\", \"tbody\",\n            \"td\", \"th\", \"thead\", \"time\", \"tr\", \"tt\", \"u\", \"ul\", \"var\", \"wbr\"\n        ];\n        let clean_content_tags = hashset![\"script\", \"style\"];\n        let generic_attributes = hashset![\"lang\", \"title\"];\n        let tag_attributes = hashmap![\n            \"a\" => hashset![\n                \"href\", \"hreflang\"\n            ],\n            \"bdo\" => hashset![\n                \"dir\"\n            ],\n            \"blockquote\" => hashset![\n                \"cite\"\n            ],\n            \"col\" => hashset![\n                \"align\", \"char\", \"charoff\", \"span\"\n            ],\n            \"colgroup\" => hashset![\n                \"align\", \"char\", \"charoff\", \"span\"\n            ],\n            \"del\" => hashset![\n                \"cite\", \"datetime\"\n            ],\n            \"hr\" => hashset![\n                \"align\", \"size\", \"width\"\n            ],\n            \"img\" => hashset![\n                \"align\", \"alt\", \"height\", \"src\", \"width\"\n            ],\n            \"ins\" => hashset![\n                \"cite\", \"datetime\"\n            ],\n            \"ol\" => hashset![\n                \"start\"\n            ],\n            \"q\" => hashset![\n                \"cite\"\n            ],\n            \"table\" => hashset![\n                \"align\", \"char\", \"charoff\", \"summary\"\n            ],\n            \"tbody\" => hashset![\n                \"align\", \"char\", \"charoff\"\n            ],\n            \"td\" => hashset![\n                \"align\", \"char\", \"charoff\", \"colspan\", \"headers\", \"rowspan\"\n            ],\n            \"tfoot\" => hashset![\n                \"align\", \"char\", \"charoff\"\n            ],\n            \"th\" => hashset![\n                \"align\", \"char\", \"charoff\", \"colspan\", \"headers\", \"rowspan\", \"scope\"\n            ],\n            \"thead\" => hashset![\n                \"align\", \"char\", \"charoff\"\n            ],\n            \"tr\" => hashset![\n                \"align\", \"char\", \"charoff\"\n            ],\n        ];\n        let tag_attribute_values = hashmap![];\n        let set_tag_attribute_values = hashmap![];\n        let url_schemes = hashset![\n            \"bitcoin\",\n            \"ftp\",\n            \"ftps\",\n            \"geo\",\n            \"http\",\n            \"https\",\n            \"im\",\n            \"irc\",\n            \"ircs\",\n            \"magnet\",\n            \"mailto\",\n            \"mms\",\n            \"mx\",\n            \"news\",\n            \"nntp\",\n            \"openpgp4fpr\",\n            \"sip\",\n            \"sms\",\n            \"smsto\",\n            \"ssh\",\n            \"tel\",\n            \"url\",\n            \"webcal\",\n            \"wtai\",\n            \"xmpp\"\n        ];\n        let allowed_classes = hashmap![];\n\n        Builder {\n            tags,\n            clean_content_tags,\n            tag_attributes,\n            tag_attribute_values,\n            set_tag_attribute_values,\n            generic_attributes,\n            url_schemes,\n            url_relative: UrlRelative::PassThrough,\n            attribute_filter: None,\n            link_rel: Some(\"noopener noreferrer\"),\n            allowed_classes,\n            strip_comments: true,\n            id_prefix: None,\n            generic_attribute_prefixes: None,\n        }\n    }\n}\n\nimpl<'a> Builder<'a> {\n    /// Sets the tags that are allowed.\n    ///\n    /// # Examples\n    ///\n    ///     use ammonia::Builder;\n    ///     use maplit::hashset;\n    ///\n    ///     # fn main() {\n    ///     let tags = hashset![\"my-tag\"];\n    ///     let a = Builder::new()\n    ///         .tags(tags)\n    ///         .clean(\"<my-tag>\")\n    ///         .to_string();\n    ///     assert_eq!(a, \"<my-tag></my-tag>\");\n    ///     # }\n    ///\n    /// # Defaults\n    ///\n    /// ```notest\n    /// a, abbr, acronym, area, article, aside, b, bdi,\n    /// bdo, blockquote, br, caption, center, cite, code,\n    /// col, colgroup, data, dd, del, details, dfn, div,\n    /// dl, dt, em, figcaption, figure, footer, h1, h2,\n    /// h3, h4, h5, h6, header, hgroup, hr, i, img,\n    /// ins, kbd, kbd, li, map, mark, nav, ol, p, pre,\n    /// q, rp, rt, rtc, ruby, s, samp, small, span,\n    /// strike, strong, sub, summary, sup, table, tbody,\n    /// td, th, thead, time, tr, tt, u, ul, var, wbr\n    /// ```\n    pub fn tags(&mut self, value: HashSet<&'a str>) -> &mut Self {\n        self.tags = value;\n        self\n    }\n\n    /// Add additonal whitelisted tags without overwriting old ones.\n    ///\n    /// Does nothing if the tag is already there.\n    ///\n    /// # Examples\n    ///\n    ///     let a = ammonia::Builder::default()\n    ///         .add_tags(&[\"my-tag\"])\n    ///         .clean(\"<my-tag>test</my-tag> <span>mess</span>\").to_string();\n    ///     assert_eq!(\"<my-tag>test</my-tag> <span>mess</span>\", a);\n    pub fn add_tags<T: 'a + ?Sized + Borrow<str>, I: IntoIter<Item = &'a T>>(\n        &mut self,\n        it: I,\n    ) -> &mut Self {\n        self.tags.extend(it.into_iter().map(Borrow::borrow));\n        self\n    }\n\n    /// Remove already-whitelisted tags.\n    ///\n    /// Does nothing if the tags is already gone.\n    ///\n    /// # Examples\n    ///\n    ///     let a = ammonia::Builder::default()\n    ///         .rm_tags(&[\"span\"])\n    ///         .clean(\"<span></span>\").to_string();\n    ///     assert_eq!(\"\", a);\n    pub fn rm_tags<'b, T: 'b + ?Sized + Borrow<str>, I: IntoIter<Item = &'b T>>(\n        &mut self,\n        it: I,\n    ) -> &mut Self {\n        for i in it {\n            self.tags.remove(i.borrow());\n        }\n        self\n    }\n\n    /// Returns a copy of the set of whitelisted tags.\n    ///\n    /// # Examples\n    ///\n    ///     use maplit::hashset;\n    ///\n    ///     let tags = hashset![\"my-tag-1\", \"my-tag-2\"];\n    ///\n    ///     let mut b = ammonia::Builder::default();\n    ///     b.tags(Clone::clone(&tags));\n    ///     assert_eq!(tags, b.clone_tags());\n    pub fn clone_tags(&self) -> HashSet<&'a str> {\n        self.tags.clone()\n    }\n\n    /// Sets the tags whose contents will be completely removed from the output.\n    ///\n    /// Adding tags which are whitelisted in `tags` or `tag_attributes` will cause\n    /// a panic.\n    ///\n    /// # Examples\n    ///\n    ///     use ammonia::Builder;\n    ///     use maplit::hashset;\n    ///\n    ///     # fn main() {\n    ///     let tag_blacklist = hashset![\"script\", \"style\"];\n    ///     let a = Builder::new()\n    ///         .clean_content_tags(tag_blacklist)\n    ///         .clean(\"<script>alert('hello')</script><style>a { background: #fff }</style>\")\n    ///         .to_string();\n    ///     assert_eq!(a, \"\");\n    ///     # }\n    ///\n    /// # Defaults\n    ///\n    /// No tags have content removed by default.\n    pub fn clean_content_tags(&mut self, value: HashSet<&'a str>) -> &mut Self {\n        self.clean_content_tags = value;\n        self\n    }\n\n    /// Add additonal blacklisted clean-content tags without overwriting old ones.\n    ///\n    /// Does nothing if the tag is already there.\n    ///\n    /// Adding tags which are whitelisted in `tags` or `tag_attributes` will cause\n    /// a panic.\n    ///\n    /// # Examples\n    ///\n    ///     let a = ammonia::Builder::default()\n    ///         .add_clean_content_tags(&[\"my-tag\"])\n    ///         .clean(\"<my-tag>test</my-tag><span>mess</span>\").to_string();\n    ///     assert_eq!(\"<span>mess</span>\", a);\n    pub fn add_clean_content_tags<T: 'a + ?Sized + Borrow<str>, I: IntoIter<Item = &'a T>>(\n        &mut self,\n        it: I,\n    ) -> &mut Self {\n        self.clean_content_tags\n            .extend(it.into_iter().map(Borrow::borrow));\n        self\n    }\n\n    /// Remove already-blacklisted clean-content tags.\n    ///\n    /// Does nothing if the tags aren't blacklisted.\n    ///\n    /// # Examples\n    ///     use ammonia::Builder;\n    ///     use maplit::hashset;\n    ///\n    ///     # fn main() {\n    ///     let tag_blacklist = hashset![\"script\"];\n    ///     let a = ammonia::Builder::default()\n    ///         .clean_content_tags(tag_blacklist)\n    ///         .rm_clean_content_tags(&[\"script\"])\n    ///         .clean(\"<script>XSS</script>\").to_string();\n    ///     assert_eq!(\"XSS\", a);\n    ///     # }\n    pub fn rm_clean_content_tags<'b, T: 'b + ?Sized + Borrow<str>, I: IntoIter<Item = &'b T>>(\n        &mut self,\n        it: I,\n    ) -> &mut Self {\n        for i in it {\n            self.clean_content_tags.remove(i.borrow());\n        }\n        self\n    }\n\n    /// Returns a copy of the set of blacklisted clean-content tags.\n    ///\n    /// # Examples\n    ///     # use maplit::hashset;\n    ///\n    ///     let tags = hashset![\"my-tag-1\", \"my-tag-2\"];\n    ///\n    ///     let mut b = ammonia::Builder::default();\n    ///     b.clean_content_tags(Clone::clone(&tags));\n    ///     assert_eq!(tags, b.clone_clean_content_tags());\n    pub fn clone_clean_content_tags(&self) -> HashSet<&'a str> {\n        self.clean_content_tags.clone()\n    }\n\n    /// Sets the HTML attributes that are allowed on specific tags.\n    ///\n    /// The value is structured as a map from tag names to a set of attribute names.\n    ///\n    /// If a tag is not itself whitelisted, adding entries to this map will do nothing.\n    ///\n    /// # Examples\n    ///\n    ///     use ammonia::Builder;\n    ///     use maplit::{hashmap, hashset};\n    ///\n    ///     # fn main() {\n    ///     let tags = hashset![\"my-tag\"];\n    ///     let tag_attributes = hashmap![\n    ///         \"my-tag\" => hashset![\"val\"]\n    ///     ];\n    ///     let a = Builder::new().tags(tags).tag_attributes(tag_attributes)\n    ///         .clean(\"<my-tag val=1>\")\n    ///         .to_string();\n    ///     assert_eq!(a, \"<my-tag val=\\\"1\\\"></my-tag>\");\n    ///     # }\n    ///\n    /// # Defaults\n    ///\n    /// ```notest\n    /// a =>\n    ///     href, hreflang\n    /// bdo =>\n    ///     dir\n    /// blockquote =>\n    ///     cite\n    /// col =>\n    ///     align, char, charoff, span\n    /// colgroup =>\n    ///     align, char, charoff, span\n    /// del =>\n    ///     cite, datetime\n    /// hr =>\n    ///     align, size, width\n    /// img =>\n    ///     align, alt, height, src, width\n    /// ins =>\n    ///     cite, datetime\n    /// ol =>\n    ///     start\n    /// q =>\n    ///     cite\n    /// table =>\n    ///     align, char, charoff, summary\n    /// tbody =>\n    ///     align, char, charoff\n    /// td =>\n    ///     align, char, charoff, colspan, headers, rowspan\n    /// tfoot =>\n    ///     align, char, charoff\n    /// th =>\n    ///     align, char, charoff, colspan, headers, rowspan, scope\n    /// thead =>\n    ///     align, char, charoff\n    /// tr =>\n    ///     align, char, charoff\n    /// ```\n    pub fn tag_attributes(&mut self, value: HashMap<&'a str, HashSet<&'a str>>) -> &mut Self {\n        self.tag_attributes = value;\n        self\n    }\n\n    /// Add additonal whitelisted tag-specific attributes without overwriting old ones.\n    ///\n    /// # Examples\n    ///\n    ///     let a = ammonia::Builder::default()\n    ///         .add_tags(&[\"my-tag\"])\n    ///         .add_tag_attributes(\"my-tag\", &[\"my-attr\"])\n    ///         .clean(\"<my-tag my-attr>test</my-tag> <span>mess</span>\").to_string();\n    ///     assert_eq!(\"<my-tag my-attr=\\\"\\\">test</my-tag> <span>mess</span>\", a);\n    pub fn add_tag_attributes<\n        T: 'a + ?Sized + Borrow<str>,\n        U: 'a + ?Sized + Borrow<str>,\n        I: IntoIter<Item = &'a T>,\n    >(\n        &mut self,\n        tag: &'a U,\n        it: I,\n    ) -> &mut Self {\n        self.tag_attributes\n            .entry(tag.borrow())\n            .or_insert_with(|| HashSet::new())\n            .extend(it.into_iter().map(Borrow::borrow));\n        self\n    }\n\n    /// Remove already-whitelisted tag-specific attributes.\n    ///\n    /// Does nothing if the attribute is already gone.\n    ///\n    /// # Examples\n    ///\n    ///     let a = ammonia::Builder::default()\n    ///         .rm_tag_attributes(\"a\", &[\"href\"])\n    ///         .clean(\"<a href=\\\"/\\\"></a>\").to_string();\n    ///     assert_eq!(\"<a rel=\\\"noopener noreferrer\\\"></a>\", a);\n    pub fn rm_tag_attributes<\n        'b,\n        'c,\n        T: 'b + ?Sized + Borrow<str>,\n        U: 'c + ?Sized + Borrow<str>,\n        I: IntoIter<Item = &'b T>,\n    >(\n        &mut self,\n        tag: &'c U,\n        it: I,\n    ) -> &mut Self {\n        if let Some(tag) = self.tag_attributes.get_mut(tag.borrow()) {\n            for i in it {\n                tag.remove(i.borrow());\n            }\n        }\n        self\n    }\n\n    /// Returns a copy of the set of whitelisted tag-specific attributes.\n    ///\n    /// # Examples\n    ///     use maplit::{hashmap, hashset};\n    ///\n    ///     let tag_attributes = hashmap![\n    ///         \"my-tag\" => hashset![\"my-attr-1\", \"my-attr-2\"]\n    ///     ];\n    ///\n    ///     let mut b = ammonia::Builder::default();\n    ///     b.tag_attributes(Clone::clone(&tag_attributes));\n    ///     assert_eq!(tag_attributes, b.clone_tag_attributes());\n    pub fn clone_tag_attributes(&self) -> HashMap<&'a str, HashSet<&'a str>> {\n        self.tag_attributes.clone()\n    }\n\n    /// Sets the values of HTML attributes that are allowed on specific tags.\n    ///\n    /// The value is structured as a map from tag names to a map from attribute names to a set of\n    /// attribute values.\n    ///\n    /// If a tag is not itself whitelisted, adding entries to this map will do nothing.\n    ///\n    /// # Examples\n    ///\n    ///     use ammonia::Builder;\n    ///     use maplit::{hashmap, hashset};\n    ///\n    ///     # fn main() {\n    ///     let tags = hashset![\"my-tag\"];\n    ///     let tag_attribute_values = hashmap![\n    ///         \"my-tag\" => hashmap![\n    ///             \"my-attr\" => hashset![\"val\"],\n    ///         ],\n    ///     ];\n    ///     let a = Builder::new().tags(tags).tag_attribute_values(tag_attribute_values)\n    ///         .clean(\"<my-tag my-attr=val>\")\n    ///         .to_string();\n    ///     assert_eq!(a, \"<my-tag my-attr=\\\"val\\\"></my-tag>\");\n    ///     # }\n    ///\n    /// # Defaults\n    ///\n    /// None.\n    pub fn tag_attribute_values(\n        &mut self,\n        value: HashMap<&'a str, HashMap<&'a str, HashSet<&'a str>>>,\n    ) -> &mut Self {\n        self.tag_attribute_values = value;\n        self\n    }\n\n    /// Add additonal whitelisted tag-specific attribute values without overwriting old ones.\n    ///\n    /// # Examples\n    ///\n    ///     let a = ammonia::Builder::default()\n    ///         .add_tags(&[\"my-tag\"])\n    ///         .add_tag_attribute_values(\"my-tag\", \"my-attr\", &[\"\"])\n    ///         .clean(\"<my-tag my-attr>test</my-tag> <span>mess</span>\").to_string();\n    ///     assert_eq!(\"<my-tag my-attr=\\\"\\\">test</my-tag> <span>mess</span>\", a);\n    pub fn add_tag_attribute_values<\n        T: 'a + ?Sized + Borrow<str>,\n        U: 'a + ?Sized + Borrow<str>,\n        V: 'a + ?Sized + Borrow<str>,\n        I: IntoIter<Item = &'a T>,\n    >(\n        &mut self,\n        tag: &'a U,\n        attribute: &'a V,\n        it: I,\n    ) -> &mut Self {\n        self.tag_attribute_values\n            .entry(tag.borrow())\n            .or_insert_with(HashMap::new)\n            .entry(attribute.borrow())\n            .or_insert_with(HashSet::new)\n            .extend(it.into_iter().map(Borrow::borrow));\n\n        self\n    }\n\n    /// Remove already-whitelisted tag-specific attribute values.\n    ///\n    /// Does nothing if the attribute or the value is already gone.\n    ///\n    /// # Examples\n    ///\n    ///     let a = ammonia::Builder::default()\n    ///         .rm_tag_attributes(\"a\", &[\"href\"])\n    ///         .add_tag_attribute_values(\"a\", \"href\", &[\"/\"])\n    ///         .rm_tag_attribute_values(\"a\", \"href\", &[\"/\"])\n    ///         .clean(\"<a href=\\\"/\\\"></a>\").to_string();\n    ///     assert_eq!(\"<a rel=\\\"noopener noreferrer\\\"></a>\", a);\n    pub fn rm_tag_attribute_values<\n        'b,\n        'c,\n        T: 'b + ?Sized + Borrow<str>,\n        U: 'c + ?Sized + Borrow<str>,\n        V: 'c + ?Sized + Borrow<str>,\n        I: IntoIter<Item = &'b T>,\n    >(\n        &mut self,\n        tag: &'c U,\n        attribute: &'c V,\n        it: I,\n    ) -> &mut Self {\n        if let Some(attrs) = self\n            .tag_attribute_values\n            .get_mut(tag.borrow())\n            .and_then(|map| map.get_mut(attribute.borrow()))\n        {\n            for i in it {\n                attrs.remove(i.borrow());\n            }\n        }\n        self\n    }\n\n    /// Returns a copy of the set of whitelisted tag-specific attribute values.\n    ///\n    /// # Examples\n    ///\n    ///     use maplit::{hashmap, hashset};\n    ///\n    ///     let attribute_values = hashmap![\n    ///         \"my-attr-1\" => hashset![\"foo\"],\n    ///         \"my-attr-2\" => hashset![\"baz\", \"bar\"],\n    ///     ];\n    ///     let tag_attribute_values = hashmap![\n    ///         \"my-tag\" => attribute_values\n    ///     ];\n    ///\n    ///     let mut b = ammonia::Builder::default();\n    ///     b.tag_attribute_values(Clone::clone(&tag_attribute_values));\n    ///     assert_eq!(tag_attribute_values, b.clone_tag_attribute_values());\n    pub fn clone_tag_attribute_values(\n        &self,\n    ) -> HashMap<&'a str, HashMap<&'a str, HashSet<&'a str>>> {\n        self.tag_attribute_values.clone()\n    }\n\n    /// Sets the values of HTML attributes that are to be set on specific tags.\n    ///\n    /// The value is structured as a map from tag names to a map from attribute names to an\n    /// attribute value.\n    ///\n    /// If a tag is not itself whitelisted, adding entries to this map will do nothing.\n    ///\n    /// # Examples\n    ///\n    ///     use ammonia::Builder;\n    ///     use maplit::{hashmap, hashset};\n    ///\n    ///     # fn main() {\n    ///     let tags = hashset![\"my-tag\"];\n    ///     let set_tag_attribute_values = hashmap![\n    ///         \"my-tag\" => hashmap![\n    ///             \"my-attr\" => \"val\",\n    ///         ],\n    ///     ];\n    ///     let a = Builder::new().tags(tags).set_tag_attribute_values(set_tag_attribute_values)\n    ///         .clean(\"<my-tag>\")\n    ///         .to_string();\n    ///     assert_eq!(a, \"<my-tag my-attr=\\\"val\\\"></my-tag>\");\n    ///     # }\n    ///\n    /// # Defaults\n    ///\n    /// None.\n    pub fn set_tag_attribute_values(\n        &mut self,\n        value: HashMap<&'a str, HashMap<&'a str, &'a str>>,\n    ) -> &mut Self {\n        self.set_tag_attribute_values = value;\n        self\n    }\n\n    /// Add an attribute value to set on a specific element.\n    ///\n    /// # Examples\n    ///\n    ///     let a = ammonia::Builder::default()\n    ///         .add_tags(&[\"my-tag\"])\n    ///         .set_tag_attribute_value(\"my-tag\", \"my-attr\", \"val\")\n    ///         .clean(\"<my-tag>test</my-tag> <span>mess</span>\").to_string();\n    ///     assert_eq!(\"<my-tag my-attr=\\\"val\\\">test</my-tag> <span>mess</span>\", a);\n    pub fn set_tag_attribute_value<\n        T: 'a + ?Sized + Borrow<str>,\n        A: 'a + ?Sized + Borrow<str>,\n        V: 'a + ?Sized + Borrow<str>,\n    >(\n        &mut self,\n        tag: &'a T,\n        attribute: &'a A,\n        value: &'a V,\n    ) -> &mut Self {\n        self.set_tag_attribute_values\n            .entry(tag.borrow())\n            .or_insert_with(HashMap::new)\n            .insert(attribute.borrow(), value.borrow());\n        self\n    }\n\n    /// Remove existing tag-specific attribute values to be set.\n    ///\n    /// Does nothing if the attribute is already gone.\n    ///\n    /// # Examples\n    ///\n    ///     let a = ammonia::Builder::default()\n    ///         // this does nothing, since no value is set for this tag attribute yet\n    ///         .rm_set_tag_attribute_value(\"a\", \"target\")\n    ///         .set_tag_attribute_value(\"a\", \"target\", \"_blank\")\n    ///         .rm_set_tag_attribute_value(\"a\", \"target\")\n    ///         .clean(\"<a href=\\\"/\\\"></a>\").to_string();\n    ///     assert_eq!(\"<a href=\\\"/\\\" rel=\\\"noopener noreferrer\\\"></a>\", a);\n    pub fn rm_set_tag_attribute_value<\n        T: 'a + ?Sized + Borrow<str>,\n        A: 'a + ?Sized + Borrow<str>,\n    >(\n        &mut self,\n        tag: &'a T,\n        attribute: &'a A,\n    ) -> &mut Self {\n        if let Some(attributes) = self.set_tag_attribute_values.get_mut(tag.borrow()) {\n            attributes.remove(attribute.borrow());\n        }\n        self\n    }\n\n    /// Returns the value that will be set for the attribute on the element, if any.\n    ///\n    /// # Examples\n    ///\n    ///     let mut b = ammonia::Builder::default();\n    ///     b.set_tag_attribute_value(\"a\", \"target\", \"_blank\");\n    ///     let value = b.get_set_tag_attribute_value(\"a\", \"target\");\n    ///     assert_eq!(value, Some(\"_blank\"));\n    pub fn get_set_tag_attribute_value<\n        T: 'a + ?Sized + Borrow<str>,\n        A: 'a + ?Sized + Borrow<str>,\n    >(\n        &self,\n        tag: &'a T,\n        attribute: &'a A,\n    ) -> Option<&'a str> {\n        self.set_tag_attribute_values\n            .get(tag.borrow())\n            .and_then(|map| map.get(attribute.borrow()))\n            .copied()\n    }\n\n    /// Returns a copy of the set of tag-specific attribute values to be set.\n    ///\n    /// # Examples\n    ///\n    ///     use maplit::{hashmap, hashset};\n    ///\n    ///     let attribute_values = hashmap![\n    ///         \"my-attr-1\" => \"foo\",\n    ///         \"my-attr-2\" => \"bar\",\n    ///     ];\n    ///     let set_tag_attribute_values = hashmap![\n    ///         \"my-tag\" => attribute_values,\n    ///     ];\n    ///\n    ///     let mut b = ammonia::Builder::default();\n    ///     b.set_tag_attribute_values(Clone::clone(&set_tag_attribute_values));\n    ///     assert_eq!(set_tag_attribute_values, b.clone_set_tag_attribute_values());\n    pub fn clone_set_tag_attribute_values(&self) -> HashMap<&'a str, HashMap<&'a str, &'a str>> {\n        self.set_tag_attribute_values.clone()\n    }\n\n    /// Sets the prefix of attributes that are allowed on any tag.\n    ///\n    /// # Examples\n    ///\n    ///     use ammonia::Builder;\n    ///     use maplit::hashset;\n    ///\n    ///     # fn main() {\n    ///     let prefixes = hashset![\"data-\"];\n    ///     let a = Builder::new()\n    ///         .generic_attribute_prefixes(prefixes)\n    ///         .clean(\"<b data-val=1>\")\n    ///         .to_string();\n    ///     assert_eq!(a, \"<b data-val=\\\"1\\\"></b>\");\n    ///     # }\n    ///\n    /// # Defaults\n    ///\n    /// ```notest\n    /// lang, title\n    /// ```\n    pub fn generic_attribute_prefixes(&mut self, value: HashSet<&'a str>) -> &mut Self {\n        self.generic_attribute_prefixes = Some(value);\n        self\n    }\n\n    /// Add additional whitelisted attribute prefix without overwriting old ones.\n    ///\n    /// # Examples\n    ///\n    ///     let a = ammonia::Builder::default()\n    ///         .add_generic_attribute_prefixes(&[\"my-\"])\n    ///         .clean(\"<span my-attr>mess</span>\").to_string();\n    ///     assert_eq!(\"<span my-attr=\\\"\\\">mess</span>\", a);\n    pub fn add_generic_attribute_prefixes<\n        T: 'a + ?Sized + Borrow<str>,\n        I: IntoIter<Item = &'a T>,\n    >(\n        &mut self,\n        it: I,\n    ) -> &mut Self {\n        self.generic_attribute_prefixes\n            .get_or_insert_with(HashSet::new)\n            .extend(it.into_iter().map(Borrow::borrow));\n        self\n    }\n\n    /// Remove already-whitelisted attribute prefixes.\n    ///\n    /// Does nothing if the attribute prefix is already gone.\n    ///\n    /// # Examples\n    ///\n    ///     let a = ammonia::Builder::default()\n    ///         .add_generic_attribute_prefixes(&[\"data-\", \"code-\"])\n    ///         .rm_generic_attribute_prefixes(&[\"data-\"])\n    ///         .clean(\"<span code-test=\\\"foo\\\" data-test=\\\"cool\\\"></span>\").to_string();\n    ///     assert_eq!(\"<span code-test=\\\"foo\\\"></span>\", a);\n    pub fn rm_generic_attribute_prefixes<\n        'b,\n        T: 'b + ?Sized + Borrow<str>,\n        I: IntoIter<Item = &'b T>,\n    >(\n        &mut self,\n        it: I,\n    ) -> &mut Self {\n        if let Some(true) = self.generic_attribute_prefixes.as_mut().map(|prefixes| {\n            for i in it {\n                let _ = prefixes.remove(i.borrow());\n            }\n            prefixes.is_empty()\n        }) {\n            self.generic_attribute_prefixes = None;\n        }\n        self\n    }\n\n    /// Returns a copy of the set of whitelisted attribute prefixes.\n    ///\n    /// # Examples\n    ///\n    ///     use maplit::hashset;\n    ///\n    ///     let generic_attribute_prefixes = hashset![\"my-prfx-1-\", \"my-prfx-2-\"];\n    ///\n    ///     let mut b = ammonia::Builder::default();\n    ///     b.generic_attribute_prefixes(Clone::clone(&generic_attribute_prefixes));\n    ///     assert_eq!(Some(generic_attribute_prefixes), b.clone_generic_attribute_prefixes());\n    pub fn clone_generic_attribute_prefixes(&self) -> Option<HashSet<&'a str>> {\n        self.generic_attribute_prefixes.clone()\n    }\n\n    /// Sets the attributes that are allowed on any tag.\n    ///\n    /// # Examples\n    ///\n    ///     use ammonia::Builder;\n    ///     use maplit::hashset;\n    ///\n    ///     # fn main() {\n    ///     let attributes = hashset![\"data-val\"];\n    ///     let a = Builder::new()\n    ///         .generic_attributes(attributes)\n    ///         .clean(\"<b data-val=1>\")\n    ///         .to_string();\n    ///     assert_eq!(a, \"<b data-val=\\\"1\\\"></b>\");\n    ///     # }\n    ///\n    /// # Defaults\n    ///\n    /// ```notest\n    /// lang, title\n    /// ```\n    pub fn generic_attributes(&mut self, value: HashSet<&'a str>) -> &mut Self {\n        self.generic_attributes = value;\n        self\n    }\n\n    /// Add additonal whitelisted attributes without overwriting old ones.\n    ///\n    /// # Examples\n    ///\n    ///     let a = ammonia::Builder::default()\n    ///         .add_generic_attributes(&[\"my-attr\"])\n    ///         .clean(\"<span my-attr>mess</span>\").to_string();\n    ///     assert_eq!(\"<span my-attr=\\\"\\\">mess</span>\", a);\n    pub fn add_generic_attributes<T: 'a + ?Sized + Borrow<str>, I: IntoIter<Item = &'a T>>(\n        &mut self,\n        it: I,\n    ) -> &mut Self {\n        self.generic_attributes\n            .extend(it.into_iter().map(Borrow::borrow));\n        self\n    }\n\n    /// Remove already-whitelisted attributes.\n    ///\n    /// Does nothing if the attribute is already gone.\n    ///\n    /// # Examples\n    ///\n    ///     let a = ammonia::Builder::default()\n    ///         .rm_generic_attributes(&[\"title\"])\n    ///         .clean(\"<span title=\\\"cool\\\"></span>\").to_string();\n    ///     assert_eq!(\"<span></span>\", a);\n    pub fn rm_generic_attributes<'b, T: 'b + ?Sized + Borrow<str>, I: IntoIter<Item = &'b T>>(\n        &mut self,\n        it: I,\n    ) -> &mut Self {\n        for i in it {\n            self.generic_attributes.remove(i.borrow());\n        }\n        self\n    }\n\n    /// Returns a copy of the set of whitelisted attributes.\n    ///\n    /// # Examples\n    ///\n    ///     use maplit::hashset;\n    ///\n    ///     let generic_attributes = hashset![\"my-attr-1\", \"my-attr-2\"];\n    ///\n    ///     let mut b = ammonia::Builder::default();\n    ///     b.generic_attributes(Clone::clone(&generic_attributes));\n    ///     assert_eq!(generic_attributes, b.clone_generic_attributes());\n    pub fn clone_generic_attributes(&self) -> HashSet<&'a str> {\n        self.generic_attributes.clone()\n    }\n\n    /// Sets the URL schemes permitted on `href` and `src` attributes.\n    ///\n    /// # Examples\n    ///\n    ///     use ammonia::Builder;\n    ///     use maplit::hashset;\n    ///\n    ///     # fn main() {\n    ///     let url_schemes = hashset![\n    ///         \"http\", \"https\", \"mailto\", \"magnet\"\n    ///     ];\n    ///     let a = Builder::new().url_schemes(url_schemes)\n    ///         .clean(\"<a href=\\\"magnet:?xt=urn:ed2k:31D6CFE0D16AE931B73C59D7E0C089C0&xl=0&dn=zero_len.fil&xt=urn:bitprint:3I42H3S6NNFQ2MSVX7XZKYAYSCX5QBYJ.LWPNACQDBZRYXW3VHJVCJ64QBZNGHOHHHZWCLNQ&xt=urn:md5:D41D8CD98F00B204E9800998ECF8427E\\\">zero-length file</a>\")\n    ///         .to_string();\n    ///\n    ///     // See `link_rel` for information on the rel=\"noopener noreferrer\" attribute\n    ///     // in the cleaned HTML.\n    ///     assert_eq!(a,\n    ///       \"<a href=\\\"magnet:?xt=urn:ed2k:31D6CFE0D16AE931B73C59D7E0C089C0&amp;xl=0&amp;dn=zero_len.fil&amp;xt=urn:bitprint:3I42H3S6NNFQ2MSVX7XZKYAYSCX5QBYJ.LWPNACQDBZRYXW3VHJVCJ64QBZNGHOHHHZWCLNQ&amp;xt=urn:md5:D41D8CD98F00B204E9800998ECF8427E\\\" rel=\\\"noopener noreferrer\\\">zero-length file</a>\");\n    ///     # }\n    ///\n    /// # Defaults\n    ///\n    /// ```notest\n    /// bitcoin, ftp, ftps, geo, http, https, im, irc,\n    /// ircs, magnet, mailto, mms, mx, news, nntp,\n    /// openpgp4fpr, sip, sms, smsto, ssh, tel, url,\n    /// webcal, wtai, xmpp\n    /// ```\n    pub fn url_schemes(&mut self, value: HashSet<&'a str>) -> &mut Self {\n        self.url_schemes = value;\n        self\n    }\n\n    /// Add additonal whitelisted URL schemes without overwriting old ones.\n    ///\n    /// # Examples\n    ///\n    ///     let a = ammonia::Builder::default()\n    ///         .add_url_schemes(&[\"my-scheme\"])\n    ///         .clean(\"<a href=my-scheme:home>mess</span>\").to_string();\n    ///     assert_eq!(\"<a href=\\\"my-scheme:home\\\" rel=\\\"noopener noreferrer\\\">mess</a>\", a);\n    pub fn add_url_schemes<T: 'a + ?Sized + Borrow<str>, I: IntoIter<Item = &'a T>>(\n        &mut self,\n        it: I,\n    ) -> &mut Self {\n        self.url_schemes.extend(it.into_iter().map(Borrow::borrow));\n        self\n    }\n\n    /// Remove already-whitelisted attributes.\n    ///\n    /// Does nothing if the attribute is already gone.\n    ///\n    /// # Examples\n    ///\n    ///     let a = ammonia::Builder::default()\n    ///         .rm_url_schemes(&[\"ftp\"])\n    ///         .clean(\"<a href=\\\"ftp://ftp.mozilla.org/\\\"></a>\").to_string();\n    ///     assert_eq!(\"<a rel=\\\"noopener noreferrer\\\"></a>\", a);\n    pub fn rm_url_schemes<'b, T: 'b + ?Sized + Borrow<str>, I: IntoIter<Item = &'b T>>(\n        &mut self,\n        it: I,\n    ) -> &mut Self {\n        for i in it {\n            self.url_schemes.remove(i.borrow());\n        }\n        self\n    }\n\n    /// Returns a copy of the set of whitelisted URL schemes.\n    ///\n    /// # Examples\n    ///     use maplit::hashset;\n    ///\n    ///     let url_schemes = hashset![\"my-scheme-1\", \"my-scheme-2\"];\n    ///\n    ///     let mut b = ammonia::Builder::default();\n    ///     b.url_schemes(Clone::clone(&url_schemes));\n    ///     assert_eq!(url_schemes, b.clone_url_schemes());\n    pub fn clone_url_schemes(&self) -> HashSet<&'a str> {\n        self.url_schemes.clone()\n    }\n\n    /// Configures the behavior for relative URLs: pass-through, resolve-with-base, or deny.\n    ///\n    /// # Examples\n    ///\n    ///     use ammonia::{Builder, UrlRelative};\n    ///\n    ///     let a = Builder::new().url_relative(UrlRelative::PassThrough)\n    ///         .clean(\"<a href=/>Home</a>\")\n    ///         .to_string();\n    ///\n    ///     // See `link_rel` for information on the rel=\"noopener noreferrer\" attribute\n    ///     // in the cleaned HTML.\n    ///     assert_eq!(\n    ///       a,\n    ///       \"<a href=\\\"/\\\" rel=\\\"noopener noreferrer\\\">Home</a>\");\n    ///\n    /// # Defaults\n    ///\n    /// ```notest\n    /// UrlRelative::PassThrough\n    /// ```\n    pub fn url_relative(&mut self, value: UrlRelative) -> &mut Self {\n        self.url_relative = value;\n        self\n    }\n\n    /// Allows rewriting of all attributes using a callback.\n    ///\n    /// The callback takes name of the element, attribute and its value.\n    /// Returns `None` to remove the attribute, or a value to use.\n    ///\n    /// Rewriting of attributes with URLs is done before `url_relative()`.\n    ///\n    /// # Panics\n    ///\n    /// If more than one callback is set.\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// use ammonia::Builder;\n    /// let a = Builder::new()\n    ///     .attribute_filter(|element, attribute, value| {\n    ///         match (element, attribute) {\n    ///             (\"img\", \"src\") => None,\n    ///             _ => Some(value.into())\n    ///         }\n    ///     })\n    ///     .link_rel(None)\n    ///     .clean(\"<a href=/><img alt=Home src=foo></a>\")\n    ///     .to_string();\n    /// assert_eq!(a,\n    ///     r#\"<a href=\"/\"><img alt=\"Home\"></a>\"#);\n    /// ```\n    pub fn attribute_filter<'cb, CallbackFn>(&mut self, callback: CallbackFn) -> &mut Self\n    where\n        CallbackFn: for<'u> Fn(&str, &str, &'u str) -> Option<Cow<'u, str>> + Send + Sync + 'static,\n    {\n        assert!(\n            self.attribute_filter.is_none(),\n            \"attribute_filter can be set only once\"\n        );\n        self.attribute_filter = Some(Box::new(callback));\n        self\n    }\n\n    /// Returns `true` if the relative URL resolver is set to `Deny`.\n    ///\n    /// # Examples\n    ///\n    ///     use ammonia::{Builder, UrlRelative};\n    ///     let mut a = Builder::default();\n    ///     a.url_relative(UrlRelative::Deny);\n    ///     assert!(a.is_url_relative_deny());\n    ///     a.url_relative(UrlRelative::PassThrough);\n    ///     assert!(!a.is_url_relative_deny());\n    pub fn is_url_relative_deny(&self) -> bool {\n        matches!(self.url_relative, UrlRelative::Deny)\n    }\n\n    /// Returns `true` if the relative URL resolver is set to `PassThrough`.\n    ///\n    /// # Examples\n    ///\n    ///     use ammonia::{Builder, UrlRelative};\n    ///     let mut a = Builder::default();\n    ///     a.url_relative(UrlRelative::Deny);\n    ///     assert!(!a.is_url_relative_pass_through());\n    ///     a.url_relative(UrlRelative::PassThrough);\n    ///     assert!(a.is_url_relative_pass_through());\n    pub fn is_url_relative_pass_through(&self) -> bool {\n        matches!(self.url_relative, UrlRelative::PassThrough)\n    }\n\n    /// Returns `true` if the relative URL resolver is set to `Custom`.\n    ///\n    /// # Examples\n    ///\n    ///     use ammonia::{Builder, UrlRelative};\n    ///     use std::borrow::Cow;\n    ///     fn test(a: &str) -> Option<Cow<str>> { None }\n    ///     # fn main() {\n    ///     let mut a = Builder::default();\n    ///     a.url_relative(UrlRelative::Custom(Box::new(test)));\n    ///     assert!(a.is_url_relative_custom());\n    ///     a.url_relative(UrlRelative::PassThrough);\n    ///     assert!(!a.is_url_relative_custom());\n    ///     a.url_relative(UrlRelative::Deny);\n    ///     assert!(!a.is_url_relative_custom());\n    ///     # }\n    pub fn is_url_relative_custom(&self) -> bool {\n        matches!(self.url_relative, UrlRelative::Custom(_))\n    }\n\n    /// Configures a `rel` attribute that will be added on links.\n    ///\n    /// If `rel` is in the generic or tag attributes, this must be set to `None`.\n    /// Common `rel` values to include:\n    ///\n    /// * `noopener`: This prevents [a particular type of XSS attack],\n    ///   and should usually be turned on for untrusted HTML.\n    /// * `noreferrer`: This prevents the browser from [sending the source URL]\n    ///   to the website that is linked to.\n    /// * `nofollow`: This prevents search engines from [using this link for\n    ///   ranking], which disincentivizes spammers.\n    ///\n    /// To turn on rel-insertion, call this function with a space-separated list.\n    /// Ammonia does not parse rel-attributes;\n    /// it just puts the given string into the attribute directly.\n    ///\n    /// [a particular type of XSS attack]: https://mathiasbynens.github.io/rel-noopener/\n    /// [sending the source URL]: https://en.wikipedia.org/wiki/HTTP_referer\n    /// [using this link for ranking]: https://en.wikipedia.org/wiki/Nofollow\n    ///\n    /// # Examples\n    ///\n    ///     use ammonia::Builder;\n    ///\n    ///     let a = Builder::new().link_rel(None)\n    ///         .clean(\"<a href=https://rust-lang.org/>Rust</a>\")\n    ///         .to_string();\n    ///     assert_eq!(\n    ///       a,\n    ///       \"<a href=\\\"https://rust-lang.org/\\\">Rust</a>\");\n    ///\n    /// # Defaults\n    ///\n    /// ```notest\n    /// Some(\"noopener noreferrer\")\n    /// ```\n    pub fn link_rel(&mut self, value: Option<&'a str>) -> &mut Self {\n        self.link_rel = value;\n        self\n    }\n\n    /// Returns the settings for links' `rel` attribute, if one is set.\n    ///\n    /// # Examples\n    ///\n    ///     use ammonia::{Builder, UrlRelative};\n    ///     let mut a = Builder::default();\n    ///     a.link_rel(Some(\"a b\"));\n    ///     assert_eq!(a.get_link_rel(), Some(\"a b\"));\n    pub fn get_link_rel(&self) -> Option<&str> {\n        self.link_rel.clone()\n    }\n\n    /// Sets the CSS classes that are allowed on specific tags.\n    ///\n    /// The values is structured as a map from tag names to a set of class names.\n    ///\n    /// If the `class` attribute is itself whitelisted for a tag, then adding entries to\n    /// this map will cause a panic.\n    ///\n    /// # Examples\n    ///\n    ///     use ammonia::Builder;\n    ///     use maplit::{hashmap, hashset};\n    ///\n    ///     # fn main() {\n    ///     let allowed_classes = hashmap![\n    ///         \"code\" => hashset![\"rs\", \"ex\", \"c\", \"cxx\", \"js\"]\n    ///     ];\n    ///     let a = Builder::new()\n    ///         .allowed_classes(allowed_classes)\n    ///         .clean(\"<code class=rs>fn main() {}</code>\")\n    ///         .to_string();\n    ///     assert_eq!(\n    ///       a,\n    ///       \"<code class=\\\"rs\\\">fn main() {}</code>\");\n    ///     # }\n    ///\n    /// # Defaults\n    ///\n    /// The set of allowed classes is empty by default.\n    pub fn allowed_classes(&mut self, value: HashMap<&'a str, HashSet<&'a str>>) -> &mut Self {\n        self.allowed_classes = value;\n        self\n    }\n\n    /// Add additonal whitelisted classes without overwriting old ones.\n    ///\n    /// # Examples\n    ///\n    ///     let a = ammonia::Builder::default()\n    ///         .add_allowed_classes(\"a\", &[\"onebox\"])\n    ///         .clean(\"<a href=/ class=onebox>mess</span>\").to_string();\n    ///     assert_eq!(\"<a href=\\\"/\\\" class=\\\"onebox\\\" rel=\\\"noopener noreferrer\\\">mess</a>\", a);\n    pub fn add_allowed_classes<\n        T: 'a + ?Sized + Borrow<str>,\n        U: 'a + ?Sized + Borrow<str>,\n        I: IntoIter<Item = &'a T>,\n    >(\n        &mut self,\n        tag: &'a U,\n        it: I,\n    ) -> &mut Self {\n        self.allowed_classes\n            .entry(tag.borrow())\n            .or_insert_with(|| HashSet::new())\n            .extend(it.into_iter().map(Borrow::borrow));\n        self\n    }\n\n    /// Remove already-whitelisted attributes.\n    ///\n    /// Does nothing if the attribute is already gone.\n    ///\n    /// # Examples\n    ///\n    ///     let a = ammonia::Builder::default()\n    ///         .add_allowed_classes(\"span\", &[\"active\"])\n    ///         .rm_allowed_classes(\"span\", &[\"active\"])\n    ///         .clean(\"<span class=active>\").to_string();\n    ///     assert_eq!(\"<span class=\\\"\\\"></span>\", a);\n    pub fn rm_allowed_classes<\n        'b,\n        'c,\n        T: 'b + ?Sized + Borrow<str>,\n        U: 'c + ?Sized + Borrow<str>,\n        I: IntoIter<Item = &'b T>,\n    >(\n        &mut self,\n        tag: &'c U,\n        it: I,\n    ) -> &mut Self {\n        if let Some(tag) = self.allowed_classes.get_mut(tag.borrow()) {\n            for i in it {\n                tag.remove(i.borrow());\n            }\n        }\n        self\n    }\n\n    /// Returns a copy of the set of whitelisted class attributes.\n    ///\n    /// # Examples\n    ///\n    ///     use maplit::{hashmap, hashset};\n    ///\n    ///     let allowed_classes = hashmap![\n    ///         \"my-tag\" => hashset![\"my-class-1\", \"my-class-2\"]\n    ///     ];\n    ///\n    ///     let mut b = ammonia::Builder::default();\n    ///     b.allowed_classes(Clone::clone(&allowed_classes));\n    ///     assert_eq!(allowed_classes, b.clone_allowed_classes());\n    pub fn clone_allowed_classes(&self) -> HashMap<&'a str, HashSet<&'a str>> {\n        self.allowed_classes.clone()\n    }\n\n    /// Configures the handling of HTML comments.\n    ///\n    /// If this option is false, comments will be preserved.\n    ///\n    /// # Examples\n    ///\n    ///     use ammonia::Builder;\n    ///\n    ///     let a = Builder::new().strip_comments(false)\n    ///         .clean(\"<!-- yes -->\")\n    ///         .to_string();\n    ///     assert_eq!(\n    ///       a,\n    ///       \"<!-- yes -->\");\n    ///\n    /// # Defaults\n    ///\n    /// `true`\n    pub fn strip_comments(&mut self, value: bool) -> &mut Self {\n        self.strip_comments = value;\n        self\n    }\n\n    /// Returns `true` if comment stripping is turned on.\n    ///\n    /// # Examples\n    ///\n    ///     let mut a = ammonia::Builder::new();\n    ///     a.strip_comments(true);\n    ///     assert!(a.will_strip_comments());\n    ///     a.strip_comments(false);\n    ///     assert!(!a.will_strip_comments());\n    pub fn will_strip_comments(&self) -> bool {\n        self.strip_comments\n    }\n\n    /// Prefixes all \"id\" attribute values with a given string.  Note that the tag and\n    /// attribute themselves must still be whitelisted.\n    ///\n    /// # Examples\n    ///\n    ///     use ammonia::Builder;\n    ///     use maplit::hashset;\n    ///\n    ///     # fn main() {\n    ///     let attributes = hashset![\"id\"];\n    ///     let a = Builder::new()\n    ///         .generic_attributes(attributes)\n    ///         .id_prefix(Some(\"safe-\"))\n    ///         .clean(\"<b id=42>\")\n    ///         .to_string();\n    ///     assert_eq!(a, \"<b id=\\\"safe-42\\\"></b>\");\n    ///     # }\n\n    ///\n    /// # Defaults\n    ///\n    /// `None`\n    pub fn id_prefix(&mut self, value: Option<&'a str>) -> &mut Self {\n        self.id_prefix = value;\n        self\n    }\n\n    /// Constructs a [`Builder`] instance configured with the [default options].\n    ///\n    /// # Examples\n    ///\n    ///     use ammonia::{Builder, Url, UrlRelative};\n    ///     # use std::error::Error;\n    ///\n    ///     # fn do_main() -> Result<(), Box<Error>> {\n    ///     let input = \"<!-- comments will be stripped -->This is an <a href=.>Ammonia</a> example using <a href=struct.Builder.html#method.new onclick=xss>the <code onmouseover=xss>new()</code> function</a>.\";\n    ///     let output = \"This is an <a href=\\\"https://docs.rs/ammonia/1.0/ammonia/\\\" rel=\\\"noopener noreferrer\\\">Ammonia</a> example using <a href=\\\"https://docs.rs/ammonia/1.0/ammonia/struct.Builder.html#method.new\\\" rel=\\\"noopener noreferrer\\\">the <code>new()</code> function</a>.\";\n    ///\n    ///     let result = Builder::new() // <--\n    ///         .url_relative(UrlRelative::RewriteWithBase(Url::parse(\"https://docs.rs/ammonia/1.0/ammonia/\")?))\n    ///         .clean(input)\n    ///         .to_string();\n    ///     assert_eq!(result, output);\n    ///     # Ok(())\n    ///     # }\n    ///     # fn main() { do_main().unwrap() }\n    ///\n    /// [default options]: fn.clean.html\n    /// [`Builder`]: struct.Builder.html\n    pub fn new() -> Self {\n        Self::default()\n    }\n\n    /// Sanitizes an HTML fragment in a string according to the configured options.\n    ///\n    /// # Examples\n    ///\n    ///     use ammonia::{Builder, Url, UrlRelative};\n    ///     # use std::error::Error;\n    ///\n    ///     # fn do_main() -> Result<(), Box<Error>> {\n    ///     let input = \"<!-- comments will be stripped -->This is an <a href=.>Ammonia</a> example using <a href=struct.Builder.html#method.new onclick=xss>the <code onmouseover=xss>new()</code> function</a>.\";\n    ///     let output = \"This is an <a href=\\\"https://docs.rs/ammonia/1.0/ammonia/\\\" rel=\\\"noopener noreferrer\\\">Ammonia</a> example using <a href=\\\"https://docs.rs/ammonia/1.0/ammonia/struct.Builder.html#method.new\\\" rel=\\\"noopener noreferrer\\\">the <code>new()</code> function</a>.\";\n    ///\n    ///     let result = Builder::new()\n    ///         .url_relative(UrlRelative::RewriteWithBase(Url::parse(\"https://docs.rs/ammonia/1.0/ammonia/\")?))\n    ///         .clean(input)\n    ///         .to_string(); // <--\n    ///     assert_eq!(result, output);\n    ///     # Ok(())\n    ///     # }\n    ///     # fn main() { do_main().unwrap() }\n    pub fn clean(&self, src: &str) -> Document {\n        let parser = Self::make_parser();\n        let dom = parser.one(src);\n        self.clean_dom(dom)\n    }\n\n    /// Sanitizes an HTML fragment from a reader according to the configured options.\n    ///\n    /// The input should be in UTF-8 encoding, otherwise the decoding is lossy, just\n    /// like when using [`String::from_utf8_lossy`].\n    ///\n    /// To avoid consuming the reader, a mutable reference can be passed to this method.\n    ///\n    /// # Examples\n    ///\n    ///     use ammonia::Builder;\n    ///     # use std::error::Error;\n    ///\n    ///     # fn do_main() -> Result<(), Box<Error>> {\n    ///     let a = Builder::new()\n    ///         .clean_from_reader(&b\"<!-- no -->\"[..])? // notice the `b`\n    ///         .to_string();\n    ///     assert_eq!(a, \"\");\n    ///     # Ok(()) }\n    ///     # fn main() { do_main().unwrap() }\n    ///\n    /// [`String::from_utf8_lossy`]: https://doc.rust-lang.org/std/string/struct.String.html#method.from_utf8_lossy\n    pub fn clean_from_reader<R>(&self, mut src: R) -> io::Result<Document>\n    where\n        R: io::Read,\n    {\n        let parser = Self::make_parser().from_utf8();\n        let dom = parser.read_from(&mut src)?;\n        Ok(self.clean_dom(dom))\n    }\n\n    /// Clean a post-parsing DOM.\n    ///\n    /// This is not a public API because RcDom isn't really stable.\n    /// We want to be able to take breaking changes to html5ever itself\n    /// without having to break Ammonia's API.\n    fn clean_dom(&self, mut dom: RcDom) -> Document {\n        let mut stack = Vec::new();\n        let mut removed = Vec::new();\n        let link_rel = self\n            .link_rel\n            .map(|link_rel| format_tendril!(\"{}\", link_rel));\n        if link_rel.is_some() {\n            assert!(self.generic_attributes.get(\"rel\").is_none());\n            assert!(self\n                .tag_attributes\n                .get(\"a\")\n                .and_then(|a| a.get(\"rel\"))\n                .is_none());\n        }\n        assert!(self.allowed_classes.is_empty() || !self.generic_attributes.contains(\"class\"));\n        for (tag_name, _classes) in &self.allowed_classes {\n            assert!(self\n                .tag_attributes\n                .get(tag_name)\n                .and_then(|a| a.get(\"class\"))\n                .is_none());\n        }\n        for tag_name in &self.clean_content_tags {\n            assert!(!self.tags.contains(tag_name));\n            assert!(!self.tag_attributes.contains_key(tag_name));\n        }\n        let url_base = if let UrlRelative::RewriteWithBase(ref base) = self.url_relative {\n            Some(base)\n        } else {\n            None\n        };\n        let body = {\n            let children = dom.document.children.borrow();\n            children[0].clone()\n        };\n        stack.extend(\n            replace(&mut *body.children.borrow_mut(), Vec::new())\n                .into_iter()\n                .rev(),\n        );\n        // This design approach is used to prevent pathological content from producing\n        // a stack overflow. The `stack` contains to-be-cleaned nodes, while `remove`,\n        // of course, contains nodes that need to be dropped (we can't just drop them,\n        // because they could have a very deep child tree).\n        while let Some(mut node) = stack.pop() {\n            let parent = node.parent\n                .replace(None).expect(\"a node in the DOM will have a parent, except the root, which is not processed\")\n                .upgrade().expect(\"a node's parent will be pointed to by its parent (or the root pointer), and will not be dropped\");\n            if self.clean_node_content(&node) {\n                removed.push(node);\n                continue;\n            }\n            let pass = self.clean_child(&mut node, url_base);\n            if pass {\n                self.adjust_node_attributes(&mut node, &link_rel, url_base, self.id_prefix);\n                dom.append(&parent.clone(), NodeOrText::AppendNode(node.clone()));\n            } else {\n                for sub in node.children.borrow_mut().iter_mut() {\n                    sub.parent.replace(Some(Rc::downgrade(&parent)));\n                }\n            }\n            stack.extend(\n                replace(&mut *node.children.borrow_mut(), Vec::new())\n                    .into_iter()\n                    .rev(),\n            );\n            if !pass {\n                removed.push(node);\n            }\n        }\n        // Now, imperatively clean up all of the child nodes.\n        // Otherwise, we could wind up with a DoS, either caused by a memory leak,\n        // or caused by a stack overflow.\n        while let Some(node) = removed.pop() {\n            removed.extend_from_slice(&replace(&mut *node.children.borrow_mut(), Vec::new())[..]);\n        }\n        Document(dom)\n    }\n\n    /// Returns `true` if a node and all its content should be removed.\n    fn clean_node_content(&self, node: &Handle) -> bool {\n        match node.data {\n            NodeData::Text { .. }\n            | NodeData::Comment { .. }\n            | NodeData::Doctype { .. }\n            | NodeData::Document\n            | NodeData::ProcessingInstruction { .. } => false,\n            NodeData::Element { ref name, .. } => self.clean_content_tags.contains(&*name.local),\n        }\n    }\n\n    /// Remove unwanted attributes, and check if the node should be kept or not.\n    ///\n    /// The root node doesn't need cleaning because we create the root node ourselves,\n    /// and it doesn't get serialized, and ... it just exists to give the parser\n    /// a context (in this case, a div-like block context).\n    fn clean_child(&self, child: &mut Handle, url_base: Option<&Url>) -> bool {\n        match child.data {\n            NodeData::Text { .. } => true,\n            NodeData::Comment { .. } => !self.strip_comments,\n            NodeData::Doctype { .. }\n            | NodeData::Document\n            | NodeData::ProcessingInstruction { .. } => false,\n            NodeData::Element {\n                ref name,\n                ref attrs,\n                ..\n            } => {\n                if self.tags.contains(&*name.local) {\n                    let attr_filter = |attr: &html5ever::Attribute| {\n                        let whitelisted = self.generic_attributes.contains(&*attr.name.local)\n                            || self.generic_attribute_prefixes.as_ref().map(|prefixes| {\n                                prefixes.iter().any(|&p| attr.name.local.starts_with(p))\n                            }) == Some(true)\n                            || self\n                                .tag_attributes\n                                .get(&*name.local)\n                                .map(|ta| ta.contains(&*attr.name.local))\n                                == Some(true)\n                            || self\n                                .tag_attribute_values\n                                .get(&*name.local)\n                                .and_then(|tav| tav.get(&*attr.name.local))\n                                .map(|vs| {\n                                    let attr_val = attr.value.to_lowercase();\n                                    vs.iter().any(|v| v.to_lowercase() == attr_val)\n                                })\n                                == Some(true);\n                        if !whitelisted {\n                            // If the class attribute is not whitelisted,\n                            // but there is a whitelisted set of allowed_classes,\n                            // do not strip out the class attribute.\n                            // Banned classes will be filtered later.\n                            &*attr.name.local == \"class\"\n                                && self.allowed_classes.contains_key(&*name.local)\n                        } else if is_url_attr(&*name.local, &*attr.name.local) {\n                            let url = Url::parse(&*attr.value);\n                            if let Ok(url) = url {\n                                self.url_schemes.contains(url.scheme())\n                            } else if url == Err(url::ParseError::RelativeUrlWithoutBase) {\n                                if matches!(self.url_relative, UrlRelative::Deny) {\n                                    false\n                                } else if let Some(url_base) = url_base {\n                                    url_base.join(&*attr.value).is_ok()\n                                } else {\n                                    true\n                                }\n                            } else {\n                                false\n                            }\n                        } else {\n                            true\n                        }\n                    };\n                    attrs.borrow_mut().retain(attr_filter);\n                    true\n                } else {\n                    false\n                }\n            }\n        }\n    }\n\n    /// Add and transform special-cased attributes and elements.\n    ///\n    /// This function handles:\n    ///\n    /// * relative URL rewriting\n    /// * adding `<a rel>` attributes\n    /// * filtering out banned classes\n    fn adjust_node_attributes(\n        &self,\n        child: &mut Handle,\n        link_rel: &Option<StrTendril>,\n        url_base: Option<&Url>,\n        id_prefix: Option<&'a str>,\n    ) {\n        if let NodeData::Element {\n            ref name,\n            ref attrs,\n            ..\n        } = child.data\n        {\n            if let Some(set_attrs) = self.set_tag_attribute_values.get(&*name.local) {\n                let mut attrs = attrs.borrow_mut();\n                for (&set_name, &set_value) in set_attrs {\n                    // set the value of the attribute if the attribute is already present\n                    if let Some(attr) = attrs.iter_mut().find(|attr| &*attr.name.local == set_name)\n                    {\n                        if &*attr.value != set_value {\n                            attr.value = set_value.into();\n                        }\n                    } else {\n                        // otherwise, add the attribute\n                        let attr = Attribute {\n                            name: QualName::new(None, ns!(), set_name.into()),\n                            value: set_value.into(),\n                        };\n                        attrs.push(attr);\n                    }\n                }\n            }\n            if let Some(ref link_rel) = *link_rel {\n                if &*name.local == \"a\" {\n                    attrs.borrow_mut().push(Attribute {\n                        name: QualName::new(None, ns!(), local_name!(\"rel\")),\n                        value: link_rel.clone(),\n                    })\n                }\n            }\n            if let Some(ref id_prefix) = id_prefix {\n                for attr in &mut *attrs.borrow_mut() {\n                    if &attr.name.local == \"id\" {\n                        if !attr.value.starts_with(id_prefix) {\n                            attr.value = format_tendril!(\"{}{}\", id_prefix, attr.value);\n                        }\n                    }\n                }\n            }\n            if let Some(ref attr_filter) = self.attribute_filter {\n                let mut drop_attrs = Vec::new();\n                let mut attrs = attrs.borrow_mut();\n                for (i, attr) in &mut attrs.iter_mut().enumerate() {\n                    let replace_with = if let Some(new) =\n                        attr_filter.filter(&*name.local, &*attr.name.local, &*attr.value)\n                    {\n                        if *new != *attr.value {\n                            Some(format_tendril!(\"{}\", new))\n                        } else {\n                            None // no need to replace the attr if filter returned the same value\n                        }\n                    } else {\n                        drop_attrs.push(i);\n                        None\n                    };\n                    if let Some(replace_with) = replace_with {\n                        attr.value = replace_with;\n                    }\n                }\n                for i in drop_attrs.into_iter().rev() {\n                    attrs.swap_remove(i);\n                }\n            }\n            if let Some(ref base) = url_base {\n                for attr in &mut *attrs.borrow_mut() {\n                    if is_url_attr(&*name.local, &*attr.name.local) {\n                        let url = base\n                            .join(&*attr.value)\n                            .expect(\"invalid URLs should be stripped earlier\");\n                        attr.value = format_tendril!(\"{}\", url);\n                    }\n                }\n            } else if let UrlRelative::Custom(ref evaluate) = self.url_relative {\n                let mut drop_attrs = Vec::new();\n                let mut attrs = attrs.borrow_mut();\n                for (i, attr) in attrs.iter_mut().enumerate() {\n                    if is_url_attr(&*name.local, &*attr.name.local) && is_url_relative(&*attr.value)\n                    {\n                        let new_value = evaluate\n                            .evaluate(&*attr.value)\n                            .as_ref()\n                            .map(Cow::as_ref)\n                            .map(StrTendril::from_str)\n                            .and_then(Result::ok);\n                        if let Some(new_value) = new_value {\n                            attr.value = new_value;\n                        } else {\n                            drop_attrs.push(i);\n                        }\n                    }\n                }\n                // Swap remove scrambles the vector after the current point.\n                // We will not do anything except with items before the current point.\n                // The `rev()` is, as such, necessary for correctness.\n                // We could use regular `remove(usize)` and a forward iterator,\n                // but that's slower.\n                for i in drop_attrs.into_iter().rev() {\n                    attrs.swap_remove(i);\n                }\n            }\n            if let Some(allowed_values) = self.allowed_classes.get(&*name.local) {\n                for attr in &mut *attrs.borrow_mut() {\n                    if &attr.name.local == \"class\" {\n                        let mut classes = vec![];\n                        for class in attr.value.split(' ') {\n                            if allowed_values.contains(class) {\n                                classes.push(class.to_owned());\n                            }\n                        }\n                        attr.value = format_tendril!(\"{}\", classes.join(\" \"));\n                    }\n                }\n            }\n        }\n    }\n\n    /// Initializes an HTML fragment parser.\n    ///\n    /// Ammonia conforms to the HTML5 fragment parsing rules,\n    /// by parsing the given fragment as if it were included in a <div> tag.\n    fn make_parser() -> html::Parser<RcDom> {\n        html::parse_fragment(\n            RcDom::default(),\n            html::ParseOpts::default(),\n            QualName::new(None, ns!(html), local_name!(\"div\")),\n            vec![],\n        )\n    }\n}\n\n/// Given an element name and attribute name, determine if the given attribute contains a URL.\nfn is_url_attr(element: &str, attr: &str) -> bool {\n    attr == \"href\"\n        || attr == \"src\"\n        || (element == \"form\" && attr == \"action\")\n        || (element == \"object\" && attr == \"data\")\n        || ((element == \"button\" || element == \"input\") && attr == \"formaction\")\n        || (element == \"a\" && attr == \"ping\")\n        || (element == \"video\" && attr == \"poster\")\n}\n\nfn is_url_relative(url: &str) -> bool {\n    matches!(\n        Url::parse(url),\n        Err(url::ParseError::RelativeUrlWithoutBase)\n    )\n}\n\n/// Policy for [relative URLs], that is, URLs that do not specify the scheme in full.\n///\n/// This policy kicks in, if set, for any attribute named `src` or `href`,\n/// as well as the `data` attribute of an `object` tag.\n///\n/// [relative URLs]: struct.Builder.html#method.url_relative\n///\n/// # Examples\n///\n/// ## `Deny`\n///\n/// * `<a href=\"test\">` is a file-relative URL, and will be removed\n/// * `<a href=\"/test\">` is a domain-relative URL, and will be removed\n/// * `<a href=\"//example.com/test\">` is a scheme-relative URL, and will be removed\n/// * `<a href=\"http://example.com/test\">` is an absolute URL, and will be kept\n///\n/// ## `PassThrough`\n///\n/// No changes will be made to any URLs, except if a disallowed scheme is used.\n///\n/// ## `RewriteWithBase`\n///\n/// If the base is set to `http://notriddle.com/some-directory/some-file`\n///\n/// * `<a href=\"test\">` will be rewritten to `<a href=\"http://notriddle.com/some-directory/test\">`\n/// * `<a href=\"/test\">` will be rewritten to `<a href=\"http://notriddle.com/test\">`\n/// * `<a href=\"//example.com/test\">` will be rewritten to `<a href=\"http://example.com/test\">`\n/// * `<a href=\"http://example.com/test\">` is an absolute URL, so it will be kept as-is\n///\n/// ## `Custom`\n///\n/// Pass the relative URL to a function.\n/// If it returns `Some(string)`, then that one gets used.\n/// Otherwise, it will remove the attribute (like `Deny` does).\n///\n///     use std::borrow::Cow;\n///     fn is_absolute_path(url: &str) -> bool {\n///         let u = url.as_bytes();\n///         // `//a/b/c` is \"protocol-relative\", meaning \"a\" is a hostname\n///         // `/a/b/c` is an absolute path, and what we want to do stuff to.\n///         u.get(0) == Some(&b'/') && u.get(1) != Some(&b'/')\n///     }\n///     fn evaluate(url: &str) -> Option<Cow<str>> {\n///         if is_absolute_path(url) {\n///             Some(Cow::Owned(String::from(\"/root\") + url))\n///         } else {\n///             Some(Cow::Borrowed(url))\n///         }\n///     }\n///     fn main() {\n///         let a = ammonia::Builder::new()\n///             .url_relative(ammonia::UrlRelative::Custom(Box::new(evaluate)))\n///             .clean(\"<a href=/test/path>fixed</a><a href=path>passed</a><a href=http://google.com/>skipped</a>\")\n///             .to_string();\n///         assert_eq!(a, \"<a href=\\\"/root/test/path\\\" rel=\\\"noopener noreferrer\\\">fixed</a><a href=\\\"path\\\" rel=\\\"noopener noreferrer\\\">passed</a><a href=\\\"http://google.com/\\\" rel=\\\"noopener noreferrer\\\">skipped</a>\");\n///     }\n///\n/// This function is only applied to relative URLs.\n/// To filter all of the URLs,\n/// use the not-yet-implemented Content Security Policy.\npub enum UrlRelative {\n    /// Relative URLs will be completely stripped from the document.\n    Deny,\n    /// Relative URLs will be passed through unchanged.\n    PassThrough,\n    /// Relative URLs will be changed into absolute URLs, based on this base URL.\n    RewriteWithBase(Url),\n    /// Rewrite URLs with a custom function.\n    Custom(Box<dyn UrlRelativeEvaluate>),\n    // Do not allow the user to exhaustively match on UrlRelative,\n    // because we may add new items to it later.\n    #[doc(hidden)]\n    __NonExhaustive,\n}\n\nimpl fmt::Debug for UrlRelative {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match *self {\n            UrlRelative::Deny => write!(f, \"UrlRelative::Deny\"),\n            UrlRelative::PassThrough => write!(f, \"UrlRelative::PassThrough\"),\n            UrlRelative::RewriteWithBase(ref base) => {\n                write!(f, \"UrlRelative::RewriteWithBase({})\", base)\n            }\n            UrlRelative::Custom(_) => write!(f, \"UrlRelative::Custom\"),\n            UrlRelative::__NonExhaustive => unreachable!(),\n        }\n    }\n}\n\n/// Types that implement this trait can be used to convert a relative URL into an absolute URL.\n///\n/// This evaluator is only called when the URL is relative; absolute URLs are not evaluated.\n///\n/// See [`url_relative`][url_relative] for more details.\n///\n/// [url_relative]: struct.Builder.html#method.url_relative\npub trait UrlRelativeEvaluate: Send + Sync {\n    /// Return `None` to remove the attribute. Return `Some(str)` to replace it with a new string.\n    fn evaluate<'a>(&self, _: &'a str) -> Option<Cow<'a, str>>;\n}\nimpl<T> UrlRelativeEvaluate for T\nwhere\n    T: Fn(&str) -> Option<Cow<'_, str>> + Send + Sync,\n{\n    fn evaluate<'a>(&self, url: &'a str) -> Option<Cow<'a, str>> {\n        self(url)\n    }\n}\n\nimpl fmt::Debug for dyn AttributeFilter {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.write_str(\"AttributeFilter\")\n    }\n}\n\n/// Types that implement this trait can be used to remove or rewrite arbitrary attributes.\n///\n/// See [`attribute_filter`][attribute_filter] for more details.\n///\n/// [attribute_filter]: struct.Builder.html#method.attribute_filter\npub trait AttributeFilter: Send + Sync {\n    /// Return `None` to remove the attribute. Return `Some(str)` to replace it with a new string.\n    fn filter<'a>(&self, _: &str, _: &str, _: &'a str) -> Option<Cow<'a, str>>;\n}\n\nimpl<T> AttributeFilter for T\nwhere\n    T: for<'a> Fn(&str, &str, &'a str) -> Option<Cow<'a, str>> + Send + Sync + 'static,\n{\n    fn filter<'a>(&self, element: &str, attribute: &str, value: &'a str) -> Option<Cow<'a, str>> {\n        self(element, attribute, value)\n    }\n}\n\n/// A sanitized HTML document.\n///\n/// The `Document` type is an opaque struct representing an HTML fragment that was sanitized by\n/// `ammonia`. It can be converted to a [`String`] or written to a [`Write`] instance. This allows\n/// users to avoid buffering the serialized representation to a [`String`] when desired.\n///\n/// This type is opaque to insulate the caller from breaking changes in the `html5ever` interface.\n///\n/// Note that this type wraps an `html5ever` DOM tree. `ammonia` does not support streaming, so\n/// the complete fragment needs to be stored in memory during processing. Currently, `Document`\n/// is backed by an [`html5ever::rcdom::Node`] object.\n///\n/// [`String`]: https://doc.rust-lang.org/nightly/std/string/struct.String.html\n/// [`Write`]: https://doc.rust-lang.org/nightly/std/io/trait.Write.html\n/// [`html5ever::rcdom::Node`]: ../markup5ever/rcdom/struct.Node.html\n///\n/// # Examples\n///\n///     use ammonia::Builder;\n///\n///     let input = \"<!-- comments will be stripped -->This is an Ammonia example.\";\n///     let output = \"This is an Ammonia example.\";\n///\n///     let document = Builder::new()\n///         .clean(input);\n///     assert_eq!(document.to_string(), output);\npub struct Document(RcDom);\n\nimpl Document {\n    /// Serializes a `Document` instance to a `String`.\n    ///\n    /// This method returns a [`String`] with the sanitized HTML. This is the simplest way to use\n    /// `ammonia`.\n    ///\n    /// [`String`]: https://doc.rust-lang.org/nightly/std/string/struct.String.html\n    ///\n    /// # Examples\n    ///\n    ///     use ammonia::Builder;\n    ///\n    ///     let input = \"Some <style></style>HTML here\";\n    ///     let output = \"Some HTML here\";\n    ///\n    ///     let document = Builder::new()\n    ///         .clean(input);\n    ///     assert_eq!(document.to_string(), output);\n    pub fn to_string(&self) -> String {\n        let opts = Self::serialize_opts();\n        let mut ret_val = Vec::new();\n        let inner: SerializableHandle = self.0.document.children.borrow()[0].clone().into();\n        serialize(&mut ret_val, &inner, opts)\n            .expect(\"Writing to a string shouldn't fail (expect on OOM)\");\n        String::from_utf8(ret_val).expect(\"html5ever only supports UTF8\")\n    }\n\n    /// Serializes a `Document` instance to a writer.\n    ///\n    /// This method writes the sanitized HTML to a [`Write`] instance, avoiding a buffering step.\n    ///\n    /// To avoid consuming the writer, a mutable reference can be passed, like in the example below.\n    ///\n    /// Note that the in-memory representation of `Document` is larger than the serialized\n    /// `String`.\n    ///\n    /// [`Write`]: https://doc.rust-lang.org/nightly/std/io/trait.Write.html\n    ///\n    /// # Examples\n    ///\n    ///     use ammonia::Builder;\n    ///\n    ///     let input = \"Some <style></style>HTML here\";\n    ///     let expected = b\"Some HTML here\";\n    ///\n    ///     let document = Builder::new()\n    ///         .clean(input);\n    ///\n    ///     let mut sanitized = Vec::new();\n    ///     document.write_to(&mut sanitized)\n    ///         .expect(\"Writing to a string should not fail (except on OOM)\");\n    ///     assert_eq!(sanitized, expected);\n    pub fn write_to<W>(&self, writer: W) -> io::Result<()>\n    where\n        W: io::Write,\n    {\n        let opts = Self::serialize_opts();\n        let inner: SerializableHandle = self.0.document.children.borrow()[0].clone().into();\n        serialize(writer, &inner, opts)\n    }\n\n    /// Exposes the `Document` instance as an [`html5ever::rcdom::Handle`][h].\n    ///\n    /// This method returns the inner object backing the `Document` instance. This allows\n    /// making further changes to the DOM without introducing redundant serialization and\n    /// parsing.\n    ///\n    /// Note that this method should be considered unstable and sits outside of the semver\n    /// stability guarantees. It may change, break, or go away at any time, either because\n    /// of `html5ever` changes or `ammonia` implementation changes.\n    ///\n    /// For this method to be accessible, a `cfg` flag is required. The easiest way is to\n    /// use the `RUSTFLAGS` environment variable:\n    ///\n    /// [h]: ../markup5ever/rcdom/type.Handle.html\n    ///\n    /// ```text\n    /// RUSTFLAGS='--cfg ammonia_unstable' cargo build\n    /// ```\n    ///\n    /// on Unix-like platforms, or\n    ///\n    /// ```text\n    /// set RUSTFLAGS=--cfg ammonia_unstable\n    /// cargo build\n    /// ```\n    ///\n    /// on Windows.\n    ///\n    /// This requirement also applies to crates that transitively depend on crates that use\n    /// this flag.\n    ///\n    /// # Examples\n    ///\n    ///     use ammonia::Builder;\n    ///     use maplit::hashset;\n    ///     use html5ever::serialize::{serialize, SerializeOpts};\n    ///\n    ///     # use std::error::Error;\n    ///     # fn do_main() -> Result<(), Box<Error>> {\n    ///     let input = \"<a>one link</a> and <a>one more</a>\";\n    ///     let expected = \"<a>one more</a> and <a>one link</a>\";\n    ///\n    ///     let document = Builder::new()\n    ///         .link_rel(None)\n    ///         .clean(input);\n    ///\n    ///     let mut node = document.to_dom_node();\n    ///     node.children.borrow_mut().reverse();\n    ///\n    ///     let mut buf = Vec::new();\n    ///     serialize(&mut buf, &node, SerializeOpts::default())?;\n    ///     let output = String::from_utf8(buf)?;\n    ///\n    ///     assert_eq!(output, expected);\n    ///     # Ok(())\n    ///     # }\n    ///     # fn main() { do_main().unwrap() }\n    #[cfg(ammonia_unstable)]\n    pub fn to_dom_node(&self) -> Handle {\n        self.0.document.children.borrow()[0].clone()\n    }\n\n    fn serialize_opts() -> SerializeOpts {\n        SerializeOpts::default()\n    }\n}\n\nimpl Clone for Document {\n    fn clone(&self) -> Self {\n        let parser = Builder::make_parser();\n        let dom = parser.one(&self.to_string()[..]);\n        Document(dom)\n    }\n}\n\nimpl fmt::Display for Document {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(f, \"{}\", self.to_string())\n    }\n}\n\nimpl fmt::Debug for Document {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(f, \"Document({})\", self.to_string())\n    }\n}\n\nimpl From<Document> for String {\n    fn from(document: Document) -> Self {\n        document.to_string()\n    }\n}\n\n#[cfg(test)]\nmod test {\n    use super::*;\n    #[test]\n    fn deeply_nested_whitelisted() {\n        clean(&\"<b>\".repeat(60_000));\n    }\n    #[test]\n    fn deeply_nested_blacklisted() {\n        clean(&\"<b-b>\".repeat(60_000));\n    }\n    #[test]\n    fn deeply_nested_alternating() {\n        clean(&\"<b-b>\".repeat(35_000));\n    }\n    #[test]\n    fn included_angles() {\n        let fragment = \"1 < 2\";\n        let result = clean(fragment);\n        assert_eq!(result, \"1 &lt; 2\");\n    }\n    #[test]\n    fn remove_script() {\n        let fragment = \"an <script>evil()</script> example\";\n        let result = clean(fragment);\n        assert_eq!(result, \"an  example\");\n    }\n    #[test]\n    fn ignore_link() {\n        let fragment = \"a <a href=\\\"http://www.google.com\\\">good</a> example\";\n        let expected = \"a <a href=\\\"http://www.google.com\\\" rel=\\\"noopener noreferrer\\\">\\\n                        good</a> example\";\n        let result = clean(fragment);\n        assert_eq!(result, expected);\n    }\n    #[test]\n    fn remove_unsafe_link() {\n        let fragment = \"an <a onclick=\\\"evil()\\\" href=\\\"http://www.google.com\\\">evil</a> example\";\n        let result = clean(fragment);\n        assert_eq!(\n            result,\n            \"an <a href=\\\"http://www.google.com\\\" rel=\\\"noopener noreferrer\\\">evil</a> example\"\n        );\n    }\n    #[test]\n    fn remove_js_link() {\n        let fragment = \"an <a href=\\\"javascript:evil()\\\">evil</a> example\";\n        let result = clean(fragment);\n        assert_eq!(result, \"an <a rel=\\\"noopener noreferrer\\\">evil</a> example\");\n    }\n    #[test]\n    fn tag_rebalance() {\n        let fragment = \"<b>AWESOME!\";\n        let result = clean(fragment);\n        assert_eq!(result, \"<b>AWESOME!</b>\");\n    }\n    #[test]\n    fn allow_url_relative() {\n        let fragment = \"<a href=test>Test</a>\";\n        let result = Builder::new()\n            .url_relative(UrlRelative::PassThrough)\n            .clean(fragment)\n            .to_string();\n        assert_eq!(\n            result,\n            \"<a href=\\\"test\\\" rel=\\\"noopener noreferrer\\\">Test</a>\"\n        );\n    }\n    #[test]\n    fn rewrite_url_relative() {\n        let fragment = \"<a href=test>Test</a>\";\n        let result = Builder::new()\n            .url_relative(UrlRelative::RewriteWithBase(\n                Url::parse(\"http://example.com/\").unwrap(),\n            ))\n            .clean(fragment)\n            .to_string();\n        assert_eq!(\n            result,\n            \"<a href=\\\"http://example.com/test\\\" rel=\\\"noopener noreferrer\\\">Test</a>\"\n        );\n    }\n    #[test]\n    fn rewrite_url_relative_with_invalid_url() {\n        // Reduced from https://github.com/Bauke/ammonia-crash-test\n        let fragment = r##\"<a href=\"\\\\\"https://example.com\\\\\"\">test</a>\"##;\n        let result = Builder::new()\n            .url_relative(UrlRelative::RewriteWithBase(\n                Url::parse(\"http://example.com/\").unwrap(),\n            ))\n            .clean(fragment)\n            .to_string();\n        assert_eq!(result, r##\"<a rel=\"noopener noreferrer\">test</a>\"##);\n    }\n    #[test]\n    fn attribute_filter_nop() {\n        let fragment = \"<a href=test>Test</a>\";\n        let result = Builder::new()\n            .attribute_filter(|elem, attr, value| {\n                assert_eq!(\"a\", elem);\n                assert!(\n                    match (attr, value) {\n                        (\"href\", \"test\") => true,\n                        (\"rel\", \"noopener noreferrer\") => true,\n                        _ => false,\n                    },\n                    \"{}\", value.to_string()\n                );\n                Some(value.into())\n            })\n            .clean(fragment)\n            .to_string();\n        assert_eq!(\n            result,\n            \"<a href=\\\"test\\\" rel=\\\"noopener noreferrer\\\">Test</a>\"\n        );\n    }\n\n    #[test]\n    fn attribute_filter_drop() {\n        let fragment = \"Test<img alt=test src=imgtest>\";\n        let result = Builder::new()\n            .attribute_filter(|elem, attr, value| {\n                assert_eq!(\"img\", elem);\n                match (attr, value) {\n                    (\"src\", \"imgtest\") => None,\n                    (\"alt\", \"test\") => Some(value.into()),\n                    _ => panic!(\"unexpected\"),\n                }\n            })\n            .clean(fragment)\n            .to_string();\n        assert_eq!(result, r#\"Test<img alt=\"test\">\"#);\n    }\n\n    #[test]\n    fn url_filter_absolute() {\n        let fragment = \"Test<img alt=test src=imgtest>\";\n        let result = Builder::new()\n            .attribute_filter(|elem, attr, value| {\n                assert_eq!(\"img\", elem);\n                match (attr, value) {\n                    (\"src\", \"imgtest\") => {\n                        Some(format!(\"https://example.com/images/{}\", value).into())\n                    }\n                    (\"alt\", \"test\") => None,\n                    _ => panic!(\"unexpected\"),\n                }\n            })\n            .url_relative(UrlRelative::RewriteWithBase(\n                Url::parse(\"http://wrong.invalid/\").unwrap(),\n            ))\n            .clean(fragment)\n            .to_string();\n        assert_eq!(\n            result,\n            r#\"Test<img src=\"https://example.com/images/imgtest\">\"#\n        );\n    }\n\n    #[test]\n    fn url_filter_relative() {\n        let fragment = \"Test<img alt=test src=imgtest>\";\n        let result = Builder::new()\n            .attribute_filter(|elem, attr, value| {\n                assert_eq!(\"img\", elem);\n                match (attr, value) {\n                    (\"src\", \"imgtest\") => Some(\"rewrite\".into()),\n                    (\"alt\", \"test\") => Some(\"altalt\".into()),\n                    _ => panic!(\"unexpected\"),\n                }\n            })\n            .url_relative(UrlRelative::RewriteWithBase(\n                Url::parse(\"https://example.com/base/#\").unwrap(),\n            ))\n            .clean(fragment)\n            .to_string();\n        assert_eq!(\n            result,\n            r#\"Test<img alt=\"altalt\" src=\"https://example.com/base/rewrite\">\"#\n        );\n    }\n\n    #[test]\n    fn rewrite_url_relative_no_rel() {\n        let fragment = \"<a href=test>Test</a>\";\n        let result = Builder::new()\n            .url_relative(UrlRelative::RewriteWithBase(\n                Url::parse(\"http://example.com/\").unwrap(),\n            ))\n            .link_rel(None)\n            .clean(fragment)\n            .to_string();\n        assert_eq!(result, \"<a href=\\\"http://example.com/test\\\">Test</a>\");\n    }\n    #[test]\n    fn deny_url_relative() {\n        let fragment = \"<a href=test>Test</a>\";\n        let result = Builder::new()\n            .url_relative(UrlRelative::Deny)\n            .clean(fragment)\n            .to_string();\n        assert_eq!(result, \"<a rel=\\\"noopener noreferrer\\\">Test</a>\");\n    }\n    #[test]\n    fn replace_rel() {\n        let fragment = \"<a href=test rel=\\\"garbage\\\">Test</a>\";\n        let result = Builder::new()\n            .url_relative(UrlRelative::PassThrough)\n            .clean(fragment)\n            .to_string();\n        assert_eq!(\n            result,\n            \"<a href=\\\"test\\\" rel=\\\"noopener noreferrer\\\">Test</a>\"\n        );\n    }\n    #[test]\n    fn consider_rel_still_banned() {\n        let fragment = \"<a href=test rel=\\\"garbage\\\">Test</a>\";\n        let result = Builder::new()\n            .url_relative(UrlRelative::PassThrough)\n            .link_rel(None)\n            .clean(fragment)\n            .to_string();\n        assert_eq!(result, \"<a href=\\\"test\\\">Test</a>\");\n    }\n    #[test]\n    fn object_data() {\n        let fragment = \"<span data=\\\"javascript:evil()\\\">Test</span>\\\n                        <object data=\\\"javascript:evil()\\\"></object>M\";\n        let expected = r#\"<span data=\"javascript:evil()\">Test</span><object></object>M\"#;\n        let result = Builder::new()\n            .tags(hashset![\"span\", \"object\"])\n            .generic_attributes(hashset![\"data\"])\n            .clean(fragment)\n            .to_string();\n        assert_eq!(result, expected);\n    }\n    #[test]\n    fn remove_attributes() {\n        let fragment = \"<table border=\\\"1\\\"><tr></tr></table>\";\n        let result = Builder::new().clean(fragment);\n        assert_eq!(\n            result.to_string(),\n            \"<table><tbody><tr></tr></tbody></table>\"\n        );\n    }\n    #[test]\n    fn quotes_in_attrs() {\n        let fragment = \"<b title='\\\"'>contents</b>\";\n        let result = clean(fragment);\n        assert_eq!(result, \"<b title=\\\"&quot;\\\">contents</b>\");\n    }\n    #[test]\n    #[should_panic]\n    fn panic_if_rel_is_allowed_and_replaced_generic() {\n        Builder::new()\n            .link_rel(Some(\"noopener noreferrer\"))\n            .generic_attributes(hashset![\"rel\"])\n            .clean(\"something\");\n    }\n    #[test]\n    #[should_panic]\n    fn panic_if_rel_is_allowed_and_replaced_a() {\n        Builder::new()\n            .link_rel(Some(\"noopener noreferrer\"))\n            .tag_attributes(hashmap![\n                \"a\" => hashset![\"rel\"],\n            ])\n            .clean(\"something\");\n    }\n    #[test]\n    fn no_panic_if_rel_is_allowed_and_replaced_span() {\n        Builder::new()\n            .link_rel(Some(\"noopener noreferrer\"))\n            .tag_attributes(hashmap![\n                \"span\" => hashset![\"rel\"],\n            ])\n            .clean(\"<span rel=\\\"what\\\">s</span>\");\n    }\n    #[test]\n    fn no_panic_if_rel_is_allowed_and_not_replaced_generic() {\n        Builder::new()\n            .link_rel(None)\n            .generic_attributes(hashset![\"rel\"])\n            .clean(\"<a rel=\\\"what\\\">s</a>\");\n    }\n    #[test]\n    fn no_panic_if_rel_is_allowed_and_not_replaced_a() {\n        Builder::new()\n            .link_rel(None)\n            .tag_attributes(hashmap![\n                \"a\" => hashset![\"rel\"],\n            ])\n            .clean(\"<a rel=\\\"what\\\">s</a>\");\n    }\n    #[test]\n    fn dont_close_void_elements() {\n        let fragment = \"<br>\";\n        let result = clean(fragment);\n        assert_eq!(result.to_string(), \"<br>\");\n    }\n    #[should_panic]\n    #[test]\n    fn panic_on_allowed_classes_tag_attributes() {\n        let fragment = \"<p class=\\\"foo bar\\\"><a class=\\\"baz bleh\\\">Hey</a></p>\";\n        Builder::new()\n            .link_rel(None)\n            .tag_attributes(hashmap![\n                \"p\" => hashset![\"class\"],\n                \"a\" => hashset![\"class\"],\n            ])\n            .allowed_classes(hashmap![\n                \"p\" => hashset![\"foo\", \"bar\"],\n                \"a\" => hashset![\"baz\"],\n            ])\n            .clean(fragment);\n    }\n    #[should_panic]\n    #[test]\n    fn panic_on_allowed_classes_generic_attributes() {\n        let fragment = \"<p class=\\\"foo bar\\\"><a class=\\\"baz bleh\\\">Hey</a></p>\";\n        Builder::new()\n            .link_rel(None)\n            .generic_attributes(hashset![\"class\", \"href\", \"some-foo\"])\n            .allowed_classes(hashmap![\n                \"p\" => hashset![\"foo\", \"bar\"],\n                \"a\" => hashset![\"baz\"],\n            ])\n            .clean(fragment);\n    }\n    #[test]\n    fn remove_non_allowed_classes() {\n        let fragment = \"<p class=\\\"foo bar\\\"><a class=\\\"baz bleh\\\">Hey</a></p>\";\n        let result = Builder::new()\n            .link_rel(None)\n            .allowed_classes(hashmap![\n                \"p\" => hashset![\"foo\", \"bar\"],\n                \"a\" => hashset![\"baz\"],\n            ])\n            .clean(fragment);\n        assert_eq!(\n            result.to_string(),\n            \"<p class=\\\"foo bar\\\"><a class=\\\"baz\\\">Hey</a></p>\"\n        );\n    }\n    #[test]\n    fn remove_non_allowed_classes_with_tag_class() {\n        let fragment = \"<p class=\\\"foo bar\\\"><a class=\\\"baz bleh\\\">Hey</a></p>\";\n        let result = Builder::new()\n            .link_rel(None)\n            .tag_attributes(hashmap![\n                \"div\" => hashset![\"class\"],\n            ])\n            .allowed_classes(hashmap![\n                \"p\" => hashset![\"foo\", \"bar\"],\n                \"a\" => hashset![\"baz\"],\n            ])\n            .clean(fragment);\n        assert_eq!(\n            result.to_string(),\n            \"<p class=\\\"foo bar\\\"><a class=\\\"baz\\\">Hey</a></p>\"\n        );\n    }\n    #[test]\n    fn remove_non_allowed_attributes_with_tag_attribute_values() {\n        let fragment = \"<p data-label=\\\"baz\\\" name=\\\"foo\\\"></p>\";\n        let result = Builder::new()\n            .tag_attribute_values(hashmap![\n                \"p\" => hashmap![\n                    \"data-label\" => hashset![\"bar\"],\n                ],\n            ])\n            .tag_attributes(hashmap![\n                \"p\" => hashset![\"name\"],\n            ])\n            .clean(fragment);\n        assert_eq!(result.to_string(), \"<p name=\\\"foo\\\"></p>\",);\n    }\n    #[test]\n    fn keep_allowed_attributes_with_tag_attribute_values() {\n        let fragment = \"<p data-label=\\\"bar\\\" name=\\\"foo\\\"></p>\";\n        let result = Builder::new()\n            .tag_attribute_values(hashmap![\n                \"p\" => hashmap![\n                    \"data-label\" => hashset![\"bar\"],\n                ],\n            ])\n            .tag_attributes(hashmap![\n                \"p\" => hashset![\"name\"],\n            ])\n            .clean(fragment);\n        assert_eq!(\n            result.to_string(),\n            \"<p data-label=\\\"bar\\\" name=\\\"foo\\\"></p>\",\n        );\n    }\n    #[test]\n    fn tag_attribute_values_case_insensitive() {\n        let fragment = \"<input type=\\\"CHECKBOX\\\" name=\\\"foo\\\">\";\n        let result = Builder::new()\n            .tags(hashset![\"input\"])\n            .tag_attribute_values(hashmap![\n                \"input\" => hashmap![\n                    \"type\" => hashset![\"checkbox\"],\n                ],\n            ])\n            .tag_attributes(hashmap![\n                \"input\" => hashset![\"name\"],\n            ])\n            .clean(fragment);\n        assert_eq!(result.to_string(), \"<input type=\\\"CHECKBOX\\\" name=\\\"foo\\\">\",);\n    }\n    #[test]\n    fn set_tag_attribute_values() {\n        let fragment = \"<a href=\\\"https://example.com/\\\">Link</a>\";\n        let result = Builder::new()\n            .link_rel(None)\n            .add_tag_attributes(\"a\", &[\"target\"])\n            .set_tag_attribute_value(\"a\", \"target\", \"_blank\")\n            .clean(fragment);\n        assert_eq!(\n            result.to_string(),\n            \"<a href=\\\"https://example.com/\\\" target=\\\"_blank\\\">Link</a>\",\n        );\n    }\n    #[test]\n    fn update_existing_set_tag_attribute_values() {\n        let fragment = \"<a target=\\\"bad\\\" href=\\\"https://example.com/\\\">Link</a>\";\n        let result = Builder::new()\n            .link_rel(None)\n            .add_tag_attributes(\"a\", &[\"target\"])\n            .set_tag_attribute_value(\"a\", \"target\", \"_blank\")\n            .clean(fragment);\n        assert_eq!(\n            result.to_string(),\n            \"<a target=\\\"_blank\\\" href=\\\"https://example.com/\\\">Link</a>\",\n        );\n    }\n    #[test]\n    fn unwhitelisted_set_tag_attribute_values() {\n        let fragment = \"<span>hi</span><my-elem>\";\n        let result = Builder::new()\n            .set_tag_attribute_value(\"my-elem\", \"my-attr\", \"val\")\n            .clean(fragment);\n        assert_eq!(result.to_string(), \"<span>hi</span>\",);\n    }\n    #[test]\n    fn remove_entity_link() {\n        let fragment = \"<a href=\\\"&#x6A&#x61&#x76&#x61&#x73&#x63&#x72&#x69&#x70&#x74&#x3A&#x61\\\n                        &#x6C&#x65&#x72&#x74&#x28&#x27&#x58&#x53&#x53&#x27&#x29\\\">Click me!</a>\";\n        let result = clean(fragment);\n        assert_eq!(\n            result.to_string(),\n            \"<a rel=\\\"noopener noreferrer\\\">Click me!</a>\"\n        );\n    }\n    #[test]\n    fn remove_relative_url_evaluate() {\n        fn is_absolute_path(url: &str) -> bool {\n            let u = url.as_bytes();\n            // `//a/b/c` is \"protocol-relative\", meaning \"a\" is a hostname\n            // `/a/b/c` is an absolute path, and what we want to do stuff to.\n            u.get(0) == Some(&b'/') && u.get(1) != Some(&b'/')\n        }\n        fn is_banned(url: &str) -> bool {\n            let u = url.as_bytes();\n            u.get(0) == Some(&b'b') && u.get(1) == Some(&b'a')\n        }\n        fn evaluate(url: &str) -> Option<Cow<'_, str>> {\n            if is_absolute_path(url) {\n                Some(Cow::Owned(String::from(\"/root\") + url))\n            } else if is_banned(url) {\n                None\n            } else {\n                Some(Cow::Borrowed(url))\n            }\n        }\n        let a = Builder::new()\n            .url_relative(UrlRelative::Custom(Box::new(evaluate)))\n            .clean(\"<a href=banned>banned</a><a href=/test/path>fixed</a><a href=path>passed</a><a href=http://google.com/>skipped</a>\")\n            .to_string();\n        assert_eq!(a, \"<a rel=\\\"noopener noreferrer\\\">banned</a><a href=\\\"/root/test/path\\\" rel=\\\"noopener noreferrer\\\">fixed</a><a href=\\\"path\\\" rel=\\\"noopener noreferrer\\\">passed</a><a href=\\\"http://google.com/\\\" rel=\\\"noopener noreferrer\\\">skipped</a>\");\n    }\n    #[test]\n    fn remove_relative_url_evaluate_b() {\n        fn is_absolute_path(url: &str) -> bool {\n            let u = url.as_bytes();\n            // `//a/b/c` is \"protocol-relative\", meaning \"a\" is a hostname\n            // `/a/b/c` is an absolute path, and what we want to do stuff to.\n            u.get(0) == Some(&b'/') && u.get(1) != Some(&b'/')\n        }\n        fn is_banned(url: &str) -> bool {\n            let u = url.as_bytes();\n            u.get(0) == Some(&b'b') && u.get(1) == Some(&b'a')\n        }\n        fn evaluate(url: &str) -> Option<Cow<'_, str>> {\n            if is_absolute_path(url) {\n                Some(Cow::Owned(String::from(\"/root\") + url))\n            } else if is_banned(url) {\n                None\n            } else {\n                Some(Cow::Borrowed(url))\n            }\n        }\n        let a = Builder::new()\n            .url_relative(UrlRelative::Custom(Box::new(evaluate)))\n            .clean(\"<a href=banned>banned</a><a href=banned title=test>banned</a><a title=test href=banned>banned</a>\")\n            .to_string();\n        assert_eq!(a, \"<a rel=\\\"noopener noreferrer\\\">banned</a><a rel=\\\"noopener noreferrer\\\" title=\\\"test\\\">banned</a><a title=\\\"test\\\" rel=\\\"noopener noreferrer\\\">banned</a>\");\n    }\n    #[test]\n    fn remove_relative_url_evaluate_c() {\n        // Don't run on absolute URLs.\n        fn evaluate(_: &str) -> Option<Cow<'_, str>> {\n            return Some(Cow::Owned(String::from(\"invalid\")));\n        }\n        let a = Builder::new()\n            .url_relative(UrlRelative::Custom(Box::new(evaluate)))\n            .clean(\"<a href=\\\"https://www.google.com/\\\">google</a>\")\n            .to_string();\n        assert_eq!(\n            a,\n            \"<a href=\\\"https://www.google.com/\\\" rel=\\\"noopener noreferrer\\\">google</a>\"\n        );\n    }\n    #[test]\n    fn clean_children_of_bad_element() {\n        let fragment = \"<bad><evil>a</evil>b</bad>\";\n        let result = Builder::new().clean(fragment);\n        assert_eq!(result.to_string(), \"ab\");\n    }\n    #[test]\n    fn reader_input() {\n        let fragment = b\"an <script>evil()</script> example\";\n        let result = Builder::new().clean_from_reader(&fragment[..]);\n        assert!(result.is_ok());\n        assert_eq!(result.unwrap().to_string(), \"an  example\");\n    }\n    #[test]\n    fn reader_non_utf8() {\n        let fragment = b\"non-utf8 \\xF0\\x90\\x80string\";\n        let result = Builder::new().clean_from_reader(&fragment[..]);\n        assert!(result.is_ok());\n        assert_eq!(result.unwrap().to_string(), \"non-utf8 \\u{fffd}string\");\n    }\n    #[test]\n    fn display_impl() {\n        let fragment = r#\"a <a>link</a>\"#;\n        let result = Builder::new().link_rel(None).clean(fragment);\n        assert_eq!(format!(\"{}\", result), \"a <a>link</a>\");\n    }\n    #[test]\n    fn debug_impl() {\n        let fragment = r#\"a <a>link</a>\"#;\n        let result = Builder::new().link_rel(None).clean(fragment);\n        assert_eq!(format!(\"{:?}\", result), \"Document(a <a>link</a>)\");\n    }\n    #[cfg(ammonia_unstable)]\n    #[test]\n    fn to_dom_node() {\n        let fragment = r#\"a <a>link</a>\"#;\n        let result = Builder::new().link_rel(None).clean(fragment);\n        let _node = result.to_dom_node();\n    }\n    #[test]\n    fn string_from_document() {\n        let fragment = r#\"a <a>link\"#;\n        let result = String::from(Builder::new().link_rel(None).clean(fragment));\n        assert_eq!(format!(\"{}\", result), \"a <a>link</a>\");\n    }\n    fn require_sync<T: Sync>(_: T) {}\n    fn require_send<T: Send>(_: T) {}\n    #[test]\n    fn require_sync_and_send() {\n        require_sync(Builder::new());\n        require_send(Builder::new());\n    }\n    #[test]\n    fn id_prefixed() {\n        let fragment = \"<a id=\\\"hello\\\"></a><b id=\\\"hello\\\"></a>\";\n        let result = String::from(\n            Builder::new()\n                .tag_attributes(hashmap![\n                    \"a\" => hashset![\"id\"],\n                ])\n                .id_prefix(Some(\"prefix-\"))\n                .clean(fragment),\n        );\n        assert_eq!(\n            result.to_string(),\n            \"<a id=\\\"prefix-hello\\\" rel=\\\"noopener noreferrer\\\"></a><b></b>\"\n        );\n    }\n    #[test]\n    fn id_already_prefixed() {\n        let fragment = \"<a id=\\\"prefix-hello\\\"></a>\";\n        let result = String::from(\n            Builder::new()\n                .tag_attributes(hashmap![\n                    \"a\" => hashset![\"id\"],\n                ])\n                .id_prefix(Some(\"prefix-\"))\n                .clean(fragment),\n        );\n        assert_eq!(\n            result.to_string(),\n            \"<a id=\\\"prefix-hello\\\" rel=\\\"noopener noreferrer\\\"></a>\"\n        );\n    }\n    #[test]\n    fn clean_content_tags() {\n        let fragment = \"<script type=\\\"text/javascript\\\"><a>Hello!</a></script>\";\n        let result = String::from(\n            Builder::new()\n                .clean_content_tags(hashset![\"script\"])\n                .clean(fragment),\n        );\n        assert_eq!(result.to_string(), \"\");\n    }\n    #[test]\n    fn only_clean_content_tags() {\n        let fragment = \"<em>This is</em><script><a>Hello!</a></script><p>still here!</p>\";\n        let result = String::from(\n            Builder::new()\n                .clean_content_tags(hashset![\"script\"])\n                .clean(fragment),\n        );\n        assert_eq!(result.to_string(), \"<em>This is</em><p>still here!</p>\");\n    }\n    #[test]\n    fn clean_removed_default_tag() {\n        let fragment = \"<em>This is</em><script><a>Hello!</a></script><p>still here!</p>\";\n        let result = String::from(\n            Builder::new()\n                .rm_tags(hashset![\"a\"])\n                .rm_tag_attributes(\"a\", hashset![\"href\", \"hreflang\"])\n                .clean_content_tags(hashset![\"script\"])\n                .clean(fragment),\n        );\n        assert_eq!(result.to_string(), \"<em>This is</em><p>still here!</p>\");\n    }\n    #[test]\n    #[should_panic]\n    fn panic_on_clean_content_tag_attribute() {\n        Builder::new()\n            .rm_tags(std::iter::once(\"a\"))\n            .clean_content_tags(hashset![\"a\"])\n            .clean(\"\");\n    }\n    #[test]\n    #[should_panic]\n    fn panic_on_clean_content_tag() {\n        Builder::new().clean_content_tags(hashset![\"a\"]).clean(\"\");\n    }\n\n    #[test]\n    fn clean_text_test() {\n        assert_eq!(\n            clean_text(\"<this> is <a test function\"),\n            \"&lt;this&gt;&#32;is&#32;&lt;a&#32;test&#32;function\"\n        );\n    }\n\n    #[test]\n    fn generic_attribute_prefixes() {\n        let prefix_data = [\"data-\"];\n        let prefix_code = [\"code-\"];\n        let mut b = Builder::new();\n        let mut hs: HashSet<&'_ str> = HashSet::new();\n        hs.insert(\"data-\");\n        assert_eq!(b.generic_attribute_prefixes.is_none(), true);\n        b.generic_attribute_prefixes(hs);\n        assert_eq!(b.generic_attribute_prefixes.is_some(), true);\n        assert_eq!(b.generic_attribute_prefixes.as_ref().unwrap().len(), 1);\n        b.add_generic_attribute_prefixes(&prefix_data);\n        assert_eq!(b.generic_attribute_prefixes.as_ref().unwrap().len(), 1);\n        b.add_generic_attribute_prefixes(&prefix_code);\n        assert_eq!(b.generic_attribute_prefixes.as_ref().unwrap().len(), 2);\n        b.rm_generic_attribute_prefixes(&prefix_code);\n        assert_eq!(b.generic_attribute_prefixes.as_ref().unwrap().len(), 1);\n        b.rm_generic_attribute_prefixes(&prefix_code);\n        assert_eq!(b.generic_attribute_prefixes.as_ref().unwrap().len(), 1);\n        b.rm_generic_attribute_prefixes(&prefix_data);\n        assert_eq!(b.generic_attribute_prefixes.is_none(), true);\n    }\n\n    #[test]\n    fn generic_attribute_prefixes_clean() {\n        let fragment = r#\"<a data-1 data-2 code-1 code-2><a>Hello!</a></a>\"#;\n        let result_cleaned = String::from(\n            Builder::new()\n                .add_tag_attributes(\"a\", &[\"data-1\"])\n                .clean(fragment),\n        );\n        assert_eq!(\n            result_cleaned,\n            r#\"<a data-1=\"\" rel=\"noopener noreferrer\"></a><a rel=\"noopener noreferrer\">Hello!</a>\"#\n        );\n        let result_allowed = String::from(\n            Builder::new()\n                .add_tag_attributes(\"a\", &[\"data-1\"])\n                .add_generic_attribute_prefixes(&[\"data-\"])\n                .clean(fragment),\n        );\n        assert_eq!(\n            result_allowed,\n            r#\"<a data-1=\"\" data-2=\"\" rel=\"noopener noreferrer\"></a><a rel=\"noopener noreferrer\">Hello!</a>\"#\n        );\n        let result_allowed = String::from(\n            Builder::new()\n                .add_tag_attributes(\"a\", &[\"data-1\", \"code-1\"])\n                .add_generic_attribute_prefixes(&[\"data-\", \"code-\"])\n                .clean(fragment),\n        );\n        assert_eq!(\n            result_allowed,\n            r#\"<a data-1=\"\" data-2=\"\" code-1=\"\" code-2=\"\" rel=\"noopener noreferrer\"></a><a rel=\"noopener noreferrer\">Hello!</a>\"#\n        );\n    }\n    #[test]\n    fn lesser_than_isnt_html() {\n        let fragment = \"1 < 2\";\n        assert!(!is_html(fragment));\n    }\n    #[test]\n    fn dense_lesser_than_isnt_html() {\n        let fragment = \"1<2\";\n        assert!(!is_html(fragment));\n    }\n    #[test]\n    fn what_about_number_elements() {\n        let fragment = \"foo<2>bar\";\n        assert!(!is_html(fragment));\n    }\n    #[test]\n    fn turbofish_is_html_sadly() {\n        let fragment = \"Vec::<u8>::new()\";\n        assert!(is_html(fragment));\n    }\n    #[test]\n    fn stop_grinning() {\n        let fragment = \"did you really believe me? <g>\";\n        assert!(is_html(fragment));\n    }\n    #[test]\n    fn dont_be_bold() {\n        let fragment = \"<b>\";\n        assert!(is_html(fragment));\n    }\n}\n"
  },
  {
    "project": "rustracts",
    "target": 1,
    "commit_id": "c15541d7968aea40d06dadd5e2c5cb57b4d6d341",
    "func": "//! This crate exposes [`ParentArc<T>`](struct.ParentArc.html) which is comparable to an\n//! [`Arc<T>`](https://doc.rust-lang.org/std/sync/struct.Arc.html) but \"strong\" references cannot\n//! be cloned which allows the `ParentArc<T>` to lock its weak references and block until all\n//! strong references are dropped. Once it is the only reference it can be consummed safely.\n//!\n//! This crate is compatible with\n//! [`#![no_std]`](https://rust-embedded.github.io/book/intro/no-std.html) environnements that\n//! provide an allocator.\n\n#![no_std]\n#![deny(missing_docs)]\n\n#[cfg(not(feature = \"std\"))]\nmod imports {\n    extern crate alloc;\n    pub(super) use alloc::boxed::Box;\n}\n\n#[cfg(feature = \"std\")]\nmod imports {\n    extern crate std;\n    pub(super) use std::boxed::Box;\n    pub(super) use std::fmt;\n}\n\nuse imports::*;\n\nuse core::mem;\nuse core::ops;\nuse core::pin::Pin;\nuse core::ptr;\nuse core::ptr::NonNull;\nuse core::sync::atomic::{AtomicBool, AtomicUsize, Ordering};\n\n/// Result Type for [`try_into_inner`]\n///\n/// [`try_into_inner`]: struct.ParentArc.html#method.try_into_inner\npub type TryUnwrapResult<T> = Result<T, TryUnwrapError<T>>;\n\n/// Errors for [`TryArcResult`](type.TryUnwrapResult.html)\npub enum TryUnwrapError<T> {\n    /// Would have locked the Temp references\n    WouldLock(ParentArc<T>),\n\n    /// Would have blocked becasue there is still a [`ChildArc`](struct.ChildArc.html) reference\n    WouldBlock(ParentArc<T>),\n}\n\n#[cfg(feature = \"std\")]\nimpl<T> fmt::Debug for TryUnwrapError<T> {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        match self {\n            TryUnwrapError::WouldLock(_) => write!(f, \"WouldLock(...)\"),\n            TryUnwrapError::WouldBlock(_) => write!(f, \"WouldBlock(...)\"),\n        }\n    }\n}\n\n/// Owner of multiple atomically reference counted children.\n///\n/// The type `ParentArc<T>` allows for shared access of the inner data by multiple threads through LockWeak references.\n/// Call downgrade on a `ParentArc` to create a child reference that can be upgraded into a\n/// temporary reader of the inner data. This allows for the locking and the consumption of the\n/// parent at any time because no strong references are held permanently.\n///\n/// Unlike [`Arc<T>`](https://doc.rust-lang.org/std/sync/struct.Arc.html) this structure will die\n/// along with it's readers.\n///\n/// # Thread Safety\n/// The [`LockWeak`](struct.LockWeak) can be passed around through threads safely because they do\n/// not guaranty the existence of the data at upgrade time.\n/// `ParentArc<T>` makes it thread safe to have multiple owned reference of the same data, but it doesn't add thread safety to its data.\npub struct ParentArc<T> {\n    ptr: NonNull<Womb<T>>,\n}\n\nimpl<T> ParentArc<T> {\n    /// Build a new [`ParentArc`](struct.ParentArc.html)\n    ///\n    /// # Examples\n    /// ```rust\n    /// use parc::ParentArc;\n    /// use std::sync::Mutex;\n    /// fn main() {\n    ///     let parent = ParentArc::new(Mutex::new(true));\n    /// }\n    /// ```\n    pub fn new(data: T) -> Self {\n        Self {\n            ptr: Womb::as_nnptr(data),\n        }\n    }\n\n    /// Constructs a new `Pin<ParentArc<T>>`. If `T` does not implement `Unpin`, then\n    /// `data` will be pinned in memory and unable to be moved.\n    pub fn pin(data: T) -> Pin<ParentArc<T>> {\n        unsafe { Pin::new_unchecked(ParentArc::new(data)) }\n    }\n\n    /// Locks all [`LockWeak`](struct.LockWeak.html) of this instance, it\n    /// will prevent all further upgrades until [`unlocked`]. It is advised to call this before\n    /// attempting a [`try_into_inner`].\n    ///\n    /// [`unlocked`]: #method.unlock\n    /// [`try_into_inner`]: #method.try_into_inner\n    ///\n    /// # Examples\n    /// ```rust\n    /// use parc::ParentArc;\n    /// use std::sync::Mutex;\n    /// fn main() {\n    ///     let parent = ParentArc::new(Mutex::new(0));\n    ///     parent.lock(); // LockWeaks are no longer able to upgrade successfully\n    ///     assert!(parent.is_locked());\n    /// }\n    /// ```\n    pub fn lock(&self) {\n        let lock = &self.inner().lock;\n        while lock.compare_and_swap(false, true, Ordering::Release) {}\n    }\n\n    /// Check wether the [`LockWeak`](struct.LockWeak.html)s are locked. Since only the Parent can\n    /// unlock it is considered a somewhat trustable result.\n    pub fn is_locked(&self) -> bool {\n        self.inner().lock.load(Ordering::Relaxed)\n    }\n\n    /// Unlocks all [`LockWeak`](struct.LockWeak.html) of this [`ParentArc`](struct.ParentArc.html),\n    /// this allows for their ugrade to start again.\n    ///\n    /// # Examples\n    /// ```rust\n    /// use parc::ParentArc;\n    /// use std::sync::Mutex;\n    /// fn main() {\n    ///     let parent = ParentArc::new(Mutex::new(0));\n    ///     \n    ///     parent.lock(); // LockWeaks are no longer able to upgrade successfully\n    ///     assert!(parent.is_locked());\n    ///     \n    ///     parent.unlock(); // LockWeaks can upgrade successfully again\n    ///     assert!(!parent.is_locked());\n    /// }\n    /// ```\n    pub fn unlock(&self) {\n        let lock = &self.inner().lock;\n        while lock.compare_and_swap(true, false, Ordering::Release) {}\n    }\n\n    /// Downgrade a [`ParentArc`](struct.ParentArc.html) into a [`LockWeak`](struct.LockWeak.html)\n    ///\n    /// # Examples\n    /// ```rust\n    /// use parc::{ParentArc, LockWeak};\n    /// use std::sync::Mutex;\n    /// fn main() {\n    ///     let parent = ParentArc::new(Mutex::new(true));\n    ///     let weak: LockWeak<_> = ParentArc::downgrade(&parent);\n    /// }\n    /// ```\n    pub fn downgrade(other: &Self) -> LockWeak<T> {\n        LockWeak { ptr: other.ptr }\n    }\n\n    /// Tries to downgrade a [`ParentArc`](struct.ParentArc.html) into a [`LockWeak`](struct.LockWeak.html) if the inner state allows the latter to upgrade.\n    ///\n    /// # Examples\n    /// ```rust\n    /// use parc::{ParentArc, LockWeak};\n    /// use std::sync::Mutex;\n    /// fn main() {\n    ///     let parent = ParentArc::new(Mutex::new(true));\n    ///     parent.lock(); // LockWeaks are no longer able to upgrade successfully\n    ///     \n    ///     if let Some(_) = ParentArc::try_downgrade(&parent) {\n    ///         assert!(false);\n    ///     }\n    /// }\n    /// ```\n    pub fn try_downgrade(other: &Self) -> Option<LockWeak<T>> {\n        if other.inner().lock.load(Ordering::Relaxed) {\n            return None;\n        }\n        Some(LockWeak { ptr: other.ptr })\n    }\n\n    /// Blocks the thread until all [`ChildArc`](struct.ChildArc.html) of this instance\n    /// have dropped, returning the underlying data.\n    ///\n    /// # Safety\n    ///\n    /// This call will indefinitly spin if a child has not droped correctly.\n    ///\n    /// # Examples\n    /// ```rust\n    /// use parc::{ParentArc, LockWeak};\n    /// use std::sync::Mutex;\n    /// fn main() {\n    ///     let parent = ParentArc::new(Mutex::new(true));\n    ///     \n    ///     let weak1: LockWeak<_> = ParentArc::downgrade(&parent);\n    ///     let weak2: LockWeak<_> = ParentArc::downgrade(&parent);\n    ///     \n    ///     let child = weak1.upgrade().unwrap();\n    ///     drop(child);\n    ///\n    ///     let _: Mutex<bool> = parent.block_into_inner();\n    /// }\n    /// ```\n    pub fn block_into_inner(self) -> T {\n        let this = self.inner();\n\n        self.lock();\n        while this.strong.load(Ordering::Acquire) != 0 {}\n\n        unsafe {\n            let elem = ptr::read(&this.data);\n            mem::forget(self);\n            elem\n        }\n    }\n\n    /// Non-blocking version of [`block_into_inner`](#method.block_into_inner). It is advised to\n    /// call [`lock`](#method.lock) before calling this one, unless you know for sure there are no\n    /// [`ChildArc`](struct.ChildArc.html) alive at this instance.\n    ///\n    /// # Safety\n    ///\n    /// This will never unwrap `Ok(T)` if a child has not droped correctly.\n    ///\n    /// # Examples\n    /// ```rust\n    /// use parc::{ParentArc, LockWeak, TryUnwrapError::*};\n    /// use std::sync::Mutex;\n    /// fn main() {\n    ///     let mut parent = ParentArc::new(Mutex::new(true));\n    ///     \n    ///     let weak1: LockWeak<_> = ParentArc::downgrade(&parent);\n    ///     let weak2: LockWeak<_> = ParentArc::downgrade(&parent);\n    ///     \n    ///     let child = weak1.upgrade().unwrap();\n    ///     \n    ///     // Unlocked LockWeaks\n    ///     parent = if let Err(WouldLock(parent)) = ParentArc::try_unwrap(parent) {\n    ///         parent\n    ///     } else {\n    ///         unreachable!()\n    ///     };\n    ///\n    ///     // Locked LockWeaks\n    ///     parent.lock();\n    ///     parent = if let Err(WouldBlock(parent)) = ParentArc::try_unwrap(parent) {\n    ///         parent\n    ///     } else {\n    ///         unreachable!()\n    ///     };\n    ///     parent.unlock();\n    ///\n    ///     // Droped children\n    ///     drop(child);\n    ///     let value: Mutex<bool> = ParentArc::try_unwrap(parent).unwrap();\n    /// }\n    /// ```\n    pub fn try_unwrap(other: Self) -> TryUnwrapResult<T> {\n        let this = other.inner();\n\n        if !this.lock.load(Ordering::Relaxed) && this.strong.load(Ordering::Relaxed) > 0 {\n            // Check for non-null count and unlock state\n            return Err(TryUnwrapError::WouldLock(other));\n        }\n        if this.strong.load(Ordering::Relaxed) != 0 {\n            return Err(TryUnwrapError::WouldBlock(other));\n        }\n\n        unsafe {\n            let elem = ptr::read(&this.data);\n            mem::forget(other);\n            Ok(elem)\n        }\n    }\n\n    fn inner(&self) -> &Womb<T> {\n        unsafe { self.ptr.as_ref() } // Ok to do this because we own the data\n    }\n}\n\nimpl<T> AsRef<T> for ParentArc<T> {\n    fn as_ref(&self) -> &T {\n        &self.inner().data\n    }\n}\n\nimpl<T> ops::Deref for ParentArc<T> {\n    type Target = T;\n    fn deref(&self) -> &Self::Target {\n        &self.inner().data\n    }\n}\n\nimpl<T> Drop for ParentArc<T> {\n    fn drop(&mut self) {\n        // Wait for all reads to be droped\n        let this = self.inner();\n        while this.strong.load(Ordering::Acquire) != 0 {}\n    }\n}\n\n// Inner state shared by all instances: Parent, Weak, Child\nstruct Womb<T> {\n    data: T,\n    lock: AtomicBool,\n    strong: AtomicUsize,\n}\n\nimpl<T> Womb<T> {\n    fn as_nnptr(data: T) -> NonNull<Self> {\n        let x = Box::new(Self {\n            data,\n            lock: AtomicBool::new(false),\n            strong: AtomicUsize::new(0),\n        });\n        unsafe { NonNull::new_unchecked(Box::into_raw(x)) }\n    }\n}\n\n/// Weak reference to a [`ParentArc`](struct.ParentArc.html).\n///\n/// This instance can be locked at any moment, you can try to upgrade it into a\n/// [`ChildArc`](struct.ChildArc.html) which assures it can be read until the reader is dropped.\n///\n/// The typical way to obtain a Weak pointer is to call\n/// [`ParentArc::downgrade`](struct.ParentArc.html#method.downgrade).\npub struct LockWeak<T> {\n    ptr: NonNull<Womb<T>>,\n}\n\nimpl<T> LockWeak<T> {\n    /// Upgrades this Weak reference into a [`ChildArc`](struct.ChildArc.html) if the data is\n    /// unlocked or still owned by the [`ParentArc`](struct.ParentArc.html).\n    ///\n    /// # Examples\n    /// ```rust\n    /// use parc::{ParentArc, LockWeak};\n    /// use std::sync::Mutex;\n    /// fn main() {\n    ///     let parent = ParentArc::new(Mutex::new(true));\n    ///\n    ///     let weak: LockWeak<_> = ParentArc::downgrade(&parent);\n    ///     let child = weak.upgrade().unwrap();\n    /// }\n    /// ```\n    pub fn upgrade(&self) -> Option<ChildArc<T>> {\n        let this = self.inner()?;\n\n        if this.lock.load(Ordering::Relaxed) {\n            return None;\n        }\n\n        let mut n = this.strong.load(Ordering::Relaxed);\n        loop {\n            match this\n                .strong\n                .compare_exchange_weak(n, n + 1, Ordering::SeqCst, Ordering::Relaxed)\n            {\n                Ok(_) => break,\n                Err(old) => n = old,\n            }\n        }\n        Some(ChildArc::from(self.ptr))\n    }\n\n    // Pointer could be voided\n    fn inner(&self) -> Option<&Womb<T>> {\n        let address = self.ptr.as_ptr() as *mut () as usize;\n        if address == core::usize::MAX {\n            None\n        } else {\n            Some(unsafe { self.ptr.as_ref() })\n        }\n    }\n}\n\nunsafe impl<T> Send for LockWeak<T> {}\n\n/// Unclonable owned reference to a [`ParentArc`](struct.ParentArc.html).\n///\n/// This type can be dereferenced into the underlying data.\n///\n/// # Examples\n/// ```rust\n/// use parc::{ParentArc, LockWeak, ChildArc};\n/// use std::sync::Mutex;\n/// fn main() {\n///     let parent = ParentArc::new(Mutex::new(true));\n///\n///     let weak: LockWeak<_> = ParentArc::downgrade(&parent);\n///     let child: ChildArc<_> = weak.upgrade().unwrap();\n///\n///     assert!(*child.lock().unwrap());\n/// }\n/// ```\npub struct ChildArc<T> {\n    ptr: NonNull<Womb<T>>,\n}\n\nimpl<T> ChildArc<T> {\n    fn from(ptr: NonNull<Womb<T>>) -> Self {\n        Self { ptr }\n    }\n    fn inner(&self) -> &Womb<T> {\n        // safe because strong count is up one\n        unsafe { self.ptr.as_ref() }\n    }\n}\n\nimpl<T> AsRef<T> for ChildArc<T> {\n    fn as_ref(&self) -> &T {\n        &self.inner().data\n    }\n}\n\nimpl<T> ops::Deref for ChildArc<T> {\n    type Target = T;\n    fn deref(&self) -> &Self::Target {\n        &self.inner().data\n    }\n}\n\nimpl<T> Drop for ChildArc<T> {\n    fn drop(&mut self) {\n        let strong = &self.inner().strong;\n\n        let mut n = strong.load(Ordering::Relaxed);\n        loop {\n            match strong.compare_exchange_weak(n, n - 1, Ordering::SeqCst, Ordering::Relaxed) {\n                Ok(_) => break,\n                Err(old) => n = old,\n            }\n        }\n    }\n}\n\n#[cfg(all(test, not(feature = \"no_std\")))]\nmod tests {\n    extern crate std;\n    use super::*;\n    use std::sync;\n    use std::thread;\n    use std::vec::Vec;\n\n    #[test]\n    fn new() {\n        let _ = ParentArc::new(2);\n    }\n\n    #[test]\n    fn one_simple_thread() {\n        let m = ParentArc::new(sync::Mutex::new(0));\n        let _ = thread::spawn({\n            let weak = ParentArc::downgrade(&m);\n            move || match weak.upgrade() {\n                Some(mutex) => *mutex.lock().unwrap() += 1,\n                None => {}\n            }\n        })\n        .join();\n        let _: sync::Mutex<usize> = m.block_into_inner();\n    }\n\n    #[test]\n    fn join_after_thread() {\n        let m = ParentArc::new(sync::Mutex::new(0));\n        let h = thread::spawn({\n            let weak = ParentArc::downgrade(&m);\n            move || match weak.upgrade() {\n                Some(mutex) => *mutex.lock().unwrap() += 1,\n                None => {}\n            }\n        });\n        let _: sync::Mutex<usize> = m.block_into_inner();\n        let _ = h.join();\n    }\n\n    #[test]\n    fn multiple_threads() {\n        let m = ParentArc::new(sync::Mutex::new(0));\n        for _ in 0..10 {\n            let _ = thread::spawn({\n                let weak = ParentArc::downgrade(&m);\n                move || match weak.upgrade() {\n                    Some(mutex) => *mutex.lock().unwrap() += 1,\n                    None => {}\n                }\n            })\n            .join();\n        }\n        let _: sync::Mutex<usize> = m.block_into_inner();\n    }\n\n    #[test]\n    fn loop_read_thread() {\n        let m = ParentArc::new(sync::Mutex::new(0));\n        let h = thread::spawn({\n            let weak = ParentArc::downgrade(&m);\n            move || loop {\n                match weak.upgrade() {\n                    Some(mutex) => *mutex.lock().unwrap() += 1,\n                    None => break,\n                }\n            }\n        });\n        let _: sync::Mutex<usize> = m.block_into_inner();\n        let _ = h.join();\n    }\n\n    #[test]\n    fn many_loop_read_threads() {\n        let m = ParentArc::new(sync::Mutex::new(0));\n\n        let mut vh = Vec::new();\n        for _ in 0..10 {\n            let h = thread::spawn({\n                let weak = ParentArc::downgrade(&m);\n                move || loop {\n                    match weak.upgrade() {\n                        Some(mutex) => *mutex.lock().unwrap() += 1,\n                        None => break,\n                    }\n                }\n            });\n            vh.push(h);\n        }\n\n        let _: sync::Mutex<usize> = m.block_into_inner();\n        for h in vh {\n            let _ = h.join();\n        }\n    }\n\n    #[test]\n    #[should_panic]\n    fn one_panic_read_threads() {\n        let m = ParentArc::new(sync::atomic::AtomicUsize::new(0));\n\n        let mut vh = Vec::new();\n        for i in 0..10 {\n            let h = thread::spawn({\n                let weak = ParentArc::downgrade(&m);\n                move || loop {\n                    match weak.upgrade() {\n                        Some(at) => {\n                            if i != 1 {\n                                at.store(1, sync::atomic::Ordering::SeqCst);\n                            } else {\n                                panic!()\n                            }\n                        }\n                        None => break,\n                    }\n                }\n            });\n            vh.push(h);\n        }\n\n        //wait for all threads to launch\n        thread::sleep(std::time::Duration::new(0, 100));\n\n        let _: sync::atomic::AtomicUsize = m.block_into_inner();\n\n        for h in vh {\n            h.join().unwrap(); // panic occurs here\n        }\n    }\n}\n"
  },
  {
    "project": "miow",
    "target": 1,
    "commit_id": "f6662ef11d1aac309aea5a6548c1a2d35c1de6e9",
    "func": "//! Extensions and types for the standard networking primitives.\n//!\n//! This module contains a number of extension traits for the types in\n//! `std::net` for Windows-specific functionality.\n\nuse std::cmp;\nuse std::io;\nuse std::mem;\nuse std::sync::atomic::{AtomicUsize, Ordering, ATOMIC_USIZE_INIT};\nuse std::net::{TcpStream, UdpSocket, SocketAddr, TcpListener};\nuse std::net::{SocketAddrV4, Ipv4Addr, SocketAddrV6, Ipv6Addr};\nuse std::os::windows::prelude::*;\n\nuse net2::TcpBuilder;\nuse winapi::*;\nuse ws2_32::*;\n\n/// A type to represent a buffer in which a socket address will be stored.\n///\n/// This type is used with the `recv_from_overlapped` function on the\n/// `UdpSocketExt` trait to provide space for the overlapped I/O operation to\n/// fill in the address upon completion.\n#[derive(Clone, Copy)]\npub struct SocketAddrBuf {\n    buf: SOCKADDR_STORAGE,\n    len: c_int,\n}\n\n/// A type to represent a buffer in which an accepted socket's address will be\n/// stored.\n///\n/// This type is used with the `accept_overlapped` method on the\n/// `TcpListenerExt` trait to provide space for the overlapped I/O operation to\n/// fill in the socket addresses upon completion.\n#[repr(C)]\npub struct AcceptAddrsBuf {\n    // For AcceptEx we've got the restriction that the addresses passed in that\n    // buffer need to be at least 16 bytes more than the maximum address length\n    // for the protocol in question, so add some extra here and there\n    local: SOCKADDR_STORAGE,\n    _pad1: [u8; 16],\n    remote: SOCKADDR_STORAGE,\n    _pad2: [u8; 16],\n}\n\n/// The parsed return value of `AcceptAddrsBuf`.\npub struct AcceptAddrs<'a> {\n    local: LPSOCKADDR,\n    local_len: c_int,\n    remote: LPSOCKADDR,\n    remote_len: c_int,\n    _data: &'a AcceptAddrsBuf,\n}\n\nstruct WsaExtension {\n    guid: GUID,\n    val: AtomicUsize,\n}\n\n/// Additional methods for the `TcpStream` type in the standard library.\npub trait TcpStreamExt {\n    /// Execute an overlapped read I/O operation on this TCP stream.\n    ///\n    /// This function will issue an overlapped I/O read (via `WSARecv`) on this\n    /// socket. The provided buffer will be filled in when the operation\n    /// completes and the given `OVERLAPPED` instance is used to track the\n    /// overlapped operation.\n    ///\n    /// If the operation succeeds, `Ok(Some(n))` is returned indicating how\n    /// many bytes were read. If the operation returns an error indicating that\n    /// the I/O is currently pending, `Ok(None)` is returned. Otherwise, the\n    /// error associated with the operation is returned and no overlapped\n    /// operation is enqueued.\n    ///\n    /// The number of bytes read will be returned as part of the completion\n    /// notification when the I/O finishes.\n    ///\n    /// # Unsafety\n    ///\n    /// This function is unsafe because the kernel requires that the `buf` and\n    /// `overlapped` pointers are valid until the end of the I/O operation. The\n    /// kernel also requires that `overlapped` is unique for this I/O operation\n    /// and is not in use for any other I/O.\n    ///\n    /// To safely use this function callers must ensure that these two input\n    /// pointers are valid until the I/O operation is completed, typically via\n    /// completion ports and waiting to receive the completion notification on\n    /// the port.\n    unsafe fn read_overlapped(&self,\n                              buf: &mut [u8],\n                              overlapped: *mut OVERLAPPED)\n                              -> io::Result<Option<usize>>;\n\n    /// Execute an overlapped write I/O operation on this TCP stream.\n    ///\n    /// This function will issue an overlapped I/O write (via `WSASend`) on this\n    /// socket. The provided buffer will be written when the operation completes\n    /// and the given `OVERLAPPED` instance is used to track the overlapped\n    /// operation.\n    ///\n    /// If the operation succeeds, `Ok(Some(n))` is returned where `n` is the\n    /// number of bytes that were written. If the operation returns an error\n    /// indicating that the I/O is currently pending, `Ok(None)` is returned.\n    /// Otherwise, the error associated with the operation is returned and no\n    /// overlapped operation is enqueued.\n    ///\n    /// The number of bytes written will be returned as part of the completion\n    /// notification when the I/O finishes.\n    ///\n    /// # Unsafety\n    ///\n    /// This function is unsafe because the kernel requires that the `buf` and\n    /// `overlapped` pointers are valid until the end of the I/O operation. The\n    /// kernel also requires that `overlapped` is unique for this I/O operation\n    /// and is not in use for any other I/O.\n    ///\n    /// To safely use this function callers must ensure that these two input\n    /// pointers are valid until the I/O operation is completed, typically via\n    /// completion ports and waiting to receive the completion notification on\n    /// the port.\n    unsafe fn write_overlapped(&self,\n                               buf: &[u8],\n                               overlapped: *mut OVERLAPPED)\n                               -> io::Result<Option<usize>>;\n\n    /// Execute a connection operation for this socket.\n    ///\n    /// For more information about this method, see the\n    /// [`TcpBuilderExt::connect_overlapped`][link] documentation.\n    ///\n    /// [link]: trait.TcpBuilderExt.html#tymethod.connect_overlapped\n    unsafe fn connect_overlapped(&self,\n                                 addr: &SocketAddr,\n                                 buf: &[u8],\n                                 overlapped: *mut OVERLAPPED)\n                                 -> io::Result<Option<usize>>;\n\n    /// Once a `connect_overlapped` has finished, this function needs to be\n    /// called to finish the connect operation.\n    ///\n    /// Currently this just calls `setsockopt` with `SO_UPDATE_CONNECT_CONTEXT`\n    /// to ensure that further functions like `getpeername` and `getsockname`\n    /// work correctly.\n    fn connect_complete(&self) -> io::Result<()>;\n\n    /// Calls the `GetOverlappedResult` function to get the result of an\n    /// overlapped operation for this handle.\n    ///\n    /// This function takes the `OVERLAPPED` argument which must have been used\n    /// to initiate an overlapped I/O operation, and returns either the\n    /// successful number of bytes transferred during the operation or an error\n    /// if one occurred, along with the results of the `lpFlags` parameter of\n    /// the relevant operation, if applicable.\n    ///\n    /// # Unsafety\n    ///\n    /// This function is unsafe as `overlapped` must have previously been used\n    /// to execute an operation for this handle, and it must also be a valid\n    /// pointer to an `OVERLAPPED` instance.\n    ///\n    /// # Panics\n    ///\n    /// This function will panic\n    unsafe fn result(&self, overlapped: *mut OVERLAPPED)\n                     -> io::Result<(usize, u32)>;\n}\n\n/// Additional methods for the `UdpSocket` type in the standard library.\npub trait UdpSocketExt {\n    /// Execute an overlapped receive I/O operation on this UDP socket.\n    ///\n    /// This function will issue an overlapped I/O read (via `WSARecvFrom`) on\n    /// this socket. The provided buffer will be filled in when the operation\n    /// completes, the source from where the data came from will be written to\n    /// `addr`, and the given `OVERLAPPED` instance is used to track the\n    /// overlapped operation.\n    ///\n    /// If the operation succeeds, `Ok(Some(n))` is returned where `n` is the\n    /// number of bytes that were read. If the operation returns an error\n    /// indicating that the I/O is currently pending, `Ok(None)` is returned.\n    /// Otherwise, the error associated with the operation is returned and no\n    /// overlapped operation is enqueued.\n    ///\n    /// The number of bytes read will be returned as part of the completion\n    /// notification when the I/O finishes.\n    ///\n    /// # Unsafety\n    ///\n    /// This function is unsafe because the kernel requires that the `buf`,\n    /// `addr`, and `overlapped` pointers are valid until the end of the I/O\n    /// operation. The kernel also requires that `overlapped` is unique for this\n    /// I/O operation and is not in use for any other I/O.\n    ///\n    /// To safely use this function callers must ensure that these two input\n    /// pointers are valid until the I/O operation is completed, typically via\n    /// completion ports and waiting to receive the completion notification on\n    /// the port.\n    unsafe fn recv_from_overlapped(&self,\n                                   buf: &mut [u8],\n                                   addr: *mut SocketAddrBuf,\n                                   overlapped: *mut OVERLAPPED)\n                                   -> io::Result<Option<usize>>;\n\n    /// Execute an overlapped receive I/O operation on this UDP socket.\n    ///\n    /// This function will issue an overlapped I/O read (via `WSARecv`) on\n    /// this socket. The provided buffer will be filled in when the operation\n    /// completes, the source from where the data came from will be written to\n    /// `addr`, and the given `OVERLAPPED` instance is used to track the\n    /// overlapped operation.\n    ///\n    /// If the operation succeeds, `Ok(Some(n))` is returned where `n` is the\n    /// number of bytes that were read. If the operation returns an error\n    /// indicating that the I/O is currently pending, `Ok(None)` is returned.\n    /// Otherwise, the error associated with the operation is returned and no\n    /// overlapped operation is enqueued.\n    ///\n    /// The number of bytes read will be returned as part of the completion\n    /// notification when the I/O finishes.\n    ///\n    /// # Unsafety\n    ///\n    /// This function is unsafe because the kernel requires that the `buf`,\n    /// and `overlapped` pointers are valid until the end of the I/O\n    /// operation. The kernel also requires that `overlapped` is unique for this\n    /// I/O operation and is not in use for any other I/O.\n    ///\n    /// To safely use this function callers must ensure that these two input\n    /// pointers are valid until the I/O operation is completed, typically via\n    /// completion ports and waiting to receive the completion notification on\n    /// the port.\n    unsafe fn recv_overlapped(&self,\n                              buf: &mut [u8],\n                              overlapped: *mut OVERLAPPED)\n                              -> io::Result<Option<usize>>;\n\n    /// Execute an overlapped send I/O operation on this UDP socket.\n    ///\n    /// This function will issue an overlapped I/O write (via `WSASendTo`) on\n    /// this socket to the address specified by `addr`. The provided buffer will\n    /// be written when the operation completes and the given `OVERLAPPED`\n    /// instance is used to track the overlapped operation.\n    ///\n    /// If the operation succeeds, `Ok(Some(n0)` is returned where `n` byte\n    /// were written. If the operation returns an error indicating that the I/O\n    /// is currently pending, `Ok(None)` is returned. Otherwise, the error\n    /// associated with the operation is returned and no overlapped operation\n    /// is enqueued.\n    ///\n    /// The number of bytes written will be returned as part of the completion\n    /// notification when the I/O finishes.\n    ///\n    /// # Unsafety\n    ///\n    /// This function is unsafe because the kernel requires that the `buf` and\n    /// `overlapped` pointers are valid until the end of the I/O operation. The\n    /// kernel also requires that `overlapped` is unique for this I/O operation\n    /// and is not in use for any other I/O.\n    ///\n    /// To safely use this function callers must ensure that these two input\n    /// pointers are valid until the I/O operation is completed, typically via\n    /// completion ports and waiting to receive the completion notification on\n    /// the port.\n    unsafe fn send_to_overlapped(&self,\n                                 buf: &[u8],\n                                 addr: &SocketAddr,\n                                 overlapped: *mut OVERLAPPED)\n                                 -> io::Result<Option<usize>>;\n\n    /// Execute an overlapped send I/O operation on this UDP socket.\n    ///\n    /// This function will issue an overlapped I/O write (via `WSASend`) on\n    /// this socket to the address it was previously connected to. The provided \n    /// buffer will be written when the operation completes and the given `OVERLAPPED`\n    /// instance is used to track the overlapped operation.\n    ///\n    /// If the operation succeeds, `Ok(Some(n0)` is returned where `n` byte\n    /// were written. If the operation returns an error indicating that the I/O\n    /// is currently pending, `Ok(None)` is returned. Otherwise, the error\n    /// associated with the operation is returned and no overlapped operation\n    /// is enqueued.\n    ///\n    /// The number of bytes written will be returned as part of the completion\n    /// notification when the I/O finishes.\n    ///\n    /// # Unsafety\n    ///\n    /// This function is unsafe because the kernel requires that the `buf` and\n    /// `overlapped` pointers are valid until the end of the I/O operation. The\n    /// kernel also requires that `overlapped` is unique for this I/O operation\n    /// and is not in use for any other I/O.\n    ///\n    /// To safely use this function callers must ensure that these two input\n    /// pointers are valid until the I/O operation is completed, typically via\n    /// completion ports and waiting to receive the completion notification on\n    /// the port.\n    unsafe fn send_overlapped(&self,\n                                 buf: &[u8],\n                                 overlapped: *mut OVERLAPPED)\n                                 -> io::Result<Option<usize>>;\n \n    /// Calls the `GetOverlappedResult` function to get the result of an\n    /// overlapped operation for this handle.\n    ///\n    /// This function takes the `OVERLAPPED` argument which must have been used\n    /// to initiate an overlapped I/O operation, and returns either the\n    /// successful number of bytes transferred during the operation or an error\n    /// if one occurred, along with the results of the `lpFlags` parameter of\n    /// the relevant operation, if applicable.\n    ///\n    /// # Unsafety\n    ///\n    /// This function is unsafe as `overlapped` must have previously been used\n    /// to execute an operation for this handle, and it must also be a valid\n    /// pointer to an `OVERLAPPED` instance.\n    ///\n    /// # Panics\n    ///\n    /// This function will panic\n    unsafe fn result(&self, overlapped: *mut OVERLAPPED)\n                     -> io::Result<(usize, u32)>;\n}\n\n/// Additional methods for the `TcpBuilder` type in the `net2` library.\npub trait TcpBuilderExt {\n    /// Attempt to consume the internal socket in this builder by executing an\n    /// overlapped connect operation.\n    ///\n    /// This function will issue a connect operation to the address specified on\n    /// the underlying socket, flagging it as an overlapped operation which will\n    /// complete asynchronously. If successful this function will return the\n    /// corresponding TCP stream.\n    ///\n    /// The `buf` argument provided is an initial buffer of data that should be\n    /// sent after the connection is initiated. It's acceptable to\n    /// pass an empty slice here.\n    ///\n    /// This function will also return whether the connect immediately\n    /// succeeded or not. If `None` is returned then the I/O operation is still\n    /// pending and will complete at a later date, and if `Some(bytes)` is\n    /// returned then that many bytes were transferred.\n    ///\n    /// Note that to succeed this requires that the underlying socket has\n    /// previously been bound via a call to `bind` to a local address.\n    ///\n    /// # Unsafety\n    ///\n    /// This function is unsafe because the kernel requires that the\n    /// `overlapped` and `buf` pointers to be  valid until the end of the I/O\n    /// operation. The kernel also requires that `overlapped` is unique for\n    /// this I/O operation and is not in use for any other I/O.\n    ///\n    /// To safely use this function callers must ensure that this pointer is\n    /// valid until the I/O operation is completed, typically via completion\n    /// ports and waiting to receive the completion notification on the port.\n    unsafe fn connect_overlapped(&self,\n                                 addr: &SocketAddr,\n                                 buf: &[u8],\n                                 overlapped: *mut OVERLAPPED)\n                                 -> io::Result<(TcpStream, Option<usize>)>;\n\n    /// Calls the `GetOverlappedResult` function to get the result of an\n    /// overlapped operation for this handle.\n    ///\n    /// This function takes the `OVERLAPPED` argument which must have been used\n    /// to initiate an overlapped I/O operation, and returns either the\n    /// successful number of bytes transferred during the operation or an error\n    /// if one occurred, along with the results of the `lpFlags` parameter of\n    /// the relevant operation, if applicable.\n    ///\n    /// # Unsafety\n    ///\n    /// This function is unsafe as `overlapped` must have previously been used\n    /// to execute an operation for this handle, and it must also be a valid\n    /// pointer to an `OVERLAPPED` instance.\n    ///\n    /// # Panics\n    ///\n    /// This function will panic\n    unsafe fn result(&self, overlapped: *mut OVERLAPPED)\n                     -> io::Result<(usize, u32)>;\n}\n\n/// Additional methods for the `TcpListener` type in the standard library.\npub trait TcpListenerExt {\n    /// Perform an accept operation on this listener, accepting a connection in\n    /// an overlapped fashion.\n    ///\n    /// This function will issue an I/O request to accept an incoming connection\n    /// with the specified overlapped instance. The `socket` provided must be a\n    /// configured but not bound or connected socket, and if successful this\n    /// will consume the internal socket of the builder to return a TCP stream.\n    ///\n    /// The `addrs` buffer provided will be filled in with the local and remote\n    /// addresses of the connection upon completion.\n    ///\n    /// If the accept succeeds immediately, `Ok(stream, true)` is returned. If\n    /// the connect indicates that the I/O is currently pending, `Ok(stream,\n    /// false)` is returned. Otherwise, the error associated with the operation\n    /// is returned and no overlapped operation is enqueued.\n    ///\n    /// # Unsafety\n    ///\n    /// This function is unsafe because the kernel requires that the\n    /// `addrs` and `overlapped` pointers are valid until the end of the I/O\n    /// operation. The kernel also requires that `overlapped` is unique for this\n    /// I/O operation and is not in use for any other I/O.\n    ///\n    /// To safely use this function callers must ensure that the pointers are\n    /// valid until the I/O operation is completed, typically via completion\n    /// ports and waiting to receive the completion notification on the port.\n    unsafe fn accept_overlapped(&self,\n                                socket: &TcpBuilder,\n                                addrs: &mut AcceptAddrsBuf,\n                                overlapped: *mut OVERLAPPED)\n                                -> io::Result<(TcpStream, bool)>;\n\n    /// Once an `accept_overlapped` has finished, this function needs to be\n    /// called to finish the accept operation.\n    ///\n    /// Currently this just calls `setsockopt` with `SO_UPDATE_ACCEPT_CONTEXT`\n    /// to ensure that further functions like `getpeername` and `getsockname`\n    /// work correctly.\n    fn accept_complete(&self, socket: &TcpStream) -> io::Result<()>;\n\n    /// Calls the `GetOverlappedResult` function to get the result of an\n    /// overlapped operation for this handle.\n    ///\n    /// This function takes the `OVERLAPPED` argument which must have been used\n    /// to initiate an overlapped I/O operation, and returns either the\n    /// successful number of bytes transferred during the operation or an error\n    /// if one occurred, along with the results of the `lpFlags` parameter of\n    /// the relevant operation, if applicable.\n    ///\n    /// # Unsafety\n    ///\n    /// This function is unsafe as `overlapped` must have previously been used\n    /// to execute an operation for this handle, and it must also be a valid\n    /// pointer to an `OVERLAPPED` instance.\n    ///\n    /// # Panics\n    ///\n    /// This function will panic\n    unsafe fn result(&self, overlapped: *mut OVERLAPPED)\n                     -> io::Result<(usize, u32)>;\n}\n\n#[doc(hidden)]\ntrait NetInt {\n    fn from_be(i: Self) -> Self;\n    fn to_be(&self) -> Self;\n}\nmacro_rules! doit {\n    ($($t:ident)*) => ($(impl NetInt for $t {\n        fn from_be(i: Self) -> Self { <$t>::from_be(i) }\n        fn to_be(&self) -> Self { <$t>::to_be(*self) }\n    })*)\n}\ndoit! { i8 i16 i32 i64 isize u8 u16 u32 u64 usize }\n\n// fn hton<I: NetInt>(i: I) -> I { i.to_be() }\nfn ntoh<I: NetInt>(i: I) -> I { I::from_be(i) }\n\nfn last_err() -> io::Result<Option<usize>> {\n    let err = unsafe { WSAGetLastError() };\n    if err == WSA_IO_PENDING as i32 {\n        Ok(None)\n    } else {\n        Err(io::Error::from_raw_os_error(err))\n    }\n}\n\nfn cvt(i: c_int, size: DWORD) -> io::Result<Option<usize>> {\n    if i == SOCKET_ERROR {\n        last_err()\n    } else {\n        Ok(Some(size as usize))\n    }\n}\n\nfn socket_addr_to_ptrs(addr: &SocketAddr) -> (*const SOCKADDR, c_int) {\n    match *addr {\n        SocketAddr::V4(ref a) => {\n            (a as *const _ as *const _, mem::size_of::<SOCKADDR_IN>() as c_int)\n        }\n        SocketAddr::V6(ref a) => {\n            (a as *const _ as *const _, mem::size_of::<sockaddr_in6>() as c_int)\n        }\n    }\n}\n\nunsafe fn ptrs_to_socket_addr(ptr: *const SOCKADDR,\n                              len: c_int) -> Option<SocketAddr> {\n    if (len as usize) < mem::size_of::<c_int>() {\n        return None\n    }\n    match (*ptr).sa_family as i32 {\n        AF_INET if len as usize >= mem::size_of::<SOCKADDR_IN>() => {\n            let b = &*(ptr as *const SOCKADDR_IN);\n            let ip = ntoh(b.sin_addr.S_un);\n            let ip = Ipv4Addr::new((ip >> 24) as u8,\n                                   (ip >> 16) as u8,\n                                   (ip >>  8) as u8,\n                                   (ip >>  0) as u8);\n            Some(SocketAddr::V4(SocketAddrV4::new(ip, ntoh(b.sin_port))))\n        }\n        AF_INET6 if len as usize >= mem::size_of::<sockaddr_in6>() => {\n            let b = &*(ptr as *const sockaddr_in6);\n            let arr = &b.sin6_addr.s6_addr;\n            let ip = Ipv6Addr::new(\n                ((arr[0] as u16) << 8) | (arr[1] as u16),\n                ((arr[2] as u16) << 8) | (arr[3] as u16),\n                ((arr[4] as u16) << 8) | (arr[5] as u16),\n                ((arr[6] as u16) << 8) | (arr[7] as u16),\n                ((arr[8] as u16) << 8) | (arr[9] as u16),\n                ((arr[10] as u16) << 8) | (arr[11] as u16),\n                ((arr[12] as u16) << 8) | (arr[13] as u16),\n                ((arr[14] as u16) << 8) | (arr[15] as u16));\n            let addr = SocketAddrV6::new(ip, ntoh(b.sin6_port),\n                                         ntoh(b.sin6_flowinfo),\n                                         ntoh(b.sin6_scope_id));\n            Some(SocketAddr::V6(addr))\n        }\n        _ => None\n    }\n}\n\nunsafe fn slice2buf(slice: &[u8]) -> WSABUF {\n    WSABUF {\n        len: cmp::min(slice.len(), <u_long>::max_value() as usize) as u_long,\n        buf: slice.as_ptr() as *mut _,\n    }\n}\n\nunsafe fn result(socket: SOCKET, overlapped: *mut OVERLAPPED)\n                 -> io::Result<(usize, u32)> {\n    let mut transferred = 0;\n    let mut flags = 0;\n    let r = WSAGetOverlappedResult(socket,\n                                   overlapped,\n                                   &mut transferred,\n                                   FALSE,\n                                   &mut flags);\n    if r == 0 {\n        Err(io::Error::last_os_error())\n    } else {\n        Ok((transferred as usize, flags))\n    }\n}\n\nimpl TcpStreamExt for TcpStream {\n    unsafe fn read_overlapped(&self,\n                              buf: &mut [u8],\n                              overlapped: *mut OVERLAPPED)\n                              -> io::Result<Option<usize>> {\n        let mut buf = slice2buf(buf);\n        let mut flags = 0;\n        let mut bytes_read: DWORD = 0;\n        let r = WSARecv(self.as_raw_socket(), &mut buf, 1,\n                        &mut bytes_read, &mut flags, overlapped, None);\n        cvt(r, bytes_read)\n    }\n\n    unsafe fn write_overlapped(&self,\n                               buf: &[u8],\n                               overlapped: *mut OVERLAPPED)\n                               -> io::Result<Option<usize>> {\n        let mut buf = slice2buf(buf);\n        let mut bytes_written = 0;\n\n        // Note here that we capture the number of bytes written. The\n        // documentation on MSDN, however, states:\n        //\n        // > Use NULL for this parameter if the lpOverlapped parameter is not\n        // > NULL to avoid potentially erroneous results. This parameter can be\n        // > NULL only if the lpOverlapped parameter is not NULL.\n        //\n        // If we're not passing a null overlapped pointer here, then why are we\n        // then capturing the number of bytes! Well so it turns out that this is\n        // clearly faster to learn the bytes here rather than later calling\n        // `WSAGetOverlappedResult`, and in practice almost all implementations\n        // use this anyway [1].\n        //\n        // As a result we use this to and report back the result.\n        //\n        // [1]: https://github.com/carllerche/mio/pull/520#issuecomment-273983823\n        let r = WSASend(self.as_raw_socket(), &mut buf, 1,\n                        &mut bytes_written, 0, overlapped, None);\n        cvt(r, bytes_written)\n    }\n\n    unsafe fn connect_overlapped(&self,\n                                 addr: &SocketAddr,\n                                 buf: &[u8],\n                                 overlapped: *mut OVERLAPPED)\n                                 -> io::Result<Option<usize>> {\n        connect_overlapped(self.as_raw_socket(), addr, buf, overlapped)\n    }\n\n    fn connect_complete(&self) -> io::Result<()> {\n        const SO_UPDATE_CONNECT_CONTEXT: c_int = 0x7010;\n        let result = unsafe {\n            setsockopt(self.as_raw_socket(),\n                       SOL_SOCKET,\n                       SO_UPDATE_CONNECT_CONTEXT,\n                       0 as *const _,\n                       0)\n        };\n        if result == 0 {\n            Ok(())\n        } else {\n            Err(io::Error::last_os_error())\n        }\n    }\n\n    unsafe fn result(&self, overlapped: *mut OVERLAPPED)\n                     -> io::Result<(usize, u32)> {\n        result(self.as_raw_socket(), overlapped)\n    }\n}\n\nunsafe fn connect_overlapped(socket: SOCKET,\n                             addr: &SocketAddr,\n                             buf: &[u8],\n                             overlapped: *mut OVERLAPPED)\n                             -> io::Result<Option<usize>> {\n    static CONNECTEX: WsaExtension = WsaExtension {\n        guid: GUID {\n            Data1: 0x25a207b9,\n            Data2: 0xddf3,\n            Data3: 0x4660,\n            Data4: [0x8e, 0xe9, 0x76, 0xe5, 0x8c, 0x74, 0x06, 0x3e],\n        },\n        val: ATOMIC_USIZE_INIT,\n    };\n    type ConnectEx = unsafe extern \"system\" fn(SOCKET, *const SOCKADDR,\n                                               c_int, PVOID, DWORD, LPDWORD,\n                                               LPOVERLAPPED) -> BOOL;\n\n    let ptr = try!(CONNECTEX.get(socket));\n    assert!(ptr != 0);\n    let connect_ex = mem::transmute::<_, ConnectEx>(ptr);\n\n    let (addr_buf, addr_len) = socket_addr_to_ptrs(addr);\n    let mut bytes_sent: DWORD = 0;\n    let r = connect_ex(socket, addr_buf, addr_len,\n                       buf.as_ptr() as *mut _,\n                       buf.len() as u32,\n                       &mut bytes_sent, overlapped);\n    if r == TRUE {\n        Ok(Some(bytes_sent as usize))\n    } else {\n        last_err()\n    }\n}\n\nimpl UdpSocketExt for UdpSocket {\n    unsafe fn recv_from_overlapped(&self,\n                                   buf: &mut [u8],\n                                   addr: *mut SocketAddrBuf,\n                                   overlapped: *mut OVERLAPPED)\n                                   -> io::Result<Option<usize>> {\n        let mut buf = slice2buf(buf);\n        let mut flags = 0;\n        let mut received_bytes: DWORD = 0;\n        let r = WSARecvFrom(self.as_raw_socket(), &mut buf, 1,\n                            &mut received_bytes, &mut flags,\n                            &mut (*addr).buf as *mut _ as *mut _,\n                            &mut (*addr).len,\n                            overlapped, None);\n        cvt(r, received_bytes)\n    }\n\n    unsafe fn recv_overlapped(&self,\n                              buf: &mut [u8],\n                              overlapped: *mut OVERLAPPED)\n                              -> io::Result<Option<usize>> {\n        let mut buf = slice2buf(buf);\n        let mut flags = 0;\n        let mut received_bytes: DWORD = 0;\n        let r = WSARecv(self.as_raw_socket(), &mut buf, 1,\n                            &mut received_bytes, &mut flags,\n                            overlapped, None);\n        cvt(r, received_bytes)\n    }\n\n    unsafe fn send_to_overlapped(&self,\n                                 buf: &[u8],\n                                 addr: &SocketAddr,\n                                 overlapped: *mut OVERLAPPED)\n                                 -> io::Result<Option<usize>> {\n        let (addr_buf, addr_len) = socket_addr_to_ptrs(addr);\n        let mut buf = slice2buf(buf);\n        let mut sent_bytes = 0;\n        let r = WSASendTo(self.as_raw_socket(), &mut buf, 1,\n                          &mut sent_bytes, 0,\n                          addr_buf as *const _, addr_len,\n                          overlapped, None);\n        cvt(r, sent_bytes)\n    }\n\n    unsafe fn send_overlapped(&self,\n                              buf: &[u8],\n                              overlapped: *mut OVERLAPPED)\n                              -> io::Result<Option<usize>> {\n        let mut buf = slice2buf(buf);\n        let mut sent_bytes = 0;\n        let r = WSASend(self.as_raw_socket(), &mut buf, 1,\n                          &mut sent_bytes, 0,\n                          overlapped, None);\n        cvt(r, sent_bytes)\n    }\n\n    unsafe fn result(&self, overlapped: *mut OVERLAPPED)\n                     -> io::Result<(usize, u32)> {\n        result(self.as_raw_socket(), overlapped)\n    }\n}\n\nimpl TcpBuilderExt for TcpBuilder {\n    unsafe fn connect_overlapped(&self,\n                                 addr: &SocketAddr,\n                                 buf: &[u8],\n                                 overlapped: *mut OVERLAPPED)\n                                 -> io::Result<(TcpStream, Option<usize>)> {\n        connect_overlapped(self.as_raw_socket(), addr, buf, overlapped).map(|s| {\n            (self.to_tcp_stream().unwrap(), s)\n        })\n    }\n\n    unsafe fn result(&self, overlapped: *mut OVERLAPPED)\n                     -> io::Result<(usize, u32)> {\n        result(self.as_raw_socket(), overlapped)\n    }\n}\n\nimpl TcpListenerExt for TcpListener {\n    unsafe fn accept_overlapped(&self,\n                                socket: &TcpBuilder,\n                                addrs: &mut AcceptAddrsBuf,\n                                overlapped: *mut OVERLAPPED)\n                                -> io::Result<(TcpStream, bool)> {\n        static ACCEPTEX: WsaExtension = WsaExtension {\n            guid: GUID {\n                Data1: 0xb5367df1,\n                Data2: 0xcbac,\n                Data3: 0x11cf,\n                Data4: [0x95, 0xca, 0x00, 0x80, 0x5f, 0x48, 0xa1, 0x92],\n            },\n            val: ATOMIC_USIZE_INIT,\n        };\n        type AcceptEx = unsafe extern \"system\" fn(SOCKET, SOCKET, PVOID,\n                                                  DWORD, DWORD, DWORD, LPDWORD,\n                                                  LPOVERLAPPED) -> BOOL;\n\n        let ptr = try!(ACCEPTEX.get(self.as_raw_socket()));\n        assert!(ptr != 0);\n        let accept_ex = mem::transmute::<_, AcceptEx>(ptr);\n\n        let mut bytes = 0;\n        let (a, b, c, d) = (*addrs).args();\n        let r = accept_ex(self.as_raw_socket(), socket.as_raw_socket(),\n                          a, b, c, d, &mut bytes, overlapped);\n        let succeeded = if r == TRUE {\n            true\n        } else {\n            try!(last_err());\n            false\n        };\n        // NB: this unwrap() should be guaranteed to succeed, and this is an\n        // assert that it does indeed succeed.\n        Ok((socket.to_tcp_stream().unwrap(), succeeded))\n    }\n\n    fn accept_complete(&self, socket: &TcpStream) -> io::Result<()> {\n        const SO_UPDATE_ACCEPT_CONTEXT: c_int = 0x700B;\n        let me = self.as_raw_socket();\n        let result = unsafe {\n            setsockopt(socket.as_raw_socket(),\n                       SOL_SOCKET,\n                       SO_UPDATE_ACCEPT_CONTEXT,\n                       &me as *const _ as *const _,\n                       mem::size_of_val(&me) as c_int)\n        };\n        if result == 0 {\n            Ok(())\n        } else {\n            Err(io::Error::last_os_error())\n        }\n    }\n\n    unsafe fn result(&self, overlapped: *mut OVERLAPPED)\n                     -> io::Result<(usize, u32)> {\n        result(self.as_raw_socket(), overlapped)\n    }\n}\n\nimpl SocketAddrBuf {\n    /// Creates a new blank socket address buffer.\n    ///\n    /// This should be used before a call to `recv_from_overlapped` overlapped\n    /// to create an instance to pass down.\n    pub fn new() -> SocketAddrBuf {\n        SocketAddrBuf {\n            buf: unsafe { mem::zeroed() },\n            len: mem::size_of::<SOCKADDR_STORAGE>() as c_int,\n        }\n    }\n\n    /// Parses this buffer to return a standard socket address.\n    ///\n    /// This function should be called after the buffer has been filled in with\n    /// a call to `recv_from_overlapped` being completed. It will interpret the\n    /// address filled in and return the standard socket address type.\n    ///\n    /// If an error is encountered then `None` is returned.\n    pub fn to_socket_addr(&self) -> Option<SocketAddr> {\n        unsafe {\n            ptrs_to_socket_addr(&self.buf as *const _ as *const _, self.len)\n        }\n    }\n}\n\nstatic GETACCEPTEXSOCKADDRS: WsaExtension = WsaExtension {\n    guid: GUID {\n        Data1: 0xb5367df2,\n        Data2: 0xcbac,\n        Data3: 0x11cf,\n        Data4: [0x95, 0xca, 0x00, 0x80, 0x5f, 0x48, 0xa1, 0x92],\n    },\n    val: ATOMIC_USIZE_INIT,\n};\ntype GetAcceptExSockaddrs = unsafe extern \"system\" fn(PVOID, DWORD, DWORD, DWORD,\n                                                      *mut LPSOCKADDR, LPINT,\n                                                      *mut LPSOCKADDR, LPINT);\n\nimpl AcceptAddrsBuf {\n    /// Creates a new blank buffer ready to be passed to a call to\n    /// `accept_overlapped`.\n    pub fn new() -> AcceptAddrsBuf {\n        unsafe { mem::zeroed() }\n    }\n\n    /// Parses the data contained in this address buffer, returning the parsed\n    /// result if successful.\n    ///\n    /// This function can be called after a call to `accept_overlapped` has\n    /// succeeded to parse out the data that was written in.\n    pub fn parse(&self, socket: &TcpListener) -> io::Result<AcceptAddrs> {\n        let mut ret = AcceptAddrs {\n            local: 0 as *mut _, local_len: 0,\n            remote: 0 as *mut _, remote_len: 0,\n            _data: self,\n        };\n        let ptr = try!(GETACCEPTEXSOCKADDRS.get(socket.as_raw_socket()));\n        assert!(ptr != 0);\n        unsafe {\n            let get_sockaddrs = mem::transmute::<_, GetAcceptExSockaddrs>(ptr);\n            let (a, b, c, d) = self.args();\n            get_sockaddrs(a, b, c, d,\n                          &mut ret.local, &mut ret.local_len,\n                          &mut ret.remote, &mut ret.remote_len);\n            Ok(ret)\n        }\n    }\n\n    fn args(&self) -> (PVOID, DWORD, DWORD, DWORD) {\n        let remote_offset = unsafe {\n            &(*(0 as *const AcceptAddrsBuf)).remote as *const _ as usize\n        };\n        (self as *const _ as *mut _, 0, remote_offset as DWORD,\n         (mem::size_of_val(self) - remote_offset) as DWORD)\n    }\n}\n\nimpl<'a> AcceptAddrs<'a> {\n    /// Returns the local socket address contained in this buffer.\n    pub fn local(&self) -> Option<SocketAddr> {\n        unsafe { ptrs_to_socket_addr(self.local, self.local_len) }\n    }\n\n    /// Returns the remote socket address contained in this buffer.\n    pub fn remote(&self) -> Option<SocketAddr> {\n        unsafe { ptrs_to_socket_addr(self.remote, self.remote_len) }\n    }\n}\n\nimpl WsaExtension {\n    fn get(&self, socket: SOCKET) -> io::Result<usize> {\n        let prev = self.val.load(Ordering::SeqCst);\n        if prev != 0 && !cfg!(debug_assertions) {\n            return Ok(prev)\n        }\n        let mut ret = 0 as usize;\n        let mut bytes = 0;\n        let r = unsafe {\n            WSAIoctl(socket, SIO_GET_EXTENSION_FUNCTION_POINTER,\n                     &self.guid as *const _ as *mut _,\n                     mem::size_of_val(&self.guid) as DWORD,\n                     &mut ret as *mut _ as *mut _,\n                     mem::size_of_val(&ret) as DWORD,\n                     &mut bytes,\n                     0 as *mut _, None)\n        };\n        cvt(r, 0).map(|_| {\n            debug_assert_eq!(bytes as usize, mem::size_of_val(&ret));\n            debug_assert!(prev == 0 || prev == ret);\n            self.val.store(ret, Ordering::SeqCst);\n            ret\n        })\n\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use std::net::{TcpListener, UdpSocket, TcpStream, SocketAddr};\n    use std::thread;\n    use std::io::prelude::*;\n\n    use Overlapped;\n    use iocp::CompletionPort;\n    use net::{TcpStreamExt, UdpSocketExt, SocketAddrBuf};\n    use net::{TcpBuilderExt, TcpListenerExt, AcceptAddrsBuf};\n    use net2::TcpBuilder;\n\n    fn each_ip(f: &mut FnMut(SocketAddr)) {\n        f(t!(\"127.0.0.1:0\".parse()));\n        f(t!(\"[::1]:0\".parse()));\n    }\n\n    #[test]\n    fn tcp_read() {\n        each_ip(&mut |addr| {\n            let l = t!(TcpListener::bind(addr));\n            let addr = t!(l.local_addr());\n            let t = thread::spawn(move || {\n                let mut a = t!(l.accept()).0;\n                t!(a.write_all(&[1, 2, 3]));\n            });\n\n            let cp = t!(CompletionPort::new(1));\n            let s = t!(TcpStream::connect(addr));\n            t!(cp.add_socket(1, &s));\n\n            let mut b = [0; 10];\n            let a = Overlapped::zero();\n            unsafe {\n                t!(s.read_overlapped(&mut b, a.raw()));\n            }\n            let status = t!(cp.get(None));\n            assert_eq!(status.bytes_transferred(), 3);\n            assert_eq!(status.token(), 1);\n            assert_eq!(status.overlapped(), a.raw());\n            assert_eq!(&b[0..3], &[1, 2, 3]);\n\n            t!(t.join());\n        })\n    }\n\n    #[test]\n    fn tcp_write() {\n        each_ip(&mut |addr| {\n            let l = t!(TcpListener::bind(addr));\n            let addr = t!(l.local_addr());\n            let t = thread::spawn(move || {\n                let mut a = t!(l.accept()).0;\n                let mut b = [0; 10];\n                let n = t!(a.read(&mut b));\n                assert_eq!(n, 3);\n                assert_eq!(&b[0..3], &[1, 2, 3]);\n            });\n\n            let cp = t!(CompletionPort::new(1));\n            let s = t!(TcpStream::connect(addr));\n            t!(cp.add_socket(1, &s));\n\n            let b = [1, 2, 3];\n            let a = Overlapped::zero();\n            unsafe {\n                t!(s.write_overlapped(&b, a.raw()));\n            }\n            let status = t!(cp.get(None));\n            assert_eq!(status.bytes_transferred(), 3);\n            assert_eq!(status.token(), 1);\n            assert_eq!(status.overlapped(), a.raw());\n\n            t!(t.join());\n        })\n    }\n\n    #[test]\n    fn tcp_connect() {\n        each_ip(&mut |addr_template| {\n            let l = t!(TcpListener::bind(addr_template));\n            let addr = t!(l.local_addr());\n            let t = thread::spawn(move || {\n                t!(l.accept());\n            });\n\n            let cp = t!(CompletionPort::new(1));\n            let builder = match addr {\n                SocketAddr::V4(..) => t!(TcpBuilder::new_v4()),\n                SocketAddr::V6(..) => t!(TcpBuilder::new_v6()),\n            };\n            t!(cp.add_socket(1, &builder));\n\n            let a = Overlapped::zero();\n            t!(builder.bind(addr_template));\n            let (s, _) = unsafe {\n                t!(builder.connect_overlapped(&addr, &[], a.raw()))\n            };\n            let status = t!(cp.get(None));\n            assert_eq!(status.bytes_transferred(), 0);\n            assert_eq!(status.token(), 1);\n            assert_eq!(status.overlapped(), a.raw());\n            t!(s.connect_complete());\n\n            t!(t.join());\n        })\n    }\n\n    #[test]\n    fn udp_recv_from() {\n        each_ip(&mut |addr| {\n            let a = t!(UdpSocket::bind(addr));\n            let b = t!(UdpSocket::bind(addr));\n            let a_addr = t!(a.local_addr());\n            let b_addr = t!(b.local_addr());\n            let t = thread::spawn(move || {\n                t!(a.send_to(&[1, 2, 3], b_addr));\n            });\n\n            let cp = t!(CompletionPort::new(1));\n            t!(cp.add_socket(1, &b));\n\n            let mut buf = [0; 10];\n            let a = Overlapped::zero();\n            let mut addr = SocketAddrBuf::new();\n            unsafe {\n                t!(b.recv_from_overlapped(&mut buf, &mut addr, a.raw()));\n            }\n            let status = t!(cp.get(None));\n            assert_eq!(status.bytes_transferred(), 3);\n            assert_eq!(status.token(), 1);\n            assert_eq!(status.overlapped(), a.raw());\n            assert_eq!(&buf[..3], &[1, 2, 3]);\n            assert_eq!(addr.to_socket_addr(), Some(a_addr));\n\n            t!(t.join());\n        })\n    }\n\n    #[test]\n    fn udp_recv() {\n        each_ip(&mut |addr| {\n            let a = t!(UdpSocket::bind(addr));\n            let b = t!(UdpSocket::bind(addr));\n            let a_addr = t!(a.local_addr());\n            let b_addr = t!(b.local_addr());\n            assert!(b.connect(a_addr).is_ok());\n            assert!(a.connect(b_addr).is_ok());\n            let t = thread::spawn(move || {\n                t!(a.send_to(&[1, 2, 3], b_addr));\n            });\n\n            let cp = t!(CompletionPort::new(1));\n            t!(cp.add_socket(1, &b));\n\n            let mut buf = [0; 10];\n            let a = Overlapped::zero();\n            unsafe {\n                t!(b.recv_overlapped(&mut buf, a.raw()));\n            }\n            let status = t!(cp.get(None));\n            assert_eq!(status.bytes_transferred(), 3);\n            assert_eq!(status.token(), 1);\n            assert_eq!(status.overlapped(), a.raw());\n            assert_eq!(&buf[..3], &[1, 2, 3]);\n\n            t!(t.join());\n        })\n    }\n\n    #[test]\n    fn udp_send_to() {\n        each_ip(&mut |addr| {\n            let a = t!(UdpSocket::bind(addr));\n            let b = t!(UdpSocket::bind(addr));\n            let a_addr = t!(a.local_addr());\n            let b_addr = t!(b.local_addr());\n            let t = thread::spawn(move || {\n                let mut b = [0; 100];\n                let (n, addr) = t!(a.recv_from(&mut b));\n                assert_eq!(n, 3);\n                assert_eq!(addr, b_addr);\n                assert_eq!(&b[..3], &[1, 2, 3]);\n            });\n\n            let cp = t!(CompletionPort::new(1));\n            t!(cp.add_socket(1, &b));\n\n            let a = Overlapped::zero();\n            unsafe {\n                t!(b.send_to_overlapped(&[1, 2, 3], &a_addr, a.raw()));\n            }\n            let status = t!(cp.get(None));\n            assert_eq!(status.bytes_transferred(), 3);\n            assert_eq!(status.token(), 1);\n            assert_eq!(status.overlapped(), a.raw());\n\n            t!(t.join());\n        })\n    }\n\n    #[test]\n    fn udp_send() {\n        each_ip(&mut |addr| {\n            let a = t!(UdpSocket::bind(addr));\n            let b = t!(UdpSocket::bind(addr));\n            let a_addr = t!(a.local_addr());\n            let b_addr = t!(b.local_addr());\n            assert!(b.connect(a_addr).is_ok());\n            assert!(a.connect(b_addr).is_ok());\n            let t = thread::spawn(move || {\n                let mut b = [0; 100];\n                let (n, addr) = t!(a.recv_from(&mut b));\n                assert_eq!(n, 3);\n                assert_eq!(addr, b_addr);\n                assert_eq!(&b[..3], &[1, 2, 3]);\n            });\n\n            let cp = t!(CompletionPort::new(1));\n            t!(cp.add_socket(1, &b));\n\n            let a = Overlapped::zero();\n            unsafe {\n                t!(b.send_overlapped(&[1, 2, 3], a.raw()));\n            }\n            let status = t!(cp.get(None));\n            assert_eq!(status.bytes_transferred(), 3);\n            assert_eq!(status.token(), 1);\n            assert_eq!(status.overlapped(), a.raw());\n\n            t!(t.join());\n        })\n    }\n\n    #[test]\n    fn tcp_accept() {\n        each_ip(&mut |addr_template| {\n            let l = t!(TcpListener::bind(addr_template));\n            let addr = t!(l.local_addr());\n            let t = thread::spawn(move || {\n                let socket = t!(TcpStream::connect(addr));\n                (socket.local_addr().unwrap(), socket.peer_addr().unwrap())\n            });\n\n            let cp = t!(CompletionPort::new(1));\n            let builder = match addr {\n                SocketAddr::V4(..) => t!(TcpBuilder::new_v4()),\n                SocketAddr::V6(..) => t!(TcpBuilder::new_v6()),\n            };\n            t!(cp.add_socket(1, &l));\n\n            let a = Overlapped::zero();\n            let mut addrs = AcceptAddrsBuf::new();\n            let (s, _) = unsafe {\n                t!(l.accept_overlapped(&builder, &mut addrs, a.raw()))\n            };\n            let status = t!(cp.get(None));\n            assert_eq!(status.bytes_transferred(), 0);\n            assert_eq!(status.token(), 1);\n            assert_eq!(status.overlapped(), a.raw());\n            t!(l.accept_complete(&s));\n\n            let (remote, local) = t!(t.join());\n            let addrs = addrs.parse(&l).unwrap();\n            assert_eq!(addrs.local(), Some(local));\n            assert_eq!(addrs.remote(), Some(remote));\n        })\n    }\n}\n"
  },
  {
    "project": "miow",
    "target": 1,
    "commit_id": "2783715269d56a0020160179c0f2ba883d12d874",
    "func": "//! Extensions and types for the standard networking primitives.\n//!\n//! This module contains a number of extension traits for the types in\n//! `std::net` for Windows-specific functionality.\n\nuse std::cmp;\nuse std::io;\nuse std::mem;\nuse std::sync::atomic::{AtomicUsize, Ordering, ATOMIC_USIZE_INIT};\nuse std::net::{TcpStream, UdpSocket, SocketAddr, TcpListener};\nuse std::net::{SocketAddrV4, Ipv4Addr, SocketAddrV6, Ipv6Addr};\nuse std::os::windows::prelude::*;\n\nuse net2::TcpBuilder;\nuse winapi::*;\nuse winapi::shared::inaddr::{in_addr_S_un, IN_ADDR};\nuse winapi::shared::in6addr::{in6_addr_u, IN6_ADDR};\nuse ws2_32::*;\n\n/// A type to represent a buffer in which a socket address will be stored.\n///\n/// This type is used with the `recv_from_overlapped` function on the\n/// `UdpSocketExt` trait to provide space for the overlapped I/O operation to\n/// fill in the address upon completion.\n#[derive(Clone, Copy)]\npub struct SocketAddrBuf {\n    buf: SOCKADDR_STORAGE,\n    len: c_int,\n}\n\n/// A type to represent a buffer in which an accepted socket's address will be\n/// stored.\n///\n/// This type is used with the `accept_overlapped` method on the\n/// `TcpListenerExt` trait to provide space for the overlapped I/O operation to\n/// fill in the socket addresses upon completion.\n#[repr(C)]\npub struct AcceptAddrsBuf {\n    // For AcceptEx we've got the restriction that the addresses passed in that\n    // buffer need to be at least 16 bytes more than the maximum address length\n    // for the protocol in question, so add some extra here and there\n    local: SOCKADDR_STORAGE,\n    _pad1: [u8; 16],\n    remote: SOCKADDR_STORAGE,\n    _pad2: [u8; 16],\n}\n\n/// The parsed return value of `AcceptAddrsBuf`.\npub struct AcceptAddrs<'a> {\n    local: LPSOCKADDR,\n    local_len: c_int,\n    remote: LPSOCKADDR,\n    remote_len: c_int,\n    _data: &'a AcceptAddrsBuf,\n}\n\nstruct WsaExtension {\n    guid: GUID,\n    val: AtomicUsize,\n}\n\n/// Additional methods for the `TcpStream` type in the standard library.\npub trait TcpStreamExt {\n    /// Execute an overlapped read I/O operation on this TCP stream.\n    ///\n    /// This function will issue an overlapped I/O read (via `WSARecv`) on this\n    /// socket. The provided buffer will be filled in when the operation\n    /// completes and the given `OVERLAPPED` instance is used to track the\n    /// overlapped operation.\n    ///\n    /// If the operation succeeds, `Ok(Some(n))` is returned indicating how\n    /// many bytes were read. If the operation returns an error indicating that\n    /// the I/O is currently pending, `Ok(None)` is returned. Otherwise, the\n    /// error associated with the operation is returned and no overlapped\n    /// operation is enqueued.\n    ///\n    /// The number of bytes read will be returned as part of the completion\n    /// notification when the I/O finishes.\n    ///\n    /// # Unsafety\n    ///\n    /// This function is unsafe because the kernel requires that the `buf` and\n    /// `overlapped` pointers are valid until the end of the I/O operation. The\n    /// kernel also requires that `overlapped` is unique for this I/O operation\n    /// and is not in use for any other I/O.\n    ///\n    /// To safely use this function callers must ensure that these two input\n    /// pointers are valid until the I/O operation is completed, typically via\n    /// completion ports and waiting to receive the completion notification on\n    /// the port.\n    unsafe fn read_overlapped(&self,\n                              buf: &mut [u8],\n                              overlapped: *mut OVERLAPPED)\n                              -> io::Result<Option<usize>>;\n\n    /// Execute an overlapped write I/O operation on this TCP stream.\n    ///\n    /// This function will issue an overlapped I/O write (via `WSASend`) on this\n    /// socket. The provided buffer will be written when the operation completes\n    /// and the given `OVERLAPPED` instance is used to track the overlapped\n    /// operation.\n    ///\n    /// If the operation succeeds, `Ok(Some(n))` is returned where `n` is the\n    /// number of bytes that were written. If the operation returns an error\n    /// indicating that the I/O is currently pending, `Ok(None)` is returned.\n    /// Otherwise, the error associated with the operation is returned and no\n    /// overlapped operation is enqueued.\n    ///\n    /// The number of bytes written will be returned as part of the completion\n    /// notification when the I/O finishes.\n    ///\n    /// # Unsafety\n    ///\n    /// This function is unsafe because the kernel requires that the `buf` and\n    /// `overlapped` pointers are valid until the end of the I/O operation. The\n    /// kernel also requires that `overlapped` is unique for this I/O operation\n    /// and is not in use for any other I/O.\n    ///\n    /// To safely use this function callers must ensure that these two input\n    /// pointers are valid until the I/O operation is completed, typically via\n    /// completion ports and waiting to receive the completion notification on\n    /// the port.\n    unsafe fn write_overlapped(&self,\n                               buf: &[u8],\n                               overlapped: *mut OVERLAPPED)\n                               -> io::Result<Option<usize>>;\n\n    /// Execute a connection operation for this socket.\n    ///\n    /// For more information about this method, see the\n    /// [`TcpBuilderExt::connect_overlapped`][link] documentation.\n    ///\n    /// [link]: trait.TcpBuilderExt.html#tymethod.connect_overlapped\n    unsafe fn connect_overlapped(&self,\n                                 addr: &SocketAddr,\n                                 buf: &[u8],\n                                 overlapped: *mut OVERLAPPED)\n                                 -> io::Result<Option<usize>>;\n\n    /// Once a `connect_overlapped` has finished, this function needs to be\n    /// called to finish the connect operation.\n    ///\n    /// Currently this just calls `setsockopt` with `SO_UPDATE_CONNECT_CONTEXT`\n    /// to ensure that further functions like `getpeername` and `getsockname`\n    /// work correctly.\n    fn connect_complete(&self) -> io::Result<()>;\n\n    /// Calls the `GetOverlappedResult` function to get the result of an\n    /// overlapped operation for this handle.\n    ///\n    /// This function takes the `OVERLAPPED` argument which must have been used\n    /// to initiate an overlapped I/O operation, and returns either the\n    /// successful number of bytes transferred during the operation or an error\n    /// if one occurred, along with the results of the `lpFlags` parameter of\n    /// the relevant operation, if applicable.\n    ///\n    /// # Unsafety\n    ///\n    /// This function is unsafe as `overlapped` must have previously been used\n    /// to execute an operation for this handle, and it must also be a valid\n    /// pointer to an `OVERLAPPED` instance.\n    ///\n    /// # Panics\n    ///\n    /// This function will panic\n    unsafe fn result(&self, overlapped: *mut OVERLAPPED)\n                     -> io::Result<(usize, u32)>;\n}\n\n/// Additional methods for the `UdpSocket` type in the standard library.\npub trait UdpSocketExt {\n    /// Execute an overlapped receive I/O operation on this UDP socket.\n    ///\n    /// This function will issue an overlapped I/O read (via `WSARecvFrom`) on\n    /// this socket. The provided buffer will be filled in when the operation\n    /// completes, the source from where the data came from will be written to\n    /// `addr`, and the given `OVERLAPPED` instance is used to track the\n    /// overlapped operation.\n    ///\n    /// If the operation succeeds, `Ok(Some(n))` is returned where `n` is the\n    /// number of bytes that were read. If the operation returns an error\n    /// indicating that the I/O is currently pending, `Ok(None)` is returned.\n    /// Otherwise, the error associated with the operation is returned and no\n    /// overlapped operation is enqueued.\n    ///\n    /// The number of bytes read will be returned as part of the completion\n    /// notification when the I/O finishes.\n    ///\n    /// # Unsafety\n    ///\n    /// This function is unsafe because the kernel requires that the `buf`,\n    /// `addr`, and `overlapped` pointers are valid until the end of the I/O\n    /// operation. The kernel also requires that `overlapped` is unique for this\n    /// I/O operation and is not in use for any other I/O.\n    ///\n    /// To safely use this function callers must ensure that these two input\n    /// pointers are valid until the I/O operation is completed, typically via\n    /// completion ports and waiting to receive the completion notification on\n    /// the port.\n    unsafe fn recv_from_overlapped(&self,\n                                   buf: &mut [u8],\n                                   addr: *mut SocketAddrBuf,\n                                   overlapped: *mut OVERLAPPED)\n                                   -> io::Result<Option<usize>>;\n\n    /// Execute an overlapped receive I/O operation on this UDP socket.\n    ///\n    /// This function will issue an overlapped I/O read (via `WSARecv`) on\n    /// this socket. The provided buffer will be filled in when the operation\n    /// completes, the source from where the data came from will be written to\n    /// `addr`, and the given `OVERLAPPED` instance is used to track the\n    /// overlapped operation.\n    ///\n    /// If the operation succeeds, `Ok(Some(n))` is returned where `n` is the\n    /// number of bytes that were read. If the operation returns an error\n    /// indicating that the I/O is currently pending, `Ok(None)` is returned.\n    /// Otherwise, the error associated with the operation is returned and no\n    /// overlapped operation is enqueued.\n    ///\n    /// The number of bytes read will be returned as part of the completion\n    /// notification when the I/O finishes.\n    ///\n    /// # Unsafety\n    ///\n    /// This function is unsafe because the kernel requires that the `buf`,\n    /// and `overlapped` pointers are valid until the end of the I/O\n    /// operation. The kernel also requires that `overlapped` is unique for this\n    /// I/O operation and is not in use for any other I/O.\n    ///\n    /// To safely use this function callers must ensure that these two input\n    /// pointers are valid until the I/O operation is completed, typically via\n    /// completion ports and waiting to receive the completion notification on\n    /// the port.\n    unsafe fn recv_overlapped(&self,\n                              buf: &mut [u8],\n                              overlapped: *mut OVERLAPPED)\n                              -> io::Result<Option<usize>>;\n\n    /// Execute an overlapped send I/O operation on this UDP socket.\n    ///\n    /// This function will issue an overlapped I/O write (via `WSASendTo`) on\n    /// this socket to the address specified by `addr`. The provided buffer will\n    /// be written when the operation completes and the given `OVERLAPPED`\n    /// instance is used to track the overlapped operation.\n    ///\n    /// If the operation succeeds, `Ok(Some(n0)` is returned where `n` byte\n    /// were written. If the operation returns an error indicating that the I/O\n    /// is currently pending, `Ok(None)` is returned. Otherwise, the error\n    /// associated with the operation is returned and no overlapped operation\n    /// is enqueued.\n    ///\n    /// The number of bytes written will be returned as part of the completion\n    /// notification when the I/O finishes.\n    ///\n    /// # Unsafety\n    ///\n    /// This function is unsafe because the kernel requires that the `buf` and\n    /// `overlapped` pointers are valid until the end of the I/O operation. The\n    /// kernel also requires that `overlapped` is unique for this I/O operation\n    /// and is not in use for any other I/O.\n    ///\n    /// To safely use this function callers must ensure that these two input\n    /// pointers are valid until the I/O operation is completed, typically via\n    /// completion ports and waiting to receive the completion notification on\n    /// the port.\n    unsafe fn send_to_overlapped(&self,\n                                 buf: &[u8],\n                                 addr: &SocketAddr,\n                                 overlapped: *mut OVERLAPPED)\n                                 -> io::Result<Option<usize>>;\n\n    /// Execute an overlapped send I/O operation on this UDP socket.\n    ///\n    /// This function will issue an overlapped I/O write (via `WSASend`) on\n    /// this socket to the address it was previously connected to. The provided \n    /// buffer will be written when the operation completes and the given `OVERLAPPED`\n    /// instance is used to track the overlapped operation.\n    ///\n    /// If the operation succeeds, `Ok(Some(n0)` is returned where `n` byte\n    /// were written. If the operation returns an error indicating that the I/O\n    /// is currently pending, `Ok(None)` is returned. Otherwise, the error\n    /// associated with the operation is returned and no overlapped operation\n    /// is enqueued.\n    ///\n    /// The number of bytes written will be returned as part of the completion\n    /// notification when the I/O finishes.\n    ///\n    /// # Unsafety\n    ///\n    /// This function is unsafe because the kernel requires that the `buf` and\n    /// `overlapped` pointers are valid until the end of the I/O operation. The\n    /// kernel also requires that `overlapped` is unique for this I/O operation\n    /// and is not in use for any other I/O.\n    ///\n    /// To safely use this function callers must ensure that these two input\n    /// pointers are valid until the I/O operation is completed, typically via\n    /// completion ports and waiting to receive the completion notification on\n    /// the port.\n    unsafe fn send_overlapped(&self,\n                                 buf: &[u8],\n                                 overlapped: *mut OVERLAPPED)\n                                 -> io::Result<Option<usize>>;\n \n    /// Calls the `GetOverlappedResult` function to get the result of an\n    /// overlapped operation for this handle.\n    ///\n    /// This function takes the `OVERLAPPED` argument which must have been used\n    /// to initiate an overlapped I/O operation, and returns either the\n    /// successful number of bytes transferred during the operation or an error\n    /// if one occurred, along with the results of the `lpFlags` parameter of\n    /// the relevant operation, if applicable.\n    ///\n    /// # Unsafety\n    ///\n    /// This function is unsafe as `overlapped` must have previously been used\n    /// to execute an operation for this handle, and it must also be a valid\n    /// pointer to an `OVERLAPPED` instance.\n    ///\n    /// # Panics\n    ///\n    /// This function will panic\n    unsafe fn result(&self, overlapped: *mut OVERLAPPED)\n                     -> io::Result<(usize, u32)>;\n}\n\n/// Additional methods for the `TcpBuilder` type in the `net2` library.\npub trait TcpBuilderExt {\n    /// Attempt to consume the internal socket in this builder by executing an\n    /// overlapped connect operation.\n    ///\n    /// This function will issue a connect operation to the address specified on\n    /// the underlying socket, flagging it as an overlapped operation which will\n    /// complete asynchronously. If successful this function will return the\n    /// corresponding TCP stream.\n    ///\n    /// The `buf` argument provided is an initial buffer of data that should be\n    /// sent after the connection is initiated. It's acceptable to\n    /// pass an empty slice here.\n    ///\n    /// This function will also return whether the connect immediately\n    /// succeeded or not. If `None` is returned then the I/O operation is still\n    /// pending and will complete at a later date, and if `Some(bytes)` is\n    /// returned then that many bytes were transferred.\n    ///\n    /// Note that to succeed this requires that the underlying socket has\n    /// previously been bound via a call to `bind` to a local address.\n    ///\n    /// # Unsafety\n    ///\n    /// This function is unsafe because the kernel requires that the\n    /// `overlapped` and `buf` pointers to be  valid until the end of the I/O\n    /// operation. The kernel also requires that `overlapped` is unique for\n    /// this I/O operation and is not in use for any other I/O.\n    ///\n    /// To safely use this function callers must ensure that this pointer is\n    /// valid until the I/O operation is completed, typically via completion\n    /// ports and waiting to receive the completion notification on the port.\n    unsafe fn connect_overlapped(&self,\n                                 addr: &SocketAddr,\n                                 buf: &[u8],\n                                 overlapped: *mut OVERLAPPED)\n                                 -> io::Result<(TcpStream, Option<usize>)>;\n\n    /// Calls the `GetOverlappedResult` function to get the result of an\n    /// overlapped operation for this handle.\n    ///\n    /// This function takes the `OVERLAPPED` argument which must have been used\n    /// to initiate an overlapped I/O operation, and returns either the\n    /// successful number of bytes transferred during the operation or an error\n    /// if one occurred, along with the results of the `lpFlags` parameter of\n    /// the relevant operation, if applicable.\n    ///\n    /// # Unsafety\n    ///\n    /// This function is unsafe as `overlapped` must have previously been used\n    /// to execute an operation for this handle, and it must also be a valid\n    /// pointer to an `OVERLAPPED` instance.\n    ///\n    /// # Panics\n    ///\n    /// This function will panic\n    unsafe fn result(&self, overlapped: *mut OVERLAPPED)\n                     -> io::Result<(usize, u32)>;\n}\n\n/// Additional methods for the `TcpListener` type in the standard library.\npub trait TcpListenerExt {\n    /// Perform an accept operation on this listener, accepting a connection in\n    /// an overlapped fashion.\n    ///\n    /// This function will issue an I/O request to accept an incoming connection\n    /// with the specified overlapped instance. The `socket` provided must be a\n    /// configured but not bound or connected socket, and if successful this\n    /// will consume the internal socket of the builder to return a TCP stream.\n    ///\n    /// The `addrs` buffer provided will be filled in with the local and remote\n    /// addresses of the connection upon completion.\n    ///\n    /// If the accept succeeds immediately, `Ok(stream, true)` is returned. If\n    /// the connect indicates that the I/O is currently pending, `Ok(stream,\n    /// false)` is returned. Otherwise, the error associated with the operation\n    /// is returned and no overlapped operation is enqueued.\n    ///\n    /// # Unsafety\n    ///\n    /// This function is unsafe because the kernel requires that the\n    /// `addrs` and `overlapped` pointers are valid until the end of the I/O\n    /// operation. The kernel also requires that `overlapped` is unique for this\n    /// I/O operation and is not in use for any other I/O.\n    ///\n    /// To safely use this function callers must ensure that the pointers are\n    /// valid until the I/O operation is completed, typically via completion\n    /// ports and waiting to receive the completion notification on the port.\n    unsafe fn accept_overlapped(&self,\n                                socket: &TcpBuilder,\n                                addrs: &mut AcceptAddrsBuf,\n                                overlapped: *mut OVERLAPPED)\n                                -> io::Result<(TcpStream, bool)>;\n\n    /// Once an `accept_overlapped` has finished, this function needs to be\n    /// called to finish the accept operation.\n    ///\n    /// Currently this just calls `setsockopt` with `SO_UPDATE_ACCEPT_CONTEXT`\n    /// to ensure that further functions like `getpeername` and `getsockname`\n    /// work correctly.\n    fn accept_complete(&self, socket: &TcpStream) -> io::Result<()>;\n\n    /// Calls the `GetOverlappedResult` function to get the result of an\n    /// overlapped operation for this handle.\n    ///\n    /// This function takes the `OVERLAPPED` argument which must have been used\n    /// to initiate an overlapped I/O operation, and returns either the\n    /// successful number of bytes transferred during the operation or an error\n    /// if one occurred, along with the results of the `lpFlags` parameter of\n    /// the relevant operation, if applicable.\n    ///\n    /// # Unsafety\n    ///\n    /// This function is unsafe as `overlapped` must have previously been used\n    /// to execute an operation for this handle, and it must also be a valid\n    /// pointer to an `OVERLAPPED` instance.\n    ///\n    /// # Panics\n    ///\n    /// This function will panic\n    unsafe fn result(&self, overlapped: *mut OVERLAPPED)\n                     -> io::Result<(usize, u32)>;\n}\n\n#[doc(hidden)]\ntrait NetInt {\n    fn from_be(i: Self) -> Self;\n    fn to_be(&self) -> Self;\n}\nmacro_rules! doit {\n    ($($t:ident)*) => ($(impl NetInt for $t {\n        fn from_be(i: Self) -> Self { <$t>::from_be(i) }\n        fn to_be(&self) -> Self { <$t>::to_be(*self) }\n    })*)\n}\ndoit! { i8 i16 i32 i64 isize u8 u16 u32 u64 usize }\n\n// fn hton<I: NetInt>(i: I) -> I { i.to_be() }\nfn ntoh<I: NetInt>(i: I) -> I { I::from_be(i) }\n\nfn last_err() -> io::Result<Option<usize>> {\n    let err = unsafe { WSAGetLastError() };\n    if err == WSA_IO_PENDING as i32 {\n        Ok(None)\n    } else {\n        Err(io::Error::from_raw_os_error(err))\n    }\n}\n\nfn cvt(i: c_int, size: DWORD) -> io::Result<Option<usize>> {\n    if i == SOCKET_ERROR {\n        last_err()\n    } else {\n        Ok(Some(size as usize))\n    }\n}\n\n/// A type with the same memory layout as `SOCKADDR`. Used in converting Rust level\n/// SocketAddr* types into their system representation. The benefit of this specific\n/// type over using `SOCKADDR_STORAGE` is that this type is exactly as large as it\n/// needs to be and not a lot larger. And it can be initialized cleaner from Rust.\n#[repr(C)]\npub(crate) union SocketAddrCRepr {\n    v4: SOCKADDR_IN,\n    v6: SOCKADDR_IN6_LH,\n}\n\nimpl SocketAddrCRepr {\n    pub(crate) fn as_ptr(&self) -> *const SOCKADDR {\n        self as *const _ as *const SOCKADDR\n    }\n}\n\nfn socket_addr_to_ptrs(addr: &SocketAddr) -> (SocketAddrCRepr, c_int) {\n    match *addr {\n        SocketAddr::V4(ref a) => {\n            let sin_addr = unsafe {\n                let mut s_un = mem::zeroed::<in_addr_S_un>();\n                *s_un.S_addr_mut() = u32::from_ne_bytes(a.ip().octets());\n                IN_ADDR { S_un: s_un }\n            };\n\n            let sockaddr_in = SOCKADDR_IN {\n                sin_family: AF_INET as ADDRESS_FAMILY,\n                sin_port: a.port().to_be(),\n                sin_addr,\n                sin_zero: [0; 8],\n            };\n\n            let sockaddr = SocketAddrCRepr { v4: sockaddr_in };\n            (sockaddr, mem::size_of::<SOCKADDR_IN>() as c_int)\n        }\n        SocketAddr::V6(ref a) => {\n            let sin6_addr = unsafe {\n                let mut u = mem::zeroed::<in6_addr_u>();\n                *u.Byte_mut() = a.ip().octets();\n                IN6_ADDR { u }\n            };\n            let u = unsafe {\n                let mut u = mem::zeroed::<SOCKADDR_IN6_LH_u>();\n                *u.sin6_scope_id_mut() = a.scope_id();\n                u\n            };\n\n            let sockaddr_in6 = SOCKADDR_IN6_LH {\n                sin6_family: AF_INET6 as ADDRESS_FAMILY,\n                sin6_port: a.port().to_be(),\n                sin6_addr,\n                sin6_flowinfo: a.flowinfo(),\n                u,\n            };\n\n            let sockaddr = SocketAddrCRepr { v6: sockaddr_in6 };\n            (sockaddr, mem::size_of::<SOCKADDR_IN6_LH>() as c_int)\n        }\n    }\n}\n\nunsafe fn ptrs_to_socket_addr(ptr: *const SOCKADDR,\n                              len: c_int) -> Option<SocketAddr> {\n    if (len as usize) < mem::size_of::<c_int>() {\n        return None\n    }\n    match (*ptr).sa_family as i32 {\n        AF_INET if len as usize >= mem::size_of::<SOCKADDR_IN>() => {\n            let b = &*(ptr as *const SOCKADDR_IN);\n            let ip = ntoh(b.sin_addr.S_un);\n            let ip = Ipv4Addr::new((ip >> 24) as u8,\n                                   (ip >> 16) as u8,\n                                   (ip >>  8) as u8,\n                                   (ip >>  0) as u8);\n            Some(SocketAddr::V4(SocketAddrV4::new(ip, ntoh(b.sin_port))))\n        }\n        AF_INET6 if len as usize >= mem::size_of::<sockaddr_in6>() => {\n            let b = &*(ptr as *const sockaddr_in6);\n            let arr = &b.sin6_addr.s6_addr;\n            let ip = Ipv6Addr::new(\n                ((arr[0] as u16) << 8) | (arr[1] as u16),\n                ((arr[2] as u16) << 8) | (arr[3] as u16),\n                ((arr[4] as u16) << 8) | (arr[5] as u16),\n                ((arr[6] as u16) << 8) | (arr[7] as u16),\n                ((arr[8] as u16) << 8) | (arr[9] as u16),\n                ((arr[10] as u16) << 8) | (arr[11] as u16),\n                ((arr[12] as u16) << 8) | (arr[13] as u16),\n                ((arr[14] as u16) << 8) | (arr[15] as u16));\n            let addr = SocketAddrV6::new(ip, ntoh(b.sin6_port),\n                                         ntoh(b.sin6_flowinfo),\n                                         ntoh(b.sin6_scope_id));\n            Some(SocketAddr::V6(addr))\n        }\n        _ => None\n    }\n}\n\nunsafe fn slice2buf(slice: &[u8]) -> WSABUF {\n    WSABUF {\n        len: cmp::min(slice.len(), <u_long>::max_value() as usize) as u_long,\n        buf: slice.as_ptr() as *mut _,\n    }\n}\n\nunsafe fn result(socket: SOCKET, overlapped: *mut OVERLAPPED)\n                 -> io::Result<(usize, u32)> {\n    let mut transferred = 0;\n    let mut flags = 0;\n    let r = WSAGetOverlappedResult(socket,\n                                   overlapped,\n                                   &mut transferred,\n                                   FALSE,\n                                   &mut flags);\n    if r == 0 {\n        Err(io::Error::last_os_error())\n    } else {\n        Ok((transferred as usize, flags))\n    }\n}\n\nimpl TcpStreamExt for TcpStream {\n    unsafe fn read_overlapped(&self,\n                              buf: &mut [u8],\n                              overlapped: *mut OVERLAPPED)\n                              -> io::Result<Option<usize>> {\n        let mut buf = slice2buf(buf);\n        let mut flags = 0;\n        let mut bytes_read: DWORD = 0;\n        let r = WSARecv(self.as_raw_socket(), &mut buf, 1,\n                        &mut bytes_read, &mut flags, overlapped, None);\n        cvt(r, bytes_read)\n    }\n\n    unsafe fn write_overlapped(&self,\n                               buf: &[u8],\n                               overlapped: *mut OVERLAPPED)\n                               -> io::Result<Option<usize>> {\n        let mut buf = slice2buf(buf);\n        let mut bytes_written = 0;\n\n        // Note here that we capture the number of bytes written. The\n        // documentation on MSDN, however, states:\n        //\n        // > Use NULL for this parameter if the lpOverlapped parameter is not\n        // > NULL to avoid potentially erroneous results. This parameter can be\n        // > NULL only if the lpOverlapped parameter is not NULL.\n        //\n        // If we're not passing a null overlapped pointer here, then why are we\n        // then capturing the number of bytes! Well so it turns out that this is\n        // clearly faster to learn the bytes here rather than later calling\n        // `WSAGetOverlappedResult`, and in practice almost all implementations\n        // use this anyway [1].\n        //\n        // As a result we use this to and report back the result.\n        //\n        // [1]: https://github.com/carllerche/mio/pull/520#issuecomment-273983823\n        let r = WSASend(self.as_raw_socket(), &mut buf, 1,\n                        &mut bytes_written, 0, overlapped, None);\n        cvt(r, bytes_written)\n    }\n\n    unsafe fn connect_overlapped(&self,\n                                 addr: &SocketAddr,\n                                 buf: &[u8],\n                                 overlapped: *mut OVERLAPPED)\n                                 -> io::Result<Option<usize>> {\n        connect_overlapped(self.as_raw_socket(), addr, buf, overlapped)\n    }\n\n    fn connect_complete(&self) -> io::Result<()> {\n        const SO_UPDATE_CONNECT_CONTEXT: c_int = 0x7010;\n        let result = unsafe {\n            setsockopt(self.as_raw_socket(),\n                       SOL_SOCKET,\n                       SO_UPDATE_CONNECT_CONTEXT,\n                       0 as *const _,\n                       0)\n        };\n        if result == 0 {\n            Ok(())\n        } else {\n            Err(io::Error::last_os_error())\n        }\n    }\n\n    unsafe fn result(&self, overlapped: *mut OVERLAPPED)\n                     -> io::Result<(usize, u32)> {\n        result(self.as_raw_socket(), overlapped)\n    }\n}\n\nunsafe fn connect_overlapped(socket: SOCKET,\n                             addr: &SocketAddr,\n                             buf: &[u8],\n                             overlapped: *mut OVERLAPPED)\n                             -> io::Result<Option<usize>> {\n    static CONNECTEX: WsaExtension = WsaExtension {\n        guid: GUID {\n            Data1: 0x25a207b9,\n            Data2: 0xddf3,\n            Data3: 0x4660,\n            Data4: [0x8e, 0xe9, 0x76, 0xe5, 0x8c, 0x74, 0x06, 0x3e],\n        },\n        val: ATOMIC_USIZE_INIT,\n    };\n    type ConnectEx = unsafe extern \"system\" fn(SOCKET, *const SOCKADDR,\n                                               c_int, PVOID, DWORD, LPDWORD,\n                                               LPOVERLAPPED) -> BOOL;\n\n    let ptr = try!(CONNECTEX.get(socket));\n    assert!(ptr != 0);\n    let connect_ex = mem::transmute::<_, ConnectEx>(ptr);\n\n    let (addr_buf, addr_len) = socket_addr_to_ptrs(addr);\n    let mut bytes_sent: DWORD = 0;\n    let r = connect_ex(socket, addr_buf.as_ptr(), addr_len,\n                       buf.as_ptr() as *mut _,\n                       buf.len() as u32,\n                       &mut bytes_sent, overlapped);\n    if r == TRUE {\n        Ok(Some(bytes_sent as usize))\n    } else {\n        last_err()\n    }\n}\n\nimpl UdpSocketExt for UdpSocket {\n    unsafe fn recv_from_overlapped(&self,\n                                   buf: &mut [u8],\n                                   addr: *mut SocketAddrBuf,\n                                   overlapped: *mut OVERLAPPED)\n                                   -> io::Result<Option<usize>> {\n        let mut buf = slice2buf(buf);\n        let mut flags = 0;\n        let mut received_bytes: DWORD = 0;\n        let r = WSARecvFrom(self.as_raw_socket(), &mut buf, 1,\n                            &mut received_bytes, &mut flags,\n                            &mut (*addr).buf as *mut _ as *mut _,\n                            &mut (*addr).len,\n                            overlapped, None);\n        cvt(r, received_bytes)\n    }\n\n    unsafe fn recv_overlapped(&self,\n                              buf: &mut [u8],\n                              overlapped: *mut OVERLAPPED)\n                              -> io::Result<Option<usize>> {\n        let mut buf = slice2buf(buf);\n        let mut flags = 0;\n        let mut received_bytes: DWORD = 0;\n        let r = WSARecv(self.as_raw_socket(), &mut buf, 1,\n                            &mut received_bytes, &mut flags,\n                            overlapped, None);\n        cvt(r, received_bytes)\n    }\n\n    unsafe fn send_to_overlapped(&self,\n                                 buf: &[u8],\n                                 addr: &SocketAddr,\n                                 overlapped: *mut OVERLAPPED)\n                                 -> io::Result<Option<usize>> {\n        let (addr_buf, addr_len) = socket_addr_to_ptrs(addr);\n        let mut buf = slice2buf(buf);\n        let mut sent_bytes = 0;\n        let r = WSASendTo(self.as_raw_socket(), &mut buf, 1,\n                          &mut sent_bytes, 0,\n                          addr_buf.as_ptr() as *const _, addr_len,\n                          overlapped, None);\n        cvt(r, sent_bytes)\n    }\n\n    unsafe fn send_overlapped(&self,\n                              buf: &[u8],\n                              overlapped: *mut OVERLAPPED)\n                              -> io::Result<Option<usize>> {\n        let mut buf = slice2buf(buf);\n        let mut sent_bytes = 0;\n        let r = WSASend(self.as_raw_socket(), &mut buf, 1,\n                          &mut sent_bytes, 0,\n                          overlapped, None);\n        cvt(r, sent_bytes)\n    }\n\n    unsafe fn result(&self, overlapped: *mut OVERLAPPED)\n                     -> io::Result<(usize, u32)> {\n        result(self.as_raw_socket(), overlapped)\n    }\n}\n\nimpl TcpBuilderExt for TcpBuilder {\n    unsafe fn connect_overlapped(&self,\n                                 addr: &SocketAddr,\n                                 buf: &[u8],\n                                 overlapped: *mut OVERLAPPED)\n                                 -> io::Result<(TcpStream, Option<usize>)> {\n        connect_overlapped(self.as_raw_socket(), addr, buf, overlapped).map(|s| {\n            (self.to_tcp_stream().unwrap(), s)\n        })\n    }\n\n    unsafe fn result(&self, overlapped: *mut OVERLAPPED)\n                     -> io::Result<(usize, u32)> {\n        result(self.as_raw_socket(), overlapped)\n    }\n}\n\nimpl TcpListenerExt for TcpListener {\n    unsafe fn accept_overlapped(&self,\n                                socket: &TcpBuilder,\n                                addrs: &mut AcceptAddrsBuf,\n                                overlapped: *mut OVERLAPPED)\n                                -> io::Result<(TcpStream, bool)> {\n        static ACCEPTEX: WsaExtension = WsaExtension {\n            guid: GUID {\n                Data1: 0xb5367df1,\n                Data2: 0xcbac,\n                Data3: 0x11cf,\n                Data4: [0x95, 0xca, 0x00, 0x80, 0x5f, 0x48, 0xa1, 0x92],\n            },\n            val: ATOMIC_USIZE_INIT,\n        };\n        type AcceptEx = unsafe extern \"system\" fn(SOCKET, SOCKET, PVOID,\n                                                  DWORD, DWORD, DWORD, LPDWORD,\n                                                  LPOVERLAPPED) -> BOOL;\n\n        let ptr = try!(ACCEPTEX.get(self.as_raw_socket()));\n        assert!(ptr != 0);\n        let accept_ex = mem::transmute::<_, AcceptEx>(ptr);\n\n        let mut bytes = 0;\n        let (a, b, c, d) = (*addrs).args();\n        let r = accept_ex(self.as_raw_socket(), socket.as_raw_socket(),\n                          a, b, c, d, &mut bytes, overlapped);\n        let succeeded = if r == TRUE {\n            true\n        } else {\n            try!(last_err());\n            false\n        };\n        // NB: this unwrap() should be guaranteed to succeed, and this is an\n        // assert that it does indeed succeed.\n        Ok((socket.to_tcp_stream().unwrap(), succeeded))\n    }\n\n    fn accept_complete(&self, socket: &TcpStream) -> io::Result<()> {\n        const SO_UPDATE_ACCEPT_CONTEXT: c_int = 0x700B;\n        let me = self.as_raw_socket();\n        let result = unsafe {\n            setsockopt(socket.as_raw_socket(),\n                       SOL_SOCKET,\n                       SO_UPDATE_ACCEPT_CONTEXT,\n                       &me as *const _ as *const _,\n                       mem::size_of_val(&me) as c_int)\n        };\n        if result == 0 {\n            Ok(())\n        } else {\n            Err(io::Error::last_os_error())\n        }\n    }\n\n    unsafe fn result(&self, overlapped: *mut OVERLAPPED)\n                     -> io::Result<(usize, u32)> {\n        result(self.as_raw_socket(), overlapped)\n    }\n}\n\nimpl SocketAddrBuf {\n    /// Creates a new blank socket address buffer.\n    ///\n    /// This should be used before a call to `recv_from_overlapped` overlapped\n    /// to create an instance to pass down.\n    pub fn new() -> SocketAddrBuf {\n        SocketAddrBuf {\n            buf: unsafe { mem::zeroed() },\n            len: mem::size_of::<SOCKADDR_STORAGE>() as c_int,\n        }\n    }\n\n    /// Parses this buffer to return a standard socket address.\n    ///\n    /// This function should be called after the buffer has been filled in with\n    /// a call to `recv_from_overlapped` being completed. It will interpret the\n    /// address filled in and return the standard socket address type.\n    ///\n    /// If an error is encountered then `None` is returned.\n    pub fn to_socket_addr(&self) -> Option<SocketAddr> {\n        unsafe {\n            ptrs_to_socket_addr(&self.buf as *const _ as *const _, self.len)\n        }\n    }\n}\n\nstatic GETACCEPTEXSOCKADDRS: WsaExtension = WsaExtension {\n    guid: GUID {\n        Data1: 0xb5367df2,\n        Data2: 0xcbac,\n        Data3: 0x11cf,\n        Data4: [0x95, 0xca, 0x00, 0x80, 0x5f, 0x48, 0xa1, 0x92],\n    },\n    val: ATOMIC_USIZE_INIT,\n};\ntype GetAcceptExSockaddrs = unsafe extern \"system\" fn(PVOID, DWORD, DWORD, DWORD,\n                                                      *mut LPSOCKADDR, LPINT,\n                                                      *mut LPSOCKADDR, LPINT);\n\nimpl AcceptAddrsBuf {\n    /// Creates a new blank buffer ready to be passed to a call to\n    /// `accept_overlapped`.\n    pub fn new() -> AcceptAddrsBuf {\n        unsafe { mem::zeroed() }\n    }\n\n    /// Parses the data contained in this address buffer, returning the parsed\n    /// result if successful.\n    ///\n    /// This function can be called after a call to `accept_overlapped` has\n    /// succeeded to parse out the data that was written in.\n    pub fn parse(&self, socket: &TcpListener) -> io::Result<AcceptAddrs> {\n        let mut ret = AcceptAddrs {\n            local: 0 as *mut _, local_len: 0,\n            remote: 0 as *mut _, remote_len: 0,\n            _data: self,\n        };\n        let ptr = try!(GETACCEPTEXSOCKADDRS.get(socket.as_raw_socket()));\n        assert!(ptr != 0);\n        unsafe {\n            let get_sockaddrs = mem::transmute::<_, GetAcceptExSockaddrs>(ptr);\n            let (a, b, c, d) = self.args();\n            get_sockaddrs(a, b, c, d,\n                          &mut ret.local, &mut ret.local_len,\n                          &mut ret.remote, &mut ret.remote_len);\n            Ok(ret)\n        }\n    }\n\n    fn args(&self) -> (PVOID, DWORD, DWORD, DWORD) {\n        let remote_offset = unsafe {\n            &(*(0 as *const AcceptAddrsBuf)).remote as *const _ as usize\n        };\n        (self as *const _ as *mut _, 0, remote_offset as DWORD,\n         (mem::size_of_val(self) - remote_offset) as DWORD)\n    }\n}\n\nimpl<'a> AcceptAddrs<'a> {\n    /// Returns the local socket address contained in this buffer.\n    pub fn local(&self) -> Option<SocketAddr> {\n        unsafe { ptrs_to_socket_addr(self.local, self.local_len) }\n    }\n\n    /// Returns the remote socket address contained in this buffer.\n    pub fn remote(&self) -> Option<SocketAddr> {\n        unsafe { ptrs_to_socket_addr(self.remote, self.remote_len) }\n    }\n}\n\nimpl WsaExtension {\n    fn get(&self, socket: SOCKET) -> io::Result<usize> {\n        let prev = self.val.load(Ordering::SeqCst);\n        if prev != 0 && !cfg!(debug_assertions) {\n            return Ok(prev)\n        }\n        let mut ret = 0 as usize;\n        let mut bytes = 0;\n        let r = unsafe {\n            WSAIoctl(socket, SIO_GET_EXTENSION_FUNCTION_POINTER,\n                     &self.guid as *const _ as *mut _,\n                     mem::size_of_val(&self.guid) as DWORD,\n                     &mut ret as *mut _ as *mut _,\n                     mem::size_of_val(&ret) as DWORD,\n                     &mut bytes,\n                     0 as *mut _, None)\n        };\n        cvt(r, 0).map(|_| {\n            debug_assert_eq!(bytes as usize, mem::size_of_val(&ret));\n            debug_assert!(prev == 0 || prev == ret);\n            self.val.store(ret, Ordering::SeqCst);\n            ret\n        })\n\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use std::net::{TcpListener, UdpSocket, TcpStream, SocketAddr};\n    use std::thread;\n    use std::io::prelude::*;\n\n    use Overlapped;\n    use iocp::CompletionPort;\n    use net::{TcpStreamExt, UdpSocketExt, SocketAddrBuf};\n    use net::{TcpBuilderExt, TcpListenerExt, AcceptAddrsBuf};\n    use net2::TcpBuilder;\n\n    fn each_ip(f: &mut FnMut(SocketAddr)) {\n        f(t!(\"127.0.0.1:0\".parse()));\n        f(t!(\"[::1]:0\".parse()));\n    }\n\n    #[test]\n    fn tcp_read() {\n        each_ip(&mut |addr| {\n            let l = t!(TcpListener::bind(addr));\n            let addr = t!(l.local_addr());\n            let t = thread::spawn(move || {\n                let mut a = t!(l.accept()).0;\n                t!(a.write_all(&[1, 2, 3]));\n            });\n\n            let cp = t!(CompletionPort::new(1));\n            let s = t!(TcpStream::connect(addr));\n            t!(cp.add_socket(1, &s));\n\n            let mut b = [0; 10];\n            let a = Overlapped::zero();\n            unsafe {\n                t!(s.read_overlapped(&mut b, a.raw()));\n            }\n            let status = t!(cp.get(None));\n            assert_eq!(status.bytes_transferred(), 3);\n            assert_eq!(status.token(), 1);\n            assert_eq!(status.overlapped(), a.raw());\n            assert_eq!(&b[0..3], &[1, 2, 3]);\n\n            t!(t.join());\n        })\n    }\n\n    #[test]\n    fn tcp_write() {\n        each_ip(&mut |addr| {\n            let l = t!(TcpListener::bind(addr));\n            let addr = t!(l.local_addr());\n            let t = thread::spawn(move || {\n                let mut a = t!(l.accept()).0;\n                let mut b = [0; 10];\n                let n = t!(a.read(&mut b));\n                assert_eq!(n, 3);\n                assert_eq!(&b[0..3], &[1, 2, 3]);\n            });\n\n            let cp = t!(CompletionPort::new(1));\n            let s = t!(TcpStream::connect(addr));\n            t!(cp.add_socket(1, &s));\n\n            let b = [1, 2, 3];\n            let a = Overlapped::zero();\n            unsafe {\n                t!(s.write_overlapped(&b, a.raw()));\n            }\n            let status = t!(cp.get(None));\n            assert_eq!(status.bytes_transferred(), 3);\n            assert_eq!(status.token(), 1);\n            assert_eq!(status.overlapped(), a.raw());\n\n            t!(t.join());\n        })\n    }\n\n    #[test]\n    fn tcp_connect() {\n        each_ip(&mut |addr_template| {\n            let l = t!(TcpListener::bind(addr_template));\n            let addr = t!(l.local_addr());\n            let t = thread::spawn(move || {\n                t!(l.accept());\n            });\n\n            let cp = t!(CompletionPort::new(1));\n            let builder = match addr {\n                SocketAddr::V4(..) => t!(TcpBuilder::new_v4()),\n                SocketAddr::V6(..) => t!(TcpBuilder::new_v6()),\n            };\n            t!(cp.add_socket(1, &builder));\n\n            let a = Overlapped::zero();\n            t!(builder.bind(addr_template));\n            let (s, _) = unsafe {\n                t!(builder.connect_overlapped(&addr, &[], a.raw()))\n            };\n            let status = t!(cp.get(None));\n            assert_eq!(status.bytes_transferred(), 0);\n            assert_eq!(status.token(), 1);\n            assert_eq!(status.overlapped(), a.raw());\n            t!(s.connect_complete());\n\n            t!(t.join());\n        })\n    }\n\n    #[test]\n    fn udp_recv_from() {\n        each_ip(&mut |addr| {\n            let a = t!(UdpSocket::bind(addr));\n            let b = t!(UdpSocket::bind(addr));\n            let a_addr = t!(a.local_addr());\n            let b_addr = t!(b.local_addr());\n            let t = thread::spawn(move || {\n                t!(a.send_to(&[1, 2, 3], b_addr));\n            });\n\n            let cp = t!(CompletionPort::new(1));\n            t!(cp.add_socket(1, &b));\n\n            let mut buf = [0; 10];\n            let a = Overlapped::zero();\n            let mut addr = SocketAddrBuf::new();\n            unsafe {\n                t!(b.recv_from_overlapped(&mut buf, &mut addr, a.raw()));\n            }\n            let status = t!(cp.get(None));\n            assert_eq!(status.bytes_transferred(), 3);\n            assert_eq!(status.token(), 1);\n            assert_eq!(status.overlapped(), a.raw());\n            assert_eq!(&buf[..3], &[1, 2, 3]);\n            assert_eq!(addr.to_socket_addr(), Some(a_addr));\n\n            t!(t.join());\n        })\n    }\n\n    #[test]\n    fn udp_recv() {\n        each_ip(&mut |addr| {\n            let a = t!(UdpSocket::bind(addr));\n            let b = t!(UdpSocket::bind(addr));\n            let a_addr = t!(a.local_addr());\n            let b_addr = t!(b.local_addr());\n            assert!(b.connect(a_addr).is_ok());\n            assert!(a.connect(b_addr).is_ok());\n            let t = thread::spawn(move || {\n                t!(a.send_to(&[1, 2, 3], b_addr));\n            });\n\n            let cp = t!(CompletionPort::new(1));\n            t!(cp.add_socket(1, &b));\n\n            let mut buf = [0; 10];\n            let a = Overlapped::zero();\n            unsafe {\n                t!(b.recv_overlapped(&mut buf, a.raw()));\n            }\n            let status = t!(cp.get(None));\n            assert_eq!(status.bytes_transferred(), 3);\n            assert_eq!(status.token(), 1);\n            assert_eq!(status.overlapped(), a.raw());\n            assert_eq!(&buf[..3], &[1, 2, 3]);\n\n            t!(t.join());\n        })\n    }\n\n    #[test]\n    fn udp_send_to() {\n        each_ip(&mut |addr| {\n            let a = t!(UdpSocket::bind(addr));\n            let b = t!(UdpSocket::bind(addr));\n            let a_addr = t!(a.local_addr());\n            let b_addr = t!(b.local_addr());\n            let t = thread::spawn(move || {\n                let mut b = [0; 100];\n                let (n, addr) = t!(a.recv_from(&mut b));\n                assert_eq!(n, 3);\n                assert_eq!(addr, b_addr);\n                assert_eq!(&b[..3], &[1, 2, 3]);\n            });\n\n            let cp = t!(CompletionPort::new(1));\n            t!(cp.add_socket(1, &b));\n\n            let a = Overlapped::zero();\n            unsafe {\n                t!(b.send_to_overlapped(&[1, 2, 3], &a_addr, a.raw()));\n            }\n            let status = t!(cp.get(None));\n            assert_eq!(status.bytes_transferred(), 3);\n            assert_eq!(status.token(), 1);\n            assert_eq!(status.overlapped(), a.raw());\n\n            t!(t.join());\n        })\n    }\n\n    #[test]\n    fn udp_send() {\n        each_ip(&mut |addr| {\n            let a = t!(UdpSocket::bind(addr));\n            let b = t!(UdpSocket::bind(addr));\n            let a_addr = t!(a.local_addr());\n            let b_addr = t!(b.local_addr());\n            assert!(b.connect(a_addr).is_ok());\n            assert!(a.connect(b_addr).is_ok());\n            let t = thread::spawn(move || {\n                let mut b = [0; 100];\n                let (n, addr) = t!(a.recv_from(&mut b));\n                assert_eq!(n, 3);\n                assert_eq!(addr, b_addr);\n                assert_eq!(&b[..3], &[1, 2, 3]);\n            });\n\n            let cp = t!(CompletionPort::new(1));\n            t!(cp.add_socket(1, &b));\n\n            let a = Overlapped::zero();\n            unsafe {\n                t!(b.send_overlapped(&[1, 2, 3], a.raw()));\n            }\n            let status = t!(cp.get(None));\n            assert_eq!(status.bytes_transferred(), 3);\n            assert_eq!(status.token(), 1);\n            assert_eq!(status.overlapped(), a.raw());\n\n            t!(t.join());\n        })\n    }\n\n    #[test]\n    fn tcp_accept() {\n        each_ip(&mut |addr_template| {\n            let l = t!(TcpListener::bind(addr_template));\n            let addr = t!(l.local_addr());\n            let t = thread::spawn(move || {\n                let socket = t!(TcpStream::connect(addr));\n                (socket.local_addr().unwrap(), socket.peer_addr().unwrap())\n            });\n\n            let cp = t!(CompletionPort::new(1));\n            let builder = match addr {\n                SocketAddr::V4(..) => t!(TcpBuilder::new_v4()),\n                SocketAddr::V6(..) => t!(TcpBuilder::new_v6()),\n            };\n            t!(cp.add_socket(1, &l));\n\n            let a = Overlapped::zero();\n            let mut addrs = AcceptAddrsBuf::new();\n            let (s, _) = unsafe {\n                t!(l.accept_overlapped(&builder, &mut addrs, a.raw()))\n            };\n            let status = t!(cp.get(None));\n            assert_eq!(status.bytes_transferred(), 0);\n            assert_eq!(status.token(), 1);\n            assert_eq!(status.overlapped(), a.raw());\n            t!(l.accept_complete(&s));\n\n            let (remote, local) = t!(t.join());\n            let addrs = addrs.parse(&l).unwrap();\n            assert_eq!(addrs.local(), Some(local));\n            assert_eq!(addrs.remote(), Some(remote));\n        })\n    }\n}\n"
  },
  {
    "project": "os_str_bytes",
    "target": 1,
    "commit_id": "e75193e151f23d0d6b2b096b69a303041496e9ff",
    "func": "// These methods are necessarily inefficient, because they must revert encoding\n// conversions performed by the standard library. However, there is currently\n// no better alternative.\n\nuse std::borrow::Cow;\nuse std::char;\nuse std::ffi::OsStr;\nuse std::ffi::OsString;\nuse std::mem;\nuse std::os::windows::ffi::OsStrExt;\nuse std::os::windows::ffi::OsStringExt;\n\nuse crate::EncodingError;\nuse crate::OsStrBytes;\nuse crate::OsStringBytes;\n\n#[allow(clippy::module_inception)]\nmod imp;\n\nfn wide_to_wtf8<TString>(encoded_string: TString, length: usize) -> Vec<u8>\nwhere\n    TString: IntoIterator<Item = u16>,\n{\n    // https://github.com/rust-lang/rust/blob/49c68bd53f90e375bfb3cbba8c1c67a9e0adb9c0/src/libstd/sys_common/wtf8.rs#L183-L199\n\n    let mut string = Vec::with_capacity(length);\n    let mut buffer = [0; mem::size_of::<char>()];\n    for ch in char::decode_utf16(encoded_string) {\n        let unchecked_char = ch.unwrap_or_else(|surrogate| {\n            let surrogate = surrogate.unpaired_surrogate().into();\n            debug_assert!(surrogate <= u32::from(char::MAX));\n            // SAFETY: https://docs.rs/os_str_bytes/#safety\n            unsafe { char::from_u32_unchecked(surrogate) }\n        });\n        string.extend_from_slice(\n            unchecked_char.encode_utf8(&mut buffer).as_bytes(),\n        );\n    }\n    debug_assert_eq!(string.len(), length);\n    string\n}\n\nfn wtf8_to_wide(string: &[u8]) -> Vec<u16> {\n    // https://github.com/rust-lang/rust/blob/49c68bd53f90e375bfb3cbba8c1c67a9e0adb9c0/src/libstd/sys_common/wtf8.rs#L797-L813\n\n    let mut string = string.iter();\n    let mut encoded_string = Vec::new();\n    let mut buffer = [0; 2];\n    while let Some(code_point) = imp::next_code_point(&mut string) {\n        debug_assert!(code_point <= u32::from(char::MAX));\n        // SAFETY: https://docs.rs/os_str_bytes/#safety\n        let unchecked_char = unsafe { char::from_u32_unchecked(code_point) };\n        encoded_string\n            .extend_from_slice(unchecked_char.encode_utf16(&mut buffer));\n    }\n    encoded_string\n}\n\nimpl OsStrBytes for OsStr {\n    #[inline]\n    fn from_bytes(string: &[u8]) -> Result<Cow<'_, Self>, EncodingError> {\n        Ok(Cow::Owned(OsStringBytes::from_bytes(string)?))\n    }\n\n    #[inline]\n    unsafe fn from_bytes_unchecked(string: &[u8]) -> Cow<'_, Self> {\n        Cow::Owned(OsStringBytes::from_bytes_unchecked(string))\n    }\n\n    #[inline]\n    fn to_bytes(&self) -> Cow<'_, [u8]> {\n        Cow::Owned(wide_to_wtf8(OsStrExt::encode_wide(self), self.len()))\n    }\n}\n\nimpl OsStringBytes for OsString {\n    #[allow(clippy::map_clone)]\n    #[inline]\n    fn from_bytes<TString>(string: TString) -> Result<Self, EncodingError>\n    where\n        TString: AsRef<[u8]>,\n    {\n        let string = string.as_ref();\n        let encoded_string = wtf8_to_wide(string);\n        if wide_to_wtf8(encoded_string.iter().map(|&x| x), string.len())\n            == string\n        {\n            Ok(OsStringExt::from_wide(&encoded_string))\n        } else {\n            Err(EncodingError(()))\n        }\n    }\n\n    #[inline]\n    unsafe fn from_bytes_unchecked<TString>(string: TString) -> Self\n    where\n        TString: AsRef<[u8]>,\n    {\n        OsStringExt::from_wide(&wtf8_to_wide(string.as_ref()))\n    }\n\n    #[inline]\n    fn from_vec(string: Vec<u8>) -> Result<Self, EncodingError> {\n        OsStringBytes::from_bytes(string)\n    }\n\n    #[inline]\n    unsafe fn from_vec_unchecked(string: Vec<u8>) -> Self {\n        OsStringBytes::from_bytes_unchecked(string)\n    }\n\n    #[inline]\n    fn into_vec(self) -> Vec<u8> {\n        OsStrBytes::to_bytes(self.as_os_str()).into_owned()\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use std::ffi::OsStr;\n    use std::ffi::OsString;\n\n    use crate::EncodingError;\n    use crate::OsStrBytes;\n    use crate::OsStringBytes;\n\n    const INVALID_STRING: &[u8] = b\"\\xF1foo\\xF1\\x80bar\\xF1\\x80\\x80baz\";\n\n    #[test]\n    fn test_invalid_bytes() {\n        assert_eq!(Err(EncodingError(())), OsStr::from_bytes(INVALID_STRING));\n        assert_eq!(\n            Err(EncodingError(())),\n            OsString::from_bytes(INVALID_STRING),\n        );\n    }\n\n    #[test]\n    fn test_invalid_vec() {\n        assert_eq!(\n            Err(EncodingError(())),\n            OsString::from_vec(INVALID_STRING.to_vec()),\n        );\n    }\n}\n"
  },
  {
    "project": "libsecp256k1",
    "target": 1,
    "commit_id": "12e3829d6cd2d6459c2c920d7cf222f3a930b955",
    "func": "//! Pure Rust implementation of the secp256k1 curve and fast ECDSA\n//! signatures. The secp256k1 curve is used extensively in Bitcoin and\n//! Ethereum-alike cryptocurrencies.\n\n#![deny(\n    unused_import_braces,\n    unused_imports,\n    unused_comparisons,\n    unused_must_use,\n    unused_variables,\n    non_shorthand_field_patterns,\n    unreachable_code,\n    unused_parens\n)]\n\npub use libsecp256k1_core::*;\n\nuse arrayref::{array_mut_ref, array_ref};\nuse core::convert::TryFrom;\nuse digest::{generic_array::GenericArray, Digest};\nuse rand::Rng;\n\n#[cfg(feature = \"std\")]\nuse core::fmt;\n#[cfg(feature = \"hmac\")]\nuse hmac_drbg::HmacDRBG;\n#[cfg(feature = \"std\")]\nuse serde::{de, ser::Serializer, Deserialize, Serialize};\n#[cfg(feature = \"hmac\")]\nuse sha2::Sha256;\n#[cfg(feature = \"hmac\")]\nuse typenum::U32;\n\nuse crate::{\n    curve::{Affine, ECMultContext, ECMultGenContext, Field, Jacobian, Scalar},\n    util::{self, Decoder, SignatureArray},\n};\n\n#[cfg(feature = \"static-context\")]\n/// A static ECMult context.\n// Correct `pre_g` values are fed into `ECMultContext::new_from_raw`, generated by build script.\npub static ECMULT_CONTEXT: ECMultContext =\n    unsafe { ECMultContext::new_from_raw(include!(concat!(env!(\"OUT_DIR\"), \"/const.rs\"))) };\n\n#[cfg(feature = \"static-context\")]\n/// A static ECMultGen context.\n// Correct `prec` values are fed into `ECMultGenContext::new_from_raw`, generated by build script.\npub static ECMULT_GEN_CONTEXT: ECMultGenContext =\n    unsafe { ECMultGenContext::new_from_raw(include!(concat!(env!(\"OUT_DIR\"), \"/const_gen.rs\"))) };\n\n#[derive(Debug, Clone, Copy, Eq, PartialEq)]\n/// Public key on a secp256k1 curve.\npub struct PublicKey(Affine);\n#[derive(Debug, Clone, Copy, Eq, PartialEq)]\n/// Secret key (256-bit) on a secp256k1 curve.\npub struct SecretKey(Scalar);\n#[derive(Debug, Clone, Copy, Eq, PartialEq)]\n/// An ECDSA signature.\npub struct Signature {\n    pub r: Scalar,\n    pub s: Scalar,\n}\n#[derive(Debug, Clone, Copy, Eq, PartialEq)]\n/// Tag used for public key recovery from signatures.\npub struct RecoveryId(u8);\n#[derive(Debug, Clone, Copy, Eq, PartialEq)]\n/// Hashed message input to an ECDSA signature.\npub struct Message(pub Scalar);\n#[derive(Debug, Clone, Eq, PartialEq)]\n/// Shared secret using ECDH.\npub struct SharedSecret<D: Digest>(GenericArray<u8, D::OutputSize>);\n\nimpl<D> Copy for SharedSecret<D>\nwhere\n    D: Copy + Digest,\n    GenericArray<u8, D::OutputSize>: Copy,\n{\n}\n\n/// Format for public key parsing.\npub enum PublicKeyFormat {\n    /// Compressed public key, 33 bytes.\n    Compressed,\n    /// Full length public key, 65 bytes.\n    Full,\n    /// Raw public key, 64 bytes.\n    Raw,\n}\n\nimpl PublicKey {\n    pub fn from_secret_key_with_context(\n        seckey: &SecretKey,\n        context: &ECMultGenContext,\n    ) -> PublicKey {\n        let mut pj = Jacobian::default();\n        context.ecmult_gen(&mut pj, &seckey.0);\n        let mut p = Affine::default();\n        p.set_gej(&pj);\n        PublicKey(p)\n    }\n\n    #[cfg(feature = \"static-context\")]\n    pub fn from_secret_key(seckey: &SecretKey) -> PublicKey {\n        Self::from_secret_key_with_context(seckey, &ECMULT_GEN_CONTEXT)\n    }\n\n    pub fn parse_slice(p: &[u8], format: Option<PublicKeyFormat>) -> Result<PublicKey, Error> {\n        let format = match (p.len(), format) {\n            (util::FULL_PUBLIC_KEY_SIZE, None)\n            | (util::FULL_PUBLIC_KEY_SIZE, Some(PublicKeyFormat::Full)) => PublicKeyFormat::Full,\n            (util::COMPRESSED_PUBLIC_KEY_SIZE, None)\n            | (util::COMPRESSED_PUBLIC_KEY_SIZE, Some(PublicKeyFormat::Compressed)) => {\n                PublicKeyFormat::Compressed\n            }\n            (util::RAW_PUBLIC_KEY_SIZE, None)\n            | (util::RAW_PUBLIC_KEY_SIZE, Some(PublicKeyFormat::Raw)) => PublicKeyFormat::Raw,\n            _ => return Err(Error::InvalidInputLength),\n        };\n\n        match format {\n            PublicKeyFormat::Full => {\n                let mut a = [0; util::FULL_PUBLIC_KEY_SIZE];\n                a.copy_from_slice(p);\n                Self::parse(&a)\n            }\n            PublicKeyFormat::Raw => {\n                use util::TAG_PUBKEY_FULL;\n\n                let mut a = [0; util::FULL_PUBLIC_KEY_SIZE];\n                a[0] = TAG_PUBKEY_FULL;\n                a[1..].copy_from_slice(p);\n                Self::parse(&a)\n            }\n            PublicKeyFormat::Compressed => {\n                let mut a = [0; util::COMPRESSED_PUBLIC_KEY_SIZE];\n                a.copy_from_slice(p);\n                Self::parse_compressed(&a)\n            }\n        }\n    }\n\n    pub fn parse(p: &[u8; util::FULL_PUBLIC_KEY_SIZE]) -> Result<PublicKey, Error> {\n        use util::{TAG_PUBKEY_FULL, TAG_PUBKEY_HYBRID_EVEN, TAG_PUBKEY_HYBRID_ODD};\n\n        if !(p[0] == TAG_PUBKEY_FULL\n            || p[0] == TAG_PUBKEY_HYBRID_EVEN\n            || p[0] == TAG_PUBKEY_HYBRID_ODD)\n        {\n            return Err(Error::InvalidPublicKey);\n        }\n        let mut x = Field::default();\n        let mut y = Field::default();\n        if !x.set_b32(array_ref!(p, 1, 32)) {\n            return Err(Error::InvalidPublicKey);\n        }\n        if !y.set_b32(array_ref!(p, 33, 32)) {\n            return Err(Error::InvalidPublicKey);\n        }\n        let mut elem = Affine::default();\n        elem.set_xy(&x, &y);\n        if (p[0] == TAG_PUBKEY_HYBRID_EVEN || p[0] == TAG_PUBKEY_HYBRID_ODD)\n            && (y.is_odd() != (p[0] == TAG_PUBKEY_HYBRID_ODD))\n        {\n            return Err(Error::InvalidPublicKey);\n        }\n        if elem.is_infinity() {\n            return Err(Error::InvalidPublicKey);\n        }\n        if elem.is_valid_var() {\n            Ok(PublicKey(elem))\n        } else {\n            Err(Error::InvalidPublicKey)\n        }\n    }\n\n    pub fn parse_compressed(\n        p: &[u8; util::COMPRESSED_PUBLIC_KEY_SIZE],\n    ) -> Result<PublicKey, Error> {\n        use util::{TAG_PUBKEY_EVEN, TAG_PUBKEY_ODD};\n\n        if !(p[0] == TAG_PUBKEY_EVEN || p[0] == TAG_PUBKEY_ODD) {\n            return Err(Error::InvalidPublicKey);\n        }\n        let mut x = Field::default();\n        if !x.set_b32(array_ref!(p, 1, 32)) {\n            return Err(Error::InvalidPublicKey);\n        }\n        let mut elem = Affine::default();\n        elem.set_xo_var(&x, p[0] == TAG_PUBKEY_ODD);\n        if elem.is_infinity() {\n            return Err(Error::InvalidPublicKey);\n        }\n        if elem.is_valid_var() {\n            Ok(PublicKey(elem))\n        } else {\n            Err(Error::InvalidPublicKey)\n        }\n    }\n\n    pub fn serialize(&self) -> [u8; util::FULL_PUBLIC_KEY_SIZE] {\n        use util::TAG_PUBKEY_FULL;\n\n        debug_assert!(!self.0.is_infinity());\n\n        let mut ret = [0u8; 65];\n        let mut elem = self.0;\n\n        elem.x.normalize_var();\n        elem.y.normalize_var();\n        elem.x.fill_b32(array_mut_ref!(ret, 1, 32));\n        elem.y.fill_b32(array_mut_ref!(ret, 33, 32));\n        ret[0] = TAG_PUBKEY_FULL;\n\n        ret\n    }\n\n    pub fn serialize_compressed(&self) -> [u8; util::COMPRESSED_PUBLIC_KEY_SIZE] {\n        use util::{TAG_PUBKEY_EVEN, TAG_PUBKEY_ODD};\n\n        debug_assert!(!self.0.is_infinity());\n\n        let mut ret = [0u8; 33];\n        let mut elem = self.0;\n\n        elem.x.normalize_var();\n        elem.y.normalize_var();\n        elem.x.fill_b32(array_mut_ref!(ret, 1, 32));\n        ret[0] = if elem.y.is_odd() {\n            TAG_PUBKEY_ODD\n        } else {\n            TAG_PUBKEY_EVEN\n        };\n\n        ret\n    }\n\n    pub fn tweak_add_assign_with_context(\n        &mut self,\n        tweak: &SecretKey,\n        context: &ECMultContext,\n    ) -> Result<(), Error> {\n        let mut r = Jacobian::default();\n        let a = Jacobian::from_ge(&self.0);\n        let one = Scalar::from_int(1);\n        context.ecmult(&mut r, &a, &one, &tweak.0);\n\n        if r.is_infinity() {\n            return Err(Error::TweakOutOfRange);\n        }\n\n        self.0.set_gej(&r);\n        Ok(())\n    }\n\n    #[cfg(feature = \"static-context\")]\n    pub fn tweak_add_assign(&mut self, tweak: &SecretKey) -> Result<(), Error> {\n        self.tweak_add_assign_with_context(tweak, &ECMULT_CONTEXT)\n    }\n\n    pub fn tweak_mul_assign_with_context(\n        &mut self,\n        tweak: &SecretKey,\n        context: &ECMultContext,\n    ) -> Result<(), Error> {\n        if tweak.0.is_zero() {\n            return Err(Error::TweakOutOfRange);\n        }\n\n        let mut r = Jacobian::default();\n        let zero = Scalar::from_int(0);\n        let pt = Jacobian::from_ge(&self.0);\n        context.ecmult(&mut r, &pt, &tweak.0, &zero);\n\n        self.0.set_gej(&r);\n        Ok(())\n    }\n\n    #[cfg(feature = \"static-context\")]\n    pub fn tweak_mul_assign(&mut self, tweak: &SecretKey) -> Result<(), Error> {\n        self.tweak_mul_assign_with_context(tweak, &ECMULT_CONTEXT)\n    }\n\n    pub fn combine(keys: &[PublicKey]) -> Result<Self, Error> {\n        let mut qj = Jacobian::default();\n        qj.set_infinity();\n\n        for key in keys {\n            qj = qj.add_ge(&key.0);\n        }\n\n        if qj.is_infinity() {\n            return Err(Error::InvalidPublicKey);\n        }\n\n        let q = Affine::from_gej(&qj);\n        Ok(PublicKey(q))\n    }\n}\n\nimpl Into<Affine> for PublicKey {\n    fn into(self) -> Affine {\n        self.0\n    }\n}\n\n#[cfg(feature = \"std\")]\nimpl Serialize for PublicKey {\n    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>\n    where\n        S: Serializer,\n    {\n        if serializer.is_human_readable() {\n            serializer.serialize_str(&base64::encode(&self.serialize()[..]))\n        } else {\n            serializer.serialize_bytes(&self.serialize())\n        }\n    }\n}\n\n#[cfg(feature = \"std\")]\nstruct PublicKeyVisitor;\n\n#[cfg(feature = \"std\")]\nimpl<'de> de::Visitor<'de> for PublicKeyVisitor {\n    type Value = PublicKey;\n\n    fn expecting(&self, formatter: &mut fmt::Formatter) -> fmt::Result {\n        formatter\n            .write_str(\"a bytestring of either 33 (compressed), 64 (raw), or 65 bytes in length\")\n    }\n\n    fn visit_str<E>(self, value: &str) -> Result<Self::Value, E>\n    where\n        E: de::Error,\n    {\n        let value: &[u8] = &base64::decode(value).unwrap();\n        let key_format = match value.len() {\n            33 => PublicKeyFormat::Compressed,\n            64 => PublicKeyFormat::Raw,\n            65 => PublicKeyFormat::Full,\n            _ => return Err(E::custom(Error::InvalidInputLength)),\n        };\n        PublicKey::parse_slice(value, Some(key_format))\n            .map_err(|_e| E::custom(Error::InvalidPublicKey))\n    }\n}\n\n#[cfg(feature = \"std\")]\nimpl<'de> Deserialize<'de> for PublicKey {\n    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>\n    where\n        D: de::Deserializer<'de>,\n    {\n        if deserializer.is_human_readable() {\n            deserializer.deserialize_str(PublicKeyVisitor)\n        } else {\n            deserializer.deserialize_bytes(PublicKeyVisitor)\n        }\n    }\n}\n\nimpl SecretKey {\n    pub fn parse(p: &[u8; util::SECRET_KEY_SIZE]) -> Result<SecretKey, Error> {\n        let mut elem = Scalar::default();\n        if !bool::from(elem.set_b32(p)) {\n            Self::try_from(elem)\n        } else {\n            Err(Error::InvalidSecretKey)\n        }\n    }\n\n    pub fn parse_slice(p: &[u8]) -> Result<SecretKey, Error> {\n        if p.len() != util::SECRET_KEY_SIZE {\n            return Err(Error::InvalidInputLength);\n        }\n\n        let mut a = [0; 32];\n        a.copy_from_slice(p);\n        Self::parse(&a)\n    }\n\n    pub fn random<R: Rng>(rng: &mut R) -> SecretKey {\n        loop {\n            let mut ret = [0u8; util::SECRET_KEY_SIZE];\n            rng.fill_bytes(&mut ret);\n\n            if let Ok(key) = Self::parse(&ret) {\n                return key;\n            }\n        }\n    }\n\n    pub fn serialize(&self) -> [u8; util::SECRET_KEY_SIZE] {\n        self.0.b32()\n    }\n\n    pub fn tweak_add_assign(&mut self, tweak: &SecretKey) -> Result<(), Error> {\n        let v = self.0 + tweak.0;\n        if v.is_zero() {\n            return Err(Error::TweakOutOfRange);\n        }\n        self.0 = v;\n        Ok(())\n    }\n\n    pub fn tweak_mul_assign(&mut self, tweak: &SecretKey) -> Result<(), Error> {\n        if tweak.0.is_zero() {\n            return Err(Error::TweakOutOfRange);\n        }\n\n        self.0 *= &tweak.0;\n        Ok(())\n    }\n\n    pub fn inv(&self) -> Self {\n        SecretKey(self.0.inv())\n    }\n}\n\nimpl Default for SecretKey {\n    fn default() -> SecretKey {\n        let mut elem = Scalar::default();\n        let overflowed = bool::from(elem.set_b32(&[\n            0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n            0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n            0x00, 0x00, 0x00, 0x01,\n        ]));\n        debug_assert!(!overflowed);\n        debug_assert!(!elem.is_zero());\n        SecretKey(elem)\n    }\n}\n\nimpl Into<Scalar> for SecretKey {\n    fn into(self) -> Scalar {\n        self.0\n    }\n}\n\nimpl TryFrom<Scalar> for SecretKey {\n    type Error = Error;\n\n    fn try_from(scalar: Scalar) -> Result<Self, Error> {\n        if scalar.is_zero() {\n            Err(Error::InvalidSecretKey)\n        } else {\n            Ok(Self(scalar))\n        }\n    }\n}\n\nimpl core::fmt::LowerHex for SecretKey {\n    fn fmt(&self, f: &mut core::fmt::Formatter<'_>) -> core::fmt::Result {\n        let scalar = self.0;\n\n        write!(f, \"{:x}\", scalar)\n    }\n}\n\nimpl Signature {\n    pub fn parse(p: &[u8; util::SIGNATURE_SIZE]) -> Signature {\n        let mut r = Scalar::default();\n        let mut s = Scalar::default();\n\n        // Okay for signature to overflow\n        let _ = r.set_b32(array_ref!(p, 0, 32));\n        let _ = s.set_b32(array_ref!(p, 32, 32));\n\n        Signature { r, s }\n    }\n\n    pub fn parse_slice(p: &[u8]) -> Result<Signature, Error> {\n        if p.len() != util::SIGNATURE_SIZE {\n            return Err(Error::InvalidInputLength);\n        }\n\n        let mut a = [0; util::SIGNATURE_SIZE];\n        a.copy_from_slice(p);\n        Ok(Self::parse(&a))\n    }\n\n    pub fn parse_der(p: &[u8]) -> Result<Signature, Error> {\n        let mut decoder = Decoder::new(p);\n\n        decoder.read_constructed_sequence()?;\n        let rlen = decoder.read_len()?;\n\n        if rlen != decoder.remaining_len() {\n            return Err(Error::InvalidSignature);\n        }\n\n        let r = decoder.read_integer()?;\n        let s = decoder.read_integer()?;\n\n        if decoder.remaining_len() != 0 {\n            return Err(Error::InvalidSignature);\n        }\n\n        Ok(Signature { r, s })\n    }\n\n    /// Converts a \"lax DER\"-encoded byte slice to a signature. This is basically\n    /// only useful for validating signatures in the Bitcoin blockchain from before\n    /// 2016. It should never be used in new applications. This library does not\n    /// support serializing to this \"format\"\n    pub fn parse_der_lax(p: &[u8]) -> Result<Signature, Error> {\n        let mut decoder = Decoder::new(p);\n\n        decoder.read_constructed_sequence()?;\n        decoder.read_seq_len_lax()?;\n\n        let r = decoder.read_integer_lax()?;\n        let s = decoder.read_integer_lax()?;\n\n        Ok(Signature { r, s })\n    }\n\n    /// Normalizes a signature to a \"low S\" form. In ECDSA, signatures are\n    /// of the form (r, s) where r and s are numbers lying in some finite\n    /// field. The verification equation will pass for (r, s) iff it passes\n    /// for (r, -s), so it is possible to ``modify'' signatures in transit\n    /// by flipping the sign of s. This does not constitute a forgery since\n    /// the signed message still cannot be changed, but for some applications,\n    /// changing even the signature itself can be a problem. Such applications\n    /// require a \"strong signature\". It is believed that ECDSA is a strong\n    /// signature except for this ambiguity in the sign of s, so to accommodate\n    /// these applications libsecp256k1 will only accept signatures for which\n    /// s is in the lower half of the field range. This eliminates the\n    /// ambiguity.\n    ///\n    /// However, for some systems, signatures with high s-values are considered\n    /// valid. (For example, parsing the historic Bitcoin blockchain requires\n    /// this.) For these applications we provide this normalization function,\n    /// which ensures that the s value lies in the lower half of its range.\n    pub fn normalize_s(&mut self) {\n        if self.s.is_high() {\n            self.s = -self.s;\n        }\n    }\n\n    pub fn serialize(&self) -> [u8; util::SIGNATURE_SIZE] {\n        let mut ret = [0u8; 64];\n        self.r.fill_b32(array_mut_ref!(ret, 0, 32));\n        self.s.fill_b32(array_mut_ref!(ret, 32, 32));\n        ret\n    }\n\n    pub fn serialize_der(&self) -> SignatureArray {\n        fn fill_scalar_with_leading_zero(scalar: &Scalar) -> [u8; 33] {\n            let mut ret = [0u8; 33];\n            scalar.fill_b32(array_mut_ref!(ret, 1, 32));\n            ret\n        }\n\n        let r_full = fill_scalar_with_leading_zero(&self.r);\n        let s_full = fill_scalar_with_leading_zero(&self.s);\n\n        fn integer_slice(full: &[u8; 33]) -> &[u8] {\n            let mut len = 33;\n            while len > 1 && full[full.len() - len] == 0 && full[full.len() - len + 1] < 0x80 {\n                len -= 1;\n            }\n            &full[(full.len() - len)..]\n        }\n\n        let r = integer_slice(&r_full);\n        let s = integer_slice(&s_full);\n\n        let mut ret = SignatureArray::new(6 + r.len() + s.len());\n        {\n            let l = ret.as_mut();\n            l[0] = 0x30;\n            l[1] = 4 + r.len() as u8 + s.len() as u8;\n            l[2] = 0x02;\n            l[3] = r.len() as u8;\n            l[4..(4 + r.len())].copy_from_slice(r);\n            l[4 + r.len()] = 0x02;\n            l[5 + r.len()] = s.len() as u8;\n            l[(6 + r.len())..(6 + r.len() + s.len())].copy_from_slice(s);\n        }\n\n        ret\n    }\n}\n\nimpl Message {\n    pub fn parse(p: &[u8; util::MESSAGE_SIZE]) -> Message {\n        let mut m = Scalar::default();\n\n        // Okay for message to overflow.\n        let _ = m.set_b32(p);\n\n        Message(m)\n    }\n\n    pub fn parse_slice(p: &[u8]) -> Result<Message, Error> {\n        if p.len() != util::MESSAGE_SIZE {\n            return Err(Error::InvalidInputLength);\n        }\n\n        let mut a = [0; util::MESSAGE_SIZE];\n        a.copy_from_slice(p);\n        Ok(Self::parse(&a))\n    }\n\n    pub fn serialize(&self) -> [u8; util::MESSAGE_SIZE] {\n        self.0.b32()\n    }\n}\n\nimpl RecoveryId {\n    /// Parse recovery ID starting with 0.\n    pub fn parse(p: u8) -> Result<RecoveryId, Error> {\n        if p < 4 {\n            Ok(RecoveryId(p))\n        } else {\n            Err(Error::InvalidRecoveryId)\n        }\n    }\n\n    /// Parse recovery ID as Ethereum RPC format, starting with 27.\n    pub fn parse_rpc(p: u8) -> Result<RecoveryId, Error> {\n        if p >= 27 && p < 27 + 4 {\n            RecoveryId::parse(p - 27)\n        } else {\n            Err(Error::InvalidRecoveryId)\n        }\n    }\n\n    pub fn serialize(&self) -> u8 {\n        self.0\n    }\n}\n\nimpl Into<u8> for RecoveryId {\n    fn into(self) -> u8 {\n        self.0\n    }\n}\n\nimpl Into<i32> for RecoveryId {\n    fn into(self) -> i32 {\n        self.0 as i32\n    }\n}\n\nimpl<D: Digest + Default> SharedSecret<D> {\n    pub fn new_with_context(\n        pubkey: &PublicKey,\n        seckey: &SecretKey,\n        context: &ECMultContext,\n    ) -> Result<SharedSecret<D>, Error> {\n        let inner = match context.ecdh_raw::<D>(&pubkey.0, &seckey.0) {\n            Some(val) => val,\n            None => return Err(Error::InvalidSecretKey),\n        };\n\n        Ok(SharedSecret(inner))\n    }\n\n    #[cfg(feature = \"static-context\")]\n    pub fn new(pubkey: &PublicKey, seckey: &SecretKey) -> Result<SharedSecret<D>, Error> {\n        Self::new_with_context(pubkey, seckey, &ECMULT_CONTEXT)\n    }\n}\n\nimpl<D: Digest> AsRef<[u8]> for SharedSecret<D> {\n    fn as_ref(&self) -> &[u8] {\n        &self.0.as_ref()\n    }\n}\n\n/// Check signature is a valid message signed by public key, using the given context.\npub fn verify_with_context(\n    message: &Message,\n    signature: &Signature,\n    pubkey: &PublicKey,\n    context: &ECMultContext,\n) -> bool {\n    context.verify_raw(&signature.r, &signature.s, &pubkey.0, &message.0)\n}\n\n#[cfg(feature = \"static-context\")]\n/// Check signature is a valid message signed by public key.\npub fn verify(message: &Message, signature: &Signature, pubkey: &PublicKey) -> bool {\n    verify_with_context(message, signature, pubkey, &ECMULT_CONTEXT)\n}\n\n/// Recover public key from a signed message, using the given context.\npub fn recover_with_context(\n    message: &Message,\n    signature: &Signature,\n    recovery_id: &RecoveryId,\n    context: &ECMultContext,\n) -> Result<PublicKey, Error> {\n    context\n        .recover_raw(&signature.r, &signature.s, recovery_id.0, &message.0)\n        .map(PublicKey)\n}\n\n#[cfg(feature = \"static-context\")]\n/// Recover public key from a signed message.\npub fn recover(\n    message: &Message,\n    signature: &Signature,\n    recovery_id: &RecoveryId,\n) -> Result<PublicKey, Error> {\n    recover_with_context(message, signature, recovery_id, &ECMULT_CONTEXT)\n}\n\n#[cfg(feature = \"hmac\")]\n/// Sign a message using the secret key, with the given context.\npub fn sign_with_context(\n    message: &Message,\n    seckey: &SecretKey,\n    context: &ECMultGenContext,\n) -> (Signature, RecoveryId) {\n    let seckey_b32 = seckey.0.b32();\n    let message_b32 = message.0.b32();\n\n    let mut drbg = HmacDRBG::<Sha256>::new(&seckey_b32, &message_b32, &[]);\n    let mut nonce = Scalar::default();\n    let mut overflow;\n\n    let result;\n    loop {\n        let generated = drbg.generate::<U32>(None);\n        overflow = bool::from(nonce.set_b32(array_ref!(generated, 0, 32)));\n\n        if !overflow && !nonce.is_zero() {\n            if let Ok(val) = context.sign_raw(&seckey.0, &message.0, &nonce) {\n                result = val;\n                break;\n            }\n        }\n    }\n\n    #[allow(unused_assignments)]\n    {\n        nonce = Scalar::default();\n    }\n    let (sigr, sigs, recid) = result;\n\n    (Signature { r: sigr, s: sigs }, RecoveryId(recid))\n}\n\n#[cfg(all(feature = \"hmac\", feature = \"static-context\"))]\n/// Sign a message using the secret key.\npub fn sign(message: &Message, seckey: &SecretKey) -> (Signature, RecoveryId) {\n    sign_with_context(message, seckey, &ECMULT_GEN_CONTEXT)\n}\n\n#[cfg(test)]\nmod tests {\n    use crate::SecretKey;\n    use hex_literal::hex;\n\n    #[test]\n    fn secret_key_inverse_is_sane() {\n        let sk = SecretKey::parse(&[1; 32]).unwrap();\n        let inv = sk.inv();\n        let invinv = inv.inv();\n        assert_eq!(sk, invinv);\n        // Check that the inverse of `[1; 32]` is same as rust-secp256k1\n        assert_eq!(\n            inv,\n            SecretKey::parse(&hex!(\n                \"1536f1d756d1abf83aaf173bc5ee3fc487c93010f18624d80bd6d4038fadd59e\"\n            ))\n            .unwrap()\n        )\n    }\n}\n"
  },
  {
    "project": "crossbeam",
    "target": 1,
    "commit_id": "be6ff29e1fce196519b65cb0b647f1ad72659498",
    "func": "// Necessary for implementing atomic methods for `AtomicUnit`\n#![allow(clippy::unit_arg)]\n#![allow(clippy::let_unit_value)]\n\nuse crate::primitive::sync::atomic::{self, AtomicBool};\nuse core::cell::UnsafeCell;\nuse core::fmt;\nuse core::mem;\nuse core::sync::atomic::Ordering;\n\n#[cfg(not(crossbeam_loom))]\nuse core::ptr;\n\n#[cfg(feature = \"std\")]\nuse std::panic::{RefUnwindSafe, UnwindSafe};\n\n#[cfg(not(crossbeam_loom))]\nuse super::seq_lock::SeqLock;\n\n/// A thread-safe mutable memory location.\n///\n/// This type is equivalent to [`Cell`], except it can also be shared among multiple threads.\n///\n/// Operations on `AtomicCell`s use atomic instructions whenever possible, and synchronize using\n/// global locks otherwise. You can call [`AtomicCell::<T>::is_lock_free()`] to check whether\n/// atomic instructions or locks will be used.\n///\n/// Atomic loads use the [`Acquire`] ordering and atomic stores use the [`Release`] ordering.\n///\n/// [`Cell`]: std::cell::Cell\n/// [`AtomicCell::<T>::is_lock_free()`]: AtomicCell::is_lock_free\n/// [`Acquire`]: std::sync::atomic::Ordering::Acquire\n/// [`Release`]: std::sync::atomic::Ordering::Release\n#[repr(transparent)]\npub struct AtomicCell<T: ?Sized> {\n    /// The inner value.\n    ///\n    /// If this value can be transmuted into a primitive atomic type, it will be treated as such.\n    /// Otherwise, all potentially concurrent operations on this data will be protected by a global\n    /// lock.\n    value: UnsafeCell<T>,\n}\n\nunsafe impl<T: Send> Send for AtomicCell<T> {}\nunsafe impl<T: Send> Sync for AtomicCell<T> {}\n\n#[cfg(feature = \"std\")]\nimpl<T> UnwindSafe for AtomicCell<T> {}\n#[cfg(feature = \"std\")]\nimpl<T> RefUnwindSafe for AtomicCell<T> {}\n\nimpl<T> AtomicCell<T> {\n    /// Creates a new atomic cell initialized with `val`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use crossbeam_utils::atomic::AtomicCell;\n    ///\n    /// let a = AtomicCell::new(7);\n    /// ```\n    pub const fn new(val: T) -> AtomicCell<T> {\n        AtomicCell {\n            value: UnsafeCell::new(val),\n        }\n    }\n\n    /// Consumes the atomic and returns the contained value.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use crossbeam_utils::atomic::AtomicCell;\n    ///\n    /// let a = AtomicCell::new(7);\n    /// let v = a.into_inner();\n    ///\n    /// assert_eq!(v, 7);\n    /// ```\n    pub fn into_inner(self) -> T {\n        self.value.into_inner()\n    }\n\n    /// Returns `true` if operations on values of this type are lock-free.\n    ///\n    /// If the compiler or the platform doesn't support the necessary atomic instructions,\n    /// `AtomicCell<T>` will use global locks for every potentially concurrent atomic operation.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use crossbeam_utils::atomic::AtomicCell;\n    ///\n    /// // This type is internally represented as `AtomicUsize` so we can just use atomic\n    /// // operations provided by it.\n    /// assert_eq!(AtomicCell::<usize>::is_lock_free(), true);\n    ///\n    /// // A wrapper struct around `isize`.\n    /// struct Foo {\n    ///     bar: isize,\n    /// }\n    /// // `AtomicCell<Foo>` will be internally represented as `AtomicIsize`.\n    /// assert_eq!(AtomicCell::<Foo>::is_lock_free(), true);\n    ///\n    /// // Operations on zero-sized types are always lock-free.\n    /// assert_eq!(AtomicCell::<()>::is_lock_free(), true);\n    ///\n    /// // Very large types cannot be represented as any of the standard atomic types, so atomic\n    /// // operations on them will have to use global locks for synchronization.\n    /// assert_eq!(AtomicCell::<[u8; 1000]>::is_lock_free(), false);\n    /// ```\n    pub const fn is_lock_free() -> bool {\n        atomic_is_lock_free::<T>()\n    }\n\n    /// Stores `val` into the atomic cell.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use crossbeam_utils::atomic::AtomicCell;\n    ///\n    /// let a = AtomicCell::new(7);\n    ///\n    /// assert_eq!(a.load(), 7);\n    /// a.store(8);\n    /// assert_eq!(a.load(), 8);\n    /// ```\n    pub fn store(&self, val: T) {\n        if mem::needs_drop::<T>() {\n            drop(self.swap(val));\n        } else {\n            unsafe {\n                atomic_store(self.value.get(), val);\n            }\n        }\n    }\n\n    /// Stores `val` into the atomic cell and returns the previous value.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use crossbeam_utils::atomic::AtomicCell;\n    ///\n    /// let a = AtomicCell::new(7);\n    ///\n    /// assert_eq!(a.load(), 7);\n    /// assert_eq!(a.swap(8), 7);\n    /// assert_eq!(a.load(), 8);\n    /// ```\n    pub fn swap(&self, val: T) -> T {\n        unsafe { atomic_swap(self.value.get(), val) }\n    }\n}\n\nimpl<T: ?Sized> AtomicCell<T> {\n    /// Returns a raw pointer to the underlying data in this atomic cell.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use crossbeam_utils::atomic::AtomicCell;\n    ///\n    /// let a = AtomicCell::new(5);\n    ///\n    /// let ptr = a.as_ptr();\n    /// ```\n    #[inline]\n    pub fn as_ptr(&self) -> *mut T {\n        self.value.get()\n    }\n}\n\nimpl<T: Default> AtomicCell<T> {\n    /// Takes the value of the atomic cell, leaving `Default::default()` in its place.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use crossbeam_utils::atomic::AtomicCell;\n    ///\n    /// let a = AtomicCell::new(5);\n    /// let five = a.take();\n    ///\n    /// assert_eq!(five, 5);\n    /// assert_eq!(a.into_inner(), 0);\n    /// ```\n    pub fn take(&self) -> T {\n        self.swap(Default::default())\n    }\n}\n\nimpl<T: Copy> AtomicCell<T> {\n    /// Loads a value from the atomic cell.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use crossbeam_utils::atomic::AtomicCell;\n    ///\n    /// let a = AtomicCell::new(7);\n    ///\n    /// assert_eq!(a.load(), 7);\n    /// ```\n    pub fn load(&self) -> T {\n        unsafe { atomic_load(self.value.get()) }\n    }\n}\n\nimpl<T: Copy + Eq> AtomicCell<T> {\n    /// If the current value equals `current`, stores `new` into the atomic cell.\n    ///\n    /// The return value is always the previous value. If it is equal to `current`, then the value\n    /// was updated.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #![allow(deprecated)]\n    /// use crossbeam_utils::atomic::AtomicCell;\n    ///\n    /// let a = AtomicCell::new(1);\n    ///\n    /// assert_eq!(a.compare_and_swap(2, 3), 1);\n    /// assert_eq!(a.load(), 1);\n    ///\n    /// assert_eq!(a.compare_and_swap(1, 2), 1);\n    /// assert_eq!(a.load(), 2);\n    /// ```\n    // TODO: remove in the next major version.\n    #[deprecated(note = \"Use `compare_exchange` instead\")]\n    pub fn compare_and_swap(&self, current: T, new: T) -> T {\n        match self.compare_exchange(current, new) {\n            Ok(v) => v,\n            Err(v) => v,\n        }\n    }\n\n    /// If the current value equals `current`, stores `new` into the atomic cell.\n    ///\n    /// The return value is a result indicating whether the new value was written and containing\n    /// the previous value. On success this value is guaranteed to be equal to `current`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use crossbeam_utils::atomic::AtomicCell;\n    ///\n    /// let a = AtomicCell::new(1);\n    ///\n    /// assert_eq!(a.compare_exchange(2, 3), Err(1));\n    /// assert_eq!(a.load(), 1);\n    ///\n    /// assert_eq!(a.compare_exchange(1, 2), Ok(1));\n    /// assert_eq!(a.load(), 2);\n    /// ```\n    pub fn compare_exchange(&self, current: T, new: T) -> Result<T, T> {\n        unsafe { atomic_compare_exchange_weak(self.value.get(), current, new) }\n    }\n\n    /// Fetches the value, and applies a function to it that returns an optional\n    /// new value. Returns a `Result` of `Ok(previous_value)` if the function returned `Some(_)`, else\n    /// `Err(previous_value)`.\n    ///\n    /// Note: This may call the function multiple times if the value has been changed from other threads in\n    /// the meantime, as long as the function returns `Some(_)`, but the function will have been applied\n    /// only once to the stored value.\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// use crossbeam_utils::atomic::AtomicCell;\n    ///\n    /// let a = AtomicCell::new(7);\n    /// assert_eq!(a.fetch_update(|_| None), Err(7));\n    /// assert_eq!(a.fetch_update(|a| Some(a + 1)), Ok(7));\n    /// assert_eq!(a.fetch_update(|a| Some(a + 1)), Ok(8));\n    /// assert_eq!(a.load(), 9);\n    /// ```\n    #[inline]\n    pub fn fetch_update<F>(&self, mut f: F) -> Result<T, T>\n    where\n        F: FnMut(T) -> Option<T>,\n    {\n        let mut prev = self.load();\n        while let Some(next) = f(prev) {\n            match self.compare_exchange(prev, next) {\n                x @ Ok(_) => return x,\n                Err(next_prev) => prev = next_prev,\n            }\n        }\n        Err(prev)\n    }\n}\n\nmacro_rules! impl_arithmetic {\n    ($t:ty, fallback, $example:tt) => {\n        impl AtomicCell<$t> {\n            /// Increments the current value by `val` and returns the previous value.\n            ///\n            /// The addition wraps on overflow.\n            ///\n            /// # Examples\n            ///\n            /// ```\n            /// use crossbeam_utils::atomic::AtomicCell;\n            ///\n            #[doc = $example]\n            ///\n            /// assert_eq!(a.fetch_add(3), 7);\n            /// assert_eq!(a.load(), 10);\n            /// ```\n            #[inline]\n            pub fn fetch_add(&self, val: $t) -> $t {\n                #[cfg(crossbeam_loom)]\n                {\n                    let _ = val;\n                    unimplemented!(\"loom does not support non-atomic atomic ops\");\n                }\n                #[cfg(not(crossbeam_loom))]\n                {\n                    let _guard = lock(self.value.get() as usize).write();\n                    let value = unsafe { &mut *(self.value.get()) };\n                    let old = *value;\n                    *value = value.wrapping_add(val);\n                    old\n                }\n            }\n\n            /// Decrements the current value by `val` and returns the previous value.\n            ///\n            /// The subtraction wraps on overflow.\n            ///\n            /// # Examples\n            ///\n            /// ```\n            /// use crossbeam_utils::atomic::AtomicCell;\n            ///\n            #[doc = $example]\n            ///\n            /// assert_eq!(a.fetch_sub(3), 7);\n            /// assert_eq!(a.load(), 4);\n            /// ```\n            #[inline]\n            pub fn fetch_sub(&self, val: $t) -> $t {\n                #[cfg(crossbeam_loom)]\n                {\n                    let _ = val;\n                    unimplemented!(\"loom does not support non-atomic atomic ops\");\n                }\n                #[cfg(not(crossbeam_loom))]\n                {\n                    let _guard = lock(self.value.get() as usize).write();\n                    let value = unsafe { &mut *(self.value.get()) };\n                    let old = *value;\n                    *value = value.wrapping_sub(val);\n                    old\n                }\n            }\n\n            /// Applies bitwise \"and\" to the current value and returns the previous value.\n            ///\n            /// # Examples\n            ///\n            /// ```\n            /// use crossbeam_utils::atomic::AtomicCell;\n            ///\n            #[doc = $example]\n            ///\n            /// assert_eq!(a.fetch_and(3), 7);\n            /// assert_eq!(a.load(), 3);\n            /// ```\n            #[inline]\n            pub fn fetch_and(&self, val: $t) -> $t {\n                #[cfg(crossbeam_loom)]\n                {\n                    let _ = val;\n                    unimplemented!(\"loom does not support non-atomic atomic ops\");\n                }\n                #[cfg(not(crossbeam_loom))]\n                {\n                    let _guard = lock(self.value.get() as usize).write();\n                    let value = unsafe { &mut *(self.value.get()) };\n                    let old = *value;\n                    *value &= val;\n                    old\n                }\n            }\n\n            /// Applies bitwise \"or\" to the current value and returns the previous value.\n            ///\n            /// # Examples\n            ///\n            /// ```\n            /// use crossbeam_utils::atomic::AtomicCell;\n            ///\n            #[doc = $example]\n            ///\n            /// assert_eq!(a.fetch_or(16), 7);\n            /// assert_eq!(a.load(), 23);\n            /// ```\n            #[inline]\n            pub fn fetch_or(&self, val: $t) -> $t {\n                #[cfg(crossbeam_loom)]\n                {\n                    let _ = val;\n                    unimplemented!(\"loom does not support non-atomic atomic ops\");\n                }\n                #[cfg(not(crossbeam_loom))]\n                {\n                    let _guard = lock(self.value.get() as usize).write();\n                    let value = unsafe { &mut *(self.value.get()) };\n                    let old = *value;\n                    *value |= val;\n                    old\n                }\n            }\n\n            /// Applies bitwise \"xor\" to the current value and returns the previous value.\n            ///\n            /// # Examples\n            ///\n            /// ```\n            /// use crossbeam_utils::atomic::AtomicCell;\n            ///\n            #[doc = $example]\n            ///\n            /// assert_eq!(a.fetch_xor(2), 7);\n            /// assert_eq!(a.load(), 5);\n            /// ```\n            #[inline]\n            pub fn fetch_xor(&self, val: $t) -> $t {\n                #[cfg(crossbeam_loom)]\n                {\n                    let _ = val;\n                    unimplemented!(\"loom does not support non-atomic atomic ops\");\n                }\n                #[cfg(not(crossbeam_loom))]\n                {\n                    let _guard = lock(self.value.get() as usize).write();\n                    let value = unsafe { &mut *(self.value.get()) };\n                    let old = *value;\n                    *value ^= val;\n                    old\n                }\n            }\n        }\n    };\n    ($t:ty, $atomic:ty, $example:tt) => {\n        impl AtomicCell<$t> {\n            /// Increments the current value by `val` and returns the previous value.\n            ///\n            /// The addition wraps on overflow.\n            ///\n            /// # Examples\n            ///\n            /// ```\n            /// use crossbeam_utils::atomic::AtomicCell;\n            ///\n            #[doc = $example]\n            ///\n            /// assert_eq!(a.fetch_add(3), 7);\n            /// assert_eq!(a.load(), 10);\n            /// ```\n            #[inline]\n            pub fn fetch_add(&self, val: $t) -> $t {\n                let a = unsafe { &*(self.value.get() as *const $atomic) };\n                a.fetch_add(val, Ordering::AcqRel)\n            }\n\n            /// Decrements the current value by `val` and returns the previous value.\n            ///\n            /// The subtraction wraps on overflow.\n            ///\n            /// # Examples\n            ///\n            /// ```\n            /// use crossbeam_utils::atomic::AtomicCell;\n            ///\n            #[doc = $example]\n            ///\n            /// assert_eq!(a.fetch_sub(3), 7);\n            /// assert_eq!(a.load(), 4);\n            /// ```\n            #[inline]\n            pub fn fetch_sub(&self, val: $t) -> $t {\n                let a = unsafe { &*(self.value.get() as *const $atomic) };\n                a.fetch_sub(val, Ordering::AcqRel)\n            }\n\n            /// Applies bitwise \"and\" to the current value and returns the previous value.\n            ///\n            /// # Examples\n            ///\n            /// ```\n            /// use crossbeam_utils::atomic::AtomicCell;\n            ///\n            #[doc = $example]\n            ///\n            /// assert_eq!(a.fetch_and(3), 7);\n            /// assert_eq!(a.load(), 3);\n            /// ```\n            #[inline]\n            pub fn fetch_and(&self, val: $t) -> $t {\n                let a = unsafe { &*(self.value.get() as *const $atomic) };\n                a.fetch_and(val, Ordering::AcqRel)\n            }\n\n            /// Applies bitwise \"or\" to the current value and returns the previous value.\n            ///\n            /// # Examples\n            ///\n            /// ```\n            /// use crossbeam_utils::atomic::AtomicCell;\n            ///\n            #[doc = $example]\n            ///\n            /// assert_eq!(a.fetch_or(16), 7);\n            /// assert_eq!(a.load(), 23);\n            /// ```\n            #[inline]\n            pub fn fetch_or(&self, val: $t) -> $t {\n                let a = unsafe { &*(self.value.get() as *const $atomic) };\n                a.fetch_or(val, Ordering::AcqRel)\n            }\n\n            /// Applies bitwise \"xor\" to the current value and returns the previous value.\n            ///\n            /// # Examples\n            ///\n            /// ```\n            /// use crossbeam_utils::atomic::AtomicCell;\n            ///\n            #[doc = $example]\n            ///\n            /// assert_eq!(a.fetch_xor(2), 7);\n            /// assert_eq!(a.load(), 5);\n            /// ```\n            #[inline]\n            pub fn fetch_xor(&self, val: $t) -> $t {\n                let a = unsafe { &*(self.value.get() as *const $atomic) };\n                a.fetch_xor(val, Ordering::AcqRel)\n            }\n        }\n    };\n}\n\nimpl_arithmetic!(u8, atomic::AtomicU8, \"let a = AtomicCell::new(7u8);\");\nimpl_arithmetic!(i8, atomic::AtomicI8, \"let a = AtomicCell::new(7i8);\");\nimpl_arithmetic!(u16, atomic::AtomicU16, \"let a = AtomicCell::new(7u16);\");\nimpl_arithmetic!(i16, atomic::AtomicI16, \"let a = AtomicCell::new(7i16);\");\nimpl_arithmetic!(u32, atomic::AtomicU32, \"let a = AtomicCell::new(7u32);\");\nimpl_arithmetic!(i32, atomic::AtomicI32, \"let a = AtomicCell::new(7i32);\");\n#[cfg(not(crossbeam_no_atomic_64))]\nimpl_arithmetic!(u64, atomic::AtomicU64, \"let a = AtomicCell::new(7u64);\");\n#[cfg(not(crossbeam_no_atomic_64))]\nimpl_arithmetic!(i64, atomic::AtomicI64, \"let a = AtomicCell::new(7i64);\");\n#[cfg(crossbeam_no_atomic_64)]\nimpl_arithmetic!(u64, fallback, \"let a = AtomicCell::new(7u64);\");\n#[cfg(crossbeam_no_atomic_64)]\nimpl_arithmetic!(i64, fallback, \"let a = AtomicCell::new(7i64);\");\n// TODO: AtomicU128 is unstable\n// impl_arithmetic!(u128, atomic::AtomicU128, \"let a = AtomicCell::new(7u128);\");\n// impl_arithmetic!(i128, atomic::AtomicI128, \"let a = AtomicCell::new(7i128);\");\nimpl_arithmetic!(u128, fallback, \"let a = AtomicCell::new(7u128);\");\nimpl_arithmetic!(i128, fallback, \"let a = AtomicCell::new(7i128);\");\n\nimpl_arithmetic!(\n    usize,\n    atomic::AtomicUsize,\n    \"let a = AtomicCell::new(7usize);\"\n);\nimpl_arithmetic!(\n    isize,\n    atomic::AtomicIsize,\n    \"let a = AtomicCell::new(7isize);\"\n);\n\nimpl AtomicCell<bool> {\n    /// Applies logical \"and\" to the current value and returns the previous value.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use crossbeam_utils::atomic::AtomicCell;\n    ///\n    /// let a = AtomicCell::new(true);\n    ///\n    /// assert_eq!(a.fetch_and(true), true);\n    /// assert_eq!(a.load(), true);\n    ///\n    /// assert_eq!(a.fetch_and(false), true);\n    /// assert_eq!(a.load(), false);\n    /// ```\n    #[inline]\n    pub fn fetch_and(&self, val: bool) -> bool {\n        let a = unsafe { &*(self.value.get() as *const AtomicBool) };\n        a.fetch_and(val, Ordering::AcqRel)\n    }\n\n    /// Applies logical \"or\" to the current value and returns the previous value.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use crossbeam_utils::atomic::AtomicCell;\n    ///\n    /// let a = AtomicCell::new(false);\n    ///\n    /// assert_eq!(a.fetch_or(false), false);\n    /// assert_eq!(a.load(), false);\n    ///\n    /// assert_eq!(a.fetch_or(true), false);\n    /// assert_eq!(a.load(), true);\n    /// ```\n    #[inline]\n    pub fn fetch_or(&self, val: bool) -> bool {\n        let a = unsafe { &*(self.value.get() as *const AtomicBool) };\n        a.fetch_or(val, Ordering::AcqRel)\n    }\n\n    /// Applies logical \"xor\" to the current value and returns the previous value.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use crossbeam_utils::atomic::AtomicCell;\n    ///\n    /// let a = AtomicCell::new(true);\n    ///\n    /// assert_eq!(a.fetch_xor(false), true);\n    /// assert_eq!(a.load(), true);\n    ///\n    /// assert_eq!(a.fetch_xor(true), true);\n    /// assert_eq!(a.load(), false);\n    /// ```\n    #[inline]\n    pub fn fetch_xor(&self, val: bool) -> bool {\n        let a = unsafe { &*(self.value.get() as *const AtomicBool) };\n        a.fetch_xor(val, Ordering::AcqRel)\n    }\n}\n\nimpl<T: Default> Default for AtomicCell<T> {\n    fn default() -> AtomicCell<T> {\n        AtomicCell::new(T::default())\n    }\n}\n\nimpl<T> From<T> for AtomicCell<T> {\n    #[inline]\n    fn from(val: T) -> AtomicCell<T> {\n        AtomicCell::new(val)\n    }\n}\n\nimpl<T: Copy + fmt::Debug> fmt::Debug for AtomicCell<T> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"AtomicCell\")\n            .field(\"value\", &self.load())\n            .finish()\n    }\n}\n\n/// Returns `true` if values of type `A` can be transmuted into values of type `B`.\nconst fn can_transmute<A, B>() -> bool {\n    // Sizes must be equal, but alignment of `A` must be greater or equal than that of `B`.\n    (mem::size_of::<A>() == mem::size_of::<B>()) & (mem::align_of::<A>() >= mem::align_of::<B>())\n}\n\n/// Returns a reference to the global lock associated with the `AtomicCell` at address `addr`.\n///\n/// This function is used to protect atomic data which doesn't fit into any of the primitive atomic\n/// types in `std::sync::atomic`. Operations on such atomics must therefore use a global lock.\n///\n/// However, there is not only one global lock but an array of many locks, and one of them is\n/// picked based on the given address. Having many locks reduces contention and improves\n/// scalability.\n#[inline]\n#[must_use]\n#[cfg(not(crossbeam_loom))]\nfn lock(addr: usize) -> &'static SeqLock {\n    // The number of locks is a prime number because we want to make sure `addr % LEN` gets\n    // dispersed across all locks.\n    //\n    // Note that addresses are always aligned to some power of 2, depending on type `T` in\n    // `AtomicCell<T>`. If `LEN` was an even number, then `addr % LEN` would be an even number,\n    // too, which means only half of the locks would get utilized!\n    //\n    // It is also possible for addresses to accidentally get aligned to a number that is not a\n    // power of 2. Consider this example:\n    //\n    // ```\n    // #[repr(C)]\n    // struct Foo {\n    //     a: AtomicCell<u8>,\n    //     b: u8,\n    //     c: u8,\n    // }\n    // ```\n    //\n    // Now, if we have a slice of type `&[Foo]`, it is possible that field `a` in all items gets\n    // stored at addresses that are multiples of 3. It'd be too bad if `LEN` was divisible by 3.\n    // In order to protect from such cases, we simply choose a large prime number for `LEN`.\n    const LEN: usize = 97;\n    #[allow(clippy::declare_interior_mutable_const)]\n    const L: SeqLock = SeqLock::new();\n    static LOCKS: [SeqLock; LEN] = [\n        L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L,\n        L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L,\n        L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L,\n        L, L, L, L, L, L, L,\n    ];\n\n    // If the modulus is a constant number, the compiler will use crazy math to transform this into\n    // a sequence of cheap arithmetic operations rather than using the slow modulo instruction.\n    &LOCKS[addr % LEN]\n}\n\n/// An atomic `()`.\n///\n/// All operations are noops.\nstruct AtomicUnit;\n\nimpl AtomicUnit {\n    #[inline]\n    fn load(&self, _order: Ordering) {}\n\n    #[inline]\n    fn store(&self, _val: (), _order: Ordering) {}\n\n    #[inline]\n    fn swap(&self, _val: (), _order: Ordering) {}\n\n    #[allow(clippy::unnecessary_wraps)] // This is intentional.\n    #[inline]\n    fn compare_exchange_weak(\n        &self,\n        _current: (),\n        _new: (),\n        _success: Ordering,\n        _failure: Ordering,\n    ) -> Result<(), ()> {\n        Ok(())\n    }\n}\n\nmacro_rules! atomic {\n    // If values of type `$t` can be transmuted into values of the primitive atomic type `$atomic`,\n    // declares variable `$a` of type `$atomic` and executes `$atomic_op`, breaking out of the loop.\n    (@check, $t:ty, $atomic:ty, $a:ident, $atomic_op:expr) => {\n        if can_transmute::<$t, $atomic>() {\n            let $a: &$atomic;\n            break $atomic_op;\n        }\n    };\n\n    // If values of type `$t` can be transmuted into values of a primitive atomic type, declares\n    // variable `$a` of that type and executes `$atomic_op`. Otherwise, just executes\n    // `$fallback_op`.\n    ($t:ty, $a:ident, $atomic_op:expr, $fallback_op:expr) => {\n        loop {\n            atomic!(@check, $t, AtomicUnit, $a, $atomic_op);\n\n            atomic!(@check, $t, atomic::AtomicU8, $a, $atomic_op);\n            atomic!(@check, $t, atomic::AtomicU16, $a, $atomic_op);\n            atomic!(@check, $t, atomic::AtomicU32, $a, $atomic_op);\n            #[cfg(not(crossbeam_no_atomic_64))]\n            atomic!(@check, $t, atomic::AtomicU64, $a, $atomic_op);\n            // TODO: AtomicU128 is unstable\n            // atomic!(@check, $t, atomic::AtomicU128, $a, $atomic_op);\n\n            #[cfg(crossbeam_loom)]\n            unimplemented!(\"loom does not support non-atomic atomic ops\");\n            #[cfg(not(crossbeam_loom))]\n            break $fallback_op;\n        }\n    };\n}\n\n/// Returns `true` if operations on `AtomicCell<T>` are lock-free.\nconst fn atomic_is_lock_free<T>() -> bool {\n    // HACK(taiki-e): This is equivalent to `atomic! { T, _a, true, false }`, but can be used in const fn even in Rust 1.36.\n    let is_lock_free = can_transmute::<T, AtomicUnit>()\n        | can_transmute::<T, atomic::AtomicU8>()\n        | can_transmute::<T, atomic::AtomicU16>()\n        | can_transmute::<T, atomic::AtomicU32>();\n    #[cfg(not(crossbeam_no_atomic_64))]\n    let is_lock_free = is_lock_free | can_transmute::<T, atomic::AtomicU64>();\n    // TODO: AtomicU128 is unstable\n    // let is_lock_free = is_lock_free | can_transmute::<T, atomic::AtomicU128>();\n    is_lock_free\n}\n\n/// Atomically reads data from `src`.\n///\n/// This operation uses the `Acquire` ordering. If possible, an atomic instructions is used, and a\n/// global lock otherwise.\nunsafe fn atomic_load<T>(src: *mut T) -> T\nwhere\n    T: Copy,\n{\n    atomic! {\n        T, a,\n        {\n            a = &*(src as *const _ as *const _);\n            mem::transmute_copy(&a.load(Ordering::Acquire))\n        },\n        {\n            let lock = lock(src as usize);\n\n            // Try doing an optimistic read first.\n            if let Some(stamp) = lock.optimistic_read() {\n                // We need a volatile read here because other threads might concurrently modify the\n                // value. In theory, data races are *always* UB, even if we use volatile reads and\n                // discard the data when a data race is detected. The proper solution would be to\n                // do atomic reads and atomic writes, but we can't atomically read and write all\n                // kinds of data since `AtomicU8` is not available on stable Rust yet.\n                let val = ptr::read_volatile(src);\n\n                if lock.validate_read(stamp) {\n                    return val;\n                }\n            }\n\n            // Grab a regular write lock so that writers don't starve this load.\n            let guard = lock.write();\n            let val = ptr::read(src);\n            // The value hasn't been changed. Drop the guard without incrementing the stamp.\n            guard.abort();\n            val\n        }\n    }\n}\n\n/// Atomically writes `val` to `dst`.\n///\n/// This operation uses the `Release` ordering. If possible, an atomic instructions is used, and a\n/// global lock otherwise.\nunsafe fn atomic_store<T>(dst: *mut T, val: T) {\n    atomic! {\n        T, a,\n        {\n            a = &*(dst as *const _ as *const _);\n            a.store(mem::transmute_copy(&val), Ordering::Release);\n            mem::forget(val);\n        },\n        {\n            let _guard = lock(dst as usize).write();\n            ptr::write(dst, val);\n        }\n    }\n}\n\n/// Atomically swaps data at `dst` with `val`.\n///\n/// This operation uses the `AcqRel` ordering. If possible, an atomic instructions is used, and a\n/// global lock otherwise.\nunsafe fn atomic_swap<T>(dst: *mut T, val: T) -> T {\n    atomic! {\n        T, a,\n        {\n            a = &*(dst as *const _ as *const _);\n            let res = mem::transmute_copy(&a.swap(mem::transmute_copy(&val), Ordering::AcqRel));\n            mem::forget(val);\n            res\n        },\n        {\n            let _guard = lock(dst as usize).write();\n            ptr::replace(dst, val)\n        }\n    }\n}\n\n/// Atomically compares data at `dst` to `current` and, if equal byte-for-byte, exchanges data at\n/// `dst` with `new`.\n///\n/// Returns the old value on success, or the current value at `dst` on failure.\n///\n/// This operation uses the `AcqRel` ordering. If possible, an atomic instructions is used, and a\n/// global lock otherwise.\nunsafe fn atomic_compare_exchange_weak<T>(dst: *mut T, mut current: T, new: T) -> Result<T, T>\nwhere\n    T: Copy + Eq,\n{\n    atomic! {\n        T, a,\n        {\n            a = &*(dst as *const _ as *const _);\n            let mut current_raw = mem::transmute_copy(&current);\n            let new_raw = mem::transmute_copy(&new);\n\n            loop {\n                match a.compare_exchange_weak(\n                    current_raw,\n                    new_raw,\n                    Ordering::AcqRel,\n                    Ordering::Acquire,\n                ) {\n                    Ok(_) => break Ok(current),\n                    Err(previous_raw) => {\n                        let previous = mem::transmute_copy(&previous_raw);\n\n                        if !T::eq(&previous, &current) {\n                            break Err(previous);\n                        }\n\n                        // The compare-exchange operation has failed and didn't store `new`. The\n                        // failure is either spurious, or `previous` was semantically equal to\n                        // `current` but not byte-equal. Let's retry with `previous` as the new\n                        // `current`.\n                        current = previous;\n                        current_raw = previous_raw;\n                    }\n                }\n            }\n        },\n        {\n            let guard = lock(dst as usize).write();\n\n            if T::eq(&*dst, &current) {\n                Ok(ptr::replace(dst, new))\n            } else {\n                let val = ptr::read(dst);\n                // The value hasn't been changed. Drop the guard without incrementing the stamp.\n                guard.abort();\n                Err(val)\n            }\n        }\n    }\n}\n"
  },
  {
    "project": "im-rs",
    "target": 1,
    "commit_id": "3f4e01a43254fe228d1ce64e47dfaf4edc8f4f19",
    "func": "// This Source Code Form is subject to the terms of the Mozilla Public\n// License, v. 2.0. If a copy of the MPL was not distributed with this\n// file, You can obtain one at http://mozilla.org/MPL/2.0/.\n\nuse std::mem::{replace, swap};\nuse std::ops::{Range, RangeBounds};\nuse std::ptr::null;\nuse std::sync::atomic::{AtomicPtr, Ordering};\n\nuse crate::nodes::chunk::Chunk;\nuse crate::sync::Lock;\nuse crate::util::{to_range, PoolRef, Ref};\nuse crate::vector::{\n    Iter, IterMut, RRBPool, Vector,\n    VectorInner::{Full, Inline, Single},\n    RRB,\n};\n\n/// Focused indexing over a [`Vector`][Vector].\n///\n/// By remembering the last tree node accessed through an index lookup and the\n/// path we took to get there, we can speed up lookups for adjacent indices\n/// tremendously. Lookups on indices in the same node are instantaneous, and\n/// lookups on sibling nodes are also very fast.\n///\n/// A `Focus` can also be used as a restricted view into a vector, using the\n/// [`narrow`][narrow] and [`split_at`][split_at] methods.\n///\n/// # When should I use a `Focus` for better performance?\n///\n/// `Focus` is useful when you need to perform a large number of index lookups\n/// that are more likely than not to be close to each other. It's usually worth\n/// using a `Focus` in any situation where you're batching a lot of index\n/// lookups together, even if they're not obviously adjacent - there's likely\n/// to be some performance gain for even completely random access.\n///\n/// If you're just iterating forwards or backwards over the [`Vector`][Vector]\n/// in order, you're better off with a regular iterator, which, in fact, is\n/// implemented using a `Focus`, but provides a simpler interface.\n///\n/// If you're just doing a very small number of index lookups, the setup cost\n/// for the `Focus` is probably not worth it.\n///\n/// A `Focus` is never faster than an index lookup on a small [`Vector`][Vector]\n/// with a length below the internal RRB tree's branching factor of 64.\n///\n/// # Examples\n///\n/// This example is contrived, as the better way to iterate forwards or\n/// backwards over a vector is with an actual iterator. Even so, the version\n/// using a `Focus` should run nearly an order of magnitude faster than the\n/// version using index lookups at a length of 1000. It should also be noted\n/// that [`vector::Iter`][Iter] is actually implemented using a `Focus` behind\n/// the scenes, so the performance of the two should be identical.\n///\n/// ```rust\n/// # #[macro_use] extern crate im;\n/// # use im::vector::Vector;\n/// # use std::iter::FromIterator;\n/// let mut vec: Vector<i64> = Vector::from_iter(0..1000);\n///\n/// // Summing a vector, the slow way:\n/// let mut sum = 0;\n/// for i in 0..1000 {\n///     sum += *vec.get(i).unwrap();\n/// }\n/// assert_eq!(499500, sum);\n///\n/// // Summing a vector faster using a Focus:\n/// let mut sum = 0;\n/// let mut focus = vec.focus();\n/// for i in 0..1000 {\n///     sum += *focus.get(i).unwrap();\n/// }\n/// assert_eq!(499500, sum);\n///\n/// // And the easy way, for completeness:\n/// let sum: i64 = vec.iter().sum();\n/// assert_eq!(499500, sum);\n/// ```\n///\n/// [Vector]: enum.Vector.html\n/// [Iter]: struct.Iter.html\n/// [narrow]: #method.narrow\n/// [split_at]: #method.split_at\npub enum Focus<'a, A> {\n    #[doc(hidden)]\n    Single(&'a [A]),\n    #[doc(hidden)]\n    Full(TreeFocus<A>),\n}\n\nimpl<'a, A> Focus<'a, A>\nwhere\n    A: Clone + 'a,\n{\n    /// Construct a `Focus` for a [`Vector`][Vector].\n    ///\n    /// [Vector]: enum.Vector.html\n    pub fn new(vector: &'a Vector<A>) -> Self {\n        match &vector.vector {\n            Inline(_, chunk) => Focus::Single(chunk),\n            Single(_, chunk) => Focus::Single(chunk),\n            Full(_, tree) => Focus::Full(TreeFocus::new(tree)),\n        }\n    }\n\n    /// Get the length of the focused [`Vector`][Vector].\n    ///\n    /// [Vector]: enum.Vector.html\n    pub fn len(&self) -> usize {\n        match self {\n            Focus::Single(chunk) => chunk.len(),\n            Focus::Full(tree) => tree.len(),\n        }\n    }\n\n    /// Test if the focused [`Vector`][Vector] is empty.\n    ///\n    /// [Vector]: enum.Vector.html\n    pub fn is_empty(&self) -> bool {\n        self.len() == 0\n    }\n\n    /// Get a reference to the value at a given index.\n    pub fn get(&mut self, index: usize) -> Option<&A> {\n        match self {\n            Focus::Single(chunk) => chunk.get(index),\n            Focus::Full(tree) => tree.get(index),\n        }\n    }\n\n    /// Get a reference to the value at a given index.\n    ///\n    /// Panics if the index is out of bounds.\n    pub fn index(&mut self, index: usize) -> &A {\n        self.get(index).expect(\"index out of bounds\")\n    }\n\n    /// Get the chunk for the given index.\n    ///\n    /// This gives you a reference to the leaf node that contains the index,\n    /// along with its start and end indices.\n    pub fn chunk_at(&mut self, index: usize) -> (Range<usize>, &[A]) {\n        let len = self.len();\n        if index >= len {\n            panic!(\"vector::Focus::chunk_at: index out of bounds\");\n        }\n        match self {\n            Focus::Single(chunk) => (0..len, chunk),\n            Focus::Full(tree) => tree.get_chunk(index),\n        }\n    }\n\n    /// Narrow the focus onto a subslice of the vector.\n    ///\n    /// `Focus::narrow(range)` has the same effect as `&slice[range]`, without\n    /// actually modifying the underlying vector.\n    ///\n    /// Panics if the range isn't fully inside the current focus.\n    ///\n    /// ## Examples\n    ///\n    /// ```rust\n    /// # #[macro_use] extern crate im;\n    /// # use im::vector::Vector;\n    /// # use std::iter::FromIterator;\n    /// let vec = Vector::from_iter(0..1000);\n    /// let narrowed = vec.focus().narrow(100..200);\n    /// let narrowed_vec = narrowed.into_iter().cloned().collect();\n    /// assert_eq!(Vector::from_iter(100..200), narrowed_vec);\n    /// ```\n    ///\n    /// [slice::split_at]: https://doc.rust-lang.org/std/primitive.slice.html#method.split_at\n    /// [Vector::split_at]: enum.Vector.html#method.split_at\n    pub fn narrow<R>(self, range: R) -> Self\n    where\n        R: RangeBounds<usize>,\n    {\n        let r = to_range(&range, self.len());\n        if r.start >= r.end || r.start >= self.len() {\n            panic!(\"vector::Focus::narrow: range out of bounds\");\n        }\n        match self {\n            Focus::Single(chunk) => Focus::Single(&chunk[r]),\n            Focus::Full(tree) => Focus::Full(tree.narrow(r)),\n        }\n    }\n\n    /// Split the focus into two.\n    ///\n    /// Given an index `index`, consume the focus and produce two new foci, the\n    /// left onto indices `0..index`, and the right onto indices `index..N`\n    /// where `N` is the length of the current focus.\n    ///\n    /// Panics if the index is out of bounds.\n    ///\n    /// This is the moral equivalent of [`slice::split_at`][slice::split_at], in\n    /// that it leaves the underlying data structure unchanged, unlike\n    /// [`Vector::split_at`][Vector::split_at].\n    ///\n    /// ## Examples\n    ///\n    /// ```rust\n    /// # #[macro_use] extern crate im;\n    /// # use im::vector::Vector;\n    /// # use std::iter::FromIterator;\n    /// let vec = Vector::from_iter(0..1000);\n    /// let (left, right) = vec.focus().split_at(500);\n    /// let left_vec = left.into_iter().cloned().collect();\n    /// let right_vec = right.into_iter().cloned().collect();\n    /// assert_eq!(Vector::from_iter(0..500), left_vec);\n    /// assert_eq!(Vector::from_iter(500..1000), right_vec);\n    /// ```\n    ///\n    /// [slice::split_at]: https://doc.rust-lang.org/std/primitive.slice.html#method.split_at\n    /// [Vector::split_at]: enum.Vector.html#method.split_at\n    pub fn split_at(self, index: usize) -> (Self, Self) {\n        if index >= self.len() {\n            panic!(\"vector::Focus::split_at: index out of bounds\");\n        }\n        match self {\n            Focus::Single(chunk) => {\n                let (left, right) = chunk.split_at(index);\n                (Focus::Single(left), Focus::Single(right))\n            }\n            Focus::Full(tree) => {\n                let (left, right) = tree.split_at(index);\n                (Focus::Full(left), Focus::Full(right))\n            }\n        }\n    }\n}\n\nimpl<'a, A> IntoIterator for Focus<'a, A>\nwhere\n    A: Clone + 'a,\n{\n    type Item = &'a A;\n    type IntoIter = Iter<'a, A>;\n\n    fn into_iter(self) -> Self::IntoIter {\n        Iter::from_focus(self)\n    }\n}\n\nimpl<'a, A> Clone for Focus<'a, A>\nwhere\n    A: Clone + 'a,\n{\n    fn clone(&self) -> Self {\n        match self {\n            Focus::Single(chunk) => Focus::Single(chunk),\n            Focus::Full(tree) => Focus::Full(tree.clone()),\n        }\n    }\n}\n\npub struct TreeFocus<A> {\n    tree: RRB<A>,\n    view: Range<usize>,\n    middle_range: Range<usize>,\n    target_range: Range<usize>,\n    target_ptr: *const Chunk<A>,\n}\n\nimpl<A> Clone for TreeFocus<A> {\n    fn clone(&self) -> Self {\n        let tree = self.tree.clone();\n        TreeFocus {\n            view: self.view.clone(),\n            middle_range: self.middle_range.clone(),\n            target_range: 0..0,\n            target_ptr: null(),\n            tree,\n        }\n    }\n}\n\n#[allow(unsafe_code)]\n#[cfg(threadsafe)]\nunsafe impl<A> Send for TreeFocus<A> {}\n#[allow(unsafe_code)]\n#[cfg(threadsafe)]\nunsafe impl<A> Sync for TreeFocus<A> {}\n\n#[inline]\nfn contains<A: Ord>(range: &Range<A>, index: &A) -> bool {\n    *index >= range.start && *index < range.end\n}\n\nimpl<A> TreeFocus<A>\nwhere\n    A: Clone,\n{\n    fn new(tree: &RRB<A>) -> Self {\n        let middle_start = tree.outer_f.len() + tree.inner_f.len();\n        let middle_end = middle_start + tree.middle.len();\n        TreeFocus {\n            tree: tree.clone(),\n            view: 0..tree.length,\n            middle_range: middle_start..middle_end,\n            target_range: 0..0,\n            target_ptr: null(),\n        }\n    }\n\n    fn len(&self) -> usize {\n        self.view.end - self.view.start\n    }\n\n    fn narrow(self, mut view: Range<usize>) -> Self {\n        view.start += self.view.start;\n        view.end += self.view.start;\n        TreeFocus {\n            view,\n            middle_range: self.middle_range.clone(),\n            target_range: 0..0,\n            target_ptr: null(),\n            tree: self.tree,\n        }\n    }\n\n    fn split_at(self, index: usize) -> (Self, Self) {\n        let len = self.len();\n        let left = self.clone().narrow(0..index);\n        let right = self.narrow(index..len);\n        (left, right)\n    }\n\n    fn physical_index(&self, index: usize) -> usize {\n        debug_assert!(index < self.view.end);\n        self.view.start + index\n    }\n\n    fn logical_range(&self, range: &Range<usize>) -> Range<usize> {\n        (range.start - self.view.start)..(range.end - self.view.start)\n    }\n\n    fn set_focus(&mut self, index: usize) {\n        if index < self.middle_range.start {\n            let outer_len = self.tree.outer_f.len();\n            if index < outer_len {\n                self.target_range = 0..outer_len;\n                self.target_ptr = &*self.tree.outer_f;\n            } else {\n                self.target_range = outer_len..self.middle_range.start;\n                self.target_ptr = &*self.tree.inner_f;\n            }\n        } else if index >= self.middle_range.end {\n            let outer_start = self.middle_range.end + self.tree.inner_b.len();\n            if index < outer_start {\n                self.target_range = self.middle_range.end..outer_start;\n                self.target_ptr = &*self.tree.inner_b;\n            } else {\n                self.target_range = outer_start..self.tree.length;\n                self.target_ptr = &*self.tree.outer_b;\n            }\n        } else {\n            let tree_index = index - self.middle_range.start;\n            let (range, ptr) = self\n                .tree\n                .middle\n                .lookup_chunk(self.tree.middle_level, 0, tree_index);\n            self.target_range =\n                (range.start + self.middle_range.start)..(range.end + self.middle_range.start);\n            self.target_ptr = ptr;\n        }\n    }\n\n    #[allow(unsafe_code)]\n    fn get_focus(&self) -> &Chunk<A> {\n        unsafe { &*self.target_ptr }\n    }\n\n    pub fn get(&mut self, index: usize) -> Option<&A> {\n        if index >= self.len() {\n            return None;\n        }\n        let phys_index = self.physical_index(index);\n        if !contains(&self.target_range, &phys_index) {\n            self.set_focus(phys_index);\n        }\n        let target_phys_index = phys_index - self.target_range.start;\n        Some(&self.get_focus()[target_phys_index])\n    }\n\n    pub fn get_chunk(&mut self, index: usize) -> (Range<usize>, &[A]) {\n        let phys_index = self.physical_index(index);\n        if !contains(&self.target_range, &phys_index) {\n            self.set_focus(phys_index);\n        }\n        let mut slice: &[A] = self.get_focus();\n        let mut left = 0;\n        let mut right = 0;\n        if self.target_range.start < self.view.start {\n            left = self.view.start - self.target_range.start;\n        }\n        if self.target_range.end > self.view.end {\n            right = self.target_range.end - self.view.end;\n        }\n        slice = &slice[left..(slice.len() - right)];\n        let phys_range = (self.target_range.start + left)..(self.target_range.end - right);\n        (self.logical_range(&phys_range), slice)\n    }\n}\n\n/// A mutable version of [`Focus`][Focus].\n///\n/// See [`Focus`][Focus] for more details.\n///\n/// You can only build one `FocusMut` at a time for a vector, effectively\n/// keeping a lock on the vector until you're done with the focus, which relies\n/// on the structure of the vector not changing while it exists.\n///\n/// ```rust,compile_fail\n/// # #[macro_use] extern crate im;\n/// # use im::vector::Vector;\n/// # use std::iter::FromIterator;\n/// let mut vec = Vector::from_iter(0..1000);\n/// let focus1 = vec.focus_mut();\n/// // Fails here in 2015 edition because you're creating\n/// // two mutable references to the same thing.\n/// let focus2 = vec.focus_mut();\n/// // Fails here in 2018 edition because creating focus2\n/// // made focus1's lifetime go out of scope.\n/// assert_eq!(Some(&0), focus1.get(0));\n/// ```\n///\n/// On the other hand, you can split that one focus into multiple sub-focuses,\n/// which is safe because they can't overlap:\n///\n/// ```rust\n/// # #[macro_use] extern crate im;\n/// # use im::vector::Vector;\n/// # use std::iter::FromIterator;\n/// let mut vec = Vector::from_iter(0..1000);\n/// let focus = vec.focus_mut();\n/// let (mut left, mut right) = focus.split_at(500);\n/// assert_eq!(Some(&0), left.get(0));\n/// assert_eq!(Some(&500), right.get(0));\n/// ```\n///\n/// These sub-foci also work as a lock on the vector, even if the focus they\n/// were created from goes out of scope.\n///\n/// ```rust,compile_fail\n/// # #[macro_use] extern crate im;\n/// # use im::vector::Vector;\n/// # use std::iter::FromIterator;\n/// let mut vec = Vector::from_iter(0..1000);\n/// let (left, right) = {\n///     let focus = vec.focus_mut();\n///     focus.split_at(500)\n/// };\n/// // `left` and `right` are still in scope even if `focus` isn't, so we can't\n/// // create another focus:\n/// let focus2 = vec.focus_mut();\n/// assert_eq!(Some(&0), left.get(0));\n/// ```\n///\n/// [Focus]: enum.Focus.html\npub enum FocusMut<'a, A> {\n    #[doc(hidden)]\n    Single(RRBPool<A>, &'a mut [A]),\n    #[doc(hidden)]\n    Full(RRBPool<A>, TreeFocusMut<'a, A>),\n}\n\nimpl<'a, A> FocusMut<'a, A>\nwhere\n    A: Clone + 'a,\n{\n    /// Construct a `FocusMut` for a `Vector`.\n    pub fn new(vector: &'a mut Vector<A>) -> Self {\n        match &mut vector.vector {\n            Inline(pool, chunk) => FocusMut::Single(pool.clone(), chunk),\n            Single(pool, chunk) => FocusMut::Single(\n                pool.clone(),\n                PoolRef::make_mut(&pool.value_pool, chunk).as_mut_slice(),\n            ),\n            Full(pool, tree) => FocusMut::Full(pool.clone(), TreeFocusMut::new(tree)),\n        }\n    }\n\n    /// Get the length of the focused `Vector`.\n    pub fn len(&self) -> usize {\n        match self {\n            FocusMut::Single(_, chunk) => chunk.len(),\n            FocusMut::Full(_, tree) => tree.len(),\n        }\n    }\n\n    /// Test if the focused `Vector` is empty.\n    pub fn is_empty(&self) -> bool {\n        self.len() == 0\n    }\n\n    /// Get a reference to the value at a given index.\n    pub fn get(&mut self, index: usize) -> Option<&A> {\n        self.get_mut(index).map(|r| &*r)\n    }\n\n    /// Get a mutable reference to the value at a given index.\n    pub fn get_mut(&mut self, index: usize) -> Option<&mut A> {\n        match self {\n            FocusMut::Single(_, chunk) => chunk.get_mut(index),\n            FocusMut::Full(pool, tree) => tree.get(pool, index),\n        }\n    }\n\n    /// Get a reference to the value at a given index.\n    ///\n    /// Panics if the index is out of bounds.\n    pub fn index(&mut self, index: usize) -> &A {\n        &*self.index_mut(index)\n    }\n\n    /// Get a mutable reference to the value at a given index.\n    ///\n    /// Panics if the index is out of bounds.\n    #[allow(clippy::should_implement_trait)] // would if I could\n    pub fn index_mut(&mut self, index: usize) -> &mut A {\n        self.get_mut(index).expect(\"index out of bounds\")\n    }\n\n    /// Update the value at a given index.\n    ///\n    /// Returns `None` if the index is out of bounds, or the replaced value\n    /// otherwise.\n    pub fn set(&mut self, index: usize, value: A) -> Option<A> {\n        match self.get_mut(index) {\n            Some(ref mut pos) => Some(replace(pos, value)),\n            None => None,\n        }\n    }\n\n    /// Swap the values at two given indices.\n    ///\n    /// Panics if either index is out of bounds.\n    ///\n    /// If the indices are equal, this function returns without doing anything.\n    pub fn swap(&mut self, a: usize, b: usize) {\n        if a == b {\n            return;\n        }\n        self.pair(a, b, |left, right| swap(left, right));\n    }\n\n    /// Lookup two indices simultaneously and run a function over them.\n    ///\n    /// Useful because the borrow checker won't let you have more than one\n    /// mutable reference into the same data structure at any given time.\n    ///\n    /// Panics if either index is out of bounds, or if they are the same index.\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// # #[macro_use] extern crate im;\n    /// # use im::vector::Vector;\n    /// # use std::iter::FromIterator;\n    /// let mut vec = vector![1, 2, 3, 4, 5];\n    /// vec.focus_mut().pair(1, 3, |a, b| *a += *b);\n    /// assert_eq!(vector![1, 6, 3, 4, 5], vec);\n    /// ```\n    #[allow(unsafe_code)]\n    pub fn pair<F, B>(&mut self, a: usize, b: usize, mut f: F) -> B\n    where\n        F: FnMut(&mut A, &mut A) -> B,\n    {\n        if a == b {\n            panic!(\"vector::FocusMut::pair: indices cannot be equal!\");\n        }\n        let pa: *mut A = self.index_mut(a);\n        let pb: *mut A = self.index_mut(b);\n        unsafe { f(&mut *pa, &mut *pb) }\n    }\n\n    /// Lookup three indices simultaneously and run a function over them.\n    ///\n    /// Useful because the borrow checker won't let you have more than one\n    /// mutable reference into the same data structure at any given time.\n    ///\n    /// Panics if any index is out of bounds, or if any indices are equal.\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// # #[macro_use] extern crate im;\n    /// # use im::vector::Vector;\n    /// # use std::iter::FromIterator;\n    /// let mut vec = vector![1, 2, 3, 4, 5];\n    /// vec.focus_mut().triplet(0, 2, 4, |a, b, c| *a += *b + *c);\n    /// assert_eq!(vector![9, 2, 3, 4, 5], vec);\n    /// ```\n    #[allow(unsafe_code)]\n    pub fn triplet<F, B>(&mut self, a: usize, b: usize, c: usize, mut f: F) -> B\n    where\n        F: FnMut(&mut A, &mut A, &mut A) -> B,\n    {\n        if a == b || b == c || a == c {\n            panic!(\"vector::FocusMut::triplet: indices cannot be equal!\");\n        }\n        let pa: *mut A = self.index_mut(a);\n        let pb: *mut A = self.index_mut(b);\n        let pc: *mut A = self.index_mut(c);\n        unsafe { f(&mut *pa, &mut *pb, &mut *pc) }\n    }\n\n    /// Get the chunk for the given index.\n    ///\n    /// This gives you a reference to the leaf node that contains the index,\n    /// along with its start and end indices.\n    pub fn chunk_at(&mut self, index: usize) -> (Range<usize>, &mut [A]) {\n        let len = self.len();\n        if index >= len {\n            panic!(\"vector::FocusMut::chunk_at: index out of bounds\");\n        }\n        match self {\n            FocusMut::Single(_, chunk) => (0..len, chunk),\n            FocusMut::Full(pool, tree) => {\n                let (range, chunk) = tree.get_chunk(pool, index);\n                (range, chunk)\n            }\n        }\n    }\n\n    /// Narrow the focus onto a subslice of the vector.\n    ///\n    /// `FocusMut::narrow(range)` has the same effect as `&slice[range]`, without\n    /// actually modifying the underlying vector.\n    ///\n    /// Panics if the range isn't fully inside the current focus.\n    ///\n    /// ## Examples\n    ///\n    /// ```rust\n    /// # #[macro_use] extern crate im;\n    /// # use im::vector::Vector;\n    /// # use std::iter::FromIterator;\n    /// let mut vec = Vector::from_iter(0..1000);\n    /// let narrowed = vec.focus_mut().narrow(100..200);\n    /// let narrowed_vec = narrowed.unmut().into_iter().cloned().collect();\n    /// assert_eq!(Vector::from_iter(100..200), narrowed_vec);\n    /// ```\n    ///\n    /// [slice::split_at]: https://doc.rust-lang.org/std/primitive.slice.html#method.split_at\n    /// [Vector::split_at]: enum.Vector.html#method.split_at\n    pub fn narrow<R>(self, range: R) -> Self\n    where\n        R: RangeBounds<usize>,\n    {\n        let r = to_range(&range, self.len());\n        if r.start > r.end || r.start > self.len() {\n            panic!(\"vector::FocusMut::narrow: range out of bounds\");\n        }\n        match self {\n            FocusMut::Single(pool, chunk) => FocusMut::Single(pool, &mut chunk[r]),\n            FocusMut::Full(pool, tree) => FocusMut::Full(pool, tree.narrow(r)),\n        }\n    }\n\n    /// Split the focus into two.\n    ///\n    /// Given an index `index`, consume the focus and produce two new foci, the\n    /// left onto indices `0..index`, and the right onto indices `index..N`\n    /// where `N` is the length of the current focus.\n    ///\n    /// Panics if the index is out of bounds.\n    ///\n    /// This is the moral equivalent of [`slice::split_at`][slice::split_at], in\n    /// that it leaves the underlying data structure unchanged, unlike\n    /// [`Vector::split_at`][Vector::split_at].\n    ///\n    /// ## Examples\n    ///\n    /// ```rust\n    /// # #[macro_use] extern crate im;\n    /// # use im::vector::Vector;\n    /// # use std::iter::FromIterator;\n    /// let mut vec = Vector::from_iter(0..1000);\n    /// {\n    ///     let (left, right) = vec.focus_mut().split_at(500);\n    ///     for ptr in left {\n    ///         *ptr += 100;\n    ///     }\n    ///     for ptr in right {\n    ///         *ptr -= 100;\n    ///     }\n    /// }\n    /// let expected = Vector::from_iter(100..600)\n    ///              + Vector::from_iter(400..900);\n    /// assert_eq!(expected, vec);\n    /// ```\n    ///\n    /// [slice::split_at]: https://doc.rust-lang.org/std/primitive.slice.html#method.split_at\n    /// [Vector::split_at]: enum.Vector.html#method.split_at\n    #[allow(clippy::redundant_clone)]\n    pub fn split_at(self, index: usize) -> (Self, Self) {\n        if index > self.len() {\n            panic!(\"vector::FocusMut::split_at: index out of bounds\");\n        }\n        match self {\n            FocusMut::Single(pool, chunk) => {\n                let (left, right) = chunk.split_at_mut(index);\n                (\n                    FocusMut::Single(pool.clone(), left),\n                    FocusMut::Single(pool, right),\n                )\n            }\n            FocusMut::Full(pool, tree) => {\n                let (left, right) = tree.split_at(index);\n                (\n                    FocusMut::Full(pool.clone(), left),\n                    FocusMut::Full(pool, right),\n                )\n            }\n        }\n    }\n\n    /// Convert a `FocusMut` into a `Focus`.\n    pub fn unmut(self) -> Focus<'a, A> {\n        match self {\n            FocusMut::Single(_, chunk) => Focus::Single(chunk),\n            FocusMut::Full(_, mut tree) => Focus::Full(TreeFocus {\n                tree: {\n                    let t = tree.tree.lock().unwrap();\n                    (*t).clone()\n                },\n                view: tree.view.clone(),\n                middle_range: tree.middle_range.clone(),\n                target_range: 0..0,\n                target_ptr: null(),\n            }),\n        }\n    }\n}\n\nimpl<'a, A> IntoIterator for FocusMut<'a, A>\nwhere\n    A: Clone + 'a,\n{\n    type Item = &'a mut A;\n    type IntoIter = IterMut<'a, A>;\n\n    fn into_iter(self) -> Self::IntoIter {\n        IterMut::from_focus(self)\n    }\n}\n\nimpl<'a, A> Into<Focus<'a, A>> for FocusMut<'a, A>\nwhere\n    A: Clone + 'a,\n{\n    fn into(self) -> Focus<'a, A> {\n        self.unmut()\n    }\n}\n\npub struct TreeFocusMut<'a, A> {\n    tree: Lock<&'a mut RRB<A>>,\n    view: Range<usize>,\n    middle_range: Range<usize>,\n    target_range: Range<usize>,\n    target_ptr: AtomicPtr<Chunk<A>>,\n}\n\nimpl<'a, A> TreeFocusMut<'a, A>\nwhere\n    A: Clone + 'a,\n{\n    fn new(tree: &'a mut RRB<A>) -> Self {\n        let middle_start = tree.outer_f.len() + tree.inner_f.len();\n        let middle_end = middle_start + tree.middle.len();\n        TreeFocusMut {\n            view: 0..tree.length,\n            tree: Lock::new(tree),\n            middle_range: middle_start..middle_end,\n            target_range: 0..0,\n            target_ptr: AtomicPtr::default(),\n        }\n    }\n\n    fn len(&self) -> usize {\n        self.view.end - self.view.start\n    }\n\n    fn narrow(self, mut view: Range<usize>) -> Self {\n        view.start += self.view.start;\n        view.end += self.view.start;\n        TreeFocusMut {\n            view,\n            middle_range: self.middle_range.clone(),\n            target_range: 0..0,\n            target_ptr: AtomicPtr::default(),\n            tree: self.tree,\n        }\n    }\n\n    fn split_at(self, index: usize) -> (Self, Self) {\n        let len = self.len();\n        debug_assert!(index <= len);\n        #[allow(unsafe_code)]\n        let left = TreeFocusMut {\n            view: self.view.start..(self.view.start + index),\n            middle_range: self.middle_range.clone(),\n            target_range: 0..0,\n            target_ptr: AtomicPtr::default(),\n            tree: self.tree.clone(),\n        };\n        let right = TreeFocusMut {\n            view: (self.view.start + index)..(self.view.start + len),\n            middle_range: self.middle_range.clone(),\n            target_range: 0..0,\n            target_ptr: AtomicPtr::default(),\n            tree: self.tree,\n        };\n        (left, right)\n    }\n\n    fn physical_index(&self, index: usize) -> usize {\n        debug_assert!(index < self.view.end);\n        self.view.start + index\n    }\n\n    fn logical_range(&self, range: &Range<usize>) -> Range<usize> {\n        (range.start - self.view.start)..(range.end - self.view.start)\n    }\n\n    fn set_focus(&mut self, pool: &RRBPool<A>, index: usize) {\n        let mut tree = self\n            .tree\n            .lock()\n            .expect(\"im::vector::Focus::set_focus: unable to acquire exclusive lock on Vector\");\n        if index < self.middle_range.start {\n            let outer_len = tree.outer_f.len();\n            if index < outer_len {\n                self.target_range = 0..outer_len;\n                self.target_ptr.store(\n                    PoolRef::make_mut(&pool.value_pool, &mut tree.outer_f),\n                    Ordering::Relaxed,\n                );\n            } else {\n                self.target_range = outer_len..self.middle_range.start;\n                self.target_ptr.store(\n                    PoolRef::make_mut(&pool.value_pool, &mut tree.inner_f),\n                    Ordering::Relaxed,\n                );\n            }\n        } else if index >= self.middle_range.end {\n            let outer_start = self.middle_range.end + tree.inner_b.len();\n            if index < outer_start {\n                self.target_range = self.middle_range.end..outer_start;\n                self.target_ptr.store(\n                    PoolRef::make_mut(&pool.value_pool, &mut tree.inner_b),\n                    Ordering::Relaxed,\n                );\n            } else {\n                self.target_range = outer_start..tree.length;\n                self.target_ptr.store(\n                    PoolRef::make_mut(&pool.value_pool, &mut tree.outer_b),\n                    Ordering::Relaxed,\n                );\n            }\n        } else {\n            let tree_index = index - self.middle_range.start;\n            let level = tree.middle_level;\n            let middle = Ref::make_mut(&mut tree.middle);\n            let (range, ptr) = middle.lookup_chunk_mut(pool, level, 0, tree_index);\n            self.target_range =\n                (range.start + self.middle_range.start)..(range.end + self.middle_range.start);\n            self.target_ptr.store(ptr, Ordering::Relaxed);\n        }\n    }\n\n    #[allow(unsafe_code)]\n    fn get_focus(&mut self) -> &mut Chunk<A> {\n        unsafe { &mut *self.target_ptr.load(Ordering::Relaxed) }\n    }\n\n    pub fn get(&mut self, pool: &RRBPool<A>, index: usize) -> Option<&mut A> {\n        if index >= self.len() {\n            return None;\n        }\n        let phys_index = self.physical_index(index);\n        if !contains(&self.target_range, &phys_index) {\n            self.set_focus(pool, phys_index);\n        }\n        let target_phys_index = phys_index - self.target_range.start;\n        Some(&mut self.get_focus()[target_phys_index])\n    }\n\n    pub fn get_chunk(&mut self, pool: &RRBPool<A>, index: usize) -> (Range<usize>, &mut [A]) {\n        let phys_index = self.physical_index(index);\n        if !contains(&self.target_range, &phys_index) {\n            self.set_focus(pool, phys_index);\n        }\n        let mut left = 0;\n        let mut right = 0;\n        if self.target_range.start < self.view.start {\n            left = self.view.start - self.target_range.start;\n        }\n        if self.target_range.end > self.view.end {\n            right = self.target_range.end - self.view.end;\n        }\n        let phys_range = (self.target_range.start + left)..(self.target_range.end - right);\n        let log_range = self.logical_range(&phys_range);\n        let slice_len = self.get_focus().len();\n        let slice = &mut (self.get_focus().as_mut_slice())[left..(slice_len - right)];\n        (log_range, slice)\n    }\n}\n"
  },
  {
    "project": "tiny-http",
    "target": 1,
    "commit_id": "4770db9760c99775f23594bc21dd3420e0388ef0",
    "func": "use ascii::{AsciiStr, AsciiString, FromAsciiError};\nuse std::cmp::Ordering;\nuse std::fmt::{self, Display, Formatter};\nuse std::str::FromStr;\n\nuse chrono::*;\n\n/// Status code of a request or response.\n#[derive(Eq, PartialEq, Clone, Debug, Ord, PartialOrd)]\npub struct StatusCode(pub u16);\n\nimpl StatusCode {\n    /// Returns the default reason phrase for this status code.\n    /// For example the status code 404 corresponds to \"Not Found\".\n    pub fn default_reason_phrase(&self) -> &'static str {\n        match self.0 {\n            100 => \"Continue\",\n            101 => \"Switching Protocols\",\n            102 => \"Processing\",\n            103 => \"Early Hints\",\n\n            200 => \"OK\",\n            201 => \"Created\",\n            202 => \"Accepted\",\n            203 => \"Non-Authoritative Information\",\n            204 => \"No Content\",\n            205 => \"Reset Content\",\n            206 => \"Partial Content\",\n            207 => \"Multi-Status\",\n            208 => \"Already Reported\",\n            226 => \"IM Used\",\n\n            300 => \"Multiple Choices\",\n            301 => \"Moved Permanently\",\n            302 => \"Found\",\n            303 => \"See Other\",\n            304 => \"Not Modified\",\n            305 => \"Use Proxy\",\n            307 => \"Temporary Redirect\",\n            308 => \"Permanent Redirect\",\n\n            400 => \"Bad Request\",\n            401 => \"Unauthorized\",\n            402 => \"Payment Required\",\n            403 => \"Forbidden\",\n            404 => \"Not Found\",\n            405 => \"Method Not Allowed\",\n            406 => \"Not Acceptable\",\n            407 => \"Proxy Authentication Required\",\n            408 => \"Request Timeout\",\n            409 => \"Conflict\",\n            410 => \"Gone\",\n            411 => \"Length Required\",\n            412 => \"Precondition Failed\",\n            413 => \"Payload Too Large\",\n            414 => \"URI Too Long\",\n            415 => \"Unsupported Media Type\",\n            416 => \"Range Not Satisfiable\",\n            417 => \"Expectation Failed\",\n            421 => \"Misdirected Request\",\n            422 => \"Unprocessable Entity\",\n            423 => \"Locked\",\n            424 => \"Failed Dependency\",\n            426 => \"Upgrade Required\",\n            428 => \"Precondition Required\",\n            429 => \"Too Many Requests\",\n            431 => \"Request Header Fields Too Large\",\n            451 => \"Unavailable For Legal Reasons\",\n\n            500 => \"Internal Server Error\",\n            501 => \"Not Implemented\",\n            502 => \"Bad Gateway\",\n            503 => \"Service Unavailable\",\n            504 => \"Gateway Timeout\",\n            505 => \"HTTP Version Not Supported\",\n            506 => \"Variant Also Negotiates\",\n            507 => \"Insufficient Storage\",\n            508 => \"Loop Detected\",\n            510 => \"Not Extended\",\n            511 => \"Network Authentication Required\",\n            _ => \"Unknown\",\n        }\n    }\n}\n\nimpl From<i8> for StatusCode {\n    fn from(in_code: i8) -> StatusCode {\n        StatusCode(in_code as u16)\n    }\n}\n\nimpl From<u8> for StatusCode {\n    fn from(in_code: u8) -> StatusCode {\n        StatusCode(in_code as u16)\n    }\n}\n\nimpl From<i16> for StatusCode {\n    fn from(in_code: i16) -> StatusCode {\n        StatusCode(in_code as u16)\n    }\n}\n\nimpl From<u16> for StatusCode {\n    fn from(in_code: u16) -> StatusCode {\n        StatusCode(in_code)\n    }\n}\n\nimpl From<i32> for StatusCode {\n    fn from(in_code: i32) -> StatusCode {\n        StatusCode(in_code as u16)\n    }\n}\n\nimpl From<u32> for StatusCode {\n    fn from(in_code: u32) -> StatusCode {\n        StatusCode(in_code as u16)\n    }\n}\n\nimpl AsRef<u16> for StatusCode {\n    fn as_ref(&self) -> &u16 {\n        &self.0\n    }\n}\n\nimpl PartialEq<u16> for StatusCode {\n    fn eq(&self, other: &u16) -> bool {\n        &self.0 == other\n    }\n}\n\nimpl PartialEq<StatusCode> for u16 {\n    fn eq(&self, other: &StatusCode) -> bool {\n        self == &other.0\n    }\n}\n\nimpl PartialOrd<u16> for StatusCode {\n    fn partial_cmp(&self, other: &u16) -> Option<Ordering> {\n        self.0.partial_cmp(other)\n    }\n}\n\nimpl PartialOrd<StatusCode> for u16 {\n    fn partial_cmp(&self, other: &StatusCode) -> Option<Ordering> {\n        self.partial_cmp(&other.0)\n    }\n}\n\n/// Represents a HTTP header.\n#[derive(Debug, Clone)]\npub struct Header {\n    pub field: HeaderField,\n    pub value: AsciiString,\n}\n\nimpl Header {\n    /// Builds a `Header` from two `Vec<u8>`s or two `&[u8]`s.\n    ///\n    /// Example:\n    ///\n    /// ```\n    /// let header = tiny_http::Header::from_bytes(&b\"Content-Type\"[..], &b\"text/plain\"[..]).unwrap();\n    /// ```\n    pub fn from_bytes<B1, B2>(header: B1, value: B2) -> Result<Header, ()>\n    where\n        B1: Into<Vec<u8>> + AsRef<[u8]>,\n        B2: Into<Vec<u8>> + AsRef<[u8]>,\n    {\n        let header = HeaderField::from_bytes(header).or(Err(()))?;\n        let value = AsciiString::from_ascii(value).or(Err(()))?;\n\n        Ok(Header {\n            field: header,\n            value,\n        })\n    }\n}\n\nimpl FromStr for Header {\n    type Err = ();\n\n    fn from_str(input: &str) -> Result<Header, ()> {\n        let mut elems = input.splitn(2, ':');\n\n        let field = elems.next();\n        let value = elems.next();\n\n        let (field, value) = match (field, value) {\n            (Some(f), Some(v)) => (f, v),\n            _ => return Err(()),\n        };\n\n        let field = match FromStr::from_str(field) {\n            Ok(f) => f,\n            _ => return Err(()),\n        };\n\n        let value = AsciiString::from_ascii(value.trim()).map_err(|_| ())?;\n\n        Ok(Header { field, value })\n    }\n}\n\nimpl Display for Header {\n    fn fmt(&self, formatter: &mut Formatter) -> Result<(), fmt::Error> {\n        write!(formatter, \"{}: {}\", self.field, self.value.as_str())\n    }\n}\n\n/// Field of a header (eg. `Content-Type`, `Content-Length`, etc.)\n///\n/// Comparaison between two `HeaderField`s ignores case.\n#[derive(Debug, Clone)]\npub struct HeaderField(AsciiString);\n\nimpl HeaderField {\n    pub fn from_bytes<B>(bytes: B) -> Result<HeaderField, FromAsciiError<B>>\n    where\n        B: Into<Vec<u8>> + AsRef<[u8]>,\n    {\n        AsciiString::from_ascii(bytes).map(HeaderField)\n    }\n\n    pub fn as_str(&self) -> &AsciiStr {\n        match self {\n            HeaderField(ref s) => s,\n        }\n    }\n\n    pub fn equiv(&self, other: &'static str) -> bool {\n        other.eq_ignore_ascii_case(self.as_str().as_str())\n    }\n}\n\nimpl FromStr for HeaderField {\n    type Err = ();\n\n    fn from_str(s: &str) -> Result<HeaderField, ()> {\n        AsciiString::from_ascii(s.trim())\n            .map(HeaderField)\n            .map_err(|_| ())\n    }\n}\n\nimpl Display for HeaderField {\n    fn fmt(&self, formatter: &mut Formatter) -> Result<(), fmt::Error> {\n        let method = self.as_str();\n        write!(formatter, \"{}\", method.as_str())\n    }\n}\n\nimpl PartialEq for HeaderField {\n    fn eq(&self, other: &HeaderField) -> bool {\n        let self_str: &str = self.as_str().as_ref();\n        let other_str = other.as_str().as_ref();\n        self_str.eq_ignore_ascii_case(other_str)\n    }\n}\n\nimpl Eq for HeaderField {}\n\n/// HTTP request methods\n///\n/// As per [RFC 7231](https://tools.ietf.org/html/rfc7231#section-4.1) and\n/// [RFC 5789](https://tools.ietf.org/html/rfc5789)\n#[derive(Debug, Clone)]\npub enum Method {\n    /// `GET`\n    Get,\n\n    /// `HEAD`\n    Head,\n\n    /// `POST`\n    Post,\n\n    /// `PUT`\n    Put,\n\n    /// `DELETE`\n    Delete,\n\n    /// `CONNECT`\n    Connect,\n\n    /// `OPTIONS`\n    Options,\n\n    /// `TRACE`\n    Trace,\n\n    /// `PATCH`\n    Patch,\n\n    /// Request methods not standardized by the IETF\n    NonStandard(AsciiString),\n}\n\nimpl Method {\n    pub fn as_str(&self) -> &str {\n        match *self {\n            Method::Get => \"GET\",\n            Method::Head => \"HEAD\",\n            Method::Post => \"POST\",\n            Method::Put => \"PUT\",\n            Method::Delete => \"DELETE\",\n            Method::Connect => \"CONNECT\",\n            Method::Options => \"OPTIONS\",\n            Method::Trace => \"TRACE\",\n            Method::Patch => \"PATCH\",\n            Method::NonStandard(ref s) => s.as_str(),\n        }\n    }\n}\n\nimpl FromStr for Method {\n    type Err = ();\n\n    fn from_str(s: &str) -> Result<Method, ()> {\n        Ok(match s {\n            s if s.eq_ignore_ascii_case(\"GET\") => Method::Get,\n            s if s.eq_ignore_ascii_case(\"HEAD\") => Method::Head,\n            s if s.eq_ignore_ascii_case(\"POST\") => Method::Post,\n            s if s.eq_ignore_ascii_case(\"PUT\") => Method::Put,\n            s if s.eq_ignore_ascii_case(\"DELETE\") => Method::Delete,\n            s if s.eq_ignore_ascii_case(\"CONNECT\") => Method::Connect,\n            s if s.eq_ignore_ascii_case(\"OPTIONS\") => Method::Options,\n            s if s.eq_ignore_ascii_case(\"TRACE\") => Method::Trace,\n            s if s.eq_ignore_ascii_case(\"PATCH\") => Method::Patch,\n            s => {\n                let ascii_string = AsciiString::from_ascii(s).map_err(|_| ())?;\n                Method::NonStandard(ascii_string)\n            }\n        })\n    }\n}\n\nimpl Display for Method {\n    fn fmt(&self, formatter: &mut Formatter) -> Result<(), fmt::Error> {\n        write!(formatter, \"{}\", self.as_str())\n    }\n}\n\nimpl PartialEq for Method {\n    fn eq(&self, other: &Method) -> bool {\n        match (self, other) {\n            (&Method::NonStandard(ref s1), &Method::NonStandard(ref s2)) => {\n                s1.as_str().eq_ignore_ascii_case(s2.as_str())\n            }\n            (&Method::Get, &Method::Get) => true,\n            (&Method::Head, &Method::Head) => true,\n            (&Method::Post, &Method::Post) => true,\n            (&Method::Put, &Method::Put) => true,\n            (&Method::Delete, &Method::Delete) => true,\n            (&Method::Connect, &Method::Connect) => true,\n            (&Method::Options, &Method::Options) => true,\n            (&Method::Trace, &Method::Trace) => true,\n            (&Method::Patch, &Method::Patch) => true,\n            _ => false,\n        }\n    }\n}\n\nimpl Eq for Method {}\n\n/// HTTP version (usually 1.0 or 1.1).\n#[derive(Debug, Clone, PartialEq, Eq, Ord)]\npub struct HTTPVersion(pub u8, pub u8);\n\nimpl Display for HTTPVersion {\n    fn fmt(&self, formatter: &mut Formatter) -> Result<(), fmt::Error> {\n        let (major, minor) = match self {\n            HTTPVersion(m, n) => (m, n),\n        };\n        write!(formatter, \"{}.{}\", major, minor)\n    }\n}\n\nimpl PartialOrd for HTTPVersion {\n    fn partial_cmp(&self, other: &HTTPVersion) -> Option<Ordering> {\n        let HTTPVersion(my_major, my_minor) = *self;\n        let HTTPVersion(other_major, other_minor) = *other;\n\n        if my_major != other_major {\n            return my_major.partial_cmp(&other_major);\n        }\n\n        my_minor.partial_cmp(&other_minor)\n    }\n}\n\nimpl PartialEq<(u8, u8)> for HTTPVersion {\n    fn eq(&self, &(major, minor): &(u8, u8)) -> bool {\n        self.eq(&HTTPVersion(major, minor))\n    }\n}\n\nimpl PartialEq<HTTPVersion> for (u8, u8) {\n    fn eq(&self, other: &HTTPVersion) -> bool {\n        let &(major, minor) = self;\n        HTTPVersion(major, minor).eq(other)\n    }\n}\n\nimpl PartialOrd<(u8, u8)> for HTTPVersion {\n    fn partial_cmp(&self, &(major, minor): &(u8, u8)) -> Option<Ordering> {\n        self.partial_cmp(&HTTPVersion(major, minor))\n    }\n}\n\nimpl PartialOrd<HTTPVersion> for (u8, u8) {\n    fn partial_cmp(&self, other: &HTTPVersion) -> Option<Ordering> {\n        let &(major, minor) = self;\n        HTTPVersion(major, minor).partial_cmp(other)\n    }\n}\n\nimpl From<(u8, u8)> for HTTPVersion {\n    fn from((major, minor): (u8, u8)) -> HTTPVersion {\n        HTTPVersion(major, minor)\n    }\n}\n/// Represents the current date, expressed in RFC 1123 format, e.g. Sun, 06 Nov 1994 08:49:37 GMT\npub struct HTTPDate {\n    d: DateTime<Utc>,\n}\n\nimpl HTTPDate {\n    pub fn new() -> HTTPDate {\n        HTTPDate { d: Utc::now() }\n    }\n}\n\nimpl ToString for HTTPDate {\n    fn to_string(&self) -> String {\n        self.d.format(\"%a, %e %b %Y %H:%M:%S GMT\").to_string()\n    }\n}\n\n#[cfg(test)]\nmod test {\n    use super::Header;\n\n    #[test]\n    fn test_parse_header() {\n        let header: Header = \"Content-Type: text/html\".parse().unwrap();\n\n        assert!(header.field.equiv(&\"content-type\"));\n        assert!(header.value.as_str() == \"text/html\");\n\n        assert!(\"hello world\".parse::<Header>().is_err());\n    }\n\n    #[test]\n    fn test_parse_header_with_doublecolon() {\n        let header: Header = \"Time: 20: 34\".parse().unwrap();\n\n        assert!(header.field.equiv(&\"time\"));\n        assert!(header.value.as_str() == \"20: 34\");\n    }\n}\n"
  },
  {
    "project": "diesel",
    "target": 1,
    "commit_id": "8e9e639983b78fce456fd5cf5ea8aa1f0556ff66",
    "func": "use std::collections::HashMap;\nuse std::marker::PhantomData;\n\nuse super::stmt::StatementUse;\nuse deserialize::{FromSqlRow, Queryable, QueryableByName};\nuse result::Error::DeserializationError;\nuse result::QueryResult;\nuse sqlite::Sqlite;\n\npub struct StatementIterator<'a, ST, T> {\n    stmt: StatementUse<'a>,\n    _marker: PhantomData<(ST, T)>,\n}\n\nimpl<'a, ST, T> StatementIterator<'a, ST, T> {\n    pub fn new(stmt: StatementUse<'a>) -> Self {\n        StatementIterator {\n            stmt: stmt,\n            _marker: PhantomData,\n        }\n    }\n}\n\nimpl<'a, ST, T> Iterator for StatementIterator<'a, ST, T>\nwhere\n    T: Queryable<ST, Sqlite>,\n{\n    type Item = QueryResult<T>;\n\n    fn next(&mut self) -> Option<Self::Item> {\n        let row = match self.stmt.step() {\n            Ok(row) => row,\n            Err(e) => return Some(Err(e)),\n        };\n        row.map(|mut row| {\n            T::Row::build_from_row(&mut row)\n                .map(T::build)\n                .map_err(DeserializationError)\n        })\n    }\n}\n\npub struct NamedStatementIterator<'a, T> {\n    stmt: StatementUse<'a>,\n    column_indices: HashMap<&'a str, usize>,\n    _marker: PhantomData<T>,\n}\n\nimpl<'a, T> NamedStatementIterator<'a, T> {\n    #[allow(clippy::new_ret_no_self)]\n    pub fn new(stmt: StatementUse<'a>) -> QueryResult<Self> {\n        let column_indices = (0..stmt.num_fields())\n            .filter_map(|i| {\n                stmt.field_name(i).map(|column| {\n                    let column = column\n                        .to_str()\n                        .map_err(|e| DeserializationError(e.into()))?;\n                    Ok((column, i))\n                })\n            })\n            .collect::<QueryResult<_>>()?;\n        Ok(NamedStatementIterator {\n            stmt,\n            column_indices,\n            _marker: PhantomData,\n        })\n    }\n}\n\nimpl<'a, T> Iterator for NamedStatementIterator<'a, T>\nwhere\n    T: QueryableByName<Sqlite>,\n{\n    type Item = QueryResult<T>;\n\n    fn next(&mut self) -> Option<Self::Item> {\n        let row = match self.stmt.step() {\n            Ok(row) => row,\n            Err(e) => return Some(Err(e)),\n        };\n        row.map(|row| {\n            let row = row.into_named(&self.column_indices);\n            T::build(&row).map_err(DeserializationError)\n        })\n    }\n}\n"
  },
  {
    "project": "evm",
    "target": 1,
    "commit_id": "b632ef27f9415e7db1b818d39b10ca2228629111",
    "func": "use super::Control;\nuse crate::{ExitError, ExitFatal, ExitRevert, ExitSucceed, Machine};\nuse core::cmp::min;\nuse primitive_types::{H256, U256};\n\n#[inline]\npub fn codesize(state: &mut Machine) -> Control {\n\tlet size = U256::from(state.code.len());\n\tpush_u256!(state, size);\n\tControl::Continue(1)\n}\n\n#[inline]\npub fn codecopy(state: &mut Machine) -> Control {\n\tpop_u256!(state, memory_offset, code_offset, len);\n\n\ttry_or_fail!(state.memory.resize_offset(memory_offset, len));\n\tmatch state\n\t\t.memory\n\t\t.copy_large(memory_offset, code_offset, len, &state.code)\n\t{\n\t\tOk(()) => Control::Continue(1),\n\t\tErr(e) => Control::Exit(e.into()),\n\t}\n}\n\n#[inline]\npub fn calldataload(state: &mut Machine) -> Control {\n\tpop_u256!(state, index);\n\n\tlet mut load = [0u8; 32];\n\t#[allow(clippy::needless_range_loop)]\n\tfor i in 0..32 {\n\t\tif let Some(p) = index.checked_add(U256::from(i)) {\n\t\t\tif p <= U256::from(usize::MAX) {\n\t\t\t\tlet p = p.as_usize();\n\t\t\t\tif p < state.data.len() {\n\t\t\t\t\tload[i] = state.data[p];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tpush!(state, H256::from(load));\n\tControl::Continue(1)\n}\n\n#[inline]\npub fn calldatasize(state: &mut Machine) -> Control {\n\tlet len = U256::from(state.data.len());\n\tpush_u256!(state, len);\n\tControl::Continue(1)\n}\n\n#[inline]\npub fn calldatacopy(state: &mut Machine) -> Control {\n\tpop_u256!(state, memory_offset, data_offset, len);\n\n\ttry_or_fail!(state.memory.resize_offset(memory_offset, len));\n\tif len == U256::zero() {\n\t\treturn Control::Continue(1);\n\t}\n\n\tmatch state\n\t\t.memory\n\t\t.copy_large(memory_offset, data_offset, len, &state.data)\n\t{\n\t\tOk(()) => Control::Continue(1),\n\t\tErr(e) => Control::Exit(e.into()),\n\t}\n}\n\n#[inline]\npub fn pop(state: &mut Machine) -> Control {\n\tpop!(state, _val);\n\tControl::Continue(1)\n}\n\n#[inline]\npub fn mload(state: &mut Machine) -> Control {\n\tpop_u256!(state, index);\n\ttry_or_fail!(state.memory.resize_offset(index, U256::from(32)));\n\tlet index = as_usize_or_fail!(index);\n\tlet value = H256::from_slice(&state.memory.get(index, 32)[..]);\n\tpush!(state, value);\n\tControl::Continue(1)\n}\n\n#[inline]\npub fn mstore(state: &mut Machine) -> Control {\n\tpop_u256!(state, index);\n\tpop!(state, value);\n\ttry_or_fail!(state.memory.resize_offset(index, U256::from(32)));\n\tlet index = as_usize_or_fail!(index);\n\tmatch state.memory.set(index, &value[..], Some(32)) {\n\t\tOk(()) => Control::Continue(1),\n\t\tErr(e) => Control::Exit(e.into()),\n\t}\n}\n\n#[inline]\npub fn mstore8(state: &mut Machine) -> Control {\n\tpop_u256!(state, index, value);\n\ttry_or_fail!(state.memory.resize_offset(index, U256::one()));\n\tlet index = as_usize_or_fail!(index);\n\tlet value = (value.low_u32() & 0xff) as u8;\n\tmatch state.memory.set(index, &[value], Some(1)) {\n\t\tOk(()) => Control::Continue(1),\n\t\tErr(e) => Control::Exit(e.into()),\n\t}\n}\n\n#[inline]\npub fn jump(state: &mut Machine) -> Control {\n\tpop_u256!(state, dest);\n\tlet dest = as_usize_or_fail!(dest, ExitError::InvalidJump);\n\n\tif state.valids.is_valid(dest) {\n\t\tControl::Jump(dest)\n\t} else {\n\t\tControl::Exit(ExitError::InvalidJump.into())\n\t}\n}\n\n#[inline]\npub fn jumpi(state: &mut Machine) -> Control {\n\tpop_u256!(state, dest);\n\tpop!(state, value);\n\tlet dest = as_usize_or_fail!(dest, ExitError::InvalidJump);\n\n\tif value != H256::zero() {\n\t\tif state.valids.is_valid(dest) {\n\t\t\tControl::Jump(dest)\n\t\t} else {\n\t\t\tControl::Exit(ExitError::InvalidJump.into())\n\t\t}\n\t} else {\n\t\tControl::Continue(1)\n\t}\n}\n\n#[inline]\npub fn pc(state: &mut Machine, position: usize) -> Control {\n\tpush_u256!(state, U256::from(position));\n\tControl::Continue(1)\n}\n\n#[inline]\npub fn msize(state: &mut Machine) -> Control {\n\tpush_u256!(state, state.memory.effective_len());\n\tControl::Continue(1)\n}\n\n#[inline]\npub fn push(state: &mut Machine, n: usize, position: usize) -> Control {\n\tlet end = min(position + 1 + n, state.code.len());\n\tlet slice = &state.code[(position + 1)..end];\n\tlet mut val = [0u8; 32];\n\tval[(32 - slice.len())..32].copy_from_slice(slice);\n\n\tpush!(state, H256(val));\n\tControl::Continue(1 + n)\n}\n\n#[inline]\npub fn dup(state: &mut Machine, n: usize) -> Control {\n\tlet value = match state.stack.peek(n - 1) {\n\t\tOk(value) => value,\n\t\tErr(e) => return Control::Exit(e.into()),\n\t};\n\tpush!(state, value);\n\tControl::Continue(1)\n}\n\n#[inline]\npub fn swap(state: &mut Machine, n: usize) -> Control {\n\tlet val1 = match state.stack.peek(0) {\n\t\tOk(value) => value,\n\t\tErr(e) => return Control::Exit(e.into()),\n\t};\n\tlet val2 = match state.stack.peek(n) {\n\t\tOk(value) => value,\n\t\tErr(e) => return Control::Exit(e.into()),\n\t};\n\tmatch state.stack.set(0, val2) {\n\t\tOk(()) => (),\n\t\tErr(e) => return Control::Exit(e.into()),\n\t}\n\tmatch state.stack.set(n, val1) {\n\t\tOk(()) => (),\n\t\tErr(e) => return Control::Exit(e.into()),\n\t}\n\tControl::Continue(1)\n}\n\n#[inline]\npub fn ret(state: &mut Machine) -> Control {\n\tpop_u256!(state, start, len);\n\ttry_or_fail!(state.memory.resize_offset(start, len));\n\tstate.return_range = start..(start + len);\n\tControl::Exit(ExitSucceed::Returned.into())\n}\n\n#[inline]\npub fn revert(state: &mut Machine) -> Control {\n\tpop_u256!(state, start, len);\n\ttry_or_fail!(state.memory.resize_offset(start, len));\n\tstate.return_range = start..(start + len);\n\tControl::Exit(ExitRevert::Reverted.into())\n}\n"
  },
  {
    "project": "coreos-installer",
    "target": 1,
    "commit_id": "99c67ffdf9111e5d3b0de9f4be2447c4b4ca84ff",
    "func": "// Copyright 2019 CoreOS, Inc.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\nuse anyhow::{Context, Result};\nuse flate2::bufread::GzDecoder;\nuse std::io::{self, BufRead, Read};\nuse xz2::bufread::XzDecoder;\n\nenum CompressDecoder<R: BufRead> {\n    Uncompressed(R),\n    Gzip(GzDecoder<R>),\n    Xz(XzDecoder<R>),\n}\n\npub struct DecompressReader<R: BufRead> {\n    decoder: CompressDecoder<R>,\n}\n\n/// Format-sniffing decompressor\nimpl<R: BufRead> DecompressReader<R> {\n    pub fn new(mut source: R) -> Result<Self> {\n        use CompressDecoder::*;\n        let sniff = source.fill_buf().context(\"sniffing input\")?;\n        let decoder = if sniff.len() > 2 && &sniff[0..2] == b\"\\x1f\\x8b\" {\n            Gzip(GzDecoder::new(source))\n        } else if sniff.len() > 6 && &sniff[0..6] == b\"\\xfd7zXZ\\x00\" {\n            Xz(XzDecoder::new(source))\n        } else {\n            Uncompressed(source)\n        };\n        Ok(Self { decoder })\n    }\n}\n\nimpl<R: BufRead> Read for DecompressReader<R> {\n    fn read(&mut self, buf: &mut [u8]) -> io::Result<usize> {\n        use CompressDecoder::*;\n        match &mut self.decoder {\n            Uncompressed(d) => d.read(buf),\n            Gzip(d) => d.read(buf),\n            Xz(d) => d.read(buf),\n        }\n    }\n}\n"
  },
  {
    "project": "rcu_cell",
    "target": 1,
    "commit_id": "0e4dc8cd07002a583462994ab4bcfecdf3338fae",
    "func": "use std::cmp;\nuse std::fmt;\nuse std::marker::PhantomData;\nuse std::ops::Deref;\nuse std::ptr::NonNull;\nuse std::sync::atomic::{self, AtomicUsize, Ordering};\n\n//---------------------------------------------------------------------------------------\n// RcuInner\n//---------------------------------------------------------------------------------------\n#[derive(Debug)]\nstruct RcuInner<T> {\n    refs: AtomicUsize,\n    data: T,\n}\n\nimpl<T> RcuInner<T> {\n    #[inline]\n    fn new(data: T) -> Self {\n        RcuInner {\n            refs: AtomicUsize::new(1),\n            data,\n        }\n    }\n\n    #[inline]\n    fn inc_ref(&self) -> usize {\n        self.refs.fetch_add(1, Ordering::Release)\n    }\n\n    #[inline]\n    fn dec_ref(&self) -> usize {\n        self.refs.fetch_sub(1, Ordering::Release) - 1\n    }\n}\n\n//---------------------------------------------------------------------------------------\n// LinkWrapper\n//---------------------------------------------------------------------------------------\n\nstruct Link<T> {\n    ptr: AtomicUsize,\n    phantom: PhantomData<*mut T>,\n}\n\nstruct LinkWrapper<T>(Link<RcuInner<T>>);\n\nimpl<T> LinkWrapper<T> {\n    // convert from usize to ref\n    #[inline]\n    fn _conv(&self, ptr: usize) -> Option<&RcuInner<T>> {\n        // ignore the reserve bit and read bit\n        let ptr = ptr & !3;\n        if ptr == 0 {\n            return None;\n        }\n        Some(unsafe { &*(ptr as *const RcuInner<T>) })\n    }\n\n    #[inline]\n    fn is_none(&self) -> bool {\n        let ptr = self.0.ptr.load(Ordering::Acquire);\n        let ptr = ptr & !3;\n        if ptr == 0 {\n            return true;\n        }\n        false\n    }\n\n    #[inline]\n    fn is_locked(&self) -> bool {\n        let ptr = self.0.ptr.load(Ordering::Acquire);\n        ptr & 1 == 1\n    }\n\n    #[inline]\n    fn get(&self) -> Option<RcuReader<T>> {\n        let ptr = self.read_lock();\n\n        let ret = self._conv(ptr).map(|p| {\n            // we are sure that the data is still in memroy with the read lock\n            p.inc_ref();\n            RcuReader {\n                inner: NonNull::new(p as *const _ as *mut _).expect(\"null shared\"),\n            }\n        });\n\n        self.read_unlock();\n        ret\n    }\n\n    #[inline]\n    fn swap(&self, data: Option<T>) -> Option<&RcuInner<T>> {\n        // we can sure that the update is\n        // only possible after get the guard\n        // in which case the reserve bit must be set\n        let new = match data {\n            Some(v) => {\n                let data = Box::new(RcuInner::new(v));\n                Box::into_raw(data) as usize | 1\n            }\n            None => 1,\n        };\n\n        // should wait until there is no read for the ptr\n        let mut old = self.0.ptr.load(Ordering::Acquire) & !2;\n\n        loop {\n            match self\n                .0\n                .ptr\n                .compare_exchange(old, new, Ordering::AcqRel, Ordering::Acquire)\n            {\n                Ok(_) => break,\n                Err(x) => {\n                    old = x & !2;\n                    atomic::spin_loop_hint()\n                }\n            }\n        }\n\n        self._conv(old)\n    }\n\n    // only one thread can acquire the link successfully\n    fn acquire(&self) -> bool {\n        let mut old = self.0.ptr.load(Ordering::Acquire);\n        if old & 1 != 0 {\n            return false;\n        }\n\n        loop {\n            let new = old | 1;\n            match self\n                .0\n                .ptr\n                .compare_exchange_weak(old, new, Ordering::AcqRel, Ordering::Acquire)\n            {\n                // successfully reserved\n                Ok(_) => return true,\n                // only try again if old value is still false\n                Err(x) if x & 1 == 0 => old = x,\n                // otherwise return false, which means the link is reserved by others\n                _ => return false,\n            }\n        }\n    }\n\n    // release only happened after acquire\n    fn release(&self) {\n        self.0.ptr.fetch_and(!1, Ordering::Release);\n    }\n\n    // only one thread can access the ptr when read/write\n    // return the current value after read lock\n    fn read_lock(&self) -> usize {\n        let mut old = self.0.ptr.load(Ordering::Acquire) & !2;\n\n        loop {\n            let new = old | 2;\n            match self\n                .0\n                .ptr\n                .compare_exchange_weak(old, new, Ordering::AcqRel, Ordering::Acquire)\n            {\n                // successfully reserved\n                Ok(_) => return new,\n                // otherwise the link is reserved by others, just spin wait\n                Err(x) => {\n                    old = x & !2;\n                    atomic::spin_loop_hint();\n                }\n            }\n        }\n    }\n\n    fn read_unlock(&self) {\n        self.0.ptr.fetch_and(!2, Ordering::Release);\n    }\n}\n\nimpl<T> Drop for LinkWrapper<T> {\n    fn drop(&mut self) {\n        if let Some(d) = self.get() {\n            d.unlink();\n        }\n    }\n}\n\nimpl<T: fmt::Debug> fmt::Debug for LinkWrapper<T> {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        let ptr = self.0.ptr.load(Ordering::Acquire);\n        let inner = self._conv(ptr);\n        f.debug_struct(\"Link\").field(\"inner\", &inner).finish()\n    }\n}\n\n//---------------------------------------------------------------------------------------\n// RcuReader\n//---------------------------------------------------------------------------------------\npub struct RcuReader<T> {\n    inner: NonNull<RcuInner<T>>,\n}\n\nunsafe impl<T: Send> Send for RcuReader<T> {}\nunsafe impl<T: Sync> Sync for RcuReader<T> {}\n\nimpl<T> Drop for RcuReader<T> {\n    #[inline]\n    fn drop(&mut self) {\n        unsafe {\n            if self.inner.as_ref().dec_ref() == 0 {\n                atomic::fence(Ordering::Acquire);\n                // drop the inner box\n                let _: Box<RcuInner<T>> = Box::from_raw(self.inner.as_ptr());\n            }\n        }\n    }\n}\n\nimpl<T> Deref for RcuReader<T> {\n    type Target = T;\n\n    #[inline]\n    fn deref(&self) -> &T {\n        unsafe { &self.inner.as_ref().data }\n    }\n}\n\nimpl<T> AsRef<T> for RcuReader<T> {\n    fn as_ref(&self) -> &T {\n        &**self\n    }\n}\n\nimpl<T> Clone for RcuReader<T> {\n    fn clone(&self) -> Self {\n        unsafe {\n            let cnt = self.inner.as_ref().inc_ref();\n            assert!(cnt > 0);\n        }\n        RcuReader { inner: self.inner }\n    }\n}\n\nimpl<T: PartialEq> PartialEq for RcuReader<T> {\n    fn eq(&self, other: &RcuReader<T>) -> bool {\n        *(*self) == *(*other)\n    }\n}\n\nimpl<T: PartialOrd> PartialOrd for RcuReader<T> {\n    fn partial_cmp(&self, other: &RcuReader<T>) -> Option<cmp::Ordering> {\n        (**self).partial_cmp(&**other)\n    }\n\n    fn lt(&self, other: &RcuReader<T>) -> bool {\n        *(*self) < *(*other)\n    }\n\n    fn le(&self, other: &RcuReader<T>) -> bool {\n        *(*self) <= *(*other)\n    }\n\n    fn gt(&self, other: &RcuReader<T>) -> bool {\n        *(*self) > *(*other)\n    }\n\n    fn ge(&self, other: &RcuReader<T>) -> bool {\n        *(*self) >= *(*other)\n    }\n}\n\nimpl<T: Ord> Ord for RcuReader<T> {\n    fn cmp(&self, other: &RcuReader<T>) -> cmp::Ordering {\n        (**self).cmp(&**other)\n    }\n}\n\nimpl<T: Eq> Eq for RcuReader<T> {}\n\nimpl<T: fmt::Debug> fmt::Debug for RcuReader<T> {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        fmt::Debug::fmt(&**self, f)\n    }\n}\n\nimpl<T> fmt::Pointer for RcuReader<T> {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        fmt::Pointer::fmt(&(&**self as *const T), f)\n    }\n}\n\nimpl<T> RcuReader<T> {\n    #[inline]\n    fn unlink(&self) {\n        unsafe {\n            self.inner.as_ref().dec_ref();\n        }\n    }\n}\n\n//---------------------------------------------------------------------------------------\n// RcuGuard\n//---------------------------------------------------------------------------------------\npub struct RcuGuard<'a, T: 'a> {\n    link: &'a LinkWrapper<T>,\n}\n\n// unsafe impl<'a, T> !Send for RcuGuard<'a, T> {}\nunsafe impl<'a, T: Sync> Sync for RcuGuard<'a, T> {}\n\nimpl<'a, T> RcuGuard<'a, T> {\n    // update the RcuCell with a new value\n    // this would not change the value that hold by readers\n    pub fn update(&mut self, data: Option<T>) {\n        // the RcuCell is acquired now\n        let old_link = self.link.swap(data);\n        if let Some(old) = old_link {\n            let cnt = old.inc_ref();\n            assert!(cnt > 0);\n            let ptr = NonNull::new(old as *const _ as *mut _).expect(\"null Shared\");\n            let d = RcuReader::<T> { inner: ptr };\n            d.unlink();\n        }\n    }\n\n    // get the mut ref of the underlying data\n    // this would change the value that hold by readers so it's not safe\n    // we can't safely update the data when still hold readers\n    // the reader garantee that the data would not change you can read from them\n    // pub unsafe fn as_mut(&mut self) -> Option<&mut T> {\n    //     // since it's locked and it's safe to update the data\n    //     // ignore the reserve bit\n    //     let ptr = self.link.ptr.load(Ordering::Acquire) & !1;\n    //     if ptr == 0 {\n    //         return None;\n    //     }\n    //     let inner = { &mut *(ptr as *mut RcuInner<T>) };\n    //     Some(&mut inner.data)\n    // }\n\n    pub fn as_ref(&self) -> Option<&T> {\n        // it's safe the get the ref since locked\n        // ignore the reserve bit\n        let ptr = self.link.0.ptr.load(Ordering::Acquire) & !3;\n        if ptr == 0 {\n            return None;\n        }\n        let inner = unsafe { &*(ptr as *const RcuInner<T>) };\n        Some(&inner.data)\n    }\n}\n\nimpl<'a, T> Drop for RcuGuard<'a, T> {\n    fn drop(&mut self) {\n        self.link.release();\n    }\n}\n\nimpl<'a, T: fmt::Debug> fmt::Debug for RcuGuard<'a, T> {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        fmt::Debug::fmt(&self.as_ref(), f)\n    }\n}\n\n//---------------------------------------------------------------------------------------\n// RcuCell\n//---------------------------------------------------------------------------------------\n#[derive(Debug)]\npub struct RcuCell<T> {\n    link: LinkWrapper<T>,\n}\n\nunsafe impl<T> Send for RcuCell<T> {}\nunsafe impl<T> Sync for RcuCell<T> {}\n\nimpl<T> Default for RcuCell<T> {\n    fn default() -> Self {\n        RcuCell::new(None)\n    }\n}\n\nimpl<T> RcuCell<T> {\n    pub fn new(data: Option<T>) -> Self {\n        let ptr = match data {\n            Some(data) => {\n                let data = Box::new(RcuInner::new(data));\n                Box::into_raw(data) as usize\n            }\n            None => 0,\n        };\n\n        RcuCell {\n            link: LinkWrapper(Link {\n                ptr: AtomicUsize::new(ptr),\n                phantom: PhantomData,\n            }),\n        }\n    }\n\n    #[inline]\n    pub fn is_none(&self) -> bool {\n        self.link.is_none()\n    }\n\n    #[inline]\n    pub fn is_locked(&self) -> bool {\n        self.link.is_locked()\n    }\n\n    pub fn read(&self) -> Option<RcuReader<T>> {\n        self.link.get()\n    }\n\n    pub fn try_lock(&self) -> Option<RcuGuard<T>> {\n        if self.link.acquire() {\n            return Some(RcuGuard { link: &self.link });\n        }\n        None\n    }\n}\n\n#[cfg(test)]\nmod test {\n    use super::*;\n    use std::sync::Arc;\n\n    #[test]\n    fn test_default() {\n        let x = RcuCell::<u32>::default();\n        assert_eq!(x.read().is_none(), true);\n    }\n\n    #[test]\n    fn simple_drop() {\n        let _ = RcuCell::new(Some(10));\n    }\n\n    #[test]\n    fn single_thread() {\n        let t = RcuCell::new(Some(10));\n        let x = t.read();\n        let y = t.read();\n        t.try_lock().unwrap().update(None);\n        let z = t.read();\n        let a = z.clone();\n        drop(t); // t can be dropped before reader\n        assert_eq!(x.map(|v| *v), Some(10));\n        assert_eq!(y.map(|v| *v), Some(10));\n        assert_eq!(z.map(|v| *v), None);\n        assert_eq!(a.map(|v| *v), None);\n    }\n\n    #[test]\n    fn single_thread_clone() {\n        let t = Arc::new(RcuCell::new(Some(10)));\n        let t1 = t.clone();\n        assert!(t1.read().map(|v| *v) == Some(10));\n        t1.try_lock().unwrap().update(Some(5));\n        assert!(t.read().map(|v| *v) == Some(5));\n    }\n\n    #[test]\n    fn test_rcu_guard() {\n        let t = RcuCell::new(Some(10));\n        let x = t.read().map(|v| *v);\n        let mut g = t.try_lock().unwrap();\n        let y = x.map(|v| v + 1);\n        g.update(y);\n        assert_eq!(t.try_lock().is_none(), true);\n        drop(g);\n        assert_eq!(t.read().map(|v| *v), Some(11));\n    }\n\n    #[test]\n    fn test_is_none() {\n        let t = RcuCell::new(Some(10));\n        assert_eq!(t.is_none(), false);\n        t.try_lock().unwrap().update(None);\n        assert_eq!(t.is_none(), true);\n    }\n\n    #[test]\n    fn test_is_locked() {\n        let t = RcuCell::new(Some(10));\n        assert_eq!(t.is_locked(), false);\n        let mut g = t.try_lock().unwrap();\n        g.update(None);\n        assert_eq!(t.is_locked(), true);\n        drop(g);\n        assert_eq!(t.is_locked(), false);\n    }\n\n    // #[test]\n    // fn test_as_mut() {\n    //     let t = RcuCell::new(Some(10));\n    //     let mut g = t.try_lock().unwrap();\n    //     assert_eq!(g.as_ref(), Some(&10));\n    //     // change the internal data with lock\n    //     g.as_mut().map(|d| *d = 20);\n    //     drop(g);\n    //     let x = t.read().unwrap();\n    //     assert_eq!(*x, 20);\n    // }\n\n    #[test]\n    fn test_clone_rcu_cell() {\n        let t = Arc::new(RcuCell::new(Some(10)));\n        let t1 = t.clone();\n        let t2 = t.clone();\n        let t3 = t.clone();\n        t1.try_lock().unwrap().update(Some(11));\n        drop(t1);\n        assert_eq!(t.read().map(|v| *v), Some(11));\n        t2.try_lock().unwrap().update(Some(12));\n        drop(t2);\n        assert_eq!(t.read().map(|v| *v), Some(12));\n        t3.try_lock().unwrap().update(Some(13));\n        drop(t3);\n        assert_eq!(t.read().map(|v| *v), Some(13));\n    }\n\n    #[test]\n    fn test_rcu_reader() {\n        let t = Arc::new(RcuCell::new(Some(10)));\n        let t1 = t.clone();\n        let t2 = t.clone();\n        let t3 = t.clone();\n        let d1 = t1.read().unwrap();\n        let d3 = t3.read().unwrap();\n        let mut g = t1.try_lock().unwrap();\n        g.update(Some(11));\n        drop(g);\n        let d2 = t2.read().unwrap();\n        assert_ne!(d1, d2);\n        assert_eq!(d1, d3);\n        assert_ne!(d2, d3);\n    }\n}\n"
  },
  {
    "project": "rbpf",
    "target": 1,
    "commit_id": "6a974772f1cbd1220bfc288786fdea51cadd4860",
    "func": "#![allow(clippy::integer_arithmetic)]\n//! This module relocates a BPF ELF\n\n// Note: Typically ELF shared objects are loaded using the program headers and\n// not the section headers.  Since we are leveraging the elfkit crate its much\n// easier to use the section headers.  There are cases (reduced size, obfuscation)\n// where the section headers may be removed from the ELF.  If that happens then\n// this loader will need to be re-written to use the program headers instead.\n\nextern crate goblin;\nextern crate scroll;\n\nuse crate::{\n    aligned_memory::AlignedMemory,\n    ebpf,\n    error::{EbpfError, UserDefinedError},\n    jit::JitProgram,\n    vm::{Config, InstructionMeter, SyscallRegistry},\n};\nuse byteorder::{ByteOrder, LittleEndian};\nuse goblin::{\n    elf::{header::*, reloc::*, section_header::*, Elf},\n    error::Error as GoblinError,\n};\nuse std::{collections::BTreeMap, fmt::Debug, mem, ops::Range, str};\n\n/// Error definitions\n#[derive(Debug, thiserror::Error, PartialEq, Eq)]\npub enum ElfError {\n    /// Failed to parse ELF file\n    #[error(\"Failed to parse ELF file: {0}\")]\n    FailedToParse(String),\n    /// Entrypoint out of bounds\n    #[error(\"Entrypoint out of bounds\")]\n    EntrypointOutOfBounds,\n    /// Invaid entrypoint\n    #[error(\"Invaid entrypoint\")]\n    InvalidEntrypoint,\n    /// Failed to get section\n    #[error(\"Failed to get section {0}\")]\n    FailedToGetSection(String),\n    /// Unresolved symbol\n    #[error(\"Unresolved symbol ({0}) at instruction #{1:?} (ELF file offset {2:#x})\")]\n    UnresolvedSymbol(String, usize, usize),\n    /// Section no found\n    #[error(\"Section not found: {0}\")]\n    SectionNotFound(String),\n    /// Relative jump out of bounds\n    #[error(\"Relative jump out of bounds at instruction #{0}\")]\n    RelativeJumpOutOfBounds(usize),\n    /// Symbol hash collision\n    #[error(\"Symbol hash collision {0:#x}\")]\n    SymbolHashCollision(u32),\n    /// Incompatible ELF: wrong endianess\n    #[error(\"Incompatible ELF: wrong endianess\")]\n    WrongEndianess,\n    /// Incompatible ELF: wrong ABI\n    #[error(\"Incompatible ELF: wrong ABI\")]\n    WrongAbi,\n    /// Incompatible ELF: wrong mchine\n    #[error(\"Incompatible ELF: wrong machine\")]\n    WrongMachine,\n    /// Incompatible ELF: wrong class\n    #[error(\"Incompatible ELF: wrong class\")]\n    WrongClass,\n    /// Not one text section\n    #[error(\"Multiple or no text sections, consider removing llc option: -function-sections\")]\n    NotOneTextSection,\n    /// Read-write data not supported\n    #[error(\"Found .bss section in ELF, read-write data not supported\")]\n    BssNotSupported,\n    /// Relocation failed, no loadable section contains virtual address\n    #[error(\"Relocation failed, no loadable section contains virtual address {0:#x}\")]\n    AddressOutsideLoadableSection(u64),\n    /// Relocation failed, invalid referenced virtual address\n    #[error(\"Relocation failed, invalid referenced virtual address {0:#x}\")]\n    InvalidVirtualAddress(u64),\n    /// Relocation failed, unknown type\n    #[error(\"Relocation failed, unknown type {0:?}\")]\n    UnknownRelocation(u32),\n    /// Failed to read relocation info\n    #[error(\"Failed to read relocation info\")]\n    FailedToReadRelocationInfo,\n    /// Incompatible ELF: wrong type\n    #[error(\"Incompatible ELF: wrong type\")]\n    WrongType,\n    /// Unknown symbol\n    #[error(\"Unknown symbol with index {0}\")]\n    UnknownSymbol(usize),\n    /// Offset or value is out of bounds\n    #[error(\"Offset or value is out of bounds\")]\n    ValueOutOfBounds,\n}\nimpl From<GoblinError> for ElfError {\n    fn from(error: GoblinError) -> Self {\n        match error {\n            GoblinError::Malformed(string) => Self::FailedToParse(format!(\"malformed: {}\", string)),\n            GoblinError::BadMagic(magic) => Self::FailedToParse(format!(\"bad magic: {:#x}\", magic)),\n            GoblinError::Scroll(error) => Self::FailedToParse(format!(\"read-write: {}\", error)),\n            GoblinError::IO(error) => Self::FailedToParse(format!(\"io: {}\", error)),\n        }\n    }\n}\nimpl<E: UserDefinedError> From<GoblinError> for EbpfError<E> {\n    fn from(error: GoblinError) -> Self {\n        ElfError::from(error).into()\n    }\n}\n\n/// Generates the hash by which a symbol can be called\npub fn hash_bpf_function(pc: usize, name: &str) -> u32 {\n    if name == \"entrypoint\" {\n        ebpf::hash_symbol_name(b\"entrypoint\")\n    } else {\n        let mut key = [0u8; mem::size_of::<u64>()];\n        LittleEndian::write_u64(&mut key, pc as u64);\n        ebpf::hash_symbol_name(&key)\n    }\n}\n\n/// Register a symbol or throw ElfError::SymbolHashCollision\npub fn register_bpf_function(\n    bpf_functions: &mut BTreeMap<u32, (usize, String)>,\n    pc: usize,\n    name: &str,\n    enable_symbol_and_section_labels: bool,\n) -> Result<u32, ElfError> {\n    let hash = hash_bpf_function(pc, name);\n    let name = if enable_symbol_and_section_labels {\n        name.to_string()\n    } else {\n        String::default()\n    };\n    if let Some(entry) = bpf_functions.insert(hash, (pc, name)) {\n        if entry.0 != pc {\n            return Err(ElfError::SymbolHashCollision(hash));\n        }\n    }\n    Ok(hash)\n}\n\n// For more information on the BPF instruction set:\n// https://github.com/iovisor/bpf-docs/blob/master/eBPF.md\n\n// msb                                                        lsb\n// +------------------------+----------------+----+----+--------+\n// |immediate               |offset          |src |dst |opcode  |\n// +------------------------+----------------+----+----+--------+\n\n// From least significant to most significant bit:\n//   8 bit opcode\n//   4 bit destination register (dst)\n//   4 bit source register (src)\n//   16 bit offset\n//   32 bit immediate (imm)\n\n/// Byte offset of the immediate field in the instruction\nconst BYTE_OFFSET_IMMEDIATE: usize = 4;\n/// Byte length of the immediate field\nconst BYTE_LENGTH_IMMEIDATE: usize = 4;\n\n/// BPF relocation types.\n#[allow(non_camel_case_types)]\n#[derive(Debug, PartialEq, Copy, Clone)]\nenum BpfRelocationType {\n    /// No relocation, placeholder\n    R_Bpf_None = 0,\n    /// R_BPF_64_64 relocation type is used for ld_imm64 instruction.\n    /// The actual to-be-relocated data (0 or section offset) is\n    /// stored at r_offset + 4 and the read/write data bitsize is 32\n    /// (4 bytes). The relocation can be resolved with the symbol\n    /// value plus implicit addend.\n    R_Bpf_64_64 = 1,\n    /// 64 bit relocation of a ldxdw instruction.  The ldxdw\n    /// instruction occupies two instruction slots. The 64-bit address\n    /// to load from is split into the 32-bit imm field of each\n    /// slot. The first slot's pre-relocation imm field contains the\n    /// virtual address (typically same as the file offset) of the\n    /// location to load. Relocation involves calculating the\n    /// post-load 64-bit physical address referenced by the imm field\n    /// and writing that physical address back into the imm fields of\n    /// the ldxdw instruction.\n    R_Bpf_64_Relative = 8,\n    /// Relocation of a call instruction.  The existing imm field\n    /// contains either an offset of the instruction to jump to (think\n    /// local function call) or a special value of \"-1\".  If -1 the\n    /// symbol must be looked up in the symbol table.  The relocation\n    /// entry contains the symbol number to call.  In order to support\n    /// both local jumps and calling external symbols a 32-bit hash is\n    /// computed and stored in the the call instruction's 32-bit imm\n    /// field.  The hash is used later to look up the 64-bit address\n    /// to jump to.  In the case of a local jump the hash is\n    /// calculated using the current program counter and in the case\n    /// of a symbol the hash is calculated using the name of the\n    /// symbol.\n    R_Bpf_64_32 = 10,\n}\nimpl BpfRelocationType {\n    fn from_x86_relocation_type(from: u32) -> Option<BpfRelocationType> {\n        match from {\n            R_X86_64_NONE => Some(BpfRelocationType::R_Bpf_None),\n            R_X86_64_64 => Some(BpfRelocationType::R_Bpf_64_64),\n            R_X86_64_RELATIVE => Some(BpfRelocationType::R_Bpf_64_Relative),\n            R_X86_64_32 => Some(BpfRelocationType::R_Bpf_64_32),\n            _ => None,\n        }\n    }\n}\n\n#[derive(Debug, PartialEq)]\nstruct SectionInfo {\n    name: String,\n    vaddr: u64,\n    offset_range: Range<usize>,\n}\n\n/// Elf loader/relocator\n#[derive(Debug, PartialEq)]\npub struct Executable<E: UserDefinedError, I: InstructionMeter> {\n    /// Configuration settings\n    config: Config,\n    /// Loaded and executable elf\n    elf_bytes: AlignedMemory,\n    /// Read-only section\n    ro_section: Vec<u8>,\n    /// Text section info\n    text_section_info: SectionInfo,\n    /// Call resolution map (hash, pc, name)\n    bpf_functions: BTreeMap<u32, (usize, String)>,\n    /// Syscall symbol map (hash, name)\n    syscall_symbols: BTreeMap<u32, String>,\n    /// Syscall resolution map\n    syscall_registry: SyscallRegistry,\n    /// Compiled program and argument\n    compiled_program: Option<JitProgram<E, I>>,\n}\n\nimpl<E: UserDefinedError, I: InstructionMeter> Executable<E, I> {\n    /// Get the configuration settings\n    pub fn get_config(&self) -> &Config {\n        &self.config\n    }\n\n    /// Get the .text section virtual address and bytes\n    pub fn get_text_bytes(&self) -> (u64, &[u8]) {\n        let offset = (self.text_section_info.vaddr - ebpf::MM_PROGRAM_START) as usize;\n        (\n            self.text_section_info.vaddr,\n            &self.ro_section[offset..offset + self.text_section_info.offset_range.len()],\n        )\n    }\n\n    /// Get the concatenated read-only sections (including the text section)\n    pub fn get_ro_section(&self) -> &[u8] {\n        self.ro_section.as_slice()\n    }\n\n    /// Get the entry point offset into the text section\n    pub fn get_entrypoint_instruction_offset(&self) -> Result<usize, EbpfError<E>> {\n        self.bpf_functions\n            .get(&ebpf::hash_symbol_name(b\"entrypoint\"))\n            .map(|(pc, _name)| *pc)\n            .ok_or(EbpfError::ElfError(ElfError::InvalidEntrypoint))\n    }\n\n    /// Get a symbol's instruction offset\n    pub fn lookup_bpf_function(&self, hash: u32) -> Option<usize> {\n        self.bpf_functions.get(&hash).map(|(pc, _name)| *pc)\n    }\n\n    /// Get the syscall registry\n    pub fn get_syscall_registry(&self) -> &SyscallRegistry {\n        &self.syscall_registry\n    }\n\n    /// Get the JIT compiled program\n    pub fn get_compiled_program(&self) -> Option<&JitProgram<E, I>> {\n        self.compiled_program.as_ref()\n    }\n\n    /// JIT compile the executable\n    pub fn jit_compile(&mut self) -> Result<(), EbpfError<E>> {\n        self.compiled_program = Some(JitProgram::<E, I>::new(self)?);\n        Ok(())\n    }\n\n    /// Report information on a symbol that failed to be resolved\n    pub fn report_unresolved_symbol(&self, insn_offset: usize) -> Result<u64, EbpfError<E>> {\n        let file_offset = insn_offset\n            .saturating_mul(ebpf::INSN_SIZE)\n            .saturating_add(self.text_section_info.offset_range.start as usize);\n\n        let mut name = \"Unknown\";\n        if let Ok(elf) = Elf::parse(self.elf_bytes.as_slice()) {\n            for relocation in &elf.dynrels {\n                match BpfRelocationType::from_x86_relocation_type(relocation.r_type) {\n                    Some(BpfRelocationType::R_Bpf_64_32) | Some(BpfRelocationType::R_Bpf_64_64) => {\n                        if relocation.r_offset as usize == file_offset {\n                            let sym = elf\n                                .dynsyms\n                                .get(relocation.r_sym)\n                                .ok_or(ElfError::UnknownSymbol(relocation.r_sym))?;\n                            name = elf\n                                .dynstrtab\n                                .get_at(sym.st_name)\n                                .ok_or(ElfError::UnknownSymbol(sym.st_name))?;\n                        }\n                    }\n                    _ => (),\n                }\n            }\n        }\n        Err(ElfError::UnresolvedSymbol(\n            name.to_string(),\n            file_offset / ebpf::INSN_SIZE + ebpf::ELF_INSN_DUMP_OFFSET,\n            file_offset,\n        )\n        .into())\n    }\n\n    /// Get syscalls and BPF functions (if debug symbols are not stripped)\n    pub fn get_function_symbols(&self) -> BTreeMap<usize, (u32, String)> {\n        let mut bpf_functions = BTreeMap::new();\n        for (hash, (pc, name)) in self.bpf_functions.iter() {\n            bpf_functions.insert(*pc, (*hash, name.clone()));\n        }\n        bpf_functions\n    }\n\n    /// Get syscalls symbols\n    pub fn get_syscall_symbols(&self) -> &BTreeMap<u32, String> {\n        &self.syscall_symbols\n    }\n\n    /// Create from raw text section bytes (list of instructions)\n    pub fn new_from_text_bytes(\n        config: Config,\n        text_bytes: &[u8],\n        syscall_registry: SyscallRegistry,\n        bpf_functions: BTreeMap<u32, (usize, String)>,\n    ) -> Self {\n        let elf_bytes = AlignedMemory::new_with_data(text_bytes, ebpf::HOST_ALIGN);\n        Self {\n            config,\n            elf_bytes,\n            ro_section: text_bytes.to_vec(),\n            text_section_info: SectionInfo {\n                name: if config.enable_symbol_and_section_labels {\n                    \".text\".to_string()\n                } else {\n                    String::default()\n                },\n                vaddr: ebpf::MM_PROGRAM_START,\n                offset_range: Range {\n                    start: 0,\n                    end: text_bytes.len(),\n                },\n            },\n            bpf_functions,\n            syscall_symbols: BTreeMap::default(),\n            syscall_registry,\n            compiled_program: None,\n        }\n    }\n\n    /// Fully loads an ELF, including validation and relocation\n    pub fn load(\n        config: Config,\n        bytes: &[u8],\n        mut syscall_registry: SyscallRegistry,\n    ) -> Result<Self, ElfError> {\n        let elf = Elf::parse(bytes)?;\n        let mut elf_bytes = AlignedMemory::new_with_data(bytes, ebpf::HOST_ALIGN);\n\n        Self::validate(&elf, elf_bytes.as_slice())?;\n\n        // calculate the text section info\n        let text_section = Self::get_section(&elf, \".text\")?;\n        let text_section_info = SectionInfo {\n            name: if config.enable_symbol_and_section_labels {\n                elf.shdr_strtab\n                    .get_at(text_section.sh_name)\n                    .unwrap()\n                    .to_string()\n            } else {\n                String::default()\n            },\n            vaddr: text_section.sh_addr.saturating_add(ebpf::MM_PROGRAM_START),\n            offset_range: text_section.file_range().unwrap_or_default(),\n        };\n        if (config.reject_section_virtual_address_file_offset_mismatch\n            && text_section.sh_addr != text_section.sh_offset)\n            || text_section_info.vaddr > ebpf::MM_STACK_START\n        {\n            return Err(ElfError::ValueOutOfBounds);\n        }\n\n        // relocate symbols\n        let mut bpf_functions = BTreeMap::default();\n        let mut syscall_symbols = BTreeMap::default();\n        Self::relocate(\n            &config,\n            &mut bpf_functions,\n            &mut syscall_symbols,\n            &mut syscall_registry,\n            &elf,\n            elf_bytes.as_slice_mut(),\n        )?;\n\n        // calculate entrypoint offset into the text section\n        let offset = elf.header.e_entry - text_section.sh_addr;\n        if offset % ebpf::INSN_SIZE as u64 != 0 {\n            return Err(ElfError::InvalidEntrypoint);\n        }\n        let entrypoint = offset as usize / ebpf::INSN_SIZE;\n        bpf_functions.remove(&ebpf::hash_symbol_name(b\"entrypoint\"));\n        register_bpf_function(\n            &mut bpf_functions,\n            entrypoint,\n            \"entrypoint\",\n            config.enable_symbol_and_section_labels,\n        )?;\n\n        // concatenate the read-only sections into one\n        let mut ro_length = text_section.sh_addr as usize + text_section_info.offset_range.len();\n        let ro_slices = elf\n            .section_headers\n            .iter()\n            .filter(|section_header| {\n                if let Some(name) = elf.shdr_strtab.get_at(section_header.sh_name) {\n                    return name == \".rodata\" || name == \".data.rel.ro\" || name == \".eh_frame\";\n                }\n                false\n            })\n            .map(|section_header| {\n                let vaddr = section_header\n                    .sh_addr\n                    .saturating_add(ebpf::MM_PROGRAM_START);\n                if (config.reject_section_virtual_address_file_offset_mismatch\n                    && section_header.sh_addr != section_header.sh_offset)\n                    || vaddr > ebpf::MM_STACK_START\n                {\n                    return Err(ElfError::ValueOutOfBounds);\n                }\n                let slice = elf_bytes\n                    .as_slice()\n                    .get(section_header.file_range().unwrap_or_default())\n                    .ok_or(ElfError::ValueOutOfBounds)?;\n                ro_length = ro_length.max(section_header.sh_addr as usize + slice.len());\n                Ok((section_header.sh_addr as usize, slice))\n            })\n            .collect::<Result<Vec<_>, ElfError>>()?;\n        let mut ro_section = vec![0; ro_length];\n        ro_section[text_section.sh_addr as usize\n            ..text_section.sh_addr as usize + text_section_info.offset_range.len()]\n            .copy_from_slice(\n                elf_bytes\n                    .as_slice()\n                    .get(text_section_info.offset_range.clone())\n                    .ok_or(ElfError::ValueOutOfBounds)?,\n            );\n        for (offset, slice) in ro_slices.iter() {\n            ro_section[*offset..*offset + slice.len()].copy_from_slice(slice);\n        }\n\n        Ok(Self {\n            config,\n            elf_bytes,\n            ro_section,\n            text_section_info,\n            bpf_functions,\n            syscall_symbols,\n            syscall_registry,\n            compiled_program: None,\n        })\n    }\n\n    // Functions exposed for tests\n\n    /// Fix-ups relative calls\n    pub fn fixup_relative_calls(\n        enable_symbol_and_section_labels: bool,\n        bpf_functions: &mut BTreeMap<u32, (usize, String)>,\n        elf_bytes: &mut [u8],\n    ) -> Result<(), ElfError> {\n        for i in 0..elf_bytes.len() / ebpf::INSN_SIZE {\n            let mut insn = ebpf::get_insn(elf_bytes, i);\n            if insn.opc == ebpf::CALL_IMM && insn.imm != -1 {\n                let target_pc = i as isize + 1 + insn.imm as isize;\n                if target_pc < 0 || target_pc >= (elf_bytes.len() / ebpf::INSN_SIZE) as isize {\n                    return Err(ElfError::RelativeJumpOutOfBounds(\n                        i + ebpf::ELF_INSN_DUMP_OFFSET,\n                    ));\n                }\n                let name = format!(\"function_{}\", target_pc);\n                let hash = register_bpf_function(\n                    bpf_functions,\n                    target_pc as usize,\n                    &name,\n                    enable_symbol_and_section_labels,\n                )?;\n                insn.imm = hash as i64;\n                let checked_slice = elf_bytes\n                    .get_mut(i * ebpf::INSN_SIZE..(i * ebpf::INSN_SIZE) + ebpf::INSN_SIZE)\n                    .ok_or(ElfError::ValueOutOfBounds)?;\n                checked_slice.copy_from_slice(&insn.to_vec());\n            }\n        }\n        Ok(())\n    }\n\n    /// Validates the ELF\n    pub fn validate(elf: &Elf, elf_bytes: &[u8]) -> Result<(), ElfError> {\n        if elf.header.e_ident[EI_CLASS] != ELFCLASS64 {\n            return Err(ElfError::WrongClass);\n        }\n        if elf.header.e_ident[EI_DATA] != ELFDATA2LSB {\n            return Err(ElfError::WrongEndianess);\n        }\n        if elf.header.e_ident[EI_OSABI] != ELFOSABI_NONE {\n            return Err(ElfError::WrongAbi);\n        }\n        if elf.header.e_machine != EM_BPF {\n            return Err(ElfError::WrongMachine);\n        }\n        if elf.header.e_type != ET_DYN {\n            return Err(ElfError::WrongType);\n        }\n\n        let num_text_sections = elf.section_headers.iter().fold(0, |count, section_header| {\n            if let Some(this_name) = elf.shdr_strtab.get_at(section_header.sh_name) {\n                if this_name == \".text\" {\n                    return count + 1;\n                }\n            }\n            count\n        });\n        if 1 != num_text_sections {\n            return Err(ElfError::NotOneTextSection);\n        }\n\n        for section_header in elf.section_headers.iter() {\n            if let Some(this_name) = elf.shdr_strtab.get_at(section_header.sh_name) {\n                if this_name.starts_with(\".bss\") {\n                    return Err(ElfError::BssNotSupported);\n                }\n            }\n        }\n\n        for section_header in &elf.section_headers {\n            let start = section_header.sh_offset as usize;\n            let end = section_header\n                .sh_offset\n                .checked_add(section_header.sh_size)\n                .ok_or(ElfError::ValueOutOfBounds)? as usize;\n            let _ = elf_bytes\n                .get(start..end)\n                .ok_or(ElfError::ValueOutOfBounds)?;\n        }\n        let text_section = Self::get_section(elf, \".text\")?;\n        if !text_section\n            .vm_range()\n            .contains(&(elf.header.e_entry as usize))\n        {\n            return Err(ElfError::EntrypointOutOfBounds);\n        }\n\n        Ok(())\n    }\n\n    // Private functions\n\n    /// Get a section by name\n    fn get_section(elf: &Elf, name: &str) -> Result<SectionHeader, ElfError> {\n        match elf.section_headers.iter().find(|section_header| {\n            if let Some(this_name) = elf.shdr_strtab.get_at(section_header.sh_name) {\n                return this_name == name;\n            }\n            false\n        }) {\n            Some(section) => Ok(section.clone()),\n            None => Err(ElfError::SectionNotFound(name.to_string())),\n        }\n    }\n\n    /// Relocates the ELF in-place\n    fn relocate(\n        config: &Config,\n        bpf_functions: &mut BTreeMap<u32, (usize, String)>,\n        syscall_symbols: &mut BTreeMap<u32, String>,\n        syscall_registry: &mut SyscallRegistry,\n        elf: &Elf,\n        elf_bytes: &mut [u8],\n    ) -> Result<(), ElfError> {\n        let text_section = Self::get_section(elf, \".text\")?;\n\n        // Fixup all program counter relative call instructions\n        Self::fixup_relative_calls(\n            config.enable_symbol_and_section_labels,\n            bpf_functions,\n            elf_bytes\n                .get_mut(text_section.file_range().unwrap_or_default())\n                .ok_or(ElfError::ValueOutOfBounds)?,\n        )?;\n\n        let mut syscall_cache = BTreeMap::new();\n        let text_section = Self::get_section(elf, \".text\")?;\n\n        // Fixup all the relocations in the relocation section if exists\n        for relocation in &elf.dynrels {\n            let r_offset = relocation.r_offset as usize;\n\n            // Offset of the immediate field\n            let imm_offset = r_offset.saturating_add(BYTE_OFFSET_IMMEDIATE);\n            match BpfRelocationType::from_x86_relocation_type(relocation.r_type) {\n                Some(BpfRelocationType::R_Bpf_64_64) => {\n                    // Read the instruction's immediate field which contains virtual\n                    // address to convert to physical\n                    let checked_slice = elf_bytes\n                        .get(imm_offset..imm_offset.saturating_add(BYTE_LENGTH_IMMEIDATE))\n                        .ok_or(ElfError::ValueOutOfBounds)?;\n                    let refd_va = LittleEndian::read_u32(checked_slice) as u64;\n                    // final \"physical address\" from the VM's perspetive is rooted at `MM_PROGRAM_START`\n                    let refd_pa = ebpf::MM_PROGRAM_START.saturating_add(refd_va);\n\n                    // The .text section has an unresolved load symbol instruction.\n                    let sym = elf\n                        .dynsyms\n                        .get(relocation.r_sym)\n                        .ok_or(ElfError::UnknownSymbol(relocation.r_sym))?;\n                    let addr = (sym.st_value + refd_pa) as u64;\n                    let checked_slice = elf_bytes\n                        .get_mut(imm_offset..imm_offset.saturating_add(BYTE_LENGTH_IMMEIDATE))\n                        .ok_or(ElfError::ValueOutOfBounds)?;\n                    LittleEndian::write_u32(checked_slice, (addr & 0xFFFFFFFF) as u32);\n                    let checked_slice = elf_bytes\n                        .get_mut(\n                            imm_offset.saturating_add(ebpf::INSN_SIZE)\n                                ..imm_offset\n                                    .saturating_add(ebpf::INSN_SIZE + BYTE_LENGTH_IMMEIDATE),\n                        )\n                        .ok_or(ElfError::ValueOutOfBounds)?;\n                    LittleEndian::write_u32(checked_slice, (addr >> 32) as u32);\n                }\n                Some(BpfRelocationType::R_Bpf_64_Relative) => {\n                    // Raw relocation between sections.  The instruction being relocated contains\n                    // the virtual address that it needs turned into a physical address.  Read it,\n                    // locate it in the ELF, convert to physical address\n\n                    // Read the instruction's immediate field which contains virtual\n                    // address to convert to physical\n                    let checked_slice = elf_bytes\n                        .get(imm_offset..imm_offset.saturating_add(BYTE_LENGTH_IMMEIDATE))\n                        .ok_or(ElfError::ValueOutOfBounds)?;\n                    let refd_va = LittleEndian::read_u32(checked_slice) as u64;\n\n                    if refd_va == 0 {\n                        return Err(ElfError::InvalidVirtualAddress(refd_va));\n                    }\n\n                    // final \"physical address\" from the VM's perspetive is rooted at `MM_PROGRAM_START`\n                    let refd_pa = ebpf::MM_PROGRAM_START.saturating_add(refd_va);\n\n                    // Write the physical address back into the target location\n                    if text_section\n                        .file_range()\n                        .unwrap_or_default()\n                        .contains(&r_offset)\n                    {\n                        // Instruction lddw spans two instruction slots, split the\n                        // physical address into a high and low and write into both slot's imm field\n\n                        let checked_slice = elf_bytes\n                            .get_mut(imm_offset..imm_offset.saturating_add(BYTE_LENGTH_IMMEIDATE))\n                            .ok_or(ElfError::ValueOutOfBounds)?;\n                        LittleEndian::write_u32(checked_slice, (refd_pa & 0xFFFFFFFF) as u32);\n                        let checked_slice = elf_bytes\n                            .get_mut(\n                                imm_offset.saturating_add(ebpf::INSN_SIZE)\n                                    ..imm_offset\n                                        .saturating_add(ebpf::INSN_SIZE + BYTE_LENGTH_IMMEIDATE),\n                            )\n                            .ok_or(ElfError::ValueOutOfBounds)?;\n                        LittleEndian::write_u32(checked_slice, (refd_pa >> 32) as u32);\n                    } else {\n                        // 64 bit memory location, write entire 64 bit physical address directly\n                        let checked_slice = elf_bytes\n                            .get_mut(r_offset..r_offset.saturating_add(mem::size_of::<u64>()))\n                            .ok_or(ElfError::ValueOutOfBounds)?;\n                        LittleEndian::write_u64(checked_slice, refd_pa);\n                    }\n                }\n                Some(BpfRelocationType::R_Bpf_64_32) => {\n                    // The .text section has an unresolved call to symbol instruction\n                    // Hash the symbol name and stick it into the call instruction's imm\n                    // field.  Later that hash will be used to look up the function location.\n\n                    let sym = elf\n                        .dynsyms\n                        .get(relocation.r_sym)\n                        .ok_or(ElfError::UnknownSymbol(relocation.r_sym))?;\n                    let name = elf\n                        .dynstrtab\n                        .get_at(sym.st_name)\n                        .ok_or(ElfError::UnknownSymbol(sym.st_name))?;\n                    let hash = if sym.is_function() && sym.st_value != 0 {\n                        // bpf call\n                        if !text_section.vm_range().contains(&(sym.st_value as usize)) {\n                            return Err(ElfError::ValueOutOfBounds);\n                        }\n                        let target_pc =\n                            (sym.st_value - text_section.sh_addr) as usize / ebpf::INSN_SIZE;\n                        register_bpf_function(\n                            bpf_functions,\n                            target_pc,\n                            name,\n                            config.enable_symbol_and_section_labels,\n                        )?\n                    } else {\n                        // syscall\n                        let hash = syscall_cache\n                            .entry(sym.st_name)\n                            .or_insert_with(|| (ebpf::hash_symbol_name(name.as_bytes()), name))\n                            .0;\n                        if config.reject_unresolved_syscalls\n                            && syscall_registry.lookup_syscall(hash).is_none()\n                        {\n                            return Err(ElfError::UnresolvedSymbol(\n                                name.to_string(),\n                                r_offset / ebpf::INSN_SIZE + ebpf::ELF_INSN_DUMP_OFFSET,\n                                r_offset,\n                            ));\n                        }\n                        hash\n                    };\n                    let checked_slice = elf_bytes\n                        .get_mut(imm_offset..imm_offset.saturating_add(BYTE_LENGTH_IMMEIDATE))\n                        .ok_or(ElfError::ValueOutOfBounds)?;\n                    LittleEndian::write_u32(checked_slice, hash);\n                }\n                _ => return Err(ElfError::UnknownRelocation(relocation.r_type)),\n            }\n        }\n\n        if config.enable_symbol_and_section_labels {\n            // Save syscall names\n            *syscall_symbols = syscall_cache\n                .values()\n                .map(|(hash, name)| (*hash, name.to_string()))\n                .collect();\n\n            // Register all known function names from the symbol table\n            for symbol in &elf.syms {\n                if symbol.st_info & 0xEF != 0x02 {\n                    continue;\n                }\n                if !text_section\n                    .vm_range()\n                    .contains(&(symbol.st_value as usize))\n                {\n                    return Err(ElfError::ValueOutOfBounds);\n                }\n                let target_pc = (symbol.st_value - text_section.sh_addr) as usize / ebpf::INSN_SIZE;\n                let name = elf\n                    .strtab\n                    .get_at(symbol.st_name)\n                    .ok_or(ElfError::UnknownSymbol(symbol.st_name))?;\n                register_bpf_function(bpf_functions, target_pc, name, true)?;\n            }\n        }\n\n        Ok(())\n    }\n\n    #[allow(dead_code)]\n    fn dump_data(name: &str, prog: &[u8]) {\n        let mut eight_bytes: Vec<u8> = Vec::new();\n        println!(\"{}\", name);\n        for i in prog.iter() {\n            if eight_bytes.len() >= 7 {\n                println!(\"{:02X?}\", eight_bytes);\n                eight_bytes.clear();\n            } else {\n                eight_bytes.push(*i);\n            }\n        }\n    }\n}\n\n#[cfg(test)]\nmod test {\n    use super::*;\n    use crate::{\n        ebpf,\n        elf::scroll::Pwrite,\n        fuzz::fuzz,\n        syscalls::{BpfSyscallString, BpfSyscallU64},\n        user_error::UserError,\n        vm::{SyscallObject, TestInstructionMeter},\n    };\n    use rand::{distributions::Uniform, Rng};\n    use std::{fs::File, io::Read};\n    type ElfExecutable = Executable<UserError, TestInstructionMeter>;\n\n    fn syscall_registry() -> SyscallRegistry {\n        let mut syscall_registry = SyscallRegistry::default();\n        syscall_registry\n            .register_syscall_by_name(b\"log\", BpfSyscallString::call)\n            .unwrap();\n        syscall_registry\n            .register_syscall_by_name(b\"log_64\", BpfSyscallU64::call)\n            .unwrap();\n        syscall_registry\n    }\n\n    #[test]\n    fn test_validate() {\n        let mut file = File::open(\"tests/elfs/noop.so\").expect(\"file open failed\");\n        let mut bytes = Vec::new();\n        file.read_to_end(&mut bytes)\n            .expect(\"failed to read elf file\");\n        let mut parsed_elf = Elf::parse(&bytes).unwrap();\n        let elf_bytes = bytes.to_vec();\n\n        ElfExecutable::validate(&parsed_elf, &elf_bytes).expect(\"validation failed\");\n        parsed_elf.header.e_ident[EI_CLASS] = ELFCLASS32;\n        ElfExecutable::validate(&parsed_elf, &elf_bytes).expect_err(\"allowed bad class\");\n        parsed_elf.header.e_ident[EI_CLASS] = ELFCLASS64;\n        ElfExecutable::validate(&parsed_elf, &elf_bytes).expect(\"validation failed\");\n        parsed_elf.header.e_ident[EI_DATA] = ELFDATA2MSB;\n        ElfExecutable::validate(&parsed_elf, &elf_bytes).expect_err(\"allowed big endian\");\n        parsed_elf.header.e_ident[EI_DATA] = ELFDATA2LSB;\n        ElfExecutable::validate(&parsed_elf, &elf_bytes).expect(\"validation failed\");\n        parsed_elf.header.e_ident[EI_OSABI] = 1;\n        ElfExecutable::validate(&parsed_elf, &elf_bytes).expect_err(\"allowed wrong abi\");\n        parsed_elf.header.e_ident[EI_OSABI] = ELFOSABI_NONE;\n        ElfExecutable::validate(&parsed_elf, &elf_bytes).expect(\"validation failed\");\n        parsed_elf.header.e_machine = EM_QDSP6;\n        ElfExecutable::validate(&parsed_elf, &elf_bytes).expect_err(\"allowed wrong machine\");\n        parsed_elf.header.e_machine = EM_BPF;\n        ElfExecutable::validate(&parsed_elf, &elf_bytes).expect(\"validation failed\");\n        parsed_elf.header.e_type = ET_REL;\n        ElfExecutable::validate(&parsed_elf, &elf_bytes).expect_err(\"allowed wrong type\");\n        parsed_elf.header.e_type = ET_DYN;\n        ElfExecutable::validate(&parsed_elf, &elf_bytes).expect(\"validation failed\");\n    }\n\n    #[test]\n    fn test_load() {\n        let mut file = File::open(\"tests/elfs/noop.so\").expect(\"file open failed\");\n        let mut elf_bytes = Vec::new();\n        file.read_to_end(&mut elf_bytes)\n            .expect(\"failed to read elf file\");\n        ElfExecutable::load(Config::default(), &elf_bytes, syscall_registry())\n            .expect(\"validation failed\");\n    }\n\n    #[test]\n    fn test_entrypoint() {\n        let mut file = File::open(\"tests/elfs/noop.so\").expect(\"file open failed\");\n        let mut elf_bytes = Vec::new();\n        file.read_to_end(&mut elf_bytes)\n            .expect(\"failed to read elf file\");\n        let elf = ElfExecutable::load(Config::default(), &elf_bytes, syscall_registry())\n            .expect(\"validation failed\");\n        let mut parsed_elf = Elf::parse(&elf_bytes).unwrap();\n        let initial_e_entry = parsed_elf.header.e_entry;\n        let executable: &Executable<UserError, TestInstructionMeter> = &elf;\n        assert_eq!(\n            0,\n            executable\n                .get_entrypoint_instruction_offset()\n                .expect(\"failed to get entrypoint\")\n        );\n\n        parsed_elf.header.e_entry += 8;\n        let mut elf_bytes = elf_bytes.clone();\n        elf_bytes.pwrite(parsed_elf.header, 0).unwrap();\n        let elf = ElfExecutable::load(Config::default(), &elf_bytes, syscall_registry())\n            .expect(\"validation failed\");\n        let executable: &Executable<UserError, TestInstructionMeter> = &elf;\n        assert_eq!(\n            1,\n            executable\n                .get_entrypoint_instruction_offset()\n                .expect(\"failed to get entrypoint\")\n        );\n\n        parsed_elf.header.e_entry = 1;\n        let mut elf_bytes = elf_bytes;\n        elf_bytes.pwrite(parsed_elf.header, 0).unwrap();\n        assert_eq!(\n            Err(ElfError::EntrypointOutOfBounds),\n            ElfExecutable::load(Config::default(), &elf_bytes, syscall_registry())\n        );\n\n        parsed_elf.header.e_entry = std::u64::MAX;\n        let mut elf_bytes = elf_bytes;\n        elf_bytes.pwrite(parsed_elf.header, 0).unwrap();\n        assert_eq!(\n            Err(ElfError::EntrypointOutOfBounds),\n            ElfExecutable::load(Config::default(), &elf_bytes, syscall_registry())\n        );\n\n        parsed_elf.header.e_entry = initial_e_entry + ebpf::INSN_SIZE as u64 + 1;\n        let mut elf_bytes = elf_bytes;\n        elf_bytes.pwrite(parsed_elf.header, 0).unwrap();\n        assert_eq!(\n            Err(ElfError::InvalidEntrypoint),\n            ElfExecutable::load(Config::default(), &elf_bytes, syscall_registry())\n        );\n\n        parsed_elf.header.e_entry = initial_e_entry;\n        let mut elf_bytes = elf_bytes;\n        elf_bytes.pwrite(parsed_elf.header, 0).unwrap();\n        let elf = ElfExecutable::load(Config::default(), &elf_bytes, syscall_registry())\n            .expect(\"validation failed\");\n        let executable: &Executable<UserError, TestInstructionMeter> = &elf;\n        assert_eq!(\n            0,\n            executable\n                .get_entrypoint_instruction_offset()\n                .expect(\"failed to get entrypoint\")\n        );\n    }\n\n    #[test]\n    fn test_fixup_relative_calls_back() {\n        // call -2\n        let mut bpf_functions: BTreeMap<u32, (usize, String)> = BTreeMap::new();\n        #[rustfmt::skip]\n        let mut prog = vec![\n            0xb7, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n            0xb7, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n            0xb7, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n            0xb7, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n            0xb7, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n            0x85, 0x10, 0x00, 0x00, 0xfe, 0xff, 0xff, 0xff];\n\n        ElfExecutable::fixup_relative_calls(true, &mut bpf_functions, &mut prog).unwrap();\n        let name = \"function_4\".to_string();\n        let hash = hash_bpf_function(4, &name);\n        let insn = ebpf::Insn {\n            opc: 0x85,\n            dst: 0,\n            src: 1,\n            imm: hash as i64,\n            ..ebpf::Insn::default()\n        };\n        assert_eq!(insn.to_array(), prog[40..]);\n        assert_eq!(*bpf_functions.get(&hash).unwrap(), (4, name));\n\n        // call +6\n        let mut bpf_functions: BTreeMap<u32, (usize, String)> = BTreeMap::new();\n        prog.splice(44.., vec![0xfa, 0xff, 0xff, 0xff]);\n        ElfExecutable::fixup_relative_calls(true, &mut bpf_functions, &mut prog).unwrap();\n        let name = \"function_0\".to_string();\n        let hash = hash_bpf_function(0, &name);\n        let insn = ebpf::Insn {\n            opc: 0x85,\n            dst: 0,\n            src: 1,\n            imm: hash as i64,\n            ..ebpf::Insn::default()\n        };\n        assert_eq!(insn.to_array(), prog[40..]);\n        assert_eq!(*bpf_functions.get(&hash).unwrap(), (0, name));\n    }\n\n    #[test]\n    fn test_fixup_relative_calls_forward() {\n        // call +0\n        let mut bpf_functions: BTreeMap<u32, (usize, String)> = BTreeMap::new();\n        #[rustfmt::skip]\n        let mut prog = vec![\n            0x85, 0x10, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n            0xb7, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n            0xb7, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n            0xb7, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n            0xb7, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n            0xb7, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00];\n\n        ElfExecutable::fixup_relative_calls(true, &mut bpf_functions, &mut prog).unwrap();\n        let name = \"function_1\".to_string();\n        let hash = hash_bpf_function(1, &name);\n        let insn = ebpf::Insn {\n            opc: 0x85,\n            dst: 0,\n            src: 1,\n            imm: hash as i64,\n            ..ebpf::Insn::default()\n        };\n        assert_eq!(insn.to_array(), prog[..8]);\n        assert_eq!(*bpf_functions.get(&hash).unwrap(), (1, name));\n\n        // call +4\n        let mut bpf_functions: BTreeMap<u32, (usize, String)> = BTreeMap::new();\n        prog.splice(4..8, vec![0x04, 0x00, 0x00, 0x00]);\n        ElfExecutable::fixup_relative_calls(true, &mut bpf_functions, &mut prog).unwrap();\n        let name = \"function_5\".to_string();\n        let hash = hash_bpf_function(5, &name);\n        let insn = ebpf::Insn {\n            opc: 0x85,\n            dst: 0,\n            src: 1,\n            imm: hash as i64,\n            ..ebpf::Insn::default()\n        };\n        assert_eq!(insn.to_array(), prog[..8]);\n        assert_eq!(*bpf_functions.get(&hash).unwrap(), (5, name));\n    }\n\n    #[test]\n    #[should_panic(\n        expected = \"called `Result::unwrap()` on an `Err` value: RelativeJumpOutOfBounds(29)\"\n    )]\n    fn test_fixup_relative_calls_out_of_bounds_forward() {\n        let mut bpf_functions: BTreeMap<u32, (usize, String)> = BTreeMap::new();\n        // call +5\n        #[rustfmt::skip]\n        let mut prog = vec![\n            0x85, 0x10, 0x00, 0x00, 0x05, 0x00, 0x00, 0x00,\n            0xb7, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n            0xb7, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n            0xb7, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n            0xb7, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n            0xb7, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00];\n\n        ElfExecutable::fixup_relative_calls(true, &mut bpf_functions, &mut prog).unwrap();\n        let name = \"function_1\".to_string();\n        let hash = hash_bpf_function(1, &name);\n        let insn = ebpf::Insn {\n            opc: 0x85,\n            dst: 0,\n            src: 1,\n            imm: hash as i64,\n            ..ebpf::Insn::default()\n        };\n        assert_eq!(insn.to_array(), prog[..8]);\n        assert_eq!(*bpf_functions.get(&hash).unwrap(), (1, name));\n    }\n\n    #[test]\n    #[should_panic(\n        expected = \"called `Result::unwrap()` on an `Err` value: RelativeJumpOutOfBounds(34)\"\n    )]\n    fn test_fixup_relative_calls_out_of_bounds_back() {\n        let mut bpf_functions: BTreeMap<u32, (usize, String)> = BTreeMap::new();\n        // call -7\n        #[rustfmt::skip]\n        let mut prog = vec![\n            0xb7, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n            0xb7, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n            0xb7, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n            0xb7, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n            0xb7, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n            0x85, 0x10, 0x00, 0x00, 0xf9, 0xff, 0xff, 0xff];\n\n        ElfExecutable::fixup_relative_calls(true, &mut bpf_functions, &mut prog).unwrap();\n        let name = \"function_4\".to_string();\n        let hash = hash_bpf_function(4, &name);\n        let insn = ebpf::Insn {\n            opc: 0x85,\n            dst: 0,\n            src: 1,\n            imm: hash as i64,\n            ..ebpf::Insn::default()\n        };\n        assert_eq!(insn.to_array(), prog[40..]);\n        assert_eq!(*bpf_functions.get(&hash).unwrap(), (4, name));\n    }\n\n    #[test]\n    #[ignore]\n    fn test_fuzz_load() {\n        // Random bytes, will mostly fail due to lack of ELF header so just do a few\n        let mut rng = rand::thread_rng();\n        let range = Uniform::new(0, 255);\n        println!(\"random bytes\");\n        for _ in 0..1_000 {\n            let elf_bytes: Vec<u8> = (0..100).map(|_| rng.sample(&range)).collect();\n            let _ = ElfExecutable::load(Config::default(), &elf_bytes, SyscallRegistry::default());\n        }\n\n        // Take a real elf and mangle it\n\n        let mut file = File::open(\"tests/elfs/noop.so\").expect(\"file open failed\");\n        let mut elf_bytes = Vec::new();\n        file.read_to_end(&mut elf_bytes)\n            .expect(\"failed to read elf file\");\n        let parsed_elf = Elf::parse(&elf_bytes).unwrap();\n\n        // focus on elf header, small typically 64 bytes\n        println!(\"mangle elf header\");\n        fuzz(\n            &elf_bytes,\n            1_000_000,\n            100,\n            0..parsed_elf.header.e_ehsize as usize,\n            0..255,\n            |bytes: &mut [u8]| {\n                let _ = ElfExecutable::load(Config::default(), bytes, SyscallRegistry::default());\n            },\n        );\n\n        // focus on section headers\n        println!(\"mangle section headers\");\n        fuzz(\n            &elf_bytes,\n            1_000_000,\n            100,\n            parsed_elf.header.e_shoff as usize..elf_bytes.len(),\n            0..255,\n            |bytes: &mut [u8]| {\n                let _ = ElfExecutable::load(Config::default(), bytes, SyscallRegistry::default());\n            },\n        );\n\n        // mangle whole elf randomly\n        println!(\"mangle whole elf\");\n        fuzz(\n            &elf_bytes,\n            1_000_000,\n            100,\n            0..elf_bytes.len(),\n            0..255,\n            |bytes: &mut [u8]| {\n                let _ = ElfExecutable::load(Config::default(), bytes, SyscallRegistry::default());\n            },\n        );\n    }\n\n    #[test]\n    fn test_relocs() {\n        let mut file = File::open(\"tests/elfs/reloc.so\").expect(\"file open failed\");\n        let mut elf_bytes = Vec::new();\n        file.read_to_end(&mut elf_bytes)\n            .expect(\"failed to read elf file\");\n        ElfExecutable::load(Config::default(), &elf_bytes, syscall_registry())\n            .expect(\"validation failed\");\n    }\n}\n"
  },
  {
    "project": "calamine",
    "target": 1,
    "commit_id": "d06428a7a4a34ffe6447b0718f6fe27b5da2f595",
    "func": "//! Coumpound File Binary format MS-CFB\n\nuse std::borrow::Cow;\nuse std::cmp::min;\nuse std::io::Read;\n\nuse log::debug;\n\nuse encoding_rs::{Encoding, UTF_16LE, UTF_8};\n\nuse crate::utils::*;\n\nconst ENDOFCHAIN: u32 = 0xFFFF_FFFE;\nconst FREESECT: u32 = 0xFFFF_FFFF;\nconst RESERVED_SECTORS: u32 = 0xFFFF_FFFA;\n\n/// A Cfb specific error enum\n#[derive(Debug)]\npub enum CfbError {\n    Io(std::io::Error),\n\n    Ole,\n    EmptyRootDir,\n    StreamNotFound(String),\n    Invalid {\n        name: &'static str,\n        expected: &'static str,\n        found: u16,\n    },\n    CodePageNotFound(u16),\n}\n\nimpl std::fmt::Display for CfbError {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            CfbError::Io(e) => write!(f, \"I/O error: {}\", e),\n            CfbError::Ole => write!(f, \"Invalid OLE signature (not an office document?)\"),\n            CfbError::EmptyRootDir => write!(f, \"Empty Root directory\"),\n            CfbError::StreamNotFound(e) => write!(f, \"Cannot find {} stream\", e),\n            CfbError::Invalid {\n                name,\n                expected,\n                found,\n            } => write!(\n                f,\n                \"Invalid {}, expecting {} found {:X}\",\n                name, expected, found\n            ),\n            CfbError::CodePageNotFound(e) => write!(f, \"Codepage {:X} not found\", e),\n        }\n    }\n}\n\nimpl std::error::Error for CfbError {\n    fn source(&self) -> Option<&(dyn std::error::Error + 'static)> {\n        match self {\n            CfbError::Io(e) => Some(e),\n            _ => None,\n        }\n    }\n}\n\n/// A struct for managing Compound File Binary format\n#[derive(Debug, Clone)]\npub struct Cfb {\n    directories: Vec<Directory>,\n    sectors: Sectors,\n    fats: Vec<u32>,\n    mini_sectors: Sectors,\n    mini_fats: Vec<u32>,\n}\n\nimpl Cfb {\n    /// Create a new `Cfb`\n    ///\n    /// Starts reading project metadata (header, directories, sectors and minisectors).\n    pub fn new<R: Read>(mut reader: &mut R, len: usize) -> Result<Cfb, CfbError> {\n        // load header\n        let (h, mut difat) = Header::from_reader(&mut reader)?;\n        let mut sectors = Sectors::new(h.sector_size, Vec::with_capacity(len));\n\n        // load fat and dif sectors\n        debug!(\"load difat\");\n        let mut sector_id = h.difat_start;\n        while sector_id < RESERVED_SECTORS {\n            difat.extend_from_slice(to_u32(sectors.get(sector_id, reader)?));\n            sector_id = difat.pop().unwrap(); //TODO: check if in infinite loop\n        }\n\n        // load the FATs\n        debug!(\"load fat\");\n        let mut fats = Vec::with_capacity(h.fat_len);\n        for id in difat.into_iter().filter(|id| *id != FREESECT) {\n            fats.extend_from_slice(to_u32(sectors.get(id, reader)?));\n        }\n\n        // get the list of directory sectors\n        debug!(\"load directories\");\n        let dirs = sectors.get_chain(h.dir_start, &fats, reader, h.dir_len * h.sector_size)?;\n        let dirs = dirs\n            .chunks(128)\n            .map(|c| Directory::from_slice(c, h.sector_size))\n            .collect::<Vec<_>>();\n\n        if dirs.is_empty() || (h.version != 3 && dirs[0].start == ENDOFCHAIN) {\n            return Err(CfbError::EmptyRootDir);\n        }\n        debug!(\"{:?}\", dirs);\n\n        // load the mini streams\n        debug!(\"load minis\");\n        let ministream = sectors.get_chain(dirs[0].start, &fats, reader, dirs[0].len)?;\n        let minifat = sectors.get_chain(\n            h.mini_fat_start,\n            &fats,\n            reader,\n            h.mini_fat_len * h.sector_size,\n        )?;\n        let minifat = to_u32(&minifat).to_vec();\n        Ok(Cfb {\n            directories: dirs,\n            sectors,\n            fats,\n            mini_sectors: Sectors::new(64, ministream),\n            mini_fats: minifat,\n        })\n    }\n\n    /// Checks if directory exists\n    pub fn has_directory(&self, name: &str) -> bool {\n        self.directories.iter().any(|d| &*d.name == name)\n    }\n\n    /// Gets a stream by name out of directories\n    pub fn get_stream<R: Read>(&mut self, name: &str, r: &mut R) -> Result<Vec<u8>, CfbError> {\n        match self.directories.iter().find(|d| &*d.name == name) {\n            None => Err(CfbError::StreamNotFound(name.to_string())),\n            Some(d) => {\n                if d.len < 4096 {\n                    // TODO: Study the possibility to return a `VecArray` (stack allocated)\n                    self.mini_sectors\n                        .get_chain(d.start, &self.mini_fats, r, d.len)\n                } else {\n                    self.sectors.get_chain(d.start, &self.fats, r, d.len)\n                }\n            }\n        }\n    }\n}\n\n/// A hidden struct which defines cfb files structure\n#[derive(Debug)]\nstruct Header {\n    version: u16,\n    sector_size: usize,\n    dir_len: usize,\n    dir_start: u32,\n    fat_len: usize,\n    mini_fat_len: usize,\n    mini_fat_start: u32,\n    difat_start: u32,\n}\n\nimpl Header {\n    fn from_reader<R: Read>(f: &mut R) -> Result<(Header, Vec<u32>), CfbError> {\n        let mut buf = [0u8; 512];\n        f.read_exact(&mut buf).map_err(CfbError::Io)?;\n\n        // check ole signature\n        if read_slice::<u64>(buf.as_ref()) != 0xE11A_B1A1_E011_CFD0 {\n            return Err(CfbError::Ole);\n        }\n\n        let version = read_u16(&buf[26..28]);\n\n        let sector_size = match read_u16(&buf[30..32]) {\n            0x0009 => 512,\n            0x000C => {\n                // sector size is 4096 bytes, but header is 512 bytes,\n                // so the remaining sector bytes have to be read\n                let mut buf_end = [0u8; 3584];\n                f.read_exact(&mut buf_end).map_err(CfbError::Io)?;\n                4096\n            }\n            s => {\n                return Err(CfbError::Invalid {\n                    name: \"sector shift\",\n                    expected: \"0x09 or 0x0C\",\n                    found: s,\n                });\n            }\n        };\n\n        if read_u16(&buf[32..34]) != 0x0006 {\n            return Err(CfbError::Invalid {\n                name: \"minisector shift\",\n                expected: \"0x06\",\n                found: read_u16(&buf[32..34]),\n            });\n        }\n\n        let dir_len = read_usize(&buf[40..44]);\n        let fat_len = read_usize(&buf[44..48]);\n        let dir_start = read_u32(&buf[48..52]);\n        let mini_fat_start = read_u32(&buf[60..64]);\n        let mini_fat_len = read_usize(&buf[64..68]);\n        let difat_start = read_u32(&buf[68..72]);\n        let difat_len = read_usize(&buf[62..76]);\n\n        let mut difat = Vec::with_capacity(difat_len);\n        difat.extend_from_slice(to_u32(&buf[76..512]));\n\n        Ok((\n            Header {\n                version,\n                sector_size,\n                dir_len,\n                fat_len,\n                dir_start,\n                mini_fat_len,\n                mini_fat_start,\n                difat_start,\n            },\n            difat,\n        ))\n    }\n}\n\n/// A struct corresponding to the elementary block of memory\n///\n/// `data` will persist in memory to ensure the file is read once\n#[derive(Debug, Clone)]\nstruct Sectors {\n    data: Vec<u8>,\n    size: usize,\n}\n\nimpl Sectors {\n    fn new(size: usize, data: Vec<u8>) -> Sectors {\n        Sectors { data, size }\n    }\n\n    fn get<R: Read>(&mut self, id: u32, r: &mut R) -> Result<&[u8], CfbError> {\n        let start = id as usize * self.size;\n        let end = start + self.size;\n        if end > self.data.len() {\n            let mut len = self.data.len();\n            unsafe {\n                self.data.set_len(end);\n            }\n            // read_exact or stop if EOF\n            while len < end {\n                let read = r.read(&mut self.data[len..end]).map_err(CfbError::Io)?;\n                if read == 0 {\n                    return Ok(&self.data[start..len]);\n                }\n                len += read;\n            }\n        }\n        Ok(&self.data[start..end])\n    }\n\n    fn get_chain<R: Read>(\n        &mut self,\n        mut sector_id: u32,\n        fats: &[u32],\n        r: &mut R,\n        len: usize,\n    ) -> Result<Vec<u8>, CfbError> {\n        let mut chain = if len > 0 {\n            Vec::with_capacity(len)\n        } else {\n            Vec::new()\n        };\n        while sector_id != ENDOFCHAIN {\n            chain.extend_from_slice(self.get(sector_id, r)?);\n            sector_id = fats[sector_id as usize];\n        }\n        if len > 0 {\n            chain.truncate(len);\n        }\n        Ok(chain)\n    }\n}\n\n/// A struct representing sector organizations, behaves similarly to a tree\n#[derive(Debug, Clone)]\nstruct Directory {\n    name: String,\n    start: u32,\n    len: usize,\n}\n\nimpl Directory {\n    fn from_slice(buf: &[u8], sector_size: usize) -> Directory {\n        let mut name = UTF_16LE.decode(&buf[..64]).0.into_owned();\n        if let Some(l) = name.as_bytes().iter().position(|b| *b == 0) {\n            name.truncate(l);\n        }\n        let start = read_u32(&buf[116..120]);\n        let len = if sector_size == 512 {\n            read_slice::<u32>(&buf[120..124]) as usize\n        } else {\n            read_slice::<u64>(&buf[120..128]) as usize\n        };\n\n        Directory { start, len, name }\n    }\n}\n\n/// Decompresses stream\npub fn decompress_stream(s: &[u8]) -> Result<Vec<u8>, CfbError> {\n    const POWER_2: [usize; 16] = [\n        1,\n        1 << 1,\n        1 << 2,\n        1 << 3,\n        1 << 4,\n        1 << 5,\n        1 << 6,\n        1 << 7,\n        1 << 8,\n        1 << 9,\n        1 << 10,\n        1 << 11,\n        1 << 12,\n        1 << 13,\n        1 << 14,\n        1 << 15,\n    ];\n\n    debug!(\"decompress stream\");\n    let mut res = Vec::new();\n\n    if s[0] != 0x01 {\n        return Err(CfbError::Invalid {\n            name: \"signature\",\n            expected: \"0x01\",\n            found: s[0] as u16,\n        });\n    }\n\n    let mut i = 1;\n    while i < s.len() {\n        let chunk_header = read_u16(&s[i..]);\n        i += 2;\n\n        // each 'chunk' is 4096 wide, let's reserve that space\n        let start = res.len();\n        res.reserve(4096);\n\n        let chunk_size = chunk_header & 0x0FFF;\n        let chunk_signature = (chunk_header & 0x7000) >> 12;\n        let chunk_flag = (chunk_header & 0x8000) >> 15;\n\n        assert_eq!(chunk_signature, 0b011, \"i={}, len={}\", i, s.len());\n\n        if chunk_flag == 0 {\n            // uncompressed\n            res.extend_from_slice(&s[i..i + 4096]);\n            i += 4096;\n        } else {\n            let mut chunk_len = 0;\n            let mut buf = [0u8; 4096];\n            'chunk: loop {\n                if i >= s.len() {\n                    break;\n                }\n\n                let bit_flags = s[i];\n                i += 1;\n                chunk_len += 1;\n\n                for bit_index in 0..8 {\n                    if chunk_len > chunk_size {\n                        break 'chunk;\n                    }\n\n                    if (bit_flags & (1 << bit_index)) == 0 {\n                        // literal token\n                        res.push(s[i]);\n                        i += 1;\n                        chunk_len += 1;\n                    } else {\n                        // copy token\n                        let token = read_u16(&s[i..]);\n                        i += 2;\n                        chunk_len += 2;\n\n                        let decomp_len = res.len() - start;\n                        let bit_count = (4..16).find(|i| POWER_2[*i] >= decomp_len).unwrap();\n                        let len_mask = 0xFFFF >> bit_count;\n                        let mut len = (token & len_mask) as usize + 3;\n                        let offset = ((token & !len_mask) >> (16 - bit_count)) as usize + 1;\n\n                        while len > offset {\n                            buf[..offset].copy_from_slice(&res[res.len() - offset..]);\n                            res.extend_from_slice(&buf[..offset]);\n                            len -= offset;\n                        }\n                        buf[..len]\n                            .copy_from_slice(&res[res.len() - offset..res.len() - offset + len]);\n                        res.extend_from_slice(&buf[..len]);\n                    }\n                }\n            }\n        }\n    }\n    Ok(res)\n}\n\n#[derive(Clone)]\npub struct XlsEncoding {\n    encoding: &'static Encoding,\n    pub high_byte: Option<bool>, // None if single byte encoding\n}\n\nimpl XlsEncoding {\n    pub fn from_codepage(codepage: u16) -> Result<XlsEncoding, CfbError> {\n        let e =\n            codepage::to_encoding(codepage).ok_or_else(|| CfbError::CodePageNotFound(codepage))?;\n        let high_byte = if e == UTF_8 || e.is_single_byte() {\n            None\n        } else {\n            Some(false)\n        };\n\n        Ok(XlsEncoding {\n            encoding: e,\n            high_byte,\n        })\n    }\n\n    pub fn decode_to(&self, stream: &[u8], len: usize, s: &mut String) -> (usize, usize) {\n        let (l, ub, bytes) = match self.high_byte {\n            None => {\n                let l = min(stream.len(), len);\n                (l, l, Cow::Borrowed(&stream[..l]))\n            }\n            Some(false) => {\n                let l = min(stream.len(), len);\n\n                // add 0x00 high bytes to unicodes\n                let mut bytes = vec![0; l * 2];\n                for (i, sce) in stream.iter().take(l).enumerate() {\n                    bytes[2 * i] = *sce;\n                }\n                (l, l, Cow::Owned(bytes))\n            }\n            Some(true) => {\n                let l = min(stream.len() / 2, len);\n                (l, 2 * l, Cow::Borrowed(&stream[..2 * l]))\n            }\n        };\n\n        s.push_str(&self.encoding.decode(&bytes).0);\n        (l, ub)\n    }\n\n    pub fn decode_all(&self, stream: &[u8]) -> String {\n        let mut s = String::with_capacity(stream.len());\n        let _ = self.decode_to(stream, stream.len(), &mut s);\n        s\n    }\n}\n"
  },
  {
    "project": "ncurses-rs",
    "target": 1,
    "commit_id": "55be2ec2f9e69f2b3870547be75cff93d27ebc7c",
    "func": "/*\n    Copyright \u00a9 2013 Free Software Foundation, Inc\n    See licensing in LICENSE file\n\n    File: lib.rs\n    Author: Jesse 'Jeaye' Wilkerson\n    Description:\n      Safe wrappers for ncurses functions.\n*/\n\n#![allow(non_camel_case_types)]\n#![allow(non_snake_case)]\n#![warn(missing_debug_implementations)]\n\nextern crate libc;\n\nuse std::mem;\nuse std::{ char, ptr };\nuse std::ffi::{CString, CStr};\nuse self::ll::{FILE_p};\npub use self::constants::*;\npub use self::panel::wrapper::*;\npub use self::menu::wrapper::*;\npub use self::menu::constants::*;\n\npub type chtype = self::ll::chtype;\npub type winttype = u32;\n\npub type mmask_t = chtype;\npub type attr_t = chtype;\npub type NCURSES_ATTR_T = attr_t;\n\npub mod ll;\npub mod constants;\npub mod panel;\npub mod menu;\n\ntrait FromCStr {\n    unsafe fn from_c_str(s: *const libc::c_char) -> Self;\n}\n\nimpl FromCStr for String {\n    unsafe fn from_c_str(s: *const libc::c_char) -> String {\n        let bytes = CStr::from_ptr(s).to_bytes();\n        String::from_utf8_unchecked(bytes.to_vec())\n    }\n}\n\nimpl FromCStr for Option<String> {\n    unsafe fn from_c_str(s: *const libc::c_char) -> Option<String> {\n        if s.is_null() {\n            None\n        } else {\n            Some(FromCStr::from_c_str(s))\n        }\n    }\n}\n\ntrait ToCStr {\n    fn to_c_str(&self) -> CString;\n}\n\nimpl <'a>ToCStr for &'a str {\n    fn to_c_str(&self) -> CString {\n        CString::new(*self).unwrap()\n    }\n}\n\n#[derive(Debug, Clone, Copy)]\npub enum CURSOR_VISIBILITY\n{\n  CURSOR_INVISIBLE = 0,\n  CURSOR_VISIBLE,\n  CURSOR_VERY_VISIBLE\n}\n\npub type WINDOW = self::ll::WINDOW;\npub type SCREEN = self::ll::SCREEN;\npub type mmaskt = self::ll::mmask_t;\npub type MEVENT = self::ll::MEVENT;\n\npub fn addch(ch: chtype) -> i32\n{ unsafe { ll::addch(ch) } }\n\n\npub fn addchnstr(s: &[chtype], n: i32) -> i32\n{ unsafe { ll::addchnstr(s.as_ptr(), n) } }\n\n\npub fn addchstr(s: &[chtype]) -> i32\n{ unsafe { ll::addchstr(s.as_ptr()) } }\n\n\npub fn addnstr(s: &str, n: i32) -> i32\n{ unsafe { ll::addnstr(s.to_c_str().as_ptr(), n) } }\n\n\npub fn addstr(s: &str) -> i32\n{ unsafe { ll::addstr(s.to_c_str().as_ptr()) } }\n\n\npub fn assume_default_colors(fg: i32, bg: i32) -> i32\n{ unsafe { ll::assume_default_colors(fg, bg) } }\n\n\npub fn attroff(a: NCURSES_ATTR_T) -> i32\n{ unsafe { ll::attroff(a) } }\n\n\npub fn attron(a: NCURSES_ATTR_T) -> i32\n{ unsafe { ll::attron(a) } }\n\n\npub fn attrset(a: NCURSES_ATTR_T) -> i32\n{ unsafe { ll::attrset(a) } }\n\n\npub fn attr_get(attrs: &mut attr_t, pair: &mut i16) -> i32\n{\n  unsafe\n  {\n    ll::attr_get(&mut* attrs as *mut attr_t,\n                 &mut* pair as *mut i16,\n                 ptr::null())\n  }\n}\n\n\npub fn attr_off(a: attr_t) -> i32\n{ unsafe { ll::attr_off(a, ptr::null()) } }\n\n\npub fn attr_on(a: attr_t) -> i32\n{ unsafe { ll::attr_on(a, ptr::null()) } }\n\n\npub fn attr_set(attr: attr_t, pair: i16) -> i32\n{ unsafe { ll::attr_set(attr, pair, ptr::null()) } }\n\n\npub fn baudrate() -> i32\n{ unsafe { ll::baudrate() } }\n\n\npub fn beep() -> i32\n{ unsafe { ll::beep() } }\n\n\npub fn bkgd(ch: chtype) -> i32\n{ unsafe { ll::bkgd(ch) } }\n\n\npub fn bkgdset(ch: chtype)\n{ unsafe { ll::bkgdset(ch) } }\n\n\npub fn border(ls: chtype, rs: chtype, ts: chtype, bs: chtype, tl: chtype, tr: chtype, bl: chtype, br: chtype) -> i32\n{ unsafe { ll::border(ls, rs, ts, bs, tl, tr, bl, br) } }\n\n\n#[link_name=\"box\"] pub fn box_(w: WINDOW, v: chtype, h: chtype) -> i32\n{ wborder(w, v, v, h, h, 0, 0, 0, 0) }\n\n\npub fn can_change_color() -> bool\n{ unsafe { ll::can_change_color() == TRUE } }\n\n\npub fn cbreak() -> i32\n{ unsafe { ll::cbreak() } }\n\n\npub fn chgat(n: i32, attr: attr_t, color: i16) -> i32\n{ unsafe { ll::chgat(n, attr, color, ptr::null()) } }\n\n\npub fn clear() -> i32\n{ unsafe { ll::clear() } }\n\n\npub fn clearok(w: WINDOW, ok: bool) -> i32\n{ unsafe { ll::clearok(w, ok as ll::c_bool) } }\n\n\npub fn clrtobot() -> i32\n{ unsafe { ll::clrtobot() } }\n\n\npub fn clrtoeol() -> i32\n{ unsafe { ll::clrtoeol() } }\n\n\npub fn color_content(color: i16, r: &mut i16, g: &mut i16, b: &mut i16) -> i32\n{\n  unsafe\n  {\n    ll::color_content(color,\n                      &mut*r as *mut i16,\n                      &mut*g as *mut i16,\n                      &mut*b as *mut i16)\n  }\n}\n\n\npub fn color_set(pair: i16) -> i32\n{ unsafe { ll::color_set(pair, ptr::null()) } }\n\n\npub fn copywin(src_win: WINDOW, dest_win: WINDOW, src_min_row: i32,\n               src_min_col: i32, dest_min_row: i32, dest_min_col: i32,\n               dest_max_row: i32, dest_max_col: i32, overlay: i32) -> i32\n{\n  unsafe\n  {\n    ll::copywin(src_win, dest_win, src_min_row, src_min_col,\n                dest_min_row, dest_min_col, dest_max_row,\n                dest_max_col, overlay)\n  }\n}\n\n\npub fn curs_set(visibility: CURSOR_VISIBILITY) -> Option<CURSOR_VISIBILITY>\n{\n  unsafe\n  {\n    match ll::curs_set(visibility as i32)\n    {\n      ERR => None,\n      ret => Some(mem::transmute::<i8, CURSOR_VISIBILITY>(ret as i8)),\n    }\n  }\n}\n\n\npub fn def_prog_mode() -> i32\n{ unsafe { ll::def_prog_mode() } }\n\n\npub fn def_shell_mode() -> i32\n{ unsafe { ll::def_shell_mode() } }\n\n\npub fn delay_output(ms: i32) -> i32\n{ unsafe { ll::delay_output(ms) } }\n\n\npub fn delch() -> i32\n{ unsafe { ll::delch() } }\n\n\npub fn delscreen(s: SCREEN)\n{ unsafe { ll::delscreen(s) } }\n\n\npub fn delwin(w: WINDOW) -> i32\n{ unsafe { ll::delwin(w) } }\n\n\npub fn deleteln() -> i32\n{ unsafe { ll::deleteln() } }\n\n\npub fn derwin(w: WINDOW, lines: i32, cols: i32, x: i32, y: i32) -> WINDOW\n{ unsafe { ll::derwin(w, lines, cols, x, y) } }\n\n\npub fn doupdate() -> i32\n{ unsafe { ll::doupdate() } }\n\n\npub fn dupwin(w: WINDOW) -> WINDOW\n{ unsafe { ll::dupwin(w) } }\n\n\npub fn echo() -> i32\n{ unsafe { ll::echo() } }\n\n\npub fn echochar(c: chtype) -> i32\n{ unsafe { ll::echochar(c) } }\n\n\npub fn erase() -> i32\n{ unsafe { ll::erase() } }\n\n\npub fn endwin() -> i32\n{ unsafe { ll::endwin() } }\n\n\npub fn erasechar() -> char\n{ unsafe { char::from_u32(ll::erasechar() as u32).expect(\"Invalid char\") } }\n\n\npub fn filter()\n{ unsafe { ll::filter() } }\n\n\npub fn flash() -> i32\n{ unsafe { ll::flash() } }\n\n\npub fn flushinp() -> i32\n{ unsafe { ll::flushinp() } }\n\n\npub fn getbkgd(w: WINDOW) -> chtype\n{ unsafe { ll::getbkgd(w) } }\n\n\npub fn getch() -> i32\n{ unsafe { ll::getch() } }\n\n#[derive(Debug)]\npub enum WchResult {\n    KeyCode(i32),\n    Char(winttype),\n}\n\npub fn get_wch() -> Option<WchResult> {\n    unsafe {\n        let mut x = 0;\n        match ll::get_wch(&mut x) {\n            OK => {\n                Some(WchResult::Char(x))\n            }\n            KEY_CODE_YES => {\n                Some(WchResult::KeyCode(x as i32))\n            }\n            _ => {\n                None\n            }\n        }\n    }\n}\n\npub fn mvget_wch(y: i32, x: i32) -> Option<WchResult> {\n    unsafe {\n        let mut result = 0;\n        match ll::mvget_wch(y, x, &mut result) {\n            OK => {\n                Some(WchResult::Char(result))\n            }\n            KEY_CODE_YES => {\n                Some(WchResult::KeyCode(result as i32))\n            }\n            _ => {\n                None\n            }\n        }\n    }\n}\n\n#[cfg(feature = \"wide\")]\npub fn wget_wch(w: WINDOW) -> Option<WchResult> {\n    unsafe {\n        let mut result = 0;\n        match ll::wget_wch(w, &mut result) {\n            OK => {\n                Some(WchResult::Char(result))\n            }\n            KEY_CODE_YES => {\n                Some(WchResult::KeyCode(result as i32))\n            }\n            _ => {\n                None\n            }\n        }\n    }\n}\n\n#[cfg(feature = \"wide\")]\npub fn mvwget_wch(w: WINDOW, y: i32, x: i32) -> Option<WchResult> {\n    unsafe {\n        let mut result = 0;\n        match ll::mvwget_wch(w, y, x, &mut result) {\n            OK => {\n                Some(WchResult::Char(result))\n            }\n            KEY_CODE_YES => {\n                Some(WchResult::KeyCode(result as i32))\n            }\n            _ => {\n                None\n            }\n        }\n    }\n}\n\npub fn unget_wch(ch: u32) -> i32 {\n    unsafe {\n        ll::unget_wch(ch)\n    }\n}\n\n\npub fn getnstr(s: &mut String, n: i32) -> i32\n{ wgetnstr(stdscr(), s, n) }\n\n\npub fn getstr(s: &mut String) -> i32\n{\n  /* XXX: This is probably broken. */\n  let mut ch = getch();\n  while ch != '\\n' as i32 && ch != '\\r' as i32\n  {\n    unsafe { s.as_mut_vec().push(ch as u8); }\n    ch = getch();\n  }\n  OK\n}\n\n\npub fn getwin(reader: *mut libc::FILE) -> WINDOW\n{ unsafe { ll::getwin(reader) } } /* TODO: Make this safe. */\n\n\npub fn getattrs(w: WINDOW) -> i32\n{ unsafe { ll::getattrs(w) } }\n\n\npub fn getcurx(w: WINDOW) -> i32\n{ unsafe { ll::getcurx(w) } }\n\n\npub fn getcury(w: WINDOW) -> i32\n{ unsafe { ll::getcury(w) } }\n\n\npub fn getbegx(w: WINDOW) -> i32\n{ unsafe { ll::getbegx(w) } }\n\n\npub fn getbegy(w: WINDOW) -> i32\n{ unsafe { ll::getbegy(w) } }\n\n\npub fn getmaxx(w: WINDOW) -> i32\n{ unsafe { ll::getmaxx(w) } }\n\n\npub fn getmaxy(w: WINDOW) -> i32\n{ unsafe { ll::getmaxy(w) } }\n\n\npub fn getparx(w: WINDOW) -> i32\n{ unsafe { ll::getparx(w) } }\n\n\npub fn getpary(w: WINDOW) -> i32\n{ unsafe { ll::getpary(w) } }\n\n\npub fn halfdelay(tenths: i32) -> i32\n{ unsafe { ll::halfdelay(tenths) } }\n\n\npub fn has_colors() -> bool\n{ unsafe { ll::has_colors() == TRUE } }\n\n\npub fn has_ic() -> bool\n{ unsafe { ll::has_ic() == TRUE } }\n\n\npub fn has_il() -> bool\n{ unsafe { ll::has_il() == TRUE } }\n\n\npub fn hline(ch: chtype, n: i32) -> i32\n{ unsafe { ll::hline(ch, n) } }\n\n\npub fn idcok(w: WINDOW, bf: bool)\n{ unsafe { ll::idcok(w, bf as ll::c_bool) } }\n\n\npub fn idlok(w: WINDOW, bf: bool) -> i32\n{ unsafe { ll::idlok(w, bf as ll::c_bool) } }\n\n\npub fn immedok(w: WINDOW, bf: bool)\n{ unsafe { ll::immedok(w, bf as ll::c_bool) } }\n\n\npub fn inch() -> chtype\n{ unsafe { ll::inch() } }\n\n\npub fn inchnstr(s: &mut Vec<chtype>, n: i32) -> i32\n{\n  /* XXX: This is probably broken. */\n  s.clear();\n  s.reserve(n as usize);\n  unsafe\n  {\n    let ret = ll::inchnstr(s.as_ptr(), n);\n\n    let capacity = s.capacity();\n    match s.iter().position(|x| *x == 0)\n    {\n      Some(index) => s.set_len(index as usize),\n      None => s.set_len(capacity),\n    }\n\n    ret\n  }\n}\n\n\npub fn inchstr(s: &mut Vec<chtype>) -> i32\n{\n  /* XXX: This is probably broken. */\n  unsafe\n  {\n    let ret = ll::inchstr(s.as_ptr());\n\n    let capacity = s.capacity();\n    match s.iter().position(|x| *x == 0)\n    {\n      Some(index) => s.set_len(index as usize),\n      None => s.set_len(capacity),\n    }\n\n    ret\n  }\n}\n\n\npub fn initscr() -> WINDOW\n{ unsafe { ll::initscr() } }\n\n\npub fn init_color(color: i16, r: i16, g: i16, b: i16) -> i32\n{ unsafe { ll::init_color(color, r, g, b) } }\n\n\npub fn init_pair(pair: i16, f: i16, b: i16) -> i32\n{ unsafe { ll::init_pair(pair, f, b) } }\n\n\npub fn innstr(s: &mut String, n: i32) -> i32\n{\n  /* XXX: This is probably broken. */\n  unsafe\n  {\n    s.as_mut_vec().clear();\n    s.reserve(n as usize);\n    let buf = s.as_bytes().as_ptr();\n    let ret = ll::innstr(mem::transmute(buf), n);\n\n    let capacity = s.capacity();\n    match s.find('\\0')\n    {\n      Some(index) => s.as_mut_vec().set_len(index as usize),\n      None => s.as_mut_vec().set_len(capacity),\n    }\n\n    ret\n  }\n}\n\n\npub fn insch(ch: chtype) -> i32\n{ unsafe { ll::insch(ch) } }\n\n\npub fn insdelln(n: i32) -> i32\n{ unsafe { ll::insdelln(n) } }\n\n\npub fn insertln() -> i32\n{ unsafe { ll::insertln() } }\n\n\npub fn insnstr(s: &str, n: i32) -> i32\n{\n  unsafe\n  {\n    let buf = s.as_ptr();\n    ll::insnstr(mem::transmute(buf), n)\n  }\n}\n\n\npub fn insstr(s: &str) -> i32\n{\n  unsafe\n  {\n    let buf = s.as_ptr();\n    ll::insstr(mem::transmute(buf))\n  }\n}\n\n\npub fn instr(s: &mut String) -> i32\n{\n  /* XXX: This is probably broken. */\n  unsafe\n  {\n    let buf = s.as_bytes().as_ptr();\n    let ret = ll::instr(mem::transmute(buf));\n\n    let capacity = s.capacity();\n    match s.find('\\0')\n    {\n      Some(index) => s.as_mut_vec().set_len(index as usize),\n      None => s.as_mut_vec().set_len(capacity),\n    }\n\n    ret\n  }\n}\n\n\npub fn intrflush(w: WINDOW, bf: bool) -> i32\n{ unsafe { ll::intrflush(w, bf as ll::c_bool) } }\n\n\npub fn isendwin() -> bool\n{ unsafe { ll::isendwin() == TRUE } }\n\n\npub fn is_linetouched(w: WINDOW, l: i32) -> bool\n{ unsafe { ll::is_linetouched(w, l) == TRUE } }\n\n\npub fn is_wintouched(w: WINDOW) -> bool\n{ unsafe { ll::is_wintouched(w) == TRUE } }\n\n\npub fn is_term_resized(lines: i32, cols: i32) -> bool\n{ unsafe { ll::is_term_resized(lines, cols) == TRUE } }\n\n\npub fn is_cleared(w: WINDOW) -> bool\n{ unsafe { ll::is_cleared(w) == TRUE } }\n\n\npub fn is_idcok(w: WINDOW) -> bool\n{ unsafe { ll::is_idcok(w) == TRUE } }\n\n\npub fn is_idlok(w: WINDOW) -> bool\n{ unsafe { ll::is_idlok(w) == TRUE } }\n\n\npub fn is_immedok(w: WINDOW) -> bool\n{ unsafe { ll::is_immedok(w) == TRUE } }\n\n\npub fn is_keypad(w: WINDOW) -> bool\n{ unsafe { ll::is_keypad(w) == TRUE } }\n\n\npub fn is_leaveok(w: WINDOW) -> bool\n{ unsafe { ll::is_leaveok(w) == TRUE } }\n\n\npub fn is_nodelay(w: WINDOW) -> bool\n{ unsafe { ll::is_nodelay(w) == TRUE } }\n\n\npub fn is_notimeout(w: WINDOW) -> bool\n{ unsafe { ll::is_notimeout(w) == TRUE } }\n\n\npub fn is_scrollok(w: WINDOW) -> bool\n{ unsafe { ll::is_scrollok(w) == TRUE } }\n\n\npub fn is_syncok(w: WINDOW) -> bool\n{ unsafe { ll::is_syncok(w) == TRUE }}\n\n\npub fn keyname(c: i32) -> Option<String>\n{ unsafe { FromCStr::from_c_str(ll::keyname(c)) } }\n\n\npub fn keypad(w: WINDOW, bf: bool) -> i32\n{ unsafe { ll::keypad(w, bf as ll::c_bool) } }\n\n\npub fn killchar() -> char\n{ unsafe { char::from_u32(ll::killchar() as u32).expect(\"Invalid char\") } }\n\n\npub fn leaveok(w: WINDOW, bf: bool) -> i32\n{ unsafe { ll::leaveok(w, bf as ll::c_bool) } }\n\n\npub fn longname() -> String\n{ unsafe { FromCStr::from_c_str(ll::longname()) } }\n\n\npub fn meta(w: WINDOW, bf: bool) -> i32\n{ unsafe { ll::meta(w, bf as ll::c_bool) } }\n\n\npub fn mv(y: i32, x: i32) -> i32\n{ unsafe { ll::mv(y, x) } }\n\n\npub fn mvaddch(y: i32, x: i32, c: chtype) -> i32\n{ unsafe { ll::mvaddch(y, x, c) } }\n\n\npub fn mvaddchnstr(y: i32, x: i32, s: &[chtype], n: i32) -> i32\n{\n  if mv(y, x) == ERR\n  { return ERR; }\n  addchnstr(s, n)\n}\n\n\npub fn mvaddchstr(y: i32, x: i32, s: &[chtype]) -> i32\n{\n  if mv(y, x) == ERR\n  { return ERR; }\n  addchstr(s)\n}\n\n\npub fn mvaddnstr(y: i32, x: i32, s: &str, n: i32) -> i32\n{\n  if mv(y, x) == ERR\n  { return ERR; }\n  addnstr(s, n)\n}\n\n\npub fn mvaddstr(y: i32, x: i32, s: &str) -> i32\n{\n  if mv(y, x) == ERR\n  { return ERR; }\n  addstr(s)\n}\n\n\npub fn mvchgat(y: i32, x: i32, n: i32, attr: attr_t, color: i16) -> i32\n{ unsafe { ll::mvchgat(y, x, n, attr, color, ptr::null()) } }\n\n\npub fn mvcur(old_y: i32, old_x: i32, new_y: i32, new_x: i32) -> i32\n{ unsafe { ll::mvcur(old_y, old_x, new_y, new_x) } }\n\n\npub fn mvdelch(y: i32, x: i32) -> i32\n{ unsafe { ll::mvdelch(y, x) } }\n\n\npub fn mvderwin(w: WINDOW, y: i32, x: i32) -> i32\n{ unsafe { ll::mvderwin(w, y, x) } }\n\n\npub fn mvgetch(y: i32, x: i32) -> i32\n{ unsafe { ll::mvgetch(y, x) } }\n\n\npub fn mvgetnstr(y: i32, x: i32, s: &mut String, n: i32) -> i32\n{\n  match mv(y, x)\n  {\n    OK => getnstr(s, n),\n    _ => ERR,\n  }\n}\n\n\npub fn mvgetstr(y: i32, x: i32, s: &mut String) -> i32\n{\n  if mv(y, x) == ERR\n  { return ERR; }\n  getstr(s)\n}\n\n\npub fn mvhline(y: i32, x: i32, ch: chtype, n: i32) -> i32\n{ unsafe { ll::mvhline(y, x, ch, n) } }\n\n\npub fn mvinch(y: i32, x: i32) -> chtype\n{ unsafe { ll::mvinch(y, x) } }\n\n\npub fn mvinchnstr(y: i32, x: i32, s: &mut Vec<chtype>, n: i32) -> i32\n{\n  if mv(y, x) == ERR\n  { return ERR; }\n  inchnstr(s, n)\n}\n\n\npub fn mvinchstr(y: i32, x: i32, s: &mut Vec<chtype>) -> i32\n{\n  if mv(y, x) == ERR\n  { return ERR; }\n  inchstr(s)\n}\n\n\npub fn mvinnstr(y: i32, x: i32, s: &mut String, n: i32) -> i32\n{\n  if mv(y, x) == ERR\n  { return ERR; }\n  innstr(s, n)\n}\n\n\npub fn mvinsch(y: i32, x: i32, ch: chtype) -> i32\n{ unsafe { ll::mvinsch(y, x, ch) } }\n\n\npub fn mvinsnstr(y: i32, x: i32, s: &str, n: i32) -> i32\n{\n  if mv(y, x) == ERR\n  { return ERR; }\n  insnstr(s, n)\n}\n\n\npub fn mvinsstr(y: i32, x: i32, s: &str) -> i32\n{\n  if mv(y, x) == ERR\n  { return ERR; }\n  insstr(s)\n}\n\n\npub fn mvinstr(y: i32, x: i32, s: &mut String) -> i32\n{\n  if mv(y, x) == ERR\n  { return ERR; }\n  instr(s)\n}\n\n\npub fn mvprintw(y: i32, x: i32, s: &str) -> i32\n{\n  if mv(y, x) == ERR\n  { return ERR; }\n  printw(s)\n}\n\n\npub fn mvvline(y: i32, x: i32, ch: chtype, n: i32) -> i32\n{ unsafe { ll::mvvline(y, x, ch, n) } }\n\n\npub fn mvwaddch(w: WINDOW, y: i32, x: i32, ch: chtype) -> i32\n{ unsafe { ll::mvwaddch(w, y, x, ch) } }\n\n\npub fn mvwaddchnstr(w: WINDOW, y: i32, x: i32, s: &[chtype], n: i32) -> i32\n{ unsafe { ll::mvwaddchnstr(w, y, x, s.as_ptr(), n) } }\n\n\npub fn mvwaddchstr(w: WINDOW, y: i32, x: i32, s: &[chtype]) -> i32\n{ unsafe { ll::mvwaddchstr(w, y, x, s.as_ptr()) } }\n\n\npub fn mvwaddnstr(w: WINDOW, y: i32, x: i32, s: &str, n: i32) -> i32\n{ unsafe { ll::mvwaddnstr(w, y, x, s.to_c_str().as_ptr(), n) } }\n\n\npub fn mvwaddstr(w: WINDOW, y: i32, x: i32, s: &str) -> i32\n{ unsafe { ll::mvwaddstr(w, y, x, s.to_c_str().as_ptr()) } }\n\n\npub fn mvwchgat(w: WINDOW, y: i32, x: i32, n: i32, attr: attr_t, color: i16) -> i32\n{ unsafe { ll::mvwchgat(w, y, x, n, attr, color, ptr::null()) } }\n\n\npub fn mvwdelch(w: WINDOW, y: i32, x: i32) -> i32\n{ unsafe { ll::mvwdelch(w, y, x) } }\n\n\npub fn mvwgetch(w: WINDOW, y: i32, x: i32) -> i32\n{ unsafe { ll::mvwgetch(w, y, x) } }\n\n\npub fn mvwgetnstr(w: WINDOW, y: i32, x: i32, s: &mut String, n: i32) -> i32\n{\n  match wmove(w, y, x)\n  { \n    OK => wgetnstr(w, s, n), \n    _ => ERR,\n  }\n}\n\n\npub fn mvwgetstr(w: WINDOW, y: i32, x: i32, s: &mut String) -> i32\n{\n  if mv(y, x) == ERR\n  { return ERR; }\n\n  /* XXX: This is probably broken. */\n  let mut ch = wgetch(w);\n  while ch != '\\n' as i32 && ch != '\\r' as i32\n  {\n    unsafe { s.as_mut_vec().push(ch as u8); }\n    ch = wgetch(w);\n  }\n  OK\n}\n\n\npub fn mvwhline(w: WINDOW, y: i32, x: i32, ch: chtype, n: i32) -> i32\n{ unsafe { ll::mvwhline(w, y, x, ch, n) } }\n\n\npub fn mvwin(w: WINDOW, y: i32, x: i32) -> i32\n{ unsafe { ll::mvwin(w, y, x) } }\n\n\npub fn mvwinch(w: WINDOW, y: i32, x: i32) -> chtype\n{ unsafe { ll::mvwinch(w, y, x) } }\n\n\npub fn mvwinchnstr(w: WINDOW, y: i32, x: i32, s: &mut Vec<chtype>, n: i32) -> i32\n{\n  /* XXX: This is probably broken. */\n  s.clear();\n  s.reserve(n as usize);\n  unsafe\n  {\n    let ret = ll::mvwinchnstr(w, y, x, s.as_ptr(), n);\n\n    let capacity = s.capacity();\n    match s.iter().position(|x| *x == 0)\n    {\n      Some(index) => s.set_len(index as usize),\n      None => s.set_len(capacity),\n    }\n\n    ret\n  }\n}\n\n\npub fn mvwinchstr(w: WINDOW, y: i32, x: i32, s: &mut Vec<chtype>) -> i32\n{\n  /* XXX: This is probably broken. */\n  unsafe\n  {\n    let ret = ll::mvwinchstr(w, y, x, s.as_ptr());\n\n    let capacity = s.capacity();\n    match s.iter().position(|x| *x == 0)\n    {\n      Some(index) => s.set_len(index as usize),\n      None => s.set_len(capacity),\n    }\n\n    ret\n  }\n}\n\n\npub fn mvwinnstr(w: WINDOW, y: i32, x: i32, s: &mut String, n: i32) -> i32\n{\n  /* XXX: This is probably broken. */\n  unsafe\n  {\n    s.as_mut_vec().clear();\n    s.reserve(n as usize);\n    let buf = s.as_bytes().as_ptr();\n    let ret = ll::mvwinnstr(w, y, x, mem::transmute(buf), n);\n\n    let capacity = s.capacity();\n    match s.find('\\0')\n    {\n      Some(index) => s.as_mut_vec().set_len(index as usize),\n      None => s.as_mut_vec().set_len(capacity),\n    }\n\n    ret\n  }\n}\n\n\npub fn mvwinsch(w: WINDOW, y: i32, x: i32, ch: chtype) -> i32\n{ unsafe { ll::mvwinsch(w, y, x, ch) } }\n\n\npub fn mvwinsnstr(w: WINDOW, y: i32, x: i32, s: &str, n: i32) -> i32\n{ unsafe { ll::mvwinsnstr(w, y, x, s.to_c_str().as_ptr(), n) } }\n\n\npub fn mvwinsstr(w: WINDOW, y: i32, x: i32, s: &str) -> i32\n{ unsafe { ll::mvwinsstr(w, y, x, s.to_c_str().as_ptr()) } }\n\n\npub fn mvwinstr(w: WINDOW, y: i32, x: i32, s: &mut String) -> i32\n{\n  /* XXX: This is probably broken. */\n  unsafe\n  {\n    let buf = s.as_bytes().as_ptr();\n    let ret = ll::mvwinstr(w, y, x, mem::transmute(buf));\n\n    let capacity = s.capacity();\n    match s.find('\\0')\n    {\n      Some(index) => s.as_mut_vec().set_len(index as usize),\n      None => s.as_mut_vec().set_len(capacity),\n    }\n\n    ret\n  }\n}\n\n\npub fn mvwprintw(w: WINDOW, y: i32, x: i32, s: &str) -> i32\n{ unsafe { ll::mvwprintw(w, y, x, s.to_c_str().as_ptr()) } }\n\n\npub fn mvwvline(w: WINDOW, y: i32, x: i32, ch: chtype, n: i32) -> i32\n{ unsafe { ll::mvwvline(w, y, x, ch, n) } }\n\n\npub fn napms(ms: i32) -> i32\n{ unsafe { ll::napms(ms) } }\n\n\npub fn newpad(lines: i32, cols: i32) -> WINDOW\n{ unsafe { ll::newpad(lines, cols) } }\n\n\npub fn newterm(ty: Option<&str>, out_fd: FILE_p, in_fd: FILE_p) -> SCREEN\n{\n  unsafe\n  {\n    match ty {\n      Some(s) => ll::newterm(s.to_c_str().as_ptr(), out_fd, in_fd),\n      None    => ll::newterm(std::ptr::null(), out_fd, in_fd),\n    }\n  }\n}\n\n\npub fn newwin(lines: i32, cols: i32, y: i32, x: i32) -> WINDOW\n{ unsafe { ll::newwin(lines, cols, y, x) } }\n\n\npub fn nl() -> i32\n{ unsafe { ll::nl() } }\n\n\npub fn nocbreak() -> i32\n{ unsafe { ll::nocbreak() } }\n\n\npub fn nodelay(w: WINDOW, bf: bool) -> i32\n{ unsafe { ll::nodelay(w, bf as ll::c_bool) } }\n\n\npub fn noecho() -> i32\n{ unsafe { ll::noecho() } }\n\n\npub fn nonl() -> i32\n{ unsafe { ll::nonl() } }\n\n\npub fn noqiflush()\n{ unsafe { ll::noqiflush() } }\n\n\npub fn noraw() -> i32\n{ unsafe { ll::noraw() } }\n\n\npub fn notimeout(w: WINDOW, bf: bool) -> i32\n{ unsafe { ll::notimeout(w, bf as ll::c_bool) } }\n\n\npub fn overlay(src: WINDOW, dst: WINDOW) -> i32\n{ unsafe { ll::overlay(src, dst) } }\n\n\npub fn overwrite(src: WINDOW, dst: WINDOW) -> i32\n{ unsafe { ll::overwrite(src, dst) } }\n\n\npub fn pair_content(pair: i16, f: &mut i16, b: &mut i16) -> i32\n{ unsafe { ll::pair_content(pair, &mut*f as *mut i16, &mut*b as *mut i16) } }\n\n\npub fn PAIR_NUMBER(attr: i32) -> i32\n{ unsafe { ll::PAIR_NUMBER(attr) } }\n\n\npub fn pechochar(pad: WINDOW, ch: chtype) -> i32\n{ unsafe { ll::pechochar(pad, ch) } }\n\n\npub fn pnoutrefresh(pad: WINDOW, pmin_row: i32, pmin_col: i32, smin_row: i32, smin_col: i32, smax_row: i32, smax_col: i32) -> i32\n{ unsafe { ll::pnoutrefresh(pad, pmin_row, pmin_col, smin_row, smin_col, smax_row, smax_col) } }\n\n\npub fn prefresh(pad: WINDOW, pmin_row: i32, pmin_col: i32, smin_row: i32, smin_col: i32, smax_row: i32, smax_col: i32) -> i32\n{ unsafe { ll::prefresh(pad, pmin_row, pmin_col, smin_row, smin_col, smax_row, smax_col) } }\n\n\npub fn printw(s: &str) -> i32\n{ unsafe { ll::printw(s.to_c_str().as_ptr()) } }\n\n\npub fn putp(s: &str) -> i32\n{ unsafe { ll::putp(s.to_c_str().as_ptr()) } }\n\n\npub fn putwin(w: WINDOW, f: FILE_p) -> i32\n{ unsafe { ll::putwin(w, f) } }\n\n\npub fn qiflush()\n{ unsafe { ll::qiflush() } }\n\n\npub fn raw() -> i32\n{ unsafe { ll::raw() } }\n\n\npub fn redrawwin(w: WINDOW) -> i32\n{ unsafe { ll::redrawwin(w) } }\n\n\npub fn refresh() -> i32\n{ unsafe { ll::refresh() } }\n\n\npub fn resetty() -> i32\n{ unsafe { ll::resetty() } }\n\n\npub fn reset_prog_mode() -> i32\n{ unsafe { ll::reset_prog_mode() } }\n\n\npub fn reset_shell_mode() -> i32\n{ unsafe { ll::reset_shell_mode() } }\n\n\npub fn resizeterm(lines: i32, cols: i32) -> i32\n{ unsafe { ll::resizeterm(lines, cols) } }\n\n\npub fn resize_term(lines: i32, cols: i32) -> i32\n{ unsafe { ll::resize_term(lines, cols) } }\n\n\npub fn savetty() -> i32\n{ unsafe { ll::savetty() } }\n\n\npub fn scr_dump(filename: &str) -> i32\n{ unsafe { ll::scr_dump(filename.to_c_str().as_ptr()) } }\n\n\npub fn scr_init(filename: &str) -> i32\n{ unsafe { ll::scr_init(filename.to_c_str().as_ptr()) } }\n\n\npub fn scrl(n: i32) -> i32\n{ unsafe { ll::scrl(n) } }\n\n\npub fn scroll(w: WINDOW) -> i32\n{ unsafe { ll::scroll(w) } }\n\n\npub fn scrollok(w: WINDOW, bf: bool) -> i32\n{ unsafe { ll::scrollok(w, bf as ll::c_bool) } }\n\n\npub fn scr_restore(filename: &str) -> i32\n{ unsafe { ll::scr_restore(filename.to_c_str().as_ptr()) } }\n\n\npub fn scr_set(filename: &str) -> i32\n{ unsafe { ll::scr_set(filename.to_c_str().as_ptr()) } }\n\npub fn setlocale(lc: LcCategory, locale: &str) -> String\n{\n  unsafe {\n    let buf = locale.to_c_str().as_ptr();\n    let ret = ll::setlocale(lc as libc::c_int, buf);\n    if ret == ptr::null() {\n        String::new()\n    } else {\n        // The clone is necessary, as the returned pointer\n        // can change at any time\n        CStr::from_ptr(ret).to_string_lossy().into_owned()\n    }\n  }\n}\n\npub fn setscrreg(top: i32, bot: i32) -> i32\n{ unsafe { ll::setscrreg(top, bot) } }\n\n\npub fn set_term(s: SCREEN) -> SCREEN\n{ unsafe { ll::set_term(s) } }\n\npub fn set_escdelay(size: i32) -> i32\n{ unsafe { ll::set_escdelay(size) } }\n\npub fn set_tabsize(size: i32) -> i32\n{ unsafe { ll::set_tabsize(size) } }\n\npub fn slk_attroff(ch: chtype) -> i32\n{ unsafe { ll::slk_attroff(ch) } }\n\n//\n//pub fn slk_attr_off(ch: attr_t) -> i32\n//{ unsafe { ll::slk_attr_off(ch, ptr::null()) } }\n\n\npub fn slk_attron(ch: chtype) -> i32\n{ unsafe { ll::slk_attron(ch) } }\n\n//\n//pub fn slk_attr_on(ch: attr_t) -> i32\n//{ unsafe { ll::slk_attr_on(ch, ptr::null()) } }\n\n\npub fn slk_attrset(ch: chtype) -> i32\n{ unsafe { ll::slk_attrset(ch) } }\n\n\npub fn slk_attr() -> attr_t\n{ unsafe { ll::slk_attr() } }\n\n\npub fn slk_attr_set(attrs: attr_t, pair: i16) -> i32\n{ unsafe { ll::slk_attr_set(attrs, pair, ptr::null()) } }\n\n\npub fn slk_clear() -> i32\n{ unsafe { ll::slk_clear() } }\n\n\npub fn slk_color(pair: i16) -> i32\n{ unsafe { ll::slk_color(pair) } }\n\n\npub fn slk_init(fmt: i32) -> i32\n{ unsafe { ll::slk_init(fmt) } }\n\n\npub fn slk_label(n: i32) -> String\n{ unsafe { FromCStr::from_c_str(ll::slk_label(n)) } }\n\n\npub fn slk_noutrefresh() -> i32\n{ unsafe { ll::slk_noutrefresh() } }\n\n\npub fn slk_refresh() -> i32\n{ unsafe { ll::slk_refresh() } }\n\n\npub fn slk_restore() -> i32\n{ unsafe { ll::slk_restore() } }\n\n\npub fn slk_set(n: i32, s: &str, fmt: i32) -> i32\n{ unsafe { ll::slk_set(n, s.to_c_str().as_ptr(), fmt) } }\n\n\npub fn slk_touch() -> i32\n{ unsafe { ll::slk_touch() }}\n\n\npub fn standout() -> i32\n{ unsafe { ll::standout() } }\n\n\npub fn standend() -> i32\n{ unsafe { ll::standend() } }\n\n\npub fn start_color() -> i32\n{ unsafe { ll::start_color() } }\n\n\npub fn subpad(w: WINDOW, lines: i32, cols: i32, y: i32, x: i32) -> WINDOW\n{ unsafe { ll::subpad(w, lines, cols, y, x) } }\n\n\npub fn subwin(w: WINDOW, lines: i32, cols: i32, y: i32, x: i32) -> WINDOW\n{ unsafe { ll::subwin(w, lines, cols, y, x) } }\n\n\npub fn syncok(w: WINDOW, bf: bool) -> i32\n{ unsafe { ll::syncok(w, bf as ll::c_bool) } }\n\n\npub fn termattrs() -> chtype\n{ unsafe { ll::termattrs() } }\n\n\npub fn termname() -> String\n{ unsafe { FromCStr::from_c_str(ll::termname()) } }\n\n\npub fn timeout(delay: i32)\n{ unsafe { ll::timeout(delay) } }\n\n\npub fn touchline(w: WINDOW, start: i32, count: i32) -> i32\n{ unsafe { ll::touchline(w, start, count) } }\n\n\npub fn touchwin(w: WINDOW) -> i32\n{ unsafe { ll::touchwin(w) } }\n\n\npub fn typeahead(fd: i32) -> i32\n{ unsafe { ll::typeahead(fd) } }\n\n\npub fn tigetflag(capname: &str) -> i32\n{ unsafe { ll::tigetflag(capname.to_c_str().as_ptr()) } }\n\n\npub fn tigetnum(capname: &str) -> i32\n{ unsafe { ll::tigetnum(capname.to_c_str().as_ptr()) } }\n\n\npub fn tigetstr(capname: &str) -> String\n{ unsafe { { FromCStr::from_c_str(ll::tigetstr(capname.to_c_str().as_ptr())) } } }\n\n\npub fn tparm(s: &str) -> String\n{ unsafe { { FromCStr::from_c_str(ll::tparm(s.to_c_str().as_ptr())) } } }\n\n\npub fn ungetch(ch: i32) -> i32\n{ unsafe { ll::ungetch(ch) } }\n\n\npub fn untouchwin(w: WINDOW) -> i32\n{ unsafe { ll::untouchwin(w) } }\n\n\npub fn use_env(f: bool)\n{ unsafe { ll::use_env(f as ll::c_bool) } }\n\n\npub fn use_default_colors() -> i32\n{ unsafe { ll::use_default_colors() } }\n\n\npub fn vidattr(attrs: chtype) -> i32\n{ unsafe { ll::vidattr(attrs) } }\n\n\npub fn vline(ch: chtype, n: i32) -> i32\n{ unsafe { ll::vline(ch, n) } }\n\n\npub fn waddch(w: WINDOW, ch: chtype) -> i32\n{ unsafe { ll::waddch(w, ch) } }\n\n\npub fn waddchnstr(w: WINDOW, s: &[chtype], n: i32) -> i32\n{ unsafe { ll::waddchnstr(w, s.as_ptr(), n) } }\n\n\npub fn waddchstr(w: WINDOW, s: &[chtype]) -> i32\n{ unsafe { ll::waddchstr(w, s.as_ptr()) } }\n\n\npub fn waddnstr(w: WINDOW, s: &str, n: i32) -> i32\n{ unsafe { ll::waddnstr(w, s.to_c_str().as_ptr(), n) } }\n\n\npub fn waddstr(w: WINDOW, s: &str) -> i32\n{ unsafe { ll::waddstr(w, s.to_c_str().as_ptr()) } }\n\n\npub fn wattron(w: WINDOW, attr: NCURSES_ATTR_T) -> i32\n{ unsafe { ll::wattron(w, attr) } }\n\n\npub fn wattroff(w: WINDOW, attr: NCURSES_ATTR_T) -> i32\n{ unsafe { ll::wattroff(w, attr) } }\n\n\npub fn wattrset(w: WINDOW, attr: NCURSES_ATTR_T) -> i32\n{ unsafe { ll::wattrset(w, attr) } }\n\n\npub fn wattr_get(w: WINDOW, attrs: &mut attr_t, pair: &mut i16) -> i32\n{ unsafe { ll::wattr_get(w, &mut*attrs as *mut attr_t, &mut*pair as *mut i16, ptr::null()) } }\n\n\npub fn wattr_on(w: WINDOW, attr: attr_t) -> i32\n{ unsafe { ll::wattr_on(w, attr, ptr::null()) } }\n\n\npub fn wattr_off(w: WINDOW, attr: attr_t) -> i32\n{ unsafe { ll::wattr_off(w, attr, ptr::null()) } }\n\n\npub fn wattr_set(w: WINDOW, attrs: attr_t, pair: i16) -> i32\n{ unsafe { ll::wattr_set(w, attrs, pair, ptr::null()) } }\n\n\npub fn wbkgd(w: WINDOW, ch: chtype) -> i32\n{ unsafe { ll::wbkgd(w, ch) } }\n\n\npub fn wbkgdset(w: WINDOW, ch: chtype)\n{ unsafe { ll::wbkgdset(w, ch) } }\n\n\npub fn wborder(w: WINDOW, ls: chtype, rs: chtype, ts: chtype, bs: chtype, tl: chtype, tr: chtype, bl: chtype, br: chtype) -> i32\n{ unsafe { ll::wborder(w, ls, rs, ts, bs, tl, tr, bl, br) } }\n\n\npub fn wchgat(w: WINDOW, n: i32, attr: attr_t, color: i16) -> i32\n{ unsafe { ll::wchgat(w, n, attr, color, ptr::null()) } }\n\n\npub fn wclear(w: WINDOW) -> i32\n{ unsafe { ll::wclear(w) } }\n\n\npub fn wclrtobot(w: WINDOW) -> i32\n{ unsafe { ll::wclrtobot(w) } }\n\n\npub fn wclrtoeol(w: WINDOW) -> i32\n{ unsafe { ll::wclrtoeol(w) } }\n\n\npub fn wcolor_set(w: WINDOW, pair: i16) -> i32\n{ unsafe { ll::wcolor_set(w, pair, ptr::null()) } }\n\n\npub fn wcursyncup(w: WINDOW)\n{ unsafe { ll::wcursyncup(w) } }\n\n\npub fn wdelch(w: WINDOW) -> i32\n{ unsafe { ll::wdelch(w) } }\n\n\npub fn wdeleteln(w: WINDOW) -> i32\n{ unsafe { ll::wdeleteln(w) } }\n\n\npub fn wechochar(w: WINDOW, ch: chtype) -> i32\n{ unsafe { ll::wechochar(w, ch) } }\n\n\npub fn werase(w: WINDOW) -> i32\n{ unsafe { ll::werase(w) } }\n\n\npub fn wgetch(w: WINDOW) -> i32\n{ unsafe { ll::wgetch(w) } }\n\n\npub fn wgetnstr(w: WINDOW, s: &mut String, n: i32) -> i32\n{\n  let mut buff: Vec<u8> = Vec::with_capacity(n as usize);\n  unsafe { buff.set_len(n as usize); }\n  \n  match unsafe { ll::wgetnstr(w, buff.as_ptr(), n) }\n  {\n    OK => {\n      *s = buff.iter()\n        .take_while(|ch| **ch != '\\0' as u8 )\n        .map(|ch| *ch as char )\n        .collect();\n\n      OK\n    },\n\n    _ => ERR,\n  }\n}\n\n\npub fn wgetstr(w: WINDOW, s: &mut String) -> i32\n{\n  /* XXX: This is probably broken. */\n  let mut ch = wgetch(w);\n  while ch != '\\n' as i32 && ch != '\\r' as i32\n  {\n    unsafe { s.as_mut_vec().push(ch as u8); }\n    ch = wgetch(w);\n  }\n  OK\n}\n\n\npub fn whline(w: WINDOW, ch: chtype, n: i32) -> i32\n{ unsafe { ll::whline(w, ch, n) } }\n\n\npub fn winch(w: WINDOW) -> chtype\n{ unsafe { ll::winch(w) } }\n\n\npub fn winchnstr(w: WINDOW, s: &mut Vec<chtype>, n: i32) -> i32\n{\n  /* XXX: This is probably broken. */\n  s.clear();\n  s.reserve(n as usize);\n  unsafe\n  {\n    let ret = ll::winchnstr(w, s.as_ptr(), n);\n\n    let capacity = s.capacity();\n    match s.iter().position(|x| *x == 0)\n    {\n      Some(index) => s.set_len(index as usize),\n      None => s.set_len(capacity),\n    }\n\n    ret\n  }\n}\n\n\npub fn winchstr(w: WINDOW, s: &mut Vec<chtype>) -> i32\n{\n  /* XXX: This is probably broken. */\n  unsafe\n  {\n    let ret = ll::winchstr(w, s.as_ptr());\n\n    let capacity = s.capacity();\n    match s.iter().position(|x| *x == 0)\n    {\n      Some(index) => s.set_len(index as usize),\n      None => s.set_len(capacity),\n    }\n\n    ret\n  }\n}\n\n\npub fn winnstr(w: WINDOW, s: &mut String, n: i32) -> i32\n{\n  /* XXX: This is probably broken. */\n  unsafe\n  {\n    s.as_mut_vec().clear();\n    s.reserve(n as usize);\n    let buf = s.as_bytes().as_ptr();\n    let ret = ll::winnstr(w, mem::transmute(buf), n);\n\n    let capacity = s.capacity();\n    match s.find('\\0')\n    {\n      Some(index) => s.as_mut_vec().set_len(index as usize),\n      None => s.as_mut_vec().set_len(capacity),\n    }\n\n    ret\n  }\n}\n\n\npub fn winsch(w: WINDOW, ch: chtype) -> i32\n{ unsafe { ll::winsch(w, ch) } }\n\n\npub fn winsdelln(w: WINDOW, n: i32) -> i32\n{ unsafe { ll::winsdelln(w, n) } }\n\n\npub fn winsertln(w: WINDOW) -> i32\n{ unsafe { ll::winsertln(w) } }\n\n\npub fn winsnstr(w: WINDOW, s: &str, n: i32) -> i32\n{\n  unsafe\n  {\n    let buf = s.as_ptr();\n    ll::winsnstr(w, mem::transmute(buf), n)\n  }\n}\n\n\npub fn winsstr(w: WINDOW, s: &str) -> i32\n{\n  unsafe\n  {\n    let buf = s.as_ptr();\n    ll::winsstr(w, mem::transmute(buf))\n  }\n}\n\n\npub fn winstr(w: WINDOW, s: &mut String) -> i32\n{\n  /* XXX: This is probably broken. */\n  unsafe\n  {\n    let buf = s.as_bytes().as_ptr();\n    let ret = ll::winstr(w, mem::transmute(buf));\n\n    let capacity = s.capacity();\n    match s.find('\\0')\n    {\n      Some(index) => s.as_mut_vec().set_len(index as usize),\n      None => s.as_mut_vec().set_len(capacity),\n    }\n\n    ret\n  }\n}\n\n\npub fn wmove(w: WINDOW, y: i32, x: i32) -> i32\n{ unsafe { ll::wmove(w, y, x) } }\n\n\npub fn wnoutrefresh(w: WINDOW) -> i32\n{ unsafe { ll::wnoutrefresh(w) } }\n\n\npub fn wprintw(w: WINDOW, s: &str) -> i32\n{ unsafe { ll::wprintw(w, s.to_c_str().as_ptr()) } }\n\n\npub fn wredrawln(w: WINDOW, start: i32, n: i32) -> i32\n{ unsafe { ll::wredrawln(w, start, n) } }\n\n\npub fn wrefresh(w: WINDOW) -> i32\n{ unsafe { ll::wrefresh(w) } }\n\n\npub fn wresize(w: WINDOW, lines: i32, cols: i32) -> i32\n{ unsafe { ll::wresize(w, lines, cols) } }\n\n\npub fn wscrl(w: WINDOW, n: i32) -> i32\n{ unsafe { ll::wscrl(w, n) } }\n\n\npub fn wsetscrreg(w: WINDOW, top: i32, bot: i32) -> i32\n{ unsafe { ll::wsetscrreg(w, top, bot) } }\n\n\npub fn wstandout(w: WINDOW) -> i32\n{ unsafe { ll::wstandout(w) } }\n\n\npub fn wstandend(w: WINDOW) -> i32\n{ unsafe { ll::wstandend(w) } }\n\n\npub fn wsyncdown(w: WINDOW)\n{ unsafe { ll::wsyncdown(w) } }\n\n\npub fn wsyncup(w: WINDOW)\n{ unsafe { ll::wsyncup(w) } }\n\n\npub fn wtimeout(w: WINDOW, delay: i32)\n{ unsafe { ll::wtimeout(w, delay) } }\n\n\npub fn wtouchln(w: WINDOW, y: i32, n: i32, changed: i32) -> i32\n{ unsafe { ll::wtouchln(w, y, n, changed) } }\n\n\npub fn wvline(w: WINDOW, ch: chtype, n: i32) -> i32\n{ unsafe { ll::wvline(w, ch, n) } }\n\n\npub fn wgetparent(w: WINDOW) -> WINDOW\n{ unsafe { ll::wgetparent(w) } }\n\n\npub fn wgetscrreg(w: WINDOW, top: &mut i32, bot: &mut i32) -> i32\n{ unsafe { ll::wgetscrreg(w, &mut*top as *mut i32, &mut*bot as *mut i32) } }\n\n/* Attributes */\npub fn NCURSES_BITS(mask: u32, shift: u32) -> u32\n{ mask << (shift + NCURSES_ATTR_SHIFT) as usize }\n\npub fn A_NORMAL() -> attr_t\n{ (1u32 - 1u32) as attr_t }\n\npub fn A_ATTRIBUTES() -> attr_t\n{ NCURSES_BITS(!(1u32 - 1u32), 0u32) as attr_t }\n\npub fn A_CHARTEXT() -> attr_t\n{(NCURSES_BITS(1u32, 0u32) - 1u32) as attr_t }\n\npub fn A_COLOR() -> attr_t\n{ NCURSES_BITS(((1u32) << 8) - 1u32, 0u32) as attr_t }\n\npub fn A_STANDOUT() -> attr_t\n{ NCURSES_BITS(1u32, 8u32) as attr_t }\n\npub fn A_UNDERLINE() -> attr_t\n{ NCURSES_BITS(1u32, 9u32) as attr_t }\n\npub fn A_REVERSE() -> attr_t\n{ NCURSES_BITS(1u32, 10u32) as attr_t }\n\npub fn A_BLINK() -> attr_t\n{ NCURSES_BITS(1u32, 11u32) as attr_t }\n\npub fn A_DIM() -> attr_t\n{ NCURSES_BITS(1u32, 12u32) as attr_t }\n\npub fn A_BOLD() -> attr_t\n{ NCURSES_BITS(1u32, 13u32) as attr_t }\n\npub fn A_ALTCHARSET() -> attr_t\n{ NCURSES_BITS(1u32, 14u32) as attr_t }\n\npub fn A_INVIS() -> attr_t\n{ NCURSES_BITS(1u32, 15u32) as attr_t }\n\npub fn A_PROTECT() -> attr_t\n{ NCURSES_BITS(1u32, 16u32) as attr_t }\n\npub fn A_HORIZONTAL() -> attr_t\n{ NCURSES_BITS(1u32, 17u32) as attr_t }\n\npub fn A_LEFT() -> attr_t\n{ NCURSES_BITS(1u32, 18u32) as attr_t }\n\npub fn A_LOW() -> attr_t\n{ NCURSES_BITS(1u32, 19u32) as attr_t }\n\npub fn A_RIGHT() -> attr_t\n{ NCURSES_BITS(1u32, 20u32) as attr_t }\n\npub fn A_TOP() -> attr_t\n{ NCURSES_BITS(1u32, 21u32) as attr_t }\n\npub fn A_VERTICAL() -> attr_t\n{ NCURSES_BITS(1u32, 22u32) as attr_t }\n\npub fn A_ITALIC() -> attr_t\n{ NCURSES_BITS(1u32, 23u32) as attr_t }\n\n/* Colors. */\npub fn COLOR_PAIR(n: i16) -> attr_t\n{ NCURSES_BITS(n as u32, 0u32) as attr_t }\n\n/*\n * Most of the pseudo functions are macros that either provide compatibility\n * with older versions of curses, or provide inline functionality to improve\n * performance.\n */\n\npub fn getyx(win: WINDOW, y: &mut i32, x: &mut i32)\n{ unsafe { *y = ll::getcury(win); *x = ll::getcurx(win); } }\n\n\npub fn getbegyx(win: WINDOW, y: &mut i32, x: &mut i32)\n{ unsafe { *y = ll::getbegy(win); *x = ll::getbegx(win) } }\n\n\npub fn getmaxyx(win: WINDOW, y: &mut i32, x: &mut i32)\n{ unsafe { *y = ll::getmaxy(win); *x = ll::getmaxx(win) } }\n\n\npub fn getparyx(win: WINDOW, y: &mut i32, x: &mut i32)\n{ unsafe { *y = ll::getpary(win); *x = ll::getparx(win) } }\n\n\npub fn getsyx(y: &mut i32, x: &mut i32)\n{\n  unsafe\n  {\n    if newscr() != ptr::null_mut()\n    {\n      if ll::is_leaveok(newscr()) == TRUE\n      {\n        *x = -1 as i32;\n        *y = -1 as i32;\n      }\n      else\n      { getyx(newscr(), y, x); }\n    }\n  }\n}\n\n\npub fn setsyx(y: &mut i32, x: &mut i32)\n{\n  unsafe\n  {\n    if newscr() !=(0 as WINDOW)\n    {\n      if *y == -1 && *x == -1\n      {\n        ll::leaveok(newscr(), 1);\n      }\n      else\n      {\n        ll::leaveok(newscr(), 0);\n        ll::wmove(newscr(), *y, *x);\n      }\n    }\n  }\n}\n\n/* Line graphics */\npub fn NCURSES_ACS(c: char) -> chtype {\n    unsafe { *acs_map().offset((c as libc::c_uchar) as isize) as chtype }\n}\n\n/* VT100 symbols begin here */\npub fn ACS_ULCORNER() -> chtype\n{ NCURSES_ACS('l') } /* upper left corner */\n\npub fn ACS_LLCORNER() -> chtype\n{ NCURSES_ACS('m') } /* lower left corner */\n\npub fn ACS_URCORNER() -> chtype\n{ NCURSES_ACS('k') } /* upper right corner */\n\npub fn ACS_LRCORNER() -> chtype\n{ NCURSES_ACS('j') } /* lower right corner */\n\npub fn ACS_LTEE() -> chtype\n{ NCURSES_ACS('t') } /* tee pointing right */\n\npub fn ACS_RTEE() -> chtype\n{ NCURSES_ACS('u') } /* tee pointing left */\n\npub fn ACS_BTEE() -> chtype\n{ NCURSES_ACS('v') } /* tee pointing up */\n\npub fn ACS_TTEE() -> chtype\n{ NCURSES_ACS('w') } /* tee pointing down */\n\npub fn ACS_HLINE() -> chtype\n{ NCURSES_ACS('q') } /* horizontal line */\n\npub fn ACS_VLINE() -> chtype\n{ NCURSES_ACS('x') } /* vertical line */\n\npub fn ACS_PLUS() -> chtype\n{ NCURSES_ACS('n') } /* large plus or crossover */\n\npub fn ACS_S1() -> chtype\n{ NCURSES_ACS('o') } /* scan line 1 */\n\npub fn ACS_S9() -> chtype\n{ NCURSES_ACS('s') } /* scan line 9 */\n\npub fn ACS_DIAMOND() -> chtype\n{ NCURSES_ACS('`') } /* diamond */\n\npub fn ACS_CKBOARD() -> chtype\n{ NCURSES_ACS('a') } /* checker board(stipple) */\n\npub fn ACS_DEGREE() -> chtype\n{ NCURSES_ACS('f') } /* degree symbol */\n\npub fn ACS_PLMINUS() -> chtype\n{ NCURSES_ACS('g') } /* plus/minus */\n\npub fn ACS_BULLET() -> chtype\n{ NCURSES_ACS('~') } /* bullet */\n\n/* Teletype 5410v1 symbols begin here */\npub fn ACS_LARROW() -> chtype\n{ NCURSES_ACS(',') } /* arrow pointing left */\n\npub fn ACS_RARROW() -> chtype\n{ NCURSES_ACS('+') } /* arrow pointing right */\n\npub fn ACS_DARROW() -> chtype\n{ NCURSES_ACS('.') } /* arrow pointing down */\n\npub fn ACS_UARROW() -> chtype\n{ NCURSES_ACS('-') } /* arrow pointing up */\n\npub fn ACS_BOARD() -> chtype\n{ NCURSES_ACS('h') } /* board of squares */\n\npub fn ACS_LANTERN() -> chtype\n{ NCURSES_ACS('i') } /* lantern symbol */\n\npub fn ACS_BLOCK() -> chtype\n{ NCURSES_ACS('0') } /* solid square block */\n\n/*\n * These aren't documented, but a lot of System Vs have them anyway\n * (you can spot pprryyzz{{||}} in a lot of AT&T terminfo strings).\n * The ACS_names may not match AT&T's, our source didn't know them.\n */\npub fn ACS_S3() -> chtype\n{ NCURSES_ACS('p') } /* scan line 3 */\n\npub fn ACS_S7() -> chtype\n{ NCURSES_ACS('r') } /* scan line 7 */\n\npub fn ACS_LEQUAL() -> chtype\n{ NCURSES_ACS('y') } /* less/equal */\n\npub fn ACS_GEQUAL() -> chtype\n{ NCURSES_ACS('z') } /* greater/equal */\n\npub fn ACS_PI() -> chtype\n{ NCURSES_ACS('{') } /* Pi */\n\npub fn ACS_NEQUAL() -> chtype\n{ NCURSES_ACS('|') } /* not equal */\n\npub fn ACS_STERLING() -> chtype\n{ NCURSES_ACS('}') } /* UK pound sign */\n\n/*\n * Line drawing ACS names are of the form ACS_trbl, where t is the top, r\n * is the right, b is the bottom, and l is the left. t, r, b, and l might\n * be B(blank), S(single), D(double), or T(thick). The subset defined\n * here only uses B and S.\n */\npub fn ACS_BSSB() -> chtype\n{ ACS_ULCORNER() }\n\npub fn ACS_SSBB() -> chtype\n{ ACS_LLCORNER() }\n\npub fn ACS_BBSS() -> chtype\n{ ACS_URCORNER() }\n\npub fn ACS_SBBS() -> chtype\n{ ACS_LRCORNER() }\n\npub fn ACS_SBSS() -> chtype\n{ ACS_RTEE() }\n\npub fn ACS_SSSB() -> chtype\n{ ACS_LTEE() }\n\npub fn ACS_SSBS() -> chtype\n{ ACS_BTEE() }\n\npub fn ACS_BSSS() -> chtype\n{ ACS_TTEE() }\n\npub fn ACS_BSBS() -> chtype\n{ ACS_HLINE() }\n\npub fn ACS_SBSB() -> chtype\n{ ACS_VLINE() }\n\npub fn ACS_SSSS() -> chtype\n{ ACS_PLUS() }\n\npub fn KEY_F(n: u8) -> i32\n{\n  assert!(n < 16);\n  KEY_F0 + n as i32\n}\n\n/*\n * Added mouse support\n */\n\npub fn has_mouse() -> bool\n{ unsafe { ll::has_mouse() == TRUE } }\n\npub fn getmouse(event: *mut MEVENT) -> i32\n{ unsafe { ll::getmouse(event) } }\n\npub fn ungetmouse(event: *mut MEVENT) -> i32\n{ unsafe { ll::ungetmouse(event) } }\n\npub fn mouseinterval(n: i32) -> i32\n{ unsafe { ll::mouseinterval(n) } }\n\npub fn mousemask(newmask: mmask_t, oldmask: Option<&mut mmask_t>) -> mmask_t\n{\n    if oldmask.is_none() { unsafe { ll::mousemask(newmask, ptr::null_mut()) } }\n    else { unsafe { ll::mousemask(newmask, oldmask.unwrap()) } }\n}\n\npub fn wenclose(w: WINDOW, y: i32, x: i32) -> bool\n{ unsafe { ll::wenclose(w, y as libc::c_int, x as libc::c_int) == TRUE } }\n\npub fn wmouse_trafo(w: WINDOW, y: &mut[i32], x: &mut[i32], to_screen: bool) -> bool\n{ unsafe { ll::wmouse_trafo(w, y.as_mut_ptr(), x.as_mut_ptr(), to_screen as ll::c_bool) == TRUE } }\n\npub fn mouse_trafo(y: &mut[i32], x: &mut[i32], to_screen: bool) -> bool\n{ unsafe { ll::mouse_trafo(y.as_mut_ptr(), x.as_mut_ptr(), to_screen as ll::c_bool) == TRUE } }\n\n#[cfg(feature = \"extended_colors\")]\npub fn init_extended_color(color: i32, r: i32, g: i32, b: i32) -> i32 {\n    unsafe { ll::init_extended_color(color, r, g, b) }\n}\n\n#[cfg(feature = \"extended_colors\")]\npub fn init_extended_pair(color: i32, f: i32, b: i32) -> i32 {\n    unsafe { ll::init_extended_pair(color, f, b) }\n}\n\n#[cfg(feature = \"extended_colors\")]\npub fn extended_color_content(color: i32, r: &mut i32, g: &mut i32, b: &mut i32) -> i32 {\n    unsafe { ll::extended_color_content(color, r, g, b) }\n}\n\n#[cfg(feature = \"extended_colors\")]\npub fn extended_pair_content(pair: i32, f: &mut i32, b: &mut i32) -> i32 {\n    unsafe { ll::extended_pair_content(pair, f, b) }\n}\n"
  },
  {
    "project": "ncurses-rs",
    "target": 1,
    "commit_id": "e093c2b7b6ecbf34f8afbd87ee111df256957e41",
    "func": "/*\n    Copyright \u00a9 2013 Free Software Foundation, Inc\n    See licensing in LICENSE file\n\n    File: lib.rs\n    Author: Jesse 'Jeaye' Wilkerson\n    Description:\n      Safe wrappers for ncurses functions.\n*/\n\n#![allow(non_camel_case_types)]\n#![allow(non_snake_case)]\n#![warn(missing_debug_implementations)]\n\nextern crate libc;\n\nuse std::mem;\nuse std::{ char, ptr };\nuse std::ffi::{CString, CStr};\nuse self::ll::{FILE_p};\npub use self::constants::*;\npub use self::panel::wrapper::*;\npub use self::menu::wrapper::*;\npub use self::menu::constants::*;\n\npub type chtype = self::ll::chtype;\npub type winttype = u32;\n\npub type mmask_t = chtype;\npub type attr_t = chtype;\npub type NCURSES_ATTR_T = attr_t;\n\npub mod ll;\npub mod constants;\npub mod panel;\npub mod menu;\n\ntrait FromCStr {\n    unsafe fn from_c_str(s: *const libc::c_char) -> Self;\n}\n\nimpl FromCStr for String {\n    unsafe fn from_c_str(s: *const libc::c_char) -> String {\n        let bytes = CStr::from_ptr(s).to_bytes();\n        String::from_utf8_unchecked(bytes.to_vec())\n    }\n}\n\nimpl FromCStr for Option<String> {\n    unsafe fn from_c_str(s: *const libc::c_char) -> Option<String> {\n        if s.is_null() {\n            None\n        } else {\n            Some(FromCStr::from_c_str(s))\n        }\n    }\n}\n\ntrait ToCStr {\n    fn to_c_str(&self) -> CString;\n}\n\nimpl <'a>ToCStr for &'a str {\n    fn to_c_str(&self) -> CString {\n        CString::new(*self).unwrap()\n    }\n}\n\n#[derive(Debug, Clone, Copy)]\npub enum CURSOR_VISIBILITY\n{\n  CURSOR_INVISIBLE = 0,\n  CURSOR_VISIBLE,\n  CURSOR_VERY_VISIBLE\n}\n\npub type WINDOW = self::ll::WINDOW;\npub type SCREEN = self::ll::SCREEN;\npub type mmaskt = self::ll::mmask_t;\npub type MEVENT = self::ll::MEVENT;\n\npub fn addch(ch: chtype) -> i32\n{ unsafe { ll::addch(ch) } }\n\n\npub fn addchnstr(s: &[chtype], n: i32) -> i32\n{ unsafe { ll::addchnstr(s.as_ptr(), n) } }\n\n\npub fn addchstr(s: &[chtype]) -> i32\n{ unsafe { ll::addchstr(s.as_ptr()) } }\n\n\npub fn addnstr(s: &str, n: i32) -> i32\n{ unsafe { ll::addnstr(s.to_c_str().as_ptr(), n) } }\n\n\npub fn addstr(s: &str) -> i32\n{ unsafe { ll::addstr(s.to_c_str().as_ptr()) } }\n\n\npub fn assume_default_colors(fg: i32, bg: i32) -> i32\n{ unsafe { ll::assume_default_colors(fg, bg) } }\n\n\npub fn attroff(a: NCURSES_ATTR_T) -> i32\n{ unsafe { ll::attroff(a) } }\n\n\npub fn attron(a: NCURSES_ATTR_T) -> i32\n{ unsafe { ll::attron(a) } }\n\n\npub fn attrset(a: NCURSES_ATTR_T) -> i32\n{ unsafe { ll::attrset(a) } }\n\n\npub fn attr_get(attrs: &mut attr_t, pair: &mut i16) -> i32\n{\n  unsafe\n  {\n    ll::attr_get(&mut* attrs as *mut attr_t,\n                 &mut* pair as *mut i16,\n                 ptr::null())\n  }\n}\n\n\npub fn attr_off(a: attr_t) -> i32\n{ unsafe { ll::attr_off(a, ptr::null()) } }\n\n\npub fn attr_on(a: attr_t) -> i32\n{ unsafe { ll::attr_on(a, ptr::null()) } }\n\n\npub fn attr_set(attr: attr_t, pair: i16) -> i32\n{ unsafe { ll::attr_set(attr, pair, ptr::null()) } }\n\n\npub fn baudrate() -> i32\n{ unsafe { ll::baudrate() } }\n\n\npub fn beep() -> i32\n{ unsafe { ll::beep() } }\n\n\npub fn bkgd(ch: chtype) -> i32\n{ unsafe { ll::bkgd(ch) } }\n\n\npub fn bkgdset(ch: chtype)\n{ unsafe { ll::bkgdset(ch) } }\n\n\npub fn border(ls: chtype, rs: chtype, ts: chtype, bs: chtype, tl: chtype, tr: chtype, bl: chtype, br: chtype) -> i32\n{ unsafe { ll::border(ls, rs, ts, bs, tl, tr, bl, br) } }\n\n\n#[link_name=\"box\"] pub fn box_(w: WINDOW, v: chtype, h: chtype) -> i32\n{ wborder(w, v, v, h, h, 0, 0, 0, 0) }\n\n\npub fn can_change_color() -> bool\n{ unsafe { ll::can_change_color() == TRUE } }\n\n\npub fn cbreak() -> i32\n{ unsafe { ll::cbreak() } }\n\n\npub fn chgat(n: i32, attr: attr_t, color: i16) -> i32\n{ unsafe { ll::chgat(n, attr, color, ptr::null()) } }\n\n\npub fn clear() -> i32\n{ unsafe { ll::clear() } }\n\n\npub fn clearok(w: WINDOW, ok: bool) -> i32\n{ unsafe { ll::clearok(w, ok as ll::c_bool) } }\n\n\npub fn clrtobot() -> i32\n{ unsafe { ll::clrtobot() } }\n\n\npub fn clrtoeol() -> i32\n{ unsafe { ll::clrtoeol() } }\n\n\npub fn color_content(color: i16, r: &mut i16, g: &mut i16, b: &mut i16) -> i32\n{\n  unsafe\n  {\n    ll::color_content(color,\n                      &mut*r as *mut i16,\n                      &mut*g as *mut i16,\n                      &mut*b as *mut i16)\n  }\n}\n\n\npub fn color_set(pair: i16) -> i32\n{ unsafe { ll::color_set(pair, ptr::null()) } }\n\n\npub fn copywin(src_win: WINDOW, dest_win: WINDOW, src_min_row: i32,\n               src_min_col: i32, dest_min_row: i32, dest_min_col: i32,\n               dest_max_row: i32, dest_max_col: i32, overlay: i32) -> i32\n{\n  unsafe\n  {\n    ll::copywin(src_win, dest_win, src_min_row, src_min_col,\n                dest_min_row, dest_min_col, dest_max_row,\n                dest_max_col, overlay)\n  }\n}\n\n\npub fn curs_set(visibility: CURSOR_VISIBILITY) -> Option<CURSOR_VISIBILITY>\n{\n  unsafe\n  {\n    match ll::curs_set(visibility as i32)\n    {\n      ERR => None,\n      ret => Some(mem::transmute::<i8, CURSOR_VISIBILITY>(ret as i8)),\n    }\n  }\n}\n\n\npub fn def_prog_mode() -> i32\n{ unsafe { ll::def_prog_mode() } }\n\n\npub fn def_shell_mode() -> i32\n{ unsafe { ll::def_shell_mode() } }\n\n\npub fn delay_output(ms: i32) -> i32\n{ unsafe { ll::delay_output(ms) } }\n\n\npub fn delch() -> i32\n{ unsafe { ll::delch() } }\n\n\npub fn delscreen(s: SCREEN)\n{ unsafe { ll::delscreen(s) } }\n\n\npub fn delwin(w: WINDOW) -> i32\n{ unsafe { ll::delwin(w) } }\n\n\npub fn deleteln() -> i32\n{ unsafe { ll::deleteln() } }\n\n\npub fn derwin(w: WINDOW, lines: i32, cols: i32, x: i32, y: i32) -> WINDOW\n{ unsafe { ll::derwin(w, lines, cols, x, y) } }\n\n\npub fn doupdate() -> i32\n{ unsafe { ll::doupdate() } }\n\n\npub fn dupwin(w: WINDOW) -> WINDOW\n{ unsafe { ll::dupwin(w) } }\n\n\npub fn echo() -> i32\n{ unsafe { ll::echo() } }\n\n\npub fn echochar(c: chtype) -> i32\n{ unsafe { ll::echochar(c) } }\n\n\npub fn erase() -> i32\n{ unsafe { ll::erase() } }\n\n\npub fn endwin() -> i32\n{ unsafe { ll::endwin() } }\n\n\npub fn erasechar() -> char\n{ unsafe { char::from_u32(ll::erasechar() as u32).expect(\"Invalid char\") } }\n\n\npub fn filter()\n{ unsafe { ll::filter() } }\n\n\npub fn flash() -> i32\n{ unsafe { ll::flash() } }\n\n\npub fn flushinp() -> i32\n{ unsafe { ll::flushinp() } }\n\n\npub fn getbkgd(w: WINDOW) -> chtype\n{ unsafe { ll::getbkgd(w) } }\n\n\npub fn getch() -> i32\n{ unsafe { ll::getch() } }\n\n#[derive(Debug)]\npub enum WchResult {\n    KeyCode(i32),\n    Char(winttype),\n}\n\npub fn get_wch() -> Option<WchResult> {\n    unsafe {\n        let mut x = 0;\n        match ll::get_wch(&mut x) {\n            OK => {\n                Some(WchResult::Char(x))\n            }\n            KEY_CODE_YES => {\n                Some(WchResult::KeyCode(x as i32))\n            }\n            _ => {\n                None\n            }\n        }\n    }\n}\n\npub fn mvget_wch(y: i32, x: i32) -> Option<WchResult> {\n    unsafe {\n        let mut result = 0;\n        match ll::mvget_wch(y, x, &mut result) {\n            OK => {\n                Some(WchResult::Char(result))\n            }\n            KEY_CODE_YES => {\n                Some(WchResult::KeyCode(result as i32))\n            }\n            _ => {\n                None\n            }\n        }\n    }\n}\n\n#[cfg(feature = \"wide\")]\npub fn wget_wch(w: WINDOW) -> Option<WchResult> {\n    unsafe {\n        let mut result = 0;\n        match ll::wget_wch(w, &mut result) {\n            OK => {\n                Some(WchResult::Char(result))\n            }\n            KEY_CODE_YES => {\n                Some(WchResult::KeyCode(result as i32))\n            }\n            _ => {\n                None\n            }\n        }\n    }\n}\n\n#[cfg(feature = \"wide\")]\npub fn mvwget_wch(w: WINDOW, y: i32, x: i32) -> Option<WchResult> {\n    unsafe {\n        let mut result = 0;\n        match ll::mvwget_wch(w, y, x, &mut result) {\n            OK => {\n                Some(WchResult::Char(result))\n            }\n            KEY_CODE_YES => {\n                Some(WchResult::KeyCode(result as i32))\n            }\n            _ => {\n                None\n            }\n        }\n    }\n}\n\npub fn unget_wch(ch: u32) -> i32 {\n    unsafe {\n        ll::unget_wch(ch)\n    }\n}\n\n\npub fn getnstr(s: &mut String, n: i32) -> i32\n{ wgetnstr(stdscr(), s, n) }\n\n\npub fn getstr(s: &mut String) -> i32\n{\n  /* XXX: This is probably broken. */\n  let mut ch = getch();\n  while ch != '\\n' as i32 && ch != '\\r' as i32\n  {\n    unsafe { s.as_mut_vec().push(ch as u8); }\n    ch = getch();\n  }\n  OK\n}\n\n\npub fn getwin(reader: *mut libc::FILE) -> WINDOW\n{ unsafe { ll::getwin(reader) } } /* TODO: Make this safe. */\n\n\npub fn getattrs(w: WINDOW) -> i32\n{ unsafe { ll::getattrs(w) } }\n\n\npub fn getcurx(w: WINDOW) -> i32\n{ unsafe { ll::getcurx(w) } }\n\n\npub fn getcury(w: WINDOW) -> i32\n{ unsafe { ll::getcury(w) } }\n\n\npub fn getbegx(w: WINDOW) -> i32\n{ unsafe { ll::getbegx(w) } }\n\n\npub fn getbegy(w: WINDOW) -> i32\n{ unsafe { ll::getbegy(w) } }\n\n\npub fn getmaxx(w: WINDOW) -> i32\n{ unsafe { ll::getmaxx(w) } }\n\n\npub fn getmaxy(w: WINDOW) -> i32\n{ unsafe { ll::getmaxy(w) } }\n\n\npub fn getparx(w: WINDOW) -> i32\n{ unsafe { ll::getparx(w) } }\n\n\npub fn getpary(w: WINDOW) -> i32\n{ unsafe { ll::getpary(w) } }\n\n\npub fn halfdelay(tenths: i32) -> i32\n{ unsafe { ll::halfdelay(tenths) } }\n\n\npub fn has_colors() -> bool\n{ unsafe { ll::has_colors() == TRUE } }\n\n\npub fn has_ic() -> bool\n{ unsafe { ll::has_ic() == TRUE } }\n\n\npub fn has_il() -> bool\n{ unsafe { ll::has_il() == TRUE } }\n\n\npub fn hline(ch: chtype, n: i32) -> i32\n{ unsafe { ll::hline(ch, n) } }\n\n\npub fn idcok(w: WINDOW, bf: bool)\n{ unsafe { ll::idcok(w, bf as ll::c_bool) } }\n\n\npub fn idlok(w: WINDOW, bf: bool) -> i32\n{ unsafe { ll::idlok(w, bf as ll::c_bool) } }\n\n\npub fn immedok(w: WINDOW, bf: bool)\n{ unsafe { ll::immedok(w, bf as ll::c_bool) } }\n\n\npub fn inch() -> chtype\n{ unsafe { ll::inch() } }\n\n\npub fn inchnstr(s: &mut Vec<chtype>, n: i32) -> i32\n{\n  /* XXX: This is probably broken. */\n  s.clear();\n  s.reserve(n as usize);\n  unsafe\n  {\n    let ret = ll::inchnstr(s.as_ptr(), n);\n\n    let capacity = s.capacity();\n    match s.iter().position(|x| *x == 0)\n    {\n      Some(index) => s.set_len(index as usize),\n      None => s.set_len(capacity),\n    }\n\n    ret\n  }\n}\n\n\npub fn inchstr(s: &mut Vec<chtype>) -> i32\n{\n  /* XXX: This is probably broken. */\n  unsafe\n  {\n    let ret = ll::inchstr(s.as_ptr());\n\n    let capacity = s.capacity();\n    match s.iter().position(|x| *x == 0)\n    {\n      Some(index) => s.set_len(index as usize),\n      None => s.set_len(capacity),\n    }\n\n    ret\n  }\n}\n\n\npub fn initscr() -> WINDOW\n{ unsafe { ll::initscr() } }\n\n\npub fn init_color(color: i16, r: i16, g: i16, b: i16) -> i32\n{ unsafe { ll::init_color(color, r, g, b) } }\n\n\npub fn init_pair(pair: i16, f: i16, b: i16) -> i32\n{ unsafe { ll::init_pair(pair, f, b) } }\n\n\npub fn innstr(s: &mut String, n: i32) -> i32\n{\n  /* XXX: This is probably broken. */\n  unsafe\n  {\n    s.as_mut_vec().clear();\n    s.reserve(n as usize);\n    let buf = s.as_bytes().as_ptr();\n    let ret = ll::innstr(mem::transmute(buf), n);\n\n    let capacity = s.capacity();\n    match s.find('\\0')\n    {\n      Some(index) => s.as_mut_vec().set_len(index as usize),\n      None => s.as_mut_vec().set_len(capacity),\n    }\n\n    ret\n  }\n}\n\n\npub fn insch(ch: chtype) -> i32\n{ unsafe { ll::insch(ch) } }\n\n\npub fn insdelln(n: i32) -> i32\n{ unsafe { ll::insdelln(n) } }\n\n\npub fn insertln() -> i32\n{ unsafe { ll::insertln() } }\n\n\npub fn insnstr(s: &str, n: i32) -> i32\n{\n  unsafe\n  {\n    let buf = s.as_ptr();\n    ll::insnstr(mem::transmute(buf), n)\n  }\n}\n\n\npub fn insstr(s: &str) -> i32\n{\n  unsafe\n  {\n    let buf = s.as_ptr();\n    ll::insstr(mem::transmute(buf))\n  }\n}\n\n\npub fn instr(s: &mut String) -> i32\n{\n  /* XXX: This is probably broken. */\n  unsafe\n  {\n    let buf = s.as_bytes().as_ptr();\n    let ret = ll::instr(mem::transmute(buf));\n\n    let capacity = s.capacity();\n    match s.find('\\0')\n    {\n      Some(index) => s.as_mut_vec().set_len(index as usize),\n      None => s.as_mut_vec().set_len(capacity),\n    }\n\n    ret\n  }\n}\n\n\npub fn intrflush(w: WINDOW, bf: bool) -> i32\n{ unsafe { ll::intrflush(w, bf as ll::c_bool) } }\n\n\npub fn isendwin() -> bool\n{ unsafe { ll::isendwin() == TRUE } }\n\n\npub fn is_linetouched(w: WINDOW, l: i32) -> bool\n{ unsafe { ll::is_linetouched(w, l) == TRUE } }\n\n\npub fn is_wintouched(w: WINDOW) -> bool\n{ unsafe { ll::is_wintouched(w) == TRUE } }\n\n\npub fn is_term_resized(lines: i32, cols: i32) -> bool\n{ unsafe { ll::is_term_resized(lines, cols) == TRUE } }\n\n\npub fn is_cleared(w: WINDOW) -> bool\n{ unsafe { ll::is_cleared(w) == TRUE } }\n\n\npub fn is_idcok(w: WINDOW) -> bool\n{ unsafe { ll::is_idcok(w) == TRUE } }\n\n\npub fn is_idlok(w: WINDOW) -> bool\n{ unsafe { ll::is_idlok(w) == TRUE } }\n\n\npub fn is_immedok(w: WINDOW) -> bool\n{ unsafe { ll::is_immedok(w) == TRUE } }\n\n\npub fn is_keypad(w: WINDOW) -> bool\n{ unsafe { ll::is_keypad(w) == TRUE } }\n\n\npub fn is_leaveok(w: WINDOW) -> bool\n{ unsafe { ll::is_leaveok(w) == TRUE } }\n\n\npub fn is_nodelay(w: WINDOW) -> bool\n{ unsafe { ll::is_nodelay(w) == TRUE } }\n\n\npub fn is_notimeout(w: WINDOW) -> bool\n{ unsafe { ll::is_notimeout(w) == TRUE } }\n\n\npub fn is_scrollok(w: WINDOW) -> bool\n{ unsafe { ll::is_scrollok(w) == TRUE } }\n\n\npub fn is_syncok(w: WINDOW) -> bool\n{ unsafe { ll::is_syncok(w) == TRUE }}\n\n\npub fn keyname(c: i32) -> Option<String>\n{ unsafe { FromCStr::from_c_str(ll::keyname(c)) } }\n\n\npub fn keypad(w: WINDOW, bf: bool) -> i32\n{ unsafe { ll::keypad(w, bf as ll::c_bool) } }\n\n\npub fn killchar() -> char\n{ unsafe { char::from_u32(ll::killchar() as u32).expect(\"Invalid char\") } }\n\n\npub fn leaveok(w: WINDOW, bf: bool) -> i32\n{ unsafe { ll::leaveok(w, bf as ll::c_bool) } }\n\n\npub fn longname() -> String\n{ unsafe { FromCStr::from_c_str(ll::longname()) } }\n\n\npub fn meta(w: WINDOW, bf: bool) -> i32\n{ unsafe { ll::meta(w, bf as ll::c_bool) } }\n\n\npub fn mv(y: i32, x: i32) -> i32\n{ unsafe { ll::mv(y, x) } }\n\n\npub fn mvaddch(y: i32, x: i32, c: chtype) -> i32\n{ unsafe { ll::mvaddch(y, x, c) } }\n\n\npub fn mvaddchnstr(y: i32, x: i32, s: &[chtype], n: i32) -> i32\n{\n  if mv(y, x) == ERR\n  { return ERR; }\n  addchnstr(s, n)\n}\n\n\npub fn mvaddchstr(y: i32, x: i32, s: &[chtype]) -> i32\n{\n  if mv(y, x) == ERR\n  { return ERR; }\n  addchstr(s)\n}\n\n\npub fn mvaddnstr(y: i32, x: i32, s: &str, n: i32) -> i32\n{\n  if mv(y, x) == ERR\n  { return ERR; }\n  addnstr(s, n)\n}\n\n\npub fn mvaddstr(y: i32, x: i32, s: &str) -> i32\n{\n  if mv(y, x) == ERR\n  { return ERR; }\n  addstr(s)\n}\n\n\npub fn mvchgat(y: i32, x: i32, n: i32, attr: attr_t, color: i16) -> i32\n{ unsafe { ll::mvchgat(y, x, n, attr, color, ptr::null()) } }\n\n\npub fn mvcur(old_y: i32, old_x: i32, new_y: i32, new_x: i32) -> i32\n{ unsafe { ll::mvcur(old_y, old_x, new_y, new_x) } }\n\n\npub fn mvdelch(y: i32, x: i32) -> i32\n{ unsafe { ll::mvdelch(y, x) } }\n\n\npub fn mvderwin(w: WINDOW, y: i32, x: i32) -> i32\n{ unsafe { ll::mvderwin(w, y, x) } }\n\n\npub fn mvgetch(y: i32, x: i32) -> i32\n{ unsafe { ll::mvgetch(y, x) } }\n\n\npub fn mvgetnstr(y: i32, x: i32, s: &mut String, n: i32) -> i32\n{\n  match mv(y, x)\n  {\n    OK => getnstr(s, n),\n    _ => ERR,\n  }\n}\n\n\npub fn mvgetstr(y: i32, x: i32, s: &mut String) -> i32\n{\n  if mv(y, x) == ERR\n  { return ERR; }\n  getstr(s)\n}\n\n\npub fn mvhline(y: i32, x: i32, ch: chtype, n: i32) -> i32\n{ unsafe { ll::mvhline(y, x, ch, n) } }\n\n\npub fn mvinch(y: i32, x: i32) -> chtype\n{ unsafe { ll::mvinch(y, x) } }\n\n\npub fn mvinchnstr(y: i32, x: i32, s: &mut Vec<chtype>, n: i32) -> i32\n{\n  if mv(y, x) == ERR\n  { return ERR; }\n  inchnstr(s, n)\n}\n\n\npub fn mvinchstr(y: i32, x: i32, s: &mut Vec<chtype>) -> i32\n{\n  if mv(y, x) == ERR\n  { return ERR; }\n  inchstr(s)\n}\n\n\npub fn mvinnstr(y: i32, x: i32, s: &mut String, n: i32) -> i32\n{\n  if mv(y, x) == ERR\n  { return ERR; }\n  innstr(s, n)\n}\n\n\npub fn mvinsch(y: i32, x: i32, ch: chtype) -> i32\n{ unsafe { ll::mvinsch(y, x, ch) } }\n\n\npub fn mvinsnstr(y: i32, x: i32, s: &str, n: i32) -> i32\n{\n  if mv(y, x) == ERR\n  { return ERR; }\n  insnstr(s, n)\n}\n\n\npub fn mvinsstr(y: i32, x: i32, s: &str) -> i32\n{\n  if mv(y, x) == ERR\n  { return ERR; }\n  insstr(s)\n}\n\n\npub fn mvinstr(y: i32, x: i32, s: &mut String) -> i32\n{\n  if mv(y, x) == ERR\n  { return ERR; }\n  instr(s)\n}\n\n\npub fn mvprintw(y: i32, x: i32, s: &str) -> i32\n{\n  if mv(y, x) == ERR\n  { return ERR; }\n  printw(s)\n}\n\n\npub fn mvvline(y: i32, x: i32, ch: chtype, n: i32) -> i32\n{ unsafe { ll::mvvline(y, x, ch, n) } }\n\n\npub fn mvwaddch(w: WINDOW, y: i32, x: i32, ch: chtype) -> i32\n{ unsafe { ll::mvwaddch(w, y, x, ch) } }\n\n\npub fn mvwaddchnstr(w: WINDOW, y: i32, x: i32, s: &[chtype], n: i32) -> i32\n{ unsafe { ll::mvwaddchnstr(w, y, x, s.as_ptr(), n) } }\n\n\npub fn mvwaddchstr(w: WINDOW, y: i32, x: i32, s: &[chtype]) -> i32\n{ unsafe { ll::mvwaddchstr(w, y, x, s.as_ptr()) } }\n\n\npub fn mvwaddnstr(w: WINDOW, y: i32, x: i32, s: &str, n: i32) -> i32\n{ unsafe { ll::mvwaddnstr(w, y, x, s.to_c_str().as_ptr(), n) } }\n\n\npub fn mvwaddstr(w: WINDOW, y: i32, x: i32, s: &str) -> i32\n{ unsafe { ll::mvwaddstr(w, y, x, s.to_c_str().as_ptr()) } }\n\n\npub fn mvwchgat(w: WINDOW, y: i32, x: i32, n: i32, attr: attr_t, color: i16) -> i32\n{ unsafe { ll::mvwchgat(w, y, x, n, attr, color, ptr::null()) } }\n\n\npub fn mvwdelch(w: WINDOW, y: i32, x: i32) -> i32\n{ unsafe { ll::mvwdelch(w, y, x) } }\n\n\npub fn mvwgetch(w: WINDOW, y: i32, x: i32) -> i32\n{ unsafe { ll::mvwgetch(w, y, x) } }\n\n\npub fn mvwgetnstr(w: WINDOW, y: i32, x: i32, s: &mut String, n: i32) -> i32\n{\n  match wmove(w, y, x)\n  { \n    OK => wgetnstr(w, s, n), \n    _ => ERR,\n  }\n}\n\n\npub fn mvwgetstr(w: WINDOW, y: i32, x: i32, s: &mut String) -> i32\n{\n  if mv(y, x) == ERR\n  { return ERR; }\n\n  /* XXX: This is probably broken. */\n  let mut ch = wgetch(w);\n  while ch != '\\n' as i32 && ch != '\\r' as i32\n  {\n    unsafe { s.as_mut_vec().push(ch as u8); }\n    ch = wgetch(w);\n  }\n  OK\n}\n\n\npub fn mvwhline(w: WINDOW, y: i32, x: i32, ch: chtype, n: i32) -> i32\n{ unsafe { ll::mvwhline(w, y, x, ch, n) } }\n\n\npub fn mvwin(w: WINDOW, y: i32, x: i32) -> i32\n{ unsafe { ll::mvwin(w, y, x) } }\n\n\npub fn mvwinch(w: WINDOW, y: i32, x: i32) -> chtype\n{ unsafe { ll::mvwinch(w, y, x) } }\n\n\npub fn mvwinchnstr(w: WINDOW, y: i32, x: i32, s: &mut Vec<chtype>, n: i32) -> i32\n{\n  /* XXX: This is probably broken. */\n  s.clear();\n  s.reserve(n as usize);\n  unsafe\n  {\n    let ret = ll::mvwinchnstr(w, y, x, s.as_ptr(), n);\n\n    let capacity = s.capacity();\n    match s.iter().position(|x| *x == 0)\n    {\n      Some(index) => s.set_len(index as usize),\n      None => s.set_len(capacity),\n    }\n\n    ret\n  }\n}\n\n\npub fn mvwinchstr(w: WINDOW, y: i32, x: i32, s: &mut Vec<chtype>) -> i32\n{\n  /* XXX: This is probably broken. */\n  unsafe\n  {\n    let ret = ll::mvwinchstr(w, y, x, s.as_ptr());\n\n    let capacity = s.capacity();\n    match s.iter().position(|x| *x == 0)\n    {\n      Some(index) => s.set_len(index as usize),\n      None => s.set_len(capacity),\n    }\n\n    ret\n  }\n}\n\n\npub fn mvwinnstr(w: WINDOW, y: i32, x: i32, s: &mut String, n: i32) -> i32\n{\n  /* XXX: This is probably broken. */\n  unsafe\n  {\n    s.as_mut_vec().clear();\n    s.reserve(n as usize);\n    let buf = s.as_bytes().as_ptr();\n    let ret = ll::mvwinnstr(w, y, x, mem::transmute(buf), n);\n\n    let capacity = s.capacity();\n    match s.find('\\0')\n    {\n      Some(index) => s.as_mut_vec().set_len(index as usize),\n      None => s.as_mut_vec().set_len(capacity),\n    }\n\n    ret\n  }\n}\n\n\npub fn mvwinsch(w: WINDOW, y: i32, x: i32, ch: chtype) -> i32\n{ unsafe { ll::mvwinsch(w, y, x, ch) } }\n\n\npub fn mvwinsnstr(w: WINDOW, y: i32, x: i32, s: &str, n: i32) -> i32\n{ unsafe { ll::mvwinsnstr(w, y, x, s.to_c_str().as_ptr(), n) } }\n\n\npub fn mvwinsstr(w: WINDOW, y: i32, x: i32, s: &str) -> i32\n{ unsafe { ll::mvwinsstr(w, y, x, s.to_c_str().as_ptr()) } }\n\n\npub fn mvwinstr(w: WINDOW, y: i32, x: i32, s: &mut String) -> i32\n{\n  /* XXX: This is probably broken. */\n  unsafe\n  {\n    let buf = s.as_bytes().as_ptr();\n    let ret = ll::mvwinstr(w, y, x, mem::transmute(buf));\n\n    let capacity = s.capacity();\n    match s.find('\\0')\n    {\n      Some(index) => s.as_mut_vec().set_len(index as usize),\n      None => s.as_mut_vec().set_len(capacity),\n    }\n\n    ret\n  }\n}\n\n\npub fn mvwprintw(w: WINDOW, y: i32, x: i32, s: &str) -> i32\n{ unsafe { ll::mvwprintw(w, y, x, s.to_c_str().as_ptr()) } }\n\n\npub fn mvwvline(w: WINDOW, y: i32, x: i32, ch: chtype, n: i32) -> i32\n{ unsafe { ll::mvwvline(w, y, x, ch, n) } }\n\n\npub fn napms(ms: i32) -> i32\n{ unsafe { ll::napms(ms) } }\n\n\npub fn newpad(lines: i32, cols: i32) -> WINDOW\n{ unsafe { ll::newpad(lines, cols) } }\n\n\npub fn newterm(ty: Option<&str>, out_fd: FILE_p, in_fd: FILE_p) -> SCREEN\n{\n  unsafe\n  {\n    match ty {\n      Some(s) => ll::newterm(s.to_c_str().as_ptr(), out_fd, in_fd),\n      None    => ll::newterm(std::ptr::null(), out_fd, in_fd),\n    }\n  }\n}\n\n\npub fn newwin(lines: i32, cols: i32, y: i32, x: i32) -> WINDOW\n{ unsafe { ll::newwin(lines, cols, y, x) } }\n\n\npub fn nl() -> i32\n{ unsafe { ll::nl() } }\n\n\npub fn nocbreak() -> i32\n{ unsafe { ll::nocbreak() } }\n\n\npub fn nodelay(w: WINDOW, bf: bool) -> i32\n{ unsafe { ll::nodelay(w, bf as ll::c_bool) } }\n\n\npub fn noecho() -> i32\n{ unsafe { ll::noecho() } }\n\n\npub fn nonl() -> i32\n{ unsafe { ll::nonl() } }\n\n\npub fn noqiflush()\n{ unsafe { ll::noqiflush() } }\n\n\npub fn noraw() -> i32\n{ unsafe { ll::noraw() } }\n\n\npub fn notimeout(w: WINDOW, bf: bool) -> i32\n{ unsafe { ll::notimeout(w, bf as ll::c_bool) } }\n\n\npub fn overlay(src: WINDOW, dst: WINDOW) -> i32\n{ unsafe { ll::overlay(src, dst) } }\n\n\npub fn overwrite(src: WINDOW, dst: WINDOW) -> i32\n{ unsafe { ll::overwrite(src, dst) } }\n\n\npub fn pair_content(pair: i16, f: &mut i16, b: &mut i16) -> i32\n{ unsafe { ll::pair_content(pair, &mut*f as *mut i16, &mut*b as *mut i16) } }\n\n\npub fn PAIR_NUMBER(attr: i32) -> i32\n{ unsafe { ll::PAIR_NUMBER(attr) } }\n\n\npub fn pechochar(pad: WINDOW, ch: chtype) -> i32\n{ unsafe { ll::pechochar(pad, ch) } }\n\n\npub fn pnoutrefresh(pad: WINDOW, pmin_row: i32, pmin_col: i32, smin_row: i32, smin_col: i32, smax_row: i32, smax_col: i32) -> i32\n{ unsafe { ll::pnoutrefresh(pad, pmin_row, pmin_col, smin_row, smin_col, smax_row, smax_col) } }\n\n\npub fn prefresh(pad: WINDOW, pmin_row: i32, pmin_col: i32, smin_row: i32, smin_col: i32, smax_row: i32, smax_col: i32) -> i32\n{ unsafe { ll::prefresh(pad, pmin_row, pmin_col, smin_row, smin_col, smax_row, smax_col) } }\n\n\n#[deprecated(since = \"5.98.0\", note = \"printw can segfault when printing string that contains % sign. Use addstr instead\")]\nunsafe pub fn printw(s: &str) -> i32\n{ ll::printw(s.to_c_str().as_ptr()) }\n\n\npub fn putp(s: &str) -> i32\n{ unsafe { ll::putp(s.to_c_str().as_ptr()) } }\n\n\npub fn putwin(w: WINDOW, f: FILE_p) -> i32\n{ unsafe { ll::putwin(w, f) } }\n\n\npub fn qiflush()\n{ unsafe { ll::qiflush() } }\n\n\npub fn raw() -> i32\n{ unsafe { ll::raw() } }\n\n\npub fn redrawwin(w: WINDOW) -> i32\n{ unsafe { ll::redrawwin(w) } }\n\n\npub fn refresh() -> i32\n{ unsafe { ll::refresh() } }\n\n\npub fn resetty() -> i32\n{ unsafe { ll::resetty() } }\n\n\npub fn reset_prog_mode() -> i32\n{ unsafe { ll::reset_prog_mode() } }\n\n\npub fn reset_shell_mode() -> i32\n{ unsafe { ll::reset_shell_mode() } }\n\n\npub fn resizeterm(lines: i32, cols: i32) -> i32\n{ unsafe { ll::resizeterm(lines, cols) } }\n\n\npub fn resize_term(lines: i32, cols: i32) -> i32\n{ unsafe { ll::resize_term(lines, cols) } }\n\n\npub fn savetty() -> i32\n{ unsafe { ll::savetty() } }\n\n\npub fn scr_dump(filename: &str) -> i32\n{ unsafe { ll::scr_dump(filename.to_c_str().as_ptr()) } }\n\n\npub fn scr_init(filename: &str) -> i32\n{ unsafe { ll::scr_init(filename.to_c_str().as_ptr()) } }\n\n\npub fn scrl(n: i32) -> i32\n{ unsafe { ll::scrl(n) } }\n\n\npub fn scroll(w: WINDOW) -> i32\n{ unsafe { ll::scroll(w) } }\n\n\npub fn scrollok(w: WINDOW, bf: bool) -> i32\n{ unsafe { ll::scrollok(w, bf as ll::c_bool) } }\n\n\npub fn scr_restore(filename: &str) -> i32\n{ unsafe { ll::scr_restore(filename.to_c_str().as_ptr()) } }\n\n\npub fn scr_set(filename: &str) -> i32\n{ unsafe { ll::scr_set(filename.to_c_str().as_ptr()) } }\n\npub fn setlocale(lc: LcCategory, locale: &str) -> String\n{\n  unsafe {\n    let buf = locale.to_c_str().as_ptr();\n    let ret = ll::setlocale(lc as libc::c_int, buf);\n    if ret == ptr::null() {\n        String::new()\n    } else {\n        // The clone is necessary, as the returned pointer\n        // can change at any time\n        CStr::from_ptr(ret).to_string_lossy().into_owned()\n    }\n  }\n}\n\npub fn setscrreg(top: i32, bot: i32) -> i32\n{ unsafe { ll::setscrreg(top, bot) } }\n\n\npub fn set_term(s: SCREEN) -> SCREEN\n{ unsafe { ll::set_term(s) } }\n\npub fn set_escdelay(size: i32) -> i32\n{ unsafe { ll::set_escdelay(size) } }\n\npub fn set_tabsize(size: i32) -> i32\n{ unsafe { ll::set_tabsize(size) } }\n\npub fn slk_attroff(ch: chtype) -> i32\n{ unsafe { ll::slk_attroff(ch) } }\n\n//\n//pub fn slk_attr_off(ch: attr_t) -> i32\n//{ unsafe { ll::slk_attr_off(ch, ptr::null()) } }\n\n\npub fn slk_attron(ch: chtype) -> i32\n{ unsafe { ll::slk_attron(ch) } }\n\n//\n//pub fn slk_attr_on(ch: attr_t) -> i32\n//{ unsafe { ll::slk_attr_on(ch, ptr::null()) } }\n\n\npub fn slk_attrset(ch: chtype) -> i32\n{ unsafe { ll::slk_attrset(ch) } }\n\n\npub fn slk_attr() -> attr_t\n{ unsafe { ll::slk_attr() } }\n\n\npub fn slk_attr_set(attrs: attr_t, pair: i16) -> i32\n{ unsafe { ll::slk_attr_set(attrs, pair, ptr::null()) } }\n\n\npub fn slk_clear() -> i32\n{ unsafe { ll::slk_clear() } }\n\n\npub fn slk_color(pair: i16) -> i32\n{ unsafe { ll::slk_color(pair) } }\n\n\npub fn slk_init(fmt: i32) -> i32\n{ unsafe { ll::slk_init(fmt) } }\n\n\npub fn slk_label(n: i32) -> String\n{ unsafe { FromCStr::from_c_str(ll::slk_label(n)) } }\n\n\npub fn slk_noutrefresh() -> i32\n{ unsafe { ll::slk_noutrefresh() } }\n\n\npub fn slk_refresh() -> i32\n{ unsafe { ll::slk_refresh() } }\n\n\npub fn slk_restore() -> i32\n{ unsafe { ll::slk_restore() } }\n\n\npub fn slk_set(n: i32, s: &str, fmt: i32) -> i32\n{ unsafe { ll::slk_set(n, s.to_c_str().as_ptr(), fmt) } }\n\n\npub fn slk_touch() -> i32\n{ unsafe { ll::slk_touch() }}\n\n\npub fn standout() -> i32\n{ unsafe { ll::standout() } }\n\n\npub fn standend() -> i32\n{ unsafe { ll::standend() } }\n\n\npub fn start_color() -> i32\n{ unsafe { ll::start_color() } }\n\n\npub fn subpad(w: WINDOW, lines: i32, cols: i32, y: i32, x: i32) -> WINDOW\n{ unsafe { ll::subpad(w, lines, cols, y, x) } }\n\n\npub fn subwin(w: WINDOW, lines: i32, cols: i32, y: i32, x: i32) -> WINDOW\n{ unsafe { ll::subwin(w, lines, cols, y, x) } }\n\n\npub fn syncok(w: WINDOW, bf: bool) -> i32\n{ unsafe { ll::syncok(w, bf as ll::c_bool) } }\n\n\npub fn termattrs() -> chtype\n{ unsafe { ll::termattrs() } }\n\n\npub fn termname() -> String\n{ unsafe { FromCStr::from_c_str(ll::termname()) } }\n\n\npub fn timeout(delay: i32)\n{ unsafe { ll::timeout(delay) } }\n\n\npub fn touchline(w: WINDOW, start: i32, count: i32) -> i32\n{ unsafe { ll::touchline(w, start, count) } }\n\n\npub fn touchwin(w: WINDOW) -> i32\n{ unsafe { ll::touchwin(w) } }\n\n\npub fn typeahead(fd: i32) -> i32\n{ unsafe { ll::typeahead(fd) } }\n\n\npub fn tigetflag(capname: &str) -> i32\n{ unsafe { ll::tigetflag(capname.to_c_str().as_ptr()) } }\n\n\npub fn tigetnum(capname: &str) -> i32\n{ unsafe { ll::tigetnum(capname.to_c_str().as_ptr()) } }\n\n\npub fn tigetstr(capname: &str) -> String\n{ unsafe { { FromCStr::from_c_str(ll::tigetstr(capname.to_c_str().as_ptr())) } } }\n\n\npub fn tparm(s: &str) -> String\n{ unsafe { { FromCStr::from_c_str(ll::tparm(s.to_c_str().as_ptr())) } } }\n\n\npub fn ungetch(ch: i32) -> i32\n{ unsafe { ll::ungetch(ch) } }\n\n\npub fn untouchwin(w: WINDOW) -> i32\n{ unsafe { ll::untouchwin(w) } }\n\n\npub fn use_env(f: bool)\n{ unsafe { ll::use_env(f as ll::c_bool) } }\n\n\npub fn use_default_colors() -> i32\n{ unsafe { ll::use_default_colors() } }\n\n\npub fn vidattr(attrs: chtype) -> i32\n{ unsafe { ll::vidattr(attrs) } }\n\n\npub fn vline(ch: chtype, n: i32) -> i32\n{ unsafe { ll::vline(ch, n) } }\n\n\npub fn waddch(w: WINDOW, ch: chtype) -> i32\n{ unsafe { ll::waddch(w, ch) } }\n\n\npub fn waddchnstr(w: WINDOW, s: &[chtype], n: i32) -> i32\n{ unsafe { ll::waddchnstr(w, s.as_ptr(), n) } }\n\n\npub fn waddchstr(w: WINDOW, s: &[chtype]) -> i32\n{ unsafe { ll::waddchstr(w, s.as_ptr()) } }\n\n\npub fn waddnstr(w: WINDOW, s: &str, n: i32) -> i32\n{ unsafe { ll::waddnstr(w, s.to_c_str().as_ptr(), n) } }\n\n\npub fn waddstr(w: WINDOW, s: &str) -> i32\n{ unsafe { ll::waddstr(w, s.to_c_str().as_ptr()) } }\n\n\npub fn wattron(w: WINDOW, attr: NCURSES_ATTR_T) -> i32\n{ unsafe { ll::wattron(w, attr) } }\n\n\npub fn wattroff(w: WINDOW, attr: NCURSES_ATTR_T) -> i32\n{ unsafe { ll::wattroff(w, attr) } }\n\n\npub fn wattrset(w: WINDOW, attr: NCURSES_ATTR_T) -> i32\n{ unsafe { ll::wattrset(w, attr) } }\n\n\npub fn wattr_get(w: WINDOW, attrs: &mut attr_t, pair: &mut i16) -> i32\n{ unsafe { ll::wattr_get(w, &mut*attrs as *mut attr_t, &mut*pair as *mut i16, ptr::null()) } }\n\n\npub fn wattr_on(w: WINDOW, attr: attr_t) -> i32\n{ unsafe { ll::wattr_on(w, attr, ptr::null()) } }\n\n\npub fn wattr_off(w: WINDOW, attr: attr_t) -> i32\n{ unsafe { ll::wattr_off(w, attr, ptr::null()) } }\n\n\npub fn wattr_set(w: WINDOW, attrs: attr_t, pair: i16) -> i32\n{ unsafe { ll::wattr_set(w, attrs, pair, ptr::null()) } }\n\n\npub fn wbkgd(w: WINDOW, ch: chtype) -> i32\n{ unsafe { ll::wbkgd(w, ch) } }\n\n\npub fn wbkgdset(w: WINDOW, ch: chtype)\n{ unsafe { ll::wbkgdset(w, ch) } }\n\n\npub fn wborder(w: WINDOW, ls: chtype, rs: chtype, ts: chtype, bs: chtype, tl: chtype, tr: chtype, bl: chtype, br: chtype) -> i32\n{ unsafe { ll::wborder(w, ls, rs, ts, bs, tl, tr, bl, br) } }\n\n\npub fn wchgat(w: WINDOW, n: i32, attr: attr_t, color: i16) -> i32\n{ unsafe { ll::wchgat(w, n, attr, color, ptr::null()) } }\n\n\npub fn wclear(w: WINDOW) -> i32\n{ unsafe { ll::wclear(w) } }\n\n\npub fn wclrtobot(w: WINDOW) -> i32\n{ unsafe { ll::wclrtobot(w) } }\n\n\npub fn wclrtoeol(w: WINDOW) -> i32\n{ unsafe { ll::wclrtoeol(w) } }\n\n\npub fn wcolor_set(w: WINDOW, pair: i16) -> i32\n{ unsafe { ll::wcolor_set(w, pair, ptr::null()) } }\n\n\npub fn wcursyncup(w: WINDOW)\n{ unsafe { ll::wcursyncup(w) } }\n\n\npub fn wdelch(w: WINDOW) -> i32\n{ unsafe { ll::wdelch(w) } }\n\n\npub fn wdeleteln(w: WINDOW) -> i32\n{ unsafe { ll::wdeleteln(w) } }\n\n\npub fn wechochar(w: WINDOW, ch: chtype) -> i32\n{ unsafe { ll::wechochar(w, ch) } }\n\n\npub fn werase(w: WINDOW) -> i32\n{ unsafe { ll::werase(w) } }\n\n\npub fn wgetch(w: WINDOW) -> i32\n{ unsafe { ll::wgetch(w) } }\n\n\npub fn wgetnstr(w: WINDOW, s: &mut String, n: i32) -> i32\n{\n  let mut buff: Vec<u8> = Vec::with_capacity(n as usize);\n  unsafe { buff.set_len(n as usize); }\n  \n  match unsafe { ll::wgetnstr(w, buff.as_ptr(), n) }\n  {\n    OK => {\n      *s = buff.iter()\n        .take_while(|ch| **ch != '\\0' as u8 )\n        .map(|ch| *ch as char )\n        .collect();\n\n      OK\n    },\n\n    _ => ERR,\n  }\n}\n\n\npub fn wgetstr(w: WINDOW, s: &mut String) -> i32\n{\n  /* XXX: This is probably broken. */\n  let mut ch = wgetch(w);\n  while ch != '\\n' as i32 && ch != '\\r' as i32\n  {\n    unsafe { s.as_mut_vec().push(ch as u8); }\n    ch = wgetch(w);\n  }\n  OK\n}\n\n\npub fn whline(w: WINDOW, ch: chtype, n: i32) -> i32\n{ unsafe { ll::whline(w, ch, n) } }\n\n\npub fn winch(w: WINDOW) -> chtype\n{ unsafe { ll::winch(w) } }\n\n\npub fn winchnstr(w: WINDOW, s: &mut Vec<chtype>, n: i32) -> i32\n{\n  /* XXX: This is probably broken. */\n  s.clear();\n  s.reserve(n as usize);\n  unsafe\n  {\n    let ret = ll::winchnstr(w, s.as_ptr(), n);\n\n    let capacity = s.capacity();\n    match s.iter().position(|x| *x == 0)\n    {\n      Some(index) => s.set_len(index as usize),\n      None => s.set_len(capacity),\n    }\n\n    ret\n  }\n}\n\n\npub fn winchstr(w: WINDOW, s: &mut Vec<chtype>) -> i32\n{\n  /* XXX: This is probably broken. */\n  unsafe\n  {\n    let ret = ll::winchstr(w, s.as_ptr());\n\n    let capacity = s.capacity();\n    match s.iter().position(|x| *x == 0)\n    {\n      Some(index) => s.set_len(index as usize),\n      None => s.set_len(capacity),\n    }\n\n    ret\n  }\n}\n\n\npub fn winnstr(w: WINDOW, s: &mut String, n: i32) -> i32\n{\n  /* XXX: This is probably broken. */\n  unsafe\n  {\n    s.as_mut_vec().clear();\n    s.reserve(n as usize);\n    let buf = s.as_bytes().as_ptr();\n    let ret = ll::winnstr(w, mem::transmute(buf), n);\n\n    let capacity = s.capacity();\n    match s.find('\\0')\n    {\n      Some(index) => s.as_mut_vec().set_len(index as usize),\n      None => s.as_mut_vec().set_len(capacity),\n    }\n\n    ret\n  }\n}\n\n\npub fn winsch(w: WINDOW, ch: chtype) -> i32\n{ unsafe { ll::winsch(w, ch) } }\n\n\npub fn winsdelln(w: WINDOW, n: i32) -> i32\n{ unsafe { ll::winsdelln(w, n) } }\n\n\npub fn winsertln(w: WINDOW) -> i32\n{ unsafe { ll::winsertln(w) } }\n\n\npub fn winsnstr(w: WINDOW, s: &str, n: i32) -> i32\n{\n  unsafe\n  {\n    let buf = s.as_ptr();\n    ll::winsnstr(w, mem::transmute(buf), n)\n  }\n}\n\n\npub fn winsstr(w: WINDOW, s: &str) -> i32\n{\n  unsafe\n  {\n    let buf = s.as_ptr();\n    ll::winsstr(w, mem::transmute(buf))\n  }\n}\n\n\npub fn winstr(w: WINDOW, s: &mut String) -> i32\n{\n  /* XXX: This is probably broken. */\n  unsafe\n  {\n    let buf = s.as_bytes().as_ptr();\n    let ret = ll::winstr(w, mem::transmute(buf));\n\n    let capacity = s.capacity();\n    match s.find('\\0')\n    {\n      Some(index) => s.as_mut_vec().set_len(index as usize),\n      None => s.as_mut_vec().set_len(capacity),\n    }\n\n    ret\n  }\n}\n\n\npub fn wmove(w: WINDOW, y: i32, x: i32) -> i32\n{ unsafe { ll::wmove(w, y, x) } }\n\n\npub fn wnoutrefresh(w: WINDOW) -> i32\n{ unsafe { ll::wnoutrefresh(w) } }\n\n\npub fn wprintw(w: WINDOW, s: &str) -> i32\n{ unsafe { ll::wprintw(w, s.to_c_str().as_ptr()) } }\n\n\npub fn wredrawln(w: WINDOW, start: i32, n: i32) -> i32\n{ unsafe { ll::wredrawln(w, start, n) } }\n\n\npub fn wrefresh(w: WINDOW) -> i32\n{ unsafe { ll::wrefresh(w) } }\n\n\npub fn wresize(w: WINDOW, lines: i32, cols: i32) -> i32\n{ unsafe { ll::wresize(w, lines, cols) } }\n\n\npub fn wscrl(w: WINDOW, n: i32) -> i32\n{ unsafe { ll::wscrl(w, n) } }\n\n\npub fn wsetscrreg(w: WINDOW, top: i32, bot: i32) -> i32\n{ unsafe { ll::wsetscrreg(w, top, bot) } }\n\n\npub fn wstandout(w: WINDOW) -> i32\n{ unsafe { ll::wstandout(w) } }\n\n\npub fn wstandend(w: WINDOW) -> i32\n{ unsafe { ll::wstandend(w) } }\n\n\npub fn wsyncdown(w: WINDOW)\n{ unsafe { ll::wsyncdown(w) } }\n\n\npub fn wsyncup(w: WINDOW)\n{ unsafe { ll::wsyncup(w) } }\n\n\npub fn wtimeout(w: WINDOW, delay: i32)\n{ unsafe { ll::wtimeout(w, delay) } }\n\n\npub fn wtouchln(w: WINDOW, y: i32, n: i32, changed: i32) -> i32\n{ unsafe { ll::wtouchln(w, y, n, changed) } }\n\n\npub fn wvline(w: WINDOW, ch: chtype, n: i32) -> i32\n{ unsafe { ll::wvline(w, ch, n) } }\n\n\npub fn wgetparent(w: WINDOW) -> WINDOW\n{ unsafe { ll::wgetparent(w) } }\n\n\npub fn wgetscrreg(w: WINDOW, top: &mut i32, bot: &mut i32) -> i32\n{ unsafe { ll::wgetscrreg(w, &mut*top as *mut i32, &mut*bot as *mut i32) } }\n\n/* Attributes */\npub fn NCURSES_BITS(mask: u32, shift: u32) -> u32\n{ mask << (shift + NCURSES_ATTR_SHIFT) as usize }\n\npub fn A_NORMAL() -> attr_t\n{ (1u32 - 1u32) as attr_t }\n\npub fn A_ATTRIBUTES() -> attr_t\n{ NCURSES_BITS(!(1u32 - 1u32), 0u32) as attr_t }\n\npub fn A_CHARTEXT() -> attr_t\n{(NCURSES_BITS(1u32, 0u32) - 1u32) as attr_t }\n\npub fn A_COLOR() -> attr_t\n{ NCURSES_BITS(((1u32) << 8) - 1u32, 0u32) as attr_t }\n\npub fn A_STANDOUT() -> attr_t\n{ NCURSES_BITS(1u32, 8u32) as attr_t }\n\npub fn A_UNDERLINE() -> attr_t\n{ NCURSES_BITS(1u32, 9u32) as attr_t }\n\npub fn A_REVERSE() -> attr_t\n{ NCURSES_BITS(1u32, 10u32) as attr_t }\n\npub fn A_BLINK() -> attr_t\n{ NCURSES_BITS(1u32, 11u32) as attr_t }\n\npub fn A_DIM() -> attr_t\n{ NCURSES_BITS(1u32, 12u32) as attr_t }\n\npub fn A_BOLD() -> attr_t\n{ NCURSES_BITS(1u32, 13u32) as attr_t }\n\npub fn A_ALTCHARSET() -> attr_t\n{ NCURSES_BITS(1u32, 14u32) as attr_t }\n\npub fn A_INVIS() -> attr_t\n{ NCURSES_BITS(1u32, 15u32) as attr_t }\n\npub fn A_PROTECT() -> attr_t\n{ NCURSES_BITS(1u32, 16u32) as attr_t }\n\npub fn A_HORIZONTAL() -> attr_t\n{ NCURSES_BITS(1u32, 17u32) as attr_t }\n\npub fn A_LEFT() -> attr_t\n{ NCURSES_BITS(1u32, 18u32) as attr_t }\n\npub fn A_LOW() -> attr_t\n{ NCURSES_BITS(1u32, 19u32) as attr_t }\n\npub fn A_RIGHT() -> attr_t\n{ NCURSES_BITS(1u32, 20u32) as attr_t }\n\npub fn A_TOP() -> attr_t\n{ NCURSES_BITS(1u32, 21u32) as attr_t }\n\npub fn A_VERTICAL() -> attr_t\n{ NCURSES_BITS(1u32, 22u32) as attr_t }\n\npub fn A_ITALIC() -> attr_t\n{ NCURSES_BITS(1u32, 23u32) as attr_t }\n\n/* Colors. */\npub fn COLOR_PAIR(n: i16) -> attr_t\n{ NCURSES_BITS(n as u32, 0u32) as attr_t }\n\n/*\n * Most of the pseudo functions are macros that either provide compatibility\n * with older versions of curses, or provide inline functionality to improve\n * performance.\n */\n\npub fn getyx(win: WINDOW, y: &mut i32, x: &mut i32)\n{ unsafe { *y = ll::getcury(win); *x = ll::getcurx(win); } }\n\n\npub fn getbegyx(win: WINDOW, y: &mut i32, x: &mut i32)\n{ unsafe { *y = ll::getbegy(win); *x = ll::getbegx(win) } }\n\n\npub fn getmaxyx(win: WINDOW, y: &mut i32, x: &mut i32)\n{ unsafe { *y = ll::getmaxy(win); *x = ll::getmaxx(win) } }\n\n\npub fn getparyx(win: WINDOW, y: &mut i32, x: &mut i32)\n{ unsafe { *y = ll::getpary(win); *x = ll::getparx(win) } }\n\n\npub fn getsyx(y: &mut i32, x: &mut i32)\n{\n  unsafe\n  {\n    if newscr() != ptr::null_mut()\n    {\n      if ll::is_leaveok(newscr()) == TRUE\n      {\n        *x = -1 as i32;\n        *y = -1 as i32;\n      }\n      else\n      { getyx(newscr(), y, x); }\n    }\n  }\n}\n\n\npub fn setsyx(y: &mut i32, x: &mut i32)\n{\n  unsafe\n  {\n    if newscr() !=(0 as WINDOW)\n    {\n      if *y == -1 && *x == -1\n      {\n        ll::leaveok(newscr(), 1);\n      }\n      else\n      {\n        ll::leaveok(newscr(), 0);\n        ll::wmove(newscr(), *y, *x);\n      }\n    }\n  }\n}\n\n/* Line graphics */\npub fn NCURSES_ACS(c: char) -> chtype {\n    unsafe { *acs_map().offset((c as libc::c_uchar) as isize) as chtype }\n}\n\n/* VT100 symbols begin here */\npub fn ACS_ULCORNER() -> chtype\n{ NCURSES_ACS('l') } /* upper left corner */\n\npub fn ACS_LLCORNER() -> chtype\n{ NCURSES_ACS('m') } /* lower left corner */\n\npub fn ACS_URCORNER() -> chtype\n{ NCURSES_ACS('k') } /* upper right corner */\n\npub fn ACS_LRCORNER() -> chtype\n{ NCURSES_ACS('j') } /* lower right corner */\n\npub fn ACS_LTEE() -> chtype\n{ NCURSES_ACS('t') } /* tee pointing right */\n\npub fn ACS_RTEE() -> chtype\n{ NCURSES_ACS('u') } /* tee pointing left */\n\npub fn ACS_BTEE() -> chtype\n{ NCURSES_ACS('v') } /* tee pointing up */\n\npub fn ACS_TTEE() -> chtype\n{ NCURSES_ACS('w') } /* tee pointing down */\n\npub fn ACS_HLINE() -> chtype\n{ NCURSES_ACS('q') } /* horizontal line */\n\npub fn ACS_VLINE() -> chtype\n{ NCURSES_ACS('x') } /* vertical line */\n\npub fn ACS_PLUS() -> chtype\n{ NCURSES_ACS('n') } /* large plus or crossover */\n\npub fn ACS_S1() -> chtype\n{ NCURSES_ACS('o') } /* scan line 1 */\n\npub fn ACS_S9() -> chtype\n{ NCURSES_ACS('s') } /* scan line 9 */\n\npub fn ACS_DIAMOND() -> chtype\n{ NCURSES_ACS('`') } /* diamond */\n\npub fn ACS_CKBOARD() -> chtype\n{ NCURSES_ACS('a') } /* checker board(stipple) */\n\npub fn ACS_DEGREE() -> chtype\n{ NCURSES_ACS('f') } /* degree symbol */\n\npub fn ACS_PLMINUS() -> chtype\n{ NCURSES_ACS('g') } /* plus/minus */\n\npub fn ACS_BULLET() -> chtype\n{ NCURSES_ACS('~') } /* bullet */\n\n/* Teletype 5410v1 symbols begin here */\npub fn ACS_LARROW() -> chtype\n{ NCURSES_ACS(',') } /* arrow pointing left */\n\npub fn ACS_RARROW() -> chtype\n{ NCURSES_ACS('+') } /* arrow pointing right */\n\npub fn ACS_DARROW() -> chtype\n{ NCURSES_ACS('.') } /* arrow pointing down */\n\npub fn ACS_UARROW() -> chtype\n{ NCURSES_ACS('-') } /* arrow pointing up */\n\npub fn ACS_BOARD() -> chtype\n{ NCURSES_ACS('h') } /* board of squares */\n\npub fn ACS_LANTERN() -> chtype\n{ NCURSES_ACS('i') } /* lantern symbol */\n\npub fn ACS_BLOCK() -> chtype\n{ NCURSES_ACS('0') } /* solid square block */\n\n/*\n * These aren't documented, but a lot of System Vs have them anyway\n * (you can spot pprryyzz{{||}} in a lot of AT&T terminfo strings).\n * The ACS_names may not match AT&T's, our source didn't know them.\n */\npub fn ACS_S3() -> chtype\n{ NCURSES_ACS('p') } /* scan line 3 */\n\npub fn ACS_S7() -> chtype\n{ NCURSES_ACS('r') } /* scan line 7 */\n\npub fn ACS_LEQUAL() -> chtype\n{ NCURSES_ACS('y') } /* less/equal */\n\npub fn ACS_GEQUAL() -> chtype\n{ NCURSES_ACS('z') } /* greater/equal */\n\npub fn ACS_PI() -> chtype\n{ NCURSES_ACS('{') } /* Pi */\n\npub fn ACS_NEQUAL() -> chtype\n{ NCURSES_ACS('|') } /* not equal */\n\npub fn ACS_STERLING() -> chtype\n{ NCURSES_ACS('}') } /* UK pound sign */\n\n/*\n * Line drawing ACS names are of the form ACS_trbl, where t is the top, r\n * is the right, b is the bottom, and l is the left. t, r, b, and l might\n * be B(blank), S(single), D(double), or T(thick). The subset defined\n * here only uses B and S.\n */\npub fn ACS_BSSB() -> chtype\n{ ACS_ULCORNER() }\n\npub fn ACS_SSBB() -> chtype\n{ ACS_LLCORNER() }\n\npub fn ACS_BBSS() -> chtype\n{ ACS_URCORNER() }\n\npub fn ACS_SBBS() -> chtype\n{ ACS_LRCORNER() }\n\npub fn ACS_SBSS() -> chtype\n{ ACS_RTEE() }\n\npub fn ACS_SSSB() -> chtype\n{ ACS_LTEE() }\n\npub fn ACS_SSBS() -> chtype\n{ ACS_BTEE() }\n\npub fn ACS_BSSS() -> chtype\n{ ACS_TTEE() }\n\npub fn ACS_BSBS() -> chtype\n{ ACS_HLINE() }\n\npub fn ACS_SBSB() -> chtype\n{ ACS_VLINE() }\n\npub fn ACS_SSSS() -> chtype\n{ ACS_PLUS() }\n\npub fn KEY_F(n: u8) -> i32\n{\n  assert!(n < 16);\n  KEY_F0 + n as i32\n}\n\n/*\n * Added mouse support\n */\n\npub fn has_mouse() -> bool\n{ unsafe { ll::has_mouse() == TRUE } }\n\npub fn getmouse(event: *mut MEVENT) -> i32\n{ unsafe { ll::getmouse(event) } }\n\npub fn ungetmouse(event: *mut MEVENT) -> i32\n{ unsafe { ll::ungetmouse(event) } }\n\npub fn mouseinterval(n: i32) -> i32\n{ unsafe { ll::mouseinterval(n) } }\n\npub fn mousemask(newmask: mmask_t, oldmask: Option<&mut mmask_t>) -> mmask_t\n{\n    if oldmask.is_none() { unsafe { ll::mousemask(newmask, ptr::null_mut()) } }\n    else { unsafe { ll::mousemask(newmask, oldmask.unwrap()) } }\n}\n\npub fn wenclose(w: WINDOW, y: i32, x: i32) -> bool\n{ unsafe { ll::wenclose(w, y as libc::c_int, x as libc::c_int) == TRUE } }\n\npub fn wmouse_trafo(w: WINDOW, y: &mut[i32], x: &mut[i32], to_screen: bool) -> bool\n{ unsafe { ll::wmouse_trafo(w, y.as_mut_ptr(), x.as_mut_ptr(), to_screen as ll::c_bool) == TRUE } }\n\npub fn mouse_trafo(y: &mut[i32], x: &mut[i32], to_screen: bool) -> bool\n{ unsafe { ll::mouse_trafo(y.as_mut_ptr(), x.as_mut_ptr(), to_screen as ll::c_bool) == TRUE } }\n\n#[cfg(feature = \"extended_colors\")]\npub fn init_extended_color(color: i32, r: i32, g: i32, b: i32) -> i32 {\n    unsafe { ll::init_extended_color(color, r, g, b) }\n}\n\n#[cfg(feature = \"extended_colors\")]\npub fn init_extended_pair(color: i32, f: i32, b: i32) -> i32 {\n    unsafe { ll::init_extended_pair(color, f, b) }\n}\n\n#[cfg(feature = \"extended_colors\")]\npub fn extended_color_content(color: i32, r: &mut i32, g: &mut i32, b: &mut i32) -> i32 {\n    unsafe { ll::extended_color_content(color, r, g, b) }\n}\n\n#[cfg(feature = \"extended_colors\")]\npub fn extended_pair_content(pair: i32, f: &mut i32, b: &mut i32) -> i32 {\n    unsafe { ll::extended_pair_content(pair, f, b) }\n}\n"
  },
  {
    "project": "spin-rs",
    "target": 1,
    "commit_id": "3cf5453294e7f24fbb7299681e00f5f0c5a7fbd8",
    "func": "use core::cell::UnsafeCell;\nuse core::default::Default;\nuse core::fmt;\nuse core::mem;\nuse core::ops::{Deref, DerefMut};\nuse core::ptr::NonNull;\nuse core::marker::PhantomData;\nuse core::sync::atomic::{spin_loop_hint as cpu_relax, AtomicUsize, Ordering};\n\n/// A reader-writer lock\n///\n/// This type of lock allows a number of readers or at most one writer at any\n/// point in time. The write portion of this lock typically allows modification\n/// of the underlying data (exclusive access) and the read portion of this lock\n/// typically allows for read-only access (shared access).\n///\n/// The type parameter `T` represents the data that this lock protects. It is\n/// required that `T` satisfies `Send` to be shared across tasks and `Sync` to\n/// allow concurrent access through readers. The RAII guards returned from the\n/// locking methods implement `Deref` (and `DerefMut` for the `write` methods)\n/// to allow access to the contained of the lock.\n///\n/// An [`RwLockUpgradeableGuard`](RwLockUpgradeableGuard) can be upgraded to a\n/// writable guard through the [`RwLockUpgradeableGuard::upgrade`](RwLockUpgradeableGuard::upgrade)\n/// [`RwLockUpgradeableGuard::try_upgrade`](RwLockUpgradeableGuard::try_upgrade) functions.\n/// Writable or upgradeable guards can be downgraded through their respective `downgrade`\n/// functions.\n///\n/// Based on Facebook's\n/// [`folly/RWSpinLock.h`](https://github.com/facebook/folly/blob/a0394d84f2d5c3e50ebfd0566f9d3acb52cfab5a/folly/synchronization/RWSpinLock.h).\n///\n/// # Examples\n///\n/// ```\n/// use spin;\n///\n/// let lock = spin::RwLock::new(5);\n///\n/// // many reader locks can be held at once\n/// {\n///     let r1 = lock.read();\n///     let r2 = lock.read();\n///     assert_eq!(*r1, 5);\n///     assert_eq!(*r2, 5);\n/// } // read locks are dropped at this point\n///\n/// // only one write lock may be held, however\n/// {\n///     let mut w = lock.write();\n///     *w += 1;\n///     assert_eq!(*w, 6);\n/// } // write lock is dropped here\n/// ```\npub struct RwLock<T: ?Sized> {\n    lock: AtomicUsize,\n    data: UnsafeCell<T>,\n}\n\nconst READER: usize = 1 << 2;\nconst UPGRADED: usize = 1 << 1;\nconst WRITER: usize = 1;\n\n/// A guard from which the protected data can be read\n///\n/// When the guard falls out of scope it will decrement the read count,\n/// potentially releasing the lock.\n#[derive(Debug)]\npub struct RwLockReadGuard<'a, T: 'a + ?Sized> {\n    lock: &'a AtomicUsize,\n    data: NonNull<T>,\n}\n\n/// A guard to which the protected data can be written\n///\n/// When the guard falls out of scope it will release the lock.\n#[derive(Debug)]\npub struct RwLockWriteGuard<'a, T: 'a + ?Sized> {\n    lock: &'a AtomicUsize,\n    data: NonNull<T>,\n    #[doc(hidden)]\n    _invariant: PhantomData<&'a mut T>,\n}\n\n/// A guard from which the protected data can be read, and can be upgraded\n/// to a writable guard if needed\n///\n/// No writers or other upgradeable guards can exist while this is in scope. New reader\n/// creation is prevented (to alleviate writer starvation) but there may be existing readers\n/// when the lock is acquired.\n///\n/// When the guard falls out of scope it will release the lock.\n#[derive(Debug)]\npub struct RwLockUpgradeableGuard<'a, T: 'a + ?Sized> {\n    lock: &'a AtomicUsize,\n    data: NonNull<T>,\n    #[doc(hidden)]\n    _invariant: PhantomData<&'a mut T>,\n}\n\n// Same unsafe impls as `std::sync::RwLock`\nunsafe impl<T: ?Sized + Send> Send for RwLock<T> {}\nunsafe impl<T: ?Sized + Send + Sync> Sync for RwLock<T> {}\n\nimpl<T> RwLock<T> {\n    /// Creates a new spinlock wrapping the supplied data.\n    ///\n    /// May be used statically:\n    ///\n    /// ```\n    /// use spin;\n    ///\n    /// static RW_LOCK: spin::RwLock<()> = spin::RwLock::new(());\n    ///\n    /// fn demo() {\n    ///     let lock = RW_LOCK.read();\n    ///     // do something with lock\n    ///     drop(lock);\n    /// }\n    /// ```\n    #[inline]\n    pub const fn new(user_data: T) -> RwLock<T> {\n        RwLock {\n            lock: AtomicUsize::new(0),\n            data: UnsafeCell::new(user_data),\n        }\n    }\n\n    /// Consumes this `RwLock`, returning the underlying data.\n    #[inline]\n    pub fn into_inner(self) -> T {\n        // We know statically that there are no outstanding references to\n        // `self` so there's no need to lock.\n        let RwLock { data, .. } = self;\n        data.into_inner()\n    }\n}\n\nimpl<T: ?Sized> RwLock<T> {\n    /// Locks this rwlock with shared read access, blocking the current thread\n    /// until it can be acquired.\n    ///\n    /// The calling thread will be blocked until there are no more writers which\n    /// hold the lock. There may be other readers currently inside the lock when\n    /// this method returns. This method does not provide any guarantees with\n    /// respect to the ordering of whether contentious readers or writers will\n    /// acquire the lock first.\n    ///\n    /// Returns an RAII guard which will release this thread's shared access\n    /// once it is dropped.\n    ///\n    /// ```\n    /// let mylock = spin::RwLock::new(0);\n    /// {\n    ///     let mut data = mylock.read();\n    ///     // The lock is now locked and the data can be read\n    ///     println!(\"{}\", *data);\n    ///     // The lock is dropped\n    /// }\n    /// ```\n    #[inline]\n    pub fn read(&self) -> RwLockReadGuard<T> {\n        loop {\n            match self.try_read() {\n                Some(guard) => return guard,\n                None => cpu_relax(),\n            }\n        }\n    }\n\n    /// Attempt to acquire this lock with shared read access.\n    ///\n    /// This function will never block and will return immediately if `read`\n    /// would otherwise succeed. Returns `Some` of an RAII guard which will\n    /// release the shared access of this thread when dropped, or `None` if the\n    /// access could not be granted. This method does not provide any\n    /// guarantees with respect to the ordering of whether contentious readers\n    /// or writers will acquire the lock first.\n    ///\n    /// ```\n    /// let mylock = spin::RwLock::new(0);\n    /// {\n    ///     match mylock.try_read() {\n    ///         Some(data) => {\n    ///             // The lock is now locked and the data can be read\n    ///             println!(\"{}\", *data);\n    ///             // The lock is dropped\n    ///         },\n    ///         None => (), // no cigar\n    ///     };\n    /// }\n    /// ```\n    #[inline]\n    pub fn try_read(&self) -> Option<RwLockReadGuard<T>> {\n        let value = self.lock.fetch_add(READER, Ordering::Acquire);\n\n        // We check the UPGRADED bit here so that new readers are prevented when an UPGRADED lock is held.\n        // This helps reduce writer starvation.\n        if value & (WRITER | UPGRADED) != 0 {\n            // Lock is taken, undo.\n            self.lock.fetch_sub(READER, Ordering::Release);\n            None\n        } else {\n            Some(RwLockReadGuard {\n                lock: &self.lock,\n                data: unsafe { NonNull::new_unchecked(self.data.get()) },\n            })\n        }\n    }\n\n    /// Force decrement the reader count.\n    ///\n    /// This is *extremely* unsafe if there are outstanding `RwLockReadGuard`s\n    /// live, or if called more times than `read` has been called, but can be\n    /// useful in FFI contexts where the caller doesn't know how to deal with\n    /// RAII. The underlying atomic operation uses `Ordering::Release`.\n    #[inline]\n    pub unsafe fn force_read_decrement(&self) {\n        debug_assert!(self.lock.load(Ordering::Relaxed) & !WRITER > 0);\n        self.lock.fetch_sub(READER, Ordering::Release);\n    }\n\n    /// Force unlock exclusive write access.\n    ///\n    /// This is *extremely* unsafe if there are outstanding `RwLockWriteGuard`s\n    /// live, or if called when there are current readers, but can be useful in\n    /// FFI contexts where the caller doesn't know how to deal with RAII. The\n    /// underlying atomic operation uses `Ordering::Release`.\n    #[inline]\n    pub unsafe fn force_write_unlock(&self) {\n        debug_assert_eq!(self.lock.load(Ordering::Relaxed) & !(WRITER | UPGRADED), 0);\n        self.lock.fetch_and(!(WRITER | UPGRADED), Ordering::Release);\n    }\n\n    /// Lock this rwlock with exclusive write access, blocking the current\n    /// thread until it can be acquired.\n    ///\n    /// This function will not return while other writers or other readers\n    /// currently have access to the lock.\n    ///\n    /// Returns an RAII guard which will drop the write access of this rwlock\n    /// when dropped.\n    ///\n    /// ```\n    /// let mylock = spin::RwLock::new(0);\n    /// {\n    ///     let mut data = mylock.write();\n    ///     // The lock is now locked and the data can be written\n    ///     *data += 1;\n    ///     // The lock is dropped\n    /// }\n    /// ```\n    #[inline]\n    pub fn write(&self) -> RwLockWriteGuard<T> {\n        loop {\n            // Use compare_exchange_weak as a slight optimisation instead of just calling try_write which\n            // uses compare_exchange (strong) internally.\n            if self\n                .lock\n                .compare_exchange_weak(0, WRITER, Ordering::Acquire, Ordering::Relaxed)\n                .is_ok()\n            {\n                return RwLockWriteGuard {\n                    lock: &self.lock,\n                    data: unsafe { NonNull::new_unchecked(self.data.get()) },\n                    _invariant: PhantomData,\n                };\n            } else {\n                cpu_relax();\n            }\n        }\n    }\n\n    /// Attempt to lock this rwlock with exclusive write access.\n    ///\n    /// This function does not ever block, and it will return `None` if a call\n    /// to `write` would otherwise block. If successful, an RAII guard is\n    /// returned.\n    ///\n    /// ```\n    /// let mylock = spin::RwLock::new(0);\n    /// {\n    ///     match mylock.try_write() {\n    ///         Some(mut data) => {\n    ///             // The lock is now locked and the data can be written\n    ///             *data += 1;\n    ///             // The lock is implicitly dropped\n    ///         },\n    ///         None => (), // no cigar\n    ///     };\n    /// }\n    /// ```\n    #[inline]\n    pub fn try_write(&self) -> Option<RwLockWriteGuard<T>> {\n        if self\n            .lock\n            .compare_exchange(0, WRITER, Ordering::Acquire, Ordering::Relaxed)\n            .is_ok()\n        {\n            Some(RwLockWriteGuard {\n                lock: &self.lock,\n                data: unsafe { NonNull::new_unchecked(self.data.get()) },\n                _invariant: PhantomData,\n            })\n        } else {\n            None\n        }\n    }\n\n    /// Obtain a readable lock guard that can later be upgraded to a writable lock guard.\n    /// Upgrades can be done through the [`RwLockUpgradeableGuard::upgrade`](RwLockUpgradeableGuard::upgrade) method.\n    #[inline]\n    pub fn upgradeable_read(&self) -> RwLockUpgradeableGuard<T> {\n        loop {\n            match self.try_upgradeable_read() {\n                Some(guard) => return guard,\n                None => cpu_relax(),\n            }\n        }\n    }\n\n    /// Tries to obtain an upgradeable lock guard.\n    #[inline]\n    pub fn try_upgradeable_read(&self) -> Option<RwLockUpgradeableGuard<T>> {\n        if self.lock.fetch_or(UPGRADED, Ordering::Acquire) & (WRITER | UPGRADED) == 0 {\n            Some(RwLockUpgradeableGuard {\n                lock: &self.lock,\n                data: unsafe { NonNull::new_unchecked(self.data.get()) },\n                _invariant: PhantomData,\n            })\n        } else {\n            // We can't unflip the UPGRADED bit back just yet as there is another upgradeable or write lock.\n            // When they unlock, they will clear the bit.\n            None\n        }\n    }\n}\n\nimpl<T: ?Sized + fmt::Debug> fmt::Debug for RwLock<T> {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        match self.try_read() {\n            Some(guard) => write!(f, \"RwLock {{ data: \")\n                .and_then(|()| (&*guard).fmt(f))\n                .and_then(|()| write!(f, \"}}\")),\n            None => write!(f, \"RwLock {{ <locked> }}\"),\n        }\n    }\n}\n\nimpl<T: ?Sized + Default> Default for RwLock<T> {\n    fn default() -> RwLock<T> {\n        RwLock::new(Default::default())\n    }\n}\n\nimpl<'rwlock, T: ?Sized> RwLockUpgradeableGuard<'rwlock, T> {\n    /// Upgrades an upgradeable lock guard to a writable lock guard.\n    ///\n    /// ```\n    /// let mylock = spin::RwLock::new(0);\n    ///\n    /// let upgradeable = mylock.upgradeable_read(); // Readable, but not yet writable\n    /// let writable = upgradeable.upgrade();\n    /// ```\n    #[inline]\n    pub fn upgrade(self) -> RwLockWriteGuard<'rwlock, T> {\n        loop {\n            // Use compare_exchange_weak as a slight optimisation instead of just calling try_upgrade which\n            // uses compare_exchange (strong) internally.\n            if self\n                .lock\n                .compare_exchange_weak(UPGRADED, WRITER, Ordering::Acquire, Ordering::Relaxed)\n                .is_ok()\n            {\n                // Upgrade successful\n                let out = RwLockWriteGuard {\n                    lock: self.lock,\n                    data: self.data,\n                    _invariant: PhantomData,\n                };\n\n                // Forget the old guard so its destructor doesn't run\n                mem::forget(self);\n\n                return out;\n            }\n\n            cpu_relax();\n        }\n    }\n\n    /// Tries to upgrade an upgradeable lock guard to a writable lock guard.\n    ///\n    /// ```\n    /// let mylock = spin::RwLock::new(0);\n    /// let upgradeable = mylock.upgradeable_read(); // Readable, but not yet writable\n    ///\n    /// match upgradeable.try_upgrade() {\n    ///     Ok(writable) => /* upgrade successful - use writable lock guard */ (),\n    ///     Err(upgradeable) => /* upgrade unsuccessful */ (),\n    /// };\n    /// ```\n    #[inline]\n    pub fn try_upgrade(self) -> Result<RwLockWriteGuard<'rwlock, T>, Self> {\n        if self\n            .lock\n            .compare_exchange(UPGRADED, WRITER, Ordering::Acquire, Ordering::Relaxed)\n            .is_ok()\n        {\n            // Upgrade successful\n            let out = Ok(RwLockWriteGuard {\n                lock: &self.lock,\n                data: self.data,\n                _invariant: PhantomData,\n            });\n\n            // Forget the old guard so its destructor doesn't run\n            mem::forget(self);\n\n            out\n        } else {\n            Err(self)\n        }\n    }\n\n    #[inline]\n    /// Downgrades the upgradeable lock guard to a readable, shared lock guard. Cannot fail and is guaranteed not to spin.\n    ///\n    /// ```\n    /// let mylock = spin::RwLock::new(1);\n    ///\n    /// let upgradeable = mylock.upgradeable_read();\n    /// assert!(mylock.try_read().is_none());\n    /// assert_eq!(*upgradeable, 1);\n    ///\n    /// let readable = upgradeable.downgrade(); // This is guaranteed not to spin\n    /// assert!(mylock.try_read().is_some());\n    /// assert_eq!(*readable, 1);\n    /// ```\n    pub fn downgrade(self) -> RwLockReadGuard<'rwlock, T> {\n        // Reserve the read guard for ourselves\n        self.lock.fetch_add(READER, Ordering::Acquire);\n\n        RwLockReadGuard {\n            lock: &self.lock,\n            data: self.data,\n        }\n\n        // Dropping self removes the UPGRADED bit\n    }\n}\n\nimpl<'rwlock, T: ?Sized> RwLockWriteGuard<'rwlock, T> {\n    /// Downgrades the writable lock guard to a readable, shared lock guard. Cannot fail and is guaranteed not to spin.\n    ///\n    /// ```\n    /// let mylock = spin::RwLock::new(0);\n    ///\n    /// let mut writable = mylock.write();\n    /// *writable = 1;\n    ///\n    /// let readable = writable.downgrade(); // This is guaranteed not to spin\n    /// # let readable_2 = mylock.try_read().unwrap();\n    /// assert_eq!(*readable, 1);\n    /// ```\n    #[inline]\n    pub fn downgrade(self) -> RwLockReadGuard<'rwlock, T> {\n        // Reserve the read guard for ourselves\n        self.lock.fetch_add(READER, Ordering::Acquire);\n\n        RwLockReadGuard {\n            lock: &self.lock,\n            data: self.data,\n        }\n\n        // Dropping self removes the WRITER bit\n    }\n}\n\nimpl<'rwlock, T: ?Sized> Deref for RwLockReadGuard<'rwlock, T> {\n    type Target = T;\n\n    fn deref(&self) -> &T {\n        unsafe { self.data.as_ref() }\n    }\n}\n\nimpl<'rwlock, T: ?Sized> Deref for RwLockUpgradeableGuard<'rwlock, T> {\n    type Target = T;\n\n    fn deref(&self) -> &T {\n        unsafe { self.data.as_ref() }\n    }\n}\n\nimpl<'rwlock, T: ?Sized> Deref for RwLockWriteGuard<'rwlock, T> {\n    type Target = T;\n\n    fn deref(&self) -> &T {\n        unsafe { self.data.as_ref() }\n    }\n}\n\nimpl<'rwlock, T: ?Sized> DerefMut for RwLockWriteGuard<'rwlock, T> {\n    fn deref_mut(&mut self) -> &mut T {\n        unsafe { self.data.as_mut() }\n    }\n}\n\nimpl<'rwlock, T: ?Sized> Drop for RwLockReadGuard<'rwlock, T> {\n    fn drop(&mut self) {\n        debug_assert!(self.lock.load(Ordering::Relaxed) & !(WRITER | UPGRADED) > 0);\n        self.lock.fetch_sub(READER, Ordering::Release);\n    }\n}\n\nimpl<'rwlock, T: ?Sized> Drop for RwLockUpgradeableGuard<'rwlock, T> {\n    fn drop(&mut self) {\n        debug_assert_eq!(\n            self.lock.load(Ordering::Relaxed) & (WRITER | UPGRADED),\n            UPGRADED\n        );\n        self.lock.fetch_sub(UPGRADED, Ordering::AcqRel);\n    }\n}\n\nimpl<'rwlock, T: ?Sized> Drop for RwLockWriteGuard<'rwlock, T> {\n    fn drop(&mut self) {\n        debug_assert_eq!(self.lock.load(Ordering::Relaxed) & WRITER, WRITER);\n\n        // Writer is responsible for clearing both WRITER and UPGRADED bits.\n        // The UPGRADED bit may be set if an upgradeable lock attempts an upgrade while this lock is held.\n        self.lock.fetch_and(!(WRITER | UPGRADED), Ordering::Release);\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use std::prelude::v1::*;\n\n    use std::sync::atomic::{AtomicUsize, Ordering};\n    use std::sync::mpsc::channel;\n    use std::sync::Arc;\n    use std::thread;\n\n    use super::*;\n\n    #[derive(Eq, PartialEq, Debug)]\n    struct NonCopy(i32);\n\n    #[test]\n    fn smoke() {\n        let l = RwLock::new(());\n        drop(l.read());\n        drop(l.write());\n        drop((l.read(), l.read()));\n        drop(l.write());\n    }\n\n    // TODO: needs RNG\n    //#[test]\n    //fn frob() {\n    //    static R: RwLock = RwLock::new();\n    //    const N: usize = 10;\n    //    const M: usize = 1000;\n    //\n    //    let (tx, rx) = channel::<()>();\n    //    for _ in 0..N {\n    //        let tx = tx.clone();\n    //        thread::spawn(move|| {\n    //            let mut rng = rand::thread_rng();\n    //            for _ in 0..M {\n    //                if rng.gen_weighted_bool(N) {\n    //                    drop(R.write());\n    //                } else {\n    //                    drop(R.read());\n    //                }\n    //            }\n    //            drop(tx);\n    //        });\n    //    }\n    //    drop(tx);\n    //    let _ = rx.recv();\n    //    unsafe { R.destroy(); }\n    //}\n\n    #[test]\n    fn test_rw_arc() {\n        let arc = Arc::new(RwLock::new(0));\n        let arc2 = arc.clone();\n        let (tx, rx) = channel();\n\n        thread::spawn(move || {\n            let mut lock = arc2.write();\n            for _ in 0..10 {\n                let tmp = *lock;\n                *lock = -1;\n                thread::yield_now();\n                *lock = tmp + 1;\n            }\n            tx.send(()).unwrap();\n        });\n\n        // Readers try to catch the writer in the act\n        let mut children = Vec::new();\n        for _ in 0..5 {\n            let arc3 = arc.clone();\n            children.push(thread::spawn(move || {\n                let lock = arc3.read();\n                assert!(*lock >= 0);\n            }));\n        }\n\n        // Wait for children to pass their asserts\n        for r in children {\n            assert!(r.join().is_ok());\n        }\n\n        // Wait for writer to finish\n        rx.recv().unwrap();\n        let lock = arc.read();\n        assert_eq!(*lock, 10);\n    }\n\n    #[test]\n    fn test_rw_access_in_unwind() {\n        let arc = Arc::new(RwLock::new(1));\n        let arc2 = arc.clone();\n        let _ = thread::spawn(move || -> () {\n            struct Unwinder {\n                i: Arc<RwLock<isize>>,\n            }\n            impl Drop for Unwinder {\n                fn drop(&mut self) {\n                    let mut lock = self.i.write();\n                    *lock += 1;\n                }\n            }\n            let _u = Unwinder { i: arc2 };\n            panic!();\n        })\n        .join();\n        let lock = arc.read();\n        assert_eq!(*lock, 2);\n    }\n\n    #[test]\n    fn test_rwlock_unsized() {\n        let rw: &RwLock<[i32]> = &RwLock::new([1, 2, 3]);\n        {\n            let b = &mut *rw.write();\n            b[0] = 4;\n            b[2] = 5;\n        }\n        let comp: &[i32] = &[4, 2, 5];\n        assert_eq!(&*rw.read(), comp);\n    }\n\n    #[test]\n    fn test_rwlock_try_write() {\n        use std::mem::drop;\n\n        let lock = RwLock::new(0isize);\n        let read_guard = lock.read();\n\n        let write_result = lock.try_write();\n        match write_result {\n            None => (),\n            Some(_) => assert!(\n                false,\n                \"try_write should not succeed while read_guard is in scope\"\n            ),\n        }\n\n        drop(read_guard);\n    }\n\n    #[test]\n    fn test_rw_try_read() {\n        let m = RwLock::new(0);\n        mem::forget(m.write());\n        assert!(m.try_read().is_none());\n    }\n\n    #[test]\n    fn test_into_inner() {\n        let m = RwLock::new(NonCopy(10));\n        assert_eq!(m.into_inner(), NonCopy(10));\n    }\n\n    #[test]\n    fn test_into_inner_drop() {\n        struct Foo(Arc<AtomicUsize>);\n        impl Drop for Foo {\n            fn drop(&mut self) {\n                self.0.fetch_add(1, Ordering::SeqCst);\n            }\n        }\n        let num_drops = Arc::new(AtomicUsize::new(0));\n        let m = RwLock::new(Foo(num_drops.clone()));\n        assert_eq!(num_drops.load(Ordering::SeqCst), 0);\n        {\n            let _inner = m.into_inner();\n            assert_eq!(num_drops.load(Ordering::SeqCst), 0);\n        }\n        assert_eq!(num_drops.load(Ordering::SeqCst), 1);\n    }\n\n    #[test]\n    fn test_force_read_decrement() {\n        let m = RwLock::new(());\n        ::std::mem::forget(m.read());\n        ::std::mem::forget(m.read());\n        ::std::mem::forget(m.read());\n        assert!(m.try_write().is_none());\n        unsafe {\n            m.force_read_decrement();\n            m.force_read_decrement();\n        }\n        assert!(m.try_write().is_none());\n        unsafe {\n            m.force_read_decrement();\n        }\n        assert!(m.try_write().is_some());\n    }\n\n    #[test]\n    fn test_force_write_unlock() {\n        let m = RwLock::new(());\n        ::std::mem::forget(m.write());\n        assert!(m.try_read().is_none());\n        unsafe {\n            m.force_write_unlock();\n        }\n        assert!(m.try_read().is_some());\n    }\n\n    #[test]\n    fn test_upgrade_downgrade() {\n        let m = RwLock::new(());\n        {\n            let _r = m.read();\n            let upg = m.try_upgradeable_read().unwrap();\n            assert!(m.try_read().is_none());\n            assert!(m.try_write().is_none());\n            assert!(upg.try_upgrade().is_err());\n        }\n        {\n            let w = m.write();\n            assert!(m.try_upgradeable_read().is_none());\n            let _r = w.downgrade();\n            assert!(m.try_upgradeable_read().is_some());\n            assert!(m.try_read().is_some());\n            assert!(m.try_write().is_none());\n        }\n        {\n            let _u = m.upgradeable_read();\n            assert!(m.try_upgradeable_read().is_none());\n        }\n\n        assert!(m.try_upgradeable_read().unwrap().try_upgrade().is_ok());\n    }\n}\n"
  },
  {
    "project": "rust-smallvec",
    "target": 1,
    "commit_id": "88b62b65fae5bc144d9e9cacf0778c8ed1ed509b",
    "func": "// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n// option. This file may not be copied, modified, or distributed\n// except according to those terms.\n\n//! Small vectors in various sizes. These store a certain number of elements inline, and fall back\n//! to the heap for larger allocations.  This can be a useful optimization for improving cache\n//! locality and reducing allocator traffic for workloads that fit within the inline buffer.\n//!\n//! ## no_std support\n//!\n//! By default, `smallvec` depends on `libstd`. However, it can be configured to use the unstable\n//! `liballoc` API instead, for use on platforms that have `liballoc` but not `libstd`.  This\n//! configuration is currently unstable and is not guaranteed to work on all versions of Rust.\n//!\n//! To depend on `smallvec` without `libstd`, use `default-features = false` in the `smallvec`\n//! section of Cargo.toml to disable its `\"std\"` feature.\n//!\n//! ## `union` feature\n//!\n//! When the `union` feature is enabled `smallvec` will track its state (inline or spilled)\n//! without the use of an enum tag, reducing the size of the `smallvec` by one machine word.\n//! This means that there is potentially no space overhead compared to `Vec`.\n//! Note that `smallvec` can still be larger than `Vec` if the inline buffer is larger than two\n//! machine words.\n//!\n//! To use this feature add `features = [\"union\"]` in the `smallvec` section of Cargo.toml.\n//! Note that this feature requires a nightly compiler (for now).\n\n#![cfg_attr(not(feature = \"std\"), no_std)]\n#![cfg_attr(not(feature = \"std\"), feature(alloc))]\n#![cfg_attr(feature = \"union\", feature(untagged_unions))]\n#![cfg_attr(feature = \"specialization\", feature(specialization))]\n#![cfg_attr(feature = \"may_dangle\", feature(dropck_eyepatch))]\n#![deny(missing_docs)]\n\n\n#[cfg(not(feature = \"std\"))]\n#[macro_use]\nextern crate alloc;\n\n#[cfg(not(feature = \"std\"))]\nuse alloc::vec::Vec;\n\n#[cfg(feature = \"serde\")]\nextern crate serde;\n\n#[cfg(not(feature = \"std\"))]\nmod std {\n    pub use core::*;\n}\n\nuse std::borrow::{Borrow, BorrowMut};\nuse std::cmp;\nuse std::fmt;\nuse std::hash::{Hash, Hasher};\nuse std::iter::{IntoIterator, FromIterator, repeat};\nuse std::mem;\nuse std::mem::ManuallyDrop;\nuse std::ops;\nuse std::ptr;\nuse std::slice;\n#[cfg(feature = \"std\")]\nuse std::io;\n#[cfg(feature = \"serde\")]\nuse serde::ser::{Serialize, Serializer, SerializeSeq};\n#[cfg(feature = \"serde\")]\nuse serde::de::{Deserialize, Deserializer, SeqAccess, Visitor};\n#[cfg(feature = \"serde\")]\nuse std::marker::PhantomData;\n\n/// Creates a [`SmallVec`] containing the arguments.\n///\n/// `smallvec!` allows `SmallVec`s to be defined with the same syntax as array expressions.\n/// There are two forms of this macro:\n///\n/// - Create a [`SmallVec`] containing a given list of elements:\n///\n/// ```\n/// # #[macro_use] extern crate smallvec;\n/// # use smallvec::SmallVec;\n/// # fn main() {\n/// let v: SmallVec<[_; 128]> = smallvec![1, 2, 3];\n/// assert_eq!(v[0], 1);\n/// assert_eq!(v[1], 2);\n/// assert_eq!(v[2], 3);\n/// # }\n/// ```\n///\n/// - Create a [`SmallVec`] from a given element and size:\n///\n/// ```\n/// # #[macro_use] extern crate smallvec;\n/// # use smallvec::SmallVec;\n/// # fn main() {\n/// let v: SmallVec<[_; 0x8000]> = smallvec![1; 3];\n/// assert_eq!(v, SmallVec::from_buf([1, 1, 1]));\n/// # }\n/// ```\n///\n/// Note that unlike array expressions this syntax supports all elements\n/// which implement [`Clone`] and the number of elements doesn't have to be\n/// a constant.\n///\n/// This will use `clone` to duplicate an expression, so one should be careful\n/// using this with types having a nonstandard `Clone` implementation. For\n/// example, `smallvec![Rc::new(1); 5]` will create a vector of five references\n/// to the same boxed integer value, not five references pointing to independently\n/// boxed integers.\n\n#[macro_export]\nmacro_rules! smallvec {\n    // count helper: transform any expression into 1\n    (@one $x:expr) => (1usize);\n    ($elem:expr; $n:expr) => ({\n        $crate::SmallVec::from_elem($elem, $n)\n    });\n    ($($x:expr),*$(,)*) => ({\n        let count = 0usize $(+ smallvec!(@one $x))*;\n        let mut vec = $crate::SmallVec::new();\n        if count <= vec.inline_size() {\n            $(vec.push($x);)*\n            vec\n        } else {\n            $crate::SmallVec::from_vec(vec![$($x,)*])\n        }\n    });\n}\n\n/// Hint to the optimizer that any code path which calls this function is\n/// statically unreachable and can be removed.\n///\n/// Equivalent to `std::hint::unreachable_unchecked` but works in older versions of Rust.\n#[inline]\npub unsafe fn unreachable() -> ! {\n    enum Void {}\n    let x: &Void = mem::transmute(1usize);\n    match *x {}\n}\n\n/// `panic!()` in debug builds, optimization hint in release.\n#[cfg(not(feature = \"union\"))]\nmacro_rules! debug_unreachable {\n    () => { debug_unreachable!(\"entered unreachable code\") };\n    ($e:expr) => {\n        if cfg!(not(debug_assertions)) {\n            unreachable();\n        } else {\n            panic!($e);\n        }\n    }\n}\n\n/// Common operations implemented by both `Vec` and `SmallVec`.\n///\n/// This can be used to write generic code that works with both `Vec` and `SmallVec`.\n///\n/// ## Example\n///\n/// ```rust\n/// use smallvec::{VecLike, SmallVec};\n///\n/// fn initialize<V: VecLike<u8>>(v: &mut V) {\n///     for i in 0..5 {\n///         v.push(i);\n///     }\n/// }\n///\n/// let mut vec = Vec::new();\n/// initialize(&mut vec);\n///\n/// let mut small_vec = SmallVec::<[u8; 8]>::new();\n/// initialize(&mut small_vec);\n/// ```\n#[deprecated(note = \"Use `Extend` and `Deref<[T]>` instead\")]\npub trait VecLike<T>:\n        ops::Index<usize, Output=T> +\n        ops::IndexMut<usize> +\n        ops::Index<ops::Range<usize>, Output=[T]> +\n        ops::IndexMut<ops::Range<usize>> +\n        ops::Index<ops::RangeFrom<usize>, Output=[T]> +\n        ops::IndexMut<ops::RangeFrom<usize>> +\n        ops::Index<ops::RangeTo<usize>, Output=[T]> +\n        ops::IndexMut<ops::RangeTo<usize>> +\n        ops::Index<ops::RangeFull, Output=[T]> +\n        ops::IndexMut<ops::RangeFull> +\n        ops::DerefMut<Target = [T]> +\n        Extend<T> {\n\n    /// Append an element to the vector.\n    fn push(&mut self, value: T);\n}\n\n#[allow(deprecated)]\nimpl<T> VecLike<T> for Vec<T> {\n    #[inline]\n    fn push(&mut self, value: T) {\n        Vec::push(self, value);\n    }\n}\n\n/// Trait to be implemented by a collection that can be extended from a slice\n///\n/// ## Example\n///\n/// ```rust\n/// use smallvec::{ExtendFromSlice, SmallVec};\n///\n/// fn initialize<V: ExtendFromSlice<u8>>(v: &mut V) {\n///     v.extend_from_slice(b\"Test!\");\n/// }\n///\n/// let mut vec = Vec::new();\n/// initialize(&mut vec);\n/// assert_eq!(&vec, b\"Test!\");\n///\n/// let mut small_vec = SmallVec::<[u8; 8]>::new();\n/// initialize(&mut small_vec);\n/// assert_eq!(&small_vec as &[_], b\"Test!\");\n/// ```\npub trait ExtendFromSlice<T> {\n    /// Extends a collection from a slice of its element type\n    fn extend_from_slice(&mut self, other: &[T]);\n}\n\nimpl<T: Clone> ExtendFromSlice<T> for Vec<T> {\n    fn extend_from_slice(&mut self, other: &[T]) {\n        Vec::extend_from_slice(self, other)\n    }\n}\n\nunsafe fn deallocate<T>(ptr: *mut T, capacity: usize) {\n    let _vec: Vec<T> = Vec::from_raw_parts(ptr, 0, capacity);\n    // Let it drop.\n}\n\n/// An iterator that removes the items from a `SmallVec` and yields them by value.\n///\n/// Returned from [`SmallVec::drain`][1].\n///\n/// [1]: struct.SmallVec.html#method.drain\npub struct Drain<'a, T: 'a> {\n    iter: slice::IterMut<'a,T>,\n}\n\nimpl<'a, T: 'a> Iterator for Drain<'a,T> {\n    type Item = T;\n\n    #[inline]\n    fn next(&mut self) -> Option<T> {\n        self.iter.next().map(|reference| unsafe { ptr::read(reference) })\n    }\n\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.iter.size_hint()\n    }\n}\n\nimpl<'a, T: 'a> DoubleEndedIterator for Drain<'a, T> {\n    #[inline]\n    fn next_back(&mut self) -> Option<T> {\n        self.iter.next_back().map(|reference| unsafe { ptr::read(reference) })\n    }\n}\n\nimpl<'a, T> ExactSizeIterator for Drain<'a, T> { }\n\nimpl<'a, T: 'a> Drop for Drain<'a,T> {\n    fn drop(&mut self) {\n        // Destroy the remaining elements.\n        for _ in self.by_ref() {}\n    }\n}\n\n#[cfg(feature = \"union\")]\nunion SmallVecData<A: Array> {\n    inline: ManuallyDrop<A>,\n    heap: (*mut A::Item, usize),\n}\n\n#[cfg(feature = \"union\")]\nimpl<A: Array> SmallVecData<A> {\n    #[inline]\n    unsafe fn inline(&self) -> &A {\n        &self.inline\n    }\n    #[inline]\n    unsafe fn inline_mut(&mut self) -> &mut A {\n        &mut self.inline\n    }\n    #[inline]\n    fn from_inline(inline: A) -> SmallVecData<A> {\n        SmallVecData { inline: ManuallyDrop::new(inline) }\n    }\n    #[inline]\n    unsafe fn into_inline(self) -> A { ManuallyDrop::into_inner(self.inline) }\n    #[inline]\n    unsafe fn heap(&self) -> (*mut A::Item, usize) {\n        self.heap\n    }\n    #[inline]\n    unsafe fn heap_mut(&mut self) -> &mut (*mut A::Item, usize) {\n        &mut self.heap\n    }\n    #[inline]\n    fn from_heap(ptr: *mut A::Item, len: usize) -> SmallVecData<A> {\n        SmallVecData { heap: (ptr, len) }\n    }\n}\n\n#[cfg(not(feature = \"union\"))]\nenum SmallVecData<A: Array> {\n    Inline(ManuallyDrop<A>),\n    Heap((*mut A::Item, usize)),\n}\n\n#[cfg(not(feature = \"union\"))]\nimpl<A: Array> SmallVecData<A> {\n    #[inline]\n    unsafe fn inline(&self) -> &A {\n        match *self {\n            SmallVecData::Inline(ref a) => a,\n            _ => debug_unreachable!(),\n        }\n    }\n    #[inline]\n    unsafe fn inline_mut(&mut self) -> &mut A {\n        match *self {\n            SmallVecData::Inline(ref mut a) => a,\n            _ => debug_unreachable!(),\n        }\n    }\n    #[inline]\n    fn from_inline(inline: A) -> SmallVecData<A> {\n        SmallVecData::Inline(ManuallyDrop::new(inline))\n    }\n    #[inline]\n    unsafe fn into_inline(self) -> A {\n        match self {\n            SmallVecData::Inline(a) => ManuallyDrop::into_inner(a),\n            _ => debug_unreachable!(),\n        }\n    }\n    #[inline]\n    unsafe fn heap(&self) -> (*mut A::Item, usize) {\n        match *self {\n            SmallVecData::Heap(data) => data,\n            _ => debug_unreachable!(),\n        }\n    }\n    #[inline]\n    unsafe fn heap_mut(&mut self) -> &mut (*mut A::Item, usize) {\n        match *self {\n            SmallVecData::Heap(ref mut data) => data,\n            _ => debug_unreachable!(),\n        }\n    }\n    #[inline]\n    fn from_heap(ptr: *mut A::Item, len: usize) -> SmallVecData<A> {\n        SmallVecData::Heap((ptr, len))\n    }\n}\n\nunsafe impl<A: Array + Send> Send for SmallVecData<A> {}\nunsafe impl<A: Array + Sync> Sync for SmallVecData<A> {}\n\n/// A `Vec`-like container that can store a small number of elements inline.\n///\n/// `SmallVec` acts like a vector, but can store a limited amount of data inline within the\n/// `SmallVec` struct rather than in a separate allocation.  If the data exceeds this limit, the\n/// `SmallVec` will \"spill\" its data onto the heap, allocating a new buffer to hold it.\n///\n/// The amount of data that a `SmallVec` can store inline depends on its backing store. The backing\n/// store can be any type that implements the `Array` trait; usually it is a small fixed-sized\n/// array.  For example a `SmallVec<[u64; 8]>` can hold up to eight 64-bit integers inline.\n///\n/// ## Example\n///\n/// ```rust\n/// use smallvec::SmallVec;\n/// let mut v = SmallVec::<[u8; 4]>::new(); // initialize an empty vector\n///\n/// // The vector can hold up to 4 items without spilling onto the heap.\n/// v.extend(0..4);\n/// assert_eq!(v.len(), 4);\n/// assert!(!v.spilled());\n///\n/// // Pushing another element will force the buffer to spill:\n/// v.push(4);\n/// assert_eq!(v.len(), 5);\n/// assert!(v.spilled());\n/// ```\npub struct SmallVec<A: Array> {\n    // The capacity field is used to determine which of the storage variants is active:\n    // If capacity <= A::size() then the inline variant is used and capacity holds the current length of the vector (number of elements actually in use).\n    // If capacity > A::size() then the heap variant is used and capacity holds the size of the memory allocation.\n    capacity: usize,\n    data: SmallVecData<A>,\n}\n\nimpl<A: Array> SmallVec<A> {\n    /// Construct an empty vector\n    #[inline]\n    pub fn new() -> SmallVec<A> {\n        unsafe {\n            SmallVec {\n                capacity: 0,\n                data: SmallVecData::from_inline(mem::uninitialized()),\n            }\n        }\n    }\n\n    /// Construct an empty vector with enough capacity pre-allocated to store at least `n`\n    /// elements.\n    ///\n    /// Will create a heap allocation only if `n` is larger than the inline capacity.\n    ///\n    /// ```\n    /// # use smallvec::SmallVec;\n    ///\n    /// let v: SmallVec<[u8; 3]> = SmallVec::with_capacity(100);\n    ///\n    /// assert!(v.is_empty());\n    /// assert!(v.capacity() >= 100);\n    /// ```\n    #[inline]\n    pub fn with_capacity(n: usize) -> Self {\n        let mut v = SmallVec::new();\n        v.reserve_exact(n);\n        v\n    }\n\n    /// Construct a new `SmallVec` from a `Vec<A::Item>`.\n    ///\n    /// Elements will be copied to the inline buffer if vec.capacity() <= A::size().\n    ///\n    /// ```rust\n    /// use smallvec::SmallVec;\n    ///\n    /// let vec = vec![1, 2, 3, 4, 5];\n    /// let small_vec: SmallVec<[_; 3]> = SmallVec::from_vec(vec);\n    ///\n    /// assert_eq!(&*small_vec, &[1, 2, 3, 4, 5]);\n    /// ```\n    #[inline]\n    pub fn from_vec(mut vec: Vec<A::Item>) -> SmallVec<A> {\n        if vec.capacity() <= A::size() {\n            unsafe {\n                let mut data = SmallVecData::<A>::from_inline(mem::uninitialized());\n                let len = vec.len();\n                vec.set_len(0);\n                ptr::copy_nonoverlapping(vec.as_ptr(), data.inline_mut().ptr_mut(), len);\n\n                SmallVec {\n                    capacity: len,\n                    data,\n                }\n            }\n        } else {\n            let (ptr, cap, len) = (vec.as_mut_ptr(), vec.capacity(), vec.len());\n            mem::forget(vec);\n\n            SmallVec {\n                capacity: cap,\n                data: SmallVecData::from_heap(ptr, len),\n            }\n        }\n    }\n\n    /// Constructs a new `SmallVec` on the stack from an `A` without\n    /// copying elements.\n    ///\n    /// ```rust\n    /// use smallvec::SmallVec;\n    ///\n    /// let buf = [1, 2, 3, 4, 5];\n    /// let small_vec: SmallVec<_> = SmallVec::from_buf(buf);\n    ///\n    /// assert_eq!(&*small_vec, &[1, 2, 3, 4, 5]);\n    /// ```\n    #[inline]\n    pub fn from_buf(buf: A) -> SmallVec<A> {\n        SmallVec {\n            capacity: A::size(),\n            data: SmallVecData::from_inline(buf),\n        }\n    }\n\n    /// Constructs a new `SmallVec` on the stack from an `A` without\n    /// copying elements. Also sets the length, which must be less or\n    /// equal to the size of `buf`.\n    ///\n    /// ```rust\n    /// use smallvec::SmallVec;\n    ///\n    /// let buf = [1, 2, 3, 4, 5, 0, 0, 0];\n    /// let small_vec: SmallVec<_> = SmallVec::from_buf_and_len(buf, 5);\n    ///\n    /// assert_eq!(&*small_vec, &[1, 2, 3, 4, 5]);\n    /// ```\n    #[inline]\n    pub fn from_buf_and_len(buf: A, len: usize) -> SmallVec<A> {\n        assert!(len <= A::size());\n        unsafe { SmallVec::from_buf_and_len_unchecked(buf, len) }\n    }\n\n    /// Constructs a new `SmallVec` on the stack from an `A` without\n    /// copying elements. Also sets the length. The user is responsible\n    /// for ensuring that `len <= A::size()`.\n    ///\n    /// ```rust\n    /// use smallvec::SmallVec;\n    ///\n    /// let buf = [1, 2, 3, 4, 5, 0, 0, 0];\n    /// let small_vec: SmallVec<_> = unsafe {\n    ///     SmallVec::from_buf_and_len_unchecked(buf, 5)\n    /// };\n    ///\n    /// assert_eq!(&*small_vec, &[1, 2, 3, 4, 5]);\n    /// ```\n    #[inline]\n    pub unsafe fn from_buf_and_len_unchecked(buf: A, len: usize) -> SmallVec<A> {\n        SmallVec {\n            capacity: len,\n            data: SmallVecData::from_inline(buf),\n        }\n    }\n\n\n    /// Sets the length of a vector.\n    ///\n    /// This will explicitly set the size of the vector, without actually\n    /// modifying its buffers, so it is up to the caller to ensure that the\n    /// vector is actually the specified size.\n    pub unsafe fn set_len(&mut self, new_len: usize) {\n        let (_, len_ptr, _) = self.triple_mut();\n        *len_ptr = new_len;\n    }\n\n    /// The maximum number of elements this vector can hold inline\n    #[inline]\n    pub fn inline_size(&self) -> usize {\n        A::size()\n    }\n\n    /// The number of elements stored in the vector\n    #[inline]\n    pub fn len(&self) -> usize {\n        self.triple().1\n    }\n\n    /// Returns `true` if the vector is empty\n    #[inline]\n    pub fn is_empty(&self) -> bool {\n        self.len() == 0\n    }\n\n    /// The number of items the vector can hold without reallocating\n    #[inline]\n    pub fn capacity(&self) -> usize {\n        self.triple().2\n    }\n\n    /// Returns a tuple with (data ptr, len, capacity)\n    /// Useful to get all SmallVec properties with a single check of the current storage variant.\n    #[inline]\n    fn triple(&self) -> (*const A::Item, usize, usize) {\n        unsafe {\n            if self.spilled() {\n                let (ptr, len) = self.data.heap();\n                (ptr, len, self.capacity)\n            } else {\n                (self.data.inline().ptr(), self.capacity, A::size())\n            }\n        }\n    }\n\n    /// Returns a tuple with (data ptr, len ptr, capacity)\n    #[inline]\n    fn triple_mut(&mut self) -> (*mut A::Item, &mut usize, usize) {\n        unsafe {\n            if self.spilled() {\n                let &mut (ptr, ref mut len_ptr) = self.data.heap_mut();\n                (ptr, len_ptr, self.capacity)\n            } else {\n                (self.data.inline_mut().ptr_mut(), &mut self.capacity, A::size())\n            }\n        }\n    }\n\n    /// Returns `true` if the data has spilled into a separate heap-allocated buffer.\n    #[inline]\n    pub fn spilled(&self) -> bool {\n        self.capacity > A::size()\n    }\n\n    /// Empty the vector and return an iterator over its former contents.\n    pub fn drain(&mut self) -> Drain<A::Item> {\n        unsafe {\n            let ptr = self.as_mut_ptr();\n\n            let current_len = self.len();\n            self.set_len(0);\n\n            let slice = slice::from_raw_parts_mut(ptr, current_len);\n\n            Drain {\n                iter: slice.iter_mut(),\n            }\n        }\n    }\n\n    /// Append an item to the vector.\n    #[inline]\n    pub fn push(&mut self, value: A::Item) {\n        unsafe {\n            let (_, &mut len, cap) = self.triple_mut();\n            if len == cap {\n                self.reserve(1);\n            }\n            let (ptr, len_ptr, _) = self.triple_mut();\n            *len_ptr = len + 1;\n            ptr::write(ptr.offset(len as isize), value);\n        }\n    }\n\n    /// Remove an item from the end of the vector and return it, or None if empty.\n    #[inline]\n    pub fn pop(&mut self) -> Option<A::Item> {\n        unsafe {\n            let (ptr, len_ptr, _) = self.triple_mut();\n            if *len_ptr == 0 {\n                return None;\n            }\n            let last_index = *len_ptr - 1;\n            *len_ptr = last_index;\n            Some(ptr::read(ptr.offset(last_index as isize)))\n        }\n    }\n\n    /// Re-allocate to set the capacity to `max(new_cap, inline_size())`.\n    ///\n    /// Panics if `new_cap` is less than the vector's length.\n    pub fn grow(&mut self, new_cap: usize) {\n        unsafe {\n            let (ptr, &mut len, cap) = self.triple_mut();\n            let unspilled = !self.spilled();\n            assert!(new_cap >= len);\n            if new_cap <= self.inline_size() {\n                if unspilled {\n                    return;\n                }\n                self.data = SmallVecData::from_inline(mem::uninitialized());\n                ptr::copy_nonoverlapping(ptr, self.data.inline_mut().ptr_mut(), len);\n                self.capacity = len;\n            } else if new_cap != cap {\n                let mut vec = Vec::with_capacity(new_cap);\n                let new_alloc = vec.as_mut_ptr();\n                mem::forget(vec);\n                ptr::copy_nonoverlapping(ptr, new_alloc, len);\n                self.data = SmallVecData::from_heap(new_alloc, len);\n                self.capacity = new_cap;\n                if unspilled {\n                    return;\n                }\n            }\n            deallocate(ptr, cap);\n        }\n    }\n\n    /// Reserve capacity for `additional` more elements to be inserted.\n    ///\n    /// May reserve more space to avoid frequent reallocations.\n    ///\n    /// If the new capacity would overflow `usize` then it will be set to `usize::max_value()`\n    /// instead. (This means that inserting `additional` new elements is not guaranteed to be\n    /// possible after calling this function.)\n    #[inline]\n    pub fn reserve(&mut self, additional: usize) {\n        // prefer triple_mut() even if triple() would work\n        // so that the optimizer removes duplicated calls to it\n        // from callers like insert()\n        let (_, &mut len, cap) = self.triple_mut();\n        if cap - len < additional {\n            let new_cap = len.checked_add(additional).\n                and_then(usize::checked_next_power_of_two).\n                unwrap_or(usize::max_value());\n            self.grow(new_cap);\n        }\n    }\n\n    /// Reserve the minimum capacity for `additional` more elements to be inserted.\n    ///\n    /// Panics if the new capacity overflows `usize`.\n    pub fn reserve_exact(&mut self, additional: usize) {\n        let (_, &mut len, cap) = self.triple_mut();\n        if cap - len < additional {\n            match len.checked_add(additional) {\n                Some(cap) => self.grow(cap),\n                None => panic!(\"reserve_exact overflow\"),\n            }\n        }\n    }\n\n    /// Shrink the capacity of the vector as much as possible.\n    ///\n    /// When possible, this will move data from an external heap buffer to the vector's inline\n    /// storage.\n    pub fn shrink_to_fit(&mut self) {\n        if !self.spilled() {\n            return;\n        }\n        let len = self.len();\n        if self.inline_size() >= len {\n            unsafe {\n                let (ptr, len) = self.data.heap();\n                self.data = SmallVecData::from_inline(mem::uninitialized());\n                ptr::copy_nonoverlapping(ptr, self.data.inline_mut().ptr_mut(), len);\n                deallocate(ptr, self.capacity);\n                self.capacity = len;\n            }\n        } else if self.capacity() > len {\n            self.grow(len);\n        }\n    }\n\n    /// Shorten the vector, keeping the first `len` elements and dropping the rest.\n    ///\n    /// If `len` is greater than or equal to the vector's current length, this has no\n    /// effect.\n    ///\n    /// This does not re-allocate.  If you want the vector's capacity to shrink, call\n    /// `shrink_to_fit` after truncating.\n    pub fn truncate(&mut self, len: usize) {\n        unsafe {\n            let (ptr, len_ptr, _) = self.triple_mut();\n            while len < *len_ptr {\n                let last_index = *len_ptr - 1;\n                *len_ptr = last_index;\n                ptr::drop_in_place(ptr.offset(last_index as isize));\n            }\n        }\n    }\n\n    /// Extracts a slice containing the entire vector.\n    ///\n    /// Equivalent to `&s[..]`.\n    pub fn as_slice(&self) -> &[A::Item] {\n        self\n    }\n\n    /// Extracts a mutable slice of the entire vector.\n    ///\n    /// Equivalent to `&mut s[..]`.\n    pub fn as_mut_slice(&mut self) -> &mut [A::Item] {\n        self\n    }\n\n    /// Remove the element at position `index`, replacing it with the last element.\n    ///\n    /// This does not preserve ordering, but is O(1).\n    ///\n    /// Panics if `index` is out of bounds.\n    #[inline]\n    pub fn swap_remove(&mut self, index: usize) -> A::Item {\n        let len = self.len();\n        self.swap(len - 1, index);\n        self.pop().unwrap_or_else(|| unsafe { unreachable() })\n    }\n\n    /// Remove all elements from the vector.\n    #[inline]\n    pub fn clear(&mut self) {\n        self.truncate(0);\n    }\n\n    /// Remove and return the element at position `index`, shifting all elements after it to the\n    /// left.\n    ///\n    /// Panics if `index` is out of bounds.\n    pub fn remove(&mut self, index: usize) -> A::Item {\n        unsafe {\n            let (mut ptr, len_ptr, _) = self.triple_mut();\n            let len = *len_ptr;\n            assert!(index < len);\n            *len_ptr = len - 1;\n            ptr = ptr.offset(index as isize);\n            let item = ptr::read(ptr);\n            ptr::copy(ptr.offset(1), ptr, len - index - 1);\n            item\n        }\n    }\n\n    /// Insert an element at position `index`, shifting all elements after it to the right.\n    ///\n    /// Panics if `index` is out of bounds.\n    pub fn insert(&mut self, index: usize, element: A::Item) {\n        self.reserve(1);\n\n        unsafe {\n            let (mut ptr, len_ptr, _) = self.triple_mut();\n            let len = *len_ptr;\n            assert!(index <= len);\n            *len_ptr = len + 1;\n            ptr = ptr.offset(index as isize);\n            ptr::copy(ptr, ptr.offset(1), len - index);\n            ptr::write(ptr, element);\n        }\n    }\n\n    /// Insert multiple elements at position `index`, shifting all following elements toward the\n    /// back.\n    pub fn insert_many<I: IntoIterator<Item=A::Item>>(&mut self, index: usize, iterable: I) {\n        let iter = iterable.into_iter();\n        if index == self.len() {\n            return self.extend(iter);\n        }\n\n        let (lower_size_bound, _) = iter.size_hint();\n        assert!(lower_size_bound <= std::isize::MAX as usize);  // Ensure offset is indexable\n        assert!(index + lower_size_bound >= index);  // Protect against overflow\n        self.reserve(lower_size_bound);\n\n        unsafe {\n            let old_len = self.len();\n            assert!(index <= old_len);\n            let mut ptr = self.as_mut_ptr().offset(index as isize);\n\n            // Move the trailing elements.\n            ptr::copy(ptr, ptr.offset(lower_size_bound as isize), old_len - index);\n\n            // In case the iterator panics, don't double-drop the items we just copied above.\n            self.set_len(index);\n\n            let mut num_added = 0;\n            for element in iter {\n                let mut cur = ptr.offset(num_added as isize);\n                if num_added >= lower_size_bound {\n                    // Iterator provided more elements than the hint.  Move trailing items again.\n                    self.reserve(1);\n                    ptr = self.as_mut_ptr().offset(index as isize);\n                    cur = ptr.offset(num_added as isize);\n                    ptr::copy(cur, cur.offset(1), old_len - index);\n                }\n                ptr::write(cur, element);\n                num_added += 1;\n            }\n            if num_added < lower_size_bound {\n                // Iterator provided fewer elements than the hint\n                ptr::copy(ptr.offset(lower_size_bound as isize), ptr.offset(num_added as isize), old_len - index);\n            }\n\n            self.set_len(old_len + num_added);\n        }\n    }\n\n    /// Convert a SmallVec to a Vec, without reallocating if the SmallVec has already spilled onto\n    /// the heap.\n    pub fn into_vec(self) -> Vec<A::Item> {\n        if self.spilled() {\n            unsafe {\n                let (ptr, len) = self.data.heap();\n                let v = Vec::from_raw_parts(ptr, len, self.capacity);\n                mem::forget(self);\n                v\n            }\n        } else {\n            self.into_iter().collect()\n        }\n    }\n\n    /// Convert the SmallVec into an `A` if possible. Otherwise return `Err(Self)`.\n    ///\n    /// This method returns `Err(Self)` if the SmallVec is too short (and the `A` contains uninitialized elements),\n    /// or if the SmallVec is too long (and all the elements were spilled to the heap).\n    pub fn into_inner(self) -> Result<A, Self> {\n        if self.spilled() || self.len() != A::size() {\n            Err(self)\n        } else {\n            unsafe {\n                let data = ptr::read(&self.data);\n                mem::forget(self);\n                Ok(data.into_inline())\n            }\n        }\n    }\n\n    /// Retains only the elements specified by the predicate.\n    ///\n    /// In other words, remove all elements `e` such that `f(&e)` returns `false`.\n    /// This method operates in place and preserves the order of the retained\n    /// elements.\n    pub fn retain<F: FnMut(&mut A::Item) -> bool>(&mut self, mut f: F) {\n        let mut del = 0;\n        let len = self.len();\n        for i in 0..len {\n            if !f(&mut self[i]) {\n                del += 1;\n            } else if del > 0 {\n                self.swap(i - del, i);\n            }\n        }\n        self.truncate(len - del);\n    }\n\n    /// Removes consecutive duplicate elements.\n    pub fn dedup(&mut self) where A::Item: PartialEq<A::Item> {\n        self.dedup_by(|a, b| a == b);\n    }\n\n    /// Removes consecutive duplicate elements using the given equality relation.\n    pub fn dedup_by<F>(&mut self, mut same_bucket: F)\n        where F: FnMut(&mut A::Item, &mut A::Item) -> bool\n    {\n        // See the implementation of Vec::dedup_by in the\n        // standard library for an explanation of this algorithm.\n        let len = self.len();\n        if len <= 1 {\n            return;\n        }\n\n        let ptr = self.as_mut_ptr();\n        let mut w: usize = 1;\n\n        unsafe {\n            for r in 1..len {\n                let p_r = ptr.offset(r as isize);\n                let p_wm1 = ptr.offset((w - 1) as isize);\n                if !same_bucket(&mut *p_r, &mut *p_wm1) {\n                    if r != w {\n                        let p_w = p_wm1.offset(1);\n                        mem::swap(&mut *p_r, &mut *p_w);\n                    }\n                    w += 1;\n                }\n            }\n        }\n\n        self.truncate(w);\n    }\n\n    /// Removes consecutive elements that map to the same key.\n    pub fn dedup_by_key<F, K>(&mut self, mut key: F)\n        where F: FnMut(&mut A::Item) -> K,\n              K: PartialEq<K>\n    {\n        self.dedup_by(|a, b| key(a) == key(b));\n    }\n\n    /// Creates a `SmallVec` directly from the raw components of another\n    /// `SmallVec`.\n    ///\n    /// # Safety\n    ///\n    /// This is highly unsafe, due to the number of invariants that aren't\n    /// checked:\n    ///\n    /// * `ptr` needs to have been previously allocated via `SmallVec` for its\n    ///   spilled storage (at least, it's highly likely to be incorrect if it\n    ///   wasn't).\n    /// * `ptr`'s `A::Item` type needs to be the same size and alignment that\n    ///   it was allocated with\n    /// * `length` needs to be less than or equal to `capacity`.\n    /// * `capacity` needs to be the capacity that the pointer was allocated\n    ///   with.\n    ///\n    /// Violating these may cause problems like corrupting the allocator's\n    /// internal data structures.\n    ///\n    /// Additionally, `capacity` must be greater than the amount of inline\n    /// storage `A` has; that is, the new `SmallVec` must need to spill over\n    /// into heap allocated storage. This condition is asserted against.\n    ///\n    /// The ownership of `ptr` is effectively transferred to the\n    /// `SmallVec` which may then deallocate, reallocate or change the\n    /// contents of memory pointed to by the pointer at will. Ensure\n    /// that nothing else uses the pointer after calling this\n    /// function.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[macro_use] extern crate smallvec;\n    /// # use smallvec::SmallVec;\n    /// use std::mem;\n    /// use std::ptr;\n    ///\n    /// fn main() {\n    ///     let mut v: SmallVec<[_; 1]> = smallvec![1, 2, 3];\n    ///\n    ///     // Pull out the important parts of `v`.\n    ///     let p = v.as_mut_ptr();\n    ///     let len = v.len();\n    ///     let cap = v.capacity();\n    ///     let spilled = v.spilled();\n    ///\n    ///     unsafe {\n    ///         // Forget all about `v`. The heap allocation that stored the\n    ///         // three values won't be deallocated.\n    ///         mem::forget(v);\n    ///\n    ///         // Overwrite memory with [4, 5, 6].\n    ///         //\n    ///         // This is only safe if `spilled` is true! Otherwise, we are\n    ///         // writing into the old `SmallVec`'s inline storage on the\n    ///         // stack.\n    ///         assert!(spilled);\n    ///         for i in 0..len as isize {\n    ///             ptr::write(p.offset(i), 4 + i);\n    ///         }\n    ///\n    ///         // Put everything back together into a SmallVec with a different\n    ///         // amount of inline storage, but which is still less than `cap`.\n    ///         let rebuilt = SmallVec::<[_; 2]>::from_raw_parts(p, len, cap);\n    ///         assert_eq!(&*rebuilt, &[4, 5, 6]);\n    ///     }\n    /// }\n    pub unsafe fn from_raw_parts(\n        ptr: *mut A::Item,\n        length: usize,\n        capacity: usize,\n    ) -> SmallVec<A> {\n        assert!(capacity > A::size());\n        SmallVec {\n            capacity,\n            data: SmallVecData::from_heap(ptr, length),\n        }\n    }\n}\n\nimpl<A: Array> SmallVec<A> where A::Item: Copy {\n    /// Copy the elements from a slice into a new `SmallVec`.\n    ///\n    /// For slices of `Copy` types, this is more efficient than `SmallVec::from(slice)`.\n    pub fn from_slice(slice: &[A::Item]) -> Self {\n        let len = slice.len();\n        if len <= A::size() {\n            SmallVec {\n                capacity: len,\n                data: SmallVecData::from_inline(unsafe {\n                    let mut data: A = mem::uninitialized();\n                    ptr::copy_nonoverlapping(slice.as_ptr(), data.ptr_mut(), len);\n                    data\n                })\n            }\n        } else {\n            let mut b = slice.to_vec();\n            let (ptr, cap) = (b.as_mut_ptr(), b.capacity());\n            mem::forget(b);\n            SmallVec {\n                capacity: cap,\n                data: SmallVecData::from_heap(ptr, len),\n            }\n        }\n    }\n\n    /// Copy elements from a slice into the vector at position `index`, shifting any following\n    /// elements toward the back.\n    ///\n    /// For slices of `Copy` types, this is more efficient than `insert`.\n    pub fn insert_from_slice(&mut self, index: usize, slice: &[A::Item]) {\n        self.reserve(slice.len());\n\n        let len = self.len();\n        assert!(index <= len);\n\n        unsafe {\n            let slice_ptr = slice.as_ptr();\n            let ptr = self.as_mut_ptr().offset(index as isize);\n            ptr::copy(ptr, ptr.offset(slice.len() as isize), len - index);\n            ptr::copy_nonoverlapping(slice_ptr, ptr, slice.len());\n            self.set_len(len + slice.len());\n        }\n    }\n\n    /// Copy elements from a slice and append them to the vector.\n    ///\n    /// For slices of `Copy` types, this is more efficient than `extend`.\n    #[inline]\n    pub fn extend_from_slice(&mut self, slice: &[A::Item]) {\n        let len = self.len();\n        self.insert_from_slice(len, slice);\n    }\n}\n\nimpl<A: Array> SmallVec<A> where A::Item: Clone {\n    /// Resizes the vector so that its length is equal to `len`.\n    ///\n    /// If `len` is less than the current length, the vector simply truncated.\n    ///\n    /// If `len` is greater than the current length, `value` is appended to the\n    /// vector until its length equals `len`.\n    pub fn resize(&mut self, len: usize, value: A::Item) {\n        let old_len = self.len();\n\n        if len > old_len {\n            self.extend(repeat(value).take(len - old_len));\n        } else {\n            self.truncate(len);\n        }\n    }\n\n    /// Creates a `SmallVec` with `n` copies of `elem`.\n    /// ```\n    /// use smallvec::SmallVec;\n    ///\n    /// let v = SmallVec::<[char; 128]>::from_elem('d', 2);\n    /// assert_eq!(v, SmallVec::from_buf(['d', 'd']));\n    /// ```\n    pub fn from_elem(elem: A::Item, n: usize) -> Self {\n        if n > A::size() {\n            vec![elem; n].into()\n        } else {\n            let mut v = SmallVec::<A>::new();\n            unsafe {\n                let (ptr, len_ptr, _) = v.triple_mut();\n                let mut local_len = SetLenOnDrop::new(len_ptr);\n\n                for i in 0..n as isize {\n                    ::std::ptr::write(ptr.offset(i), elem.clone());\n                    local_len.increment_len(1);\n                }\n            }\n            v\n        }\n    }\n}\n\nimpl<A: Array> ops::Deref for SmallVec<A> {\n    type Target = [A::Item];\n    #[inline]\n    fn deref(&self) -> &[A::Item] {\n        unsafe {\n            let (ptr, len, _) = self.triple();\n            slice::from_raw_parts(ptr, len)\n        }\n    }\n}\n\nimpl<A: Array> ops::DerefMut for SmallVec<A> {\n    #[inline]\n    fn deref_mut(&mut self) -> &mut [A::Item] {\n        unsafe {\n            let (ptr, &mut len, _) = self.triple_mut();\n            slice::from_raw_parts_mut(ptr, len)\n        }\n    }\n}\n\nimpl<A: Array> AsRef<[A::Item]> for SmallVec<A> {\n    #[inline]\n    fn as_ref(&self) -> &[A::Item] {\n        self\n    }\n}\n\nimpl<A: Array> AsMut<[A::Item]> for SmallVec<A> {\n    #[inline]\n    fn as_mut(&mut self) -> &mut [A::Item] {\n        self\n    }\n}\n\nimpl<A: Array> Borrow<[A::Item]> for SmallVec<A> {\n    #[inline]\n    fn borrow(&self) -> &[A::Item] {\n        self\n    }\n}\n\nimpl<A: Array> BorrowMut<[A::Item]> for SmallVec<A> {\n    #[inline]\n    fn borrow_mut(&mut self) -> &mut [A::Item] {\n        self\n    }\n}\n\n#[cfg(feature = \"std\")]\nimpl<A: Array<Item = u8>> io::Write for SmallVec<A> {\n    #[inline]\n    fn write(&mut self, buf: &[u8]) -> io::Result<usize> {\n        self.extend_from_slice(buf);\n        Ok(buf.len())\n    }\n\n    #[inline]\n    fn write_all(&mut self, buf: &[u8]) -> io::Result<()> {\n        self.extend_from_slice(buf);\n        Ok(())\n    }\n\n    #[inline]\n    fn flush(&mut self) -> io::Result<()> {\n        Ok(())\n    }\n}\n\n#[cfg(feature = \"serde\")]\nimpl<A: Array> Serialize for SmallVec<A> where A::Item: Serialize {\n    fn serialize<S: Serializer>(&self, serializer: S) -> Result<S::Ok, S::Error> {\n        let mut state = serializer.serialize_seq(Some(self.len()))?;\n        for item in self {\n            state.serialize_element(&item)?;\n        }\n        state.end()\n    }\n}\n\n#[cfg(feature = \"serde\")]\nimpl<'de, A: Array> Deserialize<'de> for SmallVec<A> where A::Item: Deserialize<'de> {\n    fn deserialize<D: Deserializer<'de>>(deserializer: D) -> Result<Self, D::Error> {\n        deserializer.deserialize_seq(SmallVecVisitor{phantom: PhantomData})\n    }\n}\n\n#[cfg(feature = \"serde\")]\nstruct SmallVecVisitor<A> {\n    phantom: PhantomData<A>\n}\n\n#[cfg(feature = \"serde\")]\nimpl<'de, A: Array> Visitor<'de> for SmallVecVisitor<A>\nwhere A::Item: Deserialize<'de>,\n{\n    type Value = SmallVec<A>;\n\n    fn expecting(&self, formatter: &mut fmt::Formatter) -> fmt::Result {\n        formatter.write_str(\"a sequence\")\n    }\n\n    fn visit_seq<B>(self, mut seq: B) -> Result<Self::Value, B::Error>\n        where\n            B: SeqAccess<'de>,\n    {\n        let len = seq.size_hint().unwrap_or(0);\n        let mut values = SmallVec::with_capacity(len);\n\n        while let Some(value) = seq.next_element()? {\n            values.push(value);\n        }\n\n        Ok(values)\n    }\n}\n\n\n#[cfg(feature = \"specialization\")]\ntrait SpecFrom<A: Array, S> {\n    fn spec_from(slice: S) -> SmallVec<A>;\n}\n\n#[cfg(feature = \"specialization\")]\nimpl<'a, A: Array> SpecFrom<A, &'a [A::Item]> for SmallVec<A> where A::Item: Clone {\n    #[inline]\n    default fn spec_from(slice: &'a [A::Item]) -> SmallVec<A> {\n        slice.into_iter().cloned().collect()\n    }\n}\n\n#[cfg(feature = \"specialization\")]\nimpl<'a, A: Array> SpecFrom<A, &'a [A::Item]> for SmallVec<A> where A::Item: Copy {\n    #[inline]\n    fn spec_from(slice: &'a [A::Item]) -> SmallVec<A> {\n        SmallVec::from_slice(slice)\n    }\n}\n\nimpl<'a, A: Array> From<&'a [A::Item]> for SmallVec<A> where A::Item: Clone {\n    #[cfg(not(feature = \"specialization\"))]\n    #[inline]\n    fn from(slice: &'a [A::Item]) -> SmallVec<A> {\n        slice.into_iter().cloned().collect()\n    }\n\n    #[cfg(feature = \"specialization\")]\n    #[inline]\n    fn from(slice: &'a [A::Item]) -> SmallVec<A> {\n        SmallVec::spec_from(slice)\n    }\n}\n\nimpl<A: Array> From<Vec<A::Item>> for SmallVec<A> {\n    #[inline]\n    fn from(vec: Vec<A::Item>) -> SmallVec<A> {\n        SmallVec::from_vec(vec)\n    }\n}\n\nimpl<A: Array> From<A> for SmallVec<A> {\n    #[inline]\n    fn from(array: A) -> SmallVec<A> {\n        SmallVec::from_buf(array)\n    }\n}\n\nmacro_rules! impl_index {\n    ($index_type: ty, $output_type: ty) => {\n        impl<A: Array> ops::Index<$index_type> for SmallVec<A> {\n            type Output = $output_type;\n            #[inline]\n            fn index(&self, index: $index_type) -> &$output_type {\n                &(&**self)[index]\n            }\n        }\n\n        impl<A: Array> ops::IndexMut<$index_type> for SmallVec<A> {\n            #[inline]\n            fn index_mut(&mut self, index: $index_type) -> &mut $output_type {\n                &mut (&mut **self)[index]\n            }\n        }\n    }\n}\n\nimpl_index!(usize, A::Item);\nimpl_index!(ops::Range<usize>, [A::Item]);\nimpl_index!(ops::RangeFrom<usize>, [A::Item]);\nimpl_index!(ops::RangeTo<usize>, [A::Item]);\nimpl_index!(ops::RangeFull, [A::Item]);\n\nimpl<A: Array> ExtendFromSlice<A::Item> for SmallVec<A> where A::Item: Copy {\n    fn extend_from_slice(&mut self, other: &[A::Item]) {\n        SmallVec::extend_from_slice(self, other)\n    }\n}\n\n#[allow(deprecated)]\nimpl<A: Array> VecLike<A::Item> for SmallVec<A> {\n    #[inline]\n    fn push(&mut self, value: A::Item) {\n        SmallVec::push(self, value);\n    }\n}\n\nimpl<A: Array> FromIterator<A::Item> for SmallVec<A> {\n    fn from_iter<I: IntoIterator<Item=A::Item>>(iterable: I) -> SmallVec<A> {\n        let mut v = SmallVec::new();\n        v.extend(iterable);\n        v\n    }\n}\n\nimpl<A: Array> Extend<A::Item> for SmallVec<A> {\n    fn extend<I: IntoIterator<Item=A::Item>>(&mut self, iterable: I) {\n        let mut iter = iterable.into_iter();\n        let (lower_size_bound, _) = iter.size_hint();\n        self.reserve(lower_size_bound);\n\n        unsafe {\n            let (ptr, len_ptr, cap) = self.triple_mut();\n            let mut len = SetLenOnDrop::new(len_ptr);\n            while len.get() < cap {\n                if let Some(out) = iter.next() {\n                    ptr::write(ptr.offset(len.get() as isize), out);\n                    len.increment_len(1);\n                } else {\n                    return;\n                }\n            }\n        }\n\n        for elem in iter {\n            self.push(elem);\n        }\n    }\n}\n\nimpl<A: Array> fmt::Debug for SmallVec<A> where A::Item: fmt::Debug {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        f.debug_list().entries(self.iter()).finish()\n    }\n}\n\nimpl<A: Array> Default for SmallVec<A> {\n    #[inline]\n    fn default() -> SmallVec<A> {\n        SmallVec::new()\n    }\n}\n\n#[cfg(feature = \"may_dangle\")]\nunsafe impl<#[may_dangle] A: Array> Drop for SmallVec<A> {\n    fn drop(&mut self) {\n        unsafe {\n            if self.spilled() {\n                let (ptr, len) = self.data.heap();\n                Vec::from_raw_parts(ptr, len, self.capacity);\n            } else {\n                ptr::drop_in_place(&mut self[..]);\n            }\n        }\n    }\n}\n\n#[cfg(not(feature = \"may_dangle\"))]\nimpl<A: Array> Drop for SmallVec<A> {\n    fn drop(&mut self) {\n        unsafe {\n            if self.spilled() {\n                let (ptr, len) = self.data.heap();\n                Vec::from_raw_parts(ptr, len, self.capacity);\n            } else {\n                ptr::drop_in_place(&mut self[..]);\n            }\n        }\n    }\n}\n\nimpl<A: Array> Clone for SmallVec<A> where A::Item: Clone {\n    fn clone(&self) -> SmallVec<A> {\n        let mut new_vector = SmallVec::with_capacity(self.len());\n        for element in self.iter() {\n            new_vector.push((*element).clone())\n        }\n        new_vector\n    }\n}\n\nimpl<A: Array, B: Array> PartialEq<SmallVec<B>> for SmallVec<A>\n    where A::Item: PartialEq<B::Item> {\n    #[inline]\n    fn eq(&self, other: &SmallVec<B>) -> bool { self[..] == other[..] }\n    #[inline]\n    fn ne(&self, other: &SmallVec<B>) -> bool { self[..] != other[..] }\n}\n\nimpl<A: Array> Eq for SmallVec<A> where A::Item: Eq {}\n\nimpl<A: Array> PartialOrd for SmallVec<A> where A::Item: PartialOrd {\n    #[inline]\n    fn partial_cmp(&self, other: &SmallVec<A>) -> Option<cmp::Ordering> {\n        PartialOrd::partial_cmp(&**self, &**other)\n    }\n}\n\nimpl<A: Array> Ord for SmallVec<A> where A::Item: Ord {\n    #[inline]\n    fn cmp(&self, other: &SmallVec<A>) -> cmp::Ordering {\n        Ord::cmp(&**self, &**other)\n    }\n}\n\nimpl<A: Array> Hash for SmallVec<A> where A::Item: Hash {\n    fn hash<H: Hasher>(&self, state: &mut H) {\n        (**self).hash(state)\n    }\n}\n\nunsafe impl<A: Array> Send for SmallVec<A> where A::Item: Send {}\n\n/// An iterator that consumes a `SmallVec` and yields its items by value.\n///\n/// Returned from [`SmallVec::into_iter`][1].\n///\n/// [1]: struct.SmallVec.html#method.into_iter\npub struct IntoIter<A: Array> {\n    data: SmallVec<A>,\n    current: usize,\n    end: usize,\n}\n\nimpl<A: Array> Drop for IntoIter<A> {\n    fn drop(&mut self) {\n        for _ in self { }\n    }\n}\n\nimpl<A: Array> Iterator for IntoIter<A> {\n    type Item = A::Item;\n\n    #[inline]\n    fn next(&mut self) -> Option<A::Item> {\n        if self.current == self.end {\n            None\n        }\n        else {\n            unsafe {\n                let current = self.current as isize;\n                self.current += 1;\n                Some(ptr::read(self.data.as_ptr().offset(current)))\n            }\n        }\n    }\n\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        let size = self.end - self.current;\n        (size, Some(size))\n    }\n}\n\nimpl<A: Array> DoubleEndedIterator for IntoIter<A> {\n    #[inline]\n    fn next_back(&mut self) -> Option<A::Item> {\n        if self.current == self.end {\n            None\n        }\n        else {\n            unsafe {\n                self.end -= 1;\n                Some(ptr::read(self.data.as_ptr().offset(self.end as isize)))\n            }\n        }\n    }\n}\n\nimpl<A: Array> ExactSizeIterator for IntoIter<A> { }\n\nimpl<A: Array> IntoIterator for SmallVec<A> {\n    type IntoIter = IntoIter<A>;\n    type Item = A::Item;\n    fn into_iter(mut self) -> Self::IntoIter {\n        unsafe {\n            // Set SmallVec len to zero as `IntoIter` drop handles dropping of the elements\n            let len = self.len();\n            self.set_len(0);\n            IntoIter {\n                data: self,\n                current: 0,\n                end: len,\n            }\n        }\n    }\n}\n\nimpl<'a, A: Array> IntoIterator for &'a SmallVec<A> {\n    type IntoIter = slice::Iter<'a, A::Item>;\n    type Item = &'a A::Item;\n    fn into_iter(self) -> Self::IntoIter {\n        self.iter()\n    }\n}\n\nimpl<'a, A: Array> IntoIterator for &'a mut SmallVec<A> {\n    type IntoIter = slice::IterMut<'a, A::Item>;\n    type Item = &'a mut A::Item;\n    fn into_iter(self) -> Self::IntoIter {\n        self.iter_mut()\n    }\n}\n\n/// Types that can be used as the backing store for a SmallVec\npub unsafe trait Array {\n    /// The type of the array's elements.\n    type Item;\n    /// Returns the number of items the array can hold.\n    fn size() -> usize;\n    /// Returns a pointer to the first element of the array.\n    fn ptr(&self) -> *const Self::Item;\n    /// Returns a mutable pointer to the first element of the array.\n    fn ptr_mut(&mut self) -> *mut Self::Item;\n}\n\n/// Set the length of the vec when the `SetLenOnDrop` value goes out of scope.\n///\n/// Copied from https://github.com/rust-lang/rust/pull/36355\nstruct SetLenOnDrop<'a> {\n    len: &'a mut usize,\n    local_len: usize,\n}\n\nimpl<'a> SetLenOnDrop<'a> {\n    #[inline]\n    fn new(len: &'a mut usize) -> Self {\n        SetLenOnDrop { local_len: *len, len: len }\n    }\n\n    #[inline]\n    fn get(&self) -> usize {\n        self.local_len\n    }\n\n    #[inline]\n    fn increment_len(&mut self, increment: usize) {\n        self.local_len += increment;\n    }\n}\n\nimpl<'a> Drop for SetLenOnDrop<'a> {\n    #[inline]\n    fn drop(&mut self) {\n        *self.len = self.local_len;\n    }\n}\n\nmacro_rules! impl_array(\n    ($($size:expr),+) => {\n        $(\n            unsafe impl<T> Array for [T; $size] {\n                type Item = T;\n                fn size() -> usize { $size }\n                fn ptr(&self) -> *const T { self.as_ptr() }\n                fn ptr_mut(&mut self) -> *mut T { self.as_mut_ptr() }\n            }\n        )+\n    }\n);\n\nimpl_array!(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 20, 24, 32, 36,\n            0x40, 0x80, 0x100, 0x200, 0x400, 0x800, 0x1000, 0x2000, 0x4000, 0x8000,\n            0x10000, 0x20000, 0x40000, 0x80000, 0x100000);\n\n#[cfg(test)]\nmod tests {\n    use SmallVec;\n\n    use std::iter::FromIterator;\n\n    #[cfg(feature = \"std\")]\n    use std::borrow::ToOwned;\n    #[cfg(not(feature = \"std\"))]\n    use alloc::borrow::ToOwned;\n    #[cfg(feature = \"std\")]\n    use std::rc::Rc;\n    #[cfg(not(feature = \"std\"))]\n    use alloc::rc::Rc;\n    #[cfg(not(feature = \"std\"))]\n    use alloc::boxed::Box;\n    #[cfg(not(feature = \"std\"))]\n    use alloc::vec::Vec;\n\n    #[test]\n    pub fn test_zero() {\n        let mut v = SmallVec::<[_; 0]>::new();\n        assert!(!v.spilled());\n        v.push(0usize);\n        assert!(v.spilled());\n        assert_eq!(&*v, &[0]);\n    }\n\n    // We heap allocate all these strings so that double frees will show up under valgrind.\n\n    #[test]\n    pub fn test_inline() {\n        let mut v = SmallVec::<[_; 16]>::new();\n        v.push(\"hello\".to_owned());\n        v.push(\"there\".to_owned());\n        assert_eq!(&*v, &[\n            \"hello\".to_owned(),\n            \"there\".to_owned(),\n        ][..]);\n    }\n\n    #[test]\n    pub fn test_spill() {\n        let mut v = SmallVec::<[_; 2]>::new();\n        v.push(\"hello\".to_owned());\n        assert_eq!(v[0], \"hello\");\n        v.push(\"there\".to_owned());\n        v.push(\"burma\".to_owned());\n        assert_eq!(v[0], \"hello\");\n        v.push(\"shave\".to_owned());\n        assert_eq!(&*v, &[\n            \"hello\".to_owned(),\n            \"there\".to_owned(),\n            \"burma\".to_owned(),\n            \"shave\".to_owned(),\n        ][..]);\n    }\n\n    #[test]\n    pub fn test_double_spill() {\n        let mut v = SmallVec::<[_; 2]>::new();\n        v.push(\"hello\".to_owned());\n        v.push(\"there\".to_owned());\n        v.push(\"burma\".to_owned());\n        v.push(\"shave\".to_owned());\n        v.push(\"hello\".to_owned());\n        v.push(\"there\".to_owned());\n        v.push(\"burma\".to_owned());\n        v.push(\"shave\".to_owned());\n        assert_eq!(&*v, &[\n            \"hello\".to_owned(),\n            \"there\".to_owned(),\n            \"burma\".to_owned(),\n            \"shave\".to_owned(),\n            \"hello\".to_owned(),\n            \"there\".to_owned(),\n            \"burma\".to_owned(),\n            \"shave\".to_owned(),\n        ][..]);\n    }\n\n    /// https://github.com/servo/rust-smallvec/issues/4\n    #[test]\n    fn issue_4() {\n        SmallVec::<[Box<u32>; 2]>::new();\n    }\n\n    /// https://github.com/servo/rust-smallvec/issues/5\n    #[test]\n    fn issue_5() {\n        assert!(Some(SmallVec::<[&u32; 2]>::new()).is_some());\n    }\n\n    #[test]\n    fn test_with_capacity() {\n        let v: SmallVec<[u8; 3]> = SmallVec::with_capacity(1);\n        assert!(v.is_empty());\n        assert!(!v.spilled());\n        assert_eq!(v.capacity(), 3);\n\n        let v: SmallVec<[u8; 3]> = SmallVec::with_capacity(10);\n        assert!(v.is_empty());\n        assert!(v.spilled());\n        assert_eq!(v.capacity(), 10);\n    }\n\n    #[test]\n    fn drain() {\n        let mut v: SmallVec<[u8; 2]> = SmallVec::new();\n        v.push(3);\n        assert_eq!(v.drain().collect::<Vec<_>>(), &[3]);\n\n        // spilling the vec\n        v.push(3);\n        v.push(4);\n        v.push(5);\n        assert_eq!(v.drain().collect::<Vec<_>>(), &[3, 4, 5]);\n    }\n\n    #[test]\n    fn drain_rev() {\n        let mut v: SmallVec<[u8; 2]> = SmallVec::new();\n        v.push(3);\n        assert_eq!(v.drain().rev().collect::<Vec<_>>(), &[3]);\n\n        // spilling the vec\n        v.push(3);\n        v.push(4);\n        v.push(5);\n        assert_eq!(v.drain().rev().collect::<Vec<_>>(), &[5, 4, 3]);\n    }\n\n    #[test]\n    fn into_iter() {\n        let mut v: SmallVec<[u8; 2]> = SmallVec::new();\n        v.push(3);\n        assert_eq!(v.into_iter().collect::<Vec<_>>(), &[3]);\n\n        // spilling the vec\n        let mut v: SmallVec<[u8; 2]> = SmallVec::new();\n        v.push(3);\n        v.push(4);\n        v.push(5);\n        assert_eq!(v.into_iter().collect::<Vec<_>>(), &[3, 4, 5]);\n    }\n\n    #[test]\n    fn into_iter_rev() {\n        let mut v: SmallVec<[u8; 2]> = SmallVec::new();\n        v.push(3);\n        assert_eq!(v.into_iter().rev().collect::<Vec<_>>(), &[3]);\n\n        // spilling the vec\n        let mut v: SmallVec<[u8; 2]> = SmallVec::new();\n        v.push(3);\n        v.push(4);\n        v.push(5);\n        assert_eq!(v.into_iter().rev().collect::<Vec<_>>(), &[5, 4, 3]);\n    }\n\n    #[test]\n    fn into_iter_drop() {\n        use std::cell::Cell;\n\n        struct DropCounter<'a>(&'a Cell<i32>);\n\n        impl<'a> Drop for DropCounter<'a> {\n            fn drop(&mut self) {\n                self.0.set(self.0.get() + 1);\n            }\n        }\n\n        {\n            let cell = Cell::new(0);\n            let mut v: SmallVec<[DropCounter; 2]> = SmallVec::new();\n            v.push(DropCounter(&cell));\n            v.into_iter();\n            assert_eq!(cell.get(), 1);\n        }\n\n        {\n            let cell = Cell::new(0);\n            let mut v: SmallVec<[DropCounter; 2]> = SmallVec::new();\n            v.push(DropCounter(&cell));\n            v.push(DropCounter(&cell));\n            assert!(v.into_iter().next().is_some());\n            assert_eq!(cell.get(), 2);\n        }\n\n        {\n            let cell = Cell::new(0);\n            let mut v: SmallVec<[DropCounter; 2]> = SmallVec::new();\n            v.push(DropCounter(&cell));\n            v.push(DropCounter(&cell));\n            v.push(DropCounter(&cell));\n            assert!(v.into_iter().next().is_some());\n            assert_eq!(cell.get(), 3);\n        }\n        {\n            let cell = Cell::new(0);\n            let mut v: SmallVec<[DropCounter; 2]> = SmallVec::new();\n            v.push(DropCounter(&cell));\n            v.push(DropCounter(&cell));\n            v.push(DropCounter(&cell));\n            {\n                let mut it = v.into_iter();\n                assert!(it.next().is_some());\n                assert!(it.next_back().is_some());\n            }\n            assert_eq!(cell.get(), 3);\n        }\n    }\n\n    #[test]\n    fn test_capacity() {\n        let mut v: SmallVec<[u8; 2]> = SmallVec::new();\n        v.reserve(1);\n        assert_eq!(v.capacity(), 2);\n        assert!(!v.spilled());\n\n        v.reserve_exact(0x100);\n        assert!(v.capacity() >= 0x100);\n\n        v.push(0);\n        v.push(1);\n        v.push(2);\n        v.push(3);\n\n        v.shrink_to_fit();\n        assert!(v.capacity() < 0x100);\n    }\n\n    #[test]\n    fn test_truncate() {\n        let mut v: SmallVec<[Box<u8>; 8]> = SmallVec::new();\n\n        for x in 0..8 {\n            v.push(Box::new(x));\n        }\n        v.truncate(4);\n\n        assert_eq!(v.len(), 4);\n        assert!(!v.spilled());\n\n        assert_eq!(*v.swap_remove(1), 1);\n        assert_eq!(*v.remove(1), 3);\n        v.insert(1, Box::new(3));\n\n        assert_eq!(&v.iter().map(|v| **v).collect::<Vec<_>>(), &[0, 3, 2]);\n    }\n\n    #[test]\n    fn test_insert_many() {\n        let mut v: SmallVec<[u8; 8]> = SmallVec::new();\n        for x in 0..4 {\n            v.push(x);\n        }\n        assert_eq!(v.len(), 4);\n        v.insert_many(1, [5, 6].iter().cloned());\n        assert_eq!(&v.iter().map(|v| *v).collect::<Vec<_>>(), &[0, 5, 6, 1, 2, 3]);\n    }\n\n    struct MockHintIter<T: Iterator>{x: T, hint: usize}\n    impl<T: Iterator> Iterator for MockHintIter<T> {\n        type Item = T::Item;\n        fn next(&mut self) -> Option<Self::Item> {self.x.next()}\n        fn size_hint(&self) -> (usize, Option<usize>) {(self.hint, None)}\n    }\n\n    #[test]\n    fn test_insert_many_short_hint() {\n        let mut v: SmallVec<[u8; 8]> = SmallVec::new();\n        for x in 0..4 {\n            v.push(x);\n        }\n        assert_eq!(v.len(), 4);\n        v.insert_many(1, MockHintIter{x: [5, 6].iter().cloned(), hint: 5});\n        assert_eq!(&v.iter().map(|v| *v).collect::<Vec<_>>(), &[0, 5, 6, 1, 2, 3]);\n    }\n\n    #[test]\n    fn test_insert_many_long_hint() {\n        let mut v: SmallVec<[u8; 8]> = SmallVec::new();\n        for x in 0..4 {\n            v.push(x);\n        }\n        assert_eq!(v.len(), 4);\n        v.insert_many(1, MockHintIter{x: [5, 6].iter().cloned(), hint: 1});\n        assert_eq!(&v.iter().map(|v| *v).collect::<Vec<_>>(), &[0, 5, 6, 1, 2, 3]);\n    }\n\n    #[cfg(feature = \"std\")]\n    #[test]\n    // https://github.com/servo/rust-smallvec/issues/96\n    fn test_insert_many_panic() {\n        struct PanicOnDoubleDrop {\n            dropped: Box<bool>\n        }\n\n        impl Drop for PanicOnDoubleDrop {\n            fn drop(&mut self) {\n                assert!(!*self.dropped, \"already dropped\");\n                *self.dropped = true;\n            }\n        }\n\n        struct BadIter;\n        impl Iterator for BadIter {\n            type Item = PanicOnDoubleDrop;\n            fn size_hint(&self) -> (usize, Option<usize>) { (1, None) }\n            fn next(&mut self) -> Option<Self::Item> { panic!() }\n        }\n\n        let mut vec: SmallVec<[PanicOnDoubleDrop; 0]> = vec![\n            PanicOnDoubleDrop { dropped: Box::new(false) },\n            PanicOnDoubleDrop { dropped: Box::new(false) },\n        ].into();\n        let result = ::std::panic::catch_unwind(move || {\n            vec.insert_many(0, BadIter);\n        });\n        assert!(result.is_err());\n    }\n\n    #[test]\n    #[should_panic]\n    fn test_invalid_grow() {\n        let mut v: SmallVec<[u8; 8]> = SmallVec::new();\n        v.extend(0..8);\n        v.grow(5);\n    }\n\n    #[test]\n    fn test_insert_from_slice() {\n        let mut v: SmallVec<[u8; 8]> = SmallVec::new();\n        for x in 0..4 {\n            v.push(x);\n        }\n        assert_eq!(v.len(), 4);\n        v.insert_from_slice(1, &[5, 6]);\n        assert_eq!(&v.iter().map(|v| *v).collect::<Vec<_>>(), &[0, 5, 6, 1, 2, 3]);\n    }\n\n    #[test]\n    fn test_extend_from_slice() {\n        let mut v: SmallVec<[u8; 8]> = SmallVec::new();\n        for x in 0..4 {\n            v.push(x);\n        }\n        assert_eq!(v.len(), 4);\n        v.extend_from_slice(&[5, 6]);\n        assert_eq!(&v.iter().map(|v| *v).collect::<Vec<_>>(), &[0, 1, 2, 3, 5, 6]);\n    }\n\n    #[test]\n    #[should_panic]\n    fn test_drop_panic_smallvec() {\n        // This test should only panic once, and not double panic,\n        // which would mean a double drop\n        struct DropPanic;\n\n        impl Drop for DropPanic {\n            fn drop(&mut self) {\n                panic!(\"drop\");\n            }\n        }\n\n        let mut v = SmallVec::<[_; 1]>::new();\n        v.push(DropPanic);\n    }\n\n    #[test]\n    fn test_eq() {\n        let mut a: SmallVec<[u32; 2]> = SmallVec::new();\n        let mut b: SmallVec<[u32; 2]> = SmallVec::new();\n        let mut c: SmallVec<[u32; 2]> = SmallVec::new();\n        // a = [1, 2]\n        a.push(1);\n        a.push(2);\n        // b = [1, 2]\n        b.push(1);\n        b.push(2);\n        // c = [3, 4]\n        c.push(3);\n        c.push(4);\n\n        assert!(a == b);\n        assert!(a != c);\n    }\n\n    #[test]\n    fn test_ord() {\n        let mut a: SmallVec<[u32; 2]> = SmallVec::new();\n        let mut b: SmallVec<[u32; 2]> = SmallVec::new();\n        let mut c: SmallVec<[u32; 2]> = SmallVec::new();\n        // a = [1]\n        a.push(1);\n        // b = [1, 1]\n        b.push(1);\n        b.push(1);\n        // c = [1, 2]\n        c.push(1);\n        c.push(2);\n\n        assert!(a < b);\n        assert!(b > a);\n        assert!(b < c);\n        assert!(c > b);\n    }\n\n    #[cfg(feature = \"std\")]\n    #[test]\n    fn test_hash() {\n        use std::hash::Hash;\n        use std::collections::hash_map::DefaultHasher;\n\n        {\n            let mut a: SmallVec<[u32; 2]> = SmallVec::new();\n            let b = [1, 2];\n            a.extend(b.iter().cloned());\n            let mut hasher = DefaultHasher::new();\n            assert_eq!(a.hash(&mut hasher), b.hash(&mut hasher));\n        }\n        {\n            let mut a: SmallVec<[u32; 2]> = SmallVec::new();\n            let b = [1, 2, 11, 12];\n            a.extend(b.iter().cloned());\n            let mut hasher = DefaultHasher::new();\n            assert_eq!(a.hash(&mut hasher), b.hash(&mut hasher));\n        }\n    }\n\n    #[test]\n    fn test_as_ref() {\n        let mut a: SmallVec<[u32; 2]> = SmallVec::new();\n        a.push(1);\n        assert_eq!(a.as_ref(), [1]);\n        a.push(2);\n        assert_eq!(a.as_ref(), [1, 2]);\n        a.push(3);\n        assert_eq!(a.as_ref(), [1, 2, 3]);\n    }\n\n    #[test]\n    fn test_as_mut() {\n        let mut a: SmallVec<[u32; 2]> = SmallVec::new();\n        a.push(1);\n        assert_eq!(a.as_mut(), [1]);\n        a.push(2);\n        assert_eq!(a.as_mut(), [1, 2]);\n        a.push(3);\n        assert_eq!(a.as_mut(), [1, 2, 3]);\n        a.as_mut()[1] = 4;\n        assert_eq!(a.as_mut(), [1, 4, 3]);\n    }\n\n    #[test]\n    fn test_borrow() {\n        use std::borrow::Borrow;\n\n        let mut a: SmallVec<[u32; 2]> = SmallVec::new();\n        a.push(1);\n        assert_eq!(a.borrow(), [1]);\n        a.push(2);\n        assert_eq!(a.borrow(), [1, 2]);\n        a.push(3);\n        assert_eq!(a.borrow(), [1, 2, 3]);\n    }\n\n    #[test]\n    fn test_borrow_mut() {\n        use std::borrow::BorrowMut;\n\n        let mut a: SmallVec<[u32; 2]> = SmallVec::new();\n        a.push(1);\n        assert_eq!(a.borrow_mut(), [1]);\n        a.push(2);\n        assert_eq!(a.borrow_mut(), [1, 2]);\n        a.push(3);\n        assert_eq!(a.borrow_mut(), [1, 2, 3]);\n        BorrowMut::<[u32]>::borrow_mut(&mut a)[1] = 4;\n        assert_eq!(a.borrow_mut(), [1, 4, 3]);\n    }\n\n    #[test]\n    fn test_from() {\n        assert_eq!(&SmallVec::<[u32; 2]>::from(&[1][..])[..], [1]);\n        assert_eq!(&SmallVec::<[u32; 2]>::from(&[1, 2, 3][..])[..], [1, 2, 3]);\n\n        let vec = vec![];\n        let small_vec: SmallVec<[u8; 3]> = SmallVec::from(vec);\n        assert_eq!(&*small_vec, &[]);\n        drop(small_vec);\n\n        let vec = vec![1, 2, 3, 4, 5];\n        let small_vec: SmallVec<[u8; 3]> = SmallVec::from(vec);\n        assert_eq!(&*small_vec, &[1, 2, 3, 4, 5]);\n        drop(small_vec);\n\n        let vec = vec![1, 2, 3, 4, 5];\n        let small_vec: SmallVec<[u8; 1]> = SmallVec::from(vec);\n        assert_eq!(&*small_vec, &[1, 2, 3, 4, 5]);\n        drop(small_vec);\n\n        let array = [1];\n        let small_vec: SmallVec<[u8; 1]> = SmallVec::from(array);\n        assert_eq!(&*small_vec, &[1]);\n        drop(small_vec);\n\n        let array = [99; 128];\n        let small_vec: SmallVec<[u8; 128]> = SmallVec::from(array);\n        assert_eq!(&*small_vec, vec![99u8; 128].as_slice());\n        drop(small_vec);\n    }\n\n    #[test]\n    fn test_from_slice() {\n        assert_eq!(&SmallVec::<[u32; 2]>::from_slice(&[1][..])[..], [1]);\n        assert_eq!(&SmallVec::<[u32; 2]>::from_slice(&[1, 2, 3][..])[..], [1, 2, 3]);\n    }\n\n    #[test]\n    fn test_exact_size_iterator() {\n        let mut vec = SmallVec::<[u32; 2]>::from(&[1, 2, 3][..]);\n        assert_eq!(vec.clone().into_iter().len(), 3);\n        assert_eq!(vec.drain().len(), 3);\n    }\n\n    #[test]\n    #[allow(deprecated)]\n    fn veclike_deref_slice() {\n        use super::VecLike;\n\n        fn test<T: VecLike<i32>>(vec: &mut T) {\n            assert!(!vec.is_empty());\n            assert_eq!(vec.len(), 3);\n\n            vec.sort();\n            assert_eq!(&vec[..], [1, 2, 3]);\n        }\n\n        let mut vec = SmallVec::<[i32; 2]>::from(&[3, 1, 2][..]);\n        test(&mut vec);\n    }\n\n    #[test]\n    fn shrink_to_fit_unspill() {\n        let mut vec = SmallVec::<[u8; 2]>::from_iter(0..3);\n        vec.pop();\n        assert!(vec.spilled());\n        vec.shrink_to_fit();\n        assert!(!vec.spilled(), \"shrink_to_fit will un-spill if possible\");\n    }\n\n    #[test]\n    fn test_into_vec() {\n        let vec = SmallVec::<[u8; 2]>::from_iter(0..2);\n        assert_eq!(vec.into_vec(), vec![0, 1]);\n\n        let vec = SmallVec::<[u8; 2]>::from_iter(0..3);\n        assert_eq!(vec.into_vec(), vec![0, 1, 2]);\n    }\n\n    #[test]\n    fn test_into_inner() {\n        let vec = SmallVec::<[u8; 2]>::from_iter(0..2);\n        assert_eq!(vec.into_inner(), Ok([0, 1]));\n\n        let vec = SmallVec::<[u8; 2]>::from_iter(0..1);\n        assert_eq!(vec.clone().into_inner(), Err(vec));\n\n        let vec = SmallVec::<[u8; 2]>::from_iter(0..3);\n        assert_eq!(vec.clone().into_inner(), Err(vec));\n    }\n\n    #[test]\n    fn test_from_vec() {\n        let vec = vec![];\n        let small_vec: SmallVec<[u8; 3]> = SmallVec::from_vec(vec);\n        assert_eq!(&*small_vec, &[]);\n        drop(small_vec);\n\n        let vec = vec![];\n        let small_vec: SmallVec<[u8; 1]> = SmallVec::from_vec(vec);\n        assert_eq!(&*small_vec, &[]);\n        drop(small_vec);\n\n        let vec = vec![1];\n        let small_vec: SmallVec<[u8; 3]> = SmallVec::from_vec(vec);\n        assert_eq!(&*small_vec, &[1]);\n        drop(small_vec);\n\n        let vec = vec![1, 2, 3];\n        let small_vec: SmallVec<[u8; 3]> = SmallVec::from_vec(vec);\n        assert_eq!(&*small_vec, &[1, 2, 3]);\n        drop(small_vec);\n\n        let vec = vec![1, 2, 3, 4, 5];\n        let small_vec: SmallVec<[u8; 3]> = SmallVec::from_vec(vec);\n        assert_eq!(&*small_vec, &[1, 2, 3, 4, 5]);\n        drop(small_vec);\n\n        let vec = vec![1, 2, 3, 4, 5];\n        let small_vec: SmallVec<[u8; 1]> = SmallVec::from_vec(vec);\n        assert_eq!(&*small_vec, &[1, 2, 3, 4, 5]);\n        drop(small_vec);\n    }\n\n    #[test]\n    fn test_retain() {\n        // Test inline data storate\n        let mut sv: SmallVec<[i32; 5]> = SmallVec::from_slice(&[1, 2, 3, 3, 4]);\n        sv.retain(|&mut i| i != 3);\n        assert_eq!(sv.pop(), Some(4));\n        assert_eq!(sv.pop(), Some(2));\n        assert_eq!(sv.pop(), Some(1));\n        assert_eq!(sv.pop(), None);\n\n        // Test spilled data storage\n        let mut sv: SmallVec<[i32; 3]> = SmallVec::from_slice(&[1, 2, 3, 3, 4]);\n        sv.retain(|&mut i| i != 3);\n        assert_eq!(sv.pop(), Some(4));\n        assert_eq!(sv.pop(), Some(2));\n        assert_eq!(sv.pop(), Some(1));\n        assert_eq!(sv.pop(), None);\n\n        // Test that drop implementations are called for inline.\n        let one = Rc::new(1);\n        let mut sv: SmallVec<[Rc<i32>; 3]> = SmallVec::new();\n        sv.push(Rc::clone(&one));\n        assert_eq!(Rc::strong_count(&one), 2);\n        sv.retain(|_| false);\n        assert_eq!(Rc::strong_count(&one), 1);\n\n        // Test that drop implementations are called for spilled data.\n        let mut sv: SmallVec<[Rc<i32>; 1]> = SmallVec::new();\n        sv.push(Rc::clone(&one));\n        sv.push(Rc::new(2));\n        assert_eq!(Rc::strong_count(&one), 2);\n        sv.retain(|_| false);\n        assert_eq!(Rc::strong_count(&one), 1);\n    }\n\n    #[test]\n    fn test_dedup() {\n        let mut dupes: SmallVec<[i32; 5]> = SmallVec::from_slice(&[1, 1, 2, 3, 3]);\n        dupes.dedup();\n        assert_eq!(&*dupes, &[1, 2, 3]);\n\n        let mut empty: SmallVec<[i32; 5]> = SmallVec::new();\n        empty.dedup();\n        assert!(empty.is_empty());\n\n        let mut all_ones: SmallVec<[i32; 5]> = SmallVec::from_slice(&[1, 1, 1, 1, 1]);\n        all_ones.dedup();\n        assert_eq!(all_ones.len(), 1);\n\n        let mut no_dupes: SmallVec<[i32; 5]> = SmallVec::from_slice(&[1, 2, 3, 4, 5]);\n        no_dupes.dedup();\n        assert_eq!(no_dupes.len(), 5);\n    }\n\n    #[test]\n    fn test_resize() {\n        let mut v: SmallVec<[i32; 8]> = SmallVec::new();\n        v.push(1);\n        v.resize(5, 0);\n        assert_eq!(v[..], [1, 0, 0, 0, 0][..]);\n\n        v.resize(2, -1);\n        assert_eq!(v[..], [1, 0][..]);\n    }\n\n    #[cfg(feature = \"std\")]\n    #[test]\n    fn test_write() {\n        use io::Write;\n\n        let data = [1, 2, 3, 4, 5];\n\n        let mut small_vec: SmallVec<[u8; 2]> = SmallVec::new();\n        let len = small_vec.write(&data[..]).unwrap();\n        assert_eq!(len, 5);\n        assert_eq!(small_vec.as_ref(), data.as_ref());\n\n        let mut small_vec: SmallVec<[u8; 2]> = SmallVec::new();\n        small_vec.write_all(&data[..]).unwrap();\n        assert_eq!(small_vec.as_ref(), data.as_ref());\n    }\n\n    #[cfg(feature = \"serde\")]\n    extern crate bincode;\n\n    #[cfg(feature = \"serde\")]\n    #[test]\n    fn test_serde() {\n        use self::bincode::{config, deserialize};\n        let mut small_vec: SmallVec<[i32; 2]> = SmallVec::new();\n        small_vec.push(1);\n        let encoded = config().limit(100).serialize(&small_vec).unwrap();\n        let decoded: SmallVec<[i32; 2]> = deserialize(&encoded).unwrap();\n        assert_eq!(small_vec, decoded);\n        small_vec.push(2);\n        // Spill the vec\n        small_vec.push(3);\n        small_vec.push(4);\n        // Check again after spilling.\n        let encoded = config().limit(100).serialize(&small_vec).unwrap();\n        let decoded: SmallVec<[i32; 2]> = deserialize(&encoded).unwrap();\n        assert_eq!(small_vec, decoded);\n    }\n\n    #[test]\n    fn grow_to_shrink() {\n        let mut v: SmallVec<[u8; 2]> = SmallVec::new();\n        v.push(1);\n        v.push(2);\n        v.push(3);\n        assert!(v.spilled());\n        v.clear();\n        // Shrink to inline.\n        v.grow(2);\n        assert!(!v.spilled());\n        assert_eq!(v.capacity(), 2);\n        assert_eq!(v.len(), 0);\n        v.push(4);\n        assert_eq!(v[..], [4]);\n    }\n\n    #[test]\n    fn resumable_extend() {\n        let s = \"a b c\";\n        // This iterator yields: (Some('a'), None, Some('b'), None, Some('c')), None\n        let it = s\n            .chars()\n            .scan(0, |_, ch| if ch.is_whitespace() { None } else { Some(ch) });\n        let mut v: SmallVec<[char; 4]> = SmallVec::new();\n        v.extend(it);\n        assert_eq!(v[..], ['a']);\n    }\n}\n"
  },
  {
    "project": "slice_deque",
    "target": 1,
    "commit_id": "57b1a84138222f5416eeeec33d834af0041c81c2",
    "func": "//! A double-ended queue that `Deref`s into a slice.\n//!\n//! The double-ended queue in the standard library ([`VecDeque`]) is\n//! implemented using a growable ring buffer (`0` represents uninitialized\n//! memory, and `T` represents one element in the queue):\n//!\n//! ```rust\n//! // [ 0 | 0 | 0 | T | T | T | 0 ]\n//! //               ^:head  ^:tail\n//! ```\n//!\n//! When the queue grows beyond the end of the allocated buffer, its tail wraps\n//! around:\n//!\n//! ```rust\n//! // [ T | T | 0 | T | T | T | T ]\n//! //       ^:tail  ^:head\n//! ```\n//!\n//! As a consequence, [`VecDeque`] cannot `Deref` into a slice, since its\n//! elements do not, in general, occupy a contiguous memory region. This\n//! complicates the implementation and its interface (for example, there is no\n//! `as_slice` method, but [`as_slices`] returns a pair of slices) and has\n//! negative performance consequences (e.g. need to account for wrap around\n//! while iterating over the elements).\n//!\n//! This crates provides [`SliceDeque`], a double-ended queue implemented with\n//! a growable *virtual* ring-buffer.\n//!\n//! A virtual ring-buffer implementation is very similar to the one used in\n//! `VecDeque`. The main difference is that a virtual ring-buffer maps two\n//! adjacent regions of virtual memory to the same region of physical memory:\n//!\n//! ```rust\n//! // Virtual memory:\n//! //\n//! //  __________region_0_________ __________region_1_________\n//! // [ 0 | 0 | 0 | T | T | T | 0 | 0 | 0 | 0 | T | T | T | 0 ]\n//! //               ^:head  ^:tail\n//! //\n//! // Physical memory:\n//! //\n//! // [ 0 | 0 | 0 | T | T | T | 0 ]\n//! //               ^:head  ^:tail\n//! ```\n//!\n//! That is, both the virtual memory regions `0` and `1` above (top) map to\n//! the same physical memory (bottom). Just like `VecDeque`, when the queue\n//! grows beyond the end of the allocated physical memory region, the queue\n//! wraps around, and new elements continue to be appended at the beginning of\n//! the queue. However, because `SliceDeque` maps the physical memory to two\n//! adjacent memory regions, in virtual memory space the queue maintais the\n//! ilusion of a contiguous memory layout:\n//!\n//! ```rust\n//! // Virtual memory:\n//! //\n//! //  __________region_0_________ __________region_1_________\n//! // [ T | T | 0 | T | T | T | T | T | T | 0 | T | T | T | T ]\n//! //               ^:head              ^:tail\n//! //\n//! // Physical memory:\n//! //\n//! // [ T | T | 0 | T | T | T | T ]\n//! //       ^:tail  ^:head\n//! ```\n//!\n//! Since processes in many Operating Systems only deal with virtual memory\n//! addresses, leaving the mapping to physical memory to the CPU Memory\n//! Management Unit (MMU), [`SliceDeque`] is able to `Deref`s into a slice in\n//! those systems.\n//!\n//! This simplifies [`SliceDeque`]'s API and implementation, giving it a\n//! performance advantage over [`VecDeque`] in some situations.\n//!\n//! In general, you can think of [`SliceDeque`] as a `Vec` with `O(1)`\n//! `pop_front` and amortized `O(1)` `push_front` methods.\n//!\n//! The main drawbacks of [`SliceDeque`] are:\n//!\n//! * constrained platform support: by necessity [`SliceDeque`] must use the\n//! platform-specific virtual memory facilities of the underlying operating\n//! system. While [`SliceDeque`] can work on all major operating systems,\n//! currently only `MacOS X` is supported.\n//!\n//! * no global allocator support: since the `Alloc`ator API does not support\n//! virtual memory, to use platform-specific virtual memory support\n//! [`SliceDeque`] must bypass the global allocator and talk directly to the\n//! operating system. This can have negative performance consequences since\n//! growing [`SliceDeque`] is always going to incur the cost of some system\n//! calls.\n//!\n//! * capacity constrained by virtual memory facilities: [`SliceDeque`] must\n//! allocate two adjacent memory regions that map to the same region of\n//! physical memory. Most operating systems allow this operation to be\n//! performed exclusively on memory pages (or memory allocations that are\n//! multiples of a memory page). As a consequence, the smalles [`SliceDeque`]\n//! that can be created has typically a capacity of 2 memory pages, and it can\n//! grow only to capacities that are a multiple of a memory page.\n//!\n//! The main advantages of [`SliceDeque`] are:\n//!\n//! * nicer API: since it `Deref`s to a slice, all operations that work on\n//! slices are available for `SliceDeque`.\n//!\n//! * efficient iteration: as efficient as for slices.\n//!\n//! * simpler serialization: since one can just serialize/deserialize a single\n//! slice.\n//!\n//! All in all, if your double-ended queues are small (smaller than a memory\n//! page) or they get resized very often, `VecDeque` can perform better than\n//! [`SliceDeque`]. Otherwise, [`SliceDeque`] typically performs better (see\n//! the benchmarks), but platform support and global allocator bypass are two\n//! reasons to weight in against its usage.\n//!\n//! [`VecDeque`]: https://doc.rust-lang.org/std/collections/struct.VecDeque.html\n//! [`as_slices`]: https://doc.rust-lang.org/std/collections/struct.VecDeque.html#method.as_slices\n//! [`SliceDeque`]: struct.SliceDeque.html\n\n#![cfg_attr(\n    feature = \"unstable\",\n    feature(\n        core_intrinsics,\n        exact_size_is_empty,\n        dropck_eyepatch,\n        trusted_len,\n        ptr_wrapping_offset_from,\n        specialization\n    )\n)]\n#![cfg_attr(all(test, feature = \"unstable\"), feature(box_syntax))]\n#![cfg_attr(\n    feature = \"cargo-clippy\",\n    allow(\n        clippy::len_without_is_empty,\n        clippy::shadow_reuse,\n        clippy::cast_possible_wrap,\n        clippy::cast_sign_loss,\n        clippy::cast_possible_truncation,\n        clippy::inline_always,\n        clippy::indexing_slicing\n    )\n)]\n#![cfg_attr(not(any(feature = \"use_std\", test)), no_std)]\n\n#[macro_use]\nmod macros;\n\n#[cfg(any(feature = \"use_std\", test))]\nextern crate core;\n\n#[cfg(all(\n    any(target_os = \"macos\", target_os = \"ios\"),\n    not(feature = \"unix_sysv\")\n))]\nextern crate mach;\n\n#[cfg(unix)]\nextern crate libc;\n\n#[cfg(target_os = \"windows\")]\nextern crate winapi;\n\n#[cfg(all(feature = \"bytes_buf\", feature = \"use_std\"))]\nextern crate bytes;\n\nmod mirrored;\npub use mirrored::{AllocError, Buffer};\n\n#[cfg(all(feature = \"bytes_buf\", feature = \"use_std\"))]\nuse std::io;\n\nuse core::{cmp, convert, fmt, hash, iter, mem, ops, ptr, slice, str};\n\nuse core::ptr::NonNull;\n\n#[cfg(feature = \"unstable\")]\nuse core::intrinsics;\n\n/// A stable version of the `core::intrinsics` module.\n#[cfg(not(feature = \"unstable\"))]\nmod intrinsics {\n    /// Like `core::intrinsics::unlikely` but does nothing.\n    #[inline(always)]\n    pub unsafe fn unlikely<T>(x: T) -> T {\n        x\n    }\n\n    /// Like `core::intrinsics::assume` but does nothing.\n    #[inline(always)]\n    pub unsafe fn assume<T>(x: T) -> T {\n        x\n    }\n\n    /// Like `core::intrinsics::arith_offset` but doing pointer to integer\n    /// conversions.\n    #[inline(always)]\n    pub unsafe fn arith_offset<T>(dst: *const T, offset: isize) -> *const T {\n        let r = if offset >= 0 {\n            (dst as usize).wrapping_add(offset as usize)\n        } else {\n            (dst as usize).wrapping_sub((-offset) as usize)\n        };\n        r as *const T\n    }\n}\n\n/// Stable implementation of `.offset_to` for pointers.\ntrait OffsetTo {\n    /// Stable implementation of `.offset_to` for pointers.\n    fn offset_to_(self, other: Self) -> Option<isize>;\n}\n\n/// Stable implementation of `.offset_to` for pointers.\ntrait OffsetToMut {\n    /// A const pointer type.\n    type Other;\n    /// Stable implementation of `.offset_to` for pointers.\n    fn offset_to_(self, other: Self::Other) -> Option<isize>;\n}\n\n#[cfg(not(feature = \"unstable\"))]\nimpl<T: Sized> OffsetTo for *const T {\n    #[inline(always)]\n    fn offset_to_(self, other: Self) -> Option<isize>\n    where\n        T: Sized,\n    {\n        let size = mem::size_of::<T>();\n        if size == 0 {\n            None\n        } else {\n            let diff = (other as isize).wrapping_sub(self as isize);\n            Some(diff / size as isize)\n        }\n    }\n}\n\n#[cfg(feature = \"unstable\")]\nimpl<T: Sized> OffsetTo for *const T {\n    #[inline(always)]\n    fn offset_to_(self, other: Self) -> Option<isize>\n    where\n        T: Sized,\n    {\n        let size = mem::size_of::<T>();\n        if size == 0 {\n            None\n        } else {\n            Some(other.wrapping_offset_from(self))\n        }\n    }\n}\n\n#[cfg(not(feature = \"unstable\"))]\nimpl<T: Sized> OffsetToMut for *mut T {\n    type Other = *const T;\n    #[inline(always)]\n    fn offset_to_(self, other: Self::Other) -> Option<isize>\n    where\n        T: Sized,\n    {\n        let size = mem::size_of::<T>();\n        if size == 0 {\n            None\n        } else {\n            let diff = (other as isize).wrapping_sub(self as isize);\n            Some(diff / size as isize)\n        }\n    }\n}\n\n#[cfg(feature = \"unstable\")]\nimpl<T: Sized> OffsetToMut for *mut T {\n    type Other = *const T;\n    #[inline(always)]\n    fn offset_to_(self, other: Self::Other) -> Option<isize>\n    where\n        T: Sized,\n    {\n        let size = mem::size_of::<T>();\n        if size == 0 {\n            None\n        } else {\n            Some(other.wrapping_offset_from(self))\n        }\n    }\n}\n\n/// A double-ended queue that derefs into a slice.\n///\n/// It is implemented with a growable virtual ring buffer.\npub struct SliceDeque<T> {\n    /// Index of the first element in the queue.\n    head_: usize,\n    /// Index of one past the last element in the queue.\n    tail_: usize,\n    /// Mirrored memory buffer.\n    buf: Buffer<T>,\n}\n\n/// Implementation detail of the sdeq! macro.\n#[doc(hidden)]\npub use mem::forget as __mem_forget;\n\n/// Creates a [`SliceDeque`] containing the arguments.\n///\n/// `sdeq!` allows `SliceDeque`s to be defined with the same syntax as array\n/// expressions. There are two forms of this macro:\n///\n/// - Create a [`SliceDeque`] containing a given list of elements:\n///\n/// ```\n/// # #[macro_use] extern crate slice_deque;\n/// # use slice_deque::SliceDeque;\n/// # fn main() {\n/// let v: SliceDeque<i32> = sdeq![1, 2, 3];\n/// assert_eq!(v[0], 1);\n/// assert_eq!(v[1], 2);\n/// assert_eq!(v[2], 3);\n/// # }\n/// ```\n///\n/// - Create a [`SliceDeque`] from a given element and size:\n///\n/// ```\n/// # #[macro_use] extern crate slice_deque;\n/// # use slice_deque::SliceDeque;\n/// # fn main() {\n/// let v = sdeq![7; 3];\n/// assert_eq!(v, [7, 7, 7]);\n/// # }\n/// ```\n///\n/// Note that unlike array expressions this syntax supports all elements\n/// which implement `Clone` and the number of elements doesn't have to be\n/// a constant.\n///\n/// This will use `clone` to duplicate an expression, so one should be careful\n/// using this with types having a nonstandard `Clone` implementation. For\n/// example, `sdeq![Rc::new(1); 5]` will create a deque of five references\n/// to the same boxed integer value, not five references pointing to\n/// independently boxed integers.\n///\n/// ```\n/// # #[macro_use] extern crate slice_deque;\n/// # use slice_deque::SliceDeque;\n/// # use std::rc::Rc;\n/// # fn main() {\n/// let v = sdeq![Rc::new(1_i32); 5];\n/// let ptr: *const i32 = &*v[0] as *const i32;\n/// for i in v.iter() {\n///     assert_eq!(Rc::into_raw(i.clone()), ptr);\n/// }\n/// # }\n/// ```\n///\n/// [`SliceDeque`]: struct.SliceDeque.html\n#[macro_export]\nmacro_rules! sdeq {\n    ($elem:expr; $n:expr) => (\n        {\n            let mut deq = $crate::SliceDeque::with_capacity($n);\n            deq.resize($n, $elem);\n            deq\n        }\n    );\n    () => ( $crate::SliceDeque::new() );\n    ($($x:expr),*) => (\n        {\n            unsafe {\n                let array = [$($x),*];\n                let deq = $crate::SliceDeque::steal_from_slice(&array);\n                #[cfg_attr(feature = \"cargo-clippy\", allow(clippy::forget_copy))]\n                $crate::__mem_forget(array);\n                deq\n            }\n        }\n    );\n    ($($x:expr,)*) => (sdeq![$($x),*])\n}\n\nimpl<T> SliceDeque<T> {\n    /// Creates a new empty deque.\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// # use slice_deque::SliceDeque;\n    /// let deq = SliceDeque::new();\n    /// # let o: SliceDeque<u32> = deq;\n    /// ```\n    #[inline]\n    pub fn new() -> Self {\n        Self {\n            head_: 0,\n            tail_: 0,\n            buf: Buffer::new(),\n        }\n    }\n\n    /// Creates a SliceDeque from its raw components.\n    ///\n    /// The `ptr` must be a pointer to the beginning of the memory buffer from\n    /// another `SliceDeque`, and `capacity` the capacity of this `SliceDeque`.\n    #[inline]\n    pub unsafe fn from_raw_parts(\n        ptr: *mut T, capacity: usize, head: usize, tail: usize,\n    ) -> Self {\n        debug_assert!(head <= tail);\n\n        let d = Self {\n            head_: head,\n            tail_: tail,\n            buf: Buffer::from_raw_parts(ptr, capacity * 2),\n        };\n\n        debug_assert!(d.tail() <= d.tail_upper_bound());\n        debug_assert!(d.head() <= d.head_upper_bound());\n\n        d\n    }\n\n    /// Create an empty deque with capacity to hold `n` elements.\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// # use slice_deque::SliceDeque;\n    /// let deq = SliceDeque::with_capacity(10);\n    /// # let o: SliceDeque<u32> = deq;\n    /// ```\n    #[inline]\n    pub fn with_capacity(n: usize) -> Self {\n        unsafe {\n            Self {\n                head_: 0,\n                tail_: 0,\n                buf: Buffer::uninitialized(2 * n).unwrap_or_else(|e| {\n                    let s = tiny_str!(\n                        \"failed to allocate a buffer with capacity \\\"{}\\\" due to \\\"{:?}\\\"\",\n                        n, e\n                    );\n                    panic!(\"{}\", s.as_str())\n                }),\n            }\n        }\n    }\n\n    /// Returns the number of elements that the deque can hold without\n    /// reallocating.\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// # use slice_deque::SliceDeque;\n    /// let deq = SliceDeque::with_capacity(10);\n    /// assert!(deq.capacity() >= 10);\n    /// # let o: SliceDeque<u32> = deq;\n    /// ```\n    #[inline]\n    pub fn capacity(&self) -> usize {\n        // Note: the buffer length is not necessarily a power of two\n        // debug_assert!(self.buf.len() % 2 == 0);\n        self.buf.len() / 2\n    }\n\n    /// Largest tail value\n    #[inline]\n    fn tail_upper_bound(&self) -> usize {\n        self.capacity() * 2\n    }\n\n    /// Largest head value\n    #[inline]\n    fn head_upper_bound(&self) -> usize {\n        self.capacity()\n    }\n\n    /// Get index to the head\n    #[inline]\n    fn head(&self) -> usize {\n        self.head_\n    }\n\n    /// Get index to the tail\n    #[inline]\n    fn tail(&self) -> usize {\n        self.tail_\n    }\n\n    /// Number of elements in the ring buffer.\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// # use slice_deque::SliceDeque;\n    /// let mut deq = SliceDeque::with_capacity(10);\n    /// assert!(deq.len() == 0);\n    /// deq.push_back(3);\n    /// assert!(deq.len() == 1);\n    /// ```\n    #[inline]\n    pub fn len(&self) -> usize {\n        let l = self.tail() - self.head();\n        debug_assert!(self.tail() >= self.head());\n        debug_assert!(l <= self.capacity());\n        l\n    }\n\n    /// Is the ring buffer full ?\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// # use slice_deque::SliceDeque;\n    /// let mut deq = SliceDeque::with_capacity(10);\n    /// assert!(!deq.is_full());\n    /// # let o: SliceDeque<u32> = deq;\n    /// ```\n    #[inline]\n    pub fn is_full(&self) -> bool {\n        self.len() == self.capacity()\n    }\n\n    /// Extracts a slice containing the entire deque.\n    #[inline]\n    pub fn as_slice(&self) -> &[T] {\n        unsafe {\n            let ptr = self.buf.ptr();\n            let ptr = ptr.add(self.head());\n            slice::from_raw_parts(ptr, self.len())\n        }\n    }\n\n    /// Extracts a mutable slice containing the entire deque.\n    #[inline]\n    pub fn as_mut_slice(&mut self) -> &mut [T] {\n        unsafe {\n            let ptr = self.buf.ptr();\n            let ptr = ptr.add(self.head());\n            slice::from_raw_parts_mut(ptr, self.len())\n        }\n    }\n\n    /// Returns a pair of slices, where the first slice contains the contents\n    /// of the deque and the second one is empty.\n    #[inline]\n    pub fn as_slices(&self) -> (&[T], &[T]) {\n        unsafe {\n            let left = self.as_slice();\n            let right =\n                slice::from_raw_parts(usize::max_value() as *const _, 0);\n            (left, right)\n        }\n    }\n\n    /// Returns a pair of slices, where the first slice contains the contents\n    /// of the deque and the second one is empty.\n    #[inline]\n    pub fn as_mut_slices(&mut self) -> (&mut [T], &mut [T]) {\n        unsafe {\n            let left = self.as_mut_slice();\n            let right =\n                slice::from_raw_parts_mut(usize::max_value() as *mut _, 0);\n            (left, right)\n        }\n    }\n\n    /// Returns the slice of uninitialized memory between the `tail` and the\n    /// `head`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[macro_use] extern crate slice_deque;\n    /// # fn main() {\n    /// let mut d = sdeq![1, 2, 3];\n    /// let cap = d.capacity();\n    /// let len = d.len();\n    /// unsafe {\n    ///     {\n    ///         // This slice contains the uninitialized elements in\n    ///         // the deque:\n    ///         let mut s = d.tail_head_slice();\n    ///         assert_eq!(s.len(), cap - len);\n    ///         // We can write to them and for example bump the tail of\n    ///         // the deque:\n    ///         s[0] = 4;\n    ///         s[1] = 5;\n    ///     }\n    ///     d.move_tail(2);\n    /// }\n    /// assert_eq!(d, sdeq![1, 2, 3, 4, 5]);\n    /// # }\n    /// ```\n    pub unsafe fn tail_head_slice(&mut self) -> &mut [T] {\n        let ptr = self.buf.ptr();\n        let ptr = ptr.add(self.tail());\n        slice::from_raw_parts_mut(ptr, self.capacity() - self.len())\n    }\n\n    /// Attempts to reserve capacity for inserting at least `additional`\n    /// elements without reallocating. Does nothing if the capacity is already\n    /// sufficient.\n    ///\n    /// The collection always reserves memory in multiples of the page size.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the new capacity overflows `usize`.\n    #[inline]\n    pub fn try_reserve(\n        &mut self, additional: usize,\n    ) -> Result<(), AllocError> {\n        let old_len = self.len();\n        let new_cap = self.grow_policy(additional);\n        self.reserve_capacity(new_cap)?;\n        debug_assert!(self.capacity() >= old_len + additional);\n        Ok(())\n    }\n\n    /// Reserves capacity for inserting at least `additional` elements without\n    /// reallocating. Does nothing if the capacity is already sufficient.\n    ///\n    /// The collection always reserves memory in multiples of the page size.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the new capacity overflows `usize` or on OOM.\n    #[inline]\n    pub fn reserve(&mut self, additional: usize) {\n        self.try_reserve(additional).unwrap();\n    }\n\n    /// Attempts to reserve capacity for `new_capacity` elements. Does nothing\n    /// if the capacity is already sufficient.\n    #[inline]\n    fn reserve_capacity(\n        &mut self, new_capacity: usize,\n    ) -> Result<(), AllocError> {\n        unsafe {\n            if new_capacity <= self.capacity() {\n                return Ok(());\n            }\n\n            let mut new_buffer = Buffer::uninitialized(2 * new_capacity)?;\n            debug_assert!(new_buffer.len() >= 2 * new_capacity);\n\n            let len = self.len();\n            // Move the elements from the current buffer\n            // to the beginning of the new buffer:\n            {\n                let from_ptr = self.as_mut_ptr();\n                let to_ptr = new_buffer.as_mut_slice().as_mut_ptr();\n                ::core::ptr::copy_nonoverlapping(from_ptr, to_ptr, len);\n            }\n\n            // Exchange buffers\n            mem::swap(&mut self.buf, &mut new_buffer);\n\n            // Correct head and tail (we copied to the\n            // beginning of the of the new buffer)\n            self.head_ = 0;\n            self.tail_ = len;\n\n            Ok(())\n        }\n    }\n\n    /// Reserves the minimum capacity for exactly `additional` more elements to\n    /// be inserted in the given `SliceDeq<T>`. After calling `reserve_exact`,\n    /// capacity will be greater than or equal to `self.len() + additional`.\n    /// Does nothing if the capacity is already sufficient.\n    ///\n    /// Note that the allocator may give the collection more space than it\n    /// requests. Therefore capacity can not be relied upon to be precisely\n    /// minimal. Prefer `reserve` if future insertions are expected.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the new capacity overflows `usize`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[macro_use] extern crate slice_deque;\n    /// # fn main() {\n    /// let mut deq = sdeq![1];\n    /// deq.reserve_exact(10);\n    /// assert!(deq.capacity() >= 11);\n    /// # }\n    /// ```\n    #[inline]\n    pub fn reserve_exact(&mut self, additional: usize) {\n        let old_len = self.len();\n        let new_cap = old_len.checked_add(additional).expect(\"overflow\");\n        self.reserve_capacity(new_cap).unwrap();\n        debug_assert!(self.capacity() >= old_len + additional);\n    }\n\n    /// Growth policy of the deque. The capacity is going to be a multiple of\n    /// the page-size anyways, so we just double capacity when needed.\n    #[inline]\n    fn grow_policy(&self, additional: usize) -> usize {\n        let cur_cap = self.capacity();\n        let old_len = self.len();\n        let req_cap = old_len.checked_add(additional).expect(\"overflow\");\n        if req_cap > cur_cap {\n            let dbl_cap = cur_cap.saturating_mul(2);\n            cmp::max(req_cap, dbl_cap)\n        } else {\n            req_cap\n        }\n    }\n\n    /// Moves the deque head by `x`.\n    ///\n    /// # Panics\n    ///\n    /// If the `head` wraps over the `tail` the behavior is undefined, that is,\n    /// if `x` is out-of-range `[-(capacity() - len()), len()]`.\n    ///\n    /// If `-C debug-assertions=1` violating this pre-condition `panic!`s.\n    ///\n    /// # Unsafe\n    ///\n    /// It does not `drop` nor initialize elements, it just moves where the\n    /// tail of the deque points to within the allocated buffer.\n    #[inline]\n    #[cfg_attr(feature = \"cargo-clippy\", allow(clippy::cyclomatic_complexity))]\n    pub unsafe fn move_head_unchecked(&mut self, x: isize) {\n        // Make sure that the head does not wrap over the tail:\n        debug_assert!(x >= -((self.capacity() - self.len()) as isize));\n        debug_assert!(x <= self.len() as isize);\n        let head = self.head() as isize;\n        let mut new_head = head + x;\n        let tail = self.tail() as isize;\n        let cap = self.capacity();\n        debug_assert!(new_head <= tail);\n        debug_assert!(tail - new_head <= cap as isize);\n\n        if intrinsics::unlikely(new_head < 0) {\n            // If the new head is negative we shift the range by capacity to\n            // move it towards the second mirrored memory region.\n            debug_assert!(tail < cap as isize);\n            new_head += cap as isize;\n            debug_assert!(new_head >= 0);\n            self.tail_ += cap;\n        } else if new_head as usize > cap {\n            // cannot panic because new_head >= 0\n            // If the new head is larger than the capacity, we shift the range\n            // by -capacity to move it towards the first mirrored\n            // memory region.\n            debug_assert!(tail >= cap as isize);\n            new_head -= cap as isize;\n            debug_assert!(new_head >= 0);\n            self.tail_ -= cap;\n        }\n\n        self.head_ = new_head as usize;\n        debug_assert!(self.len() as isize == (tail - head) - x);\n        debug_assert!(self.head() <= self.tail());\n\n        debug_assert!(self.tail() <= self.tail_upper_bound());\n        debug_assert!(self.head() <= self.head_upper_bound());\n    }\n\n    /// Moves the deque head by `x`.\n    ///\n    /// # Panics\n    ///\n    /// If the `head` wraps over the `tail`, that is, if `x` is out-of-range\n    /// `[-(capacity() - len()), len()]`.\n    ///\n    /// # Unsafe\n    ///\n    /// It does not `drop` nor initialize elements, it just moves where the\n    /// tail of the deque points to within the allocated buffer.\n    #[inline]\n    pub unsafe fn move_head(&mut self, x: isize) {\n        assert!(\n            x >= -((self.capacity() - self.len()) as isize)\n                && x <= self.len() as isize\n        );\n        self.move_head_unchecked(x)\n    }\n\n    /// Moves the deque tail by `x`.\n    ///\n    /// # Panics\n    ///\n    /// If the `tail` wraps over the `head` the behavior is undefined, that is,\n    /// if `x` is out-of-range `[-len(), capacity() - len()]`.\n    ///\n    /// If `-C debug-assertions=1` violating this pre-condition `panic!`s.\n    ///\n    /// # Unsafe\n    ///\n    /// It does not `drop` nor initialize elements, it just moves where the\n    /// tail of the deque points to within the allocated buffer.\n    #[inline]\n    pub unsafe fn move_tail_unchecked(&mut self, x: isize) {\n        // Make sure that the tail does not wrap over the head:\n        debug_assert!(x >= -(self.len() as isize));\n        debug_assert!(\n            x <= (self.capacity() - self.len()) as isize,\n            \"x = {}, len = {}, cap = {}\",\n            x,\n            self.len(),\n            self.capacity()\n        );\n        let head = self.head() as isize;\n        let tail = self.tail() as isize;\n        let cap = self.capacity() as isize;\n        let mut new_tail = tail + x;\n        debug_assert!(new_tail >= 0);\n        debug_assert!(head <= new_tail);\n        debug_assert!(new_tail - head <= cap);\n\n        // If the new tail falls of the mirrored region of virtual memory we\n        // shift the range by -capacity to move it towards the first mirrored\n        // memory region.\n\n        if intrinsics::unlikely(new_tail >= 2 * cap) {\n            debug_assert!(head >= cap);\n            self.head_ -= cap as usize;\n            new_tail -= cap as isize;\n            debug_assert!(new_tail <= cap);\n        }\n\n        self.tail_ = new_tail as usize;\n        debug_assert!(self.len() as isize == (tail - head) + x);\n\n        debug_assert!(self.tail() <= self.tail_upper_bound());\n        debug_assert!(self.head() <= self.head_upper_bound());\n    }\n\n    /// Moves the deque tail by `x`.\n    ///\n    /// # Panics\n    ///\n    /// If the `tail` wraps over the `head`, that is, if `x` is out-of-range\n    /// `[-len(), capacity() - len()]`.\n    ///\n    /// # Unsafe\n    ///\n    /// It does not `drop` nor initialize elements, it just moves where the\n    /// tail of the deque points to within the allocated buffer.\n    #[inline]\n    pub unsafe fn move_tail(&mut self, x: isize) {\n        assert!(\n            x >= -(self.len() as isize)\n                && x <= (self.capacity() - self.len()) as isize\n        );\n        self.move_tail_unchecked(x);\n    }\n\n    /// Appends elements to `self` from `other`.\n    #[inline]\n    unsafe fn append_elements(&mut self, other: *const [T]) {\n        let count = (*other).len();\n        self.reserve(count);\n        let len = self.len();\n        ptr::copy_nonoverlapping(\n            other as *const T,\n            self.get_unchecked_mut(len),\n            count,\n        );\n        self.move_tail_unchecked(count as isize);\n    }\n\n    /// Steal the elements from the slice `s`. You should `mem::forget` the\n    /// slice afterwards.\n    pub unsafe fn steal_from_slice(s: &[T]) -> Self {\n        let mut deq = Self::new();\n        deq.append_elements(s as *const _);\n        deq\n    }\n\n    /// Moves all the elements of `other` into `Self`, leaving `other` empty.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the number of elements in the deque overflows a `isize`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[macro_use] extern crate slice_deque;\n    /// # use slice_deque::SliceDeque;\n    /// # fn main() {\n    /// let mut deq = sdeq![1, 2, 3];\n    /// let mut deq2 = sdeq![4, 5, 6];\n    /// deq.append(&mut deq2);\n    /// assert_eq!(deq, [1, 2, 3, 4, 5, 6]);\n    /// assert_eq!(deq2, []);\n    /// # }\n    /// ```\n    #[inline]\n    pub fn append(&mut self, other: &mut Self) {\n        unsafe {\n            self.append_elements(other.as_slice() as _);\n            other.head_ = 0;\n            other.tail_ = 0;\n        }\n    }\n\n    /// Provides a reference to the first element, or `None` if the deque is\n    /// empty.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # use slice_deque::SliceDeque;\n    /// let mut deq = SliceDeque::new();\n    /// assert_eq!(deq.front(), None);\n    ///\n    /// deq.push_back(1);\n    /// deq.push_back(2);\n    /// assert_eq!(deq.front(), Some(&1));\n    /// deq.push_front(3);\n    /// assert_eq!(deq.front(), Some(&3));\n    /// ```\n    #[inline]\n    pub fn front(&self) -> Option<&T> {\n        self.get(0)\n    }\n\n    /// Provides a mutable reference to the first element, or `None` if the\n    /// deque is empty.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # use slice_deque::SliceDeque;\n    /// let mut deq = SliceDeque::new();\n    /// assert_eq!(deq.front(), None);\n    ///\n    /// deq.push_back(1);\n    /// deq.push_back(2);\n    /// assert_eq!(deq.front(), Some(&1));\n    /// (*deq.front_mut().unwrap()) = 3;\n    /// assert_eq!(deq.front(), Some(&3));\n    /// ```\n    #[inline]\n    pub fn front_mut(&mut self) -> Option<&mut T> {\n        self.get_mut(0)\n    }\n\n    /// Provides a reference to the last element, or `None` if the deque is\n    /// empty.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # use slice_deque::SliceDeque;\n    /// let mut deq = SliceDeque::new();\n    /// assert_eq!(deq.back(), None);\n    ///\n    /// deq.push_back(1);\n    /// deq.push_back(2);\n    /// assert_eq!(deq.back(), Some(&2));\n    /// deq.push_front(3);\n    /// assert_eq!(deq.back(), Some(&2));\n    /// ```\n    #[inline]\n    pub fn back(&self) -> Option<&T> {\n        let last_idx = self.len().wrapping_sub(1);\n        self.get(last_idx)\n    }\n\n    /// Provides a mutable reference to the last element, or `None` if the\n    /// deque is empty.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # use slice_deque::SliceDeque;\n    /// let mut deq = SliceDeque::new();\n    /// assert_eq!(deq.front(), None);\n    ///\n    /// deq.push_back(1);\n    /// deq.push_back(2);\n    /// assert_eq!(deq.back(), Some(&2));\n    /// (*deq.back_mut().unwrap()) = 3;\n    /// assert_eq!(deq.back(), Some(&3));\n    /// ```\n    #[inline]\n    pub fn back_mut(&mut self) -> Option<&mut T> {\n        let last_idx = self.len().wrapping_sub(1);\n        self.get_mut(last_idx)\n    }\n\n    /// Attempts to prepend `value` to the deque.\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// # use slice_deque::SliceDeque;\n    /// let mut deq = SliceDeque::new();\n    /// deq.try_push_front(1).unwrap();\n    /// deq.try_push_front(2).unwrap();\n    /// assert_eq!(deq.front(), Some(&2));\n    /// ```\n    #[inline]\n    pub fn try_push_front(&mut self, value: T) -> Result<(), (T, AllocError)> {\n        unsafe {\n            if intrinsics::unlikely(self.is_full()) {\n                if let Err(e) = self.try_reserve(1) {\n                    return Err((value, e));\n                }\n            }\n\n            self.move_head_unchecked(-1);\n            ptr::write(self.get_mut(0).unwrap(), value);\n            Ok(())\n        }\n    }\n\n    /// Prepends `value` to the deque.\n    ///\n    /// # Panics\n    ///\n    /// On OOM.\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// # use slice_deque::SliceDeque;\n    /// let mut deq = SliceDeque::new();\n    /// deq.push_front(1);\n    /// deq.push_front(2);\n    /// assert_eq!(deq.front(), Some(&2));\n    /// ```\n    #[inline]\n    pub fn push_front(&mut self, value: T) {\n        if let Err(e) = self.try_push_front(value) {\n            panic!(\"{:?}\", e.1);\n        }\n    }\n\n    /// Attempts to appends `value` to the deque.\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// # use slice_deque::SliceDeque;\n    /// let mut deq = SliceDeque::new();\n    /// deq.try_push_back(1).unwrap();\n    /// deq.try_push_back(3).unwrap();\n    /// assert_eq!(deq.back(), Some(&3));\n    /// ```\n    #[inline]\n    pub fn try_push_back(&mut self, value: T) -> Result<(), (T, AllocError)> {\n        unsafe {\n            if intrinsics::unlikely(self.is_full()) {\n                if let Err(e) = self.try_reserve(1) {\n                    return Err((value, e));\n                }\n            }\n            self.move_tail_unchecked(1);\n            let len = self.len();\n            ptr::write(self.get_mut(len - 1).unwrap(), value);\n            Ok(())\n        }\n    }\n\n    /// Appends `value` to the deque.\n    ///\n    /// # Panics\n    ///\n    /// On OOM.\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// # use slice_deque::SliceDeque;\n    /// let mut deq = SliceDeque::new();\n    /// deq.push_back(1);\n    /// deq.push_back(3);\n    /// assert_eq!(deq.back(), Some(&3));\n    /// ```\n    #[inline]\n    pub fn push_back(&mut self, value: T) {\n        if let Err(e) = self.try_push_back(value) {\n            panic!(\"{:?}\", e.1);\n        }\n    }\n\n    /// Removes the first element and returns it, or `None` if the deque is\n    /// empty.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # use slice_deque::SliceDeque;\n    /// let mut deq = SliceDeque::new();\n    /// assert_eq!(deq.pop_front(), None);\n    ///\n    /// deq.push_back(1);\n    /// deq.push_back(2);\n    ///\n    /// assert_eq!(deq.pop_front(), Some(1));\n    /// assert_eq!(deq.pop_front(), Some(2));\n    /// assert_eq!(deq.pop_front(), None);\n    /// ```\n    #[inline]\n    pub fn pop_front(&mut self) -> Option<T> {\n        unsafe {\n            let v = match self.get_mut(0) {\n                None => return None,\n                Some(v) => ptr::read(v),\n            };\n            self.move_head_unchecked(1);\n            Some(v)\n        }\n    }\n\n    /// Removes the last element from the deque and returns it, or `None` if it\n    /// is empty.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # use slice_deque::SliceDeque;\n    /// let mut deq = SliceDeque::new();\n    /// assert_eq!(deq.pop_back(), None);\n    ///\n    /// deq.push_back(1);\n    /// deq.push_back(3);\n    ///\n    /// assert_eq!(deq.pop_back(), Some(3));\n    /// assert_eq!(deq.pop_back(), Some(1));\n    /// assert_eq!(deq.pop_back(), None);\n    /// ```\n    #[inline]\n    pub fn pop_back(&mut self) -> Option<T> {\n        unsafe {\n            let len = self.len();\n            let v = match self.get_mut(len.wrapping_sub(1)) {\n                None => return None,\n                Some(v) => ptr::read(v),\n            };\n            self.move_tail_unchecked(-1);\n            Some(v)\n        }\n    }\n\n    /// Shrinks the capacity of the deque as much as possible.\n    ///\n    /// It will drop down as close as possible to the length, but because\n    /// `SliceDeque` allocates memory in multiples of the page size the deque\n    /// might still have capacity for inserting new elements without\n    /// reallocating.\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// # use slice_deque::SliceDeque;\n    /// let mut deq = SliceDeque::with_capacity(15);\n    /// deq.extend(0..4);\n    /// assert!(deq.capacity() >= 15);\n    /// deq.shrink_to_fit();\n    /// assert!(deq.capacity() >= 4);\n    /// # let o: SliceDeque<u32> = deq;\n    /// ```\n    #[inline]\n    pub fn shrink_to_fit(&mut self) {\n        if unsafe { intrinsics::unlikely(self.is_empty()) } {\n            return;\n        }\n\n        let mut new_vd = Self::with_capacity(self.len());\n        if new_vd.capacity() < self.capacity() {\n            unsafe {\n                ::core::ptr::copy_nonoverlapping(\n                    self.as_mut_ptr(),\n                    new_vd.as_mut_ptr(),\n                    self.len(),\n                );\n            }\n            new_vd.tail_ = self.len();\n            mem::swap(self, &mut new_vd);\n        }\n    }\n\n    /// Shortens the deque by removing excess elements from the back.\n    ///\n    /// If `len` is greater than the SliceDeque's current length, this has no\n    /// effect.\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// # #[macro_use] extern crate slice_deque;\n    /// # use slice_deque::SliceDeque;\n    /// # fn main() {\n    /// let mut deq = sdeq![5, 10, 15];\n    /// assert_eq!(deq, [5, 10, 15]);\n    /// deq.truncate_back(1);\n    /// assert_eq!(deq, [5]);\n    /// # }\n    /// ```\n    #[inline]\n    pub fn truncate_back(&mut self, len: usize) {\n        unsafe {\n            while len < self.len() {\n                // decrement tail before the drop_in_place(), so a panic on\n                // Drop doesn't re-drop the just-failed value.\n                self.move_tail(-1);\n                let len = self.len();\n                core::ptr::drop_in_place(self.get_unchecked_mut(len));\n            }\n        }\n    }\n\n    /// Shortens the deque by removing excess elements from the back.\n    ///\n    /// If `len` is greater than the SliceDeque's current length, this has no\n    /// effect. See `truncate_back` for examples.\n    #[inline]\n    pub fn truncate(&mut self, len: usize) {\n        self.truncate_back(len);\n    }\n\n    /// Shortens the deque by removing excess elements from the front.\n    ///\n    /// If `len` is greater than the SliceDeque's current length, this has no\n    /// effect.\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// # #[macro_use] extern crate slice_deque;\n    /// # use slice_deque::SliceDeque;\n    /// # fn main() {\n    /// let mut deq = sdeq![5, 10, 15];\n    /// assert_eq!(deq, [5, 10, 15]);\n    /// deq.truncate_front(1);\n    /// assert_eq!(deq, [15]);\n    /// # }\n    /// ```\n    #[inline]\n    pub fn truncate_front(&mut self, len: usize) {\n        unsafe {\n            while len < self.len() {\n                let head: *mut T = self.get_unchecked_mut(0) as *mut _;\n                // increment head before the drop_in_place(), so a panic on\n                // Drop doesn't re-drop the just-failed value.\n                self.move_head(1);\n                core::ptr::drop_in_place(head);\n            }\n        }\n    }\n\n    /// Creates a draining iterator that removes the specified range in the\n    /// deque and yields the removed items.\n    ///\n    /// Note 1: The element range is removed even if the iterator is only\n    /// partially consumed or not consumed at all.\n    ///\n    /// Note 2: It is unspecified how many elements are removed from the deque\n    /// if the `Drain` value is leaked.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the starting point is greater than the end point or if\n    /// the end point is greater than the length of the deque.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[macro_use] extern crate slice_deque;\n    /// # use slice_deque::SliceDeque;\n    /// # fn main() {\n    /// let mut deq = sdeq![1, 2, 3];\n    /// let u: Vec<_> = deq.drain(1..).collect();\n    /// assert_eq!(deq, &[1]);\n    /// assert_eq!(u, &[2, 3]);\n    ///\n    /// // A full range clears the deque\n    /// deq.drain(..);\n    /// assert_eq!(deq, &[]);\n    /// # }\n    /// ```\n    #[inline]\n    #[cfg(all(feature = \"unstable\", feature = \"use_std\"))]\n    #[cfg_attr(\n        feature = \"cargo-clippy\",\n        allow(clippy::needless_pass_by_value)\n    )]\n    pub fn drain<R>(&mut self, range: R) -> Drain<T>\n    where\n        R: ops::RangeBounds<usize>,\n    {\n        use ops::Bound::{Excluded, Included, Unbounded};\n        // Memory safety\n        //\n        // When the Drain is first created, it shortens the length of\n        // the source deque to make sure no uninitalized or moved-from\n        // elements are accessible at all if the Drain's destructor\n        // never gets to run.\n        //\n        // Drain will ptr::read out the values to remove.\n        // When finished, remaining tail of the deque is copied back to cover\n        // the hole, and the deque length is restored to the new length.\n        //\n        let len = self.len();\n        let start = match range.start_bound() {\n            Included(&n) => n,\n            Excluded(&n) => n + 1,\n            Unbounded => 0,\n        };\n        let end = match range.end_bound() {\n            Included(&n) => n + 1,\n            Excluded(&n) => n,\n            Unbounded => len,\n        };\n        assert!(start <= end);\n        assert!(end <= len);\n\n        unsafe {\n            // set self.deq length's to start, to be safe in case Drain is\n            // leaked\n            self.tail_ = self.head() + start;;\n            // Use the borrow in the IterMut to indicate borrowing behavior of\n            // the whole Drain iterator (like &mut T).\n            let range_slice = slice::from_raw_parts_mut(\n                self.as_mut_ptr().add(start),\n                end - start,\n            );\n            Drain {\n                tail_start: end,\n                tail_len: len - end,\n                iter: range_slice.iter(),\n                deq: NonNull::from(self),\n            }\n        }\n    }\n\n    /// Removes all values from the deque.\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// # #[macro_use] extern crate slice_deque;\n    /// # use slice_deque::SliceDeque;\n    /// # fn main() {\n    /// let mut deq = sdeq![1];\n    /// assert!(!deq.is_empty());\n    /// deq.clear();\n    /// assert!(deq.is_empty());\n    /// # }\n    /// ```\n    #[inline]\n    pub fn clear(&mut self) {\n        self.truncate(0);\n    }\n\n    /// Removes the element at `index` and return it in `O(1)` by swapping the\n    /// last element into its place.\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// # use slice_deque::SliceDeque;\n    /// let mut deq = SliceDeque::new();\n    /// assert_eq!(deq.swap_remove_back(0), None);\n    /// deq.extend(1..4);\n    /// assert_eq!(deq, [1, 2, 3]);\n    ///\n    /// assert_eq!(deq.swap_remove_back(0), Some(1));\n    /// assert_eq!(deq, [3, 2]);\n    /// ```\n    #[inline]\n    pub fn swap_remove_back(&mut self, index: usize) -> Option<T> {\n        let len = self.len();\n        if self.is_empty() {\n            None\n        } else {\n            self.swap(index, len - 1);\n            self.pop_back()\n        }\n    }\n\n    /// Removes the element at `index` and returns it in `O(1)` by swapping the\n    /// first element into its place.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # use slice_deque::SliceDeque;\n    /// let mut deq = SliceDeque::new();\n    /// assert_eq!(deq.swap_remove_front(0), None);\n    /// deq.extend(1..4);\n    /// assert_eq!(deq, [1, 2, 3]);\n    ///\n    /// assert_eq!(deq.swap_remove_front(2), Some(3));\n    /// assert_eq!(deq, [2, 1]);\n    /// ```\n    #[inline]\n    pub fn swap_remove_front(&mut self, index: usize) -> Option<T> {\n        if self.is_empty() {\n            None\n        } else {\n            self.swap(index, 0);\n            self.pop_front()\n        }\n    }\n\n    /// Inserts an `element` at `index` within the deque, shifting all elements\n    /// with indices greater than or equal to `index` towards the back.\n    ///\n    /// Element at index 0 is the front of the queue.\n    ///\n    /// # Panics\n    ///\n    /// Panics if `index` is greater than deque's length\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[macro_use] extern crate slice_deque;\n    /// # use slice_deque::SliceDeque;\n    /// # fn main() {\n    /// let mut deq = sdeq!['a', 'b', 'c'];\n    /// assert_eq!(deq, &['a', 'b', 'c']);\n    ///\n    /// deq.insert(1, 'd');\n    /// assert_eq!(deq, &['a', 'd', 'b', 'c']);\n    /// # }\n    /// ```\n    #[inline]\n    pub fn insert(&mut self, index: usize, element: T) {\n        unsafe {\n            let len = self.len();\n            assert!(index <= len);\n\n            if intrinsics::unlikely(self.is_full()) {\n                self.reserve(1);\n            }\n\n            let p = self.as_mut_ptr().add(index);\n            ptr::copy(p, p.add(1), len - index); // Shift elements\n            ptr::write(p, element); // Overwritte\n            self.move_tail_unchecked(1);\n        }\n    }\n\n    /// Removes and returns the element at position `index` within the deque,\n    /// shifting all elements after it to the front.\n    ///\n    /// # Panics\n    ///\n    /// Panics if `index` is out of bounds.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[macro_use] extern crate slice_deque;\n    /// # use slice_deque::SliceDeque;\n    /// # fn main() {\n    /// let mut deq = sdeq![1, 2, 3];\n    /// assert_eq!(deq.remove(1), 2);\n    /// assert_eq!(deq, [1, 3]);\n    /// # }\n    /// ```\n    #[inline]\n    pub fn remove(&mut self, index: usize) -> T {\n        let len = self.len();\n        assert!(index < len);\n        unsafe {\n            // copy element at pointer:\n            let ptr = self.as_mut_ptr().add(index);\n            let ret = ptr::read(ptr);\n            // shift everything to the front overwriting the deque copy of the\n            // element:\n            ptr::copy(ptr.add(1), ptr, len - index - 1);\n            self.move_tail_unchecked(-1);\n            ret\n        }\n    }\n\n    /// Splits the collection into two at the given index.\n    ///\n    /// Returns a newly allocated `Self`. `self` contains elements `[0, at)`,\n    /// and the returned `Self` contains elements `[at, len)`.\n    ///\n    /// Note that the capacity of `self` does not change.\n    ///\n    /// # Panics\n    ///\n    /// Panics if `at > len`.\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// # #[macro_use] extern crate slice_deque;\n    /// # use slice_deque::SliceDeque;\n    /// # fn main() {\n    /// let mut deq = sdeq![1, 2, 3];\n    /// let deq2 = deq.split_off(1);\n    /// assert_eq!(deq, [1]);\n    /// assert_eq!(deq2, [2, 3]);\n    /// # }\n    /// ```\n    #[inline]\n    pub fn split_off(&mut self, at: usize) -> Self {\n        assert!(at <= self.len(), \"`at` out of bounds\");\n\n        let other_len = self.len() - at;\n        let mut other = Self::with_capacity(other_len);\n\n        unsafe {\n            self.move_tail_unchecked(-(other_len as isize));\n            other.move_tail_unchecked(other_len as isize);\n\n            ptr::copy_nonoverlapping(\n                self.as_ptr().add(at),\n                other.as_mut_ptr(),\n                other.len(),\n            );\n        }\n        other\n    }\n\n    /// Retains only the elements specified by the predicate.\n    ///\n    /// That is, remove all elements `e` such that `f(&e)` returns `false`.\n    /// This method operates in place and preserves the order of the\n    /// retained elements.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[macro_use] extern crate slice_deque;\n    /// # use slice_deque::SliceDeque;\n    /// # fn main() {\n    /// let mut deq = sdeq![1, 2, 3, 4];\n    /// deq.retain(|&x| x % 2 == 0);\n    /// assert_eq!(deq, [2, 4]);\n    /// # }\n    /// ```\n    #[inline]\n    pub fn retain<F>(&mut self, mut f: F)\n    where\n        F: FnMut(&T) -> bool,\n    {\n        let len = self.len();\n        let mut del = 0;\n        {\n            let v = &mut **self;\n\n            for i in 0..len {\n                if !f(&v[i]) {\n                    del += 1;\n                } else if del > 0 {\n                    v.swap(i - del, i);\n                }\n            }\n        }\n        if del > 0 {\n            self.truncate(len - del);\n        }\n    }\n\n    /// Removes all but the first of consecutive elements in the deque that\n    /// resolve to the same key.\n    ///\n    /// If the deque is sorted, this removes all duplicates.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[macro_use] extern crate slice_deque;\n    /// # use slice_deque::SliceDeque;\n    /// # fn main() {\n    /// let mut deq = sdeq![10, 20, 21, 30, 20];\n    ///\n    /// deq.dedup_by_key(|i| *i / 10);\n    /// assert_eq!(deq, [10, 20, 30, 20]);\n    /// # }\n    /// ```\n    #[inline]\n    pub fn dedup_by_key<F, K>(&mut self, mut key: F)\n    where\n        F: FnMut(&mut T) -> K,\n        K: PartialEq,\n    {\n        self.dedup_by(|a, b| key(a) == key(b))\n    }\n\n    /// Removes all but the first of consecutive elements in the deque\n    /// satisfying a given equality relation.\n    ///\n    /// The `same_bucket` function is passed references to two elements from\n    /// the deque, and returns `true` if the elements compare equal, or\n    /// `false` if they do not. The elements are passed in opposite order\n    /// from their order in the deque, so if `same_bucket(a, b)` returns\n    /// `true`, `a` is removed.\n    ///\n    /// If the deque is sorted, this removes all duplicates.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[macro_use] extern crate slice_deque;\n    /// # use slice_deque::SliceDeque;\n    /// # fn main() {\n    /// let mut deq = sdeq![\"foo\", \"bar\", \"Bar\", \"baz\", \"bar\"];\n    ///\n    /// deq.dedup_by(|a, b| a.eq_ignore_ascii_case(b));\n    ///\n    /// assert_eq!(deq, [\"foo\", \"bar\", \"baz\", \"bar\"]);\n    /// # }\n    /// ```\n    #[inline]\n    pub fn dedup_by<F>(&mut self, mut same_bucket: F)\n    where\n        F: FnMut(&mut T, &mut T) -> bool,\n    {\n        unsafe {\n            // Although we have a mutable reference to `self`, we cannot make\n            // *arbitrary* changes. The `same_bucket` calls could panic, so we\n            // must ensure that the deque is in a valid state at all time.\n            //\n            // The way that we handle this is by using swaps; we iterate\n            // over all the elements, swapping as we go so that at the end\n            // the elements we wish to keep are in the front, and those we\n            // wish to reject are at the back. We can then truncate the\n            // deque. This operation is still O(n).\n            //\n            // Example: We start in this state, where `r` represents \"next\n            // read\" and `w` represents \"next_write`.\n            //\n            //           r\n            //     +---+---+---+---+---+---+\n            //     | 0 | 1 | 1 | 2 | 3 | 3 |\n            //     +---+---+---+---+---+---+\n            //           w\n            //\n            // Comparing self[r] against self[w-1], this is not a duplicate, so\n            // we swap self[r] and self[w] (no effect as r==w) and then\n            // increment both r and w, leaving us with:\n            //\n            //               r\n            //     +---+---+---+---+---+---+\n            //     | 0 | 1 | 1 | 2 | 3 | 3 |\n            //     +---+---+---+---+---+---+\n            //               w\n            //\n            // Comparing self[r] against self[w-1], this value is a duplicate,\n            // so we increment `r` but leave everything else unchanged:\n            //\n            //                   r\n            //     +---+---+---+---+---+---+\n            //     | 0 | 1 | 1 | 2 | 3 | 3 |\n            //     +---+---+---+---+---+---+\n            //               w\n            //\n            // Comparing self[r] against self[w-1], this is not a duplicate,\n            // so swap self[r] and self[w] and advance r and w:\n            //\n            //                       r\n            //     +---+---+---+---+---+---+\n            //     | 0 | 1 | 2 | 1 | 3 | 3 |\n            //     +---+---+---+---+---+---+\n            //                   w\n            //\n            // Not a duplicate, repeat:\n            //\n            //                           r\n            //     +---+---+---+---+---+---+\n            //     | 0 | 1 | 2 | 3 | 1 | 3 |\n            //     +---+---+---+---+---+---+\n            //                       w\n            //\n            // Duplicate, advance r. End of deque. Truncate to w.\n\n            let ln = self.len();\n            if intrinsics::unlikely(ln <= 1) {\n                return;\n            }\n\n            // Avoid bounds checks by using raw pointers.\n            let p = self.as_mut_ptr();\n            let mut r: usize = 1;\n            let mut w: usize = 1;\n\n            while r < ln {\n                let p_r = p.add(r);\n                let p_wm1 = p.add(w - 1);\n                if !same_bucket(&mut *p_r, &mut *p_wm1) {\n                    if r != w {\n                        let p_w = p_wm1.add(1);\n                        mem::swap(&mut *p_r, &mut *p_w);\n                    }\n                    w += 1;\n                }\n                r += 1;\n            }\n\n            self.truncate(w);\n        }\n    }\n\n    /// Extend the `SliceDeque` by `n` values, using the given generator.\n    #[inline]\n    fn extend_with<E: ExtendWith<T>>(&mut self, n: usize, value: E) {\n        self.reserve(n);\n\n        unsafe {\n            let mut ptr = self.as_mut_ptr().add(self.len());\n\n            // Write all elements except the last one\n            for _ in 1..n {\n                ptr::write(ptr, value.next());\n                ptr = ptr.add(1);\n                // Increment the length in every step in case next() panics\n                self.move_tail_unchecked(1);\n            }\n\n            if n > 0 {\n                // We can write the last element directly without cloning\n                // needlessly\n                ptr::write(ptr, value.last());\n                self.move_tail_unchecked(1);\n            }\n\n            // len set by scope guard\n        }\n    }\n\n    /// Extend for a general iterator.\n    ///\n    /// This function should be the moral equivalent of:\n    ///\n    /// >  for item in iterator {\n    /// >      self.push_back(item);\n    /// >  }\n    #[inline]\n    fn extend_desugared<I: Iterator<Item = T>>(&mut self, mut iterator: I) {\n        #[cfg_attr(\n            feature = \"cargo-clippy\",\n            allow(clippy::while_let_on_iterator)\n        )]\n        while let Some(element) = iterator.next() {\n            let len = self.len();\n            let cap = self.capacity();\n            if len == cap {\n                let (lower, upper) = iterator.size_hint();\n                let additional_cap = if let Some(upper) = upper {\n                    upper\n                } else {\n                    lower\n                }\n                .checked_add(1)\n                .expect(\"overflow\");\n                self.reserve(additional_cap);\n            }\n            debug_assert!(self.len() < self.capacity());\n            unsafe {\n                ptr::write(self.get_unchecked_mut(len), element);\n                // NB can't overflow since we would have had to alloc the\n                // address space\n                self.move_tail_unchecked(1);\n            }\n        }\n    }\n\n    /// Creates a splicing iterator that replaces the specified range in the\n    /// deque with the given `replace_with` iterator and yields the\n    /// removed items. `replace_with` does not need to be the same length\n    /// as `range`.\n    ///\n    /// Note 1: The element range is removed even if the iterator is not\n    /// consumed until the end.\n    ///\n    /// Note 2: It is unspecified how many elements are removed from the deque,\n    /// if the `Splice` value is leaked.\n    ///\n    /// Note 3: The input iterator `replace_with` is only consumed\n    /// when the `Splice` value is dropped.\n    ///\n    /// Note 4: This is optimal if:\n    ///\n    /// * The tail (elements in the deque after `range`) is empty,\n    /// * or `replace_with` yields fewer elements than `range`\u2019s length\n    /// * or the lower bound of its `size_hint()` is exact.\n    ///\n    /// Otherwise, a temporary deque is allocated and the tail is moved twice.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the starting point is greater than the end point or if\n    /// the end point is greater than the length of the deque.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[macro_use] extern crate slice_deque;\n    /// # use slice_deque::SliceDeque;\n    /// # fn main() {\n    /// let mut deq = sdeq![1, 2, 3];\n    /// let new = [7, 8];\n    /// let u: SliceDeque<_> = deq.splice(..2, new.iter().cloned()).collect();\n    /// assert_eq!(deq, &[7, 8, 3]);\n    /// assert_eq!(u, &[1, 2]);\n    /// # }\n    /// ```\n    #[inline]\n    #[cfg(all(feature = \"unstable\", feature = \"use_std\"))]\n    pub fn splice<R, I>(\n        &mut self, range: R, replace_with: I,\n    ) -> Splice<I::IntoIter>\n    where\n        R: ops::RangeBounds<usize>,\n        I: IntoIterator<Item = T>,\n    {\n        Splice {\n            drain: self.drain(range),\n            replace_with: replace_with.into_iter(),\n        }\n    }\n\n    /// Creates an iterator which uses a closure to determine if an element\n    /// should be removed.\n    ///\n    /// If the closure returns `true`, then the element is removed and yielded.\n    /// If the closure returns `false`, it will try again, and call the closure\n    /// on the next element, seeing if it passes the test.\n    ///\n    /// Using this method is equivalent to the following code:\n    ///\n    /// ```\n    /// # #[macro_use] extern crate slice_deque;\n    /// # use slice_deque::SliceDeque;\n    /// # fn main() {\n    /// # let some_predicate = |x: &mut i32| { *x == 2 || *x == 3 || *x == 6\n    /// # };\n    /// let mut deq = SliceDeque::new();\n    /// deq.extend(1..7);\n    /// let mut i = 0;\n    /// while i != deq.len() {\n    ///     if some_predicate(&mut deq[i]) {\n    ///         let val = deq.remove(i);\n    ///     // your code here\n    ///     } else {\n    ///         i += 1;\n    ///     }\n    /// }\n    /// # let mut expected = sdeq![1, 4, 5];\n    /// # assert_eq!(deq, expected);\n    /// # }\n    /// ```\n    ///\n    /// But `drain_filter` is easier to use. `drain_filter` is also more\n    /// efficient, because it can backshift the elements of the deque in\n    /// bulk.\n    ///\n    /// Note that `drain_filter` also lets you mutate every element in the\n    /// filter closure, regardless of whether you choose to keep or remove\n    /// it.\n    ///\n    ///\n    /// # Examples\n    ///\n    /// Splitting a deque into evens and odds, reusing the original allocation:\n    ///\n    /// ```\n    /// # #[macro_use] extern crate slice_deque;\n    /// # use slice_deque::SliceDeque;\n    /// # fn main() {\n    /// let mut numbers = sdeq![1, 2, 3, 4, 5, 6, 8, 9, 11, 13, 14, 15];\n    ///\n    /// let evens = numbers\n    ///     .drain_filter(|x| *x % 2 == 0)\n    ///     .collect::<SliceDeque<_>>();\n    /// let odds = numbers;\n    ///\n    /// assert_eq!(sdeq![2, 4, 6, 8, 14], evens);\n    /// assert_eq!(odds, sdeq![1, 3, 5, 9, 11, 13, 15]);\n    /// # }\n    /// ```\n    #[inline]\n    pub fn drain_filter<F>(&mut self, filter: F) -> DrainFilter<T, F>\n    where\n        F: FnMut(&mut T) -> bool,\n    {\n        let old_len = self.len();\n\n        // Guard against us getting leaked (leak amplification)\n        unsafe {\n            self.move_tail_unchecked(-(old_len as isize));\n        }\n\n        DrainFilter {\n            deq: self,\n            idx: 0,\n            del: 0,\n            old_len,\n            pred: filter,\n        }\n    }\n\n    // TODO: fn place_back(&mut self) -> PlaceBack<T>\n    // TODO: fn place_front(&mut self) -> PlaceFront<T>\n}\n\nimpl<T> SliceDeque<T>\nwhere\n    T: Clone,\n{\n    /// Clones and appends all elements in a slice to the `SliceDeque`.\n    ///\n    /// Iterates over the slice `other`, clones each element, and then appends\n    /// it to this `SliceDeque`. The `other` slice is traversed in-order.\n    ///\n    /// Note that this function is same as `extend` except that it is\n    /// specialized to work with slices instead. If and when Rust gets\n    /// specialization this function will likely be deprecated (but still\n    /// available).\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # use slice_deque::SliceDeque;\n    /// let mut deq = SliceDeque::new();\n    /// deq.push_back(1);\n    /// deq.extend_from_slice(&[2, 3, 4]);\n    /// assert_eq!(deq, [1, 2, 3, 4]);\n    /// ```\n    #[inline]\n    pub fn extend_from_slice(&mut self, other: &[T]) {\n        #[cfg(feature = \"unstable\")]\n        {\n            self.spec_extend(other.iter())\n        }\n        #[cfg(not(feature = \"unstable\"))]\n        {\n            self.reserve(other.len());\n            unsafe {\n                let len = self.len();\n                self.move_tail_unchecked(other.len() as isize);\n                self.get_unchecked_mut(len..).clone_from_slice(other);\n            }\n        }\n    }\n\n    /// Modifies the `SliceDeque` in-place so that `len()` is equal to\n    /// `new_len`, either by removing excess elements or by appending clones of\n    /// `value` to the back.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[macro_use] extern crate slice_deque;\n    /// # use slice_deque::SliceDeque;\n    /// # fn main() {\n    /// let mut deq = sdeq![5, 10, 15];\n    /// assert_eq!(deq, [5, 10, 15]);\n    ///\n    /// deq.resize(2, 0);\n    /// assert_eq!(deq, [5, 10]);\n    ///\n    /// deq.resize(5, 20);\n    /// assert_eq!(deq, [5, 10, 20, 20, 20]);\n    /// # }\n    /// ```\n    #[inline]\n    pub fn resize(&mut self, new_len: usize, value: T) {\n        let len = self.len();\n\n        if new_len > len {\n            self.reserve(new_len - len);\n            while self.len() < new_len {\n                self.push_back(value.clone());\n            }\n        } else {\n            self.truncate(new_len);\n        }\n        debug_assert!(self.len() == new_len);\n    }\n}\n\nimpl<T: Default> SliceDeque<T> {\n    /// Resizes the `SliceDeque` in-place so that `len` is equal to `new_len`.\n    ///\n    /// If `new_len` is greater than `len`, the `SliceDeque` is extended by the\n    /// difference, with each additional slot filled with `Default::default()`.\n    /// If `new_len` is less than `len`, the `SliceDeque` is simply truncated.\n    ///\n    /// This method uses `Default` to create new values on every push. If\n    /// you'd rather `Clone` a given value, use [`resize`].\n    ///\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[macro_use] extern crate slice_deque;\n    /// # use slice_deque::SliceDeque;\n    /// # fn main() {\n    /// let mut deq = sdeq![1, 2, 3];\n    /// deq.resize_default(5);\n    /// assert_eq!(deq, [1, 2, 3, 0, 0]);\n    ///\n    /// deq.resize_default(2);\n    /// assert_eq!(deq, [1, 2]);\n    /// # }\n    /// ```\n    ///\n    /// [`resize`]: #method.resize\n    #[inline]\n    pub fn resize_default(&mut self, new_len: usize) {\n        let len = self.len();\n\n        if new_len > len {\n            self.extend_with(new_len - len, ExtendDefault);\n        } else {\n            self.truncate(new_len);\n        }\n    }\n}\n\nimpl<T: PartialEq> SliceDeque<T> {\n    /// Removes consecutive repeated elements in the deque.\n    ///\n    /// If the deque is sorted, this removes all duplicates.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[macro_use] extern crate slice_deque;\n    /// # use slice_deque::SliceDeque;\n    /// # fn main() {\n    /// let mut deq = sdeq![1, 2, 2, 3, 2];\n    ///\n    /// deq.dedup();\n    /// assert_eq!(deq, [1, 2, 3, 2]);\n    ///\n    /// deq.sort();\n    /// assert_eq!(deq, [1, 2, 2, 3]);\n    ///\n    /// deq.dedup();\n    /// assert_eq!(deq, [1, 2, 3]);\n    /// # }\n    /// ```\n    #[inline]\n    pub fn dedup(&mut self) {\n        self.dedup_by(|a, b| a == b)\n    }\n\n    /// Removes the first instance of `item` from the deque if the item exists.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[macro_use] extern crate slice_deque;\n    /// # use slice_deque::SliceDeque;\n    /// # fn main() {\n    /// let mut deq = sdeq![1, 2, 3, 1];\n    ///\n    /// deq.remove_item(&1);\n    /// assert_eq!(deq, &[2, 3, 1]);\n    /// deq.remove_item(&1);\n    /// assert_eq!(deq, &[2, 3]);\n    /// # }\n    /// ```\n    #[inline]\n    pub fn remove_item(&mut self, item: &T) -> Option<T> {\n        let pos = match self.iter().position(|x| *x == *item) {\n            Some(x) => x,\n            None => return None,\n        };\n        Some(self.remove(pos))\n    }\n}\n\nimpl<T: fmt::Debug> fmt::Debug for SliceDeque<T> {\n    fn fmt(&self, f: &mut fmt::Formatter) -> Result<(), fmt::Error> {\n        write!(f, \"{:?}\", self.as_slice())\n        /*\n         write!(\n             f,\n             // TODO: \"SliceDeque({:?})\",\n             \"SliceDeque(len: {}, cap: {}, head: {}, tail: {}, elems: {:?})\",\n             self.len(),\n             self.capacity(),\n             self.head(),\n             self.tail(),\n             self.as_slice()\n         )\n        */\n    }\n}\n\nimpl<T> Drop for SliceDeque<T> {\n    #[inline]\n    fn drop(&mut self) {\n        self.clear();\n    }\n}\n\nimpl<T> ops::Deref for SliceDeque<T> {\n    type Target = [T];\n    #[inline]\n    fn deref(&self) -> &Self::Target {\n        self.as_slice()\n    }\n}\n\nimpl<T> ops::DerefMut for SliceDeque<T> {\n    #[inline]\n    fn deref_mut(&mut self) -> &mut Self::Target {\n        self.as_mut_slice()\n    }\n}\n\nimpl<T> Default for SliceDeque<T> {\n    #[inline]\n    fn default() -> Self {\n        Self::new()\n    }\n}\n\nimpl<T: Clone> Clone for SliceDeque<T> {\n    #[inline]\n    fn clone(&self) -> Self {\n        let mut new = Self::with_capacity(self.len());\n        for i in self.iter() {\n            new.push_back(i.clone());\n        }\n        new\n    }\n    #[inline]\n    fn clone_from(&mut self, other: &Self) {\n        self.clear();\n        for i in other.iter() {\n            self.push_back(i.clone());\n        }\n    }\n}\n\nimpl<'a, T: Clone> From<&'a [T]> for SliceDeque<T> {\n    #[inline]\n    fn from(s: &'a [T]) -> Self {\n        let mut new = Self::with_capacity(s.len());\n        for i in s {\n            new.push_back(i.clone());\n        }\n        new\n    }\n}\n\nimpl<'a, T: Clone> From<&'a mut [T]> for SliceDeque<T> {\n    #[inline]\n    fn from(s: &'a mut [T]) -> Self {\n        let mut new = Self::with_capacity(s.len());\n        for i in s {\n            new.push_back(i.clone());\n        }\n        new\n    }\n}\n\nimpl<T: hash::Hash> hash::Hash for SliceDeque<T> {\n    #[inline]\n    fn hash<H: hash::Hasher>(&self, state: &mut H) {\n        hash::Hash::hash(&**self, state)\n    }\n}\n\n///////////////////////////////////////////////////////////////////////////////\n// PartialEq implementations:\n\nmacro_rules! __impl_slice_eq1 {\n    ($Lhs:ty, $Rhs:ty) => {\n        __impl_slice_eq1! { $Lhs, $Rhs, Sized }\n    };\n    ($Lhs:ty, $Rhs:ty, $Bound:ident) => {\n        impl<'a, 'b, A: $Bound, B> PartialEq<$Rhs> for $Lhs\n        where\n            A: PartialEq<B>,\n        {\n            #[inline]\n            fn eq(&self, other: &$Rhs) -> bool {\n                self[..] == other[..]\n            }\n        }\n    };\n}\n\n__impl_slice_eq1! { SliceDeque<A>, SliceDeque<B> }\n__impl_slice_eq1! { SliceDeque<A>, &'b [B] }\n__impl_slice_eq1! { SliceDeque<A>, &'b mut [B] }\n\n#[cfg(feature = \"use_std\")]\n__impl_slice_eq1! { SliceDeque<A>, Vec<B> }\n\nmacro_rules! array_impls {\n    ($($N: expr)+) => {\n        $(\n            // NOTE: some less important impls are omitted to reduce code bloat\n            __impl_slice_eq1! { SliceDeque<A>, [B; $N] }\n            __impl_slice_eq1! { SliceDeque<A>, &'b [B; $N] }\n        )+\n    }\n}\n\narray_impls! {\n    0  1  2  3  4  5  6  7  8  9\n        10 11 12 13 14 15 16 17 18 19\n        20 21 22 23 24 25 26 27 28 29\n        30 31 32\n}\n\n///////////////////////////////////////////////////////////////////////////////\n\nimpl<T: Eq> Eq for SliceDeque<T> {}\n\nimpl<T: PartialOrd> PartialOrd for SliceDeque<T> {\n    #[inline]\n    fn partial_cmp(&self, other: &Self) -> Option<cmp::Ordering> {\n        PartialOrd::partial_cmp(&**self, &**other)\n    }\n}\n\nimpl<'a, T: PartialOrd> PartialOrd<&'a [T]> for SliceDeque<T> {\n    #[inline]\n    fn partial_cmp(&self, other: &&'a [T]) -> Option<cmp::Ordering> {\n        PartialOrd::partial_cmp(&**self, other)\n    }\n}\n\n/// A draining iterator for `SliceDeque<T>`.\n///\n/// This `struct` is created by the [`drain`] method on [`SliceDeque`].\n///\n/// [`drain`]: struct.SliceDeque.html#method.drain\n/// [`SliceDeque`]: struct.SliceDeque.html\npub struct Drain<'a, T: 'a> {\n    /// Index of tail to preserve\n    tail_start: usize,\n    /// Length of tail\n    tail_len: usize,\n    /// Current remaining range to remove\n    iter: slice::Iter<'a, T>,\n    /// A shared mutable pointer to the deque (with shared ownership).\n    deq: NonNull<SliceDeque<T>>,\n}\n\nimpl<'a, T: 'a + fmt::Debug> fmt::Debug for Drain<'a, T> {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        f.debug_tuple(\"Drain\").field(&self.iter.as_slice()).finish()\n    }\n}\n\nunsafe impl<'a, T: Sync> Sync for Drain<'a, T> {}\nunsafe impl<'a, T: Send> Send for Drain<'a, T> {}\n\nimpl<'a, T> Iterator for Drain<'a, T> {\n    type Item = T;\n\n    #[inline]\n    fn next(&mut self) -> Option<T> {\n        self.iter\n            .next()\n            .map(|elt| unsafe { ptr::read(elt as *const _) })\n    }\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.iter.size_hint()\n    }\n}\n\nimpl<'a, T> DoubleEndedIterator for Drain<'a, T> {\n    #[inline]\n    fn next_back(&mut self) -> Option<T> {\n        self.iter\n            .next_back()\n            .map(|elt| unsafe { ptr::read(elt as *const _) })\n    }\n}\n\nimpl<'a, T> Drop for Drain<'a, T> {\n    #[inline]\n    fn drop(&mut self) {\n        // exhaust self first\n        self.for_each(|_| {});\n\n        if self.tail_len > 0 {\n            unsafe {\n                let source_deq = self.deq.as_mut();\n                // memmove back untouched tail, update to new length\n                let start = source_deq.len();\n                let tail = self.tail_start;\n                let src = source_deq.as_ptr().add(tail);\n                let dst = source_deq.as_mut_ptr().add(start);\n                ptr::copy(src, dst, self.tail_len);\n                source_deq.move_tail_unchecked(self.tail_len as isize);\n            }\n        }\n    }\n}\n\n#[cfg(feature = \"unstable\")]\nimpl<'a, T> ExactSizeIterator for Drain<'a, T> {\n    #[inline]\n    fn is_empty(&self) -> bool {\n        self.iter.is_empty()\n    }\n}\n\n#[cfg(feature = \"unstable\")]\nimpl<'a, T> iter::FusedIterator for Drain<'a, T> {}\n\n/// An iterator that moves out of a deque.\n///\n/// This `struct` is created by the `into_iter` method on\n/// [`SliceDeque`][`SliceDeque`] (provided by the [`IntoIterator`] trait).\n///\n/// [`SliceDeque`]: struct.SliceDeque.html\n/// [`IntoIterator`]: ../../std/iter/trait.IntoIterator.html\npub struct IntoIter<T> {\n    /// NonNull pointer to the buffer\n    buf: NonNull<T>,\n    /// Capacity of the buffer.\n    cap: usize,\n    /// Pointer to the first element.\n    ptr: *const T,\n    /// Pointer to one-past-the-end.\n    end: *const T,\n}\n\nimpl<T: fmt::Debug> fmt::Debug for IntoIter<T> {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        f.debug_tuple(\"IntoIter\").field(&self.as_slice()).finish()\n    }\n}\n\nimpl<T> IntoIter<T> {\n    /// Returns the index of the head with respect to the beginning of the\n    /// buffer.\n    #[cfg(feature = \"unstable\")]\n    #[cfg_attr(feature = \"cargo-clippy\", allow(clippy::option_unwrap_used))]\n    #[inline]\n    fn head(&self) -> usize {\n        self.buf.as_ptr().offset_to_(self.ptr).unwrap() as usize\n    }\n\n    /// Returns the index of the tail with respect to the beginning of the\n    /// buffer.\n    #[cfg(feature = \"unstable\")]\n    #[cfg_attr(feature = \"cargo-clippy\", allow(clippy::option_unwrap_used))]\n    #[inline]\n    fn tail(&self) -> usize {\n        let t = self.buf.as_ptr().offset_to_(self.end).unwrap() as usize;\n        debug_assert!(t >= self.head());\n        t\n    }\n\n    /// Returns the remaining items of this iterator as a slice.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[macro_use] extern crate slice_deque;\n    /// # use slice_deque::SliceDeque;\n    /// # fn main() {\n    /// let mut deq = sdeq!['a', 'b', 'c'];\n    /// let mut into_iter = deq.into_iter();\n    /// assert_eq!(into_iter.as_slice(), ['a', 'b', 'c']);\n    /// let _ = into_iter.next().unwrap();\n    /// assert_eq!(into_iter.as_slice(), ['b', 'c']);\n    /// # }\n    /// ```\n    #[inline]\n    pub fn as_slice(&self) -> &[T] {\n        unsafe { slice::from_raw_parts(self.ptr, self.size_hint().0) }\n    }\n\n    /// Returns the remaining items of this iterator as a mutable slice.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[macro_use] extern crate slice_deque;\n    /// # use slice_deque::SliceDeque;\n    /// # fn main() {\n    /// let mut deq = sdeq!['a', 'b', 'c'];\n    /// let mut into_iter = deq.into_iter();\n    /// assert_eq!(into_iter.as_slice(), ['a', 'b', 'c']);\n    /// into_iter.as_mut_slice()[2] = 'z';\n    /// assert_eq!(into_iter.next().unwrap(), 'a');\n    /// assert_eq!(into_iter.next().unwrap(), 'b');\n    /// assert_eq!(into_iter.next().unwrap(), 'z');\n    /// # }\n    /// ```\n    #[inline]\n    pub fn as_mut_slice(&mut self) -> &mut [T] {\n        unsafe {\n            slice::from_raw_parts_mut(self.ptr as *mut T, self.size_hint().0)\n        }\n    }\n}\n\nunsafe impl<T: Send> Send for IntoIter<T> {}\nunsafe impl<T: Sync> Sync for IntoIter<T> {}\n\nimpl<T> Iterator for IntoIter<T> {\n    type Item = T;\n\n    #[inline]\n    fn next(&mut self) -> Option<T> {\n        unsafe {\n            if self.ptr as *const _ == self.end {\n                None\n            } else if mem::size_of::<T>() == 0 {\n                // purposefully don't use 'ptr.offset' because for\n                // deques with 0-size elements this would return the\n                // same pointer.\n                self.ptr = intrinsics::arith_offset(self.ptr as *const i8, 1)\n                    as *mut T;\n\n                // Use a non-null pointer value\n                // (self.ptr might be null because of wrapping)\n                Some(ptr::read(1 as *mut T))\n            } else {\n                let old = self.ptr;\n                self.ptr = self.ptr.add(1);\n\n                Some(ptr::read(old))\n            }\n        }\n    }\n\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        let exact = match self.ptr.offset_to_(self.end) {\n            Some(x) => x as usize,\n            None => (self.end as usize).wrapping_sub(self.ptr as usize),\n        };\n        (exact, Some(exact))\n    }\n\n    #[inline]\n    fn count(self) -> usize {\n        self.size_hint().0\n    }\n}\n\nimpl<T> DoubleEndedIterator for IntoIter<T> {\n    #[inline]\n    fn next_back(&mut self) -> Option<T> {\n        unsafe {\n            if self.end == self.ptr {\n                None\n            } else if mem::size_of::<T>() == 0 {\n                // See above for why 'ptr.offset' isn't used\n                self.end = intrinsics::arith_offset(self.end as *const i8, -1)\n                    as *mut T;\n\n                // Use a non-null pointer value\n                // (self.end might be null because of wrapping)\n                Some(ptr::read(1 as *mut T))\n            } else {\n                self.end = self.end.offset(-1);\n\n                Some(ptr::read(self.end))\n            }\n        }\n    }\n}\n\n#[cfg(feature = \"unstable\")]\nimpl<T> ExactSizeIterator for IntoIter<T> {\n    #[inline]\n    fn is_empty(&self) -> bool {\n        self.ptr == self.end\n    }\n}\n\n#[cfg(feature = \"unstable\")]\nimpl<T> iter::FusedIterator for IntoIter<T> {}\n\n#[cfg(feature = \"unstable\")]\nunsafe impl<T> iter::TrustedLen for IntoIter<T> {}\n\nimpl<T: Clone> Clone for IntoIter<T> {\n    #[inline]\n    fn clone(&self) -> Self {\n        let mut deq = SliceDeque::<T>::with_capacity(self.size_hint().0);\n        unsafe {\n            deq.append_elements(self.as_slice());\n        }\n        deq.into_iter()\n    }\n}\n\n#[cfg(feature = \"unstable\")]\nunsafe impl<#[may_dangle] T> Drop for IntoIter<T> {\n    #[inline]\n    fn drop(&mut self) {\n        // destroy the remaining elements\n        for _x in self.by_ref() {}\n\n        // Buffer handles deallocation\n        let _ =\n            unsafe { Buffer::from_raw_parts(self.buf.as_ptr(), 2 * self.cap) };\n    }\n}\n\n#[cfg(not(feature = \"unstable\"))]\nimpl<T> Drop for IntoIter<T> {\n    #[inline]\n    fn drop(&mut self) {\n        // destroy the remaining elements\n        for _x in self.by_ref() {}\n\n        // Buffer handles deallocation\n        let _ =\n            unsafe { Buffer::from_raw_parts(self.buf.as_ptr(), 2 * self.cap) };\n    }\n}\n\nimpl<T> IntoIterator for SliceDeque<T> {\n    type Item = T;\n    type IntoIter = IntoIter<T>;\n\n    /// Creates a consuming iterator, that is, one that moves each value out of\n    /// the deque (from start to end). The deque cannot be used after calling\n    /// this.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[macro_use] extern crate slice_deque;\n    /// # use slice_deque::SliceDeque;\n    /// # fn main() {\n    /// let mut deq = sdeq![\"a\".to_string(), \"b\".to_string()];\n    /// let expected = [\"a\".to_string(), \"b\".to_string()];\n    /// for (i, s) in deq.into_iter().enumerate() {\n    ///     // s has type String, not &String\n    ///     println!(\"{}\", s);\n    ///     assert_eq!(s, expected[i]);\n    /// }\n    /// # }\n    /// ```\n    #[inline]\n    fn into_iter(self) -> IntoIter<T> {\n        unsafe {\n            let buf_ptr = self.buf.ptr();\n            intrinsics::assume(!buf_ptr.is_null());\n            assert!(mem::size_of::<T>() != 0); // TODO: zero-sized types\n            let begin = buf_ptr.add(self.head()) as *const T;\n            let end = buf_ptr.add(self.tail()) as *const T;\n            assert!(begin as usize <= end as usize);\n            let it = IntoIter {\n                buf: NonNull::new_unchecked(buf_ptr),\n                cap: self.capacity(),\n                ptr: begin,\n                end,\n            };\n            debug_assert!(self.len() == it.size_hint().0);\n            #[cfg_attr(feature = \"cargo-clippy\", allow(clippy::mem_forget))]\n            mem::forget(self);\n            it\n        }\n    }\n}\n\nimpl<'a, T> IntoIterator for &'a SliceDeque<T> {\n    type Item = &'a T;\n    type IntoIter = slice::Iter<'a, T>;\n    #[inline]\n    fn into_iter(self) -> slice::Iter<'a, T> {\n        self.iter()\n    }\n}\n\nimpl<'a, T> IntoIterator for &'a mut SliceDeque<T> {\n    type Item = &'a mut T;\n    type IntoIter = slice::IterMut<'a, T>;\n    #[inline]\n    fn into_iter(self) -> slice::IterMut<'a, T> {\n        self.iter_mut()\n    }\n}\n\nimpl<T> Extend<T> for SliceDeque<T> {\n    #[inline]\n    fn extend<I: IntoIterator<Item = T>>(&mut self, iter: I) {\n        <Self as SpecExtend<T, I::IntoIter>>::spec_extend(\n            self,\n            iter.into_iter(),\n        )\n    }\n}\n\n/// Specialization trait used for `SliceDeque::from_iter` and\n/// `SliceDeque::extend`.\ntrait SpecExtend<T, I> {\n    /// Specialization for `SliceDeque::from_iter`.\n    fn from_iter(iter: I) -> Self;\n    /// Specialization for `SliceDeque::extend`.\n    fn spec_extend(&mut self, iter: I);\n}\n\n/// Default implementation of `SpecExtend::from_iter`.\n#[inline(always)]\nfn from_iter_default<T, I: Iterator<Item = T>>(\n    mut iterator: I,\n) -> SliceDeque<T> {\n    // Unroll the first iteration, as the deque is going to be\n    // expanded on this iteration in every case when the iterable is not\n    // empty, but the loop in extend_desugared() is not going to see the\n    // deque being full in the few subsequent loop iterations.\n    // So we get better branch prediction.\n    let mut deque = match iterator.next() {\n        None => return SliceDeque::<T>::new(),\n        Some(element) => {\n            let (lower, _) = iterator.size_hint();\n            let mut deque =\n                SliceDeque::<T>::with_capacity(lower.saturating_add(1));\n            unsafe {\n                ptr::write(deque.get_unchecked_mut(0), element);\n                deque.move_tail_unchecked(1);\n            }\n            deque\n        }\n    };\n    <SliceDeque<T> as SpecExtend<T, I>>::spec_extend(&mut deque, iterator);\n    deque\n}\n\nimpl<T, I> SpecExtend<T, I> for SliceDeque<T>\nwhere\n    I: Iterator<Item = T>,\n{\n    #[cfg(feature = \"unstable\")]\n    default fn from_iter(iterator: I) -> Self {\n        from_iter_default(iterator)\n    }\n\n    #[cfg(feature = \"unstable\")]\n    default fn spec_extend(&mut self, iter: I) {\n        self.extend_desugared(iter)\n    }\n\n    #[cfg(not(feature = \"unstable\"))]\n    fn from_iter(iterator: I) -> Self {\n        from_iter_default(iterator)\n    }\n\n    #[cfg(not(feature = \"unstable\"))]\n    fn spec_extend(&mut self, iter: I) {\n        self.extend_desugared(iter)\n    }\n}\n\n#[cfg(feature = \"unstable\")]\nimpl<T, I> SpecExtend<T, I> for SliceDeque<T>\nwhere\n    I: iter::TrustedLen<Item = T>,\n{\n    default fn from_iter(iterator: I) -> Self {\n        let mut deque = Self::new();\n        <Self as SpecExtend<T, I>>::spec_extend(&mut deque, iterator);\n        deque\n    }\n\n    #[cfg_attr(feature = \"cargo-clippy\", allow(clippy::use_debug))]\n    default fn spec_extend(&mut self, iterator: I) {\n        // This is the case for a TrustedLen iterator.\n        let (low, high) = iterator.size_hint();\n        if let Some(high_value) = high {\n            debug_assert_eq!(\n                low,\n                high_value,\n                \"TrustedLen iterator's size hint is not exact: {:?}\",\n                (low, high)\n            );\n        }\n        if let Some(additional) = high {\n            self.reserve(additional);\n            unsafe {\n                let mut ptr = self.as_mut_ptr().add(self.len());\n                for element in iterator {\n                    ptr::write(ptr, element);\n                    ptr = ptr.add(1);\n                    // NB can't overflow since we would have had to alloc the\n                    // address space\n                    self.move_tail_unchecked(1);\n                }\n            }\n        } else {\n            self.extend_desugared(iterator)\n        }\n    }\n}\n\n#[cfg(feature = \"unstable\")]\nimpl<T> SpecExtend<T, IntoIter<T>> for SliceDeque<T> {\n    fn from_iter(iterator: IntoIter<T>) -> Self {\n        // A common case is passing a deque into a function which immediately\n        // re-collects into a deque. We can short circuit this if the IntoIter\n        // has not been advanced at all.\n        if iterator.buf.as_ptr() as *const _ == iterator.ptr {\n            unsafe {\n                let deq = Self::from_raw_parts(\n                    iterator.buf.as_ptr(),\n                    iterator.cap,\n                    iterator.head(),\n                    iterator.tail(),\n                );\n                #[cfg_attr(\n                    feature = \"cargo-clippy\",\n                    allow(clippy::mem_forget)\n                )]\n                mem::forget(iterator);\n                deq\n            }\n        } else {\n            let mut deque = Self::new();\n            deque.spec_extend(iterator);\n            deque\n        }\n    }\n\n    fn spec_extend(&mut self, mut iterator: IntoIter<T>) {\n        unsafe {\n            self.append_elements(iterator.as_slice() as _);\n        }\n        iterator.ptr = iterator.end;\n    }\n}\n\n#[cfg(not(feature = \"unstable\"))]\nimpl<'a, T: 'a, I> SpecExtend<&'a T, I> for SliceDeque<T>\nwhere\n    I: Iterator<Item = &'a T>,\n    T: Clone,\n{\n    fn from_iter(iterator: I) -> Self {\n        SpecExtend::from_iter(iterator.cloned())\n    }\n\n    fn spec_extend(&mut self, iterator: I) {\n        self.spec_extend(iterator.cloned())\n    }\n}\n\n#[cfg(feature = \"unstable\")]\nimpl<'a, T: 'a, I> SpecExtend<&'a T, I> for SliceDeque<T>\nwhere\n    I: Iterator<Item = &'a T>,\n    T: Clone,\n{\n    default fn from_iter(iterator: I) -> Self {\n        SpecExtend::from_iter(iterator.cloned())\n    }\n\n    default fn spec_extend(&mut self, iterator: I) {\n        self.spec_extend(iterator.cloned())\n    }\n}\n\n#[cfg(feature = \"unstable\")]\nimpl<'a, T: 'a> SpecExtend<&'a T, slice::Iter<'a, T>> for SliceDeque<T>\nwhere\n    T: Copy,\n{\n    fn spec_extend(&mut self, iterator: slice::Iter<'a, T>) {\n        let slice = iterator.as_slice();\n        self.reserve(slice.len());\n        unsafe {\n            let len = self.len();\n            self.move_tail_unchecked(slice.len() as isize);\n            self.get_unchecked_mut(len..).copy_from_slice(slice);\n        }\n    }\n}\n\nimpl<T> iter::FromIterator<T> for SliceDeque<T> {\n    fn from_iter<I: IntoIterator<Item = T>>(iter: I) -> Self {\n        <Self as SpecExtend<T, I::IntoIter>>::from_iter(iter.into_iter())\n    }\n}\n\n/// This code generalises `extend_with_{element,default}`.\ntrait ExtendWith<T> {\n    /// TODO: docs\n    fn next(&self) -> T;\n    /// TODO: docs\n    fn last(self) -> T;\n}\n\n/// TODO: docs\nstruct ExtendElement<T>(T);\nimpl<T: Clone> ExtendWith<T> for ExtendElement<T> {\n    fn next(&self) -> T {\n        self.0.clone()\n    }\n    fn last(self) -> T {\n        self.0\n    }\n}\n\n/// TODO: docs\nstruct ExtendDefault;\nimpl<T: Default> ExtendWith<T> for ExtendDefault {\n    fn next(&self) -> T {\n        Default::default()\n    }\n    fn last(self) -> T {\n        Default::default()\n    }\n}\n\n/// TODO: docs\n/// FIXME: not used, this should be used by the sdeq! macro? Remove this maybe.\n#[doc(hidden)]\npub fn from_elem<T: Clone>(elem: T, n: usize) -> SliceDeque<T> {\n    <T as SpecFromElem>::from_elem(elem, n)\n}\n\n/// Specialization trait used for `SliceDeque::from_elem`.\ntrait SpecFromElem: Sized {\n    /// TODO: docs\n    fn from_elem(elem: Self, n: usize) -> SliceDeque<Self>;\n}\n\nimpl<T: Clone> SpecFromElem for T {\n    #[cfg(feature = \"unstable\")]\n    default fn from_elem(elem: Self, n: usize) -> SliceDeque<Self> {\n        let mut v = SliceDeque::with_capacity(n);\n        v.extend_with(n, ExtendElement(elem));\n        v\n    }\n\n    #[cfg(not(feature = \"unstable\"))]\n    fn from_elem(elem: Self, n: usize) -> SliceDeque<Self> {\n        let mut v = SliceDeque::with_capacity(n);\n        v.extend_with(n, ExtendElement(elem));\n        v\n    }\n}\n\n#[cfg(feature = \"unstable\")]\nimpl SpecFromElem for u8 {\n    #[inline]\n    fn from_elem(elem: Self, n: usize) -> SliceDeque<Self> {\n        unsafe {\n            let mut v = SliceDeque::with_capacity(n);\n            ptr::write_bytes(v.as_mut_ptr(), elem, n);\n            v.move_tail_unchecked(n as isize);\n            v\n        }\n    }\n}\n\nmacro_rules! impl_spec_from_elem {\n    ($t:ty, $is_zero:expr) => {\n        #[cfg(feature = \"unstable\")]\n        impl SpecFromElem for $t {\n            #[inline]\n            fn from_elem(elem: $t, n: usize) -> SliceDeque<$t> {\n                let mut v = SliceDeque::with_capacity(n);\n                v.extend_with(n, ExtendElement(elem));\n                v\n            }\n        }\n    };\n}\n\nimpl_spec_from_elem!(i8, |x| x == 0);\nimpl_spec_from_elem!(i16, |x| x == 0);\nimpl_spec_from_elem!(i32, |x| x == 0);\nimpl_spec_from_elem!(i64, |x| x == 0);\n#[cfg(feature = \"unstable\")]\nimpl_spec_from_elem!(i128, |x| x == 0);\nimpl_spec_from_elem!(isize, |x| x == 0);\n\nimpl_spec_from_elem!(u16, |x| x == 0);\nimpl_spec_from_elem!(u32, |x| x == 0);\nimpl_spec_from_elem!(u64, |x| x == 0);\n#[cfg(feature = \"unstable\")]\nimpl_spec_from_elem!(u128, |x| x == 0);\nimpl_spec_from_elem!(usize, |x| x == 0);\n\nimpl_spec_from_elem!(f32, |x: f32| x == 0. && x.is_sign_positive());\nimpl_spec_from_elem!(f64, |x: f64| x == 0. && x.is_sign_positive());\n\n/// Extend implementation that copies elements out of references before\n/// pushing them onto the `SliceDeque`.\n///\n/// This implementation is specialized for slice iterators, where it uses\n/// [`copy_from_slice`] to append the entire slice at once.\n///\n/// [`copy_from_slice`]: ../../std/primitive.slice.html#method.copy_from_slice\nimpl<'a, T: 'a + Copy> Extend<&'a T> for SliceDeque<T> {\n    fn extend<I: IntoIterator<Item = &'a T>>(&mut self, iter: I) {\n        self.spec_extend(iter.into_iter())\n    }\n}\n\n/// A splicing iterator for `SliceDeque`.\n///\n/// This struct is created by the [`splice()`] method on [`SliceDeque`]. See\n/// its documentation for more.\n///\n/// [`splice()`]: struct.SliceDeque.html#method.splice\n/// [`SliceDeque`]: struct.SliceDeque.html\n#[derive(Debug)]\npub struct Splice<'a, I: Iterator + 'a> {\n    /// TODO: docs\n    drain: Drain<'a, I::Item>,\n    /// TODO: docs\n    replace_with: I,\n}\n\nimpl<'a, I: Iterator> Iterator for Splice<'a, I> {\n    type Item = I::Item;\n    #[inline]\n    fn next(&mut self) -> Option<Self::Item> {\n        self.drain.next()\n    }\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.drain.size_hint()\n    }\n}\n\nimpl<'a, I: Iterator> DoubleEndedIterator for Splice<'a, I> {\n    #[inline]\n    fn next_back(&mut self) -> Option<Self::Item> {\n        self.drain.next_back()\n    }\n}\n\n#[cfg(feature = \"unstable\")]\nimpl<'a, I: Iterator> ExactSizeIterator for Splice<'a, I> {}\n\n// TODO: re-evaluate this\n#[cfg(feature = \"unstable\")]\nimpl<'a, I: Iterator> iter::FusedIterator for Splice<'a, I> {}\n\nimpl<'a, I: Iterator> Drop for Splice<'a, I> {\n    fn drop(&mut self) {\n        // exhaust drain first\n        while let Some(_) = self.drain.next() {}\n\n        unsafe {\n            if self.drain.tail_len == 0 {\n                self.drain.deq.as_mut().extend(self.replace_with.by_ref());\n                return;\n            }\n\n            // First fill the range left by drain().\n            if !self.drain.fill(&mut self.replace_with) {\n                return;\n            }\n\n            // There may be more elements. Use the lower bound as an estimate.\n            // FIXME: Is the upper bound a better guess? Or something else?\n            let (lower_bound, _upper_bound) = self.replace_with.size_hint();\n            if lower_bound > 0 {\n                self.drain.move_tail_unchecked(lower_bound);\n                if !self.drain.fill(&mut self.replace_with) {\n                    return;\n                }\n            }\n\n            // Collect any remaining elements.\n            // This is a zero-length deque which does not allocate if\n            // `lower_bound` was exact.\n            let mut collected = self\n                .replace_with\n                .by_ref()\n                .collect::<SliceDeque<I::Item>>()\n                .into_iter();\n            // Now we have an exact count.\n            if collected.size_hint().0 > 0 {\n                self.drain.move_tail_unchecked(collected.size_hint().0);\n                let filled = self.drain.fill(&mut collected);\n                debug_assert!(filled);\n                debug_assert_eq!(collected.size_hint().0, 0);\n            }\n        }\n        // Let `Drain::drop` move the tail back if necessary and restore\n        // `deq.tail`.\n    }\n}\n\n/// Private helper methods for `Splice::drop`\nimpl<'a, T> Drain<'a, T> {\n    /// The range from `self.deq.tail` to `self.tail()_start` contains elements\n    /// that have been moved out.\n    /// Fill that range as much as possible with new elements from the\n    /// `replace_with` iterator. Return whether we filled the entire\n    /// range. (`replace_with.next()` didn\u2019t return `None`.)\n    unsafe fn fill<I: Iterator<Item = T>>(\n        &mut self, replace_with: &mut I,\n    ) -> bool {\n        let deq = self.deq.as_mut();\n        let range_start = deq.len();\n        let range_end = self.tail_start;\n        let range_slice = slice::from_raw_parts_mut(\n            deq.as_mut_ptr().add(range_start),\n            range_end - range_start,\n        );\n\n        for place in range_slice {\n            if let Some(new_item) = replace_with.next() {\n                ptr::write(place, new_item);\n                deq.move_tail_unchecked(1);\n            } else {\n                return false;\n            }\n        }\n        true\n    }\n\n    /// Make room for inserting more elements before the tail.\n    unsafe fn move_tail_unchecked(&mut self, extra_capacity: usize) {\n        let deq = self.deq.as_mut();\n        let used_capacity = self.tail_start + self.tail_len;\n        deq.reserve_capacity(used_capacity + extra_capacity)\n            .expect(\"oom\");\n\n        let new_tail_start = self.tail_start + extra_capacity;\n        let src = deq.as_ptr().add(self.tail_start);\n        let dst = deq.as_mut_ptr().add(new_tail_start);\n        ptr::copy(src, dst, self.tail_len);\n        self.tail_start = new_tail_start;\n    }\n}\n\n/// An iterator produced by calling `drain_filter` on `SliceDeque`.\n#[derive(Debug)]\npub struct DrainFilter<'a, T: 'a, F>\nwhere\n    F: FnMut(&mut T) -> bool,\n{\n    /// TODO: docs\n    deq: &'a mut SliceDeque<T>,\n    /// TODO: docs\n    idx: usize,\n    /// TODO: docs\n    del: usize,\n    /// TODO: docs\n    old_len: usize,\n    /// TODO: docs\n    pred: F,\n}\n\nimpl<'a, T, F> Iterator for DrainFilter<'a, T, F>\nwhere\n    F: FnMut(&mut T) -> bool,\n{\n    type Item = T;\n\n    fn next(&mut self) -> Option<T> {\n        unsafe {\n            while self.idx != self.old_len {\n                let i = self.idx;\n                self.idx += 1;\n                let v = slice::from_raw_parts_mut(\n                    self.deq.as_mut_ptr(),\n                    self.old_len,\n                );\n                if (self.pred)(&mut v[i]) {\n                    self.del += 1;\n                    return Some(ptr::read(&v[i]));\n                } else if self.del > 0 {\n                    let del = self.del;\n                    let src: *const T = &v[i];\n                    let dst: *mut T = &mut v[i - del];\n                    // This is safe because self.deq has length 0\n                    // thus its elements will not have Drop::drop\n                    // called on them in the event of a panic.\n                    ptr::copy_nonoverlapping(src, dst, 1);\n                }\n            }\n            None\n        }\n    }\n\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        (0, Some(self.old_len - self.idx))\n    }\n}\n\nimpl<'a, T, F> Drop for DrainFilter<'a, T, F>\nwhere\n    F: FnMut(&mut T) -> bool,\n{\n    fn drop(&mut self) {\n        for _ in self.by_ref() {}\n\n        unsafe {\n            let new_len = self.old_len - self.del;\n            let new_tail = self.deq.head() + new_len;\n            let old_tail = self.deq.tail();\n            self.deq\n                .move_tail_unchecked(new_tail as isize - old_tail as isize);\n        }\n    }\n}\n\nimpl<T> convert::AsRef<[T]> for SliceDeque<T> {\n    fn as_ref(&self) -> &[T] {\n        &*self\n    }\n}\n\nimpl<T> convert::AsMut<[T]> for SliceDeque<T> {\n    fn as_mut(&mut self) -> &mut [T] {\n        &mut *self\n    }\n}\n\n#[cfg(all(feature = \"bytes_buf\", feature = \"use_std\"))]\nimpl ::bytes::BufMut for SliceDeque<u8> {\n    #[inline]\n    fn remaining_mut(&self) -> usize {\n        usize::max_value() - self.len()\n    }\n    #[inline]\n    unsafe fn bytes_mut(&mut self) -> &mut [u8] {\n        if self.capacity() == self.len() {\n            self.reserve(64); // Grow the deque\n        }\n\n        let cap = self.capacity();\n        let len = self.len();\n\n        let ptr = self.as_mut_ptr();\n        &mut slice::from_raw_parts_mut(ptr, cap)[len..]\n    }\n    #[inline]\n    unsafe fn advance_mut(&mut self, cnt: usize) {\n        let len = self.len();\n        let remaining = self.capacity() - len;\n        if cnt > remaining {\n            // Reserve additional capacity, and ensure that the total length\n            // will not overflow usize.\n            self.reserve(cnt);\n        }\n\n        self.move_tail_unchecked(cnt as isize);\n    }\n}\n\n#[cfg(all(feature = \"bytes_buf\", feature = \"use_std\"))]\nimpl ::bytes::IntoBuf for SliceDeque<u8> {\n    type Buf = io::Cursor<SliceDeque<u8>>;\n\n    fn into_buf(self) -> Self::Buf {\n        io::Cursor::new(self)\n    }\n}\n\n#[cfg(all(feature = \"bytes_buf\", feature = \"use_std\"))]\nimpl<'a> ::bytes::IntoBuf for &'a SliceDeque<u8> {\n    type Buf = io::Cursor<&'a [u8]>;\n\n    fn into_buf(self) -> Self::Buf {\n        io::Cursor::new(&self[..])\n    }\n}\n\n#[cfg(all(feature = \"bytes_buf\", feature = \"use_std\"))]\nimpl ::bytes::buf::FromBuf for SliceDeque<u8> {\n    fn from_buf<T>(buf: T) -> Self\n    where\n        T: ::bytes::IntoBuf,\n    {\n        use bytes::{Buf, BufMut};\n        let buf = buf.into_buf();\n        let mut ret = SliceDeque::with_capacity(buf.remaining());\n        ret.put(buf);\n        ret\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use self::collections::HashMap;\n    use super::SliceDeque;\n    use std::cell::RefCell;\n    use std::rc::Rc;\n    use std::{collections, fmt, hash, mem};\n\n    #[derive(Clone, Debug)]\n    struct WithDrop {\n        counter: Rc<RefCell<usize>>,\n    }\n\n    impl Drop for WithDrop {\n        fn drop(&mut self) {\n            *self.counter.borrow_mut() += 1;\n        }\n    }\n\n    fn sizes_to_test() -> Vec<usize> {\n        let sample = vec![\n            /* powers of 2 */ 2, 4, 8, 16, 32, 64,\n            128, /*\n                256,\n                512,\n                1024,\n                2048,\n                4096,\n                8192, 16_384, 32_768,  65_536, 131_072, 262_144,\n                */\n                /*\n                // powers of 2 - 1 or primes\n                1, 3, 7, 13, 17, 31, 61, 127, 257, 509, 1021, 2039, 4093,\n                8191, 16_381, 32_749,  65_537, 131_071, 262_143, 4_194_301,\n                // powers of 10\n                10, 100, 1000, 10_000, 100_000, 1_000_000_usize,*/\n        ];\n        sample.into_iter().collect()\n    }\n\n    fn linear_usize_deque(size: usize) -> SliceDeque<usize> {\n        let mut v: SliceDeque<usize> = SliceDeque::new();\n        for i in 0..size {\n            v.push_back(i);\n            assert_eq!(v.len(), i + 1);\n            for j in 0..v.len() {\n                assert_eq!(*v.get(j).unwrap(), j);\n            }\n        }\n        assert_eq!(v.len(), size);\n        for i in 0..size {\n            assert_eq!(*v.get(i).unwrap(), i);\n        }\n        v\n    }\n\n    fn constant_deque<T: Clone + fmt::Debug>(\n        size: usize, val: &T,\n    ) -> SliceDeque<T> {\n        let mut v: SliceDeque<T> = SliceDeque::with_capacity(size);\n        for i in 0..size {\n            let copy = val.clone();\n            v.push_back(copy);\n            assert_eq!(v.len(), i + 1);\n        }\n        assert_eq!(v.len(), size);\n        v\n    }\n\n    #[test]\n    fn get() {\n        let mut deq = SliceDeque::new();\n        deq.push_back(3);\n        deq.push_back(4);\n        deq.push_back(5);\n        assert_eq!(deq.get(1), Some(&4));\n    }\n\n    #[test]\n    fn get_mut() {\n        let mut deq = SliceDeque::new();\n        deq.push_back(3);\n        deq.push_back(4);\n        deq.push_back(5);\n        assert_eq!(deq.get(1), Some(&4));\n        if let Some(elem) = deq.get_mut(1) {\n            *elem = 7;\n        }\n        assert_eq!(deq[1], 7);\n    }\n\n    #[test]\n    fn is_empty() {\n        let mut deq = SliceDeque::new();\n        assert!(deq.is_empty());\n        deq.push_back(4);\n        assert!(!deq.is_empty());\n        deq.pop_front();\n        assert!(deq.is_empty());\n    }\n\n    #[test]\n    fn push_pop_front() {\n        for size in sizes_to_test() {\n            let mut v: SliceDeque<usize> = SliceDeque::new();\n            for i in 0..size {\n                v.push_front(i);\n                assert_eq!(v.len(), i + 1);\n                for j in 0..v.len() {\n                    assert_eq!(*v.get(v.len() - j - 1).unwrap(), j);\n                }\n            }\n            assert_eq!(v.len(), size);\n            for i in 0..size {\n                assert_eq!(*v.get(i).unwrap(), size - i - 1);\n            }\n            for i in 0..size {\n                assert_eq!(v.len(), size - i);\n                v.pop_front();\n                for j in 0..v.len() {\n                    assert_eq!(*v.get(v.len() - j - 1).unwrap(), j);\n                }\n            }\n            assert_eq!(v.len(), 0);\n        }\n    }\n\n    #[test]\n    fn push_pop_back() {\n        for size in sizes_to_test() {\n            let mut v = linear_usize_deque(size);\n            for i in 0..size {\n                assert_eq!(v.len(), size - i);\n                v.pop_back();\n                for j in 0..v.len() {\n                    assert_eq!(*v.get(j).unwrap(), j);\n                }\n            }\n            assert_eq!(v.len(), 0);\n        }\n    }\n\n    #[test]\n    fn all_head_tails() {\n        for size in sizes_to_test() {\n            let mut v = linear_usize_deque(size);\n            let permutations = 6 * v.capacity();\n\n            // rotate from left to right\n            for _ in 0..permutations {\n                v.push_back(0);\n                for j in (0..v.len() - 1).rev() {\n                    *v.get_mut(j + 1).unwrap() = *v.get(j).unwrap();\n                }\n                v.pop_front();\n                assert_eq!(v.len(), size);\n                for k in 0..size {\n                    assert_eq!(*v.get(k).unwrap(), k);\n                }\n            }\n\n            // rotate from right to left\n            for _ in 0..permutations {\n                v.push_front(0);\n                for j in 0..v.len() - 1 {\n                    *v.get_mut(j).unwrap() = *v.get(j + 1).unwrap()\n                }\n                v.pop_back();\n                assert_eq!(v.len(), size);\n                for k in 0..size {\n                    assert_eq!(*v.get(k).unwrap(), k);\n                }\n            }\n        }\n    }\n\n    #[test]\n    fn drop() {\n        for size in sizes_to_test() {\n            let mut counter = Rc::new(RefCell::new(0));\n            let val = WithDrop {\n                counter: counter.clone(),\n            };\n            {\n                let _v = constant_deque(size, &val);\n            }\n            assert_eq!(*counter.borrow(), size);\n        }\n    }\n\n    #[test]\n    fn clear() {\n        for size in sizes_to_test() {\n            let mut counter = Rc::new(RefCell::new(0));\n            let val = WithDrop {\n                counter: counter.clone(),\n            };\n            assert_eq!(*counter.borrow(), 0);\n            let mut v = constant_deque(size, &val);\n            assert_eq!(*counter.borrow(), 0);\n            v.clear();\n            assert_eq!(*counter.borrow(), size);\n            assert_eq!(v.len(), 0);\n        }\n    }\n\n    #[test]\n    fn reserve_no_cap_change() {\n        let mut slice = SliceDeque::<u8>::with_capacity(4096);\n        let cap = slice.capacity();\n        assert!(cap >= 4096);\n        slice.reserve(cap);\n        // capacity should not change if the existing capacity is already\n        // sufficient.\n        assert_eq!(slice.capacity(), cap);\n    }\n\n    #[test]\n    fn resize() {\n        for size in sizes_to_test() {\n            let mut v = linear_usize_deque(size);\n            let mut v_ref = linear_usize_deque(size / 2);\n            v.resize(size / 2, 0);\n            assert_eq!(v.len(), size / 2);\n            assert_eq!(v.as_slice(), v_ref.as_slice());\n            while v_ref.len() < size {\n                v_ref.push_back(3);\n            }\n            v.resize(size, 3);\n            assert_eq!(v.len(), size);\n            assert_eq!(v_ref.len(), size);\n            assert_eq!(v.as_slice(), v_ref.as_slice());\n\n            v.resize(0, 3);\n            assert_eq!(v.len(), 0);\n\n            v.resize(size, 3);\n            let v_ref = constant_deque(size, &3);\n            assert_eq!(v.len(), size);\n            assert_eq!(v_ref.len(), size);\n            assert_eq!(v.as_slice(), v_ref.as_slice());\n        }\n    }\n\n    #[test]\n    fn default() {\n        let d = SliceDeque::<u8>::default();\n        let r = SliceDeque::<u8>::new();\n        assert_eq!(d.as_slice(), r.as_slice());\n    }\n\n    #[test]\n    fn shrink_to_fit() {\n        let page_size = 4096;\n        for size in sizes_to_test() {\n            let mut deq = constant_deque(size, &(3 as u8));\n            let old_cap = deq.capacity();\n            deq.resize(size / 4, 3);\n            deq.shrink_to_fit();\n            if size <= page_size {\n                assert_eq!(deq.capacity(), old_cap);\n            } else {\n                assert!(deq.capacity() < old_cap);\n            }\n        }\n    }\n\n    #[test]\n    fn iter() {\n        let mut deq = SliceDeque::new();\n        deq.push_back(5);\n        deq.push_back(3);\n        deq.push_back(4);\n        let b: &[_] = &[&5, &3, &4];\n        let c: Vec<&i32> = deq.iter().collect();\n        assert_eq!(&c[..], b);\n    }\n\n    #[test]\n    fn iter_mut() {\n        let mut deq = SliceDeque::new();\n        deq.push_back(5);\n        deq.push_back(3);\n        deq.push_back(4);\n        for num in deq.iter_mut() {\n            *num = *num - 2;\n        }\n        let b: &[_] = &[&mut 3, &mut 1, &mut 2];\n        assert_eq!(&deq.iter_mut().collect::<Vec<&mut i32>>()[..], b);\n    }\n\n    #[test]\n    fn hash_map() {\n        let mut hm: HashMap<SliceDeque<u32>, u32> = HashMap::new();\n        let mut a = SliceDeque::new();\n        a.push_back(1);\n        a.push_back(2);\n        hm.insert(a.clone(), 3);\n        let b = SliceDeque::new();\n        assert_eq!(hm.get(&a), Some(&3));\n        assert_eq!(hm.get(&b), None);\n    }\n\n    #[test]\n    fn partial_ord_eq() {\n        let mut a = SliceDeque::new();\n        a.push_back(1);\n        a.push_back(2);\n        a.push_back(3);\n        assert!(a == a);\n        assert!(!(a != a));\n\n        let mut b = SliceDeque::new();\n        b.push_back(1);\n        b.push_back(3);\n        b.push_back(2);\n        assert!(a < b);\n        assert!(b > a);\n        assert!(a != b);\n\n        let mut c = SliceDeque::new();\n        c.push_back(2);\n        assert!(c > a);\n        assert!(a < c);\n    }\n\n    struct DropCounter<'a> {\n        count: &'a mut u32,\n    }\n\n    impl<'a> Drop for DropCounter<'a> {\n        fn drop(&mut self) {\n            *self.count += 1;\n        }\n    }\n\n    #[test]\n    fn vec_double_drop() {\n        struct TwoSliceDeque<T> {\n            x: SliceDeque<T>,\n            y: SliceDeque<T>,\n        }\n\n        let (mut count_x, mut count_y) = (0, 0);\n        {\n            let mut tv = TwoSliceDeque {\n                x: SliceDeque::new(),\n                y: SliceDeque::new(),\n            };\n            tv.x.push_back(DropCounter {\n                count: &mut count_x,\n            });\n            tv.y.push_back(DropCounter {\n                count: &mut count_y,\n            });\n\n            // If SliceDeque had a drop flag, here is where it would be zeroed.\n            // Instead, it should rely on its internal state to prevent\n            // doing anything significant when dropped multiple times.\n            mem::drop(tv.x);\n\n            // Here tv goes out of scope, tv.y should be dropped, but not tv.x.\n        }\n\n        assert_eq!(count_x, 1);\n        assert_eq!(count_y, 1);\n    }\n\n    #[test]\n    fn vec_reserve() {\n        let mut v = SliceDeque::new();\n        assert_eq!(v.capacity(), 0);\n\n        v.reserve(2);\n        assert!(v.capacity() >= 2);\n\n        for i in 0..16 {\n            v.push_back(i);\n        }\n\n        assert!(v.capacity() >= 16);\n        v.reserve(16);\n        assert!(v.capacity() >= 32);\n\n        v.push_back(16);\n\n        v.reserve(16);\n        assert!(v.capacity() >= 33)\n    }\n\n    #[test]\n    fn vec_extend() {\n        let mut v = SliceDeque::new();\n        let mut w = SliceDeque::new();\n\n        v.extend(w.clone());\n        assert_eq!(v, &[]);\n\n        v.extend(0..3);\n        for i in 0..3 {\n            w.push_back(i)\n        }\n\n        assert_eq!(v, w);\n\n        v.extend(3..10);\n        for i in 3..10 {\n            w.push_back(i)\n        }\n\n        assert_eq!(v, w);\n\n        v.extend(w.clone()); // specializes to `append`\n        assert!(v.iter().eq(w.iter().chain(w.iter())));\n\n        // Double drop\n        let mut count_x = 0;\n        {\n            let mut x = SliceDeque::new();\n            let mut y = SliceDeque::new();\n            y.push_back(DropCounter {\n                count: &mut count_x,\n            });\n            x.extend(y);\n        }\n        assert_eq!(count_x, 1);\n    }\n\n    #[test]\n    #[should_panic] // TODO: zero-sized types\n    fn vec_extend_zst() {\n        // Zero sized types\n        #[derive(PartialEq, Debug)]\n        struct Foo;\n\n        let mut a = SliceDeque::new();\n        let b = sdeq![Foo, Foo];\n\n        a.extend(b);\n        assert_eq!(a, &[Foo, Foo]);\n    }\n\n    #[test]\n    fn vec_extend_ref() {\n        let mut v = SliceDeque::new();\n        for &i in &[1, 2] {\n            v.push_back(i);\n        }\n        v.extend(&[3, 4, 5]);\n\n        assert_eq!(v.len(), 5);\n        assert_eq!(v, [1, 2, 3, 4, 5]);\n\n        let mut w = SliceDeque::new();\n        for &i in &[6, 7] {\n            w.push_back(i);\n        }\n        v.extend(&w);\n\n        assert_eq!(v.len(), 7);\n        assert_eq!(v, [1, 2, 3, 4, 5, 6, 7]);\n    }\n\n    #[test]\n    fn vec_slice_from_mut() {\n        let mut values = sdeq![1, 2, 3, 4, 5];\n        {\n            let slice = &mut values[2..];\n            assert!(slice == [3, 4, 5]);\n            for p in slice {\n                *p += 2;\n            }\n        }\n\n        assert!(values == [1, 2, 5, 6, 7]);\n    }\n\n    #[test]\n    fn vec_slice_to_mut() {\n        let mut values = sdeq![1, 2, 3, 4, 5];\n        {\n            let slice = &mut values[..2];\n            assert!(slice == [1, 2]);\n            for p in slice {\n                *p += 1;\n            }\n        }\n\n        assert!(values == [2, 3, 3, 4, 5]);\n    }\n\n    #[test]\n    fn vec_split_at_mut() {\n        let mut values = sdeq![1, 2, 3, 4, 5];\n        {\n            let (left, right) = values.split_at_mut(2);\n            {\n                let left: &[_] = left;\n                assert!(&left[..left.len()] == &[1, 2]);\n            }\n            for p in left {\n                *p += 1;\n            }\n\n            {\n                let right: &[_] = right;\n                assert!(&right[..right.len()] == &[3, 4, 5]);\n            }\n            for p in right {\n                *p += 2;\n            }\n        }\n\n        assert_eq!(values, [2, 3, 5, 6, 7]);\n    }\n\n    #[test]\n    fn vec_clone() {\n        let v: SliceDeque<i32> = sdeq![];\n        let w = sdeq![1, 2, 3];\n\n        assert_eq!(v, v.clone());\n\n        let z = w.clone();\n        assert_eq!(w, z);\n        // they should be disjoint in memory.\n        assert!(w.as_ptr() != z.as_ptr())\n    }\n\n    #[cfg(feature = \"unstable\")]\n    #[test]\n    fn vec_clone_from() {\n        let mut v = sdeq![];\n        let three: SliceDeque<Box<_>> = sdeq![box 1, box 2, box 3];\n        let two: SliceDeque<Box<_>> = sdeq![box 4, box 5];\n\n        // zero, long\n        v.clone_from(&three);\n        assert_eq!(v, three);\n\n        // equal\n        v.clone_from(&three);\n        assert_eq!(v, three);\n\n        // long, short\n        v.clone_from(&two);\n        assert_eq!(v, two);\n\n        // short, long\n        v.clone_from(&three);\n        assert_eq!(v, three)\n    }\n\n    #[test]\n    fn vec_retain() {\n        let mut deq = sdeq![1, 2, 3, 4];\n        deq.retain(|&x| x % 2 == 0);\n        assert_eq!(deq, [2, 4]);\n    }\n\n    #[test]\n    fn vec_dedup() {\n        fn case(a: SliceDeque<i32>, b: SliceDeque<i32>) {\n            let mut v = a;\n            v.dedup();\n            assert_eq!(v, b);\n        }\n        case(sdeq![], sdeq![]);\n        case(sdeq![1], sdeq![1]);\n        case(sdeq![1, 1], sdeq![1]);\n        case(sdeq![1, 2, 3], sdeq![1, 2, 3]);\n        case(sdeq![1, 1, 2, 3], sdeq![1, 2, 3]);\n        case(sdeq![1, 2, 2, 3], sdeq![1, 2, 3]);\n        case(sdeq![1, 2, 3, 3], sdeq![1, 2, 3]);\n        case(sdeq![1, 1, 2, 2, 2, 3, 3], sdeq![1, 2, 3]);\n    }\n\n    #[test]\n    fn vec_dedup_by_key() {\n        fn case(a: SliceDeque<i32>, b: SliceDeque<i32>) {\n            let mut v = a;\n            v.dedup_by_key(|i| *i / 10);\n            assert_eq!(v, b);\n        }\n        case(sdeq![], sdeq![]);\n        case(sdeq![10], sdeq![10]);\n        case(sdeq![10, 11], sdeq![10]);\n        case(sdeq![10, 20, 30], sdeq![10, 20, 30]);\n        case(sdeq![10, 11, 20, 30], sdeq![10, 20, 30]);\n        case(sdeq![10, 20, 21, 30], sdeq![10, 20, 30]);\n        case(sdeq![10, 20, 30, 31], sdeq![10, 20, 30]);\n        case(sdeq![10, 11, 20, 21, 22, 30, 31], sdeq![10, 20, 30]);\n    }\n\n    #[test]\n    fn vec_dedup_by() {\n        let mut deq = sdeq![\"foo\", \"bar\", \"Bar\", \"baz\", \"bar\"];\n        deq.dedup_by(|a, b| a.eq_ignore_ascii_case(b));\n\n        assert_eq!(deq, [\"foo\", \"bar\", \"baz\", \"bar\"]);\n\n        let mut deq: SliceDeque<(&'static str, i32)> =\n            sdeq![(\"foo\", 1), (\"foo\", 2), (\"bar\", 3), (\"bar\", 4), (\"bar\", 5)];\n        deq.dedup_by(|a, b| {\n            a.0 == b.0 && {\n                b.1 += a.1;\n                true\n            }\n        });\n\n        assert_eq!(deq, [(\"foo\", 3), (\"bar\", 12)]);\n    }\n\n    #[cfg(feature = \"unstable\")]\n    #[test]\n    fn vec_dedup_unique() {\n        let mut v0: SliceDeque<Box<_>> = sdeq![box 1, box 1, box 2, box 3];\n        v0.dedup();\n        let mut v1: SliceDeque<Box<_>> = sdeq![box 1, box 2, box 2, box 3];\n        v1.dedup();\n        let mut v2: SliceDeque<Box<_>> = sdeq![box 1, box 2, box 3, box 3];\n        v2.dedup();\n        // If the boxed pointers were leaked or otherwise misused, valgrind\n        // and/or rt should raise errors.\n    }\n\n    #[test]\n    #[should_panic] // TODO: zero-sized types\n    fn zero_sized_values() {\n        let mut v = SliceDeque::new();\n        assert_eq!(v.len(), 0);\n        v.push_back(());\n        assert_eq!(v.len(), 1);\n        v.push_back(());\n        assert_eq!(v.len(), 2);\n        assert_eq!(v.pop_back(), Some(()));\n        assert_eq!(v.pop_back(), Some(()));\n        assert_eq!(v.pop_back(), None);\n\n        assert_eq!(v.iter().count(), 0);\n        v.push_back(());\n        assert_eq!(v.iter().count(), 1);\n        v.push_back(());\n        assert_eq!(v.iter().count(), 2);\n\n        for &() in &v {}\n\n        assert_eq!(v.iter_mut().count(), 2);\n        v.push_back(());\n        assert_eq!(v.iter_mut().count(), 3);\n        v.push_back(());\n        assert_eq!(v.iter_mut().count(), 4);\n\n        for &mut () in &mut v {}\n        unsafe {\n            let len = v.len() as isize;\n            v.move_tail_unchecked(-len);\n        }\n        assert_eq!(v.iter_mut().count(), 0);\n    }\n\n    #[test]\n    fn vec_partition() {\n        assert_eq!(\n            sdeq![].into_iter().partition(|x: &i32| *x < 3),\n            (sdeq![], sdeq![])\n        );\n        assert_eq!(\n            sdeq![1, 2, 3].into_iter().partition(|x| *x < 4),\n            (sdeq![1, 2, 3], sdeq![])\n        );\n        assert_eq!(\n            sdeq![1, 2, 3].into_iter().partition(|x| *x < 2),\n            (sdeq![1], sdeq![2, 3])\n        );\n        assert_eq!(\n            sdeq![1, 2, 3].into_iter().partition(|x| *x < 0),\n            (sdeq![], sdeq![1, 2, 3])\n        );\n    }\n\n    #[test]\n    fn vec_zip_unzip() {\n        let z1 = sdeq![(1, 4), (2, 5), (3, 6)];\n\n        let (left, right): (SliceDeque<_>, SliceDeque<_>) =\n            z1.iter().cloned().unzip();\n\n        assert_eq!((1, 4), (left[0], right[0]));\n        assert_eq!((2, 5), (left[1], right[1]));\n        assert_eq!((3, 6), (left[2], right[2]));\n    }\n\n    #[test]\n    fn vec_vec_truncate_drop() {\n        static mut DROPS: u32 = 0;\n        struct Elem(i32);\n        impl Drop for Elem {\n            fn drop(&mut self) {\n                unsafe {\n                    DROPS += 1;\n                }\n            }\n        }\n\n        let mut v = sdeq![Elem(1), Elem(2), Elem(3), Elem(4), Elem(5)];\n        assert_eq!(unsafe { DROPS }, 0);\n        v.truncate(3);\n        assert_eq!(unsafe { DROPS }, 2);\n        v.truncate(0);\n        assert_eq!(unsafe { DROPS }, 5);\n    }\n\n    #[test]\n    fn vec_vec_truncate_front_drop() {\n        static mut DROPS: u32 = 0;\n        struct Elem(i32);\n        impl Drop for Elem {\n            fn drop(&mut self) {\n                unsafe {\n                    DROPS += 1;\n                }\n            }\n        }\n\n        let mut v = sdeq![Elem(1), Elem(2), Elem(3), Elem(4), Elem(5)];\n        assert_eq!(unsafe { DROPS }, 0);\n        v.truncate_front(3);\n        assert_eq!(unsafe { DROPS }, 2);\n        v.truncate_front(0);\n        assert_eq!(unsafe { DROPS }, 5);\n    }\n\n    #[test]\n    #[should_panic]\n    fn vec_vec_truncate_fail() {\n        struct BadElem(i32);\n        impl Drop for BadElem {\n            fn drop(&mut self) {\n                let BadElem(ref mut x) = *self;\n                if *x == 0xbadbeef {\n                    panic!(\"BadElem panic: 0xbadbeef\")\n                }\n            }\n        }\n\n        let mut v =\n            sdeq![BadElem(1), BadElem(2), BadElem(0xbadbeef), BadElem(4)];\n        v.truncate(0);\n    }\n\n    #[test]\n    fn vec_index() {\n        let deq = sdeq![1, 2, 3];\n        assert!(deq[1] == 2);\n    }\n\n    #[test]\n    #[should_panic]\n    fn vec_index_out_of_bounds() {\n        let deq = sdeq![1, 2, 3];\n        let _ = deq[3];\n    }\n\n    #[test]\n    #[should_panic]\n    fn vec_slice_out_of_bounds_1() {\n        let x = sdeq![1, 2, 3, 4, 5];\n        &x[!0..];\n    }\n\n    #[test]\n    #[should_panic]\n    fn vec_slice_out_of_bounds_2() {\n        let x = sdeq![1, 2, 3, 4, 5];\n        &x[..6];\n    }\n\n    #[test]\n    #[should_panic]\n    fn vec_slice_out_of_bounds_3() {\n        let x = sdeq![1, 2, 3, 4, 5];\n        &x[!0..4];\n    }\n\n    #[test]\n    #[should_panic]\n    fn vec_slice_out_of_bounds_4() {\n        let x = sdeq![1, 2, 3, 4, 5];\n        &x[1..6];\n    }\n\n    #[test]\n    #[should_panic]\n    fn vec_slice_out_of_bounds_5() {\n        let x = sdeq![1, 2, 3, 4, 5];\n        &x[3..2];\n    }\n\n    #[test]\n    fn vec_swap_remove_empty() {\n        let mut deq = SliceDeque::<i32>::new();\n        assert_eq!(deq.swap_remove_back(0), None);\n    }\n\n    #[test]\n    fn vec_move_items() {\n        let deq = sdeq![1, 2, 3];\n        let mut deq2 = sdeq![];\n        for i in deq {\n            deq2.push_back(i);\n        }\n        assert_eq!(deq2, [1, 2, 3]);\n    }\n\n    #[test]\n    fn vec_move_items_reverse() {\n        let deq = sdeq![1, 2, 3];\n        let mut deq2 = sdeq![];\n        for i in deq.into_iter().rev() {\n            deq2.push_back(i);\n        }\n        assert_eq!(deq2, [3, 2, 1]);\n    }\n\n    #[test]\n    #[should_panic] // TODO: zero-sized types\n    fn vec_move_items_zero_sized() {\n        let deq = sdeq![(), (), ()];\n        let mut deq2 = sdeq![];\n        for i in deq {\n            deq2.push_back(i);\n        }\n        assert_eq!(deq2, [(), (), ()]);\n    }\n\n    #[cfg(all(feature = \"unstable\", feature = \"use_std\"))]\n    #[test]\n    fn vec_drain_items() {\n        let mut deq = sdeq![1, 2, 3];\n        let mut deq2 = sdeq![];\n        for i in deq.drain(..) {\n            deq2.push_back(i);\n        }\n        assert_eq!(deq, []);\n        assert_eq!(deq2, [1, 2, 3]);\n    }\n\n    #[cfg(all(feature = \"unstable\", feature = \"use_std\"))]\n    #[test]\n    fn vec_drain_items_reverse() {\n        let mut deq = sdeq![1, 2, 3];\n        let mut deq2 = sdeq![];\n        for i in deq.drain(..).rev() {\n            deq2.push_back(i);\n        }\n        assert_eq!(deq, []);\n        assert_eq!(deq2, [3, 2, 1]);\n    }\n\n    #[cfg(all(feature = \"unstable\", feature = \"use_std\"))]\n    #[test]\n    #[should_panic]\n    fn vec_drain_items_zero_sized() {\n        let mut deq = sdeq![(), (), ()];\n        let mut deq2 = sdeq![];\n        for i in deq.drain(..) {\n            deq2.push_back(i);\n        }\n        assert_eq!(deq, []);\n        assert_eq!(deq2, [(), (), ()]);\n    }\n\n    #[cfg(all(feature = \"unstable\", feature = \"use_std\"))]\n    #[test]\n    #[should_panic]\n    fn vec_drain_out_of_bounds() {\n        let mut v = sdeq![1, 2, 3, 4, 5];\n        v.drain(5..6);\n    }\n\n    #[cfg(all(feature = \"unstable\", feature = \"use_std\"))]\n    #[test]\n    fn vec_drain_range() {\n        let mut v = sdeq![1, 2, 3, 4, 5];\n        for _ in v.drain(4..) {}\n        assert_eq!(v, &[1, 2, 3, 4]);\n\n        let mut v: SliceDeque<_> = (1..6).map(|x| x.to_string()).collect();\n        for _ in v.drain(1..4) {}\n        assert_eq!(v, &[1.to_string(), 5.to_string()]);\n\n        let mut v: SliceDeque<_> = (1..6).map(|x| x.to_string()).collect();\n        for _ in v.drain(1..4).rev() {}\n        assert_eq!(v, &[1.to_string(), 5.to_string()]);\n    }\n\n    #[cfg(all(feature = \"unstable\", feature = \"use_std\"))]\n    #[test]\n    #[should_panic] // TODO: zero-sized types\n    fn vec_drain_range_zst() {\n        let mut v: SliceDeque<_> = sdeq![(); 5];\n        for _ in v.drain(1..4).rev() {}\n        assert_eq!(v, &[(), ()]);\n    }\n\n    #[cfg(all(feature = \"unstable\", feature = \"use_std\"))]\n    #[test]\n    fn vec_drain_inclusive_range() {\n        let mut v = sdeq!['a', 'b', 'c', 'd', 'e'];\n        for _ in v.drain(1..=3) {}\n        assert_eq!(v, &['a', 'e']);\n\n        let mut v: SliceDeque<_> = (0..=5).map(|x| x.to_string()).collect();\n        for _ in v.drain(1..=5) {}\n        assert_eq!(v, &[\"0\".to_string()]);\n\n        let mut v: SliceDeque<String> =\n            (0..=5).map(|x| x.to_string()).collect();\n        for _ in v.drain(0..=5) {}\n        assert_eq!(v, SliceDeque::<String>::new());\n\n        let mut v: SliceDeque<_> = (0..=5).map(|x| x.to_string()).collect();\n        for _ in v.drain(0..=3) {}\n        assert_eq!(v, &[\"4\".to_string(), \"5\".to_string()]);\n\n        let mut v: SliceDeque<_> = (0..=1).map(|x| x.to_string()).collect();\n        for _ in v.drain(..=0) {}\n        assert_eq!(v, &[\"1\".to_string()]);\n    }\n\n    /*\n    #[cfg(all(feature = \"unstable\", feature = \"use_std\"))]\n    #[test]\n    #[should_panic] // TODO: zero-sized types\n    fn vec_drain_max_vec_size() {\n        let mut v = SliceDeque::<()>::with_capacity(usize::max_value());\n        unsafe {\n            v.set_len(usize::max_value());\n        }\n        for _ in v.drain(usize::max_value() - 1..) {}\n        assert_eq!(v.len(), usize::max_value() - 1);\n    \n        let mut v = SliceDeque::<()>::with_capacity(usize::max_value());\n        unsafe {\n            v.set_len(usize::max_value());\n        }\n        for _ in v.drain(usize::max_value() - 1..=usize::max_value() - 1) {}\n        assert_eq!(v.len(), usize::max_value() - 1);\n    }*/\n\n    #[cfg(all(feature = \"unstable\", feature = \"use_std\"))]\n    #[test]\n    #[should_panic]\n    fn vec_drain_inclusive_out_of_bounds() {\n        let mut v = sdeq![1, 2, 3, 4, 5];\n        v.drain(5..=5);\n    }\n\n    #[cfg(all(feature = \"unstable\", feature = \"use_std\"))]\n    #[test]\n    fn vec_splice() {\n        let mut v = sdeq![1, 2, 3, 4, 5];\n        let a = [10, 11, 12];\n        v.splice(2..4, a.iter().cloned());\n        assert_eq!(v, &[1, 2, 10, 11, 12, 5]);\n        v.splice(1..3, Some(20));\n        assert_eq!(v, &[1, 20, 11, 12, 5]);\n    }\n\n    #[cfg(all(feature = \"unstable\", feature = \"use_std\"))]\n    #[test]\n    fn vec_splice_inclusive_range() {\n        let mut v = sdeq![1, 2, 3, 4, 5];\n        let a = [10, 11, 12];\n        let t1: SliceDeque<_> = v.splice(2..=3, a.iter().cloned()).collect();\n        assert_eq!(v, &[1, 2, 10, 11, 12, 5]);\n        assert_eq!(t1, &[3, 4]);\n        let t2: SliceDeque<_> = v.splice(1..=2, Some(20)).collect();\n        assert_eq!(v, &[1, 20, 11, 12, 5]);\n        assert_eq!(t2, &[2, 10]);\n    }\n\n    #[cfg(all(feature = \"unstable\", feature = \"use_std\"))]\n    #[test]\n    #[should_panic]\n    fn vec_splice_out_of_bounds() {\n        let mut v = sdeq![1, 2, 3, 4, 5];\n        let a = [10, 11, 12];\n        v.splice(5..6, a.iter().cloned());\n    }\n\n    #[cfg(all(feature = \"unstable\", feature = \"use_std\"))]\n    #[test]\n    #[should_panic]\n    fn vec_splice_inclusive_out_of_bounds() {\n        let mut v = sdeq![1, 2, 3, 4, 5];\n        let a = [10, 11, 12];\n        v.splice(5..=5, a.iter().cloned());\n    }\n\n    #[cfg(all(feature = \"unstable\", feature = \"use_std\"))]\n    #[test]\n    #[should_panic] // TODO: zero-sized\n    fn vec_splice_items_zero_sized() {\n        let mut deq = sdeq![(), (), ()];\n        let deq2 = sdeq![];\n        let t: SliceDeque<_> =\n            deq.splice(1..2, deq2.iter().cloned()).collect();\n        assert_eq!(deq, &[(), ()]);\n        assert_eq!(t, &[()]);\n    }\n\n    #[cfg(all(feature = \"unstable\", feature = \"use_std\"))]\n    #[test]\n    fn vec_splice_unbounded() {\n        let mut deq = sdeq![1, 2, 3, 4, 5];\n        let t: SliceDeque<_> = deq.splice(.., None).collect();\n        assert_eq!(deq, &[]);\n        assert_eq!(t, &[1, 2, 3, 4, 5]);\n    }\n\n    #[cfg(all(feature = \"unstable\", feature = \"use_std\"))]\n    #[test]\n    fn vec_splice_forget() {\n        let mut v = sdeq![1, 2, 3, 4, 5];\n        let a = [10, 11, 12];\n        mem::forget(v.splice(2..4, a.iter().cloned()));\n        assert_eq!(v, &[1, 2]);\n    }\n\n    /* into_boxed_slice probably can't be supported portably\n    #[test]\n    fn vec_into_boxed_slice() {\n        let xs = sdeq![1, 2, 3];\n        let ys = xs.into_boxed_slice();\n        assert_eq!(&*ys, [1, 2, 3]);\n    }\n    */\n\n    #[test]\n    fn vec_append() {\n        let mut deq = sdeq![1, 2, 3];\n        let mut deq2 = sdeq![4, 5, 6];\n        deq.append(&mut deq2);\n        assert_eq!(deq, [1, 2, 3, 4, 5, 6]);\n        assert_eq!(deq2, []);\n    }\n\n    #[test]\n    fn vec_split_off() {\n        let mut deq = sdeq![1, 2, 3, 4, 5, 6];\n        let deq2 = deq.split_off(4);\n        assert_eq!(deq, [1, 2, 3, 4]);\n        assert_eq!(deq2, [5, 6]);\n    }\n\n    #[test]\n    fn vec_into_iter_as_slice() {\n        let deq = sdeq!['a', 'b', 'c'];\n        let mut into_iter = deq.into_iter();\n        assert_eq!(into_iter.as_slice(), &['a', 'b', 'c']);\n        let _ = into_iter.next().unwrap();\n        assert_eq!(into_iter.as_slice(), &['b', 'c']);\n        let _ = into_iter.next().unwrap();\n        let _ = into_iter.next().unwrap();\n        assert_eq!(into_iter.as_slice(), &[]);\n    }\n\n    #[test]\n    fn vec_into_iter_as_mut_slice() {\n        let deq = sdeq!['a', 'b', 'c'];\n        let mut into_iter = deq.into_iter();\n        assert_eq!(into_iter.as_slice(), &['a', 'b', 'c']);\n        into_iter.as_mut_slice()[0] = 'x';\n        into_iter.as_mut_slice()[1] = 'y';\n        assert_eq!(into_iter.next().unwrap(), 'x');\n        assert_eq!(into_iter.as_slice(), &['y', 'c']);\n    }\n\n    #[test]\n    fn vec_into_iter_debug() {\n        let deq = sdeq!['a', 'b', 'c'];\n        let into_iter = deq.into_iter();\n        let debug = format!(\"{:?}\", into_iter);\n        assert_eq!(debug, \"IntoIter(['a', 'b', 'c'])\");\n    }\n\n    #[test]\n    fn vec_into_iter_count() {\n        assert_eq!(sdeq![1, 2, 3].into_iter().count(), 3);\n    }\n\n    #[test]\n    fn vec_into_iter_clone() {\n        fn iter_equal<I: Iterator<Item = i32>>(it: I, slice: &[i32]) {\n            let v: SliceDeque<i32> = it.collect();\n            assert_eq!(&v[..], slice);\n        }\n        let deq = sdeq![1, 2, 3];\n        let mut it = deq.into_iter();\n        let it_c = it.clone();\n        iter_equal(it_c, &[1, 2, 3]);\n        assert_eq!(it.next(), Some(1));\n        let mut it = it.rev();\n        iter_equal(it.clone(), &[3, 2]);\n        assert_eq!(it.next(), Some(3));\n        iter_equal(it.clone(), &[2]);\n        assert_eq!(it.next(), Some(2));\n        iter_equal(it.clone(), &[]);\n        assert_eq!(it.next(), None);\n    }\n\n    /* TODO: Cow support\n    #[test]\n        fn vec_cow_from() {\n            use std::borrow::Cow;\n        let borrowed: &[_] = &[\"borrowed\", \"(slice)\"];\n        let owned = sdeq![\"owned\", \"(vec)\"];\n        match (Cow::from(owned.clone()), Cow::from(borrowed)) {\n            (Cow::Owned(o), Cow::Borrowed(b)) => assert!(o == owned && b == borrowed),\n            _ => panic!(\"invalid `Cow::from`\"),\n        }\n    }\n    \n    #[test]\n        fn vec_from_cow() {\n            use std::borrow::Cow;\n        let borrowed: &[_] = &[\"borrowed\", \"(slice)\"];\n        let owned = sdeq![\"owned\", \"(vec)\"];\n        assert_eq!(SliceDeque::from(Cow::Borrowed(borrowed)), sdeq![\"borrowed\", \"(slice)\"]);\n        assert_eq!(SliceDeque::from(Cow::Owned(owned)), sdeq![\"owned\", \"(vec)\"]);\n    }\n         */\n\n    /* TODO: covariance\n    use super::{Drain, IntoIter};\n    \n    #[allow(dead_code)]\n    fn assert_covariance() {\n        fn drain<'new>(d: Drain<'static, &'static str>) -> Drain<'new, &'new str> {\n            d\n        }\n        fn into_iter<'new>(i: IntoIter<&'static str>) -> IntoIter<&'new str> {\n            i\n        }\n    }\n        */\n\n    #[test]\n    fn from_into_inner() {\n        let deq = sdeq![1, 2, 3];\n        #[allow(unused_variables)]\n        let ptr = deq.as_ptr();\n        let deq = deq.into_iter().collect::<SliceDeque<_>>();\n        assert_eq!(deq, [1, 2, 3]);\n        #[cfg(feature = \"unstable\")]\n        {\n            assert_eq!(deq.as_ptr(), ptr);\n        }\n\n        let ptr = &deq[1] as *const _;\n        let mut it = deq.into_iter();\n        it.next().unwrap();\n        let deq = it.collect::<SliceDeque<_>>();\n        assert_eq!(deq, [2, 3]);\n        assert!(ptr != deq.as_ptr());\n    }\n\n    #[cfg(feature = \"unstable\")]\n    #[test]\n    fn overaligned_allocations() {\n        #[repr(align(256))]\n        struct Foo(usize);\n        let mut v = sdeq![Foo(273)];\n        for i in 0..0x1000 {\n            v.reserve_exact(i);\n            assert!(v[0].0 == 273);\n            assert!(v.as_ptr() as usize & 0xff == 0);\n            v.shrink_to_fit();\n            assert!(v[0].0 == 273);\n            assert!(v.as_ptr() as usize & 0xff == 0);\n        }\n    }\n\n    #[test]\n    fn drain_filter_empty() {\n        let mut deq: SliceDeque<i32> = sdeq![];\n\n        {\n            let mut iter = deq.drain_filter(|_| true);\n            assert_eq!(iter.size_hint(), (0, Some(0)));\n            assert_eq!(iter.next(), None);\n            assert_eq!(iter.size_hint(), (0, Some(0)));\n            assert_eq!(iter.next(), None);\n            assert_eq!(iter.size_hint(), (0, Some(0)));\n        }\n        assert_eq!(deq.len(), 0);\n        assert_eq!(deq, sdeq![]);\n    }\n\n    #[test]\n    #[should_panic] // TODO: zst\n    fn drain_filter_zst() {\n        let mut deq = sdeq![(), (), (), (), ()];\n        let initial_len = deq.len();\n        let mut count = 0;\n        {\n            let mut iter = deq.drain_filter(|_| true);\n            assert_eq!(iter.size_hint(), (0, Some(initial_len)));\n            while let Some(_) = iter.next() {\n                count += 1;\n                assert_eq!(iter.size_hint(), (0, Some(initial_len - count)));\n            }\n            assert_eq!(iter.size_hint(), (0, Some(0)));\n            assert_eq!(iter.next(), None);\n            assert_eq!(iter.size_hint(), (0, Some(0)));\n        }\n\n        assert_eq!(count, initial_len);\n        assert_eq!(deq.len(), 0);\n        assert_eq!(deq, sdeq![]);\n    }\n\n    #[test]\n    fn drain_filter_false() {\n        let mut deq = sdeq![1, 2, 3, 4, 5, 6, 7, 8, 9, 10];\n\n        let initial_len = deq.len();\n        let mut count = 0;\n        {\n            let mut iter = deq.drain_filter(|_| false);\n            assert_eq!(iter.size_hint(), (0, Some(initial_len)));\n            for _ in iter.by_ref() {\n                count += 1;\n            }\n            assert_eq!(iter.size_hint(), (0, Some(0)));\n            assert_eq!(iter.next(), None);\n            assert_eq!(iter.size_hint(), (0, Some(0)));\n        }\n\n        assert_eq!(count, 0);\n        assert_eq!(deq.len(), initial_len);\n        assert_eq!(deq, sdeq![1, 2, 3, 4, 5, 6, 7, 8, 9, 10]);\n    }\n\n    #[test]\n    fn drain_filter_true() {\n        let mut deq = sdeq![1, 2, 3, 4, 5, 6, 7, 8, 9, 10];\n\n        let initial_len = deq.len();\n        let mut count = 0;\n        {\n            let mut iter = deq.drain_filter(|_| true);\n            assert_eq!(iter.size_hint(), (0, Some(initial_len)));\n            while let Some(_) = iter.next() {\n                count += 1;\n                assert_eq!(iter.size_hint(), (0, Some(initial_len - count)));\n            }\n            assert_eq!(iter.size_hint(), (0, Some(0)));\n            assert_eq!(iter.next(), None);\n            assert_eq!(iter.size_hint(), (0, Some(0)));\n        }\n\n        assert_eq!(count, initial_len);\n        assert_eq!(deq.len(), 0);\n        assert_eq!(deq, sdeq![]);\n    }\n\n    #[test]\n    fn drain_filter_complex() {\n        {\n            //                [+xxx++++++xxxxx++++x+x++]\n            let mut deq = sdeq![\n                1, 2, 4, 6, 7, 9, 11, 13, 15, 17, 18, 20, 22, 24, 26, 27, 29,\n                31, 33, 34, 35, 36, 37, 39,\n            ];\n\n            let removed =\n                deq.drain_filter(|x| *x % 2 == 0).collect::<SliceDeque<_>>();\n            assert_eq!(removed.len(), 10);\n            assert_eq!(removed, sdeq![2, 4, 6, 18, 20, 22, 24, 26, 34, 36]);\n\n            assert_eq!(deq.len(), 14);\n            assert_eq!(\n                deq,\n                sdeq![1, 7, 9, 11, 13, 15, 17, 27, 29, 31, 33, 35, 37, 39]\n            );\n        }\n\n        {\n            //                [xxx++++++xxxxx++++x+x++]\n            let mut deq = sdeq![\n                2, 4, 6, 7, 9, 11, 13, 15, 17, 18, 20, 22, 24, 26, 27, 29, 31,\n                33, 34, 35, 36, 37, 39,\n            ];\n\n            let removed =\n                deq.drain_filter(|x| *x % 2 == 0).collect::<SliceDeque<_>>();\n            assert_eq!(removed.len(), 10);\n            assert_eq!(removed, sdeq![2, 4, 6, 18, 20, 22, 24, 26, 34, 36]);\n\n            assert_eq!(deq.len(), 13);\n            assert_eq!(\n                deq,\n                sdeq![7, 9, 11, 13, 15, 17, 27, 29, 31, 33, 35, 37, 39]\n            );\n        }\n\n        {\n            //                [xxx++++++xxxxx++++x+x]\n            let mut deq = sdeq![\n                2, 4, 6, 7, 9, 11, 13, 15, 17, 18, 20, 22, 24, 26, 27, 29, 31,\n                33, 34, 35, 36,\n            ];\n\n            let removed =\n                deq.drain_filter(|x| *x % 2 == 0).collect::<SliceDeque<_>>();\n            assert_eq!(removed.len(), 10);\n            assert_eq!(removed, sdeq![2, 4, 6, 18, 20, 22, 24, 26, 34, 36]);\n\n            assert_eq!(deq.len(), 11);\n            assert_eq!(deq, sdeq![7, 9, 11, 13, 15, 17, 27, 29, 31, 33, 35]);\n        }\n\n        {\n            //                [xxxxxxxxxx+++++++++++]\n            let mut deq = sdeq![\n                2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 1, 3, 5, 7, 9, 11, 13, 15,\n                17, 19,\n            ];\n\n            let removed =\n                deq.drain_filter(|x| *x % 2 == 0).collect::<SliceDeque<_>>();\n            assert_eq!(removed.len(), 10);\n            assert_eq!(removed, sdeq![2, 4, 6, 8, 10, 12, 14, 16, 18, 20]);\n\n            assert_eq!(deq.len(), 10);\n            assert_eq!(deq, sdeq![1, 3, 5, 7, 9, 11, 13, 15, 17, 19]);\n        }\n\n        {\n            //                [+++++++++++xxxxxxxxxx]\n            let mut deq = sdeq![\n                1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 2, 4, 6, 8, 10, 12, 14, 16,\n                18, 20,\n            ];\n\n            let removed =\n                deq.drain_filter(|x| *x % 2 == 0).collect::<SliceDeque<_>>();\n            assert_eq!(removed.len(), 10);\n            assert_eq!(removed, sdeq![2, 4, 6, 8, 10, 12, 14, 16, 18, 20]);\n\n            assert_eq!(deq.len(), 10);\n            assert_eq!(deq, sdeq![1, 3, 5, 7, 9, 11, 13, 15, 17, 19]);\n        }\n    }\n\n    #[test]\n    fn vecdeque_simple() {\n        let mut d = SliceDeque::new();\n        assert_eq!(d.len(), 0);\n        d.push_front(17);\n        d.push_front(42);\n        d.push_back(137);\n        assert_eq!(d.len(), 3);\n        d.push_back(137);\n        assert_eq!(d.len(), 4);\n        assert_eq!(*d.front().unwrap(), 42);\n        assert_eq!(*d.back().unwrap(), 137);\n        let mut i = d.pop_front();\n        assert_eq!(i, Some(42));\n        i = d.pop_back();\n        assert_eq!(i, Some(137));\n        i = d.pop_back();\n        assert_eq!(i, Some(137));\n        i = d.pop_back();\n        assert_eq!(i, Some(17));\n        assert_eq!(d.len(), 0);\n        d.push_back(3);\n        assert_eq!(d.len(), 1);\n        d.push_front(2);\n        assert_eq!(d.len(), 2);\n        d.push_back(4);\n        assert_eq!(d.len(), 3);\n        d.push_front(1);\n        assert_eq!(d.len(), 4);\n        assert_eq!(d[0], 1);\n        assert_eq!(d[1], 2);\n        assert_eq!(d[2], 3);\n        assert_eq!(d[3], 4);\n    }\n\n    #[cfg(test)]\n    fn vecdeque_parameterized<T: Clone + PartialEq + fmt::Debug>(\n        a: T, b: T, c: T, d: T,\n    ) {\n        let mut deq = SliceDeque::new();\n        assert_eq!(deq.len(), 0);\n        deq.push_front(a.clone());\n        deq.push_front(b.clone());\n        deq.push_back(c.clone());\n        assert_eq!(deq.len(), 3);\n        deq.push_back(d.clone());\n        assert_eq!(deq.len(), 4);\n        assert_eq!((*deq.front().unwrap()).clone(), b.clone());\n        assert_eq!((*deq.back().unwrap()).clone(), d.clone());\n        assert_eq!(deq.pop_front().unwrap(), b.clone());\n        assert_eq!(deq.pop_back().unwrap(), d.clone());\n        assert_eq!(deq.pop_back().unwrap(), c.clone());\n        assert_eq!(deq.pop_back().unwrap(), a.clone());\n        assert_eq!(deq.len(), 0);\n        deq.push_back(c.clone());\n        assert_eq!(deq.len(), 1);\n        deq.push_front(b.clone());\n        assert_eq!(deq.len(), 2);\n        deq.push_back(d.clone());\n        assert_eq!(deq.len(), 3);\n        deq.push_front(a.clone());\n        assert_eq!(deq.len(), 4);\n        assert_eq!(deq[0].clone(), a.clone());\n        assert_eq!(deq[1].clone(), b.clone());\n        assert_eq!(deq[2].clone(), c.clone());\n        assert_eq!(deq[3].clone(), d.clone());\n    }\n\n    #[test]\n    fn vecdeque_push_front_grow() {\n        let mut deq = SliceDeque::new();\n        for i in 0..66 {\n            deq.push_front(i);\n        }\n        assert_eq!(deq.len(), 66);\n\n        for i in 0..66 {\n            assert_eq!(deq[i], 65 - i);\n        }\n\n        let mut deq = SliceDeque::new();\n        for i in 0..66 {\n            deq.push_back(i);\n        }\n\n        for i in 0..66 {\n            assert_eq!(deq[i], i);\n        }\n    }\n\n    #[test]\n    fn vecdeque_index() {\n        let mut deq = SliceDeque::new();\n        for i in 1..4 {\n            deq.push_front(i);\n        }\n        assert_eq!(deq[1], 2);\n    }\n\n    #[test]\n    #[should_panic]\n    fn vecdeque_index_out_of_bounds() {\n        let mut deq = SliceDeque::new();\n        for i in 1..4 {\n            deq.push_front(i);\n        }\n        deq[3];\n    }\n\n    #[derive(Clone, PartialEq, Debug)]\n    enum Taggy {\n        One(i32),\n        Two(i32, i32),\n        Three(i32, i32, i32),\n    }\n\n    #[derive(Clone, PartialEq, Debug)]\n    enum Taggypar<T> {\n        Onepar(T),\n        Twopar(T, T),\n        Threepar(T, T, T),\n    }\n\n    #[derive(Clone, PartialEq, Debug)]\n    struct RecCy {\n        x: i32,\n        y: i32,\n        t: Taggy,\n    }\n\n    use tests::Taggy::*;\n    use tests::Taggypar::*;\n\n    fn hash<T: hash::Hash>(t: &T) -> u64 {\n        let mut s = collections::hash_map::DefaultHasher::new();\n        use hash::Hasher;\n        t.hash(&mut s);\n        s.finish()\n    }\n\n    #[test]\n    fn vecdeque_param_int() {\n        vecdeque_parameterized::<i32>(5, 72, 64, 175);\n    }\n\n    #[test]\n    fn vecdeque_param_taggy() {\n        vecdeque_parameterized::<Taggy>(\n            One(1),\n            Two(1, 2),\n            Three(1, 2, 3),\n            Two(17, 42),\n        );\n    }\n\n    #[test]\n    fn vecdeque_param_taggypar() {\n        vecdeque_parameterized::<Taggypar<i32>>(\n            Onepar::<i32>(1),\n            Twopar::<i32>(1, 2),\n            Threepar::<i32>(1, 2, 3),\n            Twopar::<i32>(17, 42),\n        );\n    }\n\n    #[test]\n    fn vecdeque_param_reccy() {\n        let reccy1 = RecCy {\n            x: 1,\n            y: 2,\n            t: One(1),\n        };\n        let reccy2 = RecCy {\n            x: 345,\n            y: 2,\n            t: Two(1, 2),\n        };\n        let reccy3 = RecCy {\n            x: 1,\n            y: 777,\n            t: Three(1, 2, 3),\n        };\n        let reccy4 = RecCy {\n            x: 19,\n            y: 252,\n            t: Two(17, 42),\n        };\n        vecdeque_parameterized::<RecCy>(reccy1, reccy2, reccy3, reccy4);\n    }\n\n    #[test]\n    fn vecdeque_with_capacity() {\n        let mut d = SliceDeque::with_capacity(0);\n        d.push_back(1);\n        assert_eq!(d.len(), 1);\n        let mut d = SliceDeque::with_capacity(50);\n        d.push_back(1);\n        assert_eq!(d.len(), 1);\n    }\n\n    #[test]\n    fn vecdeque_with_capacity_non_power_two() {\n        let mut d3 = SliceDeque::with_capacity(3);\n        d3.push_back(1);\n\n        // X = None, | = lo\n        // [|1, X, X]\n        assert_eq!(d3.pop_front(), Some(1));\n        // [X, |X, X]\n        assert_eq!(d3.front(), None);\n\n        // [X, |3, X]\n        d3.push_back(3);\n        // [X, |3, 6]\n        d3.push_back(6);\n        // [X, X, |6]\n        assert_eq!(d3.pop_front(), Some(3));\n\n        // Pushing the lo past half way point to trigger\n        // the 'B' scenario for growth\n        // [9, X, |6]\n        d3.push_back(9);\n        // [9, 12, |6]\n        d3.push_back(12);\n\n        d3.push_back(15);\n        // There used to be a bug here about how the\n        // SliceDeque made growth assumptions about the\n        // underlying Vec which didn't hold and lead\n        // to corruption.\n        // (Vec grows to next power of two)\n        // good- [9, 12, 15, X, X, X, X, |6]\n        // bug-  [15, 12, X, X, X, |6, X, X]\n        assert_eq!(d3.pop_front(), Some(6));\n\n        // Which leads us to the following state which\n        // would be a failure case.\n        // bug-  [15, 12, X, X, X, X, |X, X]\n        assert_eq!(d3.front(), Some(&9));\n    }\n\n    #[test]\n    fn vecdeque_reserve_exact() {\n        let mut d = SliceDeque::new();\n        d.push_back(0);\n        d.reserve_exact(50);\n        assert!(d.capacity() >= 51);\n    }\n\n    #[test]\n    fn vecdeque_reserve() {\n        let mut d = SliceDeque::new();\n        d.push_back(0);\n        d.reserve(50);\n        assert!(d.capacity() >= 51);\n    }\n\n    #[test]\n    fn vecdeque_swap() {\n        let mut d: SliceDeque<_> = (0..5).collect();\n        d.pop_front();\n        d.swap(0, 3);\n        assert_eq!(d.iter().cloned().collect::<Vec<_>>(), [4, 2, 3, 1]);\n    }\n\n    #[test]\n    fn vecdeque_iter() {\n        let mut d = SliceDeque::new();\n        assert_eq!(d.iter().next(), None);\n        assert_eq!(d.iter().size_hint(), (0, Some(0)));\n\n        for i in 0..5 {\n            d.push_back(i);\n        }\n        {\n            let b: &[_] = &[&0, &1, &2, &3, &4];\n            assert_eq!(d.iter().collect::<Vec<_>>(), b);\n        }\n\n        for i in 6..9 {\n            d.push_front(i);\n        }\n        {\n            let b: &[_] = &[&8, &7, &6, &0, &1, &2, &3, &4];\n            assert_eq!(d.iter().collect::<Vec<_>>(), b);\n        }\n\n        let mut it = d.iter();\n        let mut len = d.len();\n        loop {\n            match it.next() {\n                None => break,\n                _ => {\n                    len -= 1;\n                    assert_eq!(it.size_hint(), (len, Some(len)))\n                }\n            }\n        }\n    }\n\n    #[test]\n    fn vecdeque_rev_iter() {\n        let mut d = SliceDeque::new();\n        assert_eq!(d.iter().rev().next(), None);\n\n        for i in 0..5 {\n            d.push_back(i);\n        }\n        {\n            let b: &[_] = &[&4, &3, &2, &1, &0];\n            assert_eq!(d.iter().rev().collect::<Vec<_>>(), b);\n        }\n\n        for i in 6..9 {\n            d.push_front(i);\n        }\n        let b: &[_] = &[&4, &3, &2, &1, &0, &6, &7, &8];\n        assert_eq!(d.iter().rev().collect::<Vec<_>>(), b);\n    }\n\n    #[test]\n    fn vecdeque_mut_rev_iter_wrap() {\n        let mut d = SliceDeque::with_capacity(3);\n        assert!(d.iter_mut().rev().next().is_none());\n\n        d.push_back(1);\n        d.push_back(2);\n        d.push_back(3);\n        assert_eq!(d.pop_front(), Some(1));\n        d.push_back(4);\n\n        assert_eq!(\n            d.iter_mut().rev().map(|x| *x).collect::<Vec<_>>(),\n            vec![4, 3, 2]\n        );\n    }\n\n    #[test]\n    fn vecdeque_mut_iter() {\n        let mut d = SliceDeque::new();\n        assert!(d.iter_mut().next().is_none());\n\n        for i in 0..3 {\n            d.push_front(i);\n        }\n\n        for (i, elt) in d.iter_mut().enumerate() {\n            assert_eq!(*elt, 2 - i);\n            *elt = i;\n        }\n\n        {\n            let mut it = d.iter_mut();\n            assert_eq!(*it.next().unwrap(), 0);\n            assert_eq!(*it.next().unwrap(), 1);\n            assert_eq!(*it.next().unwrap(), 2);\n            assert!(it.next().is_none());\n        }\n    }\n\n    #[test]\n    fn vecdeque_mut_rev_iter() {\n        let mut d = SliceDeque::new();\n        assert!(d.iter_mut().rev().next().is_none());\n\n        for i in 0..3 {\n            d.push_front(i);\n        }\n\n        for (i, elt) in d.iter_mut().rev().enumerate() {\n            assert_eq!(*elt, i);\n            *elt = i;\n        }\n\n        {\n            let mut it = d.iter_mut().rev();\n            assert_eq!(*it.next().unwrap(), 0);\n            assert_eq!(*it.next().unwrap(), 1);\n            assert_eq!(*it.next().unwrap(), 2);\n            assert!(it.next().is_none());\n        }\n    }\n\n    #[test]\n    fn vecdeque_into_iter() {\n        // Empty iter\n        {\n            let d: SliceDeque<i32> = SliceDeque::new();\n            let mut iter = d.into_iter();\n\n            assert_eq!(iter.size_hint(), (0, Some(0)));\n            assert_eq!(iter.next(), None);\n            assert_eq!(iter.size_hint(), (0, Some(0)));\n        }\n\n        // simple iter\n        {\n            let mut d = SliceDeque::new();\n            for i in 0..5 {\n                d.push_back(i);\n            }\n\n            let b = vec![0, 1, 2, 3, 4];\n            assert_eq!(d.into_iter().collect::<Vec<_>>(), b);\n        }\n\n        // wrapped iter\n        {\n            let mut d = SliceDeque::new();\n            for i in 0..5 {\n                d.push_back(i);\n            }\n            for i in 6..9 {\n                d.push_front(i);\n            }\n\n            let b = vec![8, 7, 6, 0, 1, 2, 3, 4];\n            assert_eq!(d.into_iter().collect::<Vec<_>>(), b);\n        }\n\n        // partially used\n        {\n            let mut d = SliceDeque::new();\n            for i in 0..5 {\n                d.push_back(i);\n            }\n            for i in 6..9 {\n                d.push_front(i);\n            }\n\n            let mut it = d.into_iter();\n            assert_eq!(it.size_hint(), (8, Some(8)));\n            assert_eq!(it.next(), Some(8));\n            assert_eq!(it.size_hint(), (7, Some(7)));\n            assert_eq!(it.next_back(), Some(4));\n            assert_eq!(it.size_hint(), (6, Some(6)));\n            assert_eq!(it.next(), Some(7));\n            assert_eq!(it.size_hint(), (5, Some(5)));\n        }\n    }\n\n    #[cfg(all(feature = \"unstable\", feature = \"use_std\"))]\n    #[test]\n    fn vecdeque_drain() {\n        // Empty iter\n        {\n            let mut d: SliceDeque<i32> = SliceDeque::new();\n\n            {\n                let mut iter = d.drain(..);\n\n                assert_eq!(iter.size_hint(), (0, Some(0)));\n                assert_eq!(iter.next(), None);\n                assert_eq!(iter.size_hint(), (0, Some(0)));\n            }\n\n            assert!(d.is_empty());\n        }\n\n        // simple iter\n        {\n            let mut d = SliceDeque::new();\n            for i in 0..5 {\n                d.push_back(i);\n            }\n\n            assert_eq!(d.drain(..).collect::<Vec<_>>(), [0, 1, 2, 3, 4]);\n            assert!(d.is_empty());\n        }\n\n        // wrapped iter\n        {\n            let mut d = SliceDeque::new();\n            for i in 0..5 {\n                d.push_back(i);\n            }\n            for i in 6..9 {\n                d.push_front(i);\n            }\n\n            assert_eq!(\n                d.drain(..).collect::<Vec<_>>(),\n                [8, 7, 6, 0, 1, 2, 3, 4]\n            );\n            assert!(d.is_empty());\n        }\n\n        // partially used\n        {\n            let mut d: SliceDeque<_> = SliceDeque::new();\n            for i in 0..5 {\n                d.push_back(i);\n            }\n            for i in 6..9 {\n                d.push_front(i);\n            }\n\n            {\n                let mut it = d.drain(..);\n                assert_eq!(it.size_hint(), (8, Some(8)));\n                assert_eq!(it.next(), Some(8));\n                assert_eq!(it.size_hint(), (7, Some(7)));\n                assert_eq!(it.next_back(), Some(4));\n                assert_eq!(it.size_hint(), (6, Some(6)));\n                assert_eq!(it.next(), Some(7));\n                assert_eq!(it.size_hint(), (5, Some(5)));\n            }\n            assert!(d.is_empty());\n        }\n    }\n\n    #[cfg(feature = \"unstable\")]\n    #[test]\n    fn vecdeque_from_iter() {\n        let v = vec![1, 2, 3, 4, 5, 6, 7];\n        let deq: SliceDeque<_> = v.iter().cloned().collect();\n        let u: Vec<_> = deq.iter().cloned().collect();\n        assert_eq!(u, v);\n\n        let seq = (0..).step_by(2).take(256);\n        let deq: SliceDeque<_> = seq.collect();\n        for (i, &x) in deq.iter().enumerate() {\n            assert_eq!(2 * i, x);\n        }\n        assert_eq!(deq.len(), 256);\n    }\n\n    #[test]\n    fn vecdeque_clone() {\n        let mut d = SliceDeque::new();\n        d.push_front(17);\n        d.push_front(42);\n        d.push_back(137);\n        d.push_back(137);\n        assert_eq!(d.len(), 4);\n        let mut e = d.clone();\n        assert_eq!(e.len(), 4);\n        while !d.is_empty() {\n            assert_eq!(d.pop_back(), e.pop_back());\n        }\n        assert_eq!(d.len(), 0);\n        assert_eq!(e.len(), 0);\n    }\n\n    #[test]\n    fn vecdeque_eq() {\n        let mut d = SliceDeque::new();\n        assert!(d == SliceDeque::with_capacity(0));\n        d.push_front(137);\n        d.push_front(17);\n        d.push_front(42);\n        d.push_back(137);\n        let mut e = SliceDeque::with_capacity(0);\n        e.push_back(42);\n        e.push_back(17);\n        e.push_back(137);\n        e.push_back(137);\n        assert!(&e == &d);\n        e.pop_back();\n        e.push_back(0);\n        assert!(e != d);\n        e.clear();\n        assert!(e == SliceDeque::new());\n    }\n\n    #[test]\n    fn vecdeque_partial_eq_array() {\n        let d = SliceDeque::<char>::new();\n        assert!(d == []);\n\n        let mut d = SliceDeque::new();\n        d.push_front('a');\n        assert!(d == ['a']);\n\n        let mut d = SliceDeque::new();\n        d.push_back('a');\n        assert!(d == ['a']);\n\n        let mut d = SliceDeque::new();\n        d.push_back('a');\n        d.push_back('b');\n        assert!(d == ['a', 'b']);\n    }\n\n    #[test]\n    fn vecdeque_hash() {\n        let mut x = SliceDeque::new();\n        let mut y = SliceDeque::new();\n\n        x.push_back(1);\n        x.push_back(2);\n        x.push_back(3);\n\n        y.push_back(0);\n        y.push_back(1);\n        y.pop_front();\n        y.push_back(2);\n        y.push_back(3);\n\n        assert!(hash(&x) == hash(&y));\n    }\n\n    #[test]\n    fn vecdeque_hash_after_rotation() {\n        // test that two deques hash equal even if elements are laid out\n        // differently\n        let len = 28;\n        let mut ring: SliceDeque<i32> = (0..len as i32).collect();\n        let orig = ring.clone();\n        for _ in 0..ring.capacity() {\n            // shift values 1 step to the right by pop, sub one, push\n            ring.pop_front();\n            for elt in &mut ring {\n                *elt -= 1;\n            }\n            ring.push_back(len - 1);\n            assert_eq!(hash(&orig), hash(&ring));\n            assert_eq!(orig, ring);\n            assert_eq!(ring, orig);\n        }\n    }\n\n    #[test]\n    fn vecdeque_eq_after_rotation() {\n        // test that two deques are equal even if elements are laid out\n        // differently\n        let len = 28;\n        let mut ring: SliceDeque<i32> = (0..len as i32).collect();\n        let mut shifted = ring.clone();\n        for _ in 0..10 {\n            // shift values 1 step to the right by pop, sub one, push\n            ring.pop_front();\n            for elt in &mut ring {\n                *elt -= 1;\n            }\n            ring.push_back(len - 1);\n        }\n\n        // try every shift\n        for _ in 0..shifted.capacity() {\n            shifted.pop_front();\n            for elt in &mut shifted {\n                *elt -= 1;\n            }\n            shifted.push_back(len - 1);\n            assert_eq!(shifted, ring);\n            assert_eq!(ring, shifted);\n        }\n    }\n\n    #[test]\n    fn vecdeque_ord() {\n        let x = SliceDeque::new();\n        let mut y = SliceDeque::new();\n        y.push_back(1);\n        y.push_back(2);\n        y.push_back(3);\n        assert!(x < y);\n        assert!(y > x);\n        assert!(x <= x);\n        assert!(x >= x);\n    }\n\n    #[test]\n    fn vecdeque_show() {\n        let ringbuf: SliceDeque<_> = (0..10).collect();\n        assert_eq!(format!(\"{:?}\", ringbuf), \"[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\");\n\n        let ringbuf: SliceDeque<_> = vec![\"just\", \"one\", \"test\", \"more\"]\n            .iter()\n            .cloned()\n            .collect();\n        assert_eq!(\n            format!(\"{:?}\", ringbuf),\n            \"[\\\"just\\\", \\\"one\\\", \\\"test\\\", \\\"more\\\"]\"\n        );\n    }\n\n    #[test]\n    #[should_panic] // TODO: zero-sized\n    fn vecdeque_drop_zst() {\n        static mut DROPS: i32 = 0;\n        struct Elem;\n        impl Drop for Elem {\n            fn drop(&mut self) {\n                unsafe {\n                    DROPS += 1;\n                }\n            }\n        }\n\n        let mut ring = SliceDeque::new();\n        ring.push_back(Elem);\n        ring.push_front(Elem);\n        ring.push_back(Elem);\n        ring.push_front(Elem);\n        mem::drop(ring);\n\n        assert_eq!(unsafe { DROPS }, 4);\n    }\n\n    #[test]\n    fn vecdeque_drop() {\n        static mut DROPS: i32 = 0;\n        #[derive(Clone)]\n        struct Elem(i32);\n        impl Drop for Elem {\n            fn drop(&mut self) {\n                unsafe {\n                    DROPS += 1;\n                }\n            }\n        }\n\n        let mut ring = SliceDeque::new();\n        ring.push_back(Elem(0));\n        ring.push_front(Elem(1));\n        ring.push_back(Elem(2));\n        ring.push_front(Elem(3));\n        mem::drop(ring);\n\n        assert_eq!(unsafe { DROPS }, 4);\n    }\n\n    #[test]\n    #[should_panic]\n    fn vecdeque_drop_with_pop_zst() {\n        static mut DROPS: i32 = 0;\n        struct Elem;\n        impl Drop for Elem {\n            fn drop(&mut self) {\n                unsafe {\n                    DROPS += 1;\n                }\n            }\n        }\n\n        let mut ring = SliceDeque::new();\n        ring.push_back(Elem);\n        ring.push_front(Elem);\n        ring.push_back(Elem);\n        ring.push_front(Elem);\n\n        mem::drop(ring.pop_back());\n        mem::drop(ring.pop_front());\n        assert_eq!(unsafe { DROPS }, 2);\n\n        mem::drop(ring);\n        assert_eq!(unsafe { DROPS }, 4);\n    }\n\n    #[test]\n    fn vecdeque_drop_with_pop() {\n        static mut DROPS: i32 = 0;\n        struct Elem(i32);\n        impl Drop for Elem {\n            fn drop(&mut self) {\n                unsafe {\n                    DROPS += 1;\n                }\n            }\n        }\n\n        let mut ring = SliceDeque::new();\n        ring.push_back(Elem(0));\n        ring.push_front(Elem(0));\n        ring.push_back(Elem(0));\n        ring.push_front(Elem(0));\n\n        mem::drop(ring.pop_back());\n        mem::drop(ring.pop_front());\n        assert_eq!(unsafe { DROPS }, 2);\n\n        mem::drop(ring);\n        assert_eq!(unsafe { DROPS }, 4);\n    }\n\n    #[test]\n    #[should_panic]\n    fn vecdeque_drop_clear_zst() {\n        static mut DROPS: i32 = 0;\n        struct Elem;\n        impl Drop for Elem {\n            fn drop(&mut self) {\n                unsafe {\n                    DROPS += 1;\n                }\n            }\n        }\n\n        let mut ring = SliceDeque::new();\n        ring.push_back(Elem);\n        ring.push_front(Elem);\n        ring.push_back(Elem);\n        ring.push_front(Elem);\n        ring.clear();\n        assert_eq!(unsafe { DROPS }, 4);\n\n        mem::drop(ring);\n        assert_eq!(unsafe { DROPS }, 4);\n    }\n\n    #[test]\n    fn vecdeque_drop_clear() {\n        static mut DROPS: i32 = 0;\n        struct Elem(i32);\n        impl Drop for Elem {\n            fn drop(&mut self) {\n                unsafe {\n                    DROPS += 1;\n                }\n            }\n        }\n\n        let mut ring = SliceDeque::new();\n        ring.push_back(Elem(0));\n        ring.push_front(Elem(0));\n        ring.push_back(Elem(0));\n        ring.push_front(Elem(0));\n        ring.clear();\n        assert_eq!(unsafe { DROPS }, 4);\n\n        mem::drop(ring);\n        assert_eq!(unsafe { DROPS }, 4);\n    }\n\n    #[test]\n    fn vecdeque_reserve_grow() {\n        // test growth path A\n        // [T o o H] -> [T o o H . . . . ]\n        let mut ring = SliceDeque::with_capacity(4);\n        for i in 0..3 {\n            ring.push_back(i);\n        }\n        ring.reserve(7);\n        for i in 0..3 {\n            assert_eq!(ring.pop_front(), Some(i));\n        }\n\n        // test growth path B\n        // [H T o o] -> [. T o o H . . . ]\n        let mut ring = SliceDeque::with_capacity(4);\n        for i in 0..1 {\n            ring.push_back(i);\n            assert_eq!(ring.pop_front(), Some(i));\n        }\n        for i in 0..3 {\n            ring.push_back(i);\n        }\n        ring.reserve(7);\n        for i in 0..3 {\n            assert_eq!(ring.pop_front(), Some(i));\n        }\n\n        // test growth path C\n        // [o o H T] -> [o o H . . . . T ]\n        let mut ring = SliceDeque::with_capacity(4);\n        for i in 0..3 {\n            ring.push_back(i);\n            assert_eq!(ring.pop_front(), Some(i));\n        }\n        for i in 0..3 {\n            ring.push_back(i);\n        }\n        ring.reserve(7);\n        for i in 0..3 {\n            assert_eq!(ring.pop_front(), Some(i));\n        }\n    }\n\n    #[test]\n    fn vecdeque_get() {\n        let mut ring = SliceDeque::new();\n        ring.push_back(0);\n        assert_eq!(ring.get(0), Some(&0));\n        assert_eq!(ring.get(1), None);\n\n        ring.push_back(1);\n        assert_eq!(ring.get(0), Some(&0));\n        assert_eq!(ring.get(1), Some(&1));\n        assert_eq!(ring.get(2), None);\n\n        ring.push_back(2);\n        assert_eq!(ring.get(0), Some(&0));\n        assert_eq!(ring.get(1), Some(&1));\n        assert_eq!(ring.get(2), Some(&2));\n        assert_eq!(ring.get(3), None);\n\n        assert_eq!(ring.pop_front(), Some(0));\n        assert_eq!(ring.get(0), Some(&1));\n        assert_eq!(ring.get(1), Some(&2));\n        assert_eq!(ring.get(2), None);\n\n        assert_eq!(ring.pop_front(), Some(1));\n        assert_eq!(ring.get(0), Some(&2));\n        assert_eq!(ring.get(1), None);\n\n        assert_eq!(ring.pop_front(), Some(2));\n        assert_eq!(ring.get(0), None);\n        assert_eq!(ring.get(1), None);\n    }\n\n    #[test]\n    fn vecdeque_get_mut() {\n        let mut ring = SliceDeque::new();\n        for i in 0..3 {\n            ring.push_back(i);\n        }\n\n        match ring.get_mut(1) {\n            Some(x) => *x = -1,\n            None => (),\n        };\n\n        assert_eq!(ring.get_mut(0), Some(&mut 0));\n        assert_eq!(ring.get_mut(1), Some(&mut -1));\n        assert_eq!(ring.get_mut(2), Some(&mut 2));\n        assert_eq!(ring.get_mut(3), None);\n\n        assert_eq!(ring.pop_front(), Some(0));\n        assert_eq!(ring.get_mut(0), Some(&mut -1));\n        assert_eq!(ring.get_mut(1), Some(&mut 2));\n        assert_eq!(ring.get_mut(2), None);\n    }\n\n    #[test]\n    fn vecdeque_front() {\n        let mut ring = SliceDeque::new();\n        ring.push_back(10);\n        ring.push_back(20);\n        assert_eq!(ring.front(), Some(&10));\n        ring.pop_front();\n        assert_eq!(ring.front(), Some(&20));\n        ring.pop_front();\n        assert_eq!(ring.front(), None);\n    }\n\n    #[test]\n    fn vecdeque_as_slices() {\n        let mut ring: SliceDeque<i32> = SliceDeque::with_capacity(127);\n        let cap = ring.capacity() as i32;\n        let first = cap / 2;\n        let last = cap - first;\n        for i in 0..first {\n            ring.push_back(i);\n\n            let (left, right) = ring.as_slices();\n            let expected: Vec<_> = (0..i + 1).collect();\n            assert_eq!(left, &expected[..]);\n            assert_eq!(right, []);\n        }\n\n        for j in -last..0 {\n            ring.push_front(j);\n            let (left, right) = ring.as_slices();\n            let mut expected_left: Vec<_> = (-last..j + 1).rev().collect();\n            expected_left.extend(0..first);\n            assert_eq!(left, &expected_left[..]);\n            assert_eq!(right, []);\n        }\n\n        assert_eq!(ring.len() as i32, cap);\n        assert_eq!(ring.capacity() as i32, cap);\n    }\n\n    #[test]\n    fn vecdeque_as_mut_slices() {\n        let mut ring: SliceDeque<i32> = SliceDeque::with_capacity(127);\n        let cap = ring.capacity() as i32;\n        let first = cap / 2;\n        let last = cap - first;\n        for i in 0..first {\n            ring.push_back(i);\n\n            let (left, right) = ring.as_mut_slices();\n            let expected: Vec<_> = (0..i + 1).collect();\n            assert_eq!(left, &expected[..]);\n            assert_eq!(right, []);\n        }\n\n        for j in -last..0 {\n            ring.push_front(j);\n            let (left, right) = ring.as_mut_slices();\n            let mut expected_left: Vec<_> = (-last..j + 1).rev().collect();\n            expected_left.extend(0..first);\n            assert_eq!(left, &expected_left[..]);\n            assert_eq!(right, []);\n        }\n\n        assert_eq!(ring.len() as i32, cap);\n        assert_eq!(ring.capacity() as i32, cap);\n    }\n\n    #[test]\n    fn vecdeque_append() {\n        let mut a: SliceDeque<_> = vec![1, 2, 3].into_iter().collect();\n        let mut b: SliceDeque<_> = vec![4, 5, 6].into_iter().collect();\n\n        // normal append\n        a.append(&mut b);\n        assert_eq!(a.iter().cloned().collect::<Vec<_>>(), [1, 2, 3, 4, 5, 6]);\n        assert_eq!(b.iter().cloned().collect::<Vec<_>>(), []);\n\n        // append nothing to something\n        a.append(&mut b);\n        assert_eq!(a.iter().cloned().collect::<Vec<_>>(), [1, 2, 3, 4, 5, 6]);\n        assert_eq!(b.iter().cloned().collect::<Vec<_>>(), []);\n\n        // append something to nothing\n        b.append(&mut a);\n        assert_eq!(b.iter().cloned().collect::<Vec<_>>(), [1, 2, 3, 4, 5, 6]);\n        assert_eq!(a.iter().cloned().collect::<Vec<_>>(), []);\n    }\n\n    #[test]\n    fn vecdeque_retain() {\n        let mut buf = SliceDeque::new();\n        buf.extend(1..5);\n        buf.retain(|&x| x % 2 == 0);\n        let v: Vec<_> = buf.into_iter().collect();\n        assert_eq!(&v[..], &[2, 4]);\n    }\n\n    #[test]\n    fn vecdeque_extend_ref() {\n        let mut v = SliceDeque::new();\n        v.push_back(1);\n        v.extend(&[2, 3, 4]);\n\n        assert_eq!(v.len(), 4);\n        assert_eq!(v[0], 1);\n        assert_eq!(v[1], 2);\n        assert_eq!(v[2], 3);\n        assert_eq!(v[3], 4);\n\n        let mut w = SliceDeque::new();\n        w.push_back(5);\n        w.push_back(6);\n        v.extend(&w);\n\n        assert_eq!(v.len(), 6);\n        assert_eq!(v[0], 1);\n        assert_eq!(v[1], 2);\n        assert_eq!(v[2], 3);\n        assert_eq!(v[3], 4);\n        assert_eq!(v[4], 5);\n        assert_eq!(v[5], 6);\n    }\n\n    #[test]\n    fn vecdeque_contains() {\n        let mut v = SliceDeque::new();\n        v.extend(&[2, 3, 4]);\n\n        assert!(v.contains(&3));\n        assert!(!v.contains(&1));\n\n        v.clear();\n\n        assert!(!v.contains(&3));\n    }\n\n    /* TODO: covariance\n    #[allow(dead_code)]\n    fn assert_covariance() {\n        fn drain<'new>(d: Drain<'static, &'static str>) -> Drain<'new, &'new str> {\n            d\n        }\n    }\n        */\n\n    #[cfg(feature = \"unstable\")]\n    #[test]\n    fn vecdeque_is_empty() {\n        let mut v = SliceDeque::<i32>::new();\n        assert!(v.is_empty());\n        assert!(v.iter().is_empty());\n        assert!(v.iter_mut().is_empty());\n        v.extend(&[2, 3, 4]);\n        assert!(!v.is_empty());\n        assert!(!v.iter().is_empty());\n        assert!(!v.iter_mut().is_empty());\n        while let Some(_) = v.pop_front() {\n            assert_eq!(v.is_empty(), v.len() == 0);\n            assert_eq!(v.iter().is_empty(), v.iter().len() == 0);\n            assert_eq!(v.iter_mut().is_empty(), v.iter_mut().len() == 0);\n        }\n        assert!(v.is_empty());\n        assert!(v.iter().is_empty());\n        assert!(v.iter_mut().is_empty());\n        assert!(v.into_iter().is_empty());\n    }\n\n    #[cfg(all(feature = \"bytes_buf\", feature = \"use_std\"))]\n    #[test]\n    fn bytes_bufmut() {\n        use bytes::{BigEndian, BufMut};\n        use std::io::Write;\n\n        {\n            let mut buf = sdeq![];\n\n            buf.put(\"hello world\");\n\n            assert_eq!(buf, b\"hello world\");\n        }\n        {\n            let mut buf = SliceDeque::with_capacity(16);\n\n            unsafe {\n                buf.bytes_mut()[0] = b'h';\n                buf.bytes_mut()[1] = b'e';\n\n                buf.advance_mut(2);\n\n                buf.bytes_mut()[0] = b'l';\n                buf.bytes_mut()[1..3].copy_from_slice(b\"lo\");\n\n                buf.advance_mut(3);\n            }\n\n            assert_eq!(5, buf.len());\n            assert_eq!(buf, b\"hello\");\n        }\n        {\n            let mut buf = SliceDeque::with_capacity(16);\n\n            unsafe {\n                buf.bytes_mut()[0] = b'h';\n                buf.bytes_mut()[1] = b'e';\n\n                buf.advance_mut(2);\n\n                buf.bytes_mut()[0] = b'l';\n                buf.bytes_mut()[1..3].copy_from_slice(b\"lo\");\n\n                buf.advance_mut(3);\n            }\n\n            assert_eq!(5, buf.len());\n            assert_eq!(buf, b\"hello\");\n        }\n        {\n            let mut buf = sdeq![];\n\n            buf.put(b'h');\n            buf.put(&b\"ello\"[..]);\n            buf.put(\" world\");\n\n            assert_eq!(buf, b\"hello world\");\n        }\n        {\n            let mut buf = sdeq![];\n            buf.put_u8(0x01);\n            assert_eq!(buf, b\"\\x01\");\n        }\n        {\n            let mut buf = sdeq![];\n            buf.put_i8(0x01);\n            assert_eq!(buf, b\"\\x01\");\n        }\n        {\n            let mut buf = sdeq![];\n            buf.put_u16::<BigEndian>(0x0809);\n            assert_eq!(buf, b\"\\x08\\x09\");\n        }\n        {\n            let mut buf = sdeq![];\n\n            {\n                let reference = buf.by_ref();\n\n                // Adapt reference to `std::io::Write`.\n                let mut writer = reference.writer();\n\n                // Use the buffer as a writter\n                Write::write(&mut writer, &b\"hello world\"[..]).unwrap();\n            } // drop our &mut reference so that we can use `buf` again\n\n            assert_eq!(buf, &b\"hello world\"[..]);\n        }\n        {\n            let mut buf = sdeq![].writer();\n\n            let num = buf.write(&b\"hello world\"[..]).unwrap();\n            assert_eq!(11, num);\n\n            let buf = buf.into_inner();\n\n            assert_eq!(*buf, b\"hello world\"[..]);\n        }\n    }\n\n    #[cfg(all(feature = \"bytes_buf\", feature = \"use_std\"))]\n    #[test]\n    fn bytes_buf() {\n        {\n            use bytes::{Buf, Bytes, IntoBuf};\n\n            let buf = Bytes::from(&b\"hello world\"[..]).into_buf();\n            let vec: SliceDeque<u8> = buf.collect();\n\n            assert_eq!(vec, &b\"hello world\"[..]);\n        }\n        {\n            use bytes::{Buf, BufMut};\n            use std::io::Cursor;\n\n            let mut buf = Cursor::new(\"hello world\").take(5);\n            let mut dst = sdeq![];\n\n            dst.put(&mut buf);\n            assert_eq!(dst, b\"hello\");\n\n            let mut buf = buf.into_inner();\n            dst.clear();\n            dst.put(&mut buf);\n            assert_eq!(dst, b\" world\");\n        }\n        {\n            use bytes::{Buf, BufMut};\n            use std::io::Cursor;\n\n            let mut buf = Cursor::new(\"hello world\");\n            let mut dst = sdeq![];\n\n            {\n                let reference = buf.by_ref();\n                dst.put(&mut reference.take(5));\n                assert_eq!(dst, b\"hello\");\n            } // drop our &mut reference so we can use `buf` again\n\n            dst.clear();\n            dst.put(&mut buf);\n            assert_eq!(dst, b\" world\");\n        }\n    }\n\n    #[test]\n    fn issue_42() {\n        // https://github.com/gnzlbg/slice_deque/issues/42\n        let page_size = ::mirrored::allocation_granularity();\n        let mut deque = SliceDeque::<u8>::with_capacity(page_size);\n        let page_size = page_size as isize;\n\n        let slice = unsafe {\n            deque.move_tail(page_size);\n            deque.move_head(page_size / 100 * 99);\n            deque.move_tail(page_size / 100 * 99);\n            deque.move_head(page_size / 100 * 99);\n            deque.tail_head_slice()\n        };\n\n        for i in 0..slice.len() {\n            // segfault:\n            slice[i] = 0;\n        }\n    }\n\n    #[test]\n    fn issue_45() {\n        // https://github.com/gnzlbg/slice_deque/issues/45\n        fn refill(buf: &mut SliceDeque<u8>) {\n            let data = [0u8; MAX_SAMPLES_PER_FRAME * 5];\n            buf.extend(data.iter());\n        }\n\n        const MAX_SAMPLES_PER_FRAME: usize = 1152 * 2;\n        const BUFFER_SIZE: usize = MAX_SAMPLES_PER_FRAME * 15;\n        const REFILL_TRIGGER: usize = MAX_SAMPLES_PER_FRAME * 8;\n\n        let mut buf = SliceDeque::with_capacity(BUFFER_SIZE);\n        for _ in 0..10_000 {\n            if buf.len() < REFILL_TRIGGER {\n                refill(&mut buf);\n            }\n\n            let cur_len = buf.len();\n            buf.truncate_front(cur_len - 10);\n        }\n    }\n\n    #[test]\n    fn issue_47() {\n        let page_size = ::mirrored::allocation_granularity();\n        let mut sdq = SliceDeque::<u8>::new();\n        let vec = vec![0_u8; page_size + 1];\n        sdq.extend(vec);\n    }\n\n    #[test]\n    fn issue_50() {\n        use std::fs::File;\n        use std::io::Write;\n        use std::path::Path;\n\n        let out_buffer = SliceDeque::new();\n\n        let p = if cfg!(target_os = \"windows\") {\n            \"slice_deque_test\"\n        } else {\n            \"/tmp/slice_deque_test\"\n        };\n\n        let mut out_file = File::create(Path::new(p)).unwrap();\n        let res = out_file.write(&out_buffer[..]);\n        println!(\"Result was {:?}\", res);\n        println!(\"Buffer size: {}\", out_buffer.len());\n        println!(\"Address of buffer was: {:?}\", out_buffer.as_ptr());\n    }\n\n    #[test]\n    fn empty_ptr() {\n        {\n            let sdeq = SliceDeque::<i8>::new();\n            let v = Vec::<i8>::new();\n            assert_eq!(sdeq.as_ptr() as usize, mem::align_of::<i8>());\n            assert_eq!(v.as_ptr() as usize, mem::align_of::<i8>());\n        }\n        {\n            let sdeq = SliceDeque::<i16>::new();\n            let v = Vec::<i16>::new();\n            assert_eq!(sdeq.as_ptr() as usize, mem::align_of::<i16>());\n            assert_eq!(v.as_ptr() as usize, mem::align_of::<i16>());\n        }\n        {\n            let sdeq = SliceDeque::<i32>::new();\n            let v = Vec::<i32>::new();\n            assert_eq!(sdeq.as_ptr() as usize, mem::align_of::<i32>());\n            assert_eq!(v.as_ptr() as usize, mem::align_of::<i32>());\n        }\n        {\n            let sdeq = SliceDeque::<i64>::new();\n            let v = Vec::<i64>::new();\n            assert_eq!(sdeq.as_ptr() as usize, mem::align_of::<i64>());\n            assert_eq!(v.as_ptr() as usize, mem::align_of::<i64>());\n        }\n        {\n            #[repr(align(32))]\n            struct Foo(i8);\n            let sdeq = SliceDeque::<Foo>::new();\n            let v = Vec::<Foo>::new();\n            assert_eq!(sdeq.as_ptr() as usize, mem::align_of::<Foo>());\n            assert_eq!(v.as_ptr() as usize, mem::align_of::<Foo>());\n        }\n    }\n}\n"
  },
  {
    "project": "late-static",
    "target": 1,
    "commit_id": "9916669a85f88609e469fa6f8b4c6f62b2b84b12",
    "func": "//! Initialize variables at runtime which then behave like static variables.\n//!\n//! ```rust\n//! extern crate late_static;\n//! use late_static::LateStatic;\n//!\n//! struct Foo {\n//!     pub value: u32,\n//! }\n//!\n//! static FOO: LateStatic<Foo> = LateStatic::new();\n//!\n//! fn main() {\n//!     unsafe {\n//!         LateStatic::assign(&FOO, Foo { value: 42 });\n//!     }\n//!     println!(\"{}\", FOO.value);\n//! }\n//! ```\n#![cfg_attr(not(test), no_std)]\n\nuse core::cell::UnsafeCell;\n\n/// Static value that is manually initialized at runtime.\npub struct LateStatic<T> {\n    val: UnsafeCell<Option<T>>,\n}\n\nunsafe impl<T: Send> core::marker::Send for LateStatic<T> {}\nunsafe impl<T: Send> core::marker::Sync for LateStatic<T> {}\n\nimpl<T> LateStatic<T> {\n    /// Construct a LateStatic.\n    pub const fn new() -> Self {\n        LateStatic {\n            val: UnsafeCell::new(None),\n        }\n    }\n\n    /// Assign a value to the late static.\n    ///\n    /// This only works once. A second call to assign for a given variable will panic.\n    ///\n    /// # Safety\n    ///\n    /// This is completely unsafe if there is even the slightest chance of another\n    /// thread trying to dereference the variable.\n    pub unsafe fn assign(instance: &LateStatic<T>, val: T) {\n        let option: &mut Option<T> = &mut *instance.val.get();\n        if option.is_some() {\n            panic!(\"Second assignment to late static\");\n        } else {\n            *option = Some(val);\n        }\n    }\n\n    /// Invalidate the late static by removing its inner value.\n    ///\n    /// # Safety\n    ///\n    /// This is completely unsafe if there is even the slightest chance of another\n    /// thread trying to dereference the variable.\n    pub unsafe fn clear(instance: &LateStatic<T>) {\n        if !Self::has_value(instance) {\n            panic!(\"Tried to clear a late static without a value\");\n        }\n        let option: &mut Option<T> = &mut *instance.val.get();\n        *option = None;\n    }\n\n    /// Whether a value is assigned to this LateStatic.\n    ///\n    /// # Safety\n    ///\n    /// This is completely unsafe if there is even the slightest chance of another\n    /// thread trying to dereference the variable.\n    pub unsafe fn has_value(instance: &LateStatic<T>) -> bool {\n        let option: &Option<T> = &*instance.val.get();\n        option.is_some()\n    }\n}\n\nimpl<T> core::ops::Deref for LateStatic<T> {\n    type Target = T;\n\n    fn deref(&self) -> &T {\n        unsafe {\n            let option: &Option<T> = &*self.val.get();\n            match option {\n                Some(ref val) => val,\n                None => panic!(\"Dereference of late static before a value was assigned\"),\n            }\n        }\n    }\n}\n\nimpl<T> core::ops::DerefMut for LateStatic<T> {\n    fn deref_mut(&mut self) -> &mut T {\n        unsafe {\n            let option: &mut Option<T> = &mut *self.val.get();\n            match option {\n                Some(ref mut val) => val,\n                None => panic!(\"Dereference of late static before a value was assigned\"),\n            }\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    static ASSIGN_ONCE_TEST: LateStatic<u32> = LateStatic::new();\n    #[test]\n    fn assign_once() {\n        unsafe {\n            assert!(!LateStatic::has_value(&ASSIGN_ONCE_TEST));\n            LateStatic::assign(&ASSIGN_ONCE_TEST, 42);\n            assert!(LateStatic::has_value(&ASSIGN_ONCE_TEST));\n        }\n    }\n\n    static ASSIGN_TWICE_TEST: LateStatic<u32> = LateStatic::new();\n    #[test]\n    #[should_panic]\n    fn assign_twice() {\n        unsafe {\n            LateStatic::assign(&ASSIGN_TWICE_TEST, 42);\n            LateStatic::assign(&ASSIGN_TWICE_TEST, 37);\n        }\n    }\n\n    struct Foo {\n        pub value: u32,\n    }\n\n    static DEREF_CONST_TEST: LateStatic<Foo> = LateStatic::new();\n    #[test]\n    fn deref_const() {\n        unsafe {\n            LateStatic::assign(&DEREF_CONST_TEST, Foo { value: 42 });\n        }\n        assert_eq!(DEREF_CONST_TEST.value, 42);\n    }\n\n    static mut DEREF_MUT_TEST: LateStatic<Foo> = LateStatic::new();\n    #[test]\n    fn deref_mut() {\n        unsafe {\n            LateStatic::assign(&DEREF_MUT_TEST, Foo { value: 42 });\n            assert_eq!(DEREF_MUT_TEST.value, 42);\n            DEREF_MUT_TEST.value = 37;\n            assert_eq!(DEREF_MUT_TEST.value, 37);\n        }\n    }\n\n    static mut DEREF_WITHOUT_VALUE: LateStatic<Foo> = LateStatic::new();\n    #[test]\n    #[should_panic]\n    fn deref_without_value() {\n        unsafe {\n            #[allow(clippy::no_effect)]\n            DEREF_WITHOUT_VALUE.value;\n        }\n    }\n\n    static mut CLEAR_TEST: LateStatic<Foo> = LateStatic::new();\n    #[test]\n    fn clear() {\n        unsafe {\n            LateStatic::assign(&CLEAR_TEST, Foo { value: 42 });\n            assert_eq!(CLEAR_TEST.value, 42);\n            LateStatic::clear(&CLEAR_TEST);\n            assert!(!LateStatic::has_value(&CLEAR_TEST));\n        }\n    }\n\n    static mut CLEAR_WITHOUT_VALUE: LateStatic<Foo> = LateStatic::new();\n    #[test]\n    #[should_panic]\n    fn clear_without_value() {\n        unsafe {\n            LateStatic::clear(&CLEAR_WITHOUT_VALUE);\n        }\n    }\n}\n"
  },
  {
    "project": "rust-smallvec",
    "target": 1,
    "commit_id": "26b249075930b46cfafc70b1d18fd0cb35fd2314",
    "func": "// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n// option. This file may not be copied, modified, or distributed\n// except according to those terms.\n\n//! Small vectors in various sizes. These store a certain number of elements inline, and fall back\n//! to the heap for larger allocations.  This can be a useful optimization for improving cache\n//! locality and reducing allocator traffic for workloads that fit within the inline buffer.\n//!\n//! ## no_std support\n//!\n//! By default, `smallvec` depends on `libstd`. However, it can be configured to use the unstable\n//! `liballoc` API instead, for use on platforms that have `liballoc` but not `libstd`.  This\n//! configuration is currently unstable and is not guaranteed to work on all versions of Rust.\n//!\n//! To depend on `smallvec` without `libstd`, use `default-features = false` in the `smallvec`\n//! section of Cargo.toml to disable its `\"std\"` feature.\n//!\n//! ## `union` feature\n//!\n//! When the `union` feature is enabled `smallvec` will track its state (inline or spilled)\n//! without the use of an enum tag, reducing the size of the `smallvec` by one machine word.\n//! This means that there is potentially no space overhead compared to `Vec`.\n//! Note that `smallvec` can still be larger than `Vec` if the inline buffer is larger than two\n//! machine words.\n//!\n//! To use this feature add `features = [\"union\"]` in the `smallvec` section of Cargo.toml.\n//! Note that this feature requires a nightly compiler (for now).\n\n#![cfg_attr(not(feature = \"std\"), no_std)]\n#![cfg_attr(not(feature = \"std\"), feature(alloc))]\n#![cfg_attr(feature = \"union\", feature(untagged_unions))]\n#![deny(missing_docs)]\n\n\n#[cfg(not(feature = \"std\"))]\n#[macro_use]\nextern crate alloc;\n\n#[cfg(not(feature = \"std\"))]\nuse alloc::Vec;\n\n#[cfg(feature = \"serde\")]\nextern crate serde;\n\nextern crate unreachable;\nuse unreachable::UncheckedOptionExt;\n\n#[cfg(not(feature = \"std\"))]\nmod std {\n    pub use core::*;\n}\n\nuse std::borrow::{Borrow, BorrowMut};\nuse std::cmp;\nuse std::fmt;\nuse std::hash::{Hash, Hasher};\nuse std::iter::{IntoIterator, FromIterator, repeat};\nuse std::mem;\n#[cfg(not(feature = \"union\"))]\nuse std::mem::ManuallyDrop;\nuse std::ops;\nuse std::ptr;\nuse std::slice;\n#[cfg(feature = \"std\")]\nuse std::io;\n#[cfg(feature = \"serde\")]\nuse serde::ser::{Serialize, Serializer, SerializeSeq};\n#[cfg(feature = \"serde\")]\nuse serde::de::{Deserialize, Deserializer, SeqAccess, Visitor};\n#[cfg(feature = \"serde\")]\nuse std::marker::PhantomData;\n\n/// Creates a [`SmallVec`] containing the arguments.\n///\n/// `smallvec!` allows `SmallVec`s to be defined with the same syntax as array expressions.\n/// There are two forms of this macro:\n///\n/// - Create a [`SmallVec`] containing a given list of elements:\n///\n/// ```\n/// # #[macro_use] extern crate smallvec;\n/// # use smallvec::SmallVec;\n/// # fn main() {\n/// let v: SmallVec<[_; 128]> = smallvec![1, 2, 3];\n/// assert_eq!(v[0], 1);\n/// assert_eq!(v[1], 2);\n/// assert_eq!(v[2], 3);\n/// # }\n/// ```\n///\n/// - Create a [`SmallVec`] from a given element and size:\n///\n/// ```\n/// # #[macro_use] extern crate smallvec;\n/// # use smallvec::SmallVec;\n/// # fn main() {\n/// let v: SmallVec<[_; 0x8000]> = smallvec![1; 3];\n/// assert_eq!(v, SmallVec::from_buf([1, 1, 1]));\n/// # }\n/// ```\n///\n/// Note that unlike array expressions this syntax supports all elements\n/// which implement [`Clone`] and the number of elements doesn't have to be\n/// a constant.\n///\n/// This will use `clone` to duplicate an expression, so one should be careful\n/// using this with types having a nonstandard `Clone` implementation. For\n/// example, `smallvec![Rc::new(1); 5]` will create a vector of five references\n/// to the same boxed integer value, not five references pointing to independently\n/// boxed integers.\n\n#[macro_export]\nmacro_rules! smallvec {\n    ($elem:expr; $n:expr) => ({\n        SmallVec::from_elem($elem, $n)\n    });\n    ($($x:expr),*$(,)*) => ({\n        SmallVec::from_slice(&[$($x),*])\n    });\n}\n\n/// `panic!()` in debug builds, optimization hint in release.\n#[cfg(not(feature = \"union\"))]\nmacro_rules! debug_unreachable {\n    () => { debug_unreachable!(\"entered unreachable code\") };\n    ($e:expr) => {\n        if cfg!(not(debug_assertions)) {\n            unreachable::unreachable();\n        } else {\n            panic!($e);\n        }\n    }\n}\n\n/// Common operations implemented by both `Vec` and `SmallVec`.\n///\n/// This can be used to write generic code that works with both `Vec` and `SmallVec`.\n///\n/// ## Example\n///\n/// ```rust\n/// use smallvec::{VecLike, SmallVec};\n///\n/// fn initialize<V: VecLike<u8>>(v: &mut V) {\n///     for i in 0..5 {\n///         v.push(i);\n///     }\n/// }\n///\n/// let mut vec = Vec::new();\n/// initialize(&mut vec);\n///\n/// let mut small_vec = SmallVec::<[u8; 8]>::new();\n/// initialize(&mut small_vec);\n/// ```\n#[deprecated(note = \"Use `Extend` and `Deref<[T]>` instead\")]\npub trait VecLike<T>:\n        ops::Index<usize, Output=T> +\n        ops::IndexMut<usize> +\n        ops::Index<ops::Range<usize>, Output=[T]> +\n        ops::IndexMut<ops::Range<usize>> +\n        ops::Index<ops::RangeFrom<usize>, Output=[T]> +\n        ops::IndexMut<ops::RangeFrom<usize>> +\n        ops::Index<ops::RangeTo<usize>, Output=[T]> +\n        ops::IndexMut<ops::RangeTo<usize>> +\n        ops::Index<ops::RangeFull, Output=[T]> +\n        ops::IndexMut<ops::RangeFull> +\n        ops::DerefMut<Target = [T]> +\n        Extend<T> {\n\n    /// Append an element to the vector.\n    fn push(&mut self, value: T);\n}\n\n#[allow(deprecated)]\nimpl<T> VecLike<T> for Vec<T> {\n    #[inline]\n    fn push(&mut self, value: T) {\n        Vec::push(self, value);\n    }\n}\n\n/// Trait to be implemented by a collection that can be extended from a slice\n///\n/// ## Example\n///\n/// ```rust\n/// use smallvec::{ExtendFromSlice, SmallVec};\n///\n/// fn initialize<V: ExtendFromSlice<u8>>(v: &mut V) {\n///     v.extend_from_slice(b\"Test!\");\n/// }\n///\n/// let mut vec = Vec::new();\n/// initialize(&mut vec);\n/// assert_eq!(&vec, b\"Test!\");\n///\n/// let mut small_vec = SmallVec::<[u8; 8]>::new();\n/// initialize(&mut small_vec);\n/// assert_eq!(&small_vec as &[_], b\"Test!\");\n/// ```\npub trait ExtendFromSlice<T> {\n    /// Extends a collection from a slice of its element type\n    fn extend_from_slice(&mut self, other: &[T]);\n}\n\nimpl<T: Clone> ExtendFromSlice<T> for Vec<T> {\n    fn extend_from_slice(&mut self, other: &[T]) {\n        Vec::extend_from_slice(self, other)\n    }\n}\n\nunsafe fn deallocate<T>(ptr: *mut T, capacity: usize) {\n    let _vec: Vec<T> = Vec::from_raw_parts(ptr, 0, capacity);\n    // Let it drop.\n}\n\n/// An iterator that removes the items from a `SmallVec` and yields them by value.\n///\n/// Returned from [`SmallVec::drain`][1].\n///\n/// [1]: struct.SmallVec.html#method.drain\npub struct Drain<'a, T: 'a> {\n    iter: slice::IterMut<'a,T>,\n}\n\nimpl<'a, T: 'a> Iterator for Drain<'a,T> {\n    type Item = T;\n\n    #[inline]\n    fn next(&mut self) -> Option<T> {\n        match self.iter.next() {\n            None => None,\n            Some(reference) => {\n                unsafe {\n                    Some(ptr::read(reference))\n                }\n            }\n        }\n    }\n\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.iter.size_hint()\n    }\n}\n\nimpl<'a, T: 'a> DoubleEndedIterator for Drain<'a, T> {\n    #[inline]\n    fn next_back(&mut self) -> Option<T> {\n        match self.iter.next_back() {\n            None => None,\n            Some(reference) => {\n                unsafe {\n                    Some(ptr::read(reference))\n                }\n            }\n        }\n    }\n}\n\nimpl<'a, T> ExactSizeIterator for Drain<'a, T> { }\n\nimpl<'a, T: 'a> Drop for Drain<'a,T> {\n    fn drop(&mut self) {\n        // Destroy the remaining elements.\n        for _ in self.by_ref() {}\n    }\n}\n\n#[cfg(feature = \"union\")]\n#[allow(unions_with_drop_fields)]\nunion SmallVecData<A: Array> {\n    inline: A,\n    heap: (*mut A::Item, usize),\n}\n\n#[cfg(feature = \"union\")]\nimpl<A: Array> SmallVecData<A> {\n    #[inline]\n    unsafe fn inline(&self) -> &A {\n        &self.inline\n    }\n    #[inline]\n    unsafe fn inline_mut(&mut self) -> &mut A {\n        &mut self.inline\n    }\n    #[inline]\n    fn from_inline(inline: A) -> SmallVecData<A> {\n        SmallVecData { inline }\n    }\n    #[inline]\n    unsafe fn heap(&self) -> (*mut A::Item, usize) {\n        self.heap\n    }\n    #[inline]\n    unsafe fn heap_mut(&mut self) -> &mut (*mut A::Item, usize) {\n        &mut self.heap\n    }\n    #[inline]\n    fn from_heap(ptr: *mut A::Item, len: usize) -> SmallVecData<A> {\n        SmallVecData { heap: (ptr, len) }\n    }\n}\n\n#[cfg(not(feature = \"union\"))]\nenum SmallVecData<A: Array> {\n    Inline(ManuallyDrop<A>),\n    Heap((*mut A::Item, usize)),\n}\n\n#[cfg(not(feature = \"union\"))]\nimpl<A: Array> SmallVecData<A> {\n    #[inline]\n    unsafe fn inline(&self) -> &A {\n        match *self {\n            SmallVecData::Inline(ref a) => a,\n            _ => debug_unreachable!(),\n        }\n    }\n    #[inline]\n    unsafe fn inline_mut(&mut self) -> &mut A {\n        match *self {\n            SmallVecData::Inline(ref mut a) => a,\n            _ => debug_unreachable!(),\n        }\n    }\n    #[inline]\n    fn from_inline(inline: A) -> SmallVecData<A> {\n        SmallVecData::Inline(ManuallyDrop::new(inline))\n    }\n    #[inline]\n    unsafe fn heap(&self) -> (*mut A::Item, usize) {\n        match *self {\n            SmallVecData::Heap(data) => data,\n            _ => debug_unreachable!(),\n        }\n    }\n    #[inline]\n    unsafe fn heap_mut(&mut self) -> &mut (*mut A::Item, usize) {\n        match *self {\n            SmallVecData::Heap(ref mut data) => data,\n            _ => debug_unreachable!(),\n        }\n    }\n    #[inline]\n    fn from_heap(ptr: *mut A::Item, len: usize) -> SmallVecData<A> {\n        SmallVecData::Heap((ptr, len))\n    }\n}\n\nunsafe impl<A: Array + Send> Send for SmallVecData<A> {}\nunsafe impl<A: Array + Sync> Sync for SmallVecData<A> {}\n\n/// A `Vec`-like container that can store a small number of elements inline.\n///\n/// `SmallVec` acts like a vector, but can store a limited amount of data inline within the\n/// `Smallvec` struct rather than in a separate allocation.  If the data exceeds this limit, the\n/// `SmallVec` will \"spill\" its data onto the heap, allocating a new buffer to hold it.\n///\n/// The amount of data that a `SmallVec` can store inline depends on its backing store. The backing\n/// store can be any type that implements the `Array` trait; usually it is a small fixed-sized\n/// array.  For example a `SmallVec<[u64; 8]>` can hold up to eight 64-bit integers inline.\n///\n/// ## Example\n///\n/// ```rust\n/// use smallvec::SmallVec;\n/// let mut v = SmallVec::<[u8; 4]>::new(); // initialize an empty vector\n///\n/// // The vector can hold up to 4 items without spilling onto the heap.\n/// v.extend(0..4);\n/// assert_eq!(v.len(), 4);\n/// assert!(!v.spilled());\n///\n/// // Pushing another element will force the buffer to spill:\n/// v.push(4);\n/// assert_eq!(v.len(), 5);\n/// assert!(v.spilled());\n/// ```\npub struct SmallVec<A: Array> {\n    // The capacity field is used to determine which of the storage variants is active:\n    // If capacity <= A::size() then the inline variant is used and capacity holds the current length of the vector (number of elements actually in use).\n    // If capacity > A::size() then the heap variant is used and capacity holds the size of the memory allocation.\n    capacity: usize,\n    data: SmallVecData<A>,\n}\n\nimpl<A: Array> SmallVec<A> {\n    /// Construct an empty vector\n    #[inline]\n    pub fn new() -> SmallVec<A> {\n        unsafe {\n            SmallVec {\n                capacity: 0,\n                data: SmallVecData::from_inline(mem::uninitialized()),\n            }\n        }\n    }\n\n    /// Construct an empty vector with enough capacity pre-allocated to store at least `n`\n    /// elements.\n    ///\n    /// Will create a heap allocation only if `n` is larger than the inline capacity.\n    ///\n    /// ```\n    /// # use smallvec::SmallVec;\n    ///\n    /// let v: SmallVec<[u8; 3]> = SmallVec::with_capacity(100);\n    ///\n    /// assert!(v.is_empty());\n    /// assert!(v.capacity() >= 100);\n    /// ```\n    #[inline]\n    pub fn with_capacity(n: usize) -> Self {\n        let mut v = SmallVec::new();\n        v.reserve_exact(n);\n        v\n    }\n\n    /// Construct a new `SmallVec` from a `Vec<A::Item>`.\n    ///\n    /// Elements will be copied to the inline buffer if vec.capacity() <= A::size().\n    ///\n    /// ```rust\n    /// use smallvec::SmallVec;\n    ///\n    /// let vec = vec![1, 2, 3, 4, 5];\n    /// let small_vec: SmallVec<[_; 3]> = SmallVec::from_vec(vec);\n    ///\n    /// assert_eq!(&*small_vec, &[1, 2, 3, 4, 5]);\n    /// ```\n    #[inline]\n    pub fn from_vec(mut vec: Vec<A::Item>) -> SmallVec<A> {\n        if vec.capacity() <= A::size() {\n            unsafe {\n                let mut data = SmallVecData::<A>::from_inline(mem::uninitialized());\n                let len = vec.len();\n                vec.set_len(0);\n                ptr::copy_nonoverlapping(vec.as_ptr(), data.inline_mut().ptr_mut(), len);\n\n                SmallVec {\n                    capacity: len,\n                    data,\n                }\n            }\n        } else {\n            let (ptr, cap, len) = (vec.as_mut_ptr(), vec.capacity(), vec.len());\n            mem::forget(vec);\n\n            SmallVec {\n                capacity: cap,\n                data: SmallVecData::from_heap(ptr, len),\n            }\n        }\n    }\n\n    /// Constructs a new `SmallVec` on the stack from an `A` without\n    /// copying elements.\n    ///\n    /// ```rust\n    /// use smallvec::SmallVec;\n    ///\n    /// let buf = [1, 2, 3, 4, 5];\n    /// let small_vec: SmallVec<_> = SmallVec::from_buf(buf);\n    ///\n    /// assert_eq!(&*small_vec, &[1, 2, 3, 4, 5]);\n    /// ```\n    #[inline]\n    pub fn from_buf(buf: A) -> SmallVec<A> {\n        SmallVec {\n            capacity: A::size(),\n            data: SmallVecData::from_inline(buf),\n        }\n    }\n\n    /// Sets the length of a vector.\n    ///\n    /// This will explicitly set the size of the vector, without actually\n    /// modifying its buffers, so it is up to the caller to ensure that the\n    /// vector is actually the specified size.\n    pub unsafe fn set_len(&mut self, new_len: usize) {\n        let (_, len_ptr, _) = self.triple_mut();\n        *len_ptr = new_len;\n    }\n\n    /// The maximum number of elements this vector can hold inline\n    #[inline]\n    pub fn inline_size(&self) -> usize {\n        A::size()\n    }\n\n    /// The number of elements stored in the vector\n    #[inline]\n    pub fn len(&self) -> usize {\n        self.triple().1\n    }\n\n    /// Returns `true` if the vector is empty\n    #[inline]\n    pub fn is_empty(&self) -> bool {\n        self.len() == 0\n    }\n\n    /// The number of items the vector can hold without reallocating\n    #[inline]\n    pub fn capacity(&self) -> usize {\n        self.triple().2\n    }\n\n    /// Returns a tuple with (data ptr, len, capacity)\n    /// Useful to get all SmallVec properties with a single check of the current storage variant.\n    #[inline]\n    fn triple(&self) -> (*const A::Item, usize, usize) {\n        unsafe {\n            if self.spilled() {\n                let (ptr, len) = self.data.heap();\n                (ptr, len, self.capacity)\n            } else {\n                (self.data.inline().ptr(), self.capacity, A::size())\n            }\n        }\n    }\n\n    /// Returns a tuple with (data ptr, len ptr, capacity)\n    #[inline]\n    fn triple_mut(&mut self) -> (*mut A::Item, &mut usize, usize) {\n        unsafe {\n            if self.spilled() {\n                let &mut (ptr, ref mut len_ptr) = self.data.heap_mut();\n                (ptr, len_ptr, self.capacity)\n            } else {\n                (self.data.inline_mut().ptr_mut(), &mut self.capacity, A::size())\n            }\n        }\n    }\n\n    /// Returns `true` if the data has spilled into a separate heap-allocated buffer.\n    #[inline]\n    pub fn spilled(&self) -> bool {\n        self.capacity > A::size()\n    }\n\n    /// Empty the vector and return an iterator over its former contents.\n    pub fn drain(&mut self) -> Drain<A::Item> {\n        unsafe {\n            let ptr = self.as_mut_ptr();\n\n            let current_len = self.len();\n            self.set_len(0);\n\n            let slice = slice::from_raw_parts_mut(ptr, current_len);\n\n            Drain {\n                iter: slice.iter_mut(),\n            }\n        }\n    }\n\n    /// Append an item to the vector.\n    #[inline]\n    pub fn push(&mut self, value: A::Item) {\n        unsafe {\n            let (_, &mut len, cap) = self.triple_mut();\n            if len == cap {\n                self.grow(cmp::max(cap * 2, 1))\n            }\n            let (ptr, len_ptr, _) = self.triple_mut();\n            *len_ptr = len + 1;\n            ptr::write(ptr.offset(len as isize), value);\n        }\n    }\n\n    /// Remove an item from the end of the vector and return it, or None if empty.\n    #[inline]\n    pub fn pop(&mut self) -> Option<A::Item> {\n        unsafe {\n            let (ptr, len_ptr, _) = self.triple_mut();\n            if *len_ptr == 0 {\n                return None;\n            }\n            let last_index = *len_ptr - 1;\n            *len_ptr = last_index;\n            Some(ptr::read(ptr.offset(last_index as isize)))\n        }\n    }\n\n    /// Re-allocate to set the capacity to `max(new_cap, inline_size())`.\n    ///\n    /// Panics if `new_cap` is less than the vector's length.\n    pub fn grow(&mut self, new_cap: usize) {\n        unsafe {\n            let (ptr, &mut len, cap) = self.triple_mut();\n            let spilled = self.spilled();\n            assert!(new_cap >= len);\n            if new_cap <= self.inline_size() {\n                if !spilled {\n                    return;\n                }\n                self.data = SmallVecData::from_inline(mem::uninitialized());\n                ptr::copy_nonoverlapping(ptr, self.data.inline_mut().ptr_mut(), len);\n                deallocate(ptr, cap);\n            } else if new_cap != cap {\n                let mut vec = Vec::with_capacity(new_cap);\n                let new_alloc = vec.as_mut_ptr();\n                mem::forget(vec);\n                ptr::copy_nonoverlapping(ptr, new_alloc, len);\n                self.data = SmallVecData::from_heap(new_alloc, len);\n                self.capacity = new_cap;\n                if spilled {\n                    deallocate(ptr, cap);\n                }\n            }\n        }\n    }\n\n    /// Reserve capacity for `additional` more elements to be inserted.\n    ///\n    /// May reserve more space to avoid frequent reallocations.\n    ///\n    /// If the new capacity would overflow `usize` then it will be set to `usize::max_value()`\n    /// instead. (This means that inserting `additional` new elements is not guaranteed to be\n    /// possible after calling this function.)\n    pub fn reserve(&mut self, additional: usize) {\n        // prefer triple_mut() even if triple() would work\n        // so that the optimizer removes duplicated calls to it\n        // from callers like insert()\n        let (_, &mut len, cap) = self.triple_mut();\n        if cap - len < additional {\n            let new_cap = len.checked_add(additional).\n                and_then(usize::checked_next_power_of_two).\n                unwrap_or(usize::max_value());\n            self.grow(new_cap);\n        }\n    }\n\n    /// Reserve the minumum capacity for `additional` more elements to be inserted.\n    ///\n    /// Panics if the new capacity overflows `usize`.\n    pub fn reserve_exact(&mut self, additional: usize) {\n        let (_, &mut len, cap) = self.triple_mut();\n        if cap - len < additional {\n            match len.checked_add(additional) {\n                Some(cap) => self.grow(cap),\n                None => panic!(\"reserve_exact overflow\"),\n            }\n        }\n    }\n\n    /// Shrink the capacity of the vector as much as possible.\n    ///\n    /// When possible, this will move data from an external heap buffer to the vector's inline\n    /// storage.\n    pub fn shrink_to_fit(&mut self) {\n        if !self.spilled() {\n            return;\n        }\n        let len = self.len();\n        if self.inline_size() >= len {\n            unsafe {\n                let (ptr, len) = self.data.heap();\n                self.data = SmallVecData::from_inline(mem::uninitialized());\n                ptr::copy_nonoverlapping(ptr, self.data.inline_mut().ptr_mut(), len);\n                deallocate(ptr, self.capacity);\n                self.capacity = len;\n            }\n        } else if self.capacity() > len {\n            self.grow(len);\n        }\n    }\n\n    /// Shorten the vector, keeping the first `len` elements and dropping the rest.\n    ///\n    /// If `len` is greater than or equal to the vector's current length, this has no\n    /// effect.\n    ///\n    /// This does not re-allocate.  If you want the vector's capacity to shrink, call\n    /// `shrink_to_fit` after truncating.\n    pub fn truncate(&mut self, len: usize) {\n        unsafe {\n            let (ptr, len_ptr, _) = self.triple_mut();\n            while len < *len_ptr {\n                let last_index = *len_ptr - 1;\n                *len_ptr = last_index;\n                ptr::drop_in_place(ptr.offset(last_index as isize));\n            }\n        }\n    }\n\n    /// Extracts a slice containing the entire vector.\n    ///\n    /// Equivalent to `&s[..]`.\n    pub fn as_slice(&self) -> &[A::Item] {\n        self\n    }\n\n    /// Extracts a mutable slice of the entire vector.\n    ///\n    /// Equivalent to `&mut s[..]`.\n    pub fn as_mut_slice(&mut self) -> &mut [A::Item] {\n        self\n    }\n\n    /// Remove the element at position `index`, replacing it with the last element.\n    ///\n    /// This does not preserve ordering, but is O(1).\n    ///\n    /// Panics if `index` is out of bounds.\n    #[inline]\n    pub fn swap_remove(&mut self, index: usize) -> A::Item {\n        let len = self.len();\n        self.swap(len - 1, index);\n        unsafe { self.pop().unchecked_unwrap() }\n    }\n\n    /// Remove all elements from the vector.\n    #[inline]\n    pub fn clear(&mut self) {\n        self.truncate(0);\n    }\n\n    /// Remove and return the element at position `index`, shifting all elements after it to the\n    /// left.\n    ///\n    /// Panics if `index` is out of bounds.\n    pub fn remove(&mut self, index: usize) -> A::Item {\n        unsafe {\n            let (mut ptr, len_ptr, _) = self.triple_mut();\n            let len = *len_ptr;\n            assert!(index < len);\n            *len_ptr = len - 1;\n            ptr = ptr.offset(index as isize);\n            let item = ptr::read(ptr);\n            ptr::copy(ptr.offset(1), ptr, len - index - 1);\n            item\n        }\n    }\n\n    /// Insert an element at position `index`, shifting all elements after it to the right.\n    ///\n    /// Panics if `index` is out of bounds.\n    pub fn insert(&mut self, index: usize, element: A::Item) {\n        self.reserve(1);\n\n        unsafe {\n            let (mut ptr, len_ptr, _) = self.triple_mut();\n            let len = *len_ptr;\n            assert!(index <= len);\n            *len_ptr = len + 1;\n            ptr = ptr.offset(index as isize);\n            ptr::copy(ptr, ptr.offset(1), len - index);\n            ptr::write(ptr, element);\n        }\n    }\n\n    /// Insert multiple elements at position `index`, shifting all following elements toward the\n    /// back.\n    pub fn insert_many<I: IntoIterator<Item=A::Item>>(&mut self, index: usize, iterable: I) {\n        let iter = iterable.into_iter();\n        if index == self.len() {\n            return self.extend(iter);\n        }\n\n        let (lower_size_bound, _) = iter.size_hint();\n        assert!(lower_size_bound <= std::isize::MAX as usize);  // Ensure offset is indexable\n        assert!(index + lower_size_bound >= index);  // Protect against overflow\n        self.reserve(lower_size_bound);\n\n        unsafe {\n            let old_len = self.len();\n            assert!(index <= old_len);\n            let mut ptr = self.as_mut_ptr().offset(index as isize);\n\n            // Move the trailing elements.\n            ptr::copy(ptr, ptr.offset(lower_size_bound as isize), old_len - index);\n\n            // In case the iterator panics, don't double-drop the items we just copied above.\n            self.set_len(index);\n\n            let mut num_added = 0;\n            for element in iter {\n                let mut cur = ptr.offset(num_added as isize);\n                if num_added >= lower_size_bound {\n                    // Iterator provided more elements than the hint.  Move trailing items again.\n                    self.reserve(1);\n                    ptr = self.as_mut_ptr().offset(index as isize);\n                    cur = ptr.offset(num_added as isize);\n                    ptr::copy(cur, cur.offset(1), old_len - index);\n                }\n                ptr::write(cur, element);\n                num_added += 1;\n            }\n            if num_added < lower_size_bound {\n                // Iterator provided fewer elements than the hint\n                ptr::copy(ptr.offset(lower_size_bound as isize), ptr.offset(num_added as isize), old_len - index);\n            }\n\n            self.set_len(old_len + num_added);\n        }\n    }\n\n    /// Convert a SmallVec to a Vec, without reallocating if the SmallVec has already spilled onto\n    /// the heap.\n    pub fn into_vec(self) -> Vec<A::Item> {\n        if self.spilled() {\n            unsafe {\n                let (ptr, len) = self.data.heap();\n                let v = Vec::from_raw_parts(ptr, len, self.capacity);\n                mem::forget(self);\n                v\n            }\n        } else {\n            self.into_iter().collect()\n        }\n    }\n\n    /// Retains only the elements specified by the predicate.\n    ///\n    /// In other words, remove all elements `e` such that `f(&e)` returns `false`.\n    /// This method operates in place and preserves the order of the retained\n    /// elements.\n    pub fn retain<F: FnMut(&mut A::Item) -> bool>(&mut self, mut f: F) {\n        let mut del = 0;\n        let len = self.len();\n        for i in 0..len {\n            if !f(&mut self[i]) {\n                del += 1;\n            } else if del > 0 {\n                self.swap(i - del, i);\n            }\n        }\n        self.truncate(len - del);\n    }\n\n    /// Removes consecutive duplicate elements.\n    pub fn dedup(&mut self) where A::Item: PartialEq<A::Item> {\n        self.dedup_by(|a, b| a == b);\n    }\n\n    /// Removes consecutive duplicate elements using the given equality relation.\n    pub fn dedup_by<F>(&mut self, mut same_bucket: F)\n        where F: FnMut(&mut A::Item, &mut A::Item) -> bool\n    {\n        // See the implementation of Vec::dedup_by in the\n        // standard library for an explanation of this algorithm.\n        let len = self.len();\n        if len <= 1 {\n            return;\n        }\n\n        let ptr = self.as_mut_ptr();\n        let mut w: usize = 1;\n\n        unsafe {\n            for r in 1..len {\n                let p_r = ptr.offset(r as isize);\n                let p_wm1 = ptr.offset((w - 1) as isize);\n                if !same_bucket(&mut *p_r, &mut *p_wm1) {\n                    if r != w {\n                        let p_w = p_wm1.offset(1);\n                        mem::swap(&mut *p_r, &mut *p_w);\n                    }\n                    w += 1;\n                }\n            }\n        }\n\n        self.truncate(w);\n    }\n\n    /// Removes consecutive elements that map to the same key.\n    pub fn dedup_by_key<F, K>(&mut self, mut key: F)\n        where F: FnMut(&mut A::Item) -> K,\n              K: PartialEq<K>\n    {\n        self.dedup_by(|a, b| key(a) == key(b));\n    }\n}\n\nimpl<A: Array> SmallVec<A> where A::Item: Copy {\n    /// Copy the elements from a slice into a new `SmallVec`.\n    ///\n    /// For slices of `Copy` types, this is more efficient than `SmallVec::from(slice)`.\n    pub fn from_slice(slice: &[A::Item]) -> Self {\n        let mut vec = Self::new();\n        vec.extend_from_slice(slice);\n        vec\n    }\n\n    /// Copy elements from a slice into the vector at position `index`, shifting any following\n    /// elements toward the back.\n    ///\n    /// For slices of `Copy` types, this is more efficient than `insert`.\n    pub fn insert_from_slice(&mut self, index: usize, slice: &[A::Item]) {\n        self.reserve(slice.len());\n\n        let len = self.len();\n        assert!(index <= len);\n\n        unsafe {\n            let slice_ptr = slice.as_ptr();\n            let ptr = self.as_mut_ptr().offset(index as isize);\n            ptr::copy(ptr, ptr.offset(slice.len() as isize), len - index);\n            ptr::copy_nonoverlapping(slice_ptr, ptr, slice.len());\n            self.set_len(len + slice.len());\n        }\n    }\n\n    /// Copy elements from a slice and append them to the vector.\n    ///\n    /// For slices of `Copy` types, this is more efficient than `extend`.\n    #[inline]\n    pub fn extend_from_slice(&mut self, slice: &[A::Item]) {\n        let len = self.len();\n        self.insert_from_slice(len, slice);\n    }\n}\n\nimpl<A: Array> SmallVec<A> where A::Item: Clone {\n    /// Resizes the vector so that its length is equal to `len`.\n    ///\n    /// If `len` is less than the current length, the vector simply truncated.\n    ///\n    /// If `len` is greater than the current length, `value` is appended to the\n    /// vector until its length equals `len`.\n    pub fn resize(&mut self, len: usize, value: A::Item) {\n        let old_len = self.len();\n\n        if len > old_len {\n            self.extend(repeat(value).take(len - old_len));\n        } else {\n            self.truncate(len);\n        }\n    }\n\n    /// Creates a `SmallVec` with `n` copies of `elem`.\n    /// ```\n    /// use smallvec::SmallVec;\n    ///\n    /// let v = SmallVec::<[char; 128]>::from_elem('d', 2);\n    /// assert_eq!(v, SmallVec::from_buf(['d', 'd']));\n    /// ```\n    pub fn from_elem(elem: A::Item, n: usize) -> Self {\n        if n > A::size() {\n            vec![elem; n].into()\n        } else {\n            unsafe {\n                let mut arr: A = ::std::mem::uninitialized();\n                let ptr = arr.ptr_mut();\n\n                for i in 0..n as isize {\n                    ::std::ptr::write(ptr.offset(i), elem.clone());\n                }\n\n                SmallVec {\n                    capacity: n,\n                    data: SmallVecData::from_inline(arr),\n                }\n            }\n        }\n    }\n}\n\nimpl<A: Array> ops::Deref for SmallVec<A> {\n    type Target = [A::Item];\n    #[inline]\n    fn deref(&self) -> &[A::Item] {\n        unsafe {\n            let (ptr, len, _) = self.triple();\n            slice::from_raw_parts(ptr, len)\n        }\n    }\n}\n\nimpl<A: Array> ops::DerefMut for SmallVec<A> {\n    #[inline]\n    fn deref_mut(&mut self) -> &mut [A::Item] {\n        unsafe {\n            let (ptr, &mut len, _) = self.triple_mut();\n            slice::from_raw_parts_mut(ptr, len)\n        }\n    }\n}\n\nimpl<A: Array> AsRef<[A::Item]> for SmallVec<A> {\n    #[inline]\n    fn as_ref(&self) -> &[A::Item] {\n        self\n    }\n}\n\nimpl<A: Array> AsMut<[A::Item]> for SmallVec<A> {\n    #[inline]\n    fn as_mut(&mut self) -> &mut [A::Item] {\n        self\n    }\n}\n\nimpl<A: Array> Borrow<[A::Item]> for SmallVec<A> {\n    #[inline]\n    fn borrow(&self) -> &[A::Item] {\n        self\n    }\n}\n\nimpl<A: Array> BorrowMut<[A::Item]> for SmallVec<A> {\n    #[inline]\n    fn borrow_mut(&mut self) -> &mut [A::Item] {\n        self\n    }\n}\n\n#[cfg(feature = \"std\")]\nimpl<A: Array<Item = u8>> io::Write for SmallVec<A> {\n    #[inline]\n    fn write(&mut self, buf: &[u8]) -> io::Result<usize> {\n        self.extend_from_slice(buf);\n        Ok(buf.len())\n    }\n\n    #[inline]\n    fn write_all(&mut self, buf: &[u8]) -> io::Result<()> {\n        self.extend_from_slice(buf);\n        Ok(())\n    }\n\n    #[inline]\n    fn flush(&mut self) -> io::Result<()> {\n        Ok(())\n    }\n}\n\n#[cfg(feature = \"serde\")]\nimpl<A: Array> Serialize for SmallVec<A> where A::Item: Serialize {\n    fn serialize<S: Serializer>(&self, serializer: S) -> Result<S::Ok, S::Error> {\n        let mut state = serializer.serialize_seq(Some(self.len()))?;\n        for item in self {\n            state.serialize_element(&item)?;\n        }\n        state.end()\n    }\n}\n\n#[cfg(feature = \"serde\")]\nimpl<'de, A: Array> Deserialize<'de> for SmallVec<A> where A::Item: Deserialize<'de> {\n    fn deserialize<D: Deserializer<'de>>(deserializer: D) -> Result<Self, D::Error> {\n        deserializer.deserialize_seq(SmallVecVisitor{phantom: PhantomData})\n    }\n}\n\n#[cfg(feature = \"serde\")]\nstruct SmallVecVisitor<A> {\n    phantom: PhantomData<A>\n}\n\n#[cfg(feature = \"serde\")]\nimpl<'de, A: Array> Visitor<'de> for SmallVecVisitor<A>\nwhere A::Item: Deserialize<'de>,\n{\n    type Value = SmallVec<A>;\n\n    fn expecting(&self, formatter: &mut fmt::Formatter) -> fmt::Result {\n        formatter.write_str(\"a sequence\")\n    }\n\n    fn visit_seq<B>(self, mut seq: B) -> Result<Self::Value, B::Error>\n        where\n            B: SeqAccess<'de>,\n    {\n        let len = seq.size_hint().unwrap_or(0);\n        let mut values = SmallVec::with_capacity(len);\n\n        while let Some(value) = seq.next_element()? {\n            values.push(value);\n        }\n\n        Ok(values)\n    }\n}\n\nimpl<'a, A: Array> From<&'a [A::Item]> for SmallVec<A> where A::Item: Clone {\n    #[inline]\n    fn from(slice: &'a [A::Item]) -> SmallVec<A> {\n        slice.into_iter().cloned().collect()\n    }\n}\n\nimpl<A: Array> From<Vec<A::Item>> for SmallVec<A> {\n    #[inline]\n    fn from(vec: Vec<A::Item>) -> SmallVec<A> {\n        SmallVec::from_vec(vec)\n    }\n}\n\nimpl<A: Array> From<A> for SmallVec<A> {\n    #[inline]\n    fn from(array: A) -> SmallVec<A> {\n        SmallVec::from_buf(array)\n    }\n}\n\nmacro_rules! impl_index {\n    ($index_type: ty, $output_type: ty) => {\n        impl<A: Array> ops::Index<$index_type> for SmallVec<A> {\n            type Output = $output_type;\n            #[inline]\n            fn index(&self, index: $index_type) -> &$output_type {\n                &(&**self)[index]\n            }\n        }\n\n        impl<A: Array> ops::IndexMut<$index_type> for SmallVec<A> {\n            #[inline]\n            fn index_mut(&mut self, index: $index_type) -> &mut $output_type {\n                &mut (&mut **self)[index]\n            }\n        }\n    }\n}\n\nimpl_index!(usize, A::Item);\nimpl_index!(ops::Range<usize>, [A::Item]);\nimpl_index!(ops::RangeFrom<usize>, [A::Item]);\nimpl_index!(ops::RangeTo<usize>, [A::Item]);\nimpl_index!(ops::RangeFull, [A::Item]);\n\nimpl<A: Array> ExtendFromSlice<A::Item> for SmallVec<A> where A::Item: Copy {\n    fn extend_from_slice(&mut self, other: &[A::Item]) {\n        SmallVec::extend_from_slice(self, other)\n    }\n}\n\n#[allow(deprecated)]\nimpl<A: Array> VecLike<A::Item> for SmallVec<A> {\n    #[inline]\n    fn push(&mut self, value: A::Item) {\n        SmallVec::push(self, value);\n    }\n}\n\nimpl<A: Array> FromIterator<A::Item> for SmallVec<A> {\n    fn from_iter<I: IntoIterator<Item=A::Item>>(iterable: I) -> SmallVec<A> {\n        let mut v = SmallVec::new();\n        v.extend(iterable);\n        v\n    }\n}\n\nimpl<A: Array> Extend<A::Item> for SmallVec<A> {\n    fn extend<I: IntoIterator<Item=A::Item>>(&mut self, iterable: I) {\n        let mut iter = iterable.into_iter();\n        let (lower_size_bound, _) = iter.size_hint();\n        self.reserve(lower_size_bound);\n\n        unsafe {\n            let len = self.len();\n            let ptr = self.as_mut_ptr().offset(len as isize);\n            let mut count = 0;\n            while count < lower_size_bound {\n                if let Some(out) = iter.next() {\n                    ptr::write(ptr.offset(count as isize), out);\n                    count += 1;\n                } else {\n                    break;\n                }\n            }\n            self.set_len(len + count);\n        }\n\n        for elem in iter {\n            self.push(elem);\n        }\n    }\n}\n\nimpl<A: Array> fmt::Debug for SmallVec<A> where A::Item: fmt::Debug {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        write!(f, \"{:?}\", &**self)\n    }\n}\n\nimpl<A: Array> Default for SmallVec<A> {\n    #[inline]\n    fn default() -> SmallVec<A> {\n        SmallVec::new()\n    }\n}\n\nimpl<A: Array> Drop for SmallVec<A> {\n    fn drop(&mut self) {\n        unsafe {\n            if self.spilled() {\n                let (ptr, len) = self.data.heap();\n                Vec::from_raw_parts(ptr, len, self.capacity);\n            } else {\n                ptr::drop_in_place(&mut self[..]);\n            }\n        }\n    }\n}\n\nimpl<A: Array> Clone for SmallVec<A> where A::Item: Clone {\n    fn clone(&self) -> SmallVec<A> {\n        let mut new_vector = SmallVec::with_capacity(self.len());\n        for element in self.iter() {\n            new_vector.push((*element).clone())\n        }\n        new_vector\n    }\n}\n\nimpl<A: Array, B: Array> PartialEq<SmallVec<B>> for SmallVec<A>\n    where A::Item: PartialEq<B::Item> {\n    #[inline]\n    fn eq(&self, other: &SmallVec<B>) -> bool { self[..] == other[..] }\n    #[inline]\n    fn ne(&self, other: &SmallVec<B>) -> bool { self[..] != other[..] }\n}\n\nimpl<A: Array> Eq for SmallVec<A> where A::Item: Eq {}\n\nimpl<A: Array> PartialOrd for SmallVec<A> where A::Item: PartialOrd {\n    #[inline]\n    fn partial_cmp(&self, other: &SmallVec<A>) -> Option<cmp::Ordering> {\n        PartialOrd::partial_cmp(&**self, &**other)\n    }\n}\n\nimpl<A: Array> Ord for SmallVec<A> where A::Item: Ord {\n    #[inline]\n    fn cmp(&self, other: &SmallVec<A>) -> cmp::Ordering {\n        Ord::cmp(&**self, &**other)\n    }\n}\n\nimpl<A: Array> Hash for SmallVec<A> where A::Item: Hash {\n    fn hash<H: Hasher>(&self, state: &mut H) {\n        (**self).hash(state)\n    }\n}\n\nunsafe impl<A: Array> Send for SmallVec<A> where A::Item: Send {}\n\n/// An iterator that consumes a `SmallVec` and yields its items by value.\n///\n/// Returned from [`SmallVec::into_iter`][1].\n///\n/// [1]: struct.SmallVec.html#method.into_iter\npub struct IntoIter<A: Array> {\n    data: SmallVec<A>,\n    current: usize,\n    end: usize,\n}\n\nimpl<A: Array> Drop for IntoIter<A> {\n    fn drop(&mut self) {\n        for _ in self { }\n    }\n}\n\nimpl<A: Array> Iterator for IntoIter<A> {\n    type Item = A::Item;\n\n    #[inline]\n    fn next(&mut self) -> Option<A::Item> {\n        if self.current == self.end {\n            None\n        }\n        else {\n            unsafe {\n                let current = self.current as isize;\n                self.current += 1;\n                Some(ptr::read(self.data.as_ptr().offset(current)))\n            }\n        }\n    }\n\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        let size = self.end - self.current;\n        (size, Some(size))\n    }\n}\n\nimpl<A: Array> DoubleEndedIterator for IntoIter<A> {\n    #[inline]\n    fn next_back(&mut self) -> Option<A::Item> {\n        if self.current == self.end {\n            None\n        }\n        else {\n            unsafe {\n                self.end -= 1;\n                Some(ptr::read(self.data.as_ptr().offset(self.end as isize)))\n            }\n        }\n    }\n}\n\nimpl<A: Array> ExactSizeIterator for IntoIter<A> { }\n\nimpl<A: Array> IntoIterator for SmallVec<A> {\n    type IntoIter = IntoIter<A>;\n    type Item = A::Item;\n    fn into_iter(mut self) -> Self::IntoIter {\n        unsafe {\n            // Set SmallVec len to zero as `IntoIter` drop handles dropping of the elements\n            let len = self.len();\n            self.set_len(0);\n            IntoIter {\n                data: self,\n                current: 0,\n                end: len,\n            }\n        }\n    }\n}\n\nimpl<'a, A: Array> IntoIterator for &'a SmallVec<A> {\n    type IntoIter = slice::Iter<'a, A::Item>;\n    type Item = &'a A::Item;\n    fn into_iter(self) -> Self::IntoIter {\n        self.iter()\n    }\n}\n\nimpl<'a, A: Array> IntoIterator for &'a mut SmallVec<A> {\n    type IntoIter = slice::IterMut<'a, A::Item>;\n    type Item = &'a mut A::Item;\n    fn into_iter(self) -> Self::IntoIter {\n        self.iter_mut()\n    }\n}\n\n/// Types that can be used as the backing store for a SmallVec\npub unsafe trait Array {\n    /// The type of the array's elements.\n    type Item;\n    /// Returns the number of items the array can hold.\n    fn size() -> usize;\n    /// Returns a pointer to the first element of the array.\n    fn ptr(&self) -> *const Self::Item;\n    /// Returns a mutable pointer to the first element of the array.\n    fn ptr_mut(&mut self) -> *mut Self::Item;\n}\n\nmacro_rules! impl_array(\n    ($($size:expr),+) => {\n        $(\n            unsafe impl<T> Array for [T; $size] {\n                type Item = T;\n                fn size() -> usize { $size }\n                fn ptr(&self) -> *const T { self.as_ptr() }\n                fn ptr_mut(&mut self) -> *mut T { self.as_mut_ptr() }\n            }\n        )+\n    }\n);\n\nimpl_array!(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 20, 24, 32, 36,\n            0x40, 0x80, 0x100, 0x200, 0x400, 0x800, 0x1000, 0x2000, 0x4000, 0x8000,\n            0x10000, 0x20000, 0x40000, 0x80000, 0x100000);\n\n#[cfg(test)]\nmod tests {\n    use SmallVec;\n\n    use std::iter::FromIterator;\n\n    #[cfg(feature = \"std\")]\n    use std::borrow::ToOwned;\n    #[cfg(not(feature = \"std\"))]\n    use alloc::borrow::ToOwned;\n    #[cfg(feature = \"std\")]\n    use std::rc::Rc;\n    #[cfg(not(feature = \"std\"))]\n    use alloc::rc::Rc;\n    #[cfg(not(feature = \"std\"))]\n    use alloc::boxed::Box;\n    #[cfg(not(feature = \"std\"))]\n    use alloc::vec::Vec;\n\n    #[test]\n    pub fn test_zero() {\n        let mut v = SmallVec::<[_; 0]>::new();\n        assert!(!v.spilled());\n        v.push(0usize);\n        assert!(v.spilled());\n        assert_eq!(&*v, &[0]);\n    }\n\n    // We heap allocate all these strings so that double frees will show up under valgrind.\n\n    #[test]\n    pub fn test_inline() {\n        let mut v = SmallVec::<[_; 16]>::new();\n        v.push(\"hello\".to_owned());\n        v.push(\"there\".to_owned());\n        assert_eq!(&*v, &[\n            \"hello\".to_owned(),\n            \"there\".to_owned(),\n        ][..]);\n    }\n\n    #[test]\n    pub fn test_spill() {\n        let mut v = SmallVec::<[_; 2]>::new();\n        v.push(\"hello\".to_owned());\n        assert_eq!(v[0], \"hello\");\n        v.push(\"there\".to_owned());\n        v.push(\"burma\".to_owned());\n        assert_eq!(v[0], \"hello\");\n        v.push(\"shave\".to_owned());\n        assert_eq!(&*v, &[\n            \"hello\".to_owned(),\n            \"there\".to_owned(),\n            \"burma\".to_owned(),\n            \"shave\".to_owned(),\n        ][..]);\n    }\n\n    #[test]\n    pub fn test_double_spill() {\n        let mut v = SmallVec::<[_; 2]>::new();\n        v.push(\"hello\".to_owned());\n        v.push(\"there\".to_owned());\n        v.push(\"burma\".to_owned());\n        v.push(\"shave\".to_owned());\n        v.push(\"hello\".to_owned());\n        v.push(\"there\".to_owned());\n        v.push(\"burma\".to_owned());\n        v.push(\"shave\".to_owned());\n        assert_eq!(&*v, &[\n            \"hello\".to_owned(),\n            \"there\".to_owned(),\n            \"burma\".to_owned(),\n            \"shave\".to_owned(),\n            \"hello\".to_owned(),\n            \"there\".to_owned(),\n            \"burma\".to_owned(),\n            \"shave\".to_owned(),\n        ][..]);\n    }\n\n    /// https://github.com/servo/rust-smallvec/issues/4\n    #[test]\n    fn issue_4() {\n        SmallVec::<[Box<u32>; 2]>::new();\n    }\n\n    /// https://github.com/servo/rust-smallvec/issues/5\n    #[test]\n    fn issue_5() {\n        assert!(Some(SmallVec::<[&u32; 2]>::new()).is_some());\n    }\n\n    #[test]\n    fn test_with_capacity() {\n        let v: SmallVec<[u8; 3]> = SmallVec::with_capacity(1);\n        assert!(v.is_empty());\n        assert!(!v.spilled());\n        assert_eq!(v.capacity(), 3);\n\n        let v: SmallVec<[u8; 3]> = SmallVec::with_capacity(10);\n        assert!(v.is_empty());\n        assert!(v.spilled());\n        assert_eq!(v.capacity(), 10);\n    }\n\n    #[test]\n    fn drain() {\n        let mut v: SmallVec<[u8; 2]> = SmallVec::new();\n        v.push(3);\n        assert_eq!(v.drain().collect::<Vec<_>>(), &[3]);\n\n        // spilling the vec\n        v.push(3);\n        v.push(4);\n        v.push(5);\n        assert_eq!(v.drain().collect::<Vec<_>>(), &[3, 4, 5]);\n    }\n\n    #[test]\n    fn drain_rev() {\n        let mut v: SmallVec<[u8; 2]> = SmallVec::new();\n        v.push(3);\n        assert_eq!(v.drain().rev().collect::<Vec<_>>(), &[3]);\n\n        // spilling the vec\n        v.push(3);\n        v.push(4);\n        v.push(5);\n        assert_eq!(v.drain().rev().collect::<Vec<_>>(), &[5, 4, 3]);\n    }\n\n    #[test]\n    fn into_iter() {\n        let mut v: SmallVec<[u8; 2]> = SmallVec::new();\n        v.push(3);\n        assert_eq!(v.into_iter().collect::<Vec<_>>(), &[3]);\n\n        // spilling the vec\n        let mut v: SmallVec<[u8; 2]> = SmallVec::new();\n        v.push(3);\n        v.push(4);\n        v.push(5);\n        assert_eq!(v.into_iter().collect::<Vec<_>>(), &[3, 4, 5]);\n    }\n\n    #[test]\n    fn into_iter_rev() {\n        let mut v: SmallVec<[u8; 2]> = SmallVec::new();\n        v.push(3);\n        assert_eq!(v.into_iter().rev().collect::<Vec<_>>(), &[3]);\n\n        // spilling the vec\n        let mut v: SmallVec<[u8; 2]> = SmallVec::new();\n        v.push(3);\n        v.push(4);\n        v.push(5);\n        assert_eq!(v.into_iter().rev().collect::<Vec<_>>(), &[5, 4, 3]);\n    }\n\n    #[test]\n    fn into_iter_drop() {\n        use std::cell::Cell;\n\n        struct DropCounter<'a>(&'a Cell<i32>);\n\n        impl<'a> Drop for DropCounter<'a> {\n            fn drop(&mut self) {\n                self.0.set(self.0.get() + 1);\n            }\n        }\n\n        {\n            let cell = Cell::new(0);\n            let mut v: SmallVec<[DropCounter; 2]> = SmallVec::new();\n            v.push(DropCounter(&cell));\n            v.into_iter();\n            assert_eq!(cell.get(), 1);\n        }\n\n        {\n            let cell = Cell::new(0);\n            let mut v: SmallVec<[DropCounter; 2]> = SmallVec::new();\n            v.push(DropCounter(&cell));\n            v.push(DropCounter(&cell));\n            assert!(v.into_iter().next().is_some());\n            assert_eq!(cell.get(), 2);\n        }\n\n        {\n            let cell = Cell::new(0);\n            let mut v: SmallVec<[DropCounter; 2]> = SmallVec::new();\n            v.push(DropCounter(&cell));\n            v.push(DropCounter(&cell));\n            v.push(DropCounter(&cell));\n            assert!(v.into_iter().next().is_some());\n            assert_eq!(cell.get(), 3);\n        }\n        {\n            let cell = Cell::new(0);\n            let mut v: SmallVec<[DropCounter; 2]> = SmallVec::new();\n            v.push(DropCounter(&cell));\n            v.push(DropCounter(&cell));\n            v.push(DropCounter(&cell));\n            {\n                let mut it = v.into_iter();\n                assert!(it.next().is_some());\n                assert!(it.next_back().is_some());\n            }\n            assert_eq!(cell.get(), 3);\n        }\n    }\n\n    #[test]\n    fn test_capacity() {\n        let mut v: SmallVec<[u8; 2]> = SmallVec::new();\n        v.reserve(1);\n        assert_eq!(v.capacity(), 2);\n        assert!(!v.spilled());\n\n        v.reserve_exact(0x100);\n        assert!(v.capacity() >= 0x100);\n\n        v.push(0);\n        v.push(1);\n        v.push(2);\n        v.push(3);\n\n        v.shrink_to_fit();\n        assert!(v.capacity() < 0x100);\n    }\n\n    #[test]\n    fn test_truncate() {\n        let mut v: SmallVec<[Box<u8>; 8]> = SmallVec::new();\n\n        for x in 0..8 {\n            v.push(Box::new(x));\n        }\n        v.truncate(4);\n\n        assert_eq!(v.len(), 4);\n        assert!(!v.spilled());\n\n        assert_eq!(*v.swap_remove(1), 1);\n        assert_eq!(*v.remove(1), 3);\n        v.insert(1, Box::new(3));\n\n        assert_eq!(&v.iter().map(|v| **v).collect::<Vec<_>>(), &[0, 3, 2]);\n    }\n\n    #[test]\n    fn test_insert_many() {\n        let mut v: SmallVec<[u8; 8]> = SmallVec::new();\n        for x in 0..4 {\n            v.push(x);\n        }\n        assert_eq!(v.len(), 4);\n        v.insert_many(1, [5, 6].iter().cloned());\n        assert_eq!(&v.iter().map(|v| *v).collect::<Vec<_>>(), &[0, 5, 6, 1, 2, 3]);\n    }\n\n    struct MockHintIter<T: Iterator>{x: T, hint: usize}\n    impl<T: Iterator> Iterator for MockHintIter<T> {\n        type Item = T::Item;\n        fn next(&mut self) -> Option<Self::Item> {self.x.next()}\n        fn size_hint(&self) -> (usize, Option<usize>) {(self.hint, None)}\n    }\n\n    #[test]\n    fn test_insert_many_short_hint() {\n        let mut v: SmallVec<[u8; 8]> = SmallVec::new();\n        for x in 0..4 {\n            v.push(x);\n        }\n        assert_eq!(v.len(), 4);\n        v.insert_many(1, MockHintIter{x: [5, 6].iter().cloned(), hint: 5});\n        assert_eq!(&v.iter().map(|v| *v).collect::<Vec<_>>(), &[0, 5, 6, 1, 2, 3]);\n    }\n\n    #[test]\n    fn test_insert_many_long_hint() {\n        let mut v: SmallVec<[u8; 8]> = SmallVec::new();\n        for x in 0..4 {\n            v.push(x);\n        }\n        assert_eq!(v.len(), 4);\n        v.insert_many(1, MockHintIter{x: [5, 6].iter().cloned(), hint: 1});\n        assert_eq!(&v.iter().map(|v| *v).collect::<Vec<_>>(), &[0, 5, 6, 1, 2, 3]);\n    }\n\n    #[test]\n    // https://github.com/servo/rust-smallvec/issues/96\n    fn test_insert_many_panic() {\n        struct PanicOnDoubleDrop {\n            dropped: Box<bool>\n        }\n\n        impl Drop for PanicOnDoubleDrop {\n            fn drop(&mut self) {\n                assert!(!*self.dropped, \"already dropped\");\n                *self.dropped = true;\n            }\n        }\n\n        struct BadIter;\n        impl Iterator for BadIter {\n            type Item = PanicOnDoubleDrop;\n            fn size_hint(&self) -> (usize, Option<usize>) { (1, None) }\n            fn next(&mut self) -> Option<Self::Item> { panic!() }\n        }\n\n        let mut vec: SmallVec<[PanicOnDoubleDrop; 0]> = vec![\n            PanicOnDoubleDrop { dropped: Box::new(false) },\n            PanicOnDoubleDrop { dropped: Box::new(false) },\n        ].into();\n        let result = ::std::panic::catch_unwind(move || {\n            vec.insert_many(0, BadIter);\n        });\n        assert!(result.is_err());\n    }\n\n    #[test]\n    #[should_panic]\n    fn test_invalid_grow() {\n        let mut v: SmallVec<[u8; 8]> = SmallVec::new();\n        v.extend(0..8);\n        v.grow(5);\n    }\n\n    #[test]\n    fn test_insert_from_slice() {\n        let mut v: SmallVec<[u8; 8]> = SmallVec::new();\n        for x in 0..4 {\n            v.push(x);\n        }\n        assert_eq!(v.len(), 4);\n        v.insert_from_slice(1, &[5, 6]);\n        assert_eq!(&v.iter().map(|v| *v).collect::<Vec<_>>(), &[0, 5, 6, 1, 2, 3]);\n    }\n\n    #[test]\n    fn test_extend_from_slice() {\n        let mut v: SmallVec<[u8; 8]> = SmallVec::new();\n        for x in 0..4 {\n            v.push(x);\n        }\n        assert_eq!(v.len(), 4);\n        v.extend_from_slice(&[5, 6]);\n        assert_eq!(&v.iter().map(|v| *v).collect::<Vec<_>>(), &[0, 1, 2, 3, 5, 6]);\n    }\n\n    #[test]\n    #[should_panic]\n    fn test_drop_panic_smallvec() {\n        // This test should only panic once, and not double panic,\n        // which would mean a double drop\n        struct DropPanic;\n\n        impl Drop for DropPanic {\n            fn drop(&mut self) {\n                panic!(\"drop\");\n            }\n        }\n\n        let mut v = SmallVec::<[_; 1]>::new();\n        v.push(DropPanic);\n    }\n\n    #[test]\n    fn test_eq() {\n        let mut a: SmallVec<[u32; 2]> = SmallVec::new();\n        let mut b: SmallVec<[u32; 2]> = SmallVec::new();\n        let mut c: SmallVec<[u32; 2]> = SmallVec::new();\n        // a = [1, 2]\n        a.push(1);\n        a.push(2);\n        // b = [1, 2]\n        b.push(1);\n        b.push(2);\n        // c = [3, 4]\n        c.push(3);\n        c.push(4);\n\n        assert!(a == b);\n        assert!(a != c);\n    }\n\n    #[test]\n    fn test_ord() {\n        let mut a: SmallVec<[u32; 2]> = SmallVec::new();\n        let mut b: SmallVec<[u32; 2]> = SmallVec::new();\n        let mut c: SmallVec<[u32; 2]> = SmallVec::new();\n        // a = [1]\n        a.push(1);\n        // b = [1, 1]\n        b.push(1);\n        b.push(1);\n        // c = [1, 2]\n        c.push(1);\n        c.push(2);\n\n        assert!(a < b);\n        assert!(b > a);\n        assert!(b < c);\n        assert!(c > b);\n    }\n\n    #[cfg(feature = \"std\")]\n    #[test]\n    fn test_hash() {\n        use std::hash::Hash;\n        use std::collections::hash_map::DefaultHasher;\n\n        {\n            let mut a: SmallVec<[u32; 2]> = SmallVec::new();\n            let b = [1, 2];\n            a.extend(b.iter().cloned());\n            let mut hasher = DefaultHasher::new();\n            assert_eq!(a.hash(&mut hasher), b.hash(&mut hasher));\n        }\n        {\n            let mut a: SmallVec<[u32; 2]> = SmallVec::new();\n            let b = [1, 2, 11, 12];\n            a.extend(b.iter().cloned());\n            let mut hasher = DefaultHasher::new();\n            assert_eq!(a.hash(&mut hasher), b.hash(&mut hasher));\n        }\n    }\n\n    #[test]\n    fn test_as_ref() {\n        let mut a: SmallVec<[u32; 2]> = SmallVec::new();\n        a.push(1);\n        assert_eq!(a.as_ref(), [1]);\n        a.push(2);\n        assert_eq!(a.as_ref(), [1, 2]);\n        a.push(3);\n        assert_eq!(a.as_ref(), [1, 2, 3]);\n    }\n\n    #[test]\n    fn test_as_mut() {\n        let mut a: SmallVec<[u32; 2]> = SmallVec::new();\n        a.push(1);\n        assert_eq!(a.as_mut(), [1]);\n        a.push(2);\n        assert_eq!(a.as_mut(), [1, 2]);\n        a.push(3);\n        assert_eq!(a.as_mut(), [1, 2, 3]);\n        a.as_mut()[1] = 4;\n        assert_eq!(a.as_mut(), [1, 4, 3]);\n    }\n\n    #[test]\n    fn test_borrow() {\n        use std::borrow::Borrow;\n\n        let mut a: SmallVec<[u32; 2]> = SmallVec::new();\n        a.push(1);\n        assert_eq!(a.borrow(), [1]);\n        a.push(2);\n        assert_eq!(a.borrow(), [1, 2]);\n        a.push(3);\n        assert_eq!(a.borrow(), [1, 2, 3]);\n    }\n\n    #[test]\n    fn test_borrow_mut() {\n        use std::borrow::BorrowMut;\n\n        let mut a: SmallVec<[u32; 2]> = SmallVec::new();\n        a.push(1);\n        assert_eq!(a.borrow_mut(), [1]);\n        a.push(2);\n        assert_eq!(a.borrow_mut(), [1, 2]);\n        a.push(3);\n        assert_eq!(a.borrow_mut(), [1, 2, 3]);\n        BorrowMut::<[u32]>::borrow_mut(&mut a)[1] = 4;\n        assert_eq!(a.borrow_mut(), [1, 4, 3]);\n    }\n\n    #[test]\n    fn test_from() {\n        assert_eq!(&SmallVec::<[u32; 2]>::from(&[1][..])[..], [1]);\n        assert_eq!(&SmallVec::<[u32; 2]>::from(&[1, 2, 3][..])[..], [1, 2, 3]);\n\n        let vec = vec![];\n        let small_vec: SmallVec<[u8; 3]> = SmallVec::from(vec);\n        assert_eq!(&*small_vec, &[]);\n        drop(small_vec);\n\n        let vec = vec![1, 2, 3, 4, 5];\n        let small_vec: SmallVec<[u8; 3]> = SmallVec::from(vec);\n        assert_eq!(&*small_vec, &[1, 2, 3, 4, 5]);\n        drop(small_vec);\n\n        let vec = vec![1, 2, 3, 4, 5];\n        let small_vec: SmallVec<[u8; 1]> = SmallVec::from(vec);\n        assert_eq!(&*small_vec, &[1, 2, 3, 4, 5]);\n        drop(small_vec);\n\n        let array = [1];\n        let small_vec: SmallVec<[u8; 1]> = SmallVec::from(array);\n        assert_eq!(&*small_vec, &[1]);\n        drop(small_vec);\n\n        let array = [99; 128];\n        let small_vec: SmallVec<[u8; 128]> = SmallVec::from(array);\n        assert_eq!(&*small_vec, vec![99u8; 128].as_slice());\n        drop(small_vec);\n    }\n\n    #[test]\n    fn test_from_slice() {\n        assert_eq!(&SmallVec::<[u32; 2]>::from_slice(&[1][..])[..], [1]);\n        assert_eq!(&SmallVec::<[u32; 2]>::from_slice(&[1, 2, 3][..])[..], [1, 2, 3]);\n    }\n\n    #[test]\n    fn test_exact_size_iterator() {\n        let mut vec = SmallVec::<[u32; 2]>::from(&[1, 2, 3][..]);\n        assert_eq!(vec.clone().into_iter().len(), 3);\n        assert_eq!(vec.drain().len(), 3);\n    }\n\n    #[test]\n    #[allow(deprecated)]\n    fn veclike_deref_slice() {\n        use super::VecLike;\n\n        fn test<T: VecLike<i32>>(vec: &mut T) {\n            assert!(!vec.is_empty());\n            assert_eq!(vec.len(), 3);\n\n            vec.sort();\n            assert_eq!(&vec[..], [1, 2, 3]);\n        }\n\n        let mut vec = SmallVec::<[i32; 2]>::from(&[3, 1, 2][..]);\n        test(&mut vec);\n    }\n\n    #[test]\n    fn shrink_to_fit_unspill() {\n        let mut vec = SmallVec::<[u8; 2]>::from_iter(0..3);\n        vec.pop();\n        assert!(vec.spilled());\n        vec.shrink_to_fit();\n        assert!(!vec.spilled(), \"shrink_to_fit will un-spill if possible\");\n    }\n\n    #[test]\n    fn test_into_vec() {\n        let vec = SmallVec::<[u8; 2]>::from_iter(0..2);\n        assert_eq!(vec.into_vec(), vec![0, 1]);\n\n        let vec = SmallVec::<[u8; 2]>::from_iter(0..3);\n        assert_eq!(vec.into_vec(), vec![0, 1, 2]);\n    }\n\n    #[test]\n    fn test_from_vec() {\n        let vec = vec![];\n        let small_vec: SmallVec<[u8; 3]> = SmallVec::from_vec(vec);\n        assert_eq!(&*small_vec, &[]);\n        drop(small_vec);\n\n        let vec = vec![];\n        let small_vec: SmallVec<[u8; 1]> = SmallVec::from_vec(vec);\n        assert_eq!(&*small_vec, &[]);\n        drop(small_vec);\n\n        let vec = vec![1];\n        let small_vec: SmallVec<[u8; 3]> = SmallVec::from_vec(vec);\n        assert_eq!(&*small_vec, &[1]);\n        drop(small_vec);\n\n        let vec = vec![1, 2, 3];\n        let small_vec: SmallVec<[u8; 3]> = SmallVec::from_vec(vec);\n        assert_eq!(&*small_vec, &[1, 2, 3]);\n        drop(small_vec);\n\n        let vec = vec![1, 2, 3, 4, 5];\n        let small_vec: SmallVec<[u8; 3]> = SmallVec::from_vec(vec);\n        assert_eq!(&*small_vec, &[1, 2, 3, 4, 5]);\n        drop(small_vec);\n\n        let vec = vec![1, 2, 3, 4, 5];\n        let small_vec: SmallVec<[u8; 1]> = SmallVec::from_vec(vec);\n        assert_eq!(&*small_vec, &[1, 2, 3, 4, 5]);\n        drop(small_vec);\n    }\n\n    #[test]\n    fn test_retain() {\n        // Test inline data storate\n        let mut sv: SmallVec<[i32; 5]> = SmallVec::from_slice(&[1, 2, 3, 3, 4]);\n        sv.retain(|&mut i| i != 3);\n        assert_eq!(sv.pop(), Some(4));\n        assert_eq!(sv.pop(), Some(2));\n        assert_eq!(sv.pop(), Some(1));\n        assert_eq!(sv.pop(), None);\n\n        // Test spilled data storage\n        let mut sv: SmallVec<[i32; 3]> = SmallVec::from_slice(&[1, 2, 3, 3, 4]);\n        sv.retain(|&mut i| i != 3);\n        assert_eq!(sv.pop(), Some(4));\n        assert_eq!(sv.pop(), Some(2));\n        assert_eq!(sv.pop(), Some(1));\n        assert_eq!(sv.pop(), None);\n\n        // Test that drop implementations are called for inline.\n        let one = Rc::new(1);\n        let mut sv: SmallVec<[Rc<i32>; 3]> = SmallVec::new();\n        sv.push(Rc::clone(&one));\n        assert_eq!(Rc::strong_count(&one), 2);\n        sv.retain(|_| false);\n        assert_eq!(Rc::strong_count(&one), 1);\n\n        // Test that drop implementations are called for spilled data.\n        let mut sv: SmallVec<[Rc<i32>; 1]> = SmallVec::new();\n        sv.push(Rc::clone(&one));\n        sv.push(Rc::new(2));\n        assert_eq!(Rc::strong_count(&one), 2);\n        sv.retain(|_| false);\n        assert_eq!(Rc::strong_count(&one), 1);\n    }\n\n    #[test]\n    fn test_dedup() {\n        let mut dupes: SmallVec<[i32; 5]> = SmallVec::from_slice(&[1, 1, 2, 3, 3]);\n        dupes.dedup();\n        assert_eq!(&*dupes, &[1, 2, 3]);\n\n        let mut empty: SmallVec<[i32; 5]> = SmallVec::new();\n        empty.dedup();\n        assert!(empty.is_empty());\n\n        let mut all_ones: SmallVec<[i32; 5]> = SmallVec::from_slice(&[1, 1, 1, 1, 1]);\n        all_ones.dedup();\n        assert_eq!(all_ones.len(), 1);\n\n        let mut no_dupes: SmallVec<[i32; 5]> = SmallVec::from_slice(&[1, 2, 3, 4, 5]);\n        no_dupes.dedup();\n        assert_eq!(no_dupes.len(), 5);\n    }\n\n    #[test]\n    fn test_resize() {\n        let mut v: SmallVec<[i32; 8]> = SmallVec::new();\n        v.push(1);\n        v.resize(5, 0);\n        assert_eq!(v[..], [1, 0, 0, 0, 0][..]);\n\n        v.resize(2, -1);\n        assert_eq!(v[..], [1, 0][..]);\n    }\n\n    #[cfg(feature = \"std\")]\n    #[test]\n    fn test_write() {\n        use io::Write;\n\n        let data = [1, 2, 3, 4, 5];\n\n        let mut small_vec: SmallVec<[u8; 2]> = SmallVec::new();\n        let len = small_vec.write(&data[..]).unwrap();\n        assert_eq!(len, 5);\n        assert_eq!(small_vec.as_ref(), data.as_ref());\n\n        let mut small_vec: SmallVec<[u8; 2]> = SmallVec::new();\n        small_vec.write_all(&data[..]).unwrap();\n        assert_eq!(small_vec.as_ref(), data.as_ref());\n    }\n\n    #[cfg(feature = \"serde\")]\n    extern crate bincode;\n\n    #[cfg(feature = \"serde\")]\n    #[test]\n    fn test_serde() {\n        use self::bincode::{serialize, deserialize, Bounded};\n        let mut small_vec: SmallVec<[i32; 2]> = SmallVec::new();\n        small_vec.push(1);\n        let encoded = serialize(&small_vec, Bounded(100)).unwrap();\n        let decoded: SmallVec<[i32; 2]> = deserialize(&encoded).unwrap();\n        assert_eq!(small_vec, decoded);\n        small_vec.push(2);\n        // Spill the vec\n        small_vec.push(3);\n        small_vec.push(4);\n        // Check again after spilling.\n        let encoded = serialize(&small_vec, Bounded(100)).unwrap();\n        let decoded: SmallVec<[i32; 2]> = deserialize(&encoded).unwrap();\n        assert_eq!(small_vec, decoded);\n    }\n}\n"
  },
  {
    "project": "qcell",
    "target": 1,
    "commit_id": "b1f4e6d166b6c5cc693bfbfe5856db4b098dbd83",
    "func": "use std::cell::{Cell, UnsafeCell};\nuse std::marker::PhantomData;\n\ntype Id<'id> = PhantomData<Cell<&'id mut ()>>;\n\n/// Borrowing-owner of zero or more [`LCell`](struct.LCell.html)\n/// instances.\n///\n/// Use `LCellOwner::scope(|owner| ...)` to create an instance of this\n/// type.\n///\n/// The key piece of Rust syntax that enables this is `for<'id>`.\n/// This allows creating an invariant lifetime within a closure, which\n/// is different to any other Rust lifetime thanks to the techniques\n/// explained in various places: section 6.3 of [this thesis from\n/// Gankro](https://raw.githubusercontent.com/Gankro/thesis/master/thesis.pdf),\n/// [this Reddit\n/// post](https://www.reddit.com/r/rust/comments/3oo0oe/sound_unchecked_indexing_with_lifetimebased_value/),\n/// and [this Rust playground\n/// example](https://play.rust-lang.org/?gist=21a00b0e181a918f8ca4&version=stable).\n/// Also see [this Reddit\n/// comment](https://www.reddit.com/r/rust/comments/3aahl1/outside_of_closures_what_are_some_other_uses_for/csavac5/)\n/// and its linked playground code.\n///\n/// `LCellOwner` uses a closure to contain the invariant lifetime.\n/// However it's also worth noting the alternative approach used in\n/// crate [`generativity`](https://crates.io/crates/generativity) that\n/// uses a macro instead.\n///\n/// Some history: `GhostCell` by\n/// [**pythonesque**](https://github.com/pythonesque) predates the\n/// creation of `LCell`, and inspired it.  Discussion of `GhostCell`\n/// on Reddit showed that a lifetime-based approach to cells was\n/// feasible, but unfortunately the `ghost_cell.rs` source didn't seem\n/// to be available under a community-friendly licence.  So I went\n/// back to first principles and created `LCell` from `TCell` code,\n/// combined with invariant lifetime code derived from the various\n/// community sources that predate `GhostCell`.  Later `Send` and\n/// `Sync` support for `LCell` was contributed independently.\n///\n/// See also [crate documentation](index.html).\npub struct LCellOwner<'id> {\n    _id: Id<'id>,\n}\n\nimpl<'id> LCellOwner<'id> {\n    /// Create a new `LCellOwner`, with a new lifetime, that exists\n    /// only within the scope of the execution of the given closure\n    /// call.  If two scope calls are nested, then the two owners get\n    /// different lifetimes.\n    pub fn scope<F>(f: F)\n    where\n        F: for<'scope_id> FnOnce(LCellOwner<'scope_id>),\n    {\n        f(Self { _id: PhantomData })\n    }\n\n    /// Create a new cell owned by this owner instance.  See also\n    /// [`LCell::new`].\n    ///\n    /// [`LCell::new`]: struct.LCell.html\n    pub fn cell<T>(&self, value: T) -> LCell<'id, T> {\n        LCell::<T>::new(value)\n    }\n\n    /// Borrow contents of a `LCell` immutably (read-only).  Many\n    /// `LCell` instances can be borrowed immutably at the same time\n    /// from the same owner.\n    #[inline]\n    pub fn ro<'a, T: ?Sized>(&'a self, lc: &'a LCell<'id, T>) -> &'a T {\n        unsafe { &*lc.value.get() }\n    }\n\n    /// Borrow contents of a `LCell` mutably (read-write).  Only one\n    /// `LCell` at a time can be borrowed from the owner using this\n    /// call.  The returned reference must go out of scope before\n    /// another can be borrowed.\n    #[inline]\n    pub fn rw<'a, T: ?Sized>(&'a mut self, lc: &'a LCell<'id, T>) -> &'a mut T {\n        unsafe { &mut *lc.value.get() }\n    }\n\n    /// Borrow contents of two `LCell` instances mutably.  Panics if\n    /// the two `LCell` instances point to the same memory.\n    #[inline]\n    pub fn rw2<'a, T: ?Sized, U: ?Sized>(\n        &'a mut self,\n        lc1: &'a LCell<'id, T>,\n        lc2: &'a LCell<'id, U>,\n    ) -> (&'a mut T, &'a mut U) {\n        assert!(\n            lc1 as *const _ as *const () as usize != lc2 as *const _ as *const () as usize,\n            \"Illegal to borrow same LCell twice with rw2()\"\n        );\n        unsafe { (&mut *lc1.value.get(), &mut *lc2.value.get()) }\n    }\n\n    /// Borrow contents of three `LCell` instances mutably.  Panics if\n    /// any pair of `LCell` instances point to the same memory.\n    #[inline]\n    pub fn rw3<'a, T: ?Sized, U: ?Sized, V: ?Sized>(\n        &'a mut self,\n        lc1: &'a LCell<'id, T>,\n        lc2: &'a LCell<'id, U>,\n        lc3: &'a LCell<'id, V>,\n    ) -> (&'a mut T, &'a mut U, &'a mut V) {\n        assert!(\n            (lc1 as *const _ as *const () as usize != lc2 as *const _ as *const () as usize)\n                && (lc2 as *const _ as *const () as usize != lc3 as *const _ as *const () as usize)\n                && (lc3 as *const _ as *const () as usize != lc1 as *const _ as *const () as usize),\n            \"Illegal to borrow same LCell twice with rw3()\"\n        );\n        unsafe {\n            (\n                &mut *lc1.value.get(),\n                &mut *lc2.value.get(),\n                &mut *lc3.value.get(),\n            )\n        }\n    }\n}\n\n/// Cell whose contents are owned (for borrowing purposes) by a\n/// [`LCellOwner`].\n///\n/// To borrow from this cell, use the borrowing calls on the\n/// [`LCellOwner`] instance that owns it, i.e. that shares the same\n/// Rust lifetime.\n///\n/// See also [crate documentation](index.html).\n///\n/// [`LCellOwner`]: struct.LCellOwner.html\npub struct LCell<'id, T: ?Sized> {\n    _id: Id<'id>,\n    value: UnsafeCell<T>,\n}\n\nimpl<'id, T> LCell<'id, T> {\n    /// Create a new `LCell`.  The owner of this cell is inferred by\n    /// Rust from the context.  So the owner lifetime is whatever\n    /// lifetime is required by the first use of the new `LCell`.\n    #[inline]\n    pub fn new(value: T) -> LCell<'id, T> {\n        LCell {\n            _id: PhantomData,\n            value: UnsafeCell::new(value),\n        }\n    }\n}\n\nimpl<'id, T: ?Sized> LCell<'id, T> {\n    /// Borrow contents of this cell immutably (read-only).  Many\n    /// `LCell` instances can be borrowed immutably at the same time\n    /// from the same owner.\n    #[inline]\n    pub fn ro<'a>(&'a self, owner: &'a LCellOwner<'id>) -> &'a T {\n        owner.ro(self)\n    }\n\n    /// Borrow contents of this cell mutably (read-write).  Only one\n    /// `LCell` at a time can be borrowed from the owner using this\n    /// call.  The returned reference must go out of scope before\n    /// another can be borrowed.  To mutably borrow from two or three\n    /// cells at the same time, see [`LCellOwner::rw2`] or\n    /// [`LCellOwner::rw3`].\n    #[inline]\n    pub fn rw<'a>(&'a self, owner: &'a mut LCellOwner<'id>) -> &'a mut T {\n        owner.rw(self)\n    }\n}\n\n// LCellOwner and LCell already automatically implement Send, but not\n// Sync. We can add these implementations though, since it's fine to\n// send a &LCell to another thread, and even mutably borrow the value\n// there, as long as T is Send and Sync.\n//\n// The reason why LCell<T>'s impl of Sync requires T: Send + Sync\n// instead of just T: Sync is that LCell provides interior mutability.\n// If you send a &LCell<T> (and its owner) to a different thread, you\n// can call .rw() to get a &mut T, and use std::mem::swap() to move\n// the T, effectively sending the T to that other thread. That's not\n// allowed if T: !Send.\n//\n// Note that the bounds on T for LCell<T>'s impl of Sync are the same\n// as those of std::sync::RwLock<T>. That's not a coincidence.\n// The way these types let you access T concurrently is the same,\n// even though the locking mechanisms are different.\nunsafe impl<'id> Sync for LCellOwner<'id> {}\nunsafe impl<'id, T: Send + Sync + ?Sized> Sync for LCell<'id, T> {}\n\n#[cfg(test)]\nmod tests {\n    use super::{LCell, LCellOwner};\n    use std::rc::Rc;\n\n    #[test]\n    fn lcell() {\n        LCellOwner::scope(|mut owner| {\n            let c1 = LCell::new(100u32);\n            let c2 = owner.cell(200u32);\n            (*owner.rw(&c1)) += 1;\n            (*owner.rw(&c2)) += 2;\n            let c1ref = owner.ro(&c1);\n            let c2ref = owner.ro(&c2);\n            let total = *c1ref + *c2ref;\n            assert_eq!(total, 303);\n        });\n    }\n\n    #[test]\n    #[should_panic]\n    fn lcell_rw2() {\n        LCellOwner::scope(|mut owner| {\n            let c1 = Rc::new(LCell::new(100u32));\n            let (mutref1, mutref2) = owner.rw2(&c1, &c1);\n            *mutref1 += 1;\n            *mutref2 += 1;\n        });\n    }\n\n    #[test]\n    #[should_panic]\n    fn lcell_rw3_1() {\n        LCellOwner::scope(|mut owner| {\n            let c1 = Rc::new(LCell::new(100u32));\n            let c2 = Rc::new(LCell::new(200u32));\n            let (mutref1, mutref2, mutref3) = owner.rw3(&c1, &c1, &c2);\n            *mutref1 += 1;\n            *mutref2 += 1;\n            *mutref3 += 1;\n        });\n    }\n\n    #[test]\n    #[should_panic]\n    fn lcell_rw3_2() {\n        LCellOwner::scope(|mut owner| {\n            let c1 = Rc::new(LCell::new(100u32));\n            let c2 = Rc::new(LCell::new(200u32));\n            let (mutref1, mutref2, mutref3) = owner.rw3(&c1, &c2, &c1);\n            *mutref1 += 1;\n            *mutref2 += 1;\n            *mutref3 += 1;\n        });\n    }\n\n    #[test]\n    #[should_panic]\n    fn lcell_rw3_3() {\n        LCellOwner::scope(|mut owner| {\n            let c1 = Rc::new(LCell::new(100u32));\n            let c2 = Rc::new(LCell::new(200u32));\n            let (mutref1, mutref2, mutref3) = owner.rw3(&c2, &c1, &c1);\n            *mutref1 += 1;\n            *mutref2 += 1;\n            *mutref3 += 1;\n        });\n    }\n\n    #[test]\n    fn lcell_unsized() {\n        LCellOwner::scope(|mut owner| {\n            struct Squares(u32);\n            struct Integers(u64);\n            trait Series {\n                fn step(&mut self);\n                fn value(&self) -> u64;\n            }\n            impl Series for Squares {\n                fn step(&mut self) {\n                    self.0 += 1;\n                }\n                fn value(&self) -> u64 {\n                    (self.0 as u64) * (self.0 as u64)\n                }\n            }\n            impl Series for Integers {\n                fn step(&mut self) {\n                    self.0 += 1;\n                }\n                fn value(&self) -> u64 {\n                    self.0\n                }\n            }\n            fn series<'id>(init: u32, is_squares: bool) -> Box<LCell<'id, dyn Series>> {\n                if is_squares {\n                    Box::new(LCell::new(Squares(init)))\n                } else {\n                    Box::new(LCell::new(Integers(init as u64)))\n                }\n            }\n\n            let own = &mut owner;\n            let cell1 = series(4, false);\n            let cell2 = series(7, true);\n            let cell3 = series(3, true);\n            assert_eq!(cell1.ro(own).value(), 4);\n            cell1.rw(own).step();\n            assert_eq!(cell1.ro(own).value(), 5);\n            assert_eq!(own.ro(&cell2).value(), 49);\n            own.rw(&cell2).step();\n            assert_eq!(own.ro(&cell2).value(), 64);\n            let (r1, r2, r3) = own.rw3(&cell1, &cell2, &cell3);\n            r1.step();\n            r2.step();\n            r3.step();\n            assert_eq!(cell1.ro(own).value(), 6);\n            assert_eq!(cell2.ro(own).value(), 81);\n            assert_eq!(cell3.ro(own).value(), 16);\n            let (r1, r2) = own.rw2(&cell1, &cell2);\n            r1.step();\n            r2.step();\n            assert_eq!(cell1.ro(own).value(), 7);\n            assert_eq!(cell2.ro(own).value(), 100);\n        });\n    }\n}\n"
  },
  {
    "project": "futures-rs",
    "target": 1,
    "commit_id": "7340d3d5d6fe8082a73069582b048ebaef6626b1",
    "func": "use futures_core::future::{FusedFuture, Future};\nuse futures_core::task::{Context, Poll, Waker};\nuse slab::Slab;\nuse std::{fmt, mem};\nuse std::cell::UnsafeCell;\nuse std::ops::{Deref, DerefMut};\nuse std::pin::Pin;\nuse std::sync::Mutex as StdMutex;\nuse std::sync::atomic::{AtomicUsize, Ordering};\n\n/// A futures-aware mutex.\n/// \n/// # Fairness\n/// \n/// This mutex provides no fairness guarantees. Tasks may not acquire the mutex\n/// in the order that they requested the lock, and it's possible for a single task\n/// which repeatedly takes the lock to starve other tasks, which may be left waiting\n/// indefinitely.\npub struct Mutex<T: ?Sized> {\n    state: AtomicUsize,\n    waiters: StdMutex<Slab<Waiter>>,\n    value: UnsafeCell<T>,\n}\n\nimpl<T: ?Sized> fmt::Debug for Mutex<T> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        let state = self.state.load(Ordering::SeqCst);\n        f.debug_struct(\"Mutex\")\n            .field(\"is_locked\", &((state & IS_LOCKED) != 0))\n            .field(\"has_waiters\", &((state & HAS_WAITERS) != 0))\n            .finish()\n    }\n}\n\nimpl<T> From<T> for Mutex<T> {\n    fn from(t: T) -> Self {\n        Self::new(t)\n    }\n}\n\nimpl<T: Default> Default for Mutex<T> {\n    fn default() -> Mutex<T> {\n        Mutex::new(Default::default())\n    }\n}\n\nenum Waiter {\n    Waiting(Waker),\n    Woken,\n}\n\nimpl Waiter {\n    fn register(&mut self, waker: &Waker) {\n        match self {\n            Waiter::Waiting(w) if waker.will_wake(w) => {},\n            _ => *self = Waiter::Waiting(waker.clone()),\n        }\n    }\n\n    fn wake(&mut self) {\n        match mem::replace(self, Waiter::Woken) {\n            Waiter::Waiting(waker) => waker.wake(),\n            Waiter::Woken => {},\n        }\n    }\n}\n\n#[allow(clippy::identity_op)] // https://github.com/rust-lang/rust-clippy/issues/3445\nconst IS_LOCKED: usize = 1 << 0;\nconst HAS_WAITERS: usize = 1 << 1;\n\nimpl<T> Mutex<T> {\n    /// Creates a new futures-aware mutex.\n    pub fn new(t: T) -> Mutex<T> {\n        Mutex {\n            state: AtomicUsize::new(0),\n            waiters: StdMutex::new(Slab::new()),\n            value: UnsafeCell::new(t),\n        }\n    }\n\n    /// Consumes this mutex, returning the underlying data.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use futures::lock::Mutex;\n    ///\n    /// let mutex = Mutex::new(0);\n    /// assert_eq!(mutex.into_inner(), 0);\n    /// ```\n    pub fn into_inner(self) -> T {\n        self.value.into_inner()\n    }\n}\n\nimpl<T: ?Sized> Mutex<T> {\n    /// Attempt to acquire the lock immediately.\n    ///\n    /// If the lock is currently held, this will return `None`.\n    pub fn try_lock(&self) -> Option<MutexGuard<'_, T>> {\n        let old_state = self.state.fetch_or(IS_LOCKED, Ordering::Acquire);\n        if (old_state & IS_LOCKED) == 0 {\n            Some(MutexGuard { mutex: self })\n        } else {\n            None\n        }\n    }\n\n    /// Acquire the lock asynchronously.\n    ///\n    /// This method returns a future that will resolve once the lock has been\n    /// successfully acquired.\n    pub fn lock(&self) -> MutexLockFuture<'_, T> {\n        MutexLockFuture {\n            mutex: Some(self),\n            wait_key: WAIT_KEY_NONE,\n        }\n    }\n\n    /// Returns a mutable reference to the underlying data.\n    ///\n    /// Since this call borrows the `Mutex` mutably, no actual locking needs to\n    /// take place -- the mutable borrow statically guarantees no locks exist.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # futures::executor::block_on(async {\n    /// use futures::lock::Mutex;\n    ///\n    /// let mut mutex = Mutex::new(0);\n    /// *mutex.get_mut() = 10;\n    /// assert_eq!(*mutex.lock().await, 10);\n    /// # });\n    /// ```\n    pub fn get_mut(&mut self) -> &mut T {\n        // We know statically that there are no other references to `self`, so\n        // there's no need to lock the inner mutex.\n        unsafe { &mut *self.value.get() }\n    }\n\n    fn remove_waker(&self, wait_key: usize, wake_another: bool) {\n        if wait_key != WAIT_KEY_NONE {\n            let mut waiters = self.waiters.lock().unwrap();\n            match waiters.remove(wait_key) {\n                Waiter::Waiting(_) => {},\n                Waiter::Woken => {\n                    // We were awoken, but then dropped before we could\n                    // wake up to acquire the lock. Wake up another\n                    // waiter.\n                    if wake_another {\n                        if let Some((_i, waiter)) = waiters.iter_mut().next() {\n                            waiter.wake();\n                        }\n                    }\n                }\n            }\n            if waiters.is_empty() {\n                self.state.fetch_and(!HAS_WAITERS, Ordering::Relaxed); // released by mutex unlock\n            }\n        }\n    }\n\n    // Unlocks the mutex. Called by MutexGuard and MappedMutexGuard when they are\n    // dropped.\n    fn unlock(&self) {\n        let old_state = self.state.fetch_and(!IS_LOCKED, Ordering::AcqRel);\n        if (old_state & HAS_WAITERS) != 0 {\n            let mut waiters = self.waiters.lock().unwrap();\n            if let Some((_i, waiter)) = waiters.iter_mut().next() {\n                waiter.wake();\n            }\n        }\n    }\n}\n\n// Sentinel for when no slot in the `Slab` has been dedicated to this object.\nconst WAIT_KEY_NONE: usize = usize::max_value();\n\n/// A future which resolves when the target mutex has been successfully acquired.\npub struct MutexLockFuture<'a, T: ?Sized> {\n    // `None` indicates that the mutex was successfully acquired.\n    mutex: Option<&'a Mutex<T>>,\n    wait_key: usize,\n}\n\nimpl<T: ?Sized> fmt::Debug for MutexLockFuture<'_, T> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"MutexLockFuture\")\n            .field(\"was_acquired\", &self.mutex.is_none())\n            .field(\"mutex\", &self.mutex)\n            .field(\"wait_key\", &(\n                    if self.wait_key == WAIT_KEY_NONE {\n                        None\n                    } else {\n                        Some(self.wait_key)\n                    }\n                ))\n            .finish()\n    }\n}\n\nimpl<T: ?Sized> FusedFuture for MutexLockFuture<'_, T> {\n    fn is_terminated(&self) -> bool {\n        self.mutex.is_none()\n    }\n}\n\nimpl<'a, T: ?Sized> Future for MutexLockFuture<'a, T> {\n    type Output = MutexGuard<'a, T>;\n\n    fn poll(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> {\n        let mutex = self.mutex.expect(\"polled MutexLockFuture after completion\");\n\n        if let Some(lock) = mutex.try_lock() {\n            mutex.remove_waker(self.wait_key, false);\n            self.mutex = None;\n            return Poll::Ready(lock);\n        }\n\n        {\n            let mut waiters = mutex.waiters.lock().unwrap();\n            if self.wait_key == WAIT_KEY_NONE {\n                self.wait_key = waiters.insert(Waiter::Waiting(cx.waker().clone()));\n                if waiters.len() == 1 {\n                    mutex.state.fetch_or(HAS_WAITERS, Ordering::Relaxed); // released by mutex unlock\n                }\n            } else {\n                waiters[self.wait_key].register(cx.waker());\n            }\n        }\n\n        // Ensure that we haven't raced `MutexGuard::drop`'s unlock path by\n        // attempting to acquire the lock again.\n        if let Some(lock) = mutex.try_lock() {\n            mutex.remove_waker(self.wait_key, false);\n            self.mutex = None;\n            return Poll::Ready(lock);\n        }\n\n        Poll::Pending\n    }\n}\n\nimpl<T: ?Sized> Drop for MutexLockFuture<'_, T> {\n    fn drop(&mut self) {\n        if let Some(mutex) = self.mutex {\n            // This future was dropped before it acquired the mutex.\n            //\n            // Remove ourselves from the map, waking up another waiter if we\n            // had been awoken to acquire the lock.\n            mutex.remove_waker(self.wait_key, true);\n        }\n    }\n}\n\n/// An RAII guard returned by the `lock` and `try_lock` methods.\n/// When this structure is dropped (falls out of scope), the lock will be\n/// unlocked.\npub struct MutexGuard<'a, T: ?Sized> {\n    mutex: &'a Mutex<T>,\n}\n\nimpl<'a, T: ?Sized> MutexGuard<'a, T> {\n    /// Returns a locked view over a portion of the locked data.\n    ///\n    /// # Example\n    ///\n    /// ```\n    /// # futures::executor::block_on(async {\n    /// use futures::lock::{Mutex, MutexGuard};\n    ///\n    /// let data = Mutex::new(Some(\"value\".to_string()));\n    /// {\n    ///     let locked_str = MutexGuard::map(data.lock().await, |opt| opt.as_mut().unwrap());\n    ///     assert_eq!(&*locked_str, \"value\");\n    /// }\n    /// # });\n    /// ```\n    #[inline]\n    pub fn map<U: ?Sized, F>(this: Self, f: F) -> MappedMutexGuard<'a, T, U>\n    where\n        F: FnOnce(&mut T) -> &mut U,\n    {\n        let mutex = this.mutex;\n        let value = f(unsafe { &mut *this.mutex.value.get() });\n        // Don't run the `drop` method for MutexGuard. The ownership of the underlying\n        // locked state is being moved to the returned MappedMutexGuard.\n        mem::forget(this);\n        MappedMutexGuard { mutex, value }\n    }\n}\n\nimpl<T: ?Sized + fmt::Debug> fmt::Debug for MutexGuard<'_, T> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"MutexGuard\")\n            .field(\"value\", &&**self)\n            .field(\"mutex\", &self.mutex)\n            .finish()\n    }\n}\n\nimpl<T: ?Sized> Drop for MutexGuard<'_, T> {\n    fn drop(&mut self) {\n        self.mutex.unlock()\n    }\n}\n\nimpl<T: ?Sized> Deref for MutexGuard<'_, T> {\n    type Target = T;\n    fn deref(&self) -> &T {\n        unsafe { &*self.mutex.value.get() }\n    }\n}\n\nimpl<T: ?Sized> DerefMut for MutexGuard<'_, T> {\n    fn deref_mut(&mut self) -> &mut T {\n        unsafe { &mut *self.mutex.value.get() }\n    }\n}\n\n/// An RAII guard returned by the `MutexGuard::map` and `MappedMutexGuard::map` methods.\n/// When this structure is dropped (falls out of scope), the lock will be unlocked.\npub struct MappedMutexGuard<'a, T: ?Sized, U: ?Sized> {\n    mutex: &'a Mutex<T>,\n    value: *mut U,\n}\n\nimpl<'a, T: ?Sized, U: ?Sized> MappedMutexGuard<'a, T, U> {\n    /// Returns a locked view over a portion of the locked data.\n    ///\n    /// # Example\n    ///\n    /// ```\n    /// # futures::executor::block_on(async {\n    /// use futures::lock::{MappedMutexGuard, Mutex, MutexGuard};\n    ///\n    /// let data = Mutex::new(Some(\"value\".to_string()));\n    /// {\n    ///     let locked_str = MutexGuard::map(data.lock().await, |opt| opt.as_mut().unwrap());\n    ///     let locked_char = MappedMutexGuard::map(locked_str, |s| s.get_mut(0..1).unwrap());\n    ///     assert_eq!(&*locked_char, \"v\");\n    /// }\n    /// # });\n    /// ```\n    #[inline]\n    pub fn map<V: ?Sized, F>(this: Self, f: F) -> MappedMutexGuard<'a, T, V>\n    where\n        F: FnOnce(&mut U) -> &mut V,\n    {\n        let mutex = this.mutex;\n        let value = f(unsafe { &mut *this.value });\n        // Don't run the `drop` method for MappedMutexGuard. The ownership of the underlying\n        // locked state is being moved to the returned MappedMutexGuard.\n        mem::forget(this);\n        MappedMutexGuard { mutex, value }\n    }\n}\n\nimpl<T: ?Sized, U: ?Sized + fmt::Debug> fmt::Debug for MappedMutexGuard<'_, T, U> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"MappedMutexGuard\")\n            .field(\"value\", &&**self)\n            .field(\"mutex\", &self.mutex)\n            .finish()\n    }\n}\n\nimpl<T: ?Sized, U: ?Sized> Drop for MappedMutexGuard<'_, T, U> {\n    fn drop(&mut self) {\n        self.mutex.unlock()\n    }\n}\n\nimpl<T: ?Sized, U: ?Sized> Deref for MappedMutexGuard<'_, T, U> {\n    type Target = U;\n    fn deref(&self) -> &U {\n        unsafe { &*self.value }\n    }\n}\n\nimpl<T: ?Sized, U: ?Sized> DerefMut for MappedMutexGuard<'_, T, U> {\n    fn deref_mut(&mut self) -> &mut U {\n        unsafe { &mut *self.value }\n    }\n}\n\n// Mutexes can be moved freely between threads and acquired on any thread so long\n// as the inner value can be safely sent between threads.\nunsafe impl<T: ?Sized + Send> Send for Mutex<T> {}\nunsafe impl<T: ?Sized + Send> Sync for Mutex<T> {}\n\n// It's safe to switch which thread the acquire is being attempted on so long as\n// `T` can be accessed on that thread.\nunsafe impl<T: ?Sized + Send> Send for MutexLockFuture<'_, T> {}\n// doesn't have any interesting `&self` methods (only Debug)\nunsafe impl<T: ?Sized> Sync for MutexLockFuture<'_, T> {}\n\n// Safe to send since we don't track any thread-specific details-- the inner\n// lock is essentially spinlock-equivalent (attempt to flip an atomic bool)\nunsafe impl<T: ?Sized + Send> Send for MutexGuard<'_, T> {}\nunsafe impl<T: ?Sized + Sync> Sync for MutexGuard<'_, T> {}\nunsafe impl<T: ?Sized + Send, U: ?Sized> Send for MappedMutexGuard<'_, T, U> {}\nunsafe impl<T: ?Sized + Sync, U: ?Sized> Sync for MappedMutexGuard<'_, T, U> {}\n\n#[test]\nfn test_mutex_guard_debug_not_recurse() {\n    let mutex = Mutex::new(42);\n    let guard = mutex.try_lock().unwrap();\n    let _ = format!(\"{:?}\", guard);\n    let guard = MutexGuard::map(guard, |n| n);\n    let _ = format!(\"{:?}\", guard);\n}\n"
  },
  {
    "project": "cdr-rs",
    "target": 1,
    "commit_id": "880a281afe6f49109a90e2a8bb943c02a360bf49",
    "func": "//! Deserializing CDR into Rust data types.\n\nuse std::{self, io::Read, marker::PhantomData};\n\nuse byteorder::{BigEndian, ByteOrder, LittleEndian, ReadBytesExt};\nuse serde::de::{self, IntoDeserializer};\n\nuse crate::error::{Error, Result};\nuse crate::size::{Infinite, SizeLimit};\n\n/// A deserializer that reads bytes from a buffer.\npub struct Deserializer<R, S, E> {\n    reader: R,\n    size_limit: S,\n    pos: u64,\n    phantom: PhantomData<E>,\n}\n\nimpl<R, S, E> Deserializer<R, S, E>\nwhere\n    R: Read,\n    S: SizeLimit,\n    E: ByteOrder,\n{\n    pub fn new(reader: R, size_limit: S) -> Self {\n        Self {\n            reader,\n            size_limit,\n            pos: 0,\n            phantom: PhantomData,\n        }\n    }\n\n    fn read_padding_of<T>(&mut self) -> Result<()> {\n        // Calculate the required padding to align with 1-byte, 2-byte, 4-byte, 8-byte boundaries\n        // Instead of using the slow modulo operation '%', the faster bit-masking is used\n        let alignment = std::mem::size_of::<T>();\n        let rem_mask = alignment - 1; // mask like 0x0, 0x1, 0x3, 0x7\n        let mut padding: [u8; 8] = [0; 8];\n        match (self.pos as usize) & rem_mask {\n            0 => Ok(()),\n            n @ 1..=7 => {\n                let amt = alignment - n;\n                self.read_size(amt as u64)?;\n                self.reader\n                    .read_exact(&mut padding[..amt])\n                    .map_err(Into::into)\n            }\n            _ => unreachable!(),\n        }\n    }\n\n    fn read_size(&mut self, size: u64) -> Result<()> {\n        self.pos += size;\n        self.size_limit.add(size)\n    }\n\n    fn read_size_of<T>(&mut self) -> Result<()> {\n        self.read_size(std::mem::size_of::<T>() as u64)\n    }\n\n    fn read_string(&mut self) -> Result<String> {\n        String::from_utf8(self.read_vec().map(|mut v| {\n            v.pop(); // removes a terminating null character\n            v\n        })?)\n        .map_err(|e| Error::InvalidUtf8Encoding(e.utf8_error()))\n    }\n\n    fn read_vec(&mut self) -> Result<Vec<u8>> {\n        let len: u32 = de::Deserialize::deserialize(&mut *self)?;\n        let mut buf = Vec::with_capacity(len as usize);\n        unsafe { buf.set_len(len as usize) }\n        self.read_size(u64::from(len))?;\n        self.reader.read_exact(&mut buf[..])?;\n        Ok(buf)\n    }\n\n    pub(crate) fn reset_pos(&mut self) {\n        self.pos = 0;\n    }\n}\n\nimpl<'de, 'a, R, S, E> de::Deserializer<'de> for &'a mut Deserializer<R, S, E>\nwhere\n    R: Read,\n    S: SizeLimit,\n    E: ByteOrder,\n{\n    type Error = Error;\n\n    fn deserialize_any<V>(self, _visitor: V) -> Result<V::Value>\n    where\n        V: de::Visitor<'de>,\n    {\n        Err(Error::DeserializeAnyNotSupported)\n    }\n\n    fn deserialize_bool<V>(self, visitor: V) -> Result<V::Value>\n    where\n        V: de::Visitor<'de>,\n    {\n        let value: u8 = de::Deserialize::deserialize(self)?;\n        match value {\n            1 => visitor.visit_bool(true),\n            0 => visitor.visit_bool(false),\n            value => Err(Error::InvalidBoolEncoding(value)),\n        }\n    }\n\n    fn deserialize_u8<V>(self, visitor: V) -> Result<V::Value>\n    where\n        V: de::Visitor<'de>,\n    {\n        self.read_size_of::<u8>()?;\n        visitor.visit_u8(self.reader.read_u8()?)\n    }\n\n    fn deserialize_u16<V>(self, visitor: V) -> Result<V::Value>\n    where\n        V: de::Visitor<'de>,\n    {\n        self.read_padding_of::<u16>()?;\n        self.read_size_of::<u16>()?;\n        visitor.visit_u16(self.reader.read_u16::<E>()?)\n    }\n\n    fn deserialize_u32<V>(self, visitor: V) -> Result<V::Value>\n    where\n        V: de::Visitor<'de>,\n    {\n        self.read_padding_of::<u32>()?;\n        self.read_size_of::<u32>()?;\n        visitor.visit_u32(self.reader.read_u32::<E>()?)\n    }\n\n    fn deserialize_u64<V>(self, visitor: V) -> Result<V::Value>\n    where\n        V: de::Visitor<'de>,\n    {\n        self.read_padding_of::<u64>()?;\n        self.read_size_of::<u64>()?;\n        visitor.visit_u64(self.reader.read_u64::<E>()?)\n    }\n\n    fn deserialize_i8<V>(self, visitor: V) -> Result<V::Value>\n    where\n        V: de::Visitor<'de>,\n    {\n        self.read_size_of::<i8>()?;\n        visitor.visit_i8(self.reader.read_i8()?)\n    }\n\n    fn deserialize_i16<V>(self, visitor: V) -> Result<V::Value>\n    where\n        V: de::Visitor<'de>,\n    {\n        self.read_padding_of::<i16>()?;\n        self.read_size_of::<i16>()?;\n        visitor.visit_i16(self.reader.read_i16::<E>()?)\n    }\n\n    fn deserialize_i32<V>(self, visitor: V) -> Result<V::Value>\n    where\n        V: de::Visitor<'de>,\n    {\n        self.read_padding_of::<i32>()?;\n        self.read_size_of::<i32>()?;\n        visitor.visit_i32(self.reader.read_i32::<E>()?)\n    }\n\n    fn deserialize_i64<V>(self, visitor: V) -> Result<V::Value>\n    where\n        V: de::Visitor<'de>,\n    {\n        self.read_padding_of::<i64>()?;\n        self.read_size_of::<i64>()?;\n        visitor.visit_i64(self.reader.read_i64::<E>()?)\n    }\n\n    fn deserialize_f32<V>(self, visitor: V) -> Result<V::Value>\n    where\n        V: de::Visitor<'de>,\n    {\n        self.read_padding_of::<f32>()?;\n        self.read_size_of::<f32>()?;\n        visitor.visit_f32(self.reader.read_f32::<E>()?)\n    }\n\n    fn deserialize_f64<V>(self, visitor: V) -> Result<V::Value>\n    where\n        V: de::Visitor<'de>,\n    {\n        self.read_padding_of::<f64>()?;\n        self.read_size_of::<f64>()?;\n        visitor.visit_f64(self.reader.read_f64::<E>()?)\n    }\n\n    fn deserialize_char<V>(self, visitor: V) -> Result<V::Value>\n    where\n        V: de::Visitor<'de>,\n    {\n        let mut buf = [0u8; 4];\n        self.reader.read_exact(&mut buf[..1])?;\n\n        let width = utf8_char_width(buf[0]);\n        if width != 1 {\n            Err(Error::InvalidCharEncoding)\n        } else {\n            self.read_size(width as u64)?;\n            visitor.visit_char(buf[0] as char)\n        }\n    }\n\n    fn deserialize_str<V>(self, visitor: V) -> Result<V::Value>\n    where\n        V: de::Visitor<'de>,\n    {\n        visitor.visit_str(&self.read_string()?)\n    }\n\n    fn deserialize_string<V>(self, visitor: V) -> Result<V::Value>\n    where\n        V: de::Visitor<'de>,\n    {\n        visitor.visit_string(self.read_string()?)\n    }\n\n    fn deserialize_bytes<V>(self, visitor: V) -> Result<V::Value>\n    where\n        V: de::Visitor<'de>,\n    {\n        visitor.visit_bytes(&self.read_vec()?)\n    }\n\n    fn deserialize_byte_buf<V>(self, visitor: V) -> Result<V::Value>\n    where\n        V: de::Visitor<'de>,\n    {\n        visitor.visit_byte_buf(self.read_vec()?)\n    }\n\n    fn deserialize_option<V>(self, _visitor: V) -> Result<V::Value>\n    where\n        V: de::Visitor<'de>,\n    {\n        Err(Error::TypeNotSupported)\n    }\n\n    fn deserialize_unit<V>(self, visitor: V) -> Result<V::Value>\n    where\n        V: de::Visitor<'de>,\n    {\n        visitor.visit_unit()\n    }\n\n    fn deserialize_unit_struct<V>(self, _name: &'static str, visitor: V) -> Result<V::Value>\n    where\n        V: de::Visitor<'de>,\n    {\n        visitor.visit_unit()\n    }\n\n    fn deserialize_newtype_struct<V>(self, _name: &'static str, visitor: V) -> Result<V::Value>\n    where\n        V: de::Visitor<'de>,\n    {\n        visitor.visit_newtype_struct(self)\n    }\n\n    fn deserialize_seq<V>(self, visitor: V) -> Result<V::Value>\n    where\n        V: de::Visitor<'de>,\n    {\n        let len: u32 = de::Deserialize::deserialize(&mut *self)?;\n        self.deserialize_tuple(len as usize, visitor)\n    }\n\n    fn deserialize_tuple<V>(self, len: usize, visitor: V) -> Result<V::Value>\n    where\n        V: de::Visitor<'de>,\n    {\n        struct Access<'a, R: 'a, S: 'a, E: 'a>\n        where\n            R: Read,\n            S: SizeLimit,\n            E: ByteOrder,\n        {\n            deserializer: &'a mut Deserializer<R, S, E>,\n            len: usize,\n        }\n\n        impl<'de, 'a, R: 'a, S, E> de::SeqAccess<'de> for Access<'a, R, S, E>\n        where\n            R: Read,\n            S: SizeLimit,\n            E: ByteOrder,\n        {\n            type Error = Error;\n\n            fn next_element_seed<T>(&mut self, seed: T) -> Result<Option<T::Value>>\n            where\n                T: de::DeserializeSeed<'de>,\n            {\n                if self.len > 0 {\n                    self.len -= 1;\n                    let value = de::DeserializeSeed::deserialize(seed, &mut *self.deserializer)?;\n                    Ok(Some(value))\n                } else {\n                    Ok(None)\n                }\n            }\n\n            fn size_hint(&self) -> Option<usize> {\n                Some(self.len)\n            }\n        }\n\n        visitor.visit_seq(Access {\n            deserializer: self,\n            len,\n        })\n    }\n\n    fn deserialize_tuple_struct<V>(\n        self,\n        _name: &'static str,\n        len: usize,\n        visitor: V,\n    ) -> Result<V::Value>\n    where\n        V: de::Visitor<'de>,\n    {\n        self.deserialize_tuple(len, visitor)\n    }\n\n    fn deserialize_map<V>(self, _visitor: V) -> Result<V::Value>\n    where\n        V: de::Visitor<'de>,\n    {\n        Err(Error::TypeNotSupported)\n    }\n\n    fn deserialize_struct<V>(\n        self,\n        _name: &'static str,\n        fields: &'static [&'static str],\n        visitor: V,\n    ) -> Result<V::Value>\n    where\n        V: de::Visitor<'de>,\n    {\n        self.deserialize_tuple(fields.len(), visitor)\n    }\n\n    fn deserialize_enum<V>(\n        self,\n        _name: &'static str,\n        _variants: &'static [&'static str],\n        visitor: V,\n    ) -> Result<V::Value>\n    where\n        V: de::Visitor<'de>,\n    {\n        impl<'de, 'a, R: 'a, S, E> de::EnumAccess<'de> for &'a mut Deserializer<R, S, E>\n        where\n            R: Read,\n            S: SizeLimit,\n            E: ByteOrder,\n        {\n            type Error = Error;\n            type Variant = Self;\n\n            fn variant_seed<V>(self, seed: V) -> Result<(V::Value, Self::Variant)>\n            where\n                V: de::DeserializeSeed<'de>,\n            {\n                let idx: u32 = de::Deserialize::deserialize(&mut *self)?;\n                let val: Result<_> = seed.deserialize(idx.into_deserializer());\n                Ok((val?, self))\n            }\n        }\n\n        visitor.visit_enum(self)\n    }\n\n    fn deserialize_identifier<V>(self, _visitor: V) -> Result<V::Value>\n    where\n        V: de::Visitor<'de>,\n    {\n        Err(Error::TypeNotSupported)\n    }\n\n    fn deserialize_ignored_any<V>(self, _visitor: V) -> Result<V::Value>\n    where\n        V: de::Visitor<'de>,\n    {\n        Err(Error::TypeNotSupported)\n    }\n\n    fn is_human_readable(&self) -> bool {\n        false\n    }\n}\n\nimpl<'de, 'a, R, S, E> de::VariantAccess<'de> for &'a mut Deserializer<R, S, E>\nwhere\n    R: Read,\n    S: SizeLimit,\n    E: ByteOrder,\n{\n    type Error = Error;\n\n    fn unit_variant(self) -> Result<()> {\n        Ok(())\n    }\n\n    fn newtype_variant_seed<T>(self, seed: T) -> Result<T::Value>\n    where\n        T: de::DeserializeSeed<'de>,\n    {\n        de::DeserializeSeed::deserialize(seed, self)\n    }\n\n    fn tuple_variant<V>(self, len: usize, visitor: V) -> Result<V::Value>\n    where\n        V: de::Visitor<'de>,\n    {\n        de::Deserializer::deserialize_tuple(self, len, visitor)\n    }\n\n    fn struct_variant<V>(self, fields: &'static [&'static str], visitor: V) -> Result<V::Value>\n    where\n        V: de::Visitor<'de>,\n    {\n        de::Deserializer::deserialize_tuple(self, fields.len(), visitor)\n    }\n}\n\nimpl<R, S> From<Deserializer<R, S, BigEndian>> for Deserializer<R, S, LittleEndian> {\n    fn from(t: Deserializer<R, S, BigEndian>) -> Self {\n        Deserializer::<R, S, LittleEndian> {\n            reader: t.reader,\n            size_limit: t.size_limit,\n            pos: t.pos,\n            phantom: PhantomData,\n        }\n    }\n}\n\n#[inline]\nfn utf8_char_width(first_byte: u8) -> usize {\n    UTF8_CHAR_WIDTH[first_byte as usize] as usize\n}\n\n// https://tools.ietf.org/html/rfc3629\nconst UTF8_CHAR_WIDTH: &[u8; 256] = &[\n    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, //\n    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, // 0x1F\n    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, //\n    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, // 0x3F\n    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, //\n    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, // 0x5F\n    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, //\n    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, // 0x7F\n    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, //\n    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, // 0x9F\n    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, //\n    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, // 0xBF\n    0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, //\n    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, // 0xDF\n    3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, // 0xEF\n    4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, // 0xFF\n];\n\n/// Deserializes a slice of bytes into an object.\npub fn deserialize_data<'de, T, E>(bytes: &[u8]) -> Result<T>\nwhere\n    T: de::Deserialize<'de>,\n    E: ByteOrder,\n{\n    deserialize_data_from::<_, _, _, E>(bytes, Infinite)\n}\n\n/// Deserializes an object directly from a `Read`.\npub fn deserialize_data_from<'de, R, T, S, E>(reader: R, size_limit: S) -> Result<T>\nwhere\n    R: Read,\n    T: de::Deserialize<'de>,\n    S: SizeLimit,\n    E: ByteOrder,\n{\n    let mut deserializer = Deserializer::<_, S, E>::new(reader, size_limit);\n    de::Deserialize::deserialize(&mut deserializer)\n}\n"
  },
  {
    "project": "bra-rs",
    "target": 1,
    "commit_id": "ff2b2995f43c24193aa71a3801bf7af287e2ca98",
    "func": "use std::io::{BufRead, Error as IoError, ErrorKind as IoErrorKind, Read, Result as IoResult};\nuse std::ops::Bound;\nuse std::ops::RangeBounds;\n\n/// A buffered reader that greedily retains all memory read into a buffer.\n/// \n/// Like [`std::io::BufReader`], it fetches bytes from the source in bulk to\n/// reduce the number of actual reads. Moreover, it provides methods for\n/// reading a byte or slice of bytes at an arbitrary position, reading as many\n/// bytes as required to reach that position of the data stream, if they are\n/// not in memory already. The position indices are always relative to the\n/// position of the data source when it was passed to this construct via\n/// [`new`] or [`with_capacity`].\n/// \n/// [`std::io::BufReader`]: https://doc.rust-lang.org/std/io/struct.BufReader.html\n/// [`new`]: ./struct.GreedyAccessReader.html#method.new\n/// [`with_capacity`]: ./struct.GreedyAccessReader.html#method.with_capacity\npub struct GreedyAccessReader<R> {\n    inner: R,\n    buf: Vec<u8>,\n    consumed: usize,\n}\n\nimpl<R> GreedyAccessReader<R>\nwhere\n    R: Read,\n{\n    /// Creates a new greedy buffered reader with the given byte source.\n    pub fn new(src: R) -> Self {\n        GreedyAccessReader {\n            inner: src,\n            buf: Vec::new(),\n            consumed: 0,\n        }\n    }\n\n    /// Creates a new greedy buffered reader with the given byte source and\n    /// the specified buffer capacity.\n    /// \n    /// The buffer will be able to read approximately `capacity` bytes without\n    /// reallocating.\n    pub fn with_capacity(src: R, capacity: usize) -> Self {\n        GreedyAccessReader {\n            inner: src,\n            buf: Vec::with_capacity(capacity),\n            consumed: 0,\n        }\n    }\n\n    /// Retrieves the internal reader, discarding the buffer in the process.\n    ///\n    /// Note that any leftover data in the internal buffer is lost.\n    pub fn into_inner(self) -> R {\n        self.inner\n    }\n\n    /// Retrieves the internal buffer in its current state, discarding the\n    /// reader in the process.\n    pub fn into_buffer(self) -> Vec<u8> {\n        self.buf\n    }\n\n    /// Retrieves the internal reader and buffer in their current state.\n    pub fn into_parts(self) -> (R, Vec<u8>) {\n        (self.inner, self.buf)\n    }\n\n    /// Fetches a single byte from the buffered data source. \n    pub fn get(&mut self, index: usize) -> IoResult<u8> {\n        if let Some(v) = self.buf.get(index) {\n            Ok(*v)\n        } else {\n            self.prefetch_up_to(index + 1)?;\n\n            self.buf\n                .get(index)\n                .cloned()\n                .ok_or_else(|| IoError::new(IoErrorKind::Other, \"Index out of bounds\"))\n        }\n    }\n\n    /// Obtains a slice of bytes.\n    /// \n    /// The range's end must be bound (e.g. `5..` is not supported).\n    /// \n    /// # Error\n    /// \n    /// Returns an I/O error if the range is out of the boundaries\n    /// \n    /// # Panics\n    /// \n    /// Panics if the range is not end bounded.\n    pub fn slice<T>(&mut self, range: T) -> IoResult<&[u8]>\n    where\n        T: Clone,\n        T: RangeBounds<usize>,\n    {\n        let end = range.end_bound();\n        let e = match end {\n            Bound::Unbounded => {\n                unimplemented!(\"Unbounded end is currently not supported\");\n            }\n            Bound::Excluded(&e) => e,\n            Bound::Included(&e) => e + 1,\n        };\n\n        let b = match range.start_bound() {\n            Bound::Unbounded => 0,\n            Bound::Excluded(&b) | Bound::Included(&b) => b,\n        };\n\n        self.prefetch_up_to(e)?;\n\n        if b > e || e > self.buf.len() {\n            Err(IoError::new(IoErrorKind::Other, \"Index out of bounds\"))\n        } else {\n            Ok(&self.buf[b..e])\n        }\n    }\n\n    /// Clears all memory of past reads, shrinking or freeing the buffer in the\n    /// process. The reader will behave as if freshly constructed, save for\n    /// already prefetched data, so that no bytes are lost. The following byte\n    /// being read becomes the byte at index `#0`.\n    pub fn clear(&mut self) {\n        if self.consumed < self.buf.len() {\n            self.buf = self.buf[self.consumed..].to_vec();\n        } else {\n            self.buf = Vec::new();\n        }\n        self.consumed = 0;\n    }\n\n    /// Shrinks the internal buffer to minimal capacity.\n    pub fn shrink_to_fit(&mut self) {\n        self.buf.shrink_to_fit()\n    }\n\n    fn reserve_up_to(&mut self, index: usize) {\n        let mut new_size = 16;\n        while new_size < index || new_size < self.buf.capacity() {\n            new_size *= 2;\n        }\n        let additional = new_size - self.buf.capacity();\n        if additional > 0 {\n            self.buf.reserve(additional);\n        }\n    }\n\n    fn data_to_read(&self) -> &[u8] {\n        &self.buf[self.consumed..]\n    }\n\n    fn prefetch_up_to(&mut self, i: usize) -> IoResult<()> {\n        self.reserve_up_to(i);\n        let mut l = 0;\n        while self.buf.len() <= i {\n            let b = self.fill_buf()?;\n            if b.len() == l {\n                // no extra data since last call, retreat\n                break;\n            } else {\n                // record length, continue fetching\n                l = b.len();\n            }\n        }\n        Ok(())\n    }\n}\n\nimpl<R> Read for GreedyAccessReader<R>\nwhere\n    R: Read,\n{\n    fn read(&mut self, buf: &mut [u8]) -> IoResult<usize> {\n        // we'll be reading from the buffer\n        let mut to_read = self.data_to_read();\n        if to_read.is_empty() {\n            self.fill_buf()?;\n            to_read = self.data_to_read();\n        }\n\n        let len = usize::min(to_read.len(), buf.len());\n        buf[..len].copy_from_slice(&self.buf[self.consumed..self.consumed + len]);\n        self.consume(len);\n        Ok(len)\n    }\n}\n\nimpl<R> BufRead for GreedyAccessReader<R>\nwhere\n    R: Read,\n{\n    fn fill_buf(&mut self) -> IoResult<&[u8]> {\n        if self.buf.capacity() == self.consumed {\n            self.reserve_up_to(self.buf.capacity() + 16);\n        }\n\n        let b = self.buf.len();\n        let buf = unsafe {\n            // safe because it's within the buffer's limits\n            // and we won't be reading uninitialized memory\n            std::slice::from_raw_parts_mut(\n                self.buf.as_mut_ptr().add(b),\n                self.buf.capacity() - b)\n        };\n\n        match self.inner.read(buf) {\n            Ok(o) => {\n                unsafe {\n                    // reset the size to include the written portion,\n                    // safe because the extra data is initialized\n                    self.buf.set_len(b + o);\n                }\n\n                Ok(&self.buf[self.consumed..])\n            }\n            Err(e) => Err(e),\n        }\n    }\n\n    fn consume(&mut self, amt: usize) {\n        self.consumed += amt;\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::GreedyAccessReader;\n    use std::io::Read;\n    #[test]\n    fn smoke_test() {\n        let data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 50];\n\n        let mut read = GreedyAccessReader::new(&data[..]);\n        let mut o = Vec::new();\n        read.read_to_end(&mut o).unwrap();\n\n        assert_eq!(o, &data);\n    }\n\n    #[test]\n    fn test_get() {\n        let data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 50];\n\n        let mut read = GreedyAccessReader::new(&data[..]);\n\n        assert_eq!(read.get(1).unwrap(), 2);\n        assert_eq!(read.get(2).unwrap(), 3);\n        assert_eq!(read.get(16).unwrap(), 50);\n        assert_eq!(read.get(10).unwrap(), 11);\n        assert!(read.get(17).is_err());\n    }\n\n    #[test]\n    fn test_slice() {\n        let data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 50];\n\n        let mut read = GreedyAccessReader::new(&data[..]);\n\n        assert_eq!(read.slice(0..0).unwrap(), &[]);\n        assert_eq!(read.slice(1..2).unwrap(), &[2]);\n        assert_eq!(read.slice(..=5).unwrap(), &[1, 2, 3, 4, 5, 6]);\n        assert_eq!(read.slice(14..=16).unwrap(), &[15, 16, 50]);\n        assert_eq!(read.slice(10..12).unwrap(), &[11, 12]);\n        assert!(read.slice(7..18).is_err());\n        assert!(read.slice(6..5).is_err());\n    }\n\n    #[test]\n    fn arbitrary_get_infinite() {\n        const B: u8 = 0x33;\n        let mut read = GreedyAccessReader::new(std::io::repeat(B));\n\n        assert_eq!(read.get(4).unwrap(), B);\n        assert_eq!(read.get(13).unwrap(), B);\n        assert_eq!(read.get(24389).unwrap(), B);\n        assert_eq!(read.get(156).unwrap(), B);\n        assert_eq!(read.get(9006).unwrap(), B);\n        assert_eq!(read.get(2019).unwrap(), B);\n        assert_eq!(read.get(100000).unwrap(), B);\n    }\n\n    #[test]\n    fn test_clear() {\n        let data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 50];\n        let mut read = GreedyAccessReader::new(&data[..]);\n\n        assert_eq!(read.get(0).unwrap(), 1);\n        assert_eq!(read.get(8).unwrap(), 9);\n        assert_eq!(read.get(16).unwrap(), 50);\n\n        let mut chunk = [0; 8];\n        read.read_exact(&mut chunk).unwrap();\n        assert_eq!(chunk, [1, 2, 3, 4, 5, 6, 7, 8]);\n\n        assert_eq!(read.get(0).unwrap(), 1);\n        assert_eq!(read.get(8).unwrap(), 9);\n        assert_eq!(read.get(16).unwrap(), 50);\n\n        read.clear();\n\n        assert_eq!(read.get(0).unwrap(), 9);\n        assert_eq!(read.get(8).unwrap(), 50);\n        assert!(read.get(16).is_err());\n\n        read.read_exact(&mut chunk).unwrap();\n        assert_eq!(chunk, [9, 10, 11, 12, 13, 14, 15, 16]);\n\n        assert_eq!(read.get(0).unwrap(), 9);\n        assert_eq!(read.get(8).unwrap(), 50);\n        assert!(read.get(16).is_err());\n    }\n}\n"
  },
  {
    "project": "lazy-init",
    "target": 1,
    "commit_id": "054096b3987782cc6805324ba4df4dbe8c8b19b7",
    "func": "#![deny(missing_docs)]\n\n//! A crate for things that are\n//! 1) Lazily initialized\n//! 2) Expensive to create\n//! 3) Immutable after creation\n//! 4) Used on multiple threads\n//!\n//! `Lazy<T>` is better than `Mutex<Option<T>>` because after creation accessing\n//! `T` does not require any locking, just a single boolean load with\n//! `Ordering::Acquire` (which on x86 is just a compiler barrier, not an actual\n//! memory barrier).\n\nuse std::cell::UnsafeCell;\nuse std::fmt;\nuse std::sync::Mutex;\nuse std::sync::atomic::{AtomicBool, Ordering};\n\nenum ThisOrThat<T, U> {\n    This(T),\n    That(U),\n}\n\n/// `LazyTransform<T, U>` is a synchronized holder type, that holds a value of\n/// type T until it is lazily converted into a value of type U.\npub struct LazyTransform<T, U> {\n    initialized: AtomicBool,\n    lock: Mutex<()>,\n    value: UnsafeCell<Option<ThisOrThat<T, U>>>,\n}\n\n// Implementation details.\nimpl<T, U> LazyTransform<T, U>\n    where T: Sync,\n          U: Sync\n{\n    fn extract(&self) -> Option<&U> {\n        // Make sure we're initialized first!\n        match unsafe { (*self.value.get()).as_ref() } {\n            None => None,\n            Some(&ThisOrThat::This(_)) => panic!(), // Should already be initialized!\n            Some(&ThisOrThat::That(ref that)) => Some(that),\n        }\n    }\n}\n\n// Public API.\nimpl<T, U> LazyTransform<T, U> {\n    /// Construct a new, untransformed `LazyTransform<T, U>` with an argument of\n    /// type T.\n    pub fn new(t: T) -> LazyTransform<T, U> {\n        LazyTransform {\n            initialized: AtomicBool::new(false),\n            lock: Mutex::new(()),\n            value: UnsafeCell::new(Some(ThisOrThat::This(t))),\n        }\n    }\n\n    /// Unwrap the contained value, returning `Ok(U)` if the `LazyTransform<T, U>` has been\n    /// transformed or `Err(T)` if it has not.\n    pub fn into_inner(self) -> Result<U, T> {\n        // We don't need to inspect `self.initialized` since `self` is owned\n        // so it is guaranteed that no other threads are accessing its data.\n        match self.value.into_inner().unwrap() {\n            ThisOrThat::This(t) => Err(t),\n            ThisOrThat::That(u) => Ok(u),\n        }\n    }\n}\n\n// Public API.\nimpl<T, U> LazyTransform<T, U>\n    where T: Sync,\n          U: Sync\n{\n    /// Get a reference to the transformed value, invoking `f` to transform it\n    /// if the `LazyTransform<T, U>` has yet to be transformed.  It is\n    /// guaranteed that if multiple calls to `get_or_create` race, only one\n    /// will invoke its closure, and every call will receive a reference to the\n    /// newly transformed value.\n    ///\n    /// The closure can only ever be called once, so think carefully about what\n    /// transformation you want to apply!\n    pub fn get_or_create<F>(&self, f: F) -> &U\n        where F: FnOnce(T) -> U\n    {\n        // In addition to being correct, this pattern is vouched for by Hans Boehm\n        // (http://schd.ws/hosted_files/cppcon2016/74/HansWeakAtomics.pdf Page 27)\n        if !self.initialized.load(Ordering::Acquire) {\n            // We *may* not be initialized. We have to block to be certain.\n            let _lock = self.lock.lock().unwrap();\n            if !self.initialized.load(Ordering::Relaxed) {\n                // Ok, we're definitely uninitialized.\n                // Safe to fiddle with the UnsafeCell now, because we're locked,\n                // and there can't be any outstanding references.\n                let value = unsafe { &mut *self.value.get() };\n                let this = match value.take().unwrap() {\n                    ThisOrThat::This(t) => t,\n                    ThisOrThat::That(_) => panic!(), // Can't already be initialized!\n                };\n                *value = Some(ThisOrThat::That(f(this)));\n                self.initialized.store(true, Ordering::Release);\n            } else {\n                // We raced, and someone else initialized us. We can fall\n                // through now.\n            }\n        }\n\n        // We're initialized, our value is immutable, no synchronization needed.\n        self.extract().unwrap()\n    }\n\n    /// Get a reference to the transformed value, returning `Some(&U)` if the\n    /// `LazyTransform<T, U>` has been transformed or `None` if it has not.  It\n    /// is guaranteed that if a reference is returned it is to the transformed\n    /// value inside the the `LazyTransform<T>`.\n    pub fn get(&self) -> Option<&U> {\n        if self.initialized.load(Ordering::Acquire) {\n            // We're initialized, our value is immutable, no synchronization needed.\n            self.extract()\n        } else {\n            None\n        }\n    }\n}\n\nunsafe impl<T, U> Sync for LazyTransform<T, U>\n    where T: Sync + Send,\n          U: Sync\n{\n}\n\nimpl<T, U> Default for LazyTransform<T, U>\n    where T: Sync + Default,\n          U: Sync\n{\n    fn default() -> Self {\n        LazyTransform::new(T::default())\n    }\n}\n\n/// `Lazy<T>` is a lazily initialized synchronized holder type.  You can think\n/// of it as a `LazyTransform` where the initial type doesn't exist.\npub struct Lazy<T> {\n    inner: LazyTransform<(), T>,\n}\n\nimpl<T> Lazy<T> {\n    /// Construct a new, uninitialized `Lazy<T>`.\n    pub fn new() -> Lazy<T> {\n        Self::default()\n    }\n\n    /// Unwrap the contained value, returning `Some` if the `Lazy<T>` has been initialized\n    /// or `None` if it has not.\n    pub fn into_inner(self) -> Option<T> {\n        self.inner.into_inner().ok()\n    }\n}\n\nimpl<T> Lazy<T>\n    where T: Sync\n{\n    /// Get a reference to the contained value, invoking `f` to create it\n    /// if the `Lazy<T>` is uninitialized.  It is guaranteed that if multiple\n    /// calls to `get_or_create` race, only one will invoke its closure, and\n    /// every call will receive a reference to the newly created value.\n    ///\n    /// The value stored in the `Lazy<T>` is immutable after the closure returns\n    /// it, so think carefully about what you want to put inside!\n    pub fn get_or_create<F>(&self, f: F) -> &T\n        where F: FnOnce() -> T\n    {\n        self.inner.get_or_create(|_| f())\n    }\n\n    /// Get a reference to the contained value, returning `Some(ref)` if the\n    /// `Lazy<T>` has been initialized or `None` if it has not.  It is\n    /// guaranteed that if a reference is returned it is to the value inside\n    /// the `Lazy<T>`.\n    pub fn get(&self) -> Option<&T> {\n        self.inner.get()\n    }\n}\n\n// `#[derive(Default)]` automatically adds `T: Default` trait bound, but that\n// is too restrictive, because `Lazy<T>` always has a default value for any `T`.\nimpl<T> Default for Lazy<T> {\n    fn default() -> Self {\n        Lazy { inner: LazyTransform::new(()) }\n    }\n}\n\nimpl<T> fmt::Debug for Lazy<T>\n    where T: fmt::Debug + Sync\n{\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        if let Some(v) = self.get() {\n            f.write_fmt(format_args!(\"Lazy({:?})\", v))\n        } else {\n            f.write_str(\"Lazy(<uninitialized>)\")\n        }\n    }\n}\n\n#[cfg(test)]\nextern crate scoped_pool;\n\n#[cfg(test)]\nmod tests {\n\n    use scoped_pool::Pool;\n    use std::{thread, time};\n    use std::sync::atomic::{AtomicUsize, Ordering};\n    use super::{Lazy, LazyTransform};\n\n    #[test]\n    fn test_lazy() {\n        let lazy_value: Lazy<u8> = Lazy::new();\n\n        assert_eq!(lazy_value.get(), None);\n\n        let n = AtomicUsize::new(0);\n\n        let pool = Pool::new(100);\n        pool.scoped(|scope| {\n            for _ in 0..100 {\n                let lazy_ref = &lazy_value;\n                let n_ref = &n;\n                scope.execute(move || {\n                    let ten_millis = time::Duration::from_millis(10);\n                    thread::sleep(ten_millis);\n\n                    let value = *lazy_ref.get_or_create(|| {\n                        // Make everybody else wait on me, because I'm a jerk.\n                        thread::sleep(ten_millis);\n\n                        // Make this relaxed so it doesn't interfere with\n                        // Lazy internals at all.\n                        n_ref.fetch_add(1, Ordering::Relaxed);\n\n                        42\n                    });\n                    assert_eq!(value, 42);\n\n                    let value = lazy_ref.get();\n                    assert_eq!(value, Some(&42));\n                });\n            }\n        });\n\n        assert_eq!(n.load(Ordering::SeqCst), 1);\n    }\n\n    #[test]\n    fn test_lazy_transform() {\n        let lazy_value: LazyTransform<u8, u8> = LazyTransform::new(21);\n\n        assert_eq!(lazy_value.get(), None);\n\n        let n = AtomicUsize::new(0);\n\n        let pool = Pool::new(100);\n        pool.scoped(|scope| {\n            for _ in 0..100 {\n                let lazy_ref = &lazy_value;\n                let n_ref = &n;\n                scope.execute(move || {\n                    let ten_millis = time::Duration::from_millis(10);\n                    thread::sleep(ten_millis);\n\n                    let value = *lazy_ref.get_or_create(|v| {\n                        // Make everybody else wait on me, because I'm a jerk.\n                        thread::sleep(ten_millis);\n\n                        // Make this relaxed so it doesn't interfere with\n                        // Lazy internals at all.\n                        n_ref.fetch_add(1, Ordering::Relaxed);\n\n                        v * 2\n                    });\n                    assert_eq!(value, 42);\n\n                    let value = lazy_ref.get();\n                    assert_eq!(value, Some(&42));\n                });\n            }\n        });\n\n        assert_eq!(n.load(Ordering::SeqCst), 1);\n    }\n}\n"
  },
  {
    "project": "rust-smallvec",
    "target": 1,
    "commit_id": "19de50108d403efaa7cd979eac3bb97a4432fd4b",
    "func": "// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n// option. This file may not be copied, modified, or distributed\n// except according to those terms.\n\n//! Small vectors in various sizes. These store a certain number of elements inline, and fall back\n//! to the heap for larger allocations.  This can be a useful optimization for improving cache\n//! locality and reducing allocator traffic for workloads that fit within the inline buffer.\n//!\n//! ## no_std support\n//!\n//! By default, `smallvec` depends on `libstd`. However, it can be configured to use the unstable\n//! `liballoc` API instead, for use on platforms that have `liballoc` but not `libstd`.  This\n//! configuration is currently unstable and is not guaranteed to work on all versions of Rust.\n//!\n//! To depend on `smallvec` without `libstd`, use `default-features = false` in the `smallvec`\n//! section of Cargo.toml to disable its `\"std\"` feature.\n//!\n//! ## `union` feature\n//!\n//! When the `union` feature is enabled `smallvec` will track its state (inline or spilled)\n//! without the use of an enum tag, reducing the size of the `smallvec` by one machine word.\n//! This means that there is potentially no space overhead compared to `Vec`.\n//! Note that `smallvec` can still be larger than `Vec` if the inline buffer is larger than two\n//! machine words.\n//!\n//! To use this feature add `features = [\"union\"]` in the `smallvec` section of Cargo.toml.\n//! Note that this feature requires a nightly compiler (for now).\n\n#![cfg_attr(not(feature = \"std\"), no_std)]\n#![cfg_attr(not(feature = \"std\"), feature(alloc))]\n#![cfg_attr(feature = \"union\", feature(untagged_unions))]\n#![cfg_attr(feature = \"specialization\", feature(specialization))]\n#![cfg_attr(feature = \"may_dangle\", feature(dropck_eyepatch))]\n#![deny(missing_docs)]\n\n\n#[cfg(not(feature = \"std\"))]\n#[macro_use]\nextern crate alloc;\n\n#[cfg(not(feature = \"std\"))]\nuse alloc::vec::Vec;\n\n#[cfg(feature = \"serde\")]\nextern crate serde;\n\n#[cfg(not(feature = \"std\"))]\nmod std {\n    pub use core::*;\n}\n\nuse std::borrow::{Borrow, BorrowMut};\nuse std::cmp;\nuse std::fmt;\nuse std::hash::{Hash, Hasher};\nuse std::iter::{IntoIterator, FromIterator, repeat};\nuse std::mem;\nuse std::mem::ManuallyDrop;\nuse std::ops;\nuse std::ptr;\nuse std::slice;\n#[cfg(feature = \"std\")]\nuse std::io;\n#[cfg(feature = \"serde\")]\nuse serde::ser::{Serialize, Serializer, SerializeSeq};\n#[cfg(feature = \"serde\")]\nuse serde::de::{Deserialize, Deserializer, SeqAccess, Visitor};\n#[cfg(feature = \"serde\")]\nuse std::marker::PhantomData;\n\n/// Creates a [`SmallVec`] containing the arguments.\n///\n/// `smallvec!` allows `SmallVec`s to be defined with the same syntax as array expressions.\n/// There are two forms of this macro:\n///\n/// - Create a [`SmallVec`] containing a given list of elements:\n///\n/// ```\n/// # #[macro_use] extern crate smallvec;\n/// # use smallvec::SmallVec;\n/// # fn main() {\n/// let v: SmallVec<[_; 128]> = smallvec![1, 2, 3];\n/// assert_eq!(v[0], 1);\n/// assert_eq!(v[1], 2);\n/// assert_eq!(v[2], 3);\n/// # }\n/// ```\n///\n/// - Create a [`SmallVec`] from a given element and size:\n///\n/// ```\n/// # #[macro_use] extern crate smallvec;\n/// # use smallvec::SmallVec;\n/// # fn main() {\n/// let v: SmallVec<[_; 0x8000]> = smallvec![1; 3];\n/// assert_eq!(v, SmallVec::from_buf([1, 1, 1]));\n/// # }\n/// ```\n///\n/// Note that unlike array expressions this syntax supports all elements\n/// which implement [`Clone`] and the number of elements doesn't have to be\n/// a constant.\n///\n/// This will use `clone` to duplicate an expression, so one should be careful\n/// using this with types having a nonstandard `Clone` implementation. For\n/// example, `smallvec![Rc::new(1); 5]` will create a vector of five references\n/// to the same boxed integer value, not five references pointing to independently\n/// boxed integers.\n\n#[macro_export]\nmacro_rules! smallvec {\n    // count helper: transform any expression into 1\n    (@one $x:expr) => (1usize);\n    ($elem:expr; $n:expr) => ({\n        $crate::SmallVec::from_elem($elem, $n)\n    });\n    ($($x:expr),*$(,)*) => ({\n        let count = 0usize $(+ smallvec!(@one $x))*;\n        let mut vec = $crate::SmallVec::new();\n        if count <= vec.inline_size() {\n            $(vec.push($x);)*\n            vec\n        } else {\n            $crate::SmallVec::from_vec(vec![$($x,)*])\n        }\n    });\n}\n\n/// Hint to the optimizer that any code path which calls this function is\n/// statically unreachable and can be removed.\n///\n/// Equivalent to `std::hint::unreachable_unchecked` but works in older versions of Rust.\n#[inline]\npub unsafe fn unreachable() -> ! {\n    enum Void {}\n    let x: &Void = mem::transmute(1usize);\n    match *x {}\n}\n\n/// `panic!()` in debug builds, optimization hint in release.\n#[cfg(not(feature = \"union\"))]\nmacro_rules! debug_unreachable {\n    () => { debug_unreachable!(\"entered unreachable code\") };\n    ($e:expr) => {\n        if cfg!(not(debug_assertions)) {\n            unreachable();\n        } else {\n            panic!($e);\n        }\n    }\n}\n\n/// Common operations implemented by both `Vec` and `SmallVec`.\n///\n/// This can be used to write generic code that works with both `Vec` and `SmallVec`.\n///\n/// ## Example\n///\n/// ```rust\n/// use smallvec::{VecLike, SmallVec};\n///\n/// fn initialize<V: VecLike<u8>>(v: &mut V) {\n///     for i in 0..5 {\n///         v.push(i);\n///     }\n/// }\n///\n/// let mut vec = Vec::new();\n/// initialize(&mut vec);\n///\n/// let mut small_vec = SmallVec::<[u8; 8]>::new();\n/// initialize(&mut small_vec);\n/// ```\n#[deprecated(note = \"Use `Extend` and `Deref<[T]>` instead\")]\npub trait VecLike<T>:\n        ops::Index<usize, Output=T> +\n        ops::IndexMut<usize> +\n        ops::Index<ops::Range<usize>, Output=[T]> +\n        ops::IndexMut<ops::Range<usize>> +\n        ops::Index<ops::RangeFrom<usize>, Output=[T]> +\n        ops::IndexMut<ops::RangeFrom<usize>> +\n        ops::Index<ops::RangeTo<usize>, Output=[T]> +\n        ops::IndexMut<ops::RangeTo<usize>> +\n        ops::Index<ops::RangeFull, Output=[T]> +\n        ops::IndexMut<ops::RangeFull> +\n        ops::DerefMut<Target = [T]> +\n        Extend<T> {\n\n    /// Append an element to the vector.\n    fn push(&mut self, value: T);\n}\n\n#[allow(deprecated)]\nimpl<T> VecLike<T> for Vec<T> {\n    #[inline]\n    fn push(&mut self, value: T) {\n        Vec::push(self, value);\n    }\n}\n\n/// Trait to be implemented by a collection that can be extended from a slice\n///\n/// ## Example\n///\n/// ```rust\n/// use smallvec::{ExtendFromSlice, SmallVec};\n///\n/// fn initialize<V: ExtendFromSlice<u8>>(v: &mut V) {\n///     v.extend_from_slice(b\"Test!\");\n/// }\n///\n/// let mut vec = Vec::new();\n/// initialize(&mut vec);\n/// assert_eq!(&vec, b\"Test!\");\n///\n/// let mut small_vec = SmallVec::<[u8; 8]>::new();\n/// initialize(&mut small_vec);\n/// assert_eq!(&small_vec as &[_], b\"Test!\");\n/// ```\npub trait ExtendFromSlice<T> {\n    /// Extends a collection from a slice of its element type\n    fn extend_from_slice(&mut self, other: &[T]);\n}\n\nimpl<T: Clone> ExtendFromSlice<T> for Vec<T> {\n    fn extend_from_slice(&mut self, other: &[T]) {\n        Vec::extend_from_slice(self, other)\n    }\n}\n\nunsafe fn deallocate<T>(ptr: *mut T, capacity: usize) {\n    let _vec: Vec<T> = Vec::from_raw_parts(ptr, 0, capacity);\n    // Let it drop.\n}\n\n/// An iterator that removes the items from a `SmallVec` and yields them by value.\n///\n/// Returned from [`SmallVec::drain`][1].\n///\n/// [1]: struct.SmallVec.html#method.drain\npub struct Drain<'a, T: 'a> {\n    iter: slice::IterMut<'a,T>,\n}\n\nimpl<'a, T: 'a> Iterator for Drain<'a,T> {\n    type Item = T;\n\n    #[inline]\n    fn next(&mut self) -> Option<T> {\n        self.iter.next().map(|reference| unsafe { ptr::read(reference) })\n    }\n\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.iter.size_hint()\n    }\n}\n\nimpl<'a, T: 'a> DoubleEndedIterator for Drain<'a, T> {\n    #[inline]\n    fn next_back(&mut self) -> Option<T> {\n        self.iter.next_back().map(|reference| unsafe { ptr::read(reference) })\n    }\n}\n\nimpl<'a, T> ExactSizeIterator for Drain<'a, T> { }\n\nimpl<'a, T: 'a> Drop for Drain<'a,T> {\n    fn drop(&mut self) {\n        // Destroy the remaining elements.\n        for _ in self.by_ref() {}\n    }\n}\n\n#[cfg(feature = \"union\")]\nunion SmallVecData<A: Array> {\n    inline: ManuallyDrop<A>,\n    heap: (*mut A::Item, usize),\n}\n\n#[cfg(feature = \"union\")]\nimpl<A: Array> SmallVecData<A> {\n    #[inline]\n    unsafe fn inline(&self) -> &A {\n        &self.inline\n    }\n    #[inline]\n    unsafe fn inline_mut(&mut self) -> &mut A {\n        &mut self.inline\n    }\n    #[inline]\n    fn from_inline(inline: A) -> SmallVecData<A> {\n        SmallVecData { inline: ManuallyDrop::new(inline) }\n    }\n    #[inline]\n    unsafe fn into_inline(self) -> A { ManuallyDrop::into_inner(self.inline) }\n    #[inline]\n    unsafe fn heap(&self) -> (*mut A::Item, usize) {\n        self.heap\n    }\n    #[inline]\n    unsafe fn heap_mut(&mut self) -> &mut (*mut A::Item, usize) {\n        &mut self.heap\n    }\n    #[inline]\n    fn from_heap(ptr: *mut A::Item, len: usize) -> SmallVecData<A> {\n        SmallVecData { heap: (ptr, len) }\n    }\n}\n\n#[cfg(not(feature = \"union\"))]\nenum SmallVecData<A: Array> {\n    Inline(ManuallyDrop<A>),\n    Heap((*mut A::Item, usize)),\n}\n\n#[cfg(not(feature = \"union\"))]\nimpl<A: Array> SmallVecData<A> {\n    #[inline]\n    unsafe fn inline(&self) -> &A {\n        match *self {\n            SmallVecData::Inline(ref a) => a,\n            _ => debug_unreachable!(),\n        }\n    }\n    #[inline]\n    unsafe fn inline_mut(&mut self) -> &mut A {\n        match *self {\n            SmallVecData::Inline(ref mut a) => a,\n            _ => debug_unreachable!(),\n        }\n    }\n    #[inline]\n    fn from_inline(inline: A) -> SmallVecData<A> {\n        SmallVecData::Inline(ManuallyDrop::new(inline))\n    }\n    #[inline]\n    unsafe fn into_inline(self) -> A {\n        match self {\n            SmallVecData::Inline(a) => ManuallyDrop::into_inner(a),\n            _ => debug_unreachable!(),\n        }\n    }\n    #[inline]\n    unsafe fn heap(&self) -> (*mut A::Item, usize) {\n        match *self {\n            SmallVecData::Heap(data) => data,\n            _ => debug_unreachable!(),\n        }\n    }\n    #[inline]\n    unsafe fn heap_mut(&mut self) -> &mut (*mut A::Item, usize) {\n        match *self {\n            SmallVecData::Heap(ref mut data) => data,\n            _ => debug_unreachable!(),\n        }\n    }\n    #[inline]\n    fn from_heap(ptr: *mut A::Item, len: usize) -> SmallVecData<A> {\n        SmallVecData::Heap((ptr, len))\n    }\n}\n\nunsafe impl<A: Array + Send> Send for SmallVecData<A> {}\nunsafe impl<A: Array + Sync> Sync for SmallVecData<A> {}\n\n/// A `Vec`-like container that can store a small number of elements inline.\n///\n/// `SmallVec` acts like a vector, but can store a limited amount of data inline within the\n/// `SmallVec` struct rather than in a separate allocation.  If the data exceeds this limit, the\n/// `SmallVec` will \"spill\" its data onto the heap, allocating a new buffer to hold it.\n///\n/// The amount of data that a `SmallVec` can store inline depends on its backing store. The backing\n/// store can be any type that implements the `Array` trait; usually it is a small fixed-sized\n/// array.  For example a `SmallVec<[u64; 8]>` can hold up to eight 64-bit integers inline.\n///\n/// ## Example\n///\n/// ```rust\n/// use smallvec::SmallVec;\n/// let mut v = SmallVec::<[u8; 4]>::new(); // initialize an empty vector\n///\n/// // The vector can hold up to 4 items without spilling onto the heap.\n/// v.extend(0..4);\n/// assert_eq!(v.len(), 4);\n/// assert!(!v.spilled());\n///\n/// // Pushing another element will force the buffer to spill:\n/// v.push(4);\n/// assert_eq!(v.len(), 5);\n/// assert!(v.spilled());\n/// ```\npub struct SmallVec<A: Array> {\n    // The capacity field is used to determine which of the storage variants is active:\n    // If capacity <= A::size() then the inline variant is used and capacity holds the current length of the vector (number of elements actually in use).\n    // If capacity > A::size() then the heap variant is used and capacity holds the size of the memory allocation.\n    capacity: usize,\n    data: SmallVecData<A>,\n}\n\nimpl<A: Array> SmallVec<A> {\n    /// Construct an empty vector\n    #[inline]\n    pub fn new() -> SmallVec<A> {\n        unsafe {\n            SmallVec {\n                capacity: 0,\n                data: SmallVecData::from_inline(mem::uninitialized()),\n            }\n        }\n    }\n\n    /// Construct an empty vector with enough capacity pre-allocated to store at least `n`\n    /// elements.\n    ///\n    /// Will create a heap allocation only if `n` is larger than the inline capacity.\n    ///\n    /// ```\n    /// # use smallvec::SmallVec;\n    ///\n    /// let v: SmallVec<[u8; 3]> = SmallVec::with_capacity(100);\n    ///\n    /// assert!(v.is_empty());\n    /// assert!(v.capacity() >= 100);\n    /// ```\n    #[inline]\n    pub fn with_capacity(n: usize) -> Self {\n        let mut v = SmallVec::new();\n        v.reserve_exact(n);\n        v\n    }\n\n    /// Construct a new `SmallVec` from a `Vec<A::Item>`.\n    ///\n    /// Elements will be copied to the inline buffer if vec.capacity() <= A::size().\n    ///\n    /// ```rust\n    /// use smallvec::SmallVec;\n    ///\n    /// let vec = vec![1, 2, 3, 4, 5];\n    /// let small_vec: SmallVec<[_; 3]> = SmallVec::from_vec(vec);\n    ///\n    /// assert_eq!(&*small_vec, &[1, 2, 3, 4, 5]);\n    /// ```\n    #[inline]\n    pub fn from_vec(mut vec: Vec<A::Item>) -> SmallVec<A> {\n        if vec.capacity() <= A::size() {\n            unsafe {\n                let mut data = SmallVecData::<A>::from_inline(mem::uninitialized());\n                let len = vec.len();\n                vec.set_len(0);\n                ptr::copy_nonoverlapping(vec.as_ptr(), data.inline_mut().ptr_mut(), len);\n\n                SmallVec {\n                    capacity: len,\n                    data,\n                }\n            }\n        } else {\n            let (ptr, cap, len) = (vec.as_mut_ptr(), vec.capacity(), vec.len());\n            mem::forget(vec);\n\n            SmallVec {\n                capacity: cap,\n                data: SmallVecData::from_heap(ptr, len),\n            }\n        }\n    }\n\n    /// Constructs a new `SmallVec` on the stack from an `A` without\n    /// copying elements.\n    ///\n    /// ```rust\n    /// use smallvec::SmallVec;\n    ///\n    /// let buf = [1, 2, 3, 4, 5];\n    /// let small_vec: SmallVec<_> = SmallVec::from_buf(buf);\n    ///\n    /// assert_eq!(&*small_vec, &[1, 2, 3, 4, 5]);\n    /// ```\n    #[inline]\n    pub fn from_buf(buf: A) -> SmallVec<A> {\n        SmallVec {\n            capacity: A::size(),\n            data: SmallVecData::from_inline(buf),\n        }\n    }\n\n    /// Constructs a new `SmallVec` on the stack from an `A` without\n    /// copying elements. Also sets the length, which must be less or\n    /// equal to the size of `buf`.\n    ///\n    /// ```rust\n    /// use smallvec::SmallVec;\n    ///\n    /// let buf = [1, 2, 3, 4, 5, 0, 0, 0];\n    /// let small_vec: SmallVec<_> = SmallVec::from_buf_and_len(buf, 5);\n    ///\n    /// assert_eq!(&*small_vec, &[1, 2, 3, 4, 5]);\n    /// ```\n    #[inline]\n    pub fn from_buf_and_len(buf: A, len: usize) -> SmallVec<A> {\n        assert!(len <= A::size());\n        unsafe { SmallVec::from_buf_and_len_unchecked(buf, len) }\n    }\n\n    /// Constructs a new `SmallVec` on the stack from an `A` without\n    /// copying elements. Also sets the length. The user is responsible\n    /// for ensuring that `len <= A::size()`.\n    ///\n    /// ```rust\n    /// use smallvec::SmallVec;\n    ///\n    /// let buf = [1, 2, 3, 4, 5, 0, 0, 0];\n    /// let small_vec: SmallVec<_> = unsafe {\n    ///     SmallVec::from_buf_and_len_unchecked(buf, 5)\n    /// };\n    ///\n    /// assert_eq!(&*small_vec, &[1, 2, 3, 4, 5]);\n    /// ```\n    #[inline]\n    pub unsafe fn from_buf_and_len_unchecked(buf: A, len: usize) -> SmallVec<A> {\n        SmallVec {\n            capacity: len,\n            data: SmallVecData::from_inline(buf),\n        }\n    }\n\n\n    /// Sets the length of a vector.\n    ///\n    /// This will explicitly set the size of the vector, without actually\n    /// modifying its buffers, so it is up to the caller to ensure that the\n    /// vector is actually the specified size.\n    pub unsafe fn set_len(&mut self, new_len: usize) {\n        let (_, len_ptr, _) = self.triple_mut();\n        *len_ptr = new_len;\n    }\n\n    /// The maximum number of elements this vector can hold inline\n    #[inline]\n    pub fn inline_size(&self) -> usize {\n        A::size()\n    }\n\n    /// The number of elements stored in the vector\n    #[inline]\n    pub fn len(&self) -> usize {\n        self.triple().1\n    }\n\n    /// Returns `true` if the vector is empty\n    #[inline]\n    pub fn is_empty(&self) -> bool {\n        self.len() == 0\n    }\n\n    /// The number of items the vector can hold without reallocating\n    #[inline]\n    pub fn capacity(&self) -> usize {\n        self.triple().2\n    }\n\n    /// Returns a tuple with (data ptr, len, capacity)\n    /// Useful to get all SmallVec properties with a single check of the current storage variant.\n    #[inline]\n    fn triple(&self) -> (*const A::Item, usize, usize) {\n        unsafe {\n            if self.spilled() {\n                let (ptr, len) = self.data.heap();\n                (ptr, len, self.capacity)\n            } else {\n                (self.data.inline().ptr(), self.capacity, A::size())\n            }\n        }\n    }\n\n    /// Returns a tuple with (data ptr, len ptr, capacity)\n    #[inline]\n    fn triple_mut(&mut self) -> (*mut A::Item, &mut usize, usize) {\n        unsafe {\n            if self.spilled() {\n                let &mut (ptr, ref mut len_ptr) = self.data.heap_mut();\n                (ptr, len_ptr, self.capacity)\n            } else {\n                (self.data.inline_mut().ptr_mut(), &mut self.capacity, A::size())\n            }\n        }\n    }\n\n    /// Returns `true` if the data has spilled into a separate heap-allocated buffer.\n    #[inline]\n    pub fn spilled(&self) -> bool {\n        self.capacity > A::size()\n    }\n\n    /// Empty the vector and return an iterator over its former contents.\n    pub fn drain(&mut self) -> Drain<A::Item> {\n        unsafe {\n            let ptr = self.as_mut_ptr();\n\n            let current_len = self.len();\n            self.set_len(0);\n\n            let slice = slice::from_raw_parts_mut(ptr, current_len);\n\n            Drain {\n                iter: slice.iter_mut(),\n            }\n        }\n    }\n\n    /// Append an item to the vector.\n    #[inline]\n    pub fn push(&mut self, value: A::Item) {\n        unsafe {\n            let (_, &mut len, cap) = self.triple_mut();\n            if len == cap {\n                self.reserve(1);\n            }\n            let (ptr, len_ptr, _) = self.triple_mut();\n            *len_ptr = len + 1;\n            ptr::write(ptr.offset(len as isize), value);\n        }\n    }\n\n    /// Remove an item from the end of the vector and return it, or None if empty.\n    #[inline]\n    pub fn pop(&mut self) -> Option<A::Item> {\n        unsafe {\n            let (ptr, len_ptr, _) = self.triple_mut();\n            if *len_ptr == 0 {\n                return None;\n            }\n            let last_index = *len_ptr - 1;\n            *len_ptr = last_index;\n            Some(ptr::read(ptr.offset(last_index as isize)))\n        }\n    }\n\n    /// Re-allocate to set the capacity to `max(new_cap, inline_size())`.\n    ///\n    /// Panics if `new_cap` is less than the vector's length.\n    pub fn grow(&mut self, new_cap: usize) {\n        unsafe {\n            let (ptr, &mut len, cap) = self.triple_mut();\n            let unspilled = !self.spilled();\n            assert!(new_cap >= len);\n            if new_cap <= self.inline_size() {\n                if unspilled {\n                    return;\n                }\n                self.data = SmallVecData::from_inline(mem::uninitialized());\n                ptr::copy_nonoverlapping(ptr, self.data.inline_mut().ptr_mut(), len);\n            } else if new_cap != cap {\n                let mut vec = Vec::with_capacity(new_cap);\n                let new_alloc = vec.as_mut_ptr();\n                mem::forget(vec);\n                ptr::copy_nonoverlapping(ptr, new_alloc, len);\n                self.data = SmallVecData::from_heap(new_alloc, len);\n                self.capacity = new_cap;\n                if unspilled {\n                    return;\n                }\n            }\n            deallocate(ptr, cap);\n        }\n    }\n\n    /// Reserve capacity for `additional` more elements to be inserted.\n    ///\n    /// May reserve more space to avoid frequent reallocations.\n    ///\n    /// If the new capacity would overflow `usize` then it will be set to `usize::max_value()`\n    /// instead. (This means that inserting `additional` new elements is not guaranteed to be\n    /// possible after calling this function.)\n    #[inline]\n    pub fn reserve(&mut self, additional: usize) {\n        // prefer triple_mut() even if triple() would work\n        // so that the optimizer removes duplicated calls to it\n        // from callers like insert()\n        let (_, &mut len, cap) = self.triple_mut();\n        if cap - len < additional {\n            let new_cap = len.checked_add(additional).\n                and_then(usize::checked_next_power_of_two).\n                unwrap_or(usize::max_value());\n            self.grow(new_cap);\n        }\n    }\n\n    /// Reserve the minimum capacity for `additional` more elements to be inserted.\n    ///\n    /// Panics if the new capacity overflows `usize`.\n    pub fn reserve_exact(&mut self, additional: usize) {\n        let (_, &mut len, cap) = self.triple_mut();\n        if cap - len < additional {\n            match len.checked_add(additional) {\n                Some(cap) => self.grow(cap),\n                None => panic!(\"reserve_exact overflow\"),\n            }\n        }\n    }\n\n    /// Shrink the capacity of the vector as much as possible.\n    ///\n    /// When possible, this will move data from an external heap buffer to the vector's inline\n    /// storage.\n    pub fn shrink_to_fit(&mut self) {\n        if !self.spilled() {\n            return;\n        }\n        let len = self.len();\n        if self.inline_size() >= len {\n            unsafe {\n                let (ptr, len) = self.data.heap();\n                self.data = SmallVecData::from_inline(mem::uninitialized());\n                ptr::copy_nonoverlapping(ptr, self.data.inline_mut().ptr_mut(), len);\n                deallocate(ptr, self.capacity);\n                self.capacity = len;\n            }\n        } else if self.capacity() > len {\n            self.grow(len);\n        }\n    }\n\n    /// Shorten the vector, keeping the first `len` elements and dropping the rest.\n    ///\n    /// If `len` is greater than or equal to the vector's current length, this has no\n    /// effect.\n    ///\n    /// This does not re-allocate.  If you want the vector's capacity to shrink, call\n    /// `shrink_to_fit` after truncating.\n    pub fn truncate(&mut self, len: usize) {\n        unsafe {\n            let (ptr, len_ptr, _) = self.triple_mut();\n            while len < *len_ptr {\n                let last_index = *len_ptr - 1;\n                *len_ptr = last_index;\n                ptr::drop_in_place(ptr.offset(last_index as isize));\n            }\n        }\n    }\n\n    /// Extracts a slice containing the entire vector.\n    ///\n    /// Equivalent to `&s[..]`.\n    pub fn as_slice(&self) -> &[A::Item] {\n        self\n    }\n\n    /// Extracts a mutable slice of the entire vector.\n    ///\n    /// Equivalent to `&mut s[..]`.\n    pub fn as_mut_slice(&mut self) -> &mut [A::Item] {\n        self\n    }\n\n    /// Remove the element at position `index`, replacing it with the last element.\n    ///\n    /// This does not preserve ordering, but is O(1).\n    ///\n    /// Panics if `index` is out of bounds.\n    #[inline]\n    pub fn swap_remove(&mut self, index: usize) -> A::Item {\n        let len = self.len();\n        self.swap(len - 1, index);\n        self.pop().unwrap_or_else(|| unsafe { unreachable() })\n    }\n\n    /// Remove all elements from the vector.\n    #[inline]\n    pub fn clear(&mut self) {\n        self.truncate(0);\n    }\n\n    /// Remove and return the element at position `index`, shifting all elements after it to the\n    /// left.\n    ///\n    /// Panics if `index` is out of bounds.\n    pub fn remove(&mut self, index: usize) -> A::Item {\n        unsafe {\n            let (mut ptr, len_ptr, _) = self.triple_mut();\n            let len = *len_ptr;\n            assert!(index < len);\n            *len_ptr = len - 1;\n            ptr = ptr.offset(index as isize);\n            let item = ptr::read(ptr);\n            ptr::copy(ptr.offset(1), ptr, len - index - 1);\n            item\n        }\n    }\n\n    /// Insert an element at position `index`, shifting all elements after it to the right.\n    ///\n    /// Panics if `index` is out of bounds.\n    pub fn insert(&mut self, index: usize, element: A::Item) {\n        self.reserve(1);\n\n        unsafe {\n            let (mut ptr, len_ptr, _) = self.triple_mut();\n            let len = *len_ptr;\n            assert!(index <= len);\n            *len_ptr = len + 1;\n            ptr = ptr.offset(index as isize);\n            ptr::copy(ptr, ptr.offset(1), len - index);\n            ptr::write(ptr, element);\n        }\n    }\n\n    /// Insert multiple elements at position `index`, shifting all following elements toward the\n    /// back.\n    pub fn insert_many<I: IntoIterator<Item=A::Item>>(&mut self, index: usize, iterable: I) {\n        let iter = iterable.into_iter();\n        if index == self.len() {\n            return self.extend(iter);\n        }\n\n        let (lower_size_bound, _) = iter.size_hint();\n        assert!(lower_size_bound <= std::isize::MAX as usize);  // Ensure offset is indexable\n        assert!(index + lower_size_bound >= index);  // Protect against overflow\n        self.reserve(lower_size_bound);\n\n        unsafe {\n            let old_len = self.len();\n            assert!(index <= old_len);\n            let mut ptr = self.as_mut_ptr().offset(index as isize);\n\n            // Move the trailing elements.\n            ptr::copy(ptr, ptr.offset(lower_size_bound as isize), old_len - index);\n\n            // In case the iterator panics, don't double-drop the items we just copied above.\n            self.set_len(index);\n\n            let mut num_added = 0;\n            for element in iter {\n                let mut cur = ptr.offset(num_added as isize);\n                if num_added >= lower_size_bound {\n                    // Iterator provided more elements than the hint.  Move trailing items again.\n                    self.reserve(1);\n                    ptr = self.as_mut_ptr().offset(index as isize);\n                    cur = ptr.offset(num_added as isize);\n                    ptr::copy(cur, cur.offset(1), old_len - index);\n                }\n                ptr::write(cur, element);\n                num_added += 1;\n            }\n            if num_added < lower_size_bound {\n                // Iterator provided fewer elements than the hint\n                ptr::copy(ptr.offset(lower_size_bound as isize), ptr.offset(num_added as isize), old_len - index);\n            }\n\n            self.set_len(old_len + num_added);\n        }\n    }\n\n    /// Convert a SmallVec to a Vec, without reallocating if the SmallVec has already spilled onto\n    /// the heap.\n    pub fn into_vec(self) -> Vec<A::Item> {\n        if self.spilled() {\n            unsafe {\n                let (ptr, len) = self.data.heap();\n                let v = Vec::from_raw_parts(ptr, len, self.capacity);\n                mem::forget(self);\n                v\n            }\n        } else {\n            self.into_iter().collect()\n        }\n    }\n\n    /// Convert the SmallVec into an `A` if possible. Otherwise return `Err(Self)`.\n    ///\n    /// This method returns `Err(Self)` if the SmallVec is too short (and the `A` contains uninitialized elements),\n    /// or if the SmallVec is too long (and all the elements were spilled to the heap).\n    pub fn into_inner(self) -> Result<A, Self> {\n        if self.spilled() || self.len() != A::size() {\n            Err(self)\n        } else {\n            unsafe {\n                let data = ptr::read(&self.data);\n                mem::forget(self);\n                Ok(data.into_inline())\n            }\n        }\n    }\n\n    /// Retains only the elements specified by the predicate.\n    ///\n    /// In other words, remove all elements `e` such that `f(&e)` returns `false`.\n    /// This method operates in place and preserves the order of the retained\n    /// elements.\n    pub fn retain<F: FnMut(&mut A::Item) -> bool>(&mut self, mut f: F) {\n        let mut del = 0;\n        let len = self.len();\n        for i in 0..len {\n            if !f(&mut self[i]) {\n                del += 1;\n            } else if del > 0 {\n                self.swap(i - del, i);\n            }\n        }\n        self.truncate(len - del);\n    }\n\n    /// Removes consecutive duplicate elements.\n    pub fn dedup(&mut self) where A::Item: PartialEq<A::Item> {\n        self.dedup_by(|a, b| a == b);\n    }\n\n    /// Removes consecutive duplicate elements using the given equality relation.\n    pub fn dedup_by<F>(&mut self, mut same_bucket: F)\n        where F: FnMut(&mut A::Item, &mut A::Item) -> bool\n    {\n        // See the implementation of Vec::dedup_by in the\n        // standard library for an explanation of this algorithm.\n        let len = self.len();\n        if len <= 1 {\n            return;\n        }\n\n        let ptr = self.as_mut_ptr();\n        let mut w: usize = 1;\n\n        unsafe {\n            for r in 1..len {\n                let p_r = ptr.offset(r as isize);\n                let p_wm1 = ptr.offset((w - 1) as isize);\n                if !same_bucket(&mut *p_r, &mut *p_wm1) {\n                    if r != w {\n                        let p_w = p_wm1.offset(1);\n                        mem::swap(&mut *p_r, &mut *p_w);\n                    }\n                    w += 1;\n                }\n            }\n        }\n\n        self.truncate(w);\n    }\n\n    /// Removes consecutive elements that map to the same key.\n    pub fn dedup_by_key<F, K>(&mut self, mut key: F)\n        where F: FnMut(&mut A::Item) -> K,\n              K: PartialEq<K>\n    {\n        self.dedup_by(|a, b| key(a) == key(b));\n    }\n\n    /// Creates a `SmallVec` directly from the raw components of another\n    /// `SmallVec`.\n    ///\n    /// # Safety\n    ///\n    /// This is highly unsafe, due to the number of invariants that aren't\n    /// checked:\n    ///\n    /// * `ptr` needs to have been previously allocated via `SmallVec` for its\n    ///   spilled storage (at least, it's highly likely to be incorrect if it\n    ///   wasn't).\n    /// * `ptr`'s `A::Item` type needs to be the same size and alignment that\n    ///   it was allocated with\n    /// * `length` needs to be less than or equal to `capacity`.\n    /// * `capacity` needs to be the capacity that the pointer was allocated\n    ///   with.\n    ///\n    /// Violating these may cause problems like corrupting the allocator's\n    /// internal data structures.\n    ///\n    /// Additionally, `capacity` must be greater than the amount of inline\n    /// storage `A` has; that is, the new `SmallVec` must need to spill over\n    /// into heap allocated storage. This condition is asserted against.\n    ///\n    /// The ownership of `ptr` is effectively transferred to the\n    /// `SmallVec` which may then deallocate, reallocate or change the\n    /// contents of memory pointed to by the pointer at will. Ensure\n    /// that nothing else uses the pointer after calling this\n    /// function.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[macro_use] extern crate smallvec;\n    /// # use smallvec::SmallVec;\n    /// use std::mem;\n    /// use std::ptr;\n    ///\n    /// fn main() {\n    ///     let mut v: SmallVec<[_; 1]> = smallvec![1, 2, 3];\n    ///\n    ///     // Pull out the important parts of `v`.\n    ///     let p = v.as_mut_ptr();\n    ///     let len = v.len();\n    ///     let cap = v.capacity();\n    ///     let spilled = v.spilled();\n    ///\n    ///     unsafe {\n    ///         // Forget all about `v`. The heap allocation that stored the\n    ///         // three values won't be deallocated.\n    ///         mem::forget(v);\n    ///\n    ///         // Overwrite memory with [4, 5, 6].\n    ///         //\n    ///         // This is only safe if `spilled` is true! Otherwise, we are\n    ///         // writing into the old `SmallVec`'s inline storage on the\n    ///         // stack.\n    ///         assert!(spilled);\n    ///         for i in 0..len as isize {\n    ///             ptr::write(p.offset(i), 4 + i);\n    ///         }\n    ///\n    ///         // Put everything back together into a SmallVec with a different\n    ///         // amount of inline storage, but which is still less than `cap`.\n    ///         let rebuilt = SmallVec::<[_; 2]>::from_raw_parts(p, len, cap);\n    ///         assert_eq!(&*rebuilt, &[4, 5, 6]);\n    ///     }\n    /// }\n    pub unsafe fn from_raw_parts(\n        ptr: *mut A::Item,\n        length: usize,\n        capacity: usize,\n    ) -> SmallVec<A> {\n        assert!(capacity > A::size());\n        SmallVec {\n            capacity,\n            data: SmallVecData::from_heap(ptr, length),\n        }\n    }\n}\n\nimpl<A: Array> SmallVec<A> where A::Item: Copy {\n    /// Copy the elements from a slice into a new `SmallVec`.\n    ///\n    /// For slices of `Copy` types, this is more efficient than `SmallVec::from(slice)`.\n    pub fn from_slice(slice: &[A::Item]) -> Self {\n        let len = slice.len();\n        if len <= A::size() {\n            SmallVec {\n                capacity: len,\n                data: SmallVecData::from_inline(unsafe {\n                    let mut data: A = mem::uninitialized();\n                    ptr::copy_nonoverlapping(slice.as_ptr(), data.ptr_mut(), len);\n                    data\n                })\n            }\n        } else {\n            let mut b = slice.to_vec();\n            let (ptr, cap) = (b.as_mut_ptr(), b.capacity());\n            mem::forget(b);\n            SmallVec {\n                capacity: cap,\n                data: SmallVecData::from_heap(ptr, len),\n            }\n        }\n    }\n\n    /// Copy elements from a slice into the vector at position `index`, shifting any following\n    /// elements toward the back.\n    ///\n    /// For slices of `Copy` types, this is more efficient than `insert`.\n    pub fn insert_from_slice(&mut self, index: usize, slice: &[A::Item]) {\n        self.reserve(slice.len());\n\n        let len = self.len();\n        assert!(index <= len);\n\n        unsafe {\n            let slice_ptr = slice.as_ptr();\n            let ptr = self.as_mut_ptr().offset(index as isize);\n            ptr::copy(ptr, ptr.offset(slice.len() as isize), len - index);\n            ptr::copy_nonoverlapping(slice_ptr, ptr, slice.len());\n            self.set_len(len + slice.len());\n        }\n    }\n\n    /// Copy elements from a slice and append them to the vector.\n    ///\n    /// For slices of `Copy` types, this is more efficient than `extend`.\n    #[inline]\n    pub fn extend_from_slice(&mut self, slice: &[A::Item]) {\n        let len = self.len();\n        self.insert_from_slice(len, slice);\n    }\n}\n\nimpl<A: Array> SmallVec<A> where A::Item: Clone {\n    /// Resizes the vector so that its length is equal to `len`.\n    ///\n    /// If `len` is less than the current length, the vector simply truncated.\n    ///\n    /// If `len` is greater than the current length, `value` is appended to the\n    /// vector until its length equals `len`.\n    pub fn resize(&mut self, len: usize, value: A::Item) {\n        let old_len = self.len();\n\n        if len > old_len {\n            self.extend(repeat(value).take(len - old_len));\n        } else {\n            self.truncate(len);\n        }\n    }\n\n    /// Creates a `SmallVec` with `n` copies of `elem`.\n    /// ```\n    /// use smallvec::SmallVec;\n    ///\n    /// let v = SmallVec::<[char; 128]>::from_elem('d', 2);\n    /// assert_eq!(v, SmallVec::from_buf(['d', 'd']));\n    /// ```\n    pub fn from_elem(elem: A::Item, n: usize) -> Self {\n        if n > A::size() {\n            vec![elem; n].into()\n        } else {\n            let mut v = SmallVec::<A>::new();\n            unsafe {\n                let (ptr, len_ptr, _) = v.triple_mut();\n                let mut local_len = SetLenOnDrop::new(len_ptr);\n\n                for i in 0..n as isize {\n                    ::std::ptr::write(ptr.offset(i), elem.clone());\n                    local_len.increment_len(1);\n                }\n            }\n            v\n        }\n    }\n}\n\nimpl<A: Array> ops::Deref for SmallVec<A> {\n    type Target = [A::Item];\n    #[inline]\n    fn deref(&self) -> &[A::Item] {\n        unsafe {\n            let (ptr, len, _) = self.triple();\n            slice::from_raw_parts(ptr, len)\n        }\n    }\n}\n\nimpl<A: Array> ops::DerefMut for SmallVec<A> {\n    #[inline]\n    fn deref_mut(&mut self) -> &mut [A::Item] {\n        unsafe {\n            let (ptr, &mut len, _) = self.triple_mut();\n            slice::from_raw_parts_mut(ptr, len)\n        }\n    }\n}\n\nimpl<A: Array> AsRef<[A::Item]> for SmallVec<A> {\n    #[inline]\n    fn as_ref(&self) -> &[A::Item] {\n        self\n    }\n}\n\nimpl<A: Array> AsMut<[A::Item]> for SmallVec<A> {\n    #[inline]\n    fn as_mut(&mut self) -> &mut [A::Item] {\n        self\n    }\n}\n\nimpl<A: Array> Borrow<[A::Item]> for SmallVec<A> {\n    #[inline]\n    fn borrow(&self) -> &[A::Item] {\n        self\n    }\n}\n\nimpl<A: Array> BorrowMut<[A::Item]> for SmallVec<A> {\n    #[inline]\n    fn borrow_mut(&mut self) -> &mut [A::Item] {\n        self\n    }\n}\n\n#[cfg(feature = \"std\")]\nimpl<A: Array<Item = u8>> io::Write for SmallVec<A> {\n    #[inline]\n    fn write(&mut self, buf: &[u8]) -> io::Result<usize> {\n        self.extend_from_slice(buf);\n        Ok(buf.len())\n    }\n\n    #[inline]\n    fn write_all(&mut self, buf: &[u8]) -> io::Result<()> {\n        self.extend_from_slice(buf);\n        Ok(())\n    }\n\n    #[inline]\n    fn flush(&mut self) -> io::Result<()> {\n        Ok(())\n    }\n}\n\n#[cfg(feature = \"serde\")]\nimpl<A: Array> Serialize for SmallVec<A> where A::Item: Serialize {\n    fn serialize<S: Serializer>(&self, serializer: S) -> Result<S::Ok, S::Error> {\n        let mut state = serializer.serialize_seq(Some(self.len()))?;\n        for item in self {\n            state.serialize_element(&item)?;\n        }\n        state.end()\n    }\n}\n\n#[cfg(feature = \"serde\")]\nimpl<'de, A: Array> Deserialize<'de> for SmallVec<A> where A::Item: Deserialize<'de> {\n    fn deserialize<D: Deserializer<'de>>(deserializer: D) -> Result<Self, D::Error> {\n        deserializer.deserialize_seq(SmallVecVisitor{phantom: PhantomData})\n    }\n}\n\n#[cfg(feature = \"serde\")]\nstruct SmallVecVisitor<A> {\n    phantom: PhantomData<A>\n}\n\n#[cfg(feature = \"serde\")]\nimpl<'de, A: Array> Visitor<'de> for SmallVecVisitor<A>\nwhere A::Item: Deserialize<'de>,\n{\n    type Value = SmallVec<A>;\n\n    fn expecting(&self, formatter: &mut fmt::Formatter) -> fmt::Result {\n        formatter.write_str(\"a sequence\")\n    }\n\n    fn visit_seq<B>(self, mut seq: B) -> Result<Self::Value, B::Error>\n        where\n            B: SeqAccess<'de>,\n    {\n        let len = seq.size_hint().unwrap_or(0);\n        let mut values = SmallVec::with_capacity(len);\n\n        while let Some(value) = seq.next_element()? {\n            values.push(value);\n        }\n\n        Ok(values)\n    }\n}\n\n\n#[cfg(feature = \"specialization\")]\ntrait SpecFrom<A: Array, S> {\n    fn spec_from(slice: S) -> SmallVec<A>;\n}\n\n#[cfg(feature = \"specialization\")]\nimpl<'a, A: Array> SpecFrom<A, &'a [A::Item]> for SmallVec<A> where A::Item: Clone {\n    #[inline]\n    default fn spec_from(slice: &'a [A::Item]) -> SmallVec<A> {\n        slice.into_iter().cloned().collect()\n    }\n}\n\n#[cfg(feature = \"specialization\")]\nimpl<'a, A: Array> SpecFrom<A, &'a [A::Item]> for SmallVec<A> where A::Item: Copy {\n    #[inline]\n    fn spec_from(slice: &'a [A::Item]) -> SmallVec<A> {\n        SmallVec::from_slice(slice)\n    }\n}\n\nimpl<'a, A: Array> From<&'a [A::Item]> for SmallVec<A> where A::Item: Clone {\n    #[cfg(not(feature = \"specialization\"))]\n    #[inline]\n    fn from(slice: &'a [A::Item]) -> SmallVec<A> {\n        slice.into_iter().cloned().collect()\n    }\n\n    #[cfg(feature = \"specialization\")]\n    #[inline]\n    fn from(slice: &'a [A::Item]) -> SmallVec<A> {\n        SmallVec::spec_from(slice)\n    }\n}\n\nimpl<A: Array> From<Vec<A::Item>> for SmallVec<A> {\n    #[inline]\n    fn from(vec: Vec<A::Item>) -> SmallVec<A> {\n        SmallVec::from_vec(vec)\n    }\n}\n\nimpl<A: Array> From<A> for SmallVec<A> {\n    #[inline]\n    fn from(array: A) -> SmallVec<A> {\n        SmallVec::from_buf(array)\n    }\n}\n\nmacro_rules! impl_index {\n    ($index_type: ty, $output_type: ty) => {\n        impl<A: Array> ops::Index<$index_type> for SmallVec<A> {\n            type Output = $output_type;\n            #[inline]\n            fn index(&self, index: $index_type) -> &$output_type {\n                &(&**self)[index]\n            }\n        }\n\n        impl<A: Array> ops::IndexMut<$index_type> for SmallVec<A> {\n            #[inline]\n            fn index_mut(&mut self, index: $index_type) -> &mut $output_type {\n                &mut (&mut **self)[index]\n            }\n        }\n    }\n}\n\nimpl_index!(usize, A::Item);\nimpl_index!(ops::Range<usize>, [A::Item]);\nimpl_index!(ops::RangeFrom<usize>, [A::Item]);\nimpl_index!(ops::RangeTo<usize>, [A::Item]);\nimpl_index!(ops::RangeFull, [A::Item]);\n\nimpl<A: Array> ExtendFromSlice<A::Item> for SmallVec<A> where A::Item: Copy {\n    fn extend_from_slice(&mut self, other: &[A::Item]) {\n        SmallVec::extend_from_slice(self, other)\n    }\n}\n\n#[allow(deprecated)]\nimpl<A: Array> VecLike<A::Item> for SmallVec<A> {\n    #[inline]\n    fn push(&mut self, value: A::Item) {\n        SmallVec::push(self, value);\n    }\n}\n\nimpl<A: Array> FromIterator<A::Item> for SmallVec<A> {\n    fn from_iter<I: IntoIterator<Item=A::Item>>(iterable: I) -> SmallVec<A> {\n        let mut v = SmallVec::new();\n        v.extend(iterable);\n        v\n    }\n}\n\nimpl<A: Array> Extend<A::Item> for SmallVec<A> {\n    fn extend<I: IntoIterator<Item=A::Item>>(&mut self, iterable: I) {\n        let mut iter = iterable.into_iter();\n        let (lower_size_bound, _) = iter.size_hint();\n        self.reserve(lower_size_bound);\n\n        unsafe {\n            let (ptr, len_ptr, cap) = self.triple_mut();\n            let mut len = SetLenOnDrop::new(len_ptr);\n            while len.get() < cap {\n                if let Some(out) = iter.next() {\n                    ptr::write(ptr.offset(len.get() as isize), out);\n                    len.increment_len(1);\n                } else {\n                    break;\n                }\n            }\n        }\n\n        for elem in iter {\n            self.push(elem);\n        }\n    }\n}\n\nimpl<A: Array> fmt::Debug for SmallVec<A> where A::Item: fmt::Debug {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        f.debug_list().entries(self.iter()).finish()\n    }\n}\n\nimpl<A: Array> Default for SmallVec<A> {\n    #[inline]\n    fn default() -> SmallVec<A> {\n        SmallVec::new()\n    }\n}\n\n#[cfg(feature = \"may_dangle\")]\nunsafe impl<#[may_dangle] A: Array> Drop for SmallVec<A> {\n    fn drop(&mut self) {\n        unsafe {\n            if self.spilled() {\n                let (ptr, len) = self.data.heap();\n                Vec::from_raw_parts(ptr, len, self.capacity);\n            } else {\n                ptr::drop_in_place(&mut self[..]);\n            }\n        }\n    }\n}\n\n#[cfg(not(feature = \"may_dangle\"))]\nimpl<A: Array> Drop for SmallVec<A> {\n    fn drop(&mut self) {\n        unsafe {\n            if self.spilled() {\n                let (ptr, len) = self.data.heap();\n                Vec::from_raw_parts(ptr, len, self.capacity);\n            } else {\n                ptr::drop_in_place(&mut self[..]);\n            }\n        }\n    }\n}\n\nimpl<A: Array> Clone for SmallVec<A> where A::Item: Clone {\n    fn clone(&self) -> SmallVec<A> {\n        let mut new_vector = SmallVec::with_capacity(self.len());\n        for element in self.iter() {\n            new_vector.push((*element).clone())\n        }\n        new_vector\n    }\n}\n\nimpl<A: Array, B: Array> PartialEq<SmallVec<B>> for SmallVec<A>\n    where A::Item: PartialEq<B::Item> {\n    #[inline]\n    fn eq(&self, other: &SmallVec<B>) -> bool { self[..] == other[..] }\n    #[inline]\n    fn ne(&self, other: &SmallVec<B>) -> bool { self[..] != other[..] }\n}\n\nimpl<A: Array> Eq for SmallVec<A> where A::Item: Eq {}\n\nimpl<A: Array> PartialOrd for SmallVec<A> where A::Item: PartialOrd {\n    #[inline]\n    fn partial_cmp(&self, other: &SmallVec<A>) -> Option<cmp::Ordering> {\n        PartialOrd::partial_cmp(&**self, &**other)\n    }\n}\n\nimpl<A: Array> Ord for SmallVec<A> where A::Item: Ord {\n    #[inline]\n    fn cmp(&self, other: &SmallVec<A>) -> cmp::Ordering {\n        Ord::cmp(&**self, &**other)\n    }\n}\n\nimpl<A: Array> Hash for SmallVec<A> where A::Item: Hash {\n    fn hash<H: Hasher>(&self, state: &mut H) {\n        (**self).hash(state)\n    }\n}\n\nunsafe impl<A: Array> Send for SmallVec<A> where A::Item: Send {}\n\n/// An iterator that consumes a `SmallVec` and yields its items by value.\n///\n/// Returned from [`SmallVec::into_iter`][1].\n///\n/// [1]: struct.SmallVec.html#method.into_iter\npub struct IntoIter<A: Array> {\n    data: SmallVec<A>,\n    current: usize,\n    end: usize,\n}\n\nimpl<A: Array> Drop for IntoIter<A> {\n    fn drop(&mut self) {\n        for _ in self { }\n    }\n}\n\nimpl<A: Array> Iterator for IntoIter<A> {\n    type Item = A::Item;\n\n    #[inline]\n    fn next(&mut self) -> Option<A::Item> {\n        if self.current == self.end {\n            None\n        }\n        else {\n            unsafe {\n                let current = self.current as isize;\n                self.current += 1;\n                Some(ptr::read(self.data.as_ptr().offset(current)))\n            }\n        }\n    }\n\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        let size = self.end - self.current;\n        (size, Some(size))\n    }\n}\n\nimpl<A: Array> DoubleEndedIterator for IntoIter<A> {\n    #[inline]\n    fn next_back(&mut self) -> Option<A::Item> {\n        if self.current == self.end {\n            None\n        }\n        else {\n            unsafe {\n                self.end -= 1;\n                Some(ptr::read(self.data.as_ptr().offset(self.end as isize)))\n            }\n        }\n    }\n}\n\nimpl<A: Array> ExactSizeIterator for IntoIter<A> { }\n\nimpl<A: Array> IntoIterator for SmallVec<A> {\n    type IntoIter = IntoIter<A>;\n    type Item = A::Item;\n    fn into_iter(mut self) -> Self::IntoIter {\n        unsafe {\n            // Set SmallVec len to zero as `IntoIter` drop handles dropping of the elements\n            let len = self.len();\n            self.set_len(0);\n            IntoIter {\n                data: self,\n                current: 0,\n                end: len,\n            }\n        }\n    }\n}\n\nimpl<'a, A: Array> IntoIterator for &'a SmallVec<A> {\n    type IntoIter = slice::Iter<'a, A::Item>;\n    type Item = &'a A::Item;\n    fn into_iter(self) -> Self::IntoIter {\n        self.iter()\n    }\n}\n\nimpl<'a, A: Array> IntoIterator for &'a mut SmallVec<A> {\n    type IntoIter = slice::IterMut<'a, A::Item>;\n    type Item = &'a mut A::Item;\n    fn into_iter(self) -> Self::IntoIter {\n        self.iter_mut()\n    }\n}\n\n/// Types that can be used as the backing store for a SmallVec\npub unsafe trait Array {\n    /// The type of the array's elements.\n    type Item;\n    /// Returns the number of items the array can hold.\n    fn size() -> usize;\n    /// Returns a pointer to the first element of the array.\n    fn ptr(&self) -> *const Self::Item;\n    /// Returns a mutable pointer to the first element of the array.\n    fn ptr_mut(&mut self) -> *mut Self::Item;\n}\n\n/// Set the length of the vec when the `SetLenOnDrop` value goes out of scope.\n///\n/// Copied from https://github.com/rust-lang/rust/pull/36355\nstruct SetLenOnDrop<'a> {\n    len: &'a mut usize,\n    local_len: usize,\n}\n\nimpl<'a> SetLenOnDrop<'a> {\n    #[inline]\n    fn new(len: &'a mut usize) -> Self {\n        SetLenOnDrop { local_len: *len, len: len }\n    }\n\n    #[inline]\n    fn get(&self) -> usize {\n        self.local_len\n    }\n\n    #[inline]\n    fn increment_len(&mut self, increment: usize) {\n        self.local_len += increment;\n    }\n}\n\nimpl<'a> Drop for SetLenOnDrop<'a> {\n    #[inline]\n    fn drop(&mut self) {\n        *self.len = self.local_len;\n    }\n}\n\nmacro_rules! impl_array(\n    ($($size:expr),+) => {\n        $(\n            unsafe impl<T> Array for [T; $size] {\n                type Item = T;\n                fn size() -> usize { $size }\n                fn ptr(&self) -> *const T { self.as_ptr() }\n                fn ptr_mut(&mut self) -> *mut T { self.as_mut_ptr() }\n            }\n        )+\n    }\n);\n\nimpl_array!(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 20, 24, 32, 36,\n            0x40, 0x80, 0x100, 0x200, 0x400, 0x800, 0x1000, 0x2000, 0x4000, 0x8000,\n            0x10000, 0x20000, 0x40000, 0x80000, 0x100000);\n\n#[cfg(test)]\nmod tests {\n    use SmallVec;\n\n    use std::iter::FromIterator;\n\n    #[cfg(feature = \"std\")]\n    use std::borrow::ToOwned;\n    #[cfg(not(feature = \"std\"))]\n    use alloc::borrow::ToOwned;\n    #[cfg(feature = \"std\")]\n    use std::rc::Rc;\n    #[cfg(not(feature = \"std\"))]\n    use alloc::rc::Rc;\n    #[cfg(not(feature = \"std\"))]\n    use alloc::boxed::Box;\n    #[cfg(not(feature = \"std\"))]\n    use alloc::vec::Vec;\n\n    #[test]\n    pub fn test_zero() {\n        let mut v = SmallVec::<[_; 0]>::new();\n        assert!(!v.spilled());\n        v.push(0usize);\n        assert!(v.spilled());\n        assert_eq!(&*v, &[0]);\n    }\n\n    // We heap allocate all these strings so that double frees will show up under valgrind.\n\n    #[test]\n    pub fn test_inline() {\n        let mut v = SmallVec::<[_; 16]>::new();\n        v.push(\"hello\".to_owned());\n        v.push(\"there\".to_owned());\n        assert_eq!(&*v, &[\n            \"hello\".to_owned(),\n            \"there\".to_owned(),\n        ][..]);\n    }\n\n    #[test]\n    pub fn test_spill() {\n        let mut v = SmallVec::<[_; 2]>::new();\n        v.push(\"hello\".to_owned());\n        assert_eq!(v[0], \"hello\");\n        v.push(\"there\".to_owned());\n        v.push(\"burma\".to_owned());\n        assert_eq!(v[0], \"hello\");\n        v.push(\"shave\".to_owned());\n        assert_eq!(&*v, &[\n            \"hello\".to_owned(),\n            \"there\".to_owned(),\n            \"burma\".to_owned(),\n            \"shave\".to_owned(),\n        ][..]);\n    }\n\n    #[test]\n    pub fn test_double_spill() {\n        let mut v = SmallVec::<[_; 2]>::new();\n        v.push(\"hello\".to_owned());\n        v.push(\"there\".to_owned());\n        v.push(\"burma\".to_owned());\n        v.push(\"shave\".to_owned());\n        v.push(\"hello\".to_owned());\n        v.push(\"there\".to_owned());\n        v.push(\"burma\".to_owned());\n        v.push(\"shave\".to_owned());\n        assert_eq!(&*v, &[\n            \"hello\".to_owned(),\n            \"there\".to_owned(),\n            \"burma\".to_owned(),\n            \"shave\".to_owned(),\n            \"hello\".to_owned(),\n            \"there\".to_owned(),\n            \"burma\".to_owned(),\n            \"shave\".to_owned(),\n        ][..]);\n    }\n\n    /// https://github.com/servo/rust-smallvec/issues/4\n    #[test]\n    fn issue_4() {\n        SmallVec::<[Box<u32>; 2]>::new();\n    }\n\n    /// https://github.com/servo/rust-smallvec/issues/5\n    #[test]\n    fn issue_5() {\n        assert!(Some(SmallVec::<[&u32; 2]>::new()).is_some());\n    }\n\n    #[test]\n    fn test_with_capacity() {\n        let v: SmallVec<[u8; 3]> = SmallVec::with_capacity(1);\n        assert!(v.is_empty());\n        assert!(!v.spilled());\n        assert_eq!(v.capacity(), 3);\n\n        let v: SmallVec<[u8; 3]> = SmallVec::with_capacity(10);\n        assert!(v.is_empty());\n        assert!(v.spilled());\n        assert_eq!(v.capacity(), 10);\n    }\n\n    #[test]\n    fn drain() {\n        let mut v: SmallVec<[u8; 2]> = SmallVec::new();\n        v.push(3);\n        assert_eq!(v.drain().collect::<Vec<_>>(), &[3]);\n\n        // spilling the vec\n        v.push(3);\n        v.push(4);\n        v.push(5);\n        assert_eq!(v.drain().collect::<Vec<_>>(), &[3, 4, 5]);\n    }\n\n    #[test]\n    fn drain_rev() {\n        let mut v: SmallVec<[u8; 2]> = SmallVec::new();\n        v.push(3);\n        assert_eq!(v.drain().rev().collect::<Vec<_>>(), &[3]);\n\n        // spilling the vec\n        v.push(3);\n        v.push(4);\n        v.push(5);\n        assert_eq!(v.drain().rev().collect::<Vec<_>>(), &[5, 4, 3]);\n    }\n\n    #[test]\n    fn into_iter() {\n        let mut v: SmallVec<[u8; 2]> = SmallVec::new();\n        v.push(3);\n        assert_eq!(v.into_iter().collect::<Vec<_>>(), &[3]);\n\n        // spilling the vec\n        let mut v: SmallVec<[u8; 2]> = SmallVec::new();\n        v.push(3);\n        v.push(4);\n        v.push(5);\n        assert_eq!(v.into_iter().collect::<Vec<_>>(), &[3, 4, 5]);\n    }\n\n    #[test]\n    fn into_iter_rev() {\n        let mut v: SmallVec<[u8; 2]> = SmallVec::new();\n        v.push(3);\n        assert_eq!(v.into_iter().rev().collect::<Vec<_>>(), &[3]);\n\n        // spilling the vec\n        let mut v: SmallVec<[u8; 2]> = SmallVec::new();\n        v.push(3);\n        v.push(4);\n        v.push(5);\n        assert_eq!(v.into_iter().rev().collect::<Vec<_>>(), &[5, 4, 3]);\n    }\n\n    #[test]\n    fn into_iter_drop() {\n        use std::cell::Cell;\n\n        struct DropCounter<'a>(&'a Cell<i32>);\n\n        impl<'a> Drop for DropCounter<'a> {\n            fn drop(&mut self) {\n                self.0.set(self.0.get() + 1);\n            }\n        }\n\n        {\n            let cell = Cell::new(0);\n            let mut v: SmallVec<[DropCounter; 2]> = SmallVec::new();\n            v.push(DropCounter(&cell));\n            v.into_iter();\n            assert_eq!(cell.get(), 1);\n        }\n\n        {\n            let cell = Cell::new(0);\n            let mut v: SmallVec<[DropCounter; 2]> = SmallVec::new();\n            v.push(DropCounter(&cell));\n            v.push(DropCounter(&cell));\n            assert!(v.into_iter().next().is_some());\n            assert_eq!(cell.get(), 2);\n        }\n\n        {\n            let cell = Cell::new(0);\n            let mut v: SmallVec<[DropCounter; 2]> = SmallVec::new();\n            v.push(DropCounter(&cell));\n            v.push(DropCounter(&cell));\n            v.push(DropCounter(&cell));\n            assert!(v.into_iter().next().is_some());\n            assert_eq!(cell.get(), 3);\n        }\n        {\n            let cell = Cell::new(0);\n            let mut v: SmallVec<[DropCounter; 2]> = SmallVec::new();\n            v.push(DropCounter(&cell));\n            v.push(DropCounter(&cell));\n            v.push(DropCounter(&cell));\n            {\n                let mut it = v.into_iter();\n                assert!(it.next().is_some());\n                assert!(it.next_back().is_some());\n            }\n            assert_eq!(cell.get(), 3);\n        }\n    }\n\n    #[test]\n    fn test_capacity() {\n        let mut v: SmallVec<[u8; 2]> = SmallVec::new();\n        v.reserve(1);\n        assert_eq!(v.capacity(), 2);\n        assert!(!v.spilled());\n\n        v.reserve_exact(0x100);\n        assert!(v.capacity() >= 0x100);\n\n        v.push(0);\n        v.push(1);\n        v.push(2);\n        v.push(3);\n\n        v.shrink_to_fit();\n        assert!(v.capacity() < 0x100);\n    }\n\n    #[test]\n    fn test_truncate() {\n        let mut v: SmallVec<[Box<u8>; 8]> = SmallVec::new();\n\n        for x in 0..8 {\n            v.push(Box::new(x));\n        }\n        v.truncate(4);\n\n        assert_eq!(v.len(), 4);\n        assert!(!v.spilled());\n\n        assert_eq!(*v.swap_remove(1), 1);\n        assert_eq!(*v.remove(1), 3);\n        v.insert(1, Box::new(3));\n\n        assert_eq!(&v.iter().map(|v| **v).collect::<Vec<_>>(), &[0, 3, 2]);\n    }\n\n    #[test]\n    fn test_insert_many() {\n        let mut v: SmallVec<[u8; 8]> = SmallVec::new();\n        for x in 0..4 {\n            v.push(x);\n        }\n        assert_eq!(v.len(), 4);\n        v.insert_many(1, [5, 6].iter().cloned());\n        assert_eq!(&v.iter().map(|v| *v).collect::<Vec<_>>(), &[0, 5, 6, 1, 2, 3]);\n    }\n\n    struct MockHintIter<T: Iterator>{x: T, hint: usize}\n    impl<T: Iterator> Iterator for MockHintIter<T> {\n        type Item = T::Item;\n        fn next(&mut self) -> Option<Self::Item> {self.x.next()}\n        fn size_hint(&self) -> (usize, Option<usize>) {(self.hint, None)}\n    }\n\n    #[test]\n    fn test_insert_many_short_hint() {\n        let mut v: SmallVec<[u8; 8]> = SmallVec::new();\n        for x in 0..4 {\n            v.push(x);\n        }\n        assert_eq!(v.len(), 4);\n        v.insert_many(1, MockHintIter{x: [5, 6].iter().cloned(), hint: 5});\n        assert_eq!(&v.iter().map(|v| *v).collect::<Vec<_>>(), &[0, 5, 6, 1, 2, 3]);\n    }\n\n    #[test]\n    fn test_insert_many_long_hint() {\n        let mut v: SmallVec<[u8; 8]> = SmallVec::new();\n        for x in 0..4 {\n            v.push(x);\n        }\n        assert_eq!(v.len(), 4);\n        v.insert_many(1, MockHintIter{x: [5, 6].iter().cloned(), hint: 1});\n        assert_eq!(&v.iter().map(|v| *v).collect::<Vec<_>>(), &[0, 5, 6, 1, 2, 3]);\n    }\n\n    #[cfg(feature = \"std\")]\n    #[test]\n    // https://github.com/servo/rust-smallvec/issues/96\n    fn test_insert_many_panic() {\n        struct PanicOnDoubleDrop {\n            dropped: Box<bool>\n        }\n\n        impl Drop for PanicOnDoubleDrop {\n            fn drop(&mut self) {\n                assert!(!*self.dropped, \"already dropped\");\n                *self.dropped = true;\n            }\n        }\n\n        struct BadIter;\n        impl Iterator for BadIter {\n            type Item = PanicOnDoubleDrop;\n            fn size_hint(&self) -> (usize, Option<usize>) { (1, None) }\n            fn next(&mut self) -> Option<Self::Item> { panic!() }\n        }\n\n        let mut vec: SmallVec<[PanicOnDoubleDrop; 0]> = vec![\n            PanicOnDoubleDrop { dropped: Box::new(false) },\n            PanicOnDoubleDrop { dropped: Box::new(false) },\n        ].into();\n        let result = ::std::panic::catch_unwind(move || {\n            vec.insert_many(0, BadIter);\n        });\n        assert!(result.is_err());\n    }\n\n    #[test]\n    #[should_panic]\n    fn test_invalid_grow() {\n        let mut v: SmallVec<[u8; 8]> = SmallVec::new();\n        v.extend(0..8);\n        v.grow(5);\n    }\n\n    #[test]\n    fn test_insert_from_slice() {\n        let mut v: SmallVec<[u8; 8]> = SmallVec::new();\n        for x in 0..4 {\n            v.push(x);\n        }\n        assert_eq!(v.len(), 4);\n        v.insert_from_slice(1, &[5, 6]);\n        assert_eq!(&v.iter().map(|v| *v).collect::<Vec<_>>(), &[0, 5, 6, 1, 2, 3]);\n    }\n\n    #[test]\n    fn test_extend_from_slice() {\n        let mut v: SmallVec<[u8; 8]> = SmallVec::new();\n        for x in 0..4 {\n            v.push(x);\n        }\n        assert_eq!(v.len(), 4);\n        v.extend_from_slice(&[5, 6]);\n        assert_eq!(&v.iter().map(|v| *v).collect::<Vec<_>>(), &[0, 1, 2, 3, 5, 6]);\n    }\n\n    #[test]\n    #[should_panic]\n    fn test_drop_panic_smallvec() {\n        // This test should only panic once, and not double panic,\n        // which would mean a double drop\n        struct DropPanic;\n\n        impl Drop for DropPanic {\n            fn drop(&mut self) {\n                panic!(\"drop\");\n            }\n        }\n\n        let mut v = SmallVec::<[_; 1]>::new();\n        v.push(DropPanic);\n    }\n\n    #[test]\n    fn test_eq() {\n        let mut a: SmallVec<[u32; 2]> = SmallVec::new();\n        let mut b: SmallVec<[u32; 2]> = SmallVec::new();\n        let mut c: SmallVec<[u32; 2]> = SmallVec::new();\n        // a = [1, 2]\n        a.push(1);\n        a.push(2);\n        // b = [1, 2]\n        b.push(1);\n        b.push(2);\n        // c = [3, 4]\n        c.push(3);\n        c.push(4);\n\n        assert!(a == b);\n        assert!(a != c);\n    }\n\n    #[test]\n    fn test_ord() {\n        let mut a: SmallVec<[u32; 2]> = SmallVec::new();\n        let mut b: SmallVec<[u32; 2]> = SmallVec::new();\n        let mut c: SmallVec<[u32; 2]> = SmallVec::new();\n        // a = [1]\n        a.push(1);\n        // b = [1, 1]\n        b.push(1);\n        b.push(1);\n        // c = [1, 2]\n        c.push(1);\n        c.push(2);\n\n        assert!(a < b);\n        assert!(b > a);\n        assert!(b < c);\n        assert!(c > b);\n    }\n\n    #[cfg(feature = \"std\")]\n    #[test]\n    fn test_hash() {\n        use std::hash::Hash;\n        use std::collections::hash_map::DefaultHasher;\n\n        {\n            let mut a: SmallVec<[u32; 2]> = SmallVec::new();\n            let b = [1, 2];\n            a.extend(b.iter().cloned());\n            let mut hasher = DefaultHasher::new();\n            assert_eq!(a.hash(&mut hasher), b.hash(&mut hasher));\n        }\n        {\n            let mut a: SmallVec<[u32; 2]> = SmallVec::new();\n            let b = [1, 2, 11, 12];\n            a.extend(b.iter().cloned());\n            let mut hasher = DefaultHasher::new();\n            assert_eq!(a.hash(&mut hasher), b.hash(&mut hasher));\n        }\n    }\n\n    #[test]\n    fn test_as_ref() {\n        let mut a: SmallVec<[u32; 2]> = SmallVec::new();\n        a.push(1);\n        assert_eq!(a.as_ref(), [1]);\n        a.push(2);\n        assert_eq!(a.as_ref(), [1, 2]);\n        a.push(3);\n        assert_eq!(a.as_ref(), [1, 2, 3]);\n    }\n\n    #[test]\n    fn test_as_mut() {\n        let mut a: SmallVec<[u32; 2]> = SmallVec::new();\n        a.push(1);\n        assert_eq!(a.as_mut(), [1]);\n        a.push(2);\n        assert_eq!(a.as_mut(), [1, 2]);\n        a.push(3);\n        assert_eq!(a.as_mut(), [1, 2, 3]);\n        a.as_mut()[1] = 4;\n        assert_eq!(a.as_mut(), [1, 4, 3]);\n    }\n\n    #[test]\n    fn test_borrow() {\n        use std::borrow::Borrow;\n\n        let mut a: SmallVec<[u32; 2]> = SmallVec::new();\n        a.push(1);\n        assert_eq!(a.borrow(), [1]);\n        a.push(2);\n        assert_eq!(a.borrow(), [1, 2]);\n        a.push(3);\n        assert_eq!(a.borrow(), [1, 2, 3]);\n    }\n\n    #[test]\n    fn test_borrow_mut() {\n        use std::borrow::BorrowMut;\n\n        let mut a: SmallVec<[u32; 2]> = SmallVec::new();\n        a.push(1);\n        assert_eq!(a.borrow_mut(), [1]);\n        a.push(2);\n        assert_eq!(a.borrow_mut(), [1, 2]);\n        a.push(3);\n        assert_eq!(a.borrow_mut(), [1, 2, 3]);\n        BorrowMut::<[u32]>::borrow_mut(&mut a)[1] = 4;\n        assert_eq!(a.borrow_mut(), [1, 4, 3]);\n    }\n\n    #[test]\n    fn test_from() {\n        assert_eq!(&SmallVec::<[u32; 2]>::from(&[1][..])[..], [1]);\n        assert_eq!(&SmallVec::<[u32; 2]>::from(&[1, 2, 3][..])[..], [1, 2, 3]);\n\n        let vec = vec![];\n        let small_vec: SmallVec<[u8; 3]> = SmallVec::from(vec);\n        assert_eq!(&*small_vec, &[]);\n        drop(small_vec);\n\n        let vec = vec![1, 2, 3, 4, 5];\n        let small_vec: SmallVec<[u8; 3]> = SmallVec::from(vec);\n        assert_eq!(&*small_vec, &[1, 2, 3, 4, 5]);\n        drop(small_vec);\n\n        let vec = vec![1, 2, 3, 4, 5];\n        let small_vec: SmallVec<[u8; 1]> = SmallVec::from(vec);\n        assert_eq!(&*small_vec, &[1, 2, 3, 4, 5]);\n        drop(small_vec);\n\n        let array = [1];\n        let small_vec: SmallVec<[u8; 1]> = SmallVec::from(array);\n        assert_eq!(&*small_vec, &[1]);\n        drop(small_vec);\n\n        let array = [99; 128];\n        let small_vec: SmallVec<[u8; 128]> = SmallVec::from(array);\n        assert_eq!(&*small_vec, vec![99u8; 128].as_slice());\n        drop(small_vec);\n    }\n\n    #[test]\n    fn test_from_slice() {\n        assert_eq!(&SmallVec::<[u32; 2]>::from_slice(&[1][..])[..], [1]);\n        assert_eq!(&SmallVec::<[u32; 2]>::from_slice(&[1, 2, 3][..])[..], [1, 2, 3]);\n    }\n\n    #[test]\n    fn test_exact_size_iterator() {\n        let mut vec = SmallVec::<[u32; 2]>::from(&[1, 2, 3][..]);\n        assert_eq!(vec.clone().into_iter().len(), 3);\n        assert_eq!(vec.drain().len(), 3);\n    }\n\n    #[test]\n    #[allow(deprecated)]\n    fn veclike_deref_slice() {\n        use super::VecLike;\n\n        fn test<T: VecLike<i32>>(vec: &mut T) {\n            assert!(!vec.is_empty());\n            assert_eq!(vec.len(), 3);\n\n            vec.sort();\n            assert_eq!(&vec[..], [1, 2, 3]);\n        }\n\n        let mut vec = SmallVec::<[i32; 2]>::from(&[3, 1, 2][..]);\n        test(&mut vec);\n    }\n\n    #[test]\n    fn shrink_to_fit_unspill() {\n        let mut vec = SmallVec::<[u8; 2]>::from_iter(0..3);\n        vec.pop();\n        assert!(vec.spilled());\n        vec.shrink_to_fit();\n        assert!(!vec.spilled(), \"shrink_to_fit will un-spill if possible\");\n    }\n\n    #[test]\n    fn test_into_vec() {\n        let vec = SmallVec::<[u8; 2]>::from_iter(0..2);\n        assert_eq!(vec.into_vec(), vec![0, 1]);\n\n        let vec = SmallVec::<[u8; 2]>::from_iter(0..3);\n        assert_eq!(vec.into_vec(), vec![0, 1, 2]);\n    }\n\n    #[test]\n    fn test_into_inner() {\n        let vec = SmallVec::<[u8; 2]>::from_iter(0..2);\n        assert_eq!(vec.into_inner(), Ok([0, 1]));\n\n        let vec = SmallVec::<[u8; 2]>::from_iter(0..1);\n        assert_eq!(vec.clone().into_inner(), Err(vec));\n\n        let vec = SmallVec::<[u8; 2]>::from_iter(0..3);\n        assert_eq!(vec.clone().into_inner(), Err(vec));\n    }\n\n    #[test]\n    fn test_from_vec() {\n        let vec = vec![];\n        let small_vec: SmallVec<[u8; 3]> = SmallVec::from_vec(vec);\n        assert_eq!(&*small_vec, &[]);\n        drop(small_vec);\n\n        let vec = vec![];\n        let small_vec: SmallVec<[u8; 1]> = SmallVec::from_vec(vec);\n        assert_eq!(&*small_vec, &[]);\n        drop(small_vec);\n\n        let vec = vec![1];\n        let small_vec: SmallVec<[u8; 3]> = SmallVec::from_vec(vec);\n        assert_eq!(&*small_vec, &[1]);\n        drop(small_vec);\n\n        let vec = vec![1, 2, 3];\n        let small_vec: SmallVec<[u8; 3]> = SmallVec::from_vec(vec);\n        assert_eq!(&*small_vec, &[1, 2, 3]);\n        drop(small_vec);\n\n        let vec = vec![1, 2, 3, 4, 5];\n        let small_vec: SmallVec<[u8; 3]> = SmallVec::from_vec(vec);\n        assert_eq!(&*small_vec, &[1, 2, 3, 4, 5]);\n        drop(small_vec);\n\n        let vec = vec![1, 2, 3, 4, 5];\n        let small_vec: SmallVec<[u8; 1]> = SmallVec::from_vec(vec);\n        assert_eq!(&*small_vec, &[1, 2, 3, 4, 5]);\n        drop(small_vec);\n    }\n\n    #[test]\n    fn test_retain() {\n        // Test inline data storate\n        let mut sv: SmallVec<[i32; 5]> = SmallVec::from_slice(&[1, 2, 3, 3, 4]);\n        sv.retain(|&mut i| i != 3);\n        assert_eq!(sv.pop(), Some(4));\n        assert_eq!(sv.pop(), Some(2));\n        assert_eq!(sv.pop(), Some(1));\n        assert_eq!(sv.pop(), None);\n\n        // Test spilled data storage\n        let mut sv: SmallVec<[i32; 3]> = SmallVec::from_slice(&[1, 2, 3, 3, 4]);\n        sv.retain(|&mut i| i != 3);\n        assert_eq!(sv.pop(), Some(4));\n        assert_eq!(sv.pop(), Some(2));\n        assert_eq!(sv.pop(), Some(1));\n        assert_eq!(sv.pop(), None);\n\n        // Test that drop implementations are called for inline.\n        let one = Rc::new(1);\n        let mut sv: SmallVec<[Rc<i32>; 3]> = SmallVec::new();\n        sv.push(Rc::clone(&one));\n        assert_eq!(Rc::strong_count(&one), 2);\n        sv.retain(|_| false);\n        assert_eq!(Rc::strong_count(&one), 1);\n\n        // Test that drop implementations are called for spilled data.\n        let mut sv: SmallVec<[Rc<i32>; 1]> = SmallVec::new();\n        sv.push(Rc::clone(&one));\n        sv.push(Rc::new(2));\n        assert_eq!(Rc::strong_count(&one), 2);\n        sv.retain(|_| false);\n        assert_eq!(Rc::strong_count(&one), 1);\n    }\n\n    #[test]\n    fn test_dedup() {\n        let mut dupes: SmallVec<[i32; 5]> = SmallVec::from_slice(&[1, 1, 2, 3, 3]);\n        dupes.dedup();\n        assert_eq!(&*dupes, &[1, 2, 3]);\n\n        let mut empty: SmallVec<[i32; 5]> = SmallVec::new();\n        empty.dedup();\n        assert!(empty.is_empty());\n\n        let mut all_ones: SmallVec<[i32; 5]> = SmallVec::from_slice(&[1, 1, 1, 1, 1]);\n        all_ones.dedup();\n        assert_eq!(all_ones.len(), 1);\n\n        let mut no_dupes: SmallVec<[i32; 5]> = SmallVec::from_slice(&[1, 2, 3, 4, 5]);\n        no_dupes.dedup();\n        assert_eq!(no_dupes.len(), 5);\n    }\n\n    #[test]\n    fn test_resize() {\n        let mut v: SmallVec<[i32; 8]> = SmallVec::new();\n        v.push(1);\n        v.resize(5, 0);\n        assert_eq!(v[..], [1, 0, 0, 0, 0][..]);\n\n        v.resize(2, -1);\n        assert_eq!(v[..], [1, 0][..]);\n    }\n\n    #[cfg(feature = \"std\")]\n    #[test]\n    fn test_write() {\n        use io::Write;\n\n        let data = [1, 2, 3, 4, 5];\n\n        let mut small_vec: SmallVec<[u8; 2]> = SmallVec::new();\n        let len = small_vec.write(&data[..]).unwrap();\n        assert_eq!(len, 5);\n        assert_eq!(small_vec.as_ref(), data.as_ref());\n\n        let mut small_vec: SmallVec<[u8; 2]> = SmallVec::new();\n        small_vec.write_all(&data[..]).unwrap();\n        assert_eq!(small_vec.as_ref(), data.as_ref());\n    }\n\n    #[cfg(feature = \"serde\")]\n    extern crate bincode;\n\n    #[cfg(feature = \"serde\")]\n    #[test]\n    fn test_serde() {\n        use self::bincode::{config, deserialize};\n        let mut small_vec: SmallVec<[i32; 2]> = SmallVec::new();\n        small_vec.push(1);\n        let encoded = config().limit(100).serialize(&small_vec).unwrap();\n        let decoded: SmallVec<[i32; 2]> = deserialize(&encoded).unwrap();\n        assert_eq!(small_vec, decoded);\n        small_vec.push(2);\n        // Spill the vec\n        small_vec.push(3);\n        small_vec.push(4);\n        // Check again after spilling.\n        let encoded = config().limit(100).serialize(&small_vec).unwrap();\n        let decoded: SmallVec<[i32; 2]> = deserialize(&encoded).unwrap();\n        assert_eq!(small_vec, decoded);\n    }\n}\n"
  },
  {
    "project": "ash",
    "target": 1,
    "commit_id": "17149bd791cd6e09b145063a238d3e27d855780c",
    "func": "use crate::vk;\nuse std::iter::Iterator;\nuse std::marker::PhantomData;\nuse std::mem::size_of;\nuse std::os::raw::c_void;\nuse std::{io, slice};\n\n/// [`Align`] handles dynamic alignment. The is useful for dynamic uniform buffers where\n/// the alignment might be different. For example a 4x4 f32 matrix has a size of 64 bytes\n/// but the min alignment for a dynamic uniform buffer might be 256 bytes. A slice of `&[Mat4x4<f32>]`\n/// has a memory layout of `[[64 bytes], [64 bytes], [64 bytes]]`, but it might need to have a memory\n/// layout of `[[256 bytes], [256 bytes], [256 bytes]]`.\n/// [`Align::copy_from_slice`] will copy a slice of `&[T]` directly into the host memory without\n/// an additional allocation and with the correct alignment.\n#[derive(Debug, Clone)]\npub struct Align<T> {\n    ptr: *mut c_void,\n    elem_size: vk::DeviceSize,\n    size: vk::DeviceSize,\n    _m: PhantomData<T>,\n}\n\n#[derive(Debug)]\npub struct AlignIter<'a, T: 'a> {\n    align: &'a mut Align<T>,\n    current: vk::DeviceSize,\n}\n\nimpl<T: Copy> Align<T> {\n    pub fn copy_from_slice(&mut self, slice: &[T]) {\n        use std::slice::from_raw_parts_mut;\n        if self.elem_size == size_of::<T>() as u64 {\n            unsafe {\n                let mapped_slice = from_raw_parts_mut(self.ptr as *mut T, slice.len());\n                mapped_slice.copy_from_slice(slice);\n            }\n        } else {\n            for (i, val) in self.iter_mut().enumerate().take(slice.len()) {\n                *val = slice[i];\n            }\n        }\n    }\n}\n\nfn calc_padding(adr: vk::DeviceSize, align: vk::DeviceSize) -> vk::DeviceSize {\n    (align - adr % align) % align\n}\n\nimpl<T> Align<T> {\n    pub unsafe fn new(ptr: *mut c_void, alignment: vk::DeviceSize, size: vk::DeviceSize) -> Self {\n        let padding = calc_padding(size_of::<T>() as vk::DeviceSize, alignment);\n        let elem_size = size_of::<T>() as vk::DeviceSize + padding;\n        assert!(calc_padding(size, alignment) == 0, \"size must be aligned\");\n        Align {\n            ptr,\n            elem_size,\n            size,\n            _m: PhantomData,\n        }\n    }\n\n    pub fn iter_mut(&mut self) -> AlignIter<T> {\n        AlignIter {\n            current: 0,\n            align: self,\n        }\n    }\n}\n\nimpl<'a, T: Copy + 'a> Iterator for AlignIter<'a, T> {\n    type Item = &'a mut T;\n    fn next(&mut self) -> Option<Self::Item> {\n        if self.current == self.align.size {\n            return None;\n        }\n        unsafe {\n            // Need to cast to *mut u8 because () has size 0\n            let ptr = (self.align.ptr as *mut u8).offset(self.current as isize) as *mut T;\n            self.current += self.align.elem_size;\n            Some(&mut *ptr)\n        }\n    }\n}\n\n/// Decode SPIR-V from bytes.\n///\n/// This function handles SPIR-V of arbitrary endianness gracefully, and returns correctly aligned\n/// storage.\n///\n/// # Examples\n/// ```no_run\n/// // Decode SPIR-V from a file\n/// let mut file = std::fs::File::open(\"/path/to/shader.spv\").unwrap();\n/// let words = ash::util::read_spv(&mut file).unwrap();\n/// ```\n/// ```\n/// // Decode SPIR-V from memory\n/// const SPIRV: &[u8] = &[\n///     // ...\n/// #   0x03, 0x02, 0x23, 0x07,\n/// ];\n/// let words = ash::util::read_spv(&mut std::io::Cursor::new(&SPIRV[..])).unwrap();\n/// ```\npub fn read_spv<R: io::Read + io::Seek>(x: &mut R) -> io::Result<Vec<u32>> {\n    let size = x.seek(io::SeekFrom::End(0))?;\n    if size % 4 != 0 {\n        return Err(io::Error::new(\n            io::ErrorKind::InvalidData,\n            \"input length not divisible by 4\",\n        ));\n    }\n    if size > usize::max_value() as u64 {\n        return Err(io::Error::new(io::ErrorKind::InvalidData, \"input too long\"));\n    }\n    let words = (size / 4) as usize;\n    let mut result = Vec::<u32>::with_capacity(words);\n    x.seek(io::SeekFrom::Start(0))?;\n    unsafe {\n        x.read_exact(slice::from_raw_parts_mut(\n            result.as_mut_ptr() as *mut u8,\n            words * 4,\n        ))?;\n        result.set_len(words);\n    }\n    const MAGIC_NUMBER: u32 = 0x0723_0203;\n    if !result.is_empty() && result[0] == MAGIC_NUMBER.swap_bytes() {\n        for word in &mut result {\n            *word = word.swap_bytes();\n        }\n    }\n    if result.is_empty() || result[0] != MAGIC_NUMBER {\n        return Err(io::Error::new(\n            io::ErrorKind::InvalidData,\n            \"input missing SPIR-V magic number\",\n        ));\n    }\n    Ok(result)\n}\n"
  },
  {
    "project": "com-impl",
    "target": 1,
    "commit_id": "bc6bb5384cac1278e9e89e65400ff9e218b705d1",
    "func": "use proc_macro2::TokenStream;\nuse syn::{\n    Attribute, Data, DeriveInput, Fields, FieldsNamed, GenericArgument, Generics, Ident, Lit, Meta,\n    NestedMeta, Path, PathArguments, Type, TypePath,\n};\n\npub fn expand_derive_com_impl(input: &DeriveInput) -> Result<TokenStream, String> {\n    let com_impl = ComImpl::parse(input)?;\n    let result = com_impl.quote();\n\n    Ok(result)\n}\n\nstruct ComImpl<'a> {\n    name: &'a Ident,\n    vtbl_member: &'a Ident,\n    refc_member: &'a Ident,\n    other_members: Vec<Mem<'a>>,\n    interfaces: Vec<Type>,\n    generics: &'a Generics,\n}\n\nimpl<'a> ComImpl<'a> {\n    fn quote(&self) -> TokenStream {\n        let create_raw = self.quote_create_raw();\n        let iunknown_vtbl = self.quote_iunknown_vtbl();\n        let iunknown_impl = self.quote_iunknown_impl();\n\n        quote! {\n            #create_raw\n            #iunknown_vtbl\n            #iunknown_impl\n        }\n    }\n\n    fn quote_create_raw(&self) -> TokenStream {\n        let name = self.name;\n        let vtbl = self.vtbl_member;\n        let refcount = self.refc_member;\n        let (impgen, tygen, wherec) = self.generics.split_for_impl();\n        let params = self.other_members.iter().map(|m| m.quote_param());\n        let inits = self.other_members.iter().map(|m| m.quote_init());\n\n        quote! {\n            impl #impgen #name #tygen #wherec {\n                fn create_raw(#(#params),*) -> *mut Self {\n                    Box::into_raw(Box::new(#name {\n                        #vtbl: <Self as com_impl::BuildVTable<_>>::static_vtable(),\n                        #refcount: Default::default(),\n                        #(#inits,)*\n                    }))\n                }\n            }\n        }\n    }\n\n    fn quote_iunknown_vtbl(&self) -> TokenStream {\n        let name = self.name;\n        let (impgen, tygen, wherec) = self.generics.split_for_impl();\n        let buildvtbl = quote! { com_impl::BuildVTable<winapi::um::unknwnbase::IUnknownVtbl> };\n\n        quote! {\n            unsafe impl #impgen #buildvtbl for #name #tygen #wherec {\n                const VTBL: winapi::um::unknwnbase::IUnknownVtbl = winapi::um::unknwnbase::IUnknownVtbl {\n                    AddRef: Self::__com_impl__IUnknown__AddRef,\n                    Release: Self::__com_impl__IUnknown__Release,\n                    QueryInterface: Self::__com_impl__IUnknown__QueryInterface,\n                };\n\n                fn static_vtable() -> com_impl::VTable<winapi::um::unknwnbase::IUnknownVtbl> {\n                    com_impl::VTable::new(&Self::VTBL)\n                }\n            }\n        }\n    }\n\n    fn quote_iunknown_impl(&self) -> TokenStream {\n        let name = self.name;\n        let refcount = self.refc_member;\n        let (impgen, tygen, wherec) = self.generics.split_for_impl();\n\n        let is_equal_iid = self.interfaces.iter().map(|path| {\n            quote! {\n                winapi::shared::guiddef::IsEqualIID(\n                    &*riid,\n                    &<#path as winapi::Interface>::uuidof(),\n                )\n            }\n        });\n\n        quote! {\n            #[allow(non_snake_case)]\n            impl #impgen #name #tygen #wherec {\n                #[inline(never)]\n                unsafe extern \"system\" fn __com_impl__IUnknown__AddRef(\n                    this: *mut winapi::um::unknwnbase::IUnknown,\n                ) -> u32 {\n                    let this = &*(this as *const Self);\n                    this.#refcount.add_ref()\n                }\n\n                #[inline(never)]\n                unsafe extern \"system\" fn __com_impl__IUnknown__Release(\n                    this: *mut winapi::um::unknwnbase::IUnknown,\n                ) -> u32 {\n                    let ptr = this as *mut Self;\n                    let count = (*ptr).#refcount.release();\n                    if count == 0 {\n                        // This was the last ref\n                        Box::from_raw(ptr);\n                    }\n                    count\n                }\n\n                #[inline(never)]\n                unsafe extern \"system\" fn __com_impl__IUnknown__QueryInterface(\n                    this: *mut winapi::um::unknwnbase::IUnknown,\n                    riid: *const winapi::shared::guiddef::IID,\n                    ppv: *mut *mut winapi::ctypes::c_void,\n                ) -> winapi::shared::winerror::HRESULT {\n                    if ppv.is_null() {\n                        return winapi::shared::winerror::E_POINTER;\n                    }\n                    if #( #is_equal_iid )||* {\n                        *ppv = this as *mut winapi::ctypes::c_void;\n                        winapi::shared::winerror::S_OK\n                    } else {\n                        *ppv = std::ptr::null_mut();\n                        winapi::shared::winerror::E_NOINTERFACE\n                    }\n                }\n            }\n        }\n    }\n\n    // ----------------------------------------------------------------\n\n    fn parse(input: &'a DeriveInput) -> Result<Self, String> {\n        if !Self::is_repr_c(input) {\n            return Err(\"Your struct *must* be #[repr(C)] for ComImpl.\".into());\n        }\n\n        let data = match &input.data {\n            Data::Struct(data) => data,\n            _ => return Err(\"ComImpl will only work with structs with named members.\".into()),\n        };\n        let fields = match &data.fields {\n            Fields::Named(fields) => fields,\n            _ => return Err(\"ComImpl will only work with structs with named members.\".into()),\n        };\n\n        let name = &input.ident;\n        let vtbl_member = Self::determine_vtbl_member(fields)?;\n        let refc_member = Self::determine_refcount_member(fields)?;\n        let other_members = Self::parse_members(fields, vtbl_member, refc_member);\n        let interfaces = Self::determine_interfaces(&input.attrs, fields, vtbl_member)?;\n        let generics = &input.generics;\n\n        Ok(ComImpl {\n            name,\n            vtbl_member,\n            refc_member,\n            other_members,\n            interfaces,\n            generics,\n        })\n    }\n\n    fn is_repr_c(input: &'a DeriveInput) -> bool {\n        for attr in &input.attrs {\n            if attr.path.segments.len() != 1 || attr.path.segments[0].ident != \"repr\" {\n                continue;\n            }\n\n            let meta = match attr.parse_meta() {\n                Ok(meta) => meta,\n                Err(_) => continue,\n            };\n\n            let list = match &meta {\n                Meta::List(list) if list.nested.len() > 0 => list,\n                _ => continue,\n            };\n\n            match &list.nested[0] {\n                NestedMeta::Meta(Meta::Word(id)) if id == \"C\" => return true,\n                _ => continue,\n            }\n        }\n        false\n    }\n\n    fn determine_vtbl_member(fields: &FieldsNamed) -> Result<&Ident, String> {\n        for field in fields.named.iter() {\n            let ty = Self::ty_stem(&field.ty);\n            let ty = match ty {\n                Some(ty) => ty,\n                None => continue,\n            };\n            if ty != \"VTable\" {\n                continue;\n            }\n\n            return Ok(field.ident.as_ref().unwrap());\n        }\n\n        Err(\"Could not find a com_impl::VTable member\".into())\n    }\n\n    fn determine_refcount_member(fields: &FieldsNamed) -> Result<&Ident, String> {\n        for field in fields.named.iter() {\n            let ty = Self::ty_stem(&field.ty);\n            let ty = match ty {\n                Some(ty) => ty,\n                None => continue,\n            };\n            if ty != \"Refcount\" {\n                continue;\n            }\n\n            return Ok(field.ident.as_ref().unwrap());\n        }\n\n        Err(\"Could not find a com_impl::Refcount member\".into())\n    }\n\n    fn parse_members<'b>(fields: &'b FieldsNamed, vtbl: &Ident, refc: &Ident) -> Vec<Mem<'b>> {\n        fields\n            .named\n            .iter()\n            .filter_map(|f| {\n                let name = f.ident.as_ref().unwrap();\n                if name == vtbl || name == refc {\n                    return None;\n                }\n                let ty = &f.ty;\n                Some(Mem { name, ty })\n            })\n            .collect()\n    }\n\n    fn determine_interfaces(\n        attrs: &[Attribute],\n        fields: &FieldsNamed,\n        vtbl: &Ident,\n    ) -> Result<Vec<Type>, String> {\n        for attr in attrs {\n            if attr.path.segments.len() != 1 || attr.path.segments[0].ident != \"interfaces\" {\n                continue;\n            }\n\n            let meta = attr.parse_meta().map_err(|e| e.to_string())?;\n            let list = match &meta {\n                Meta::List(list) => list,\n                _ => return Err(\"Invalid syntax for #[interfaces]\".into()),\n            };\n\n            let interfaces = Some(Ok(Self::iunknown_path()))\n                .into_iter()\n                .chain(list.nested.iter().map(|m| match m {\n                    NestedMeta::Meta(Meta::Word(word)) => Ok(Type::from(TypePath {\n                        qself: None,\n                        path: Path::from(word.clone()),\n                    })),\n                    NestedMeta::Literal(Lit::Str(lit)) => {\n                        syn::parse_str(&lit.value()).map_err(|e| e.to_string())\n                    }\n                    _ => Err(\"Bad syntax for #[interfaces]\".into()),\n                }))\n                .collect();\n\n            return interfaces;\n        }\n\n        for field in fields.named.iter() {\n            if field.ident.as_ref() != Some(vtbl) {\n                continue;\n            }\n            let mut vtbl_ty = Self::vtbl_generic(&field.ty)?.clone();\n            match &mut vtbl_ty {\n                Type::Path(path) => {\n                    let mut last = path.path.segments.last_mut().unwrap();\n                    let mut last = last.value_mut();\n                    let s = last.ident.to_string();\n                    if s.ends_with(\"Vtbl\") {\n                        let nonv = &s[..s.len() - 4];\n                        if nonv == \"IUnknown\" {\n                            return Ok(vec![Self::iunknown_path()]);\n                        }\n                        let new_end = Ident::new(nonv, last.ident.span());\n                        last.ident = new_end;\n                    } else {\n                        break;\n                    }\n                }\n                _ => unreachable!(),\n            };\n\n            return Ok(vec![Self::iunknown_path(), vtbl_ty]);\n        }\n\n        Err(\"Could not determine the COM interfaces you would like to implement.\".into())\n    }\n\n    fn iunknown_path() -> Type {\n        syn::parse_str(\"winapi::um::unknwnbase::IUnknown\").unwrap()\n    }\n\n    fn vtbl_generic(ty: &Type) -> Result<&Type, String> {\n        let segments = match ty {\n            Type::Path(typath) => &typath.path.segments,\n            _ => return Err(\"A ComImpl struct must have a VTable member.\".into()),\n        };\n\n        let final_seg = match segments.last() {\n            Some(seg) => *seg.value(),\n            None => return Err(\"A ComImpl struct must have a VTable member.\".into()),\n        };\n\n        if final_seg.ident != \"VTable\" {\n            return Err(\"A ComImpl struct must have a VTable member.\".into());\n        }\n\n        let args = match &final_seg.arguments {\n            PathArguments::AngleBracketed(args) => &args.args,\n            _ => return Err(\"Invalid generic arguments to VTable.\".into()),\n        };\n\n        if args.len() != 1 {\n            return Err(\"Invalid generic arguments to VTable.\".into());\n        }\n\n        let itype = match &args[0] {\n            GenericArgument::Type(ty) => ty,\n            _ => return Err(\"Invalid generic arguments to VTable.\".into()),\n        };\n\n        Ok(itype)\n    }\n\n    fn ty_stem(ty: &Type) -> Option<&Ident> {\n        let segments = match ty {\n            Type::Path(typath) => &typath.path.segments,\n            _ => return None,\n        };\n\n        let final_seg = *segments.last()?.value();\n        Some(&final_seg.ident)\n    }\n}\n\nstruct Mem<'a> {\n    name: &'a Ident,\n    ty: &'a Type,\n}\n\nimpl<'a> Mem<'a> {\n    fn quote_param(&self) -> TokenStream {\n        let (name, ty) = (self.name, self.ty);\n        quote! { #name: #ty }\n    }\n\n    fn quote_init(&self) -> TokenStream {\n        let name = self.name;\n        quote! { #name: #name }\n    }\n}\n"
  },
  {
    "project": "rusb",
    "target": 1,
    "commit_id": "12ee91dd081428c610d3ccb5bba422198beee084",
    "func": "use libc::{c_int, c_void, timeval};\n\nuse std::{mem, ptr, sync::Arc, sync::Once, time::Duration};\n\nuse crate::{device::Device, device_handle::DeviceHandle, device_list::DeviceList, error};\nuse libusb1_sys::{constants::*, *};\n\n#[cfg(windows)]\ntype Seconds = ::libc::c_long;\n#[cfg(windows)]\ntype MicroSeconds = ::libc::c_long;\n\n#[cfg(not(windows))]\ntype Seconds = ::libc::time_t;\n#[cfg(not(windows))]\ntype MicroSeconds = ::libc::suseconds_t;\n\n#[derive(Copy, Clone, Eq, PartialEq, Default)]\npub struct GlobalContext {}\n\n/// A `libusb` context.\n#[derive(Clone, Eq, PartialEq)]\npub struct Context {\n    context: Arc<ContextInner>,\n}\n\n#[derive(Eq, PartialEq)]\nstruct ContextInner {\n    inner: ptr::NonNull<libusb_context>,\n}\n\nimpl Drop for ContextInner {\n    /// Closes the `libusb` context.\n    fn drop(&mut self) {\n        unsafe {\n            libusb_exit(self.inner.as_ptr());\n        }\n    }\n}\n\nunsafe impl Sync for Context {}\nunsafe impl Send for Context {}\n\npub trait Hotplug<T: UsbContext> {\n    fn device_arrived(&mut self, device: Device<T>);\n    fn device_left(&mut self, device: Device<T>);\n}\n\npub type Registration = c_int;\n\npub trait UsbContext: Clone + Sized {\n    /// Get the raw libusb_context pointer, for advanced use in unsafe code.\n    fn as_raw(&self) -> *mut libusb_context;\n\n    /// Returns a list of the current USB devices.\n    fn devices(&self) -> crate::Result<DeviceList<Self>> {\n        DeviceList::new_with_context(self.clone())\n    }\n\n    /// Convenience function to open a device by its vendor ID and product ID.\n    ///\n    /// This function is provided as a convenience for building prototypes without having to\n    /// iterate a [`DeviceList`](struct.DeviceList.html). It is not meant for production\n    /// applications.\n    ///\n    /// Returns a device handle for the first device found matching `vendor_id` and `product_id`.\n    /// On error, or if the device could not be found, it returns `None`.\n    fn open_device_with_vid_pid(\n        &self,\n        vendor_id: u16,\n        product_id: u16,\n    ) -> Option<DeviceHandle<Self>> {\n        let handle =\n            unsafe { libusb_open_device_with_vid_pid(self.as_raw(), vendor_id, product_id) };\n        let ptr = std::ptr::NonNull::new(handle)?;\n        Some(unsafe { DeviceHandle::from_libusb(self.clone(), ptr) })\n    }\n\n    /// Sets the log level of a `libusb` for context.\n    fn set_log_level(&mut self, level: LogLevel) {\n        unsafe {\n            libusb_set_debug(self.as_raw(), level.as_c_int());\n        }\n    }\n\n    fn register_callback(\n        &self,\n        vendor_id: Option<u16>,\n        product_id: Option<u16>,\n        class: Option<u8>,\n        callback: Box<dyn Hotplug<Self>>,\n    ) -> crate::Result<Registration> {\n        let mut handle: libusb_hotplug_callback_handle = 0;\n        let callback = CallbackData {\n            context: self.clone(),\n            hotplug: callback,\n        };\n        let to = Box::new(callback);\n        let n = unsafe {\n            libusb_hotplug_register_callback(\n                self.as_raw(),\n                LIBUSB_HOTPLUG_EVENT_DEVICE_ARRIVED | LIBUSB_HOTPLUG_EVENT_DEVICE_LEFT,\n                LIBUSB_HOTPLUG_NO_FLAGS,\n                vendor_id\n                    .map(c_int::from)\n                    .unwrap_or(LIBUSB_HOTPLUG_MATCH_ANY),\n                product_id\n                    .map(c_int::from)\n                    .unwrap_or(LIBUSB_HOTPLUG_MATCH_ANY),\n                class.map(c_int::from).unwrap_or(LIBUSB_HOTPLUG_MATCH_ANY),\n                hotplug_callback::<Self>,\n                Box::into_raw(to) as *mut c_void,\n                &mut handle,\n            )\n        };\n        if n < 0 {\n            Err(error::from_libusb(n))\n        } else {\n            Ok(handle)\n        }\n    }\n\n    fn unregister_callback(&self, reg: Registration) {\n        // TODO: fix handler leak\n        unsafe { libusb_hotplug_deregister_callback(self.as_raw(), reg) }\n    }\n\n    fn handle_events(&self, timeout: Option<Duration>) -> crate::Result<()> {\n        let n = unsafe {\n            match timeout {\n                Some(t) => {\n                    let tv = timeval {\n                        tv_sec: t.as_secs() as Seconds,\n                        tv_usec: t.subsec_nanos() as MicroSeconds / 1000,\n                    };\n                    libusb_handle_events_timeout_completed(self.as_raw(), &tv, ptr::null_mut())\n                }\n                None => libusb_handle_events_completed(self.as_raw(), ptr::null_mut()),\n            }\n        };\n        if n < 0 {\n            Err(error::from_libusb(n as c_int))\n        } else {\n            Ok(())\n        }\n    }\n}\n\nimpl UsbContext for Context {\n    fn as_raw(&self) -> *mut libusb_context {\n        self.context.inner.as_ptr()\n    }\n}\n\nimpl UsbContext for GlobalContext {\n    fn as_raw(&self) -> *mut libusb_context {\n        static mut USB_CONTEXT: *mut libusb_context = ptr::null_mut();\n        static ONCE: Once = Once::new();\n\n        ONCE.call_once(|| {\n            let mut context = mem::MaybeUninit::<*mut libusb_context>::uninit();\n            unsafe {\n                USB_CONTEXT = match libusb_init(context.as_mut_ptr()) {\n                    0 => context.assume_init(),\n                    err => panic!(\n                        \"Can't init Global usb context, error {:?}\",\n                        error::from_libusb(err)\n                    ),\n                }\n            };\n        });\n        // Clone data that is safe to use concurrently.\n        unsafe { USB_CONTEXT }\n    }\n}\n\nstruct CallbackData<T: UsbContext> {\n    context: T,\n    hotplug: Box<dyn Hotplug<T>>,\n}\n\nimpl Context {\n    /// Opens a new `libusb` context.\n    pub fn new() -> crate::Result<Self> {\n        let mut context = mem::MaybeUninit::<*mut libusb_context>::uninit();\n\n        try_unsafe!(libusb_init(context.as_mut_ptr()));\n\n        Ok(Context {\n            context: unsafe {\n                Arc::new(ContextInner {\n                    inner: ptr::NonNull::new_unchecked(context.assume_init()),\n                })\n            },\n        })\n    }\n\n    /// Creates a new `libusb` context and sets runtime options.\n    pub fn with_options(opts: &[crate::UsbOption]) -> crate::Result<Self> {\n        let mut this = Self::new()?;\n\n        for opt in opts {\n            opt.apply(&mut this)?;\n        }\n\n        Ok(this)\n    }\n}\n\nextern \"system\" fn hotplug_callback<T: UsbContext>(\n    _ctx: *mut libusb_context,\n    device: *mut libusb_device,\n    event: libusb_hotplug_event,\n    reg: *mut c_void,\n) -> c_int {\n    unsafe {\n        let mut reg = Box::<CallbackData<T>>::from_raw(reg as _);\n        let device = Device::from_libusb(\n            reg.context.clone(),\n            std::ptr::NonNull::new_unchecked(device),\n        );\n        match event {\n            LIBUSB_HOTPLUG_EVENT_DEVICE_ARRIVED => reg.hotplug.device_arrived(device),\n            LIBUSB_HOTPLUG_EVENT_DEVICE_LEFT => reg.hotplug.device_left(device),\n            _ => (),\n        }\n        mem::forget(reg);\n    }\n    0\n}\n\n/// Library logging levels.\n#[derive(Clone, Copy)]\npub enum LogLevel {\n    /// No messages are printed by `libusb` (default).\n    None,\n\n    /// Error messages printed to `stderr`.\n    Error,\n\n    /// Warning and error messages are printed to `stderr`.\n    Warning,\n\n    /// Informational messages are printed to `stdout`. Warnings and error messages are printed to\n    /// `stderr`.\n    Info,\n\n    /// Debug and informational messages are printed to `stdout`. Warnings and error messages are\n    /// printed to `stderr`.\n    Debug,\n}\n\nimpl LogLevel {\n    pub(crate) fn as_c_int(self) -> c_int {\n        match self {\n            LogLevel::None => LIBUSB_LOG_LEVEL_NONE,\n            LogLevel::Error => LIBUSB_LOG_LEVEL_ERROR,\n            LogLevel::Warning => LIBUSB_LOG_LEVEL_WARNING,\n            LogLevel::Info => LIBUSB_LOG_LEVEL_INFO,\n            LogLevel::Debug => LIBUSB_LOG_LEVEL_DEBUG,\n        }\n    }\n}\n"
  },
  {
    "project": "flatbuffers",
    "target": 1,
    "commit_id": "842f672bafd560beeeeebed7accf196101003625",
    "func": "/*\n * Copyright 2018 Google Inc. All rights reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nuse std::marker::PhantomData;\nuse std::mem::size_of;\nuse std::ops::Deref;\n\nuse endian_scalar::{emplace_scalar, read_scalar, read_scalar_at};\nuse follow::Follow;\nuse push::Push;\n\npub const FLATBUFFERS_MAX_BUFFER_SIZE: usize = (1u64 << 31) as usize;\n\npub const FILE_IDENTIFIER_LENGTH: usize = 4;\n\npub const VTABLE_METADATA_FIELDS: usize = 2;\n\npub const SIZE_U8: usize = size_of::<u8>();\npub const SIZE_I8: usize = size_of::<i8>();\n\npub const SIZE_U16: usize = size_of::<u16>();\npub const SIZE_I16: usize = size_of::<i16>();\n\npub const SIZE_U32: usize = size_of::<u32>();\npub const SIZE_I32: usize = size_of::<i32>();\n\npub const SIZE_U64: usize = size_of::<u64>();\npub const SIZE_I64: usize = size_of::<i64>();\n\npub const SIZE_F32: usize = size_of::<f32>();\npub const SIZE_F64: usize = size_of::<f64>();\n\npub const SIZE_SOFFSET: usize = SIZE_I32;\npub const SIZE_UOFFSET: usize = SIZE_U32;\npub const SIZE_VOFFSET: usize = SIZE_I16;\n\npub const SIZE_SIZEPREFIX: usize = SIZE_UOFFSET;\n\n/// SOffsetT is an i32 that is used by tables to reference their vtables.\npub type SOffsetT = i32;\n\n/// UOffsetT is a u32 that is used by pervasively to represent both pointers\n/// and lengths of vectors.\npub type UOffsetT = u32;\n\n/// VOffsetT is a i32 that is used by vtables to store field data.\npub type VOffsetT = i16;\n\n/// TableFinishedWIPOffset marks a WIPOffset as being for a finished table.\n#[derive(Clone, Copy)]\npub struct TableFinishedWIPOffset {}\n\n/// TableUnfinishedWIPOffset marks a WIPOffset as being for an unfinished table.\n#[derive(Clone, Copy)]\npub struct TableUnfinishedWIPOffset {}\n\n/// UnionWIPOffset marks a WIPOffset as being for a union value.\n#[derive(Clone, Copy)]\npub struct UnionWIPOffset {}\n\n/// VTableWIPOffset marks a WIPOffset as being for a vtable.\n#[derive(Clone, Copy)]\npub struct VTableWIPOffset {}\n\n/// WIPOffset contains an UOffsetT with a special meaning: it is the location of\n/// data relative to the *end* of an in-progress FlatBuffer. The\n/// FlatBufferBuilder uses this to track the location of objects in an absolute\n/// way. The impl of Push converts a WIPOffset into a ForwardsUOffset.\n#[derive(Debug, Clone, Copy)]\npub struct WIPOffset<T>(UOffsetT, PhantomData<T>);\n\nimpl<T> PartialEq for WIPOffset<T> {\n    fn eq(&self, o: &WIPOffset<T>) -> bool {\n        self.value() == o.value()\n    }\n}\n\nimpl<T> Deref for WIPOffset<T> {\n    type Target = UOffsetT;\n    #[inline]\n    fn deref(&self) -> &UOffsetT {\n        &self.0\n    }\n}\nimpl<'a, T: 'a> WIPOffset<T> {\n    /// Create a new WIPOffset.\n    #[inline]\n    pub fn new(o: UOffsetT) -> WIPOffset<T> {\n        WIPOffset {\n            0: o,\n            1: PhantomData,\n        }\n    }\n\n    /// Return a wrapped value that brings its meaning as a union WIPOffset\n    /// into the type system.\n    #[inline(always)]\n    pub fn as_union_value(&self) -> WIPOffset<UnionWIPOffset> {\n        WIPOffset::new(self.0)\n    }\n    /// Get the underlying value.\n    #[inline(always)]\n    pub fn value(&self) -> UOffsetT {\n        self.0\n    }\n}\n\nimpl<T> Push for WIPOffset<T> {\n    type Output = ForwardsUOffset<T>;\n\n    #[inline(always)]\n    fn push(&self, dst: &mut [u8], rest: &[u8]) {\n        let n = (SIZE_UOFFSET + rest.len() - self.value() as usize) as UOffsetT;\n        emplace_scalar::<UOffsetT>(dst, n);\n    }\n}\n\nimpl<T> Push for ForwardsUOffset<T> {\n    type Output = Self;\n\n    #[inline(always)]\n    fn push(&self, dst: &mut [u8], rest: &[u8]) {\n        self.value().push(dst, rest);\n    }\n}\n\n/// ForwardsUOffset is used by Follow to traverse a FlatBuffer: the pointer\n/// is incremented by the value contained in this type.\n#[derive(Debug, Clone, Copy)]\npub struct ForwardsUOffset<T>(UOffsetT, PhantomData<T>);\nimpl<T> ForwardsUOffset<T> {\n    #[inline(always)]\n    pub fn value(&self) -> UOffsetT {\n        self.0\n    }\n}\n\nimpl<'a, T: Follow<'a>> Follow<'a> for ForwardsUOffset<T> {\n    type Inner = T::Inner;\n    #[inline(always)]\n    fn follow(buf: &'a [u8], loc: usize) -> Self::Inner {\n        let slice = &buf[loc..loc + SIZE_UOFFSET];\n        let off = read_scalar::<u32>(slice) as usize;\n        T::follow(buf, loc + off)\n    }\n}\n\n/// ForwardsVOffset is used by Follow to traverse a FlatBuffer: the pointer\n/// is incremented by the value contained in this type.\n#[derive(Debug)]\npub struct ForwardsVOffset<T>(VOffsetT, PhantomData<T>);\nimpl<T> ForwardsVOffset<T> {\n    #[inline(always)]\n    pub fn value(&self) -> VOffsetT {\n        self.0\n    }\n}\n\nimpl<'a, T: Follow<'a>> Follow<'a> for ForwardsVOffset<T> {\n    type Inner = T::Inner;\n    #[inline(always)]\n    fn follow(buf: &'a [u8], loc: usize) -> Self::Inner {\n        let slice = &buf[loc..loc + SIZE_VOFFSET];\n        let off = read_scalar::<VOffsetT>(slice) as usize;\n        T::follow(buf, loc + off)\n    }\n}\n\nimpl<T> Push for ForwardsVOffset<T> {\n    type Output = Self;\n\n    #[inline]\n    fn push(&self, dst: &mut [u8], rest: &[u8]) {\n        self.value().push(dst, rest);\n    }\n}\n\n/// ForwardsSOffset is used by Follow to traverse a FlatBuffer: the pointer\n/// is incremented by the *negative* of the value contained in this type.\n#[derive(Debug)]\npub struct BackwardsSOffset<T>(SOffsetT, PhantomData<T>);\nimpl<T> BackwardsSOffset<T> {\n    #[inline(always)]\n    pub fn value(&self) -> SOffsetT {\n        self.0\n    }\n}\n\nimpl<'a, T: Follow<'a>> Follow<'a> for BackwardsSOffset<T> {\n    type Inner = T::Inner;\n    #[inline(always)]\n    fn follow(buf: &'a [u8], loc: usize) -> Self::Inner {\n        let slice = &buf[loc..loc + SIZE_SOFFSET];\n        let off = read_scalar::<SOffsetT>(slice);\n        T::follow(buf, (loc as SOffsetT - off) as usize)\n    }\n}\n\nimpl<T> Push for BackwardsSOffset<T> {\n    type Output = Self;\n\n    #[inline]\n    fn push(&self, dst: &mut [u8], rest: &[u8]) {\n        self.value().push(dst, rest);\n    }\n}\n\n/// SkipSizePrefix is used by Follow to traverse a FlatBuffer: the pointer is\n/// incremented by a fixed constant in order to skip over the size prefix value.\npub struct SkipSizePrefix<T>(PhantomData<T>);\nimpl<'a, T: Follow<'a> + 'a> Follow<'a> for SkipSizePrefix<T> {\n    type Inner = T::Inner;\n    #[inline(always)]\n    fn follow(buf: &'a [u8], loc: usize) -> Self::Inner {\n        T::follow(buf, loc + SIZE_SIZEPREFIX)\n    }\n}\n\n/// SkipRootOffset is used by Follow to traverse a FlatBuffer: the pointer is\n/// incremented by a fixed constant in order to skip over the root offset value.\npub struct SkipRootOffset<T>(PhantomData<T>);\nimpl<'a, T: Follow<'a> + 'a> Follow<'a> for SkipRootOffset<T> {\n    type Inner = T::Inner;\n    #[inline(always)]\n    fn follow(buf: &'a [u8], loc: usize) -> Self::Inner {\n        T::follow(buf, loc + SIZE_UOFFSET)\n    }\n}\n\n/// FileIdentifier is used by Follow to traverse a FlatBuffer: the pointer is\n/// dereferenced into a byte slice, whose bytes are the file identifer value.\npub struct FileIdentifier;\nimpl<'a> Follow<'a> for FileIdentifier {\n    type Inner = &'a [u8];\n    #[inline(always)]\n    fn follow(buf: &'a [u8], loc: usize) -> Self::Inner {\n        &buf[loc..loc + FILE_IDENTIFIER_LENGTH]\n    }\n}\n\n/// SkipFileIdentifier is used by Follow to traverse a FlatBuffer: the pointer\n/// is incremented by a fixed constant in order to skip over the file\n/// identifier value.\npub struct SkipFileIdentifier<T>(PhantomData<T>);\nimpl<'a, T: Follow<'a> + 'a> Follow<'a> for SkipFileIdentifier<T> {\n    type Inner = T::Inner;\n    #[inline(always)]\n    fn follow(buf: &'a [u8], loc: usize) -> Self::Inner {\n        T::follow(buf, loc + FILE_IDENTIFIER_LENGTH)\n    }\n}\n\n/// Follow trait impls for primitive types.\n///\n/// Ideally, these would be implemented as a single impl using trait bounds on\n/// EndianScalar, but implementing Follow that way causes a conflict with\n/// other impls.\nmacro_rules! impl_follow_for_endian_scalar {\n    ($ty:ident) => {\n        impl<'a> Follow<'a> for $ty {\n            type Inner = $ty;\n            #[inline(always)]\n            fn follow(buf: &'a [u8], loc: usize) -> Self::Inner {\n                read_scalar_at::<$ty>(buf, loc)\n            }\n        }\n    };\n}\n\nimpl_follow_for_endian_scalar!(bool);\nimpl_follow_for_endian_scalar!(u8);\nimpl_follow_for_endian_scalar!(u16);\nimpl_follow_for_endian_scalar!(u32);\nimpl_follow_for_endian_scalar!(u64);\nimpl_follow_for_endian_scalar!(i8);\nimpl_follow_for_endian_scalar!(i16);\nimpl_follow_for_endian_scalar!(i32);\nimpl_follow_for_endian_scalar!(i64);\nimpl_follow_for_endian_scalar!(f32);\nimpl_follow_for_endian_scalar!(f64);\n"
  },
  {
    "project": "abox",
    "target": 1,
    "commit_id": "5abe75222bc49af6b62ea37f87d7be0c56973310",
    "func": "use std::mem;\nuse std::sync::Arc;\nuse std::sync::atomic::{AtomicPtr, Ordering};\nuse std::ops::Deref;\n\n\n/// AtomicBox<T> is a safe wrapper around AtomicPtr<T>\n/// You can safely swap values using the replace_with method\n#[derive(Debug)]\npub struct AtomicBox<T: Sized>\n{\n    ptr: AtomicPtr<T>,\n}\n\nimpl<T: Sized> AtomicBox<T> {\n    /// Allocates a new AtomicBox containing the given value\n    pub fn new(value: T) -> AtomicBox<T> {\n        AtomicBox {\n            ptr: AtomicPtr::new(AtomicBox::alloc_from(value)),\n        }\n    }\n\n    #[inline]\n    fn alloc_from(value: T) -> *mut T {\n        let total: Arc<T> = Arc::new(value);\n\n        Arc::into_raw(total) as *mut T\n    }\n\n    fn compare_and_swap(&self,\n                        current: *mut T,\n                        new: *mut T,\n                        order: Ordering) -> *mut T {\n        self.ptr.compare_and_swap(current, new, order)\n    }\n\n    fn take(&self) -> Arc<T> {\n        loop {\n            let curr = self.ptr.load(Ordering::Acquire);\n            let null: *mut T = std::ptr::null_mut();\n\n            if curr == null {\n                continue;\n            }\n\n            if self.compare_and_swap(curr, null, Ordering::AcqRel) == curr {\n                return unsafe { Arc::from_raw(curr) };\n            }\n        }\n    }\n\n    fn release(&self, ptr: *mut T) {\n        assert!(ptr != 0xfffffffffffffff0 as *mut T);\n        self.ptr.store(ptr, Ordering::Release);\n    }\n\n    pub fn get(&self) -> Arc<T> {\n        let val = self.take();\n        let copy = Arc::clone(&val);\n        let ptr = Arc::into_raw(val) as *mut T;\n\n        self.release(ptr);\n        copy\n    }\n\n    /// Atomically replace the inner value with the result of applying the\n    /// given closure to the current value\n    pub fn replace_with<F>(&self, f: F)\n        where F: Fn(Arc<T>) -> T\n    {\n        let val = self.take();\n        let new_val = f(val);\n        let ptr = Arc::into_raw(Arc::new(new_val)) as *mut T;\n        self.release(ptr);\n    }\n}\n\nimpl<T: Sized + PartialEq> PartialEq for AtomicBox<T> {\n    fn eq(&self, other: &AtomicBox<T>) -> bool {\n        self == other\n    }\n}\n\nimpl<T: Sized> Drop for AtomicBox<T> {\n    fn drop(&mut self) {\n        unsafe {\n            Arc::from_raw(self.ptr.load(Ordering::Acquire))\n        };\n    }\n}\n\nunsafe impl<T: Sized> Sync for AtomicBox<T> {}\nunsafe impl<T: Sized> Send for AtomicBox<T> {}\n\n#[cfg(test)]\nmod tests {\n    use std::sync::{Arc, Barrier};\n    use std::thread;\n\n    use super::AtomicBox;\n\n    #[test]\n    fn atomic_arc_new() {\n        let b = AtomicBox::new(1024);\n\n        assert_eq!(*b.get(), 1024);\n    }\n\n    #[test]\n    fn atomic_arc_replace_with() {\n        let value: i64 = 1024;\n        let b = AtomicBox::new(value);\n\n        b.replace_with(|x| *x  * 2);\n\n        assert_eq!(*b.get(), value * 2);\n    }\n\n    #[test]\n    fn atomic_arc_replace_with_ten_times() {\n        let value = 1024;\n        let b = AtomicBox::new(value);\n\n        for _i in 0..10 {\n            b.replace_with(|x| *x * 2);\n        }\n\n        assert_eq!(*b.get(), value * 2_i32.pow(10));\n    }\n\n    #[test]\n    fn atomic_arc_replace_instance() {\n        let b = Arc::new(AtomicBox::new(1024));\n        let b1 = b.clone();\n\n        b1.replace_with(|x| *x * 2);\n\n        assert_eq!(*b.get(), 2048);\n    }\n\n    #[test]\n    fn atomic_arc_threaded_leak_test() {\n        let val = Arc::new(AtomicBox::new(10));\n        let val_cpys: Vec<Arc<AtomicBox<i32>>> = (0..10)\n            .map(|_| val.clone())\n            .collect();\n        let mut guards = Vec::new();\n\n        for i in 0..10 {\n            let val_cpy = val_cpys[i].clone();\n            let guard = thread::spawn(move || {\n                val_cpy.replace_with(|x| *x * 2);\n            });\n\n            guards.push(guard);\n        }\n\n        for g in guards {\n            g.join().unwrap();\n        }\n\n        assert_eq!(*val.get(), 10 * 2_i32.pow(10));\n    }\n\n    #[test]\n    fn atomic_arc_threaded_contention() {\n        let abox = Arc::new(AtomicBox::new(0));\n        let thread_num = 10;\n        let mut guards = Vec::new();\n        let barrier = Arc::new(Barrier::new(thread_num));\n\n        for _i in 0..thread_num {\n            let b = Arc::clone(&barrier);\n            let cpy = abox.clone();\n            guards.push(thread::spawn(move || {\n                b.wait();\n                for _j in 0..1000 {\n                    cpy.replace_with(|x| *x + 100)\n                }\n            }));\n        }\n\n        for g in guards {\n            g.join().unwrap();\n        }\n\n        assert_eq!(*abox.get(), thread_num * 1000 * 100);\n    }\n\n    #[test]\n    fn atomic_arc_vector_container() {\n        let values: Vec<i32> = (0..10).map(|x: i32| {\n            x.pow(2)\n        }).collect();\n        let abox = Arc::new(AtomicBox::new(vec![]));\n        let mut guards = Vec::new();\n\n        for i in 0..10 {\n            let cpy = abox.clone();\n            let values: Vec<i32> = values.clone();\n\n            guards.push(thread::spawn(move || {\n                cpy.replace_with(|x| {\n                    let mut nx = (*x).clone();\n                    nx.push(values[i]);\n                    nx\n                })\n            }));\n        }\n\n        for g in guards {\n            g.join().unwrap();\n        }\n\n        assert_eq!(abox.get().len(), values.len());\n\n        for i in values {\n            assert_eq!(abox.get().contains(&i), true);\n        }\n    }\n}\n"
  },
  {
    "project": "quinn",
    "target": 1,
    "commit_id": "2f0dc868d7ae6682edf383e6643a4923f8d916dc",
    "func": "use std::{\n    io,\n    io::IoSliceMut,\n    mem::{self, MaybeUninit},\n    net::{IpAddr, Ipv4Addr, Ipv6Addr, SocketAddr, SocketAddrV4, SocketAddrV6},\n    os::unix::io::AsRawFd,\n    ptr,\n    task::{Context, Poll},\n};\n\nuse futures::ready;\nuse lazy_static::lazy_static;\nuse proto::{EcnCodepoint, Transmit};\nuse tokio::io::unix::AsyncFd;\n\nuse super::{cmsg, RecvMeta, UdpCapabilities};\n\n#[cfg(target_os = \"freebsd\")]\ntype IpTosTy = libc::c_uchar;\n#[cfg(not(target_os = \"freebsd\"))]\ntype IpTosTy = libc::c_int;\n\n/// Tokio-compatible UDP socket with some useful specializations.\n///\n/// Unlike a standard tokio UDP socket, this allows ECN bits to be read and written on some\n/// platforms.\n#[derive(Debug)]\npub struct UdpSocket {\n    io: AsyncFd<mio::net::UdpSocket>,\n}\n\nimpl UdpSocket {\n    pub fn from_std(socket: std::net::UdpSocket) -> io::Result<UdpSocket> {\n        socket.set_nonblocking(true)?;\n        let io = mio::net::UdpSocket::from_std(socket);\n        init(&io)?;\n        Ok(UdpSocket {\n            io: AsyncFd::new(io)?,\n        })\n    }\n\n    pub fn poll_send(\n        &self,\n        cx: &mut Context,\n        transmits: &[Transmit],\n    ) -> Poll<Result<usize, io::Error>> {\n        loop {\n            let mut guard = ready!(self.io.poll_write_ready(cx))?;\n            if let Ok(res) = guard.try_io(|io| send(io.get_ref(), transmits)) {\n                return Poll::Ready(res);\n            }\n        }\n    }\n\n    pub fn poll_recv(\n        &self,\n        cx: &mut Context,\n        bufs: &mut [IoSliceMut<'_>],\n        meta: &mut [RecvMeta],\n    ) -> Poll<io::Result<usize>> {\n        debug_assert!(!bufs.is_empty());\n        loop {\n            let mut guard = ready!(self.io.poll_read_ready(cx))?;\n            if let Ok(res) = guard.try_io(|io| recv(io.get_ref(), bufs, meta)) {\n                return Poll::Ready(res);\n            }\n        }\n    }\n\n    pub fn local_addr(&self) -> io::Result<SocketAddr> {\n        self.io.get_ref().local_addr()\n    }\n}\n\nfn init(io: &mio::net::UdpSocket) -> io::Result<()> {\n    // Safety\n    assert_eq!(\n        mem::size_of::<SocketAddrV4>(),\n        mem::size_of::<libc::sockaddr_in>()\n    );\n    assert_eq!(\n        mem::size_of::<SocketAddrV6>(),\n        mem::size_of::<libc::sockaddr_in6>()\n    );\n\n    let mut cmsg_platform_space = 0;\n    if cfg!(target_os = \"linux\") {\n        cmsg_platform_space +=\n            unsafe { libc::CMSG_SPACE(mem::size_of::<libc::in6_pktinfo>() as _) as usize };\n    }\n\n    assert!(\n        CMSG_LEN\n            >= unsafe { libc::CMSG_SPACE(mem::size_of::<libc::c_int>() as _) as usize }\n                + cmsg_platform_space\n    );\n    assert!(\n        mem::align_of::<libc::cmsghdr>() <= mem::align_of::<cmsg::Aligned<[u8; 0]>>(),\n        \"control message buffers will be misaligned\"\n    );\n\n    let addr = io.local_addr()?;\n\n    // macos and ios do not support IP_RECVTOS on dual-stack sockets :(\n    if addr.is_ipv4() || ((!cfg!(any(target_os = \"macos\", target_os = \"ios\"))) && !io.only_v6()?) {\n        let on: libc::c_int = 1;\n        let rc = unsafe {\n            libc::setsockopt(\n                io.as_raw_fd(),\n                libc::IPPROTO_IP,\n                libc::IP_RECVTOS,\n                &on as *const _ as _,\n                mem::size_of_val(&on) as _,\n            )\n        };\n        if rc == -1 {\n            return Err(io::Error::last_os_error());\n        }\n    }\n    #[cfg(target_os = \"linux\")]\n    {\n        if addr.is_ipv4() {\n            let rc = unsafe {\n                libc::setsockopt(\n                    io.as_raw_fd(),\n                    libc::IPPROTO_IP,\n                    libc::IP_MTU_DISCOVER,\n                    &libc::IP_PMTUDISC_PROBE as *const _ as _,\n                    mem::size_of_val(&libc::IP_PMTUDISC_PROBE) as _,\n                )\n            };\n            if rc == -1 {\n                return Err(io::Error::last_os_error());\n            }\n\n            let on: libc::c_int = 1;\n            let rc = unsafe {\n                libc::setsockopt(\n                    io.as_raw_fd(),\n                    libc::IPPROTO_IP,\n                    libc::IP_PKTINFO,\n                    &on as *const _ as _,\n                    mem::size_of_val(&on) as _,\n                )\n            };\n            if rc == -1 {\n                return Err(io::Error::last_os_error());\n            }\n        } else if addr.is_ipv6() {\n            let rc = unsafe {\n                libc::setsockopt(\n                    io.as_raw_fd(),\n                    libc::IPPROTO_IPV6,\n                    libc::IPV6_MTU_DISCOVER,\n                    &libc::IP_PMTUDISC_PROBE as *const _ as _,\n                    mem::size_of_val(&libc::IP_PMTUDISC_PROBE) as _,\n                )\n            };\n            if rc == -1 {\n                return Err(io::Error::last_os_error());\n            }\n\n            let on: libc::c_int = 1;\n            let rc = unsafe {\n                libc::setsockopt(\n                    io.as_raw_fd(),\n                    libc::IPPROTO_IPV6,\n                    libc::IPV6_RECVPKTINFO,\n                    &on as *const _ as _,\n                    mem::size_of_val(&on) as _,\n                )\n            };\n            if rc == -1 {\n                return Err(io::Error::last_os_error());\n            }\n        }\n    }\n    if addr.is_ipv6() {\n        let on: libc::c_int = 1;\n        let rc = unsafe {\n            libc::setsockopt(\n                io.as_raw_fd(),\n                libc::IPPROTO_IPV6,\n                libc::IPV6_RECVTCLASS,\n                &on as *const _ as _,\n                mem::size_of_val(&on) as _,\n            )\n        };\n        if rc == -1 {\n            return Err(io::Error::last_os_error());\n        }\n    }\n    Ok(())\n}\n\n#[cfg(not(any(target_os = \"macos\", target_os = \"ios\")))]\nfn send(io: &mio::net::UdpSocket, transmits: &[Transmit]) -> io::Result<usize> {\n    let mut msgs: [libc::mmsghdr; BATCH_SIZE] = unsafe { mem::zeroed() };\n    let mut iovecs: [libc::iovec; BATCH_SIZE] = unsafe { mem::zeroed() };\n    let mut cmsgs = [cmsg::Aligned([0u8; CMSG_LEN]); BATCH_SIZE];\n    for (i, transmit) in transmits.iter().enumerate().take(BATCH_SIZE) {\n        prepare_msg(\n            transmit,\n            &mut msgs[i].msg_hdr,\n            &mut iovecs[i],\n            &mut cmsgs[i],\n        );\n    }\n    loop {\n        let n = unsafe {\n            libc::sendmmsg(\n                io.as_raw_fd(),\n                msgs.as_mut_ptr(),\n                transmits.len().min(BATCH_SIZE) as _,\n                0,\n            )\n        };\n        if n == -1 {\n            let e = io::Error::last_os_error();\n            if e.kind() == io::ErrorKind::Interrupted {\n                continue;\n            }\n            return Err(e);\n        }\n        return Ok(n as usize);\n    }\n}\n\n#[cfg(any(target_os = \"macos\", target_os = \"ios\"))]\nfn send(io: &mio::net::UdpSocket, transmits: &[Transmit]) -> io::Result<usize> {\n    let mut hdr: libc::msghdr = unsafe { mem::zeroed() };\n    let mut iov: libc::iovec = unsafe { mem::zeroed() };\n    let mut ctrl = cmsg::Aligned([0u8; CMSG_LEN]);\n    let mut sent = 0;\n    while sent < transmits.len() {\n        prepare_msg(&transmits[sent], &mut hdr, &mut iov, &mut ctrl);\n        let n = unsafe { libc::sendmsg(io.as_raw_fd(), &hdr, 0) };\n        if n == -1 {\n            let e = io::Error::last_os_error();\n            if e.kind() == io::ErrorKind::Interrupted {\n                continue;\n            }\n            if sent != 0 {\n                // We need to report that some packets were sent in this case, so we rely on\n                // errors being either harmlessly transient (in the case of WouldBlock) or\n                // recurring on the next call.\n                return Ok(sent);\n            }\n            return Err(e);\n        } else {\n            sent += 1;\n        }\n    }\n    Ok(sent)\n}\n\n#[cfg(not(any(target_os = \"macos\", target_os = \"ios\")))]\nfn recv(\n    io: &mio::net::UdpSocket,\n    bufs: &mut [IoSliceMut<'_>],\n    meta: &mut [RecvMeta],\n) -> io::Result<usize> {\n    let mut names = [MaybeUninit::<libc::sockaddr_storage>::uninit(); BATCH_SIZE];\n    let mut ctrls = [cmsg::Aligned(MaybeUninit::<[u8; CMSG_LEN]>::uninit()); BATCH_SIZE];\n    let mut hdrs = unsafe { mem::zeroed::<[libc::mmsghdr; BATCH_SIZE]>() };\n    let max_msg_count = bufs.len().min(BATCH_SIZE);\n    for i in 0..max_msg_count {\n        prepare_recv(\n            &mut bufs[i],\n            &mut names[i],\n            &mut ctrls[i],\n            &mut hdrs[i].msg_hdr,\n        );\n    }\n    let msg_count = loop {\n        let n = unsafe {\n            libc::recvmmsg(\n                io.as_raw_fd(),\n                hdrs.as_mut_ptr(),\n                bufs.len().min(BATCH_SIZE) as libc::c_uint,\n                0,\n                ptr::null_mut(),\n            )\n        };\n        if n == -1 {\n            let e = io::Error::last_os_error();\n            if e.kind() == io::ErrorKind::Interrupted {\n                continue;\n            }\n            return Err(e);\n        }\n        break n;\n    };\n    for i in 0..(msg_count as usize) {\n        meta[i] = decode_recv(&names[i], &hdrs[i].msg_hdr, hdrs[i].msg_len as usize);\n    }\n    Ok(msg_count as usize)\n}\n\n#[cfg(any(target_os = \"macos\", target_os = \"ios\"))]\nfn recv(\n    io: &mio::net::UdpSocket,\n    bufs: &mut [IoSliceMut<'_>],\n    meta: &mut [RecvMeta],\n) -> io::Result<usize> {\n    let mut name = MaybeUninit::<libc::sockaddr_storage>::uninit();\n    let mut ctrl = cmsg::Aligned(MaybeUninit::<[u8; CMSG_LEN]>::uninit());\n    let mut hdr = unsafe { mem::zeroed::<libc::msghdr>() };\n    prepare_recv(&mut bufs[0], &mut name, &mut ctrl, &mut hdr);\n    let n = loop {\n        let n = unsafe { libc::recvmsg(io.as_raw_fd(), &mut hdr, 0) };\n        if n == -1 {\n            let e = io::Error::last_os_error();\n            if e.kind() == io::ErrorKind::Interrupted {\n                continue;\n            }\n            return Err(e);\n        }\n        if hdr.msg_flags & libc::MSG_TRUNC != 0 {\n            continue;\n        }\n        break n;\n    };\n    meta[0] = decode_recv(&name, &hdr, n as usize);\n    Ok(1)\n}\n\n/// Returns the platforms UDP socket capabilities\npub fn caps() -> UdpCapabilities {\n    *CAPABILITIES\n}\n\nconst CMSG_LEN: usize = 80;\n\nfn prepare_msg(\n    transmit: &Transmit,\n    hdr: &mut libc::msghdr,\n    iov: &mut libc::iovec,\n    ctrl: &mut cmsg::Aligned<[u8; CMSG_LEN]>,\n) {\n    iov.iov_base = transmit.contents.as_ptr() as *const _ as *mut _;\n    iov.iov_len = transmit.contents.len();\n\n    let (name, namelen) = match transmit.destination {\n        SocketAddr::V4(ref addr) => (addr as *const _ as _, mem::size_of::<libc::sockaddr_in>()),\n        SocketAddr::V6(ref addr) => (addr as *const _ as _, mem::size_of::<libc::sockaddr_in6>()),\n    };\n    hdr.msg_name = name;\n    hdr.msg_namelen = namelen as _;\n    hdr.msg_iov = iov;\n    hdr.msg_iovlen = 1;\n\n    hdr.msg_control = ctrl.0.as_mut_ptr() as _;\n    hdr.msg_controllen = CMSG_LEN as _;\n    let mut encoder = unsafe { cmsg::Encoder::new(hdr) };\n    let ecn = transmit.ecn.map_or(0, |x| x as libc::c_int);\n    if transmit.destination.is_ipv4() {\n        encoder.push(libc::IPPROTO_IP, libc::IP_TOS, ecn as IpTosTy);\n    } else {\n        encoder.push(libc::IPPROTO_IPV6, libc::IPV6_TCLASS, ecn);\n    }\n\n    if let Some(segment_size) = transmit.segment_size {\n        debug_assert!(\n            caps().gso,\n            \"Platform must support GSO for setting segment size\"\n        );\n\n        gso::set_segment_size(&mut encoder, segment_size as u16);\n    }\n\n    if let Some(ip) = &transmit.src_ip {\n        if cfg!(target_os = \"linux\") {\n            match ip {\n                IpAddr::V4(v4) => {\n                    let pktinfo = libc::in_pktinfo {\n                        ipi_ifindex: 0,\n                        ipi_spec_dst: unsafe {\n                            *(v4 as *const Ipv4Addr as *const () as *const libc::in_addr)\n                        },\n                        ipi_addr: libc::in_addr { s_addr: 0 },\n                    };\n                    encoder.push(libc::IPPROTO_IP, libc::IP_PKTINFO, pktinfo);\n                }\n                IpAddr::V6(v6) => {\n                    let pktinfo = libc::in6_pktinfo {\n                        ipi6_ifindex: 0,\n                        ipi6_addr: unsafe {\n                            *(v6 as *const Ipv6Addr as *const () as *const libc::in6_addr)\n                        },\n                    };\n                    encoder.push(libc::IPPROTO_IPV6, libc::IPV6_PKTINFO, pktinfo);\n                }\n            }\n        }\n    }\n\n    encoder.finish();\n}\n\nfn prepare_recv(\n    buf: &mut IoSliceMut,\n    name: &mut MaybeUninit<libc::sockaddr_storage>,\n    ctrl: &mut cmsg::Aligned<MaybeUninit<[u8; CMSG_LEN]>>,\n    hdr: &mut libc::msghdr,\n) {\n    hdr.msg_name = name.as_mut_ptr() as _;\n    hdr.msg_namelen = mem::size_of::<libc::sockaddr_storage>() as _;\n    hdr.msg_iov = buf as *mut IoSliceMut as *mut libc::iovec;\n    hdr.msg_iovlen = 1;\n    hdr.msg_control = ctrl.0.as_mut_ptr() as _;\n    hdr.msg_controllen = CMSG_LEN as _;\n    hdr.msg_flags = 0;\n}\n\nfn decode_recv(\n    name: &MaybeUninit<libc::sockaddr_storage>,\n    hdr: &libc::msghdr,\n    len: usize,\n) -> RecvMeta {\n    let name = unsafe { name.assume_init() };\n    let mut ecn_bits = 0;\n    let mut dst_ip = None;\n\n    let cmsg_iter = unsafe { cmsg::Iter::new(&hdr) };\n    for cmsg in cmsg_iter {\n        match (cmsg.cmsg_level, cmsg.cmsg_type) {\n            // FreeBSD uses IP_RECVTOS here, and we can be liberal because cmsgs are opt-in.\n            (libc::IPPROTO_IP, libc::IP_TOS) | (libc::IPPROTO_IP, libc::IP_RECVTOS) => unsafe {\n                ecn_bits = cmsg::decode::<u8>(cmsg);\n            },\n            (libc::IPPROTO_IPV6, libc::IPV6_TCLASS) => unsafe {\n                // Temporary hack around broken macos ABI. Remove once upstream fixes it.\n                // https://bugreport.apple.com/web/?problemID=48761855\n                if cfg!(target_os = \"macos\")\n                    && cmsg.cmsg_len as usize == libc::CMSG_LEN(mem::size_of::<u8>() as _) as usize\n                {\n                    ecn_bits = cmsg::decode::<u8>(cmsg);\n                } else {\n                    ecn_bits = cmsg::decode::<libc::c_int>(cmsg) as u8;\n                }\n            },\n            (libc::IPPROTO_IP, libc::IP_PKTINFO) => unsafe {\n                let pktinfo = cmsg::decode::<libc::in_pktinfo>(cmsg);\n                dst_ip = Some(IpAddr::V4(ptr::read(&pktinfo.ipi_addr as *const _ as _)));\n            },\n            (libc::IPPROTO_IPV6, libc::IPV6_PKTINFO) => unsafe {\n                let pktinfo = cmsg::decode::<libc::in6_pktinfo>(cmsg);\n                dst_ip = Some(IpAddr::V6(ptr::read(&pktinfo.ipi6_addr as *const _ as _)));\n            },\n            _ => {}\n        }\n    }\n\n    let addr = match libc::c_int::from(name.ss_family) {\n        libc::AF_INET => unsafe { SocketAddr::V4(ptr::read(&name as *const _ as _)) },\n        libc::AF_INET6 => unsafe { SocketAddr::V6(ptr::read(&name as *const _ as _)) },\n        _ => unreachable!(),\n    };\n\n    RecvMeta {\n        len,\n        addr,\n        ecn: EcnCodepoint::from_bits(ecn_bits),\n        dst_ip,\n    }\n}\n\n#[cfg(not(any(target_os = \"macos\", target_os = \"ios\")))]\n// Chosen somewhat arbitrarily; might benefit from additional tuning.\npub const BATCH_SIZE: usize = 32;\n\n#[cfg(any(target_os = \"macos\", target_os = \"ios\"))]\npub const BATCH_SIZE: usize = 1;\n\n#[cfg(target_os = \"linux\")]\nmod gso {\n    use super::*;\n\n    /// Checks whether GSO support is available by setting the UDP_SEGMENT\n    /// option on a socket\n    pub fn supports_gso() -> bool {\n        const GSO_SIZE: libc::c_int = 1500;\n\n        let socket = match std::net::UdpSocket::bind(\"[::]:0\") {\n            Ok(socket) => socket,\n            Err(_) => return false,\n        };\n\n        let rc = unsafe {\n            libc::setsockopt(\n                socket.as_raw_fd(),\n                libc::SOL_UDP,\n                libc::UDP_SEGMENT,\n                &GSO_SIZE as *const _ as _,\n                mem::size_of_val(&GSO_SIZE) as _,\n            )\n        };\n\n        rc != -1\n    }\n\n    pub fn set_segment_size(encoder: &mut cmsg::Encoder, segment_size: u16) {\n        encoder.push(libc::SOL_UDP, libc::UDP_SEGMENT, segment_size);\n    }\n}\n\n#[cfg(not(target_os = \"linux\"))]\nmod gso {\n    use super::*;\n\n    pub fn supports_gso() -> bool {\n        false\n    }\n\n    pub fn set_segment_size(_encoder: &mut cmsg::Encoder, _segment_size: u16) {\n        panic!(\"Setting a segment size is not supported on current platform\");\n    }\n}\n\nlazy_static! {\n    static ref CAPABILITIES: UdpCapabilities = {\n        UdpCapabilities {\n            gso: gso::supports_gso(),\n        }\n    };\n}\n"
  },
  {
    "project": "quinn",
    "target": 1,
    "commit_id": "ae13bdac8b95966a4fdef3b17aa6d2096799f7cb",
    "func": "use std::{\n    io,\n    io::IoSliceMut,\n    mem::{self, MaybeUninit},\n    net::{IpAddr, SocketAddr, SocketAddrV4, SocketAddrV6},\n    os::unix::io::AsRawFd,\n    ptr,\n    task::{Context, Poll},\n};\n\nuse futures::ready;\nuse lazy_static::lazy_static;\nuse proto::{EcnCodepoint, Transmit};\nuse tokio::io::unix::AsyncFd;\n\nuse super::{cmsg, RecvMeta, UdpCapabilities};\n\n#[cfg(target_os = \"freebsd\")]\ntype IpTosTy = libc::c_uchar;\n#[cfg(not(target_os = \"freebsd\"))]\ntype IpTosTy = libc::c_int;\n\n/// Tokio-compatible UDP socket with some useful specializations.\n///\n/// Unlike a standard tokio UDP socket, this allows ECN bits to be read and written on some\n/// platforms.\n#[derive(Debug)]\npub struct UdpSocket {\n    io: AsyncFd<mio::net::UdpSocket>,\n}\n\nimpl UdpSocket {\n    pub fn from_std(socket: std::net::UdpSocket) -> io::Result<UdpSocket> {\n        socket.set_nonblocking(true)?;\n        let io = mio::net::UdpSocket::from_std(socket);\n        init(&io)?;\n        Ok(UdpSocket {\n            io: AsyncFd::new(io)?,\n        })\n    }\n\n    pub fn poll_send(\n        &self,\n        cx: &mut Context,\n        transmits: &[Transmit],\n    ) -> Poll<Result<usize, io::Error>> {\n        loop {\n            let mut guard = ready!(self.io.poll_write_ready(cx))?;\n            if let Ok(res) = guard.try_io(|io| send(io.get_ref(), transmits)) {\n                return Poll::Ready(res);\n            }\n        }\n    }\n\n    pub fn poll_recv(\n        &self,\n        cx: &mut Context,\n        bufs: &mut [IoSliceMut<'_>],\n        meta: &mut [RecvMeta],\n    ) -> Poll<io::Result<usize>> {\n        debug_assert!(!bufs.is_empty());\n        loop {\n            let mut guard = ready!(self.io.poll_read_ready(cx))?;\n            if let Ok(res) = guard.try_io(|io| recv(io.get_ref(), bufs, meta)) {\n                return Poll::Ready(res);\n            }\n        }\n    }\n\n    pub fn local_addr(&self) -> io::Result<SocketAddr> {\n        self.io.get_ref().local_addr()\n    }\n}\n\nfn init(io: &mio::net::UdpSocket) -> io::Result<()> {\n    // Safety\n    assert_eq!(\n        mem::size_of::<SocketAddrV4>(),\n        mem::size_of::<libc::sockaddr_in>()\n    );\n    assert_eq!(\n        mem::size_of::<SocketAddrV6>(),\n        mem::size_of::<libc::sockaddr_in6>()\n    );\n\n    let mut cmsg_platform_space = 0;\n    if cfg!(target_os = \"linux\") {\n        cmsg_platform_space +=\n            unsafe { libc::CMSG_SPACE(mem::size_of::<libc::in6_pktinfo>() as _) as usize };\n    }\n\n    assert!(\n        CMSG_LEN\n            >= unsafe { libc::CMSG_SPACE(mem::size_of::<libc::c_int>() as _) as usize }\n                + cmsg_platform_space\n    );\n    assert!(\n        mem::align_of::<libc::cmsghdr>() <= mem::align_of::<cmsg::Aligned<[u8; 0]>>(),\n        \"control message buffers will be misaligned\"\n    );\n\n    let addr = io.local_addr()?;\n\n    // macos and ios do not support IP_RECVTOS on dual-stack sockets :(\n    if addr.is_ipv4() || ((!cfg!(any(target_os = \"macos\", target_os = \"ios\"))) && !io.only_v6()?) {\n        let on: libc::c_int = 1;\n        let rc = unsafe {\n            libc::setsockopt(\n                io.as_raw_fd(),\n                libc::IPPROTO_IP,\n                libc::IP_RECVTOS,\n                &on as *const _ as _,\n                mem::size_of_val(&on) as _,\n            )\n        };\n        if rc == -1 {\n            return Err(io::Error::last_os_error());\n        }\n    }\n    #[cfg(target_os = \"linux\")]\n    {\n        if addr.is_ipv4() {\n            let rc = unsafe {\n                libc::setsockopt(\n                    io.as_raw_fd(),\n                    libc::IPPROTO_IP,\n                    libc::IP_MTU_DISCOVER,\n                    &libc::IP_PMTUDISC_PROBE as *const _ as _,\n                    mem::size_of_val(&libc::IP_PMTUDISC_PROBE) as _,\n                )\n            };\n            if rc == -1 {\n                return Err(io::Error::last_os_error());\n            }\n\n            let on: libc::c_int = 1;\n            let rc = unsafe {\n                libc::setsockopt(\n                    io.as_raw_fd(),\n                    libc::IPPROTO_IP,\n                    libc::IP_PKTINFO,\n                    &on as *const _ as _,\n                    mem::size_of_val(&on) as _,\n                )\n            };\n            if rc == -1 {\n                return Err(io::Error::last_os_error());\n            }\n        } else if addr.is_ipv6() {\n            let rc = unsafe {\n                libc::setsockopt(\n                    io.as_raw_fd(),\n                    libc::IPPROTO_IPV6,\n                    libc::IPV6_MTU_DISCOVER,\n                    &libc::IP_PMTUDISC_PROBE as *const _ as _,\n                    mem::size_of_val(&libc::IP_PMTUDISC_PROBE) as _,\n                )\n            };\n            if rc == -1 {\n                return Err(io::Error::last_os_error());\n            }\n\n            let on: libc::c_int = 1;\n            let rc = unsafe {\n                libc::setsockopt(\n                    io.as_raw_fd(),\n                    libc::IPPROTO_IPV6,\n                    libc::IPV6_RECVPKTINFO,\n                    &on as *const _ as _,\n                    mem::size_of_val(&on) as _,\n                )\n            };\n            if rc == -1 {\n                return Err(io::Error::last_os_error());\n            }\n        }\n    }\n    if addr.is_ipv6() {\n        let on: libc::c_int = 1;\n        let rc = unsafe {\n            libc::setsockopt(\n                io.as_raw_fd(),\n                libc::IPPROTO_IPV6,\n                libc::IPV6_RECVTCLASS,\n                &on as *const _ as _,\n                mem::size_of_val(&on) as _,\n            )\n        };\n        if rc == -1 {\n            return Err(io::Error::last_os_error());\n        }\n    }\n    Ok(())\n}\n\n#[cfg(not(any(target_os = \"macos\", target_os = \"ios\")))]\nfn send(io: &mio::net::UdpSocket, transmits: &[Transmit]) -> io::Result<usize> {\n    let mut msgs: [libc::mmsghdr; BATCH_SIZE] = unsafe { mem::zeroed() };\n    let mut iovecs: [libc::iovec; BATCH_SIZE] = unsafe { mem::zeroed() };\n    let mut cmsgs = [cmsg::Aligned([0u8; CMSG_LEN]); BATCH_SIZE];\n    for (i, transmit) in transmits.iter().enumerate().take(BATCH_SIZE) {\n        prepare_msg(\n            transmit,\n            &mut msgs[i].msg_hdr,\n            &mut iovecs[i],\n            &mut cmsgs[i],\n        );\n    }\n    loop {\n        let n = unsafe {\n            libc::sendmmsg(\n                io.as_raw_fd(),\n                msgs.as_mut_ptr(),\n                transmits.len().min(BATCH_SIZE) as _,\n                0,\n            )\n        };\n        if n == -1 {\n            let e = io::Error::last_os_error();\n            if e.kind() == io::ErrorKind::Interrupted {\n                continue;\n            }\n            return Err(e);\n        }\n        return Ok(n as usize);\n    }\n}\n\n#[cfg(any(target_os = \"macos\", target_os = \"ios\"))]\nfn send(io: &mio::net::UdpSocket, transmits: &[Transmit]) -> io::Result<usize> {\n    let mut hdr: libc::msghdr = unsafe { mem::zeroed() };\n    let mut iov: libc::iovec = unsafe { mem::zeroed() };\n    let mut ctrl = cmsg::Aligned([0u8; CMSG_LEN]);\n    let mut sent = 0;\n    while sent < transmits.len() {\n        prepare_msg(&transmits[sent], &mut hdr, &mut iov, &mut ctrl);\n        let n = unsafe { libc::sendmsg(io.as_raw_fd(), &hdr, 0) };\n        if n == -1 {\n            let e = io::Error::last_os_error();\n            if e.kind() == io::ErrorKind::Interrupted {\n                continue;\n            }\n            if sent != 0 {\n                // We need to report that some packets were sent in this case, so we rely on\n                // errors being either harmlessly transient (in the case of WouldBlock) or\n                // recurring on the next call.\n                return Ok(sent);\n            }\n            return Err(e);\n        } else {\n            sent += 1;\n        }\n    }\n    Ok(sent)\n}\n\n#[cfg(not(any(target_os = \"macos\", target_os = \"ios\")))]\nfn recv(\n    io: &mio::net::UdpSocket,\n    bufs: &mut [IoSliceMut<'_>],\n    meta: &mut [RecvMeta],\n) -> io::Result<usize> {\n    let mut names = [MaybeUninit::<libc::sockaddr_storage>::uninit(); BATCH_SIZE];\n    let mut ctrls = [cmsg::Aligned(MaybeUninit::<[u8; CMSG_LEN]>::uninit()); BATCH_SIZE];\n    let mut hdrs = unsafe { mem::zeroed::<[libc::mmsghdr; BATCH_SIZE]>() };\n    let max_msg_count = bufs.len().min(BATCH_SIZE);\n    for i in 0..max_msg_count {\n        prepare_recv(\n            &mut bufs[i],\n            &mut names[i],\n            &mut ctrls[i],\n            &mut hdrs[i].msg_hdr,\n        );\n    }\n    let msg_count = loop {\n        let n = unsafe {\n            libc::recvmmsg(\n                io.as_raw_fd(),\n                hdrs.as_mut_ptr(),\n                bufs.len().min(BATCH_SIZE) as libc::c_uint,\n                0,\n                ptr::null_mut(),\n            )\n        };\n        if n == -1 {\n            let e = io::Error::last_os_error();\n            if e.kind() == io::ErrorKind::Interrupted {\n                continue;\n            }\n            return Err(e);\n        }\n        break n;\n    };\n    for i in 0..(msg_count as usize) {\n        meta[i] = decode_recv(&names[i], &hdrs[i].msg_hdr, hdrs[i].msg_len as usize);\n    }\n    Ok(msg_count as usize)\n}\n\n#[cfg(any(target_os = \"macos\", target_os = \"ios\"))]\nfn recv(\n    io: &mio::net::UdpSocket,\n    bufs: &mut [IoSliceMut<'_>],\n    meta: &mut [RecvMeta],\n) -> io::Result<usize> {\n    let mut name = MaybeUninit::<libc::sockaddr_storage>::uninit();\n    let mut ctrl = cmsg::Aligned(MaybeUninit::<[u8; CMSG_LEN]>::uninit());\n    let mut hdr = unsafe { mem::zeroed::<libc::msghdr>() };\n    prepare_recv(&mut bufs[0], &mut name, &mut ctrl, &mut hdr);\n    let n = loop {\n        let n = unsafe { libc::recvmsg(io.as_raw_fd(), &mut hdr, 0) };\n        if n == -1 {\n            let e = io::Error::last_os_error();\n            if e.kind() == io::ErrorKind::Interrupted {\n                continue;\n            }\n            return Err(e);\n        }\n        if hdr.msg_flags & libc::MSG_TRUNC != 0 {\n            continue;\n        }\n        break n;\n    };\n    meta[0] = decode_recv(&name, &hdr, n as usize);\n    Ok(1)\n}\n\n/// Returns the platforms UDP socket capabilities\npub fn caps() -> UdpCapabilities {\n    *CAPABILITIES\n}\n\nconst CMSG_LEN: usize = 80;\n\nfn prepare_msg(\n    transmit: &Transmit,\n    hdr: &mut libc::msghdr,\n    iov: &mut libc::iovec,\n    ctrl: &mut cmsg::Aligned<[u8; CMSG_LEN]>,\n) {\n    iov.iov_base = transmit.contents.as_ptr() as *const _ as *mut _;\n    iov.iov_len = transmit.contents.len();\n\n    let (name, namelen) = match transmit.destination {\n        SocketAddr::V4(ref addr) => (addr as *const _ as _, mem::size_of::<libc::sockaddr_in>()),\n        SocketAddr::V6(ref addr) => (addr as *const _ as _, mem::size_of::<libc::sockaddr_in6>()),\n    };\n    hdr.msg_name = name;\n    hdr.msg_namelen = namelen as _;\n    hdr.msg_iov = iov;\n    hdr.msg_iovlen = 1;\n\n    hdr.msg_control = ctrl.0.as_mut_ptr() as _;\n    hdr.msg_controllen = CMSG_LEN as _;\n    let mut encoder = unsafe { cmsg::Encoder::new(hdr) };\n    let ecn = transmit.ecn.map_or(0, |x| x as libc::c_int);\n    if transmit.destination.is_ipv4() {\n        encoder.push(libc::IPPROTO_IP, libc::IP_TOS, ecn as IpTosTy);\n    } else {\n        encoder.push(libc::IPPROTO_IPV6, libc::IPV6_TCLASS, ecn);\n    }\n\n    if let Some(segment_size) = transmit.segment_size {\n        debug_assert!(\n            caps().gso,\n            \"Platform must support GSO for setting segment size\"\n        );\n\n        gso::set_segment_size(&mut encoder, segment_size as u16);\n    }\n\n    if let Some(ip) = &transmit.src_ip {\n        if cfg!(target_os = \"linux\") {\n            match ip {\n                IpAddr::V4(v4) => {\n                    let pktinfo = libc::in_pktinfo {\n                        ipi_ifindex: 0,\n                        ipi_spec_dst: libc::in_addr {\n                            s_addr: u32::from_ne_bytes(v4.octets()),\n                        },\n                        ipi_addr: libc::in_addr { s_addr: 0 },\n                    };\n                    encoder.push(libc::IPPROTO_IP, libc::IP_PKTINFO, pktinfo);\n                }\n                IpAddr::V6(v6) => {\n                    let pktinfo = libc::in6_pktinfo {\n                        ipi6_ifindex: 0,\n                        ipi6_addr: libc::in6_addr {\n                            s6_addr: v6.octets(),\n                        },\n                    };\n                    encoder.push(libc::IPPROTO_IPV6, libc::IPV6_PKTINFO, pktinfo);\n                }\n            }\n        }\n    }\n\n    encoder.finish();\n}\n\nfn prepare_recv(\n    buf: &mut IoSliceMut,\n    name: &mut MaybeUninit<libc::sockaddr_storage>,\n    ctrl: &mut cmsg::Aligned<MaybeUninit<[u8; CMSG_LEN]>>,\n    hdr: &mut libc::msghdr,\n) {\n    hdr.msg_name = name.as_mut_ptr() as _;\n    hdr.msg_namelen = mem::size_of::<libc::sockaddr_storage>() as _;\n    hdr.msg_iov = buf as *mut IoSliceMut as *mut libc::iovec;\n    hdr.msg_iovlen = 1;\n    hdr.msg_control = ctrl.0.as_mut_ptr() as _;\n    hdr.msg_controllen = CMSG_LEN as _;\n    hdr.msg_flags = 0;\n}\n\nfn decode_recv(\n    name: &MaybeUninit<libc::sockaddr_storage>,\n    hdr: &libc::msghdr,\n    len: usize,\n) -> RecvMeta {\n    let name = unsafe { name.assume_init() };\n    let mut ecn_bits = 0;\n    let mut dst_ip = None;\n\n    let cmsg_iter = unsafe { cmsg::Iter::new(&hdr) };\n    for cmsg in cmsg_iter {\n        match (cmsg.cmsg_level, cmsg.cmsg_type) {\n            // FreeBSD uses IP_RECVTOS here, and we can be liberal because cmsgs are opt-in.\n            (libc::IPPROTO_IP, libc::IP_TOS) | (libc::IPPROTO_IP, libc::IP_RECVTOS) => unsafe {\n                ecn_bits = cmsg::decode::<u8>(cmsg);\n            },\n            (libc::IPPROTO_IPV6, libc::IPV6_TCLASS) => unsafe {\n                // Temporary hack around broken macos ABI. Remove once upstream fixes it.\n                // https://bugreport.apple.com/web/?problemID=48761855\n                if cfg!(target_os = \"macos\")\n                    && cmsg.cmsg_len as usize == libc::CMSG_LEN(mem::size_of::<u8>() as _) as usize\n                {\n                    ecn_bits = cmsg::decode::<u8>(cmsg);\n                } else {\n                    ecn_bits = cmsg::decode::<libc::c_int>(cmsg) as u8;\n                }\n            },\n            (libc::IPPROTO_IP, libc::IP_PKTINFO) => unsafe {\n                let pktinfo = cmsg::decode::<libc::in_pktinfo>(cmsg);\n                dst_ip = Some(IpAddr::V4(ptr::read(&pktinfo.ipi_addr as *const _ as _)));\n            },\n            (libc::IPPROTO_IPV6, libc::IPV6_PKTINFO) => unsafe {\n                let pktinfo = cmsg::decode::<libc::in6_pktinfo>(cmsg);\n                dst_ip = Some(IpAddr::V6(ptr::read(&pktinfo.ipi6_addr as *const _ as _)));\n            },\n            _ => {}\n        }\n    }\n\n    let addr = match libc::c_int::from(name.ss_family) {\n        libc::AF_INET => unsafe { SocketAddr::V4(ptr::read(&name as *const _ as _)) },\n        libc::AF_INET6 => unsafe { SocketAddr::V6(ptr::read(&name as *const _ as _)) },\n        _ => unreachable!(),\n    };\n\n    RecvMeta {\n        len,\n        addr,\n        ecn: EcnCodepoint::from_bits(ecn_bits),\n        dst_ip,\n    }\n}\n\n#[cfg(not(any(target_os = \"macos\", target_os = \"ios\")))]\n// Chosen somewhat arbitrarily; might benefit from additional tuning.\npub const BATCH_SIZE: usize = 32;\n\n#[cfg(any(target_os = \"macos\", target_os = \"ios\"))]\npub const BATCH_SIZE: usize = 1;\n\n#[cfg(target_os = \"linux\")]\nmod gso {\n    use super::*;\n\n    /// Checks whether GSO support is available by setting the UDP_SEGMENT\n    /// option on a socket\n    pub fn supports_gso() -> bool {\n        const GSO_SIZE: libc::c_int = 1500;\n\n        let socket = match std::net::UdpSocket::bind(\"[::]:0\") {\n            Ok(socket) => socket,\n            Err(_) => return false,\n        };\n\n        let rc = unsafe {\n            libc::setsockopt(\n                socket.as_raw_fd(),\n                libc::SOL_UDP,\n                libc::UDP_SEGMENT,\n                &GSO_SIZE as *const _ as _,\n                mem::size_of_val(&GSO_SIZE) as _,\n            )\n        };\n\n        rc != -1\n    }\n\n    pub fn set_segment_size(encoder: &mut cmsg::Encoder, segment_size: u16) {\n        encoder.push(libc::SOL_UDP, libc::UDP_SEGMENT, segment_size);\n    }\n}\n\n#[cfg(not(target_os = \"linux\"))]\nmod gso {\n    use super::*;\n\n    pub fn supports_gso() -> bool {\n        false\n    }\n\n    pub fn set_segment_size(_encoder: &mut cmsg::Encoder, _segment_size: u16) {\n        panic!(\"Setting a segment size is not supported on current platform\");\n    }\n}\n\nlazy_static! {\n    static ref CAPABILITIES: UdpCapabilities = {\n        UdpCapabilities {\n            gso: gso::supports_gso(),\n        }\n    };\n}\n"
  },
  {
    "project": "conqueue",
    "target": 1,
    "commit_id": "442843346d3cb69cd54143450fef21bdd4c698f0",
    "func": "use std::mem;\nuse std::ptr;\nuse std::sync::atomic::{AtomicPtr, Ordering};\nuse std::sync::Arc;\n\nstruct QueueHead<T> {\n    element: Option<T>,\n    next: *mut QueueHead<T>,\n}\n\n/// A `QueueSender` is used to push items into\n/// the queue.\n///\n/// It implements `Send` and `Sync`, thus allowing\n/// multiple callers to concurrent push items.\npub struct QueueSender<T> {\n    in_queue: Arc<AtomicPtr<QueueHead<T>>>,\n}\n\nimpl<T> QueueSender<T> {\n    /// Push the supplied element into the queue.\n    pub fn push(&self, element: T) {\n        let mut in_queue = ptr::null_mut();\n        let mut new = Box::into_raw(Box::new(QueueHead {\n            element: Some(element),\n            next: in_queue,\n        }));\n\n        loop {\n            match self\n                .in_queue\n                .compare_exchange(in_queue, new, Ordering::SeqCst, Ordering::SeqCst)\n            {\n                Ok(_) => {\n                    return;\n                }\n\n                Err(actual) => {\n                    in_queue = actual;\n\n                    unsafe {\n                        if !in_queue.is_null() && (*in_queue).element.is_none() {\n                            Box::from_raw(new);\n                            return;\n                        }\n\n                        (*new).next = in_queue;\n                    }\n                }\n            }\n        }\n    }\n}\n\nimpl<T> Clone for QueueSender<T> {\n    fn clone(&self) -> Self {\n        Self {\n            in_queue: self.in_queue.clone(),\n        }\n    }\n}\n\nimpl<T> Drop for QueueSender<T> {\n    fn drop(&mut self) {\n        let mut in_queue = Arc::new(AtomicPtr::default());\n\n        mem::swap(&mut in_queue, &mut self.in_queue);\n\n        if let Ok(head) = Arc::try_unwrap(in_queue) {\n            let head = head.swap(ptr::null_mut(), Ordering::SeqCst);\n\n            if !head.is_null() {\n                unsafe { Box::from_raw(head) };\n            }\n        }\n    }\n}\n\nunsafe impl<T> Sync for QueueSender<T> {}\n\nunsafe impl<T> Send for QueueSender<T> {}\n\n/// A `QueueReceiver` is used to pop previously\n/// pushed items from the queue.\npub struct QueueReceiver<T> {\n    in_queue: Arc<AtomicPtr<QueueHead<T>>>,\n    out_queue: *mut QueueHead<T>,\n}\n\nimpl<T> QueueReceiver<T> {\n    /// Pop an item from the queue. If the queue is\n    /// empty, `None` is returned.\n    pub fn pop(&mut self) -> Option<T> {\n        if self.out_queue.is_null() {\n            let mut head = ptr::null_mut();\n\n            loop {\n                match self.in_queue.compare_exchange(\n                    head,\n                    ptr::null_mut(),\n                    Ordering::SeqCst,\n                    Ordering::SeqCst,\n                ) {\n                    Ok(_) => {\n                        while !head.is_null() {\n                            unsafe {\n                                let next = (*head).next;\n                                (*head).next = self.out_queue;\n                                self.out_queue = head;\n                                head = next;\n                            }\n                        }\n\n                        break;\n                    }\n\n                    Err(actual) => {\n                        head = actual;\n\n                        if head.is_null() {\n                            break;\n                        }\n                    }\n                }\n            }\n        }\n\n        if self.out_queue.is_null() {\n            None\n        } else {\n            unsafe {\n                let head = Box::from_raw(self.out_queue);\n                self.out_queue = head.next;\n                Some(head.element.unwrap())\n            }\n        }\n    }\n}\n\nimpl<T> Drop for QueueReceiver<T> {\n    fn drop(&mut self) {\n        let last = Box::into_raw(Box::new(QueueHead {\n            element: None,\n            next: ptr::null_mut(),\n        }));\n\n        let mut head = ptr::null_mut();\n\n        loop {\n            match self\n                .in_queue\n                .compare_exchange(head, last, Ordering::SeqCst, Ordering::SeqCst)\n            {\n                Ok(_) => {\n                    while !head.is_null() {\n                        let boxed = unsafe { Box::from_raw(head) };\n\n                        head = boxed.next;\n                    }\n\n                    break;\n                }\n\n                Err(actual) => {\n                    head = actual;\n                }\n            }\n        }\n\n        let mut in_queue = Arc::new(AtomicPtr::default());\n\n        mem::swap(&mut in_queue, &mut self.in_queue);\n\n        if let Ok(head) = Arc::try_unwrap(in_queue) {\n            let head = head.swap(ptr::null_mut(), Ordering::SeqCst);\n\n            if !head.is_null() {\n                unsafe { Box::from_raw(head) };\n            }\n        }\n    }\n}\n\nunsafe impl<T> Send for QueueReceiver<T> {}\n\npub struct Queue;\n\nimpl Queue {\n    /// Create a new queue, returning a sender\n    /// and receiver pair.\n    ///\n    /// Senders may be cloned to allow multiple\n    /// producers, but only a single receiver\n    /// may exist.\n    pub fn unbounded<T>() -> (QueueSender<T>, QueueReceiver<T>) {\n        let in_queue = Arc::new(AtomicPtr::new(ptr::null_mut()));\n\n        let receiver = QueueReceiver {\n            in_queue: in_queue.clone(),\n            out_queue: ptr::null_mut(),\n        };\n\n        let sender = QueueSender { in_queue };\n\n        (sender, receiver)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use crate::Queue;\n    use std::sync::atomic::{AtomicUsize, Ordering};\n    use std::sync::Arc;\n    use std::thread;\n    use std::time;\n\n    #[test]\n    fn test_single_thread() {\n        let (tx, mut rx) = Queue::unbounded();\n\n        tx.push(1);\n        tx.push(2);\n        tx.push(3);\n        tx.push(4);\n\n        assert_eq!(rx.pop(), Some(1));\n        assert_eq!(rx.pop(), Some(2));\n        assert_eq!(rx.pop(), Some(3));\n        assert_eq!(rx.pop(), Some(4));\n\n        tx.push(4);\n        tx.push(3);\n        tx.push(2);\n        tx.push(1);\n\n        assert_eq!(rx.pop(), Some(4));\n        assert_eq!(rx.pop(), Some(3));\n        assert_eq!(rx.pop(), Some(2));\n        assert_eq!(rx.pop(), Some(1));\n    }\n\n    #[test]\n    fn test_multiple_threads() {\n        let (tx, mut rx) = Queue::unbounded();\n\n        tx.push(1);\n        tx.push(2);\n        tx.push(3);\n        tx.push(4);\n\n        assert_eq!(rx.pop(), Some(1));\n        assert_eq!(rx.pop(), Some(2));\n        assert_eq!(rx.pop(), Some(3));\n        assert_eq!(rx.pop(), Some(4));\n\n        tx.push(4);\n        tx.push(3);\n        tx.push(2);\n        tx.push(1);\n\n        assert_eq!(rx.pop(), Some(4));\n        assert_eq!(rx.pop(), Some(3));\n        assert_eq!(rx.pop(), Some(2));\n        assert_eq!(rx.pop(), Some(1));\n    }\n\n    #[test]\n    fn test_disconnected() {\n        struct MyStruct {\n            dropped: Arc<AtomicUsize>,\n        }\n\n        impl Drop for MyStruct {\n            fn drop(&mut self) {\n                self.dropped.fetch_add(1, Ordering::SeqCst);\n            }\n        }\n\n        let dropped = Arc::new(AtomicUsize::new(0));\n\n        let (tx, rx) = Queue::unbounded();\n\n        for _ in 1..=10 {\n            tx.push(MyStruct {\n                dropped: dropped.clone(),\n            });\n        }\n\n        drop(rx);\n\n        for _ in 1..=10 {\n            tx.push(MyStruct {\n                dropped: dropped.clone(),\n            });\n        }\n\n        assert_eq!(dropped.load(Ordering::SeqCst), 20);\n    }\n\n    #[test]\n    fn test_drop() {\n        struct MyStruct {\n            sum: Arc<AtomicUsize>,\n            value: usize,\n        }\n\n        impl Drop for MyStruct {\n            fn drop(&mut self) {\n                self.sum.fetch_add(self.value, Ordering::SeqCst);\n            }\n        }\n\n        let sum = Arc::new(AtomicUsize::new(0));\n\n        let (tx, mut rx) = Queue::unbounded();\n\n        tx.push(MyStruct {\n            sum: sum.clone(),\n            value: 1,\n        });\n        tx.push(MyStruct {\n            sum: sum.clone(),\n            value: 2,\n        });\n        tx.push(MyStruct {\n            sum: sum.clone(),\n            value: 3,\n        });\n\n        assert_eq!(rx.pop().map(|s| s.value), Some(1));\n        assert_eq!(rx.pop().map(|s| s.value), Some(2));\n        assert_eq!(rx.pop().map(|s| s.value), Some(3));\n        assert_eq!(rx.pop().map(|s| s.value), None);\n\n        assert_eq!(sum.load(Ordering::SeqCst), 6);\n    }\n\n    #[test]\n    #[ignore]\n    fn benchmark() {\n        let num_items = 10_000_000;\n\n        for n in [1, 2, 4, 8, 16, 32, 64, 128].iter() {\n            for _ in 0..1 {\n                run(num_items, *n);\n            }\n\n            let start = time::Instant::now();\n\n            run(num_items, *n);\n\n            let duration = start.elapsed();\n\n            let ns_per = duration.as_nanos() / (num_items as u128 * *n as u128);\n\n            println!(\n                \"producers={}, taken={}ms, ns_per={}\",\n                n,\n                duration.as_millis(),\n                ns_per\n            );\n        }\n    }\n\n    fn run(items: usize, num_producers: usize) {\n        let (tx, mut rx) = Queue::unbounded();\n        let done = Arc::new(AtomicUsize::new(0));\n\n        for _ in 0..num_producers {\n            let done = done.clone();\n            let queue = tx.clone();\n\n            thread::spawn(move || {\n                for n in 0..items {\n                    queue.push(n);\n                }\n\n                done.fetch_add(1, Ordering::SeqCst);\n            });\n        }\n\n        while done.load(Ordering::SeqCst) != num_producers {\n            while let Some(_) = rx.pop() {}\n        }\n    }\n}\n"
  },
  {
    "project": "lru-rs",
    "target": 1,
    "commit_id": "09f68c63755b35f9cf5cb5d6765cf8dc080f9ea3",
    "func": "// MIT License\n\n// Copyright (c) 2016 Jerome Froelich\n\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation the rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so, subject to the following conditions:\n\n// The above copyright notice and this permission notice shall be included in all\n// copies or substantial portions of the Software.\n\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n// SOFTWARE.\n\n//! An implementation of a LRU cache. The cache supports `get`, `get_mut`, `put`,\n//! and `pop` operations, all of which are O(1). This crate was heavily influenced\n//! by the [LRU Cache implementation in an earlier version of Rust's std::collections crate](https://doc.rust-lang.org/0.12.0/std/collections/lru_cache/struct.LruCache.html).\n//!\n//! ## Example\n//!\n//! ```rust\n//! extern crate lru;\n//!\n//! use lru::LruCache;\n//!\n//! fn main() {\n//!         let mut cache = LruCache::new(2);\n//!         cache.put(\"apple\", 3);\n//!         cache.put(\"banana\", 2);\n//!\n//!         assert_eq!(*cache.get(&\"apple\").unwrap(), 3);\n//!         assert_eq!(*cache.get(&\"banana\").unwrap(), 2);\n//!         assert!(cache.get(&\"pear\").is_none());\n//!\n//!         assert_eq!(cache.put(\"banana\", 4), Some(2));\n//!         assert_eq!(cache.put(\"pear\", 5), None);\n//!\n//!         assert_eq!(*cache.get(&\"pear\").unwrap(), 5);\n//!         assert_eq!(*cache.get(&\"banana\").unwrap(), 4);\n//!         assert!(cache.get(&\"apple\").is_none());\n//!\n//!         {\n//!             let v = cache.get_mut(&\"banana\").unwrap();\n//!             *v = 6;\n//!         }\n//!\n//!         assert_eq!(*cache.get(&\"banana\").unwrap(), 6);\n//! }\n//! ```\n\n#![no_std]\n#![cfg_attr(feature = \"nightly\", feature(negative_impls, auto_traits))]\n\n#[cfg(feature = \"hashbrown\")]\nextern crate hashbrown;\n\n#[cfg(test)]\nextern crate scoped_threadpool;\n\nuse alloc::borrow::Borrow;\nuse alloc::boxed::Box;\nuse core::fmt;\nuse core::hash::{BuildHasher, Hash, Hasher};\nuse core::iter::FusedIterator;\nuse core::marker::PhantomData;\nuse core::mem;\nuse core::ptr;\nuse core::usize;\n\n#[cfg(any(test, not(feature = \"hashbrown\")))]\nextern crate std;\n\n#[cfg(feature = \"hashbrown\")]\nuse hashbrown::HashMap;\n#[cfg(not(feature = \"hashbrown\"))]\nuse std::collections::HashMap;\n\nextern crate alloc;\n\n// Struct used to hold a reference to a key\n#[doc(hidden)]\npub struct KeyRef<K> {\n    k: *const K,\n}\n\nimpl<K: Hash> Hash for KeyRef<K> {\n    fn hash<H: Hasher>(&self, state: &mut H) {\n        unsafe { (*self.k).hash(state) }\n    }\n}\n\nimpl<K: PartialEq> PartialEq for KeyRef<K> {\n    fn eq(&self, other: &KeyRef<K>) -> bool {\n        unsafe { (*self.k).eq(&*other.k) }\n    }\n}\n\nimpl<K: Eq> Eq for KeyRef<K> {}\n\n#[cfg(feature = \"nightly\")]\n#[doc(hidden)]\npub auto trait NotKeyRef {}\n\n#[cfg(feature = \"nightly\")]\nimpl<K> !NotKeyRef for KeyRef<K> {}\n\n#[cfg(feature = \"nightly\")]\nimpl<K, D> Borrow<D> for KeyRef<K>\nwhere\n    K: Borrow<D>,\n    D: NotKeyRef + ?Sized,\n{\n    fn borrow(&self) -> &D {\n        unsafe { &*self.k }.borrow()\n    }\n}\n\n#[cfg(not(feature = \"nightly\"))]\nimpl<K> Borrow<K> for KeyRef<K> {\n    fn borrow(&self) -> &K {\n        unsafe { &*self.k }\n    }\n}\n\n#[cfg(not(feature = \"nightly\"))]\nimpl Borrow<str> for KeyRef<alloc::string::String> {\n    fn borrow(&self) -> &str {\n        unsafe { &*self.k }\n    }\n}\n\n#[cfg(not(feature = \"nightly\"))]\nimpl<T> Borrow<[T]> for KeyRef<alloc::vec::Vec<T>> {\n    fn borrow(&self) -> &[T] {\n        unsafe { &*self.k }\n    }\n}\n\n// Struct used to hold a key value pair. Also contains references to previous and next entries\n// so we can maintain the entries in a linked list ordered by their use.\nstruct LruEntry<K, V> {\n    key: mem::MaybeUninit<K>,\n    val: mem::MaybeUninit<V>,\n    prev: *mut LruEntry<K, V>,\n    next: *mut LruEntry<K, V>,\n}\n\nimpl<K, V> LruEntry<K, V> {\n    fn new(key: K, val: V) -> Self {\n        LruEntry {\n            key: mem::MaybeUninit::new(key),\n            val: mem::MaybeUninit::new(val),\n            prev: ptr::null_mut(),\n            next: ptr::null_mut(),\n        }\n    }\n\n    fn new_sigil() -> Self {\n        LruEntry {\n            key: mem::MaybeUninit::uninit(),\n            val: mem::MaybeUninit::uninit(),\n            prev: ptr::null_mut(),\n            next: ptr::null_mut(),\n        }\n    }\n}\n\n#[cfg(feature = \"hashbrown\")]\npub type DefaultHasher = hashbrown::hash_map::DefaultHashBuilder;\n#[cfg(not(feature = \"hashbrown\"))]\npub type DefaultHasher = std::collections::hash_map::RandomState;\n\n/// An LRU Cache\npub struct LruCache<K, V, S = DefaultHasher> {\n    map: HashMap<KeyRef<K>, Box<LruEntry<K, V>>, S>,\n    cap: usize,\n\n    // head and tail are sigil nodes to faciliate inserting entries\n    head: *mut LruEntry<K, V>,\n    tail: *mut LruEntry<K, V>,\n}\n\nimpl<K: Hash + Eq, V> LruCache<K, V> {\n    /// Creates a new LRU Cache that holds at most `cap` items.\n    ///\n    /// # Example\n    ///\n    /// ```\n    /// use lru::LruCache;\n    /// let mut cache: LruCache<isize, &str> = LruCache::new(10);\n    /// ```\n    pub fn new(cap: usize) -> LruCache<K, V> {\n        LruCache::construct(cap, HashMap::with_capacity(cap))\n    }\n\n    /// Creates a new LRU Cache that never automatically evicts items.\n    ///\n    /// # Example\n    ///\n    /// ```\n    /// use lru::LruCache;\n    /// let mut cache: LruCache<isize, &str> = LruCache::unbounded();\n    /// ```\n    pub fn unbounded() -> LruCache<K, V> {\n        LruCache::construct(usize::MAX, HashMap::default())\n    }\n}\n\nimpl<K: Hash + Eq, V, S: BuildHasher> LruCache<K, V, S> {\n    /// Creates a new LRU Cache that holds at most `cap` items and\n    /// uses the provided hash builder to hash keys.\n    ///\n    /// # Example\n    ///\n    /// ```\n    /// use lru::{LruCache, DefaultHasher};\n    ///\n    /// let s = DefaultHasher::default();\n    /// let mut cache: LruCache<isize, &str> = LruCache::with_hasher(10, s);\n    /// ```\n    pub fn with_hasher(cap: usize, hash_builder: S) -> LruCache<K, V, S> {\n        LruCache::construct(cap, HashMap::with_capacity_and_hasher(cap, hash_builder))\n    }\n\n    /// Creates a new LRU Cache that never automatically evicts items and\n    /// uses the provided hash builder to hash keys.\n    ///\n    /// # Example\n    ///\n    /// ```\n    /// use lru::{LruCache, DefaultHasher};\n    ///\n    /// let s = DefaultHasher::default();\n    /// let mut cache: LruCache<isize, &str> = LruCache::unbounded_with_hasher(s);\n    /// ```\n    pub fn unbounded_with_hasher(hash_builder: S) -> LruCache<K, V, S> {\n        LruCache::construct(usize::MAX, HashMap::with_hasher(hash_builder))\n    }\n\n    /// Creates a new LRU Cache with the given capacity.\n    fn construct(cap: usize, map: HashMap<KeyRef<K>, Box<LruEntry<K, V>>, S>) -> LruCache<K, V, S> {\n        // NB: The compiler warns that cache does not need to be marked as mutable if we\n        // declare it as such since we only mutate it inside the unsafe block.\n        let cache = LruCache {\n            map,\n            cap,\n            head: Box::into_raw(Box::new(LruEntry::new_sigil())),\n            tail: Box::into_raw(Box::new(LruEntry::new_sigil())),\n        };\n\n        unsafe {\n            (*cache.head).next = cache.tail;\n            (*cache.tail).prev = cache.head;\n        }\n\n        cache\n    }\n\n    /// Puts a key-value pair into cache. If the key already exists in the cache, then it updates\n    /// the key's value and returns the old value. Otherwise, `None` is returned.\n    ///\n    /// # Example\n    ///\n    /// ```\n    /// use lru::LruCache;\n    /// let mut cache = LruCache::new(2);\n    ///\n    /// assert_eq!(None, cache.put(1, \"a\"));\n    /// assert_eq!(None, cache.put(2, \"b\"));\n    /// assert_eq!(Some(\"b\"), cache.put(2, \"beta\"));\n    ///\n    /// assert_eq!(cache.get(&1), Some(&\"a\"));\n    /// assert_eq!(cache.get(&2), Some(&\"beta\"));\n    /// ```\n    pub fn put(&mut self, k: K, mut v: V) -> Option<V> {\n        let node_ptr = self.map.get_mut(&KeyRef { k: &k }).map(|node| {\n            let node_ptr: *mut LruEntry<K, V> = &mut **node;\n            node_ptr\n        });\n\n        match node_ptr {\n            Some(node_ptr) => {\n                // if the key is already in the cache just update its value and move it to the\n                // front of the list\n                unsafe { mem::swap(&mut v, &mut (*(*node_ptr).val.as_mut_ptr()) as &mut V) }\n                self.detach(node_ptr);\n                self.attach(node_ptr);\n                Some(v)\n            }\n            None => {\n                // if the capacity is zero, do nothing\n                if self.cap() == 0 {\n                    return None;\n                }\n\n                let mut node = if self.len() == self.cap() {\n                    // if the cache is full, remove the last entry so we can use it for the new key\n                    let old_key = KeyRef {\n                        k: unsafe { &(*(*(*self.tail).prev).key.as_ptr()) },\n                    };\n                    let mut old_node = self.map.remove(&old_key).unwrap();\n\n                    // drop the node's current key and val so we can overwrite them\n                    unsafe {\n                        ptr::drop_in_place(old_node.key.as_mut_ptr());\n                        ptr::drop_in_place(old_node.val.as_mut_ptr());\n                    }\n\n                    old_node.key = mem::MaybeUninit::new(k);\n                    old_node.val = mem::MaybeUninit::new(v);\n\n                    let node_ptr: *mut LruEntry<K, V> = &mut *old_node;\n                    self.detach(node_ptr);\n\n                    old_node\n                } else {\n                    // if the cache is not full allocate a new LruEntry\n                    Box::new(LruEntry::new(k, v))\n                };\n\n                let node_ptr: *mut LruEntry<K, V> = &mut *node;\n                self.attach(node_ptr);\n\n                let keyref = unsafe { (*node_ptr).key.as_ptr() };\n                self.map.insert(KeyRef { k: keyref }, node);\n                None\n            }\n        }\n    }\n\n    /// Returns a reference to the value of the key in the cache or `None` if it is not\n    /// present in the cache. Moves the key to the head of the LRU list if it exists.\n    ///\n    /// # Example\n    ///\n    /// ```\n    /// use lru::LruCache;\n    /// let mut cache = LruCache::new(2);\n    ///\n    /// cache.put(1, \"a\");\n    /// cache.put(2, \"b\");\n    /// cache.put(2, \"c\");\n    /// cache.put(3, \"d\");\n    ///\n    /// assert_eq!(cache.get(&1), None);\n    /// assert_eq!(cache.get(&2), Some(&\"c\"));\n    /// assert_eq!(cache.get(&3), Some(&\"d\"));\n    /// ```\n    pub fn get<'a, Q>(&'a mut self, k: &Q) -> Option<&'a V>\n    where\n        KeyRef<K>: Borrow<Q>,\n        Q: Hash + Eq + ?Sized,\n    {\n        if let Some(node) = self.map.get_mut(k) {\n            let node_ptr: *mut LruEntry<K, V> = &mut **node;\n\n            self.detach(node_ptr);\n            self.attach(node_ptr);\n\n            Some(unsafe { &(*(*node_ptr).val.as_ptr()) as &V })\n        } else {\n            None\n        }\n    }\n\n    /// Returns a mutable reference to the value of the key in the cache or `None` if it\n    /// is not present in the cache. Moves the key to the head of the LRU list if it exists.\n    ///\n    /// # Example\n    ///\n    /// ```\n    /// use lru::LruCache;\n    /// let mut cache = LruCache::new(2);\n    ///\n    /// cache.put(\"apple\", 8);\n    /// cache.put(\"banana\", 4);\n    /// cache.put(\"banana\", 6);\n    /// cache.put(\"pear\", 2);\n    ///\n    /// assert_eq!(cache.get_mut(&\"apple\"), None);\n    /// assert_eq!(cache.get_mut(&\"banana\"), Some(&mut 6));\n    /// assert_eq!(cache.get_mut(&\"pear\"), Some(&mut 2));\n    /// ```\n    pub fn get_mut<'a, Q>(&'a mut self, k: &Q) -> Option<&'a mut V>\n    where\n        KeyRef<K>: Borrow<Q>,\n        Q: Hash + Eq + ?Sized,\n    {\n        if let Some(node) = self.map.get_mut(k) {\n            let node_ptr: *mut LruEntry<K, V> = &mut **node;\n\n            self.detach(node_ptr);\n            self.attach(node_ptr);\n\n            Some(unsafe { &mut (*(*node_ptr).val.as_mut_ptr()) as &mut V })\n        } else {\n            None\n        }\n    }\n\n    /// Returns a reference to the value corresponding to the key in the cache or `None` if it is\n    /// not present in the cache. Unlike `get`, `peek` does not update the LRU list so the key's\n    /// position will be unchanged.\n    ///\n    /// # Example\n    ///\n    /// ```\n    /// use lru::LruCache;\n    /// let mut cache = LruCache::new(2);\n    ///\n    /// cache.put(1, \"a\");\n    /// cache.put(2, \"b\");\n    ///\n    /// assert_eq!(cache.peek(&1), Some(&\"a\"));\n    /// assert_eq!(cache.peek(&2), Some(&\"b\"));\n    /// ```\n    pub fn peek<'a, Q>(&'a self, k: &Q) -> Option<&'a V>\n    where\n        KeyRef<K>: Borrow<Q>,\n        Q: Hash + Eq + ?Sized,\n    {\n        self.map\n            .get(k)\n            .map(|node| unsafe { &(*(*node).val.as_ptr()) as &V })\n    }\n\n    /// Returns a mutable reference to the value corresponding to the key in the cache or `None`\n    /// if it is not present in the cache. Unlike `get_mut`, `peek_mut` does not update the LRU\n    /// list so the key's position will be unchanged.\n    ///\n    /// # Example\n    ///\n    /// ```\n    /// use lru::LruCache;\n    /// let mut cache = LruCache::new(2);\n    ///\n    /// cache.put(1, \"a\");\n    /// cache.put(2, \"b\");\n    ///\n    /// assert_eq!(cache.peek_mut(&1), Some(&mut \"a\"));\n    /// assert_eq!(cache.peek_mut(&2), Some(&mut \"b\"));\n    /// ```\n    pub fn peek_mut<'a, Q>(&'a mut self, k: &Q) -> Option<&'a mut V>\n    where\n        KeyRef<K>: Borrow<Q>,\n        Q: Hash + Eq + ?Sized,\n    {\n        match self.map.get_mut(k) {\n            None => None,\n            Some(node) => Some(unsafe { &mut (*(*node).val.as_mut_ptr()) as &mut V }),\n        }\n    }\n\n    /// Returns the value corresponding to the least recently used item or `None` if the\n    /// cache is empty. Like `peek`, `peek_lru` does not update the LRU list so the item's\n    /// position will be unchanged.\n    ///\n    /// # Example\n    ///\n    /// ```\n    /// use lru::LruCache;\n    /// let mut cache = LruCache::new(2);\n    ///\n    /// cache.put(1, \"a\");\n    /// cache.put(2, \"b\");\n    ///\n    /// assert_eq!(cache.peek_lru(), Some((&1, &\"a\")));\n    /// ```\n    pub fn peek_lru<'a>(&'_ self) -> Option<(&'a K, &'a V)> {\n        if self.is_empty() {\n            return None;\n        }\n\n        let (key, val);\n        unsafe {\n            let node = (*self.tail).prev;\n            key = &(*(*node).key.as_ptr()) as &K;\n            val = &(*(*node).val.as_ptr()) as &V;\n        }\n\n        Some((key, val))\n    }\n\n    /// Returns a bool indicating whether the given key is in the cache. Does not update the\n    /// LRU list.\n    ///\n    /// # Example\n    ///\n    /// ```\n    /// use lru::LruCache;\n    /// let mut cache = LruCache::new(2);\n    ///\n    /// cache.put(1, \"a\");\n    /// cache.put(2, \"b\");\n    /// cache.put(3, \"c\");\n    ///\n    /// assert!(!cache.contains(&1));\n    /// assert!(cache.contains(&2));\n    /// assert!(cache.contains(&3));\n    /// ```\n    pub fn contains<Q>(&self, k: &Q) -> bool\n    where\n        KeyRef<K>: Borrow<Q>,\n        Q: Hash + Eq + ?Sized,\n    {\n        self.map.contains_key(k)\n    }\n\n    /// Removes and returns the value corresponding to the key from the cache or\n    /// `None` if it does not exist.\n    ///\n    /// # Example\n    ///\n    /// ```\n    /// use lru::LruCache;\n    /// let mut cache = LruCache::new(2);\n    ///\n    /// cache.put(2, \"a\");\n    ///\n    /// assert_eq!(cache.pop(&1), None);\n    /// assert_eq!(cache.pop(&2), Some(\"a\"));\n    /// assert_eq!(cache.pop(&2), None);\n    /// assert_eq!(cache.len(), 0);\n    /// ```\n    pub fn pop<Q>(&mut self, k: &Q) -> Option<V>\n    where\n        KeyRef<K>: Borrow<Q>,\n        Q: Hash + Eq + ?Sized,\n    {\n        match self.map.remove(k) {\n            None => None,\n            Some(mut old_node) => {\n                unsafe {\n                    ptr::drop_in_place(old_node.key.as_mut_ptr());\n                }\n                let node_ptr: *mut LruEntry<K, V> = &mut *old_node;\n                self.detach(node_ptr);\n                unsafe { Some(old_node.val.assume_init()) }\n            }\n        }\n    }\n\n    /// Removes and returns the key and value corresponding to the least recently\n    /// used item or `None` if the cache is empty.\n    ///\n    /// # Example\n    ///\n    /// ```\n    /// use lru::LruCache;\n    /// let mut cache = LruCache::new(2);\n    ///\n    /// cache.put(2, \"a\");\n    /// cache.put(3, \"b\");\n    /// cache.put(4, \"c\");\n    /// cache.get(&3);\n    ///\n    /// assert_eq!(cache.pop_lru(), Some((4, \"c\")));\n    /// assert_eq!(cache.pop_lru(), Some((3, \"b\")));\n    /// assert_eq!(cache.pop_lru(), None);\n    /// assert_eq!(cache.len(), 0);\n    /// ```\n    pub fn pop_lru(&mut self) -> Option<(K, V)> {\n        let node = self.remove_last()?;\n        // N.B.: Can't destructure directly because of https://github.com/rust-lang/rust/issues/28536\n        let node = *node;\n        let LruEntry { key, val, .. } = node;\n        unsafe { Some((key.assume_init(), val.assume_init())) }\n    }\n\n    /// Returns the number of key-value pairs that are currently in the the cache.\n    ///\n    /// # Example\n    ///\n    /// ```\n    /// use lru::LruCache;\n    /// let mut cache = LruCache::new(2);\n    /// assert_eq!(cache.len(), 0);\n    ///\n    /// cache.put(1, \"a\");\n    /// assert_eq!(cache.len(), 1);\n    ///\n    /// cache.put(2, \"b\");\n    /// assert_eq!(cache.len(), 2);\n    ///\n    /// cache.put(3, \"c\");\n    /// assert_eq!(cache.len(), 2);\n    /// ```\n    pub fn len(&self) -> usize {\n        self.map.len()\n    }\n\n    /// Returns a bool indicating whether the cache is empty or not.\n    ///\n    /// # Example\n    ///\n    /// ```\n    /// use lru::LruCache;\n    /// let mut cache = LruCache::new(2);\n    /// assert!(cache.is_empty());\n    ///\n    /// cache.put(1, \"a\");\n    /// assert!(!cache.is_empty());\n    /// ```\n    pub fn is_empty(&self) -> bool {\n        self.map.len() == 0\n    }\n\n    /// Returns the maximum number of key-value pairs the cache can hold.\n    ///\n    /// # Example\n    ///\n    /// ```\n    /// use lru::LruCache;\n    /// let mut cache: LruCache<isize, &str> = LruCache::new(2);\n    /// assert_eq!(cache.cap(), 2);\n    /// ```\n    pub fn cap(&self) -> usize {\n        self.cap\n    }\n\n    /// Resizes the cache. If the new capacity is smaller than the size of the current\n    /// cache any entries past the new capacity are discarded.\n    ///\n    /// # Example\n    ///\n    /// ```\n    /// use lru::LruCache;\n    /// let mut cache: LruCache<isize, &str> = LruCache::new(2);\n    ///\n    /// cache.put(1, \"a\");\n    /// cache.put(2, \"b\");\n    /// cache.resize(4);\n    /// cache.put(3, \"c\");\n    /// cache.put(4, \"d\");\n    ///\n    /// assert_eq!(cache.len(), 4);\n    /// assert_eq!(cache.get(&1), Some(&\"a\"));\n    /// assert_eq!(cache.get(&2), Some(&\"b\"));\n    /// assert_eq!(cache.get(&3), Some(&\"c\"));\n    /// assert_eq!(cache.get(&4), Some(&\"d\"));\n    /// ```\n    pub fn resize(&mut self, cap: usize) {\n        // return early if capacity doesn't change\n        if cap == self.cap {\n            return;\n        }\n\n        while self.map.len() > cap {\n            self.pop_lru();\n        }\n        self.map.shrink_to_fit();\n\n        self.cap = cap;\n    }\n\n    /// Clears the contents of the cache.\n    ///\n    /// # Example\n    ///\n    /// ```\n    /// use lru::LruCache;\n    /// let mut cache: LruCache<isize, &str> = LruCache::new(2);\n    /// assert_eq!(cache.len(), 0);\n    ///\n    /// cache.put(1, \"a\");\n    /// assert_eq!(cache.len(), 1);\n    ///\n    /// cache.put(2, \"b\");\n    /// assert_eq!(cache.len(), 2);\n    ///\n    /// cache.clear();\n    /// assert_eq!(cache.len(), 0);\n    /// ```\n    pub fn clear(&mut self) {\n        while self.pop_lru().is_some() {}\n    }\n\n    /// An iterator visiting all entries in most-recently used order. The iterator element type is\n    /// `(&'a K, &'a V)`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use lru::LruCache;\n    ///\n    /// let mut cache = LruCache::new(3);\n    /// cache.put(\"a\", 1);\n    /// cache.put(\"b\", 2);\n    /// cache.put(\"c\", 3);\n    ///\n    /// for (key, val) in cache.iter() {\n    ///     println!(\"key: {} val: {}\", key, val);\n    /// }\n    /// ```\n    pub fn iter<'a>(&'_ self) -> Iter<'a, K, V> {\n        Iter {\n            len: self.len(),\n            ptr: unsafe { (*self.head).next },\n            end: unsafe { (*self.tail).prev },\n            phantom: PhantomData,\n        }\n    }\n\n    /// An iterator visiting all entries in most-recently-used order, giving a mutable reference on\n    /// V.  The iterator element type is `(&'a K, &'a mut V)`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use lru::LruCache;\n    ///\n    /// struct HddBlock {\n    ///     dirty: bool,\n    ///     data: [u8; 512]\n    /// }\n    ///\n    /// let mut cache = LruCache::new(3);\n    /// cache.put(0, HddBlock { dirty: false, data: [0x00; 512]});\n    /// cache.put(1, HddBlock { dirty: true,  data: [0x55; 512]});\n    /// cache.put(2, HddBlock { dirty: true,  data: [0x77; 512]});\n    ///\n    /// // write dirty blocks to disk.\n    /// for (block_id, block) in cache.iter_mut() {\n    ///     if block.dirty {\n    ///         // write block to disk\n    ///         block.dirty = false\n    ///     }\n    /// }\n    /// ```\n    pub fn iter_mut<'a>(&'_ mut self) -> IterMut<'a, K, V> {\n        IterMut {\n            len: self.len(),\n            ptr: unsafe { (*self.head).next },\n            end: unsafe { (*self.tail).prev },\n            phantom: PhantomData,\n        }\n    }\n\n    fn remove_last(&mut self) -> Option<Box<LruEntry<K, V>>> {\n        let prev;\n        unsafe { prev = (*self.tail).prev }\n        if prev != self.head {\n            let old_key = KeyRef {\n                k: unsafe { &(*(*(*self.tail).prev).key.as_ptr()) },\n            };\n            let mut old_node = self.map.remove(&old_key).unwrap();\n            let node_ptr: *mut LruEntry<K, V> = &mut *old_node;\n            self.detach(node_ptr);\n            Some(old_node)\n        } else {\n            None\n        }\n    }\n\n    fn detach(&mut self, node: *mut LruEntry<K, V>) {\n        unsafe {\n            (*(*node).prev).next = (*node).next;\n            (*(*node).next).prev = (*node).prev;\n        }\n    }\n\n    fn attach(&mut self, node: *mut LruEntry<K, V>) {\n        unsafe {\n            (*node).next = (*self.head).next;\n            (*node).prev = self.head;\n            (*self.head).next = node;\n            (*(*node).next).prev = node;\n        }\n    }\n}\n\nimpl<K, V, S> Drop for LruCache<K, V, S> {\n    fn drop(&mut self) {\n        self.map.values_mut().for_each(|e| unsafe {\n            ptr::drop_in_place(e.key.as_mut_ptr());\n            ptr::drop_in_place(e.val.as_mut_ptr());\n        });\n        // We rebox the head/tail, and because these are maybe-uninit\n        // they do not have the absent k/v dropped.\n        unsafe {\n            let _head = *Box::from_raw(self.head);\n            let _tail = *Box::from_raw(self.tail);\n        }\n    }\n}\n\nimpl<'a, K: Hash + Eq, V, S: BuildHasher> IntoIterator for &'a LruCache<K, V, S> {\n    type Item = (&'a K, &'a V);\n    type IntoIter = Iter<'a, K, V>;\n\n    fn into_iter(self) -> Iter<'a, K, V> {\n        self.iter()\n    }\n}\n\nimpl<'a, K: Hash + Eq, V, S: BuildHasher> IntoIterator for &'a mut LruCache<K, V, S> {\n    type Item = (&'a K, &'a mut V);\n    type IntoIter = IterMut<'a, K, V>;\n\n    fn into_iter(self) -> IterMut<'a, K, V> {\n        self.iter_mut()\n    }\n}\n\n// The compiler does not automatically derive Send and Sync for LruCache because it contains\n// raw pointers. The raw pointers are safely encapsulated by LruCache though so we can\n// implement Send and Sync for it below.\nunsafe impl<K: Send, V: Send, S: Send> Send for LruCache<K, V, S> {}\nunsafe impl<K: Sync, V: Sync, S: Sync> Sync for LruCache<K, V, S> {}\n\nimpl<K: Hash + Eq, V> fmt::Debug for LruCache<K, V> {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        f.debug_struct(\"LruCache\")\n            .field(\"len\", &self.len())\n            .field(\"cap\", &self.cap())\n            .finish()\n    }\n}\n\n/// An iterator over the entries of a `LruCache`.\n///\n/// This `struct` is created by the [`iter`] method on [`LruCache`][`LruCache`]. See its\n/// documentation for more.\n///\n/// [`iter`]: struct.LruCache.html#method.iter\n/// [`LruCache`]: struct.LruCache.html\npub struct Iter<'a, K: 'a, V: 'a> {\n    len: usize,\n\n    ptr: *const LruEntry<K, V>,\n    end: *const LruEntry<K, V>,\n\n    phantom: PhantomData<&'a K>,\n}\n\nimpl<'a, K, V> Iterator for Iter<'a, K, V> {\n    type Item = (&'a K, &'a V);\n\n    fn next(&mut self) -> Option<(&'a K, &'a V)> {\n        if self.len == 0 {\n            return None;\n        }\n\n        let key = unsafe { &(*(*self.ptr).key.as_ptr()) as &K };\n        let val = unsafe { &(*(*self.ptr).val.as_ptr()) as &V };\n\n        self.len -= 1;\n        self.ptr = unsafe { (*self.ptr).next };\n\n        Some((key, val))\n    }\n\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        (self.len, Some(self.len))\n    }\n\n    fn count(self) -> usize {\n        self.len\n    }\n}\n\nimpl<'a, K, V> DoubleEndedIterator for Iter<'a, K, V> {\n    fn next_back(&mut self) -> Option<(&'a K, &'a V)> {\n        if self.len == 0 {\n            return None;\n        }\n\n        let key = unsafe { &(*(*self.end).key.as_ptr()) as &K };\n        let val = unsafe { &(*(*self.end).val.as_ptr()) as &V };\n\n        self.len -= 1;\n        self.end = unsafe { (*self.end).prev };\n\n        Some((key, val))\n    }\n}\n\nimpl<'a, K, V> ExactSizeIterator for Iter<'a, K, V> {}\nimpl<'a, K, V> FusedIterator for Iter<'a, K, V> {}\n\nimpl<'a, K, V> Clone for Iter<'a, K, V> {\n    fn clone(&self) -> Iter<'a, K, V> {\n        Iter {\n            len: self.len,\n            ptr: self.ptr,\n            end: self.end,\n            phantom: PhantomData,\n        }\n    }\n}\n\n// The compiler does not automatically derive Send and Sync for Iter because it contains\n// raw pointers.\nunsafe impl<'a, K: Send, V: Send> Send for Iter<'a, K, V> {}\nunsafe impl<'a, K: Sync, V: Sync> Sync for Iter<'a, K, V> {}\n\n/// An iterator over mutables entries of a `LruCache`.\n///\n/// This `struct` is created by the [`iter_mut`] method on [`LruCache`][`LruCache`]. See its\n/// documentation for more.\n///\n/// [`iter_mut`]: struct.LruCache.html#method.iter_mut\n/// [`LruCache`]: struct.LruCache.html\npub struct IterMut<'a, K: 'a, V: 'a> {\n    len: usize,\n\n    ptr: *mut LruEntry<K, V>,\n    end: *mut LruEntry<K, V>,\n\n    phantom: PhantomData<&'a K>,\n}\n\nimpl<'a, K, V> Iterator for IterMut<'a, K, V> {\n    type Item = (&'a K, &'a mut V);\n\n    fn next(&mut self) -> Option<(&'a K, &'a mut V)> {\n        if self.len == 0 {\n            return None;\n        }\n\n        let key = unsafe { &mut (*(*self.ptr).key.as_mut_ptr()) as &mut K };\n        let val = unsafe { &mut (*(*self.ptr).val.as_mut_ptr()) as &mut V };\n\n        self.len -= 1;\n        self.ptr = unsafe { (*self.ptr).next };\n\n        Some((key, val))\n    }\n\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        (self.len, Some(self.len))\n    }\n\n    fn count(self) -> usize {\n        self.len\n    }\n}\n\nimpl<'a, K, V> DoubleEndedIterator for IterMut<'a, K, V> {\n    fn next_back(&mut self) -> Option<(&'a K, &'a mut V)> {\n        if self.len == 0 {\n            return None;\n        }\n\n        let key = unsafe { &mut (*(*self.end).key.as_mut_ptr()) as &mut K };\n        let val = unsafe { &mut (*(*self.end).val.as_mut_ptr()) as &mut V };\n\n        self.len -= 1;\n        self.end = unsafe { (*self.end).prev };\n\n        Some((key, val))\n    }\n}\n\nimpl<'a, K, V> ExactSizeIterator for IterMut<'a, K, V> {}\nimpl<'a, K, V> FusedIterator for IterMut<'a, K, V> {}\n\n// The compiler does not automatically derive Send and Sync for Iter because it contains\n// raw pointers.\nunsafe impl<'a, K: Send, V: Send> Send for IterMut<'a, K, V> {}\nunsafe impl<'a, K: Sync, V: Sync> Sync for IterMut<'a, K, V> {}\n\n#[cfg(test)]\nmod tests {\n    use super::LruCache;\n    use core::fmt::Debug;\n    use scoped_threadpool::Pool;\n    use std::sync::atomic::{AtomicUsize, Ordering};\n\n    fn assert_opt_eq<V: PartialEq + Debug>(opt: Option<&V>, v: V) {\n        assert!(opt.is_some());\n        assert_eq!(opt.unwrap(), &v);\n    }\n\n    fn assert_opt_eq_mut<V: PartialEq + Debug>(opt: Option<&mut V>, v: V) {\n        assert!(opt.is_some());\n        assert_eq!(opt.unwrap(), &v);\n    }\n\n    fn assert_opt_eq_tuple<K: PartialEq + Debug, V: PartialEq + Debug>(\n        opt: Option<(&K, &V)>,\n        kv: (K, V),\n    ) {\n        assert!(opt.is_some());\n        let res = opt.unwrap();\n        assert_eq!(res.0, &kv.0);\n        assert_eq!(res.1, &kv.1);\n    }\n\n    fn assert_opt_eq_mut_tuple<K: PartialEq + Debug, V: PartialEq + Debug>(\n        opt: Option<(&K, &mut V)>,\n        kv: (K, V),\n    ) {\n        assert!(opt.is_some());\n        let res = opt.unwrap();\n        assert_eq!(res.0, &kv.0);\n        assert_eq!(res.1, &kv.1);\n    }\n\n    #[test]\n    fn test_unbounded() {\n        let mut cache = LruCache::unbounded();\n        for i in 0..13370 {\n            cache.put(i, ());\n        }\n        assert_eq!(cache.len(), 13370);\n    }\n\n    #[test]\n    #[cfg(feature = \"hashbrown\")]\n    fn test_with_hasher() {\n        use hashbrown::hash_map::DefaultHashBuilder;\n\n        let s = DefaultHashBuilder::default();\n        let mut cache = LruCache::with_hasher(16, s);\n\n        for i in 0..13370 {\n            cache.put(i, ());\n        }\n        assert_eq!(cache.len(), 16);\n    }\n\n    #[test]\n    fn test_put_and_get() {\n        let mut cache = LruCache::new(2);\n        assert!(cache.is_empty());\n\n        assert_eq!(cache.put(\"apple\", \"red\"), None);\n        assert_eq!(cache.put(\"banana\", \"yellow\"), None);\n\n        assert_eq!(cache.cap(), 2);\n        assert_eq!(cache.len(), 2);\n        assert!(!cache.is_empty());\n        assert_opt_eq(cache.get(&\"apple\"), \"red\");\n        assert_opt_eq(cache.get(&\"banana\"), \"yellow\");\n    }\n\n    #[test]\n    fn test_put_and_get_mut() {\n        let mut cache = LruCache::new(2);\n\n        cache.put(\"apple\", \"red\");\n        cache.put(\"banana\", \"yellow\");\n\n        assert_eq!(cache.cap(), 2);\n        assert_eq!(cache.len(), 2);\n        assert_opt_eq_mut(cache.get_mut(&\"apple\"), \"red\");\n        assert_opt_eq_mut(cache.get_mut(&\"banana\"), \"yellow\");\n    }\n\n    #[test]\n    fn test_get_mut_and_update() {\n        let mut cache = LruCache::new(2);\n\n        cache.put(\"apple\", 1);\n        cache.put(\"banana\", 3);\n\n        {\n            let v = cache.get_mut(&\"apple\").unwrap();\n            *v = 4;\n        }\n\n        assert_eq!(cache.cap(), 2);\n        assert_eq!(cache.len(), 2);\n        assert_opt_eq_mut(cache.get_mut(&\"apple\"), 4);\n        assert_opt_eq_mut(cache.get_mut(&\"banana\"), 3);\n    }\n\n    #[test]\n    fn test_put_update() {\n        let mut cache = LruCache::new(1);\n\n        assert_eq!(cache.put(\"apple\", \"red\"), None);\n        assert_eq!(cache.put(\"apple\", \"green\"), Some(\"red\"));\n\n        assert_eq!(cache.len(), 1);\n        assert_opt_eq(cache.get(&\"apple\"), \"green\");\n    }\n\n    #[test]\n    fn test_put_removes_oldest() {\n        let mut cache = LruCache::new(2);\n\n        assert_eq!(cache.put(\"apple\", \"red\"), None);\n        assert_eq!(cache.put(\"banana\", \"yellow\"), None);\n        assert_eq!(cache.put(\"pear\", \"green\"), None);\n\n        assert!(cache.get(&\"apple\").is_none());\n        assert_opt_eq(cache.get(&\"banana\"), \"yellow\");\n        assert_opt_eq(cache.get(&\"pear\"), \"green\");\n\n        // Even though we inserted \"apple\" into the cache earlier it has since been removed from\n        // the cache so there is no current value for `put` to return.\n        assert_eq!(cache.put(\"apple\", \"green\"), None);\n        assert_eq!(cache.put(\"tomato\", \"red\"), None);\n\n        assert!(cache.get(&\"pear\").is_none());\n        assert_opt_eq(cache.get(&\"apple\"), \"green\");\n        assert_opt_eq(cache.get(&\"tomato\"), \"red\");\n    }\n\n    #[test]\n    fn test_peek() {\n        let mut cache = LruCache::new(2);\n\n        cache.put(\"apple\", \"red\");\n        cache.put(\"banana\", \"yellow\");\n\n        assert_opt_eq(cache.peek(&\"banana\"), \"yellow\");\n        assert_opt_eq(cache.peek(&\"apple\"), \"red\");\n\n        cache.put(\"pear\", \"green\");\n\n        assert!(cache.peek(&\"apple\").is_none());\n        assert_opt_eq(cache.peek(&\"banana\"), \"yellow\");\n        assert_opt_eq(cache.peek(&\"pear\"), \"green\");\n    }\n\n    #[test]\n    fn test_peek_mut() {\n        let mut cache = LruCache::new(2);\n\n        cache.put(\"apple\", \"red\");\n        cache.put(\"banana\", \"yellow\");\n\n        assert_opt_eq_mut(cache.peek_mut(&\"banana\"), \"yellow\");\n        assert_opt_eq_mut(cache.peek_mut(&\"apple\"), \"red\");\n        assert!(cache.peek_mut(&\"pear\").is_none());\n\n        cache.put(\"pear\", \"green\");\n\n        assert!(cache.peek_mut(&\"apple\").is_none());\n        assert_opt_eq_mut(cache.peek_mut(&\"banana\"), \"yellow\");\n        assert_opt_eq_mut(cache.peek_mut(&\"pear\"), \"green\");\n\n        {\n            let v = cache.peek_mut(&\"banana\").unwrap();\n            *v = \"green\";\n        }\n\n        assert_opt_eq_mut(cache.peek_mut(&\"banana\"), \"green\");\n    }\n\n    #[test]\n    fn test_peek_lru() {\n        let mut cache = LruCache::new(2);\n\n        assert!(cache.peek_lru().is_none());\n\n        cache.put(\"apple\", \"red\");\n        cache.put(\"banana\", \"yellow\");\n        assert_opt_eq_tuple(cache.peek_lru(), (\"apple\", \"red\"));\n\n        cache.get(&\"apple\");\n        assert_opt_eq_tuple(cache.peek_lru(), (\"banana\", \"yellow\"));\n\n        cache.clear();\n        assert!(cache.peek_lru().is_none());\n    }\n\n    #[test]\n    fn test_contains() {\n        let mut cache = LruCache::new(2);\n\n        cache.put(\"apple\", \"red\");\n        cache.put(\"banana\", \"yellow\");\n        cache.put(\"pear\", \"green\");\n\n        assert!(!cache.contains(&\"apple\"));\n        assert!(cache.contains(&\"banana\"));\n        assert!(cache.contains(&\"pear\"));\n    }\n\n    #[test]\n    fn test_pop() {\n        let mut cache = LruCache::new(2);\n\n        cache.put(\"apple\", \"red\");\n        cache.put(\"banana\", \"yellow\");\n\n        assert_eq!(cache.len(), 2);\n        assert_opt_eq(cache.get(&\"apple\"), \"red\");\n        assert_opt_eq(cache.get(&\"banana\"), \"yellow\");\n\n        let popped = cache.pop(&\"apple\");\n        assert!(popped.is_some());\n        assert_eq!(popped.unwrap(), \"red\");\n        assert_eq!(cache.len(), 1);\n        assert!(cache.get(&\"apple\").is_none());\n        assert_opt_eq(cache.get(&\"banana\"), \"yellow\");\n    }\n\n    #[test]\n    fn test_pop_lru() {\n        let mut cache = LruCache::new(200);\n\n        for i in 0..75 {\n            cache.put(i, \"A\");\n        }\n        for i in 0..75 {\n            cache.put(i + 100, \"B\");\n        }\n        for i in 0..75 {\n            cache.put(i + 200, \"C\");\n        }\n        assert_eq!(cache.len(), 200);\n\n        for i in 0..75 {\n            assert_opt_eq(cache.get(&(74 - i + 100)), \"B\");\n        }\n        assert_opt_eq(cache.get(&25), \"A\");\n\n        for i in 26..75 {\n            assert_eq!(cache.pop_lru(), Some((i, \"A\")));\n        }\n        for i in 0..75 {\n            assert_eq!(cache.pop_lru(), Some((i + 200, \"C\")));\n        }\n        for i in 0..75 {\n            assert_eq!(cache.pop_lru(), Some((74 - i + 100, \"B\")));\n        }\n        assert_eq!(cache.pop_lru(), Some((25, \"A\")));\n        for _ in 0..50 {\n            assert_eq!(cache.pop_lru(), None);\n        }\n    }\n\n    #[test]\n    fn test_clear() {\n        let mut cache = LruCache::new(2);\n\n        cache.put(\"apple\", \"red\");\n        cache.put(\"banana\", \"yellow\");\n\n        assert_eq!(cache.len(), 2);\n        assert_opt_eq(cache.get(&\"apple\"), \"red\");\n        assert_opt_eq(cache.get(&\"banana\"), \"yellow\");\n\n        cache.clear();\n        assert_eq!(cache.len(), 0);\n    }\n\n    #[test]\n    fn test_resize_larger() {\n        let mut cache = LruCache::new(2);\n\n        cache.put(1, \"a\");\n        cache.put(2, \"b\");\n        cache.resize(4);\n        cache.put(3, \"c\");\n        cache.put(4, \"d\");\n\n        assert_eq!(cache.len(), 4);\n        assert_eq!(cache.get(&1), Some(&\"a\"));\n        assert_eq!(cache.get(&2), Some(&\"b\"));\n        assert_eq!(cache.get(&3), Some(&\"c\"));\n        assert_eq!(cache.get(&4), Some(&\"d\"));\n    }\n\n    #[test]\n    fn test_resize_smaller() {\n        let mut cache = LruCache::new(4);\n\n        cache.put(1, \"a\");\n        cache.put(2, \"b\");\n        cache.put(3, \"c\");\n        cache.put(4, \"d\");\n\n        cache.resize(2);\n\n        assert_eq!(cache.len(), 2);\n        assert!(cache.get(&1).is_none());\n        assert!(cache.get(&2).is_none());\n        assert_eq!(cache.get(&3), Some(&\"c\"));\n        assert_eq!(cache.get(&4), Some(&\"d\"));\n    }\n\n    #[test]\n    fn test_send() {\n        use std::thread;\n\n        let mut cache = LruCache::new(4);\n        cache.put(1, \"a\");\n\n        let handle = thread::spawn(move || {\n            assert_eq!(cache.get(&1), Some(&\"a\"));\n        });\n\n        assert!(handle.join().is_ok());\n    }\n\n    #[test]\n    fn test_multiple_threads() {\n        let mut pool = Pool::new(1);\n        let mut cache = LruCache::new(4);\n        cache.put(1, \"a\");\n\n        let cache_ref = &cache;\n        pool.scoped(|scoped| {\n            scoped.execute(move || {\n                assert_eq!(cache_ref.peek(&1), Some(&\"a\"));\n            });\n        });\n\n        assert_eq!((cache_ref).peek(&1), Some(&\"a\"));\n    }\n\n    #[test]\n    fn test_iter_forwards() {\n        let mut cache = LruCache::new(3);\n        cache.put(\"a\", 1);\n        cache.put(\"b\", 2);\n        cache.put(\"c\", 3);\n\n        {\n            // iter const\n            let mut iter = cache.iter();\n            assert_eq!(iter.len(), 3);\n            assert_opt_eq_tuple(iter.next(), (\"c\", 3));\n\n            assert_eq!(iter.len(), 2);\n            assert_opt_eq_tuple(iter.next(), (\"b\", 2));\n\n            assert_eq!(iter.len(), 1);\n            assert_opt_eq_tuple(iter.next(), (\"a\", 1));\n\n            assert_eq!(iter.len(), 0);\n            assert_eq!(iter.next(), None);\n        }\n        {\n            // iter mut\n            let mut iter = cache.iter_mut();\n            assert_eq!(iter.len(), 3);\n            assert_opt_eq_mut_tuple(iter.next(), (\"c\", 3));\n\n            assert_eq!(iter.len(), 2);\n            assert_opt_eq_mut_tuple(iter.next(), (\"b\", 2));\n\n            assert_eq!(iter.len(), 1);\n            assert_opt_eq_mut_tuple(iter.next(), (\"a\", 1));\n\n            assert_eq!(iter.len(), 0);\n            assert_eq!(iter.next(), None);\n        }\n    }\n\n    #[test]\n    fn test_iter_backwards() {\n        let mut cache = LruCache::new(3);\n        cache.put(\"a\", 1);\n        cache.put(\"b\", 2);\n        cache.put(\"c\", 3);\n\n        {\n            // iter const\n            let mut iter = cache.iter();\n            assert_eq!(iter.len(), 3);\n            assert_opt_eq_tuple(iter.next_back(), (\"a\", 1));\n\n            assert_eq!(iter.len(), 2);\n            assert_opt_eq_tuple(iter.next_back(), (\"b\", 2));\n\n            assert_eq!(iter.len(), 1);\n            assert_opt_eq_tuple(iter.next_back(), (\"c\", 3));\n\n            assert_eq!(iter.len(), 0);\n            assert_eq!(iter.next_back(), None);\n        }\n\n        {\n            // iter mut\n            let mut iter = cache.iter_mut();\n            assert_eq!(iter.len(), 3);\n            assert_opt_eq_mut_tuple(iter.next_back(), (\"a\", 1));\n\n            assert_eq!(iter.len(), 2);\n            assert_opt_eq_mut_tuple(iter.next_back(), (\"b\", 2));\n\n            assert_eq!(iter.len(), 1);\n            assert_opt_eq_mut_tuple(iter.next_back(), (\"c\", 3));\n\n            assert_eq!(iter.len(), 0);\n            assert_eq!(iter.next_back(), None);\n        }\n    }\n\n    #[test]\n    fn test_iter_forwards_and_backwards() {\n        let mut cache = LruCache::new(3);\n        cache.put(\"a\", 1);\n        cache.put(\"b\", 2);\n        cache.put(\"c\", 3);\n\n        {\n            // iter const\n            let mut iter = cache.iter();\n            assert_eq!(iter.len(), 3);\n            assert_opt_eq_tuple(iter.next(), (\"c\", 3));\n\n            assert_eq!(iter.len(), 2);\n            assert_opt_eq_tuple(iter.next_back(), (\"a\", 1));\n\n            assert_eq!(iter.len(), 1);\n            assert_opt_eq_tuple(iter.next(), (\"b\", 2));\n\n            assert_eq!(iter.len(), 0);\n            assert_eq!(iter.next_back(), None);\n        }\n        {\n            // iter mut\n            let mut iter = cache.iter_mut();\n            assert_eq!(iter.len(), 3);\n            assert_opt_eq_mut_tuple(iter.next(), (\"c\", 3));\n\n            assert_eq!(iter.len(), 2);\n            assert_opt_eq_mut_tuple(iter.next_back(), (\"a\", 1));\n\n            assert_eq!(iter.len(), 1);\n            assert_opt_eq_mut_tuple(iter.next(), (\"b\", 2));\n\n            assert_eq!(iter.len(), 0);\n            assert_eq!(iter.next_back(), None);\n        }\n    }\n\n    #[test]\n    fn test_iter_multiple_threads() {\n        let mut pool = Pool::new(1);\n        let mut cache = LruCache::new(3);\n        cache.put(\"a\", 1);\n        cache.put(\"b\", 2);\n        cache.put(\"c\", 3);\n\n        let mut iter = cache.iter();\n        assert_eq!(iter.len(), 3);\n        assert_opt_eq_tuple(iter.next(), (\"c\", 3));\n\n        {\n            let iter_ref = &mut iter;\n            pool.scoped(|scoped| {\n                scoped.execute(move || {\n                    assert_eq!(iter_ref.len(), 2);\n                    assert_opt_eq_tuple(iter_ref.next(), (\"b\", 2));\n                });\n            });\n        }\n\n        assert_eq!(iter.len(), 1);\n        assert_opt_eq_tuple(iter.next(), (\"a\", 1));\n\n        assert_eq!(iter.len(), 0);\n        assert_eq!(iter.next(), None);\n    }\n\n    #[test]\n    fn test_iter_clone() {\n        let mut cache = LruCache::new(3);\n        cache.put(\"a\", 1);\n        cache.put(\"b\", 2);\n\n        let mut iter = cache.iter();\n        let mut iter_clone = iter.clone();\n\n        assert_eq!(iter.len(), 2);\n        assert_opt_eq_tuple(iter.next(), (\"b\", 2));\n        assert_eq!(iter_clone.len(), 2);\n        assert_opt_eq_tuple(iter_clone.next(), (\"b\", 2));\n\n        assert_eq!(iter.len(), 1);\n        assert_opt_eq_tuple(iter.next(), (\"a\", 1));\n        assert_eq!(iter_clone.len(), 1);\n        assert_opt_eq_tuple(iter_clone.next(), (\"a\", 1));\n\n        assert_eq!(iter.len(), 0);\n        assert_eq!(iter.next(), None);\n        assert_eq!(iter_clone.len(), 0);\n        assert_eq!(iter_clone.next(), None);\n    }\n\n    #[test]\n    fn test_that_pop_actually_detaches_node() {\n        let mut cache = LruCache::new(5);\n\n        cache.put(\"a\", 1);\n        cache.put(\"b\", 2);\n        cache.put(\"c\", 3);\n        cache.put(\"d\", 4);\n        cache.put(\"e\", 5);\n\n        assert_eq!(cache.pop(&\"c\"), Some(3));\n\n        cache.put(\"f\", 6);\n\n        let mut iter = cache.iter();\n        assert_opt_eq_tuple(iter.next(), (\"f\", 6));\n        assert_opt_eq_tuple(iter.next(), (\"e\", 5));\n        assert_opt_eq_tuple(iter.next(), (\"d\", 4));\n        assert_opt_eq_tuple(iter.next(), (\"b\", 2));\n        assert_opt_eq_tuple(iter.next(), (\"a\", 1));\n        assert!(iter.next().is_none());\n    }\n\n    #[test]\n    fn test_get_with_borrow() {\n        use alloc::string::String;\n\n        let mut cache = LruCache::new(2);\n\n        let key = String::from(\"apple\");\n        cache.put(key, \"red\");\n\n        assert_opt_eq(cache.get(\"apple\"), \"red\");\n    }\n\n    #[test]\n    fn test_get_mut_with_borrow() {\n        use alloc::string::String;\n\n        let mut cache = LruCache::new(2);\n\n        let key = String::from(\"apple\");\n        cache.put(key, \"red\");\n\n        assert_opt_eq_mut(cache.get_mut(\"apple\"), \"red\");\n    }\n\n    #[test]\n    fn test_no_memory_leaks() {\n        static DROP_COUNT: AtomicUsize = AtomicUsize::new(0);\n\n        struct DropCounter;\n\n        impl Drop for DropCounter {\n            fn drop(&mut self) {\n                DROP_COUNT.fetch_add(1, Ordering::SeqCst);\n            }\n        }\n\n        let n = 100;\n        for _ in 0..n {\n            let mut cache = LruCache::new(1);\n            for i in 0..n {\n                cache.put(i, DropCounter {});\n            }\n        }\n        assert_eq!(DROP_COUNT.load(Ordering::SeqCst), n * n);\n    }\n\n    #[test]\n    fn test_no_memory_leaks_with_clear() {\n        static DROP_COUNT: AtomicUsize = AtomicUsize::new(0);\n\n        struct DropCounter;\n\n        impl Drop for DropCounter {\n            fn drop(&mut self) {\n                DROP_COUNT.fetch_add(1, Ordering::SeqCst);\n            }\n        }\n\n        let n = 100;\n        for _ in 0..n {\n            let mut cache = LruCache::new(1);\n            for i in 0..n {\n                cache.put(i, DropCounter {});\n            }\n            cache.clear();\n        }\n        assert_eq!(DROP_COUNT.load(Ordering::SeqCst), n * n);\n    }\n\n    #[test]\n    fn test_no_memory_leaks_with_resize() {\n        static DROP_COUNT: AtomicUsize = AtomicUsize::new(0);\n\n        struct DropCounter;\n\n        impl Drop for DropCounter {\n            fn drop(&mut self) {\n                DROP_COUNT.fetch_add(1, Ordering::SeqCst);\n            }\n        }\n\n        let n = 100;\n        for _ in 0..n {\n            let mut cache = LruCache::new(1);\n            for i in 0..n {\n                cache.put(i, DropCounter {});\n            }\n            cache.resize(0);\n        }\n        assert_eq!(DROP_COUNT.load(Ordering::SeqCst), n * n);\n    }\n\n    #[test]\n    fn test_no_memory_leaks_with_pop() {\n        static DROP_COUNT: AtomicUsize = AtomicUsize::new(0);\n\n        #[derive(Hash, Eq)]\n        struct KeyDropCounter(usize);\n\n        impl PartialEq for KeyDropCounter {\n            fn eq(&self, other: &Self) -> bool {\n                self.0.eq(&other.0)\n            }\n        }\n\n        impl Drop for KeyDropCounter {\n            fn drop(&mut self) {\n                DROP_COUNT.fetch_add(1, Ordering::SeqCst);\n            }\n        }\n\n        let n = 100;\n        for _ in 0..n {\n            let mut cache = LruCache::new(1);\n\n            for i in 0..100 {\n                cache.put(KeyDropCounter(i), i);\n                cache.pop(&KeyDropCounter(i));\n            }\n        }\n\n        assert_eq!(DROP_COUNT.load(Ordering::SeqCst), n * n * 2);\n    }\n\n    #[test]\n    fn test_zero_cap_no_crash() {\n        let mut cache = LruCache::new(0);\n        cache.put(\"reizeiin\", \"tohka\");\n    }\n}\n"
  },
  {
    "project": "autorand-rs",
    "target": 1,
    "commit_id": "c838309507f9364ecf61553a6ae113dd720fdab9",
    "func": "pub use autorand_derive::Random;\npub use rand;\n\nuse std::collections::{BTreeMap, BTreeSet, HashMap, HashSet, LinkedList, VecDeque};\nuse std::hash::{BuildHasher, Hash};\n\nuse rand::{distributions::Alphanumeric, Rng};\n\nconst LEN_LIMIT: usize = 16;\n\nconst UINT_LIMIT: usize = u16::max_value() as usize;\nconst INT_LOWER_LIMIT: isize = 0 - (UINT_LIMIT as isize);\nconst INT_UPPER_LIMIT: isize = UINT_LIMIT as isize;\n\npub trait Random: Sized {\n    fn random() -> Self;\n}\n\nimpl<T: Random> Random for Option<T> {\n    fn random() -> Self {\n        if rand::random::<bool>() {\n            Some(T::random())\n        } else {\n            None\n        }\n    }\n}\n\nimpl Random for String {\n    fn random() -> Self {\n        let mut rng = rand::thread_rng();\n        let length = rng.gen_range(0, LEN_LIMIT);\n        rng.sample_iter(&Alphanumeric).take(length).collect()\n    }\n}\n\nimpl<T: Random> Random for Vec<T> {\n    fn random() -> Self {\n        rand_length_iter().collect()\n    }\n}\n\nimpl<K: Random + Eq + Hash, V: Random, S: BuildHasher + Default> Random for HashMap<K, V, S> {\n    fn random() -> Self {\n        rand_length_iter::<(K, V)>().collect()\n    }\n}\n\nimpl<K: Random + Ord, V: Random> Random for BTreeMap<K, V> {\n    fn random() -> Self {\n        rand_length_iter::<(K, V)>().collect()\n    }\n}\n\nimpl<T: Random + Eq + Hash, S: BuildHasher + Default> Random for HashSet<T, S> {\n    fn random() -> Self {\n        rand_length_iter().collect()\n    }\n}\n\nimpl<T: Random + Ord> Random for BTreeSet<T> {\n    fn random() -> Self {\n        rand_length_iter().collect()\n    }\n}\n\nimpl<T: Random> Random for VecDeque<T> {\n    fn random() -> Self {\n        rand_length_iter().collect()\n    }\n}\n\nimpl<T: Random> Random for LinkedList<T> {\n    fn random() -> Self {\n        rand_length_iter().collect()\n    }\n}\n\nfn rand_length_iter<T: Random>() -> impl Iterator<Item = T> {\n    let length = rand::thread_rng().gen_range(0, LEN_LIMIT);\n    rand_iter().take(length)\n}\n\nfn rand_iter<T: Random>() -> impl Iterator<Item = T> {\n    (0..).map(|_| T::random())\n}\n\nimpl Random for f32 {\n    fn random() -> Self {\n        let base = rand::random::<f32>();\n        (base * 1000.0).ceil() / 1000.0\n    }\n}\n\nimpl Random for f64 {\n    fn random() -> Self {\n        let base = rand::random::<f64>();\n        (base * 1000.0).ceil() / 1000.0\n    }\n}\n\nmacro_rules! impl_primitives_unsigned {\n    ($($t:tt,)*) => {\n        $(\n        impl Random for $t {\n            fn random() -> Self {\n                let mut rng = rand::thread_rng();\n                if cfg!(not(feature = \"limited-integers\")) || ($t::max_value() as usize) < UINT_LIMIT {\n                    rng.gen_range(0, $t::max_value())\n                } else {\n                    rng.gen_range(0, UINT_LIMIT as $t)\n                }\n            }\n        }\n        )*\n    };\n}\n\nmacro_rules! impl_primitives_signed {\n    ($($t:tt,)*) => {\n        $(\n        impl Random for $t {\n            fn random() -> Self {\n                let mut rng = rand::thread_rng();\n                if cfg!(not(feature = \"limited-integers\")) || ($t::max_value() as isize) < INT_UPPER_LIMIT {\n                    rng.gen_range($t::min_value(), $t::max_value())\n                } else {\n                    rng.gen_range(INT_LOWER_LIMIT as $t, INT_UPPER_LIMIT as $t)\n                }\n            }\n        }\n        )*\n    };\n}\n\n#[rustfmt::skip]\nimpl_primitives_signed! {\n    i8, i16, i32, i64, isize,\n}\n\nimpl_primitives_unsigned! {\n    u8, u16, u32, u64, usize,\n}\n\nimpl Random for char {\n    fn random() -> Self {\n        rand::random()\n    }\n}\n\nimpl Random for bool {\n    fn random() -> Self {\n        rand::random()\n    }\n}\n\nmacro_rules! impl_arrays {\n    ($($s:expr,)*) => {\n        $(\n        impl<T: Random> Random for [T; $s] {\n            fn random() -> Self {\n                unsafe {\n                    let mut array: [T; $s] = std::mem::uninitialized();\n                    for i in 0..$s {\n                        std::ptr::write(&mut array[i], T::random());\n                    }\n                    array\n                }\n            }\n        }\n        )*\n    };\n}\n\n#[rustfmt::skip]\nimpl_arrays!(\n    1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,\n    17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32,\n    64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384,\n);\n\nmacro_rules! impl_tuples {\n    ($([$($t:tt)*],)*) => {\n        $(\n        impl<$($t:Random,)*> Random for ($($t,)*) {\n            fn random() -> Self {\n                ($($t::random(),)*)\n            }\n        }\n        )*\n    };\n}\n\nimpl_tuples!(\n    [A],\n    [A B],\n    [A B C],\n    [A B C D],\n    [A B C D E],\n    [A B C D E F],\n    [A B C D E F G],\n    [A B C D E F G H],\n    [A B C D E F G H I],\n    [A B C D E F G H I J],\n    [A B C D E F G H I J K],\n);\n\n#[cfg(feature = \"json\")]\nimpl Random for serde_json::Map<String, serde_json::Value> {\n    fn random() -> Self {\n        rand_length_iter().collect()\n    }\n}\n\n#[cfg(feature = \"json\")]\nimpl Random for serde_json::Number {\n    fn random() -> Self {\n        serde_json::Number::from_f64(Random::random()).unwrap()\n    }\n}\n\n#[cfg(feature = \"json\")]\n#[cfg(not(feature = \"json-value-always-null\"))]\nimpl Random for serde_json::Value {\n    fn random() -> Self {\n        use serde_json::Value;\n        let variant = rand::thread_rng().gen_range(0u8, 6);\n        match variant {\n            0 => Value::Number(Random::random()),\n            1 => Value::Bool(Random::random()),\n            2 => Value::String(Random::random()),\n            3 => Value::Array(Random::random()),\n            4 => Value::Null,\n            5 => Value::Object(Random::random()),\n            _ => unreachable!(),\n        }\n    }\n}\n\n#[cfg(feature = \"json\")]\n#[cfg(feature = \"json-value-always-null\")]\nimpl Random for serde_json::Value {\n    fn random() -> Self {\n        use serde_json::Value;\n        Value::Null\n    }\n}\n"
  },
  {
    "project": "byte_buffer",
    "target": 1,
    "commit_id": "79b1a5c23a4962cbcd1539af9aadbfc277981442",
    "func": "#![allow(unused)]\n\nuse crate::make_box;\nuse crate::pool::ElemBuilder;\nuse crate::utils::{check_len, cpu_relax, enter, make_elem};\nuse std::mem;\nuse std::ptr;\nuse std::sync::atomic::{AtomicBool, AtomicU16, AtomicUsize, AtomicPtr, Ordering};\n\n/// Constants\npub(crate) const SLOT_CAP: usize = 8;\nconst TRIALS_COUNT: usize = 4;\n\npub(crate) struct Bucket<T> {\n    /// the actual data store\n    slot: [Option<T>; SLOT_CAP],\n\n    /// the current ready-to-use slot index, always offset by 1 to the actual index\n    len: usize,\n\n    /// if the slot is currently being read/write to\n    access: AtomicBool,\n}\n\nimpl<T> Bucket<T> {\n    pub(crate) fn new(filler: Option<fn() -> T>) -> Self {\n        // create the placeholder\n        let mut slice: [Option<T>; SLOT_CAP] = Default::default();\n\n        // fill the placeholder if required\n        if let Some(handle) = filler.as_ref() {\n            for item in slice.iter_mut() {\n                item.replace(handle());\n            }\n        }\n\n        // done\n        Bucket {\n            slot: slice,\n            len: SLOT_CAP,\n            access: AtomicBool::new(false),\n        }\n    }\n\n    pub(crate) fn size_hint(&self) -> usize {\n        self.len % (SLOT_CAP + 1)\n    }\n\n    pub(crate) fn access(&self, get: bool) -> bool {\n        // count down to lock timeout\n        let mut count = if get { 4 } else { 2 };\n\n        // check the access and wait if not available\n        while self\n            .access\n            .compare_exchange(false, true, Ordering::Acquire, Ordering::Acquire)\n            .is_err()\n        {\n            if count == 0 {\n                return false;\n            }\n\n            cpu_relax(2 * count);\n            count -= 1;\n        }\n\n        if (get && self.len == 0) || (!get && self.len == SLOT_CAP) {\n            // not actually locked\n            self.leave();\n\n            // read but empty, or write but full, all fail\n            return false;\n        }\n\n        true\n    }\n\n    pub(crate) fn leave(&self) {\n        self.access.store(false, Ordering::Release);\n    }\n\n    /// The function is safe because it's used internally, and each time it's guaranteed a access has\n    /// been acquired previously\n    pub(crate) fn checkout(&mut self) -> Result<T, ()> {\n        // need to loop over the slots to make sure we're getting the valid value, starting from\n        let i = self.len - 1;\n        let val = self.slot[i].take().ok_or(());\n\n        // update internal states if we're good\n        if val.is_ok() {\n            self.len = i;\n        }\n\n        // return the inner value\n        val\n    }\n\n    /// The function is safe because it's used internally, and each time it's guaranteed a access has\n    /// been acquired previously\n    pub(crate) fn release(&mut self, mut val: T, reset: Option<fn(&mut T)>) {\n        // need to loop over the slots to make sure we're getting the valid value\n        let i = self.len;\n        if i >= SLOT_CAP {\n            return;\n        }\n\n        if self.slot[i].is_none() {\n            // reset the struct before releasing it to the pool\n            if let Some(handle) = reset {\n                handle(&mut val);\n            }\n\n            // move the value in\n            self.slot[i].replace(val);\n\n            // update internal states\n            self.len = i + 1;\n\n            // done\n            return;\n        }\n\n        // if all slots are full, no need to fallback, the `val` will be dropped here\n        drop(val);\n    }\n\n    /*\n        fn swap_in(&mut self, index: usize, content: T) {\n            let src = &mut self.slot[index] as *mut Option<T>;\n            unsafe {\n                src.write(Some(content));\n            }\n        }\n\n        fn swap_out(&mut self, index: usize) -> T {\n            let src = &mut self.slot[index] as *mut Option<T>;\n\n            unsafe {\n                // save off the old values\n                let val = ptr::read(src).unwrap_or_default();\n\n                // swap values\n                src.write(None);\n\n                val\n            }\n        }\n    */\n}\n\npub(crate) struct Bucket2<T> {\n    /// The actual data store. Data are stored in heap and not managed by the runtime, so we must\n    /// restore them and drop the data when the bucket is dropped.\n    slot: [*mut T; SLOT_CAP],\n\n    /// the current ready-to-use slot count, always offset by 1 to the actual index. This may not be\n    /// a real-time reflection of how many elements are actually in the bucket, especially if other\n    /// threads are actively interact with the sync pool.\n    len: AtomicUsize,\n\n    /// The bitmap of the slots. The implementation rely on the assumption that each bucket only contains\n    /// at most 8 elements, otherwise, we need to update the underlying atomic data structure.\n    ///\n    /// Each position's state are comprised with 2 consecutive bits at (2 * pos) and (2 * pos + 1),\n    /// where the bit at (2 * pos) indicates if the slot contains an element (1 -> element; 0 -> empty);\n    /// the bit at (2 * pos + 1) indicates if someone is operating at the slot, and hence everyone\n    /// else shall avoid using the position, otherwise we may corrupt the underlying data structure.\n    bitmap: AtomicU16,\n}\n\nimpl<T> Bucket2<T> {\n    /// Instantiate the bucket and set initial values. If we want to pre-fill the slots, we will also\n    /// make sure the bitmap is updated as well.\n    pub(crate) fn new(filler: Option<&ElemBuilder<T>>) -> Self {\n        // create the placeholder\n        let mut slice: [*mut T; SLOT_CAP] = [ptr::null_mut(); SLOT_CAP];\n        let mut bitmap: u16 = 0;\n\n        // fill the slots and update the bitmap\n        if let Some(handle) = filler {\n            for (i, item) in slice.iter_mut().enumerate() {\n                *item = Box::into_raw(make_elem(handle));\n                bitmap |= 1 << (2 * i as u16);\n            }\n        }\n\n        // done\n        Bucket2 {\n            slot: slice,\n            len: AtomicUsize::new(SLOT_CAP),\n            bitmap: AtomicU16::new(bitmap),\n        }\n    }\n\n    /// Obtain the number of available elements in this bucket. The size is volatile if the API is\n    /// accessed concurrently with read/write, so the\n    pub(crate) fn size_hint(&self) -> usize {\n        self.len.load(Ordering::Acquire) % (SLOT_CAP + 1)\n        //        check_len(self.bitmap.load(Ordering::Acquire))\n    }\n\n    /// Try to locate a position where we can fulfil the request -- either grab an element from the\n    /// bucket, or put an element back into the bucket. If such a request can't be done, we will\n    /// return error.\n    pub(crate) fn access(&self, get: bool) -> Result<usize, ()> {\n        // register intentions first, make sure the len is in post-action state so it can reject\n        // future or concurrent attempts if it's unlikely to succeed in this slot.\n        let curr_len = if get {\n            self.len.fetch_sub(1, Ordering::Relaxed)\n        } else {\n            self.len.fetch_add(1, Ordering::Relaxed)\n        };\n\n        // oops, last op blew off the roof, back off mate. Note that (0 - 1 == MAX_USIZE) for stack\n        // overflow, still way off the roof and a proof of not doing well.\n        if curr_len > SLOT_CAP || (get && curr_len == 0) {\n            return self.access_failure(get);\n        }\n\n        // try 2 times on this slot if the desired slot happens to be taken ...\n        let mut trials: usize = TRIALS_COUNT;\n        while trials > 0 {\n            trials -= 1;\n\n            // init try\n            let (pos, mask) = match enter(self.bitmap.load(Ordering::Acquire), get) {\n                Ok(pos) => (pos, 0b10 << (2 * pos)),\n                Err(()) => continue,\n            };\n\n            // main loop to try to update the bitmap\n            let old = self.bitmap.fetch_or(mask, Ordering::AcqRel);\n\n            // if the lock bit we replaced was not yet marked at the atomic op, we're good\n            if old & mask == 0 {\n                return Ok(pos as usize);\n            }\n\n            // otherwise, try again after some wait. The earliest registered gets some favor by\n            // checking and trying to lodge a position more frequently than the later ones.\n            cpu_relax(trials + 1);\n        }\n\n        self.access_failure(get)\n    }\n\n    /// Update the bitmap to make sure: 1) the lock bit of the operated upon position is flipped back\n    /// to free-to-use; 2) the marker bit of the operated upon position is properly updated. We should\n    /// succeed at the first trial of the for-loop, otherwise we may in trouble.\n    pub(crate) fn leave(&self, pos: u16) {\n        // the lock bit we want to toggle\n        let lock_bit = 0b10 << (2 * pos);\n\n        loop {\n            // update both lock bit and the slot bit\n            let old = self.bitmap.fetch_xor(0b11 << (2 * pos), Ordering::SeqCst);\n            if old & lock_bit == lock_bit {\n                return;\n            }\n        }\n    }\n\n    /// Locate the element from the desired position. The API will return an error if such operation\n    /// can't be accomplished, such as the destination doesn't contain a element, or the desired position\n    /// is OOB.\n    ///\n    /// The function is safe because it's used internally, and each time it's guaranteed an exclusive\n    /// access has been acquired previously.\n    pub(crate) fn checkout(&mut self, pos: usize) -> Result<Box<T>, ()> {\n        // check the boundary and underlying slot position before doing something with it.\n        if pos >= SLOT_CAP || self.slot[pos].is_null() {\n            return Err(());\n        }\n\n        // swap the pointer out of the slot, this is the raw pointer to the heap memory location of\n        // the underlying data. The swap operation is cheap, since *mut T is guaranteed to be 8-bytes\n        // in length and hence we'll run the \"simplified\" version of the mem swap which is cheaper\n        // to run.\n        let val = mem::replace(&mut self.slot[pos], ptr::null_mut());\n\n        // Restore to the box version, this won't allocate since the pointed to content already\n        // exist. This action is safe since all values we put behind the pointers are knocked out\n        // from its boxed version, guaranteed by the implementation of the `new` and `release` APIs.\n        Ok(unsafe { Box::from_raw(val) })\n    }\n\n    /// Release the element back into the pool. If a reset function has been previously provided, we\n    /// will call the function to reset the value before putting it back. The API will be no-op if\n    /// the desired operation can't be conducted, such as if the position is OOB, or the position\n    /// already contains an element.\n    ///\n    /// The function is safe because it's used internally, and each time it's guaranteed an exclusive\n    /// access has been acquired previously\n    pub(crate) fn release(&mut self, pos: usize, mut val: Box<T>, reset: Option<fn(&mut T)>) {\n        // check if the slot has already been occupied (unlikely but still)\n        if pos >= SLOT_CAP || !self.slot[pos].is_null() {\n            return;\n        }\n\n        // reset the struct before releasing it to the pool\n        if let Some(handle) = reset {\n            handle(&mut val);\n        }\n\n        // move the value in\n        self.slot[pos] = Box::into_raw(val);\n    }\n\n    #[inline]\n    fn access_failure(&self, get: bool) -> Result<usize, ()> {\n        if get {\n            self.len.fetch_add(1, Ordering::AcqRel);\n        } else {\n            self.len.fetch_sub(1, Ordering::AcqRel);\n        }\n\n        Err(())\n    }\n}\n\nimpl<T> Drop for Bucket2<T> {\n    fn drop(&mut self) {\n        for item in self.slot.iter_mut() {\n            if item.is_null() {\n                continue;\n            }\n\n            unsafe {\n                ptr::drop_in_place(*item);\n            }\n            *item = ptr::null_mut();\n        }\n    }\n}\n\nunsafe impl<T> Send for Bucket2<T> {}\n\npub(crate) struct RingBucket<T> {\n    /// The actual data store. Data are stored in heap and not managed by the runtime, so we must\n    /// restore them and drop the data when the bucket is dropped.\n    slot: [AtomicPtr<T>; SLOT_CAP],\n\n    /// the current ready-to-use slot count, always offset by 1 to the actual index. This may not be\n    /// a real-time reflection of how many elements are actually in the bucket, especially if other\n    /// threads are actively interact with the sync pool.\n    len: AtomicUsize,\n\n    head: AtomicUsize,\n\n    tail: AtomicUsize,\n}\n\nimpl<T> RingBucket<T> {\n    /// Instantiate the bucket and set initial values. If we want to pre-fill the slots, we will also\n    /// make sure the bitmap is updated as well.\n    pub(crate) fn new(filler: Option<&ElemBuilder<T>>) -> Self {\n        // create the placeholder\n        let mut slice: [AtomicPtr<T>; SLOT_CAP] = Default::default();\n\n        // fill the slots and update the bitmap\n        if let Some(handle) = filler {\n            for (_, item) in slice.iter_mut().enumerate() {\n                item.swap(Box::into_raw(make_elem(handle)), Ordering::SeqCst);\n            }\n        }\n\n        // done\n        RingBucket {\n            slot: slice,\n            len: AtomicUsize::new(SLOT_CAP),\n            head: AtomicUsize::new(0),\n            tail: AtomicUsize::new(SLOT_CAP),\n        }\n    }\n}\n"
  },
  {
    "project": "libsbc-rs",
    "target": 1,
    "commit_id": "7278b23901f93d956d9739fdfc4ced147cc3f242",
    "func": "//! Bindings to the Linux Bluetooth low-complexity, subband codec (SBC) library.\n\nextern crate failure;\nextern crate libsbc_sys as ffi;\nextern crate slice_deque;\n\npub use crate::error::{Error, ErrorKind, Result};\n\nmod error;\n\nuse std::io::Read;\nuse std::mem;\n\nuse failure::ResultExt;\nuse slice_deque::SliceDeque;\n\n// TODO: Tune these buffer sizes\n/// Maximum number of samples present in an SBC frame\nconst MAX_SAMPLES_PER_FRAME: usize = 8196;\n\nconst BUFFER_SIZE: usize = MAX_SAMPLES_PER_FRAME * 15;\nconst REFILL_TRIGGER: usize = MAX_SAMPLES_PER_FRAME * 8;\n\n/// SBC stream decoder that produces frames.\npub struct Decoder<R>\nwhere\n    R: Read,\n{\n    reader: R,\n    buffer: SliceDeque<u8>,\n    sbc: Box<ffi::sbc_struct>,\n}\n\nunsafe impl<R> Send for Decoder<R>\nwhere\n        R: Read,\n{\n}\n\n/// A SBC frame\npub struct Frame {\n    /// Decoded audio\n    pub data: Vec<i16>,\n    /// Sample rate in hertz.\n    pub sample_rate: i32,\n    /// Number of channels in the frame.\n    pub channels: usize,\n}\n\nimpl<R> Decoder<R>\nwhere\n    R: Read,\n{\n\n    /// Create a new decoder from the reader.\n    pub fn new(reader: R) -> Decoder<R> {\n        let mut sbc = unsafe { Box::new(mem::zeroed()) };\n        unsafe {\n            // TODO: Magic number\n            ffi::sbc_init(&mut *sbc, 0);\n            // sbc.endian = ffi::SBC_BE as u8;\n        };\n\n        Decoder {\n            reader,\n            buffer: SliceDeque::with_capacity(BUFFER_SIZE),\n            sbc,\n        }\n    }\n\n    /// Decode the next frame from the stream.\n    pub fn next_frame(&mut self) -> Result<Frame> {\n        loop {\n            if self.buffer.len() < REFILL_TRIGGER {\n                if self.refill()? == 0 {\n                    return Err(Error::eof());\n                }\n            }\n\n            return self.decode_frame()\n        }\n    }\n\n    fn decode_frame(&mut self) -> Result<Frame> {\n        let mut pcm: Vec<i16> = Vec::with_capacity(MAX_SAMPLES_PER_FRAME);\n\n        let mut num_written: usize = 0;\n        let num_read: isize = unsafe {\n            ffi::sbc_decode(\n                &mut *self.sbc,\n                self.buffer.as_ptr() as *const std::os::raw::c_void,\n                self.buffer.len(),\n                pcm.as_mut_ptr() as *mut std::os::raw::c_void,\n                pcm.capacity(),\n                &mut num_written,\n            ) as _\n        };\n\n        let sample_rate = match self.sbc.frequency as u32 {\n            ffi::SBC_FREQ_16000 => 16000,\n            ffi::SBC_FREQ_32000 => 32000,\n            ffi::SBC_FREQ_44100 => 44100,\n            ffi::SBC_FREQ_48000 => 48000,\n            _ => return Err(ErrorKind::BadDecode.into()),\n        };\n\n        let channels = match self.sbc.mode as u32 {\n            ffi::SBC_MODE_MONO => 1,\n            ffi::SBC_MODE_DUAL_CHANNEL => 2,\n            ffi::SBC_MODE_STEREO => 2,\n            ffi::SBC_MODE_JOINT_STEREO => 2,\n            _ => return Err(ErrorKind::BadDecode.into()),\n        };\n\n        if num_written > 0 {\n            // Divide by the size of i16\n            unsafe { pcm.set_len(num_written / 2) }\n        }\n\n        let frame = Frame {\n            data: pcm,\n            sample_rate,\n            channels,\n        };\n\n        let current_len = self.buffer.len();\n        if num_read < 0 || num_read as usize > current_len {\n            return Err(ErrorKind::BadDecode.into());\n        }\n        let num_read = num_read as usize;\n\n        self.buffer.truncate_front(current_len - num_read);\n\n        if num_written == 0 {\n            Err(ErrorKind::NoData.into())\n        } else {\n            Ok(frame)\n        }\n    }\n\n    fn refill(&mut self) -> Result<usize> {\n        let mut data: [u8; MAX_SAMPLES_PER_FRAME * 5] = [0; MAX_SAMPLES_PER_FRAME * 5];\n        let bytes_read = self.reader.read(&mut data).context(ErrorKind::Io)?;\n        self.buffer.extend(data.iter());\n        Ok(bytes_read)\n    }\n}\n"
  },
  {
    "project": "metrics",
    "target": 1,
    "commit_id": "5be6c93b6d186ca4745d1a7f2c1a42dee86c21e4",
    "func": "use crossbeam_epoch::{pin as epoch_pin, unprotected, Atomic, Guard, Owned, Shared};\nuse crossbeam_utils::Backoff;\nuse std::{\n    cell::UnsafeCell,\n    cmp::min,\n    mem, slice,\n    sync::atomic::{AtomicUsize, Ordering},\n};\n\n#[cfg(target_pointer_width = \"16\")]\nconst BLOCK_SIZE: usize = 16;\n#[cfg(target_pointer_width = \"32\")]\nconst BLOCK_SIZE: usize = 32;\n#[cfg(target_pointer_width = \"64\")]\nconst BLOCK_SIZE: usize = 64;\n\n/// Discrete chunk of values with atomic read/write access.\nstruct Block<T> {\n    // Write index.\n    write: AtomicUsize,\n\n    // Read bitmap.\n    read: AtomicUsize,\n\n    // The individual slots.\n    slots: [UnsafeCell<T>; BLOCK_SIZE],\n\n    // The \"next\" block to iterate, aka the block that came before this one.\n    next: Atomic<Block<T>>,\n}\n\nimpl<T> Block<T> {\n    /// Creates a new [`Block`].\n    pub fn new() -> Self {\n        Block {\n            write: AtomicUsize::new(0),\n            read: AtomicUsize::new(0),\n            slots: unsafe { mem::zeroed() },\n            next: Atomic::null(),\n        }\n    }\n\n    // Gets the length of the next block, if it exists.\n    pub(crate) fn next_len(&self, guard: &Guard) -> usize {\n        let tail = self.next.load(Ordering::Acquire, guard);\n        if tail.is_null() {\n            return 0;\n        }\n\n        let tail_block = unsafe { tail.deref() };\n        tail_block.len()\n    }\n\n    /// Gets the current length of this block.\n    pub fn len(&self) -> usize {\n        self.read.load(Ordering::Acquire).trailing_ones() as usize\n    }\n\n    // Whether or not this block is currently quieseced i.e. no in-flight writes.\n    pub fn is_quiesced(&self) -> bool {\n        let len = self.len();\n        if len == BLOCK_SIZE {\n            return true;\n        }\n\n        // We have to clamp self.write since multiple threads might race on filling the last block,\n        // so the value could actually exceed BLOCK_SIZE.\n        min(self.write.load(Ordering::Acquire), BLOCK_SIZE) == len\n    }\n\n    /// Gets a slice of the data written to this block.\n    pub fn data(&self) -> &[T] {\n        let len = self.len();\n        let head = self.slots[0].get();\n        unsafe { slice::from_raw_parts(head as *const T, len) }\n    }\n\n    /// Pushes a value into this block.\n    pub fn push(&self, value: T) -> Result<(), T> {\n        // Try to increment the index.  If we've reached the end of the block, let the bucket know\n        // so it can attach another block.\n        let index = self.write.fetch_add(1, Ordering::AcqRel);\n        if index >= BLOCK_SIZE {\n            return Err(value);\n        }\n\n        // Update the slot.\n        unsafe {\n            self.slots[index].get().write(value);\n        }\n\n        // Scoot our read index forward.\n        self.read.fetch_or(1 << index, Ordering::AcqRel);\n\n        Ok(())\n    }\n}\n\nunsafe impl<T> Send for Block<T> {}\nunsafe impl<T> Sync for Block<T> {}\n\nimpl<T> std::fmt::Debug for Block<T> {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        let has_next = unsafe { !self.next.load(Ordering::Acquire, &unprotected()).is_null() };\n        f.debug_struct(\"Block\")\n            .field(\"type\", &std::any::type_name::<T>())\n            .field(\"block_size\", &BLOCK_SIZE)\n            .field(\"write\", &self.write.load(Ordering::Acquire))\n            .field(\"read\", &self.read.load(Ordering::Acquire))\n            .field(\"len\", &self.len())\n            .field(\"has_next\", &has_next)\n            .finish()\n    }\n}\n\n/// A lock-free bucket with snapshot capabilities.\n///\n/// This bucket is implemented as a singly-linked list of blocks, where each block is a small\n/// buffer that can hold a handful of elements.  There is no limit to how many elements can be in\n/// the bucket at a time.  Blocks are dynamically allocated as elements are pushed into the bucket.\n///\n/// Unlike a queue, buckets cannot be drained element by element: callers must iterate the whole\n/// structure.  Reading the bucket happens in a quasi-reverse fashion, to allow writers to make\n/// forward progress without affecting the iteration of the previously written values.\n///\n/// For example, in a scenario where an internal block can hold 4 elements, and the caller has\n/// written 10 elements to the bucket, you would expect to see the values in this order when iterating:\n///\n/// [6 7 8 9] [2 3 4 5] [0 1]\n///\n/// Block sizes are dependent on the target architecture, where each block can hold N items, and N\n/// is the number of bits in the target architecture's pointer width.\n#[derive(Debug)]\npub struct AtomicBucket<T> {\n    tail: Atomic<Block<T>>,\n}\n\nimpl<T> AtomicBucket<T> {\n    /// Creates a new, empty bucket.\n    pub fn new() -> Self {\n        AtomicBucket {\n            tail: Atomic::null(),\n        }\n    }\n\n    /// Checks whether or not this bucket is empty.\n    pub fn is_empty(&self) -> bool {\n        let guard = &epoch_pin();\n        let tail = self.tail.load(Ordering::Acquire, guard);\n        if tail.is_null() {\n            return true;\n        }\n\n        // We have to check the next block of our tail in case the current tail is simply a fresh\n        // block that has not been written to yet.\n        let tail_block = unsafe { tail.deref() };\n        tail_block.len() == 0 && tail_block.next_len(&guard) == 0\n    }\n\n    /// Pushes an element into the bucket.\n    pub fn push(&self, value: T) {\n        let mut original = value;\n        let guard = &epoch_pin();\n        loop {\n            // Load the tail block, or install a new one.\n            let mut tail = self.tail.load(Ordering::Acquire, guard);\n            if tail.is_null() {\n                // No blocks at all yet.  We need to create one.\n                match self.tail.compare_and_set(\n                    Shared::null(),\n                    Owned::new(Block::new()),\n                    Ordering::AcqRel,\n                    guard,\n                ) {\n                    // We won the race to install the new block.\n                    Ok(ptr) => tail = ptr,\n                    // Somebody else beat us, so just update our pointer.\n                    Err(e) => tail = e.current,\n                }\n            }\n\n            // We have a block now, so we need to try writing to it.\n            let tail_block = unsafe { tail.deref() };\n            match tail_block.push(original) {\n                // If the push was OK, then the block wasn't full.  It might _now_ be full, but we'll\n                // let future callers deal with installing a new block if necessary.\n                Ok(_) => return,\n                // The block was full, so we've been given the value back and we need to install a new block.\n                Err(value) => {\n                    match self.tail.compare_and_set(\n                        tail,\n                        Owned::new(Block::new()),\n                        Ordering::AcqRel,\n                        guard,\n                    ) {\n                        // We managed to install the block, so we need to link this new block to\n                        // the nextious block.\n                        Ok(ptr) => {\n                            let new_tail = unsafe { ptr.deref() };\n                            new_tail.next.store(tail, Ordering::Release);\n\n                            // Now push into our new block.\n                            match new_tail.push(value) {\n                                // We wrote the value successfully, so we're good here!\n                                Ok(_) => return,\n                                // The block was full, so just loop and start over.\n                                Err(value) => {\n                                    original = value;\n                                    continue;\n                                }\n                            }\n                        }\n                        // Somebody else installed the block before us, so let's just start over.\n                        Err(_) => original = value,\n                    }\n                }\n            }\n        }\n    }\n\n    /// Collects all of the elements written to the bucket.\n    ///\n    /// This operation can be slow as it involves allocating enough space to hold all of the\n    /// elements within the bucket.  Consider [`data_with`](AtomicBucket::data_with) to incrementally iterate\n    /// the internal blocks within the bucket.\n    ///\n    /// Elements are in partial reverse order: blocks are iterated in reverse order, but the\n    /// elements within them will appear in their original order.\n    pub fn data(&self) -> Vec<T>\n    where\n        T: Clone,\n    {\n        let mut values = Vec::new();\n        self.data_with(|block| values.extend_from_slice(block));\n        values\n    }\n\n    /// Iterates all of the elements written to the bucket, invoking `f` for each block.\n    ///\n    /// Elements are in partial reverse order: blocks are iterated in reverse order, but the\n    /// elements within them will appear in their original order.\n    pub fn data_with<F>(&self, mut f: F)\n    where\n        F: FnMut(&[T]),\n    {\n        let guard = &epoch_pin();\n        let backoff = Backoff::new();\n\n        // While we have a valid block -- either `tail` or the next block as we keep reading -- we\n        // load the data from each block and process it by calling `f`.\n        let mut block_ptr = self.tail.load(Ordering::Acquire, guard);\n        while !block_ptr.is_null() {\n            let block = unsafe { block_ptr.deref() };\n\n            // We wait for the block to be quiesced to ensure we get any in-flight writes, and\n            // snoozing specifically yields the reading thread to ensure things are given a\n            // chance to complete.\n            while !block.is_quiesced() {\n                backoff.snooze();\n            }\n\n            // Read the data out of the block.\n            let data = block.data();\n            f(data);\n\n            // Load the next block.\n            block_ptr = block.next.load(Ordering::Acquire, guard);\n        }\n    }\n\n    /// Clears the bucket.\n    ///\n    /// Deallocation of the internal blocks happens only when all readers have finished, and so\n    /// will not necessarily occur during or immediately preceding this method.\n    ///\n    /// # Note\n    /// This method will not affect reads that are already in progress.\n    pub fn clear(&self) {\n        self.clear_with(|_| {})\n    }\n\n    /// Clears the bucket, invoking `f` for every block that will be cleared.\n    ///\n    /// Deallocation of the internal blocks happens only when all readers have finished, and so\n    /// will not necessarily occur during or immediately preceding this method.\n    ///\n    /// This method is useful for accumulating values and then observing them, in a way that allows\n    /// the caller to avoid visiting the same values again the next time.\n    ///\n    /// This method allows a pattern of observing values before they're cleared, with a clear\n    /// demarcation. A similar pattern used in the wild would be to have some data structure, like\n    /// a vector, which is continuously filled, and then eventually swapped out with a new, empty\n    /// vector, allowing the caller to read all of the old values while new values are being\n    /// written, over and over again.\n    ///\n    /// # Note\n    /// This method will not affect reads that are already in progress.\n    pub fn clear_with<F>(&self, mut f: F)\n    where\n        F: FnMut(&[T]),\n    {\n        // We simply swap the tail pointer which effectively clears the bucket.  Callers might\n        // still be in process of writing to the tail node, or reading the data, but new callers\n        // will see it as empty until another write proceeds.\n        let guard = &epoch_pin();\n        let mut block_ptr = self.tail.load(Ordering::Acquire, guard);\n        if !block_ptr.is_null()\n            && self\n                .tail\n                .compare_and_set(block_ptr, Shared::null(), Ordering::SeqCst, guard)\n                .is_ok()\n        {\n            let mut freeable_blocks = Vec::new();\n            let backoff = Backoff::new();\n\n            // While we have a valid block -- either `tail` or the next block as we keep reading -- we\n            // load the data from each block and process it by calling `f`.\n            while !block_ptr.is_null() {\n                let block = unsafe { block_ptr.deref() };\n\n                // We wait for the block to be quiesced to ensure we get any in-flight writes, and\n                // snoozing specifically yields the reading thread to ensure things are given a\n                // chance to complete.\n                while !block.is_quiesced() {\n                    backoff.snooze();\n                }\n\n                // Read the data out of the block.\n                let data = block.data();\n                f(data);\n\n                // Load the next block and take the shared reference to the current.\n                let old_block_ptr =\n                    mem::replace(&mut block_ptr, block.next.load(Ordering::Acquire, guard));\n                freeable_blocks.push(old_block_ptr);\n            }\n\n            // Once a block has been read, it is now detached from the bucket and no longer\n            // required, so we enqueue a deferred operation to block it as soon as all threads are\n            // unpinned, which reclaims the memory.\n            unsafe {\n                guard.defer_unchecked(move || {\n                    for block in freeable_blocks {\n                        drop(block.into_owned());\n                    }\n                });\n            }\n\n            // This asks the global collector to attempt to drive execution of deferred operations a\n            // little sooner than it may have done so otherwise.\n            guard.flush();\n        }\n    }\n}\n\nimpl<T> Default for AtomicBucket<T> {\n    fn default() -> Self {\n        Self {\n            tail: Atomic::null(),\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::{AtomicBucket, Block, BLOCK_SIZE};\n    use crossbeam_utils::thread::scope;\n\n    #[test]\n    fn test_create_new_block() {\n        let block: Block<u64> = Block::new();\n        assert_eq!(block.len(), 0);\n\n        let data = block.data();\n        assert_eq!(data.len(), 0);\n    }\n\n    #[test]\n    fn test_block_write_then_read() {\n        let block = Block::new();\n        assert_eq!(block.len(), 0);\n\n        let data = block.data();\n        assert_eq!(data.len(), 0);\n\n        let result = block.push(42);\n        assert!(result.is_ok());\n        assert_eq!(block.len(), 1);\n\n        let data = block.data();\n        assert_eq!(data.len(), 1);\n        assert_eq!(data[0], 42);\n    }\n\n    #[test]\n    fn test_block_write_until_full_then_read() {\n        let block = Block::new();\n        assert_eq!(block.len(), 0);\n\n        let data = block.data();\n        assert_eq!(data.len(), 0);\n\n        let mut i = 0;\n        let mut total = 0;\n        while i < BLOCK_SIZE as u64 {\n            assert!(block.push(i).is_ok());\n\n            total += i;\n            i += 1;\n        }\n\n        let data = block.data();\n        assert_eq!(data.len(), BLOCK_SIZE);\n\n        let sum: u64 = data.iter().sum();\n        assert_eq!(sum, total);\n\n        let result = block.push(42);\n        assert!(result.is_err());\n    }\n\n    #[test]\n    fn test_block_write_until_full_then_read_mt() {\n        let block = Block::new();\n        assert_eq!(block.len(), 0);\n\n        let data = block.data();\n        assert_eq!(data.len(), 0);\n\n        let res = scope(|s| {\n            let t1 = s.spawn(|_| {\n                let mut i = 0;\n                let mut total = 0;\n                while i < BLOCK_SIZE as u64 / 2 {\n                    assert!(block.push(i).is_ok());\n\n                    total += i;\n                    i += 1;\n                }\n                total\n            });\n\n            let t2 = s.spawn(|_| {\n                let mut i = 0;\n                let mut total = 0;\n                while i < BLOCK_SIZE as u64 / 2 {\n                    assert!(block.push(i).is_ok());\n\n                    total += i;\n                    i += 1;\n                }\n                total\n            });\n\n            let t1_total = t1.join().unwrap();\n            let t2_total = t2.join().unwrap();\n\n            t1_total + t2_total\n        });\n\n        let total = res.unwrap();\n\n        let data = block.data();\n        assert_eq!(data.len(), BLOCK_SIZE);\n\n        let sum: u64 = data.iter().sum();\n        assert_eq!(sum, total);\n\n        let result = block.push(42);\n        assert!(result.is_err());\n    }\n\n    #[test]\n    fn test_bucket_write_then_read() {\n        let bucket = AtomicBucket::new();\n        bucket.push(42);\n\n        let snapshot = bucket.data();\n        assert_eq!(snapshot.len(), 1);\n        assert_eq!(snapshot[0], 42);\n    }\n\n    #[test]\n    fn test_bucket_multiple_blocks_write_then_read() {\n        let bucket = AtomicBucket::new();\n\n        let snapshot = bucket.data();\n        assert_eq!(snapshot.len(), 0);\n\n        let target = (BLOCK_SIZE * 3 + BLOCK_SIZE / 2) as u64;\n        let mut i = 0;\n        let mut total = 0;\n        while i < target {\n            bucket.push(i);\n\n            total += i;\n            i += 1;\n        }\n\n        let snapshot = bucket.data();\n        assert_eq!(snapshot.len(), target as usize);\n\n        let sum: u64 = snapshot.iter().sum();\n        assert_eq!(sum, total);\n    }\n\n    #[test]\n    fn test_bucket_write_then_read_mt() {\n        let bucket = AtomicBucket::new();\n\n        let snapshot = bucket.data();\n        assert_eq!(snapshot.len(), 0);\n\n        let res = scope(|s| {\n            let t1 = s.spawn(|_| {\n                let mut i = 0;\n                let mut total = 0;\n                while i < BLOCK_SIZE as u64 * 100_000 {\n                    bucket.push(i);\n\n                    total += i;\n                    i += 1;\n                }\n                total\n            });\n\n            let t2 = s.spawn(|_| {\n                let mut i = 0;\n                let mut total = 0;\n                while i < BLOCK_SIZE as u64 * 100_000 {\n                    bucket.push(i);\n\n                    total += i;\n                    i += 1;\n                }\n                total\n            });\n\n            let t1_total = t1.join().unwrap();\n            let t2_total = t2.join().unwrap();\n\n            t1_total + t2_total\n        });\n\n        let total = res.unwrap();\n\n        let snapshot = bucket.data();\n        assert_eq!(snapshot.len(), BLOCK_SIZE * 200_000);\n\n        let sum = snapshot.iter().sum::<u64>();\n        assert_eq!(sum, total);\n    }\n\n    #[test]\n    fn test_clear_and_clear_with() {\n        let bucket = AtomicBucket::new();\n\n        let snapshot = bucket.data();\n        assert_eq!(snapshot.len(), 0);\n\n        let mut i = 0;\n        let mut total_pushed = 0;\n        while i < BLOCK_SIZE * 4 {\n            bucket.push(i);\n\n            total_pushed += i;\n            i += 1;\n        }\n\n        let snapshot = bucket.data();\n        assert_eq!(snapshot.len(), i);\n\n        let mut total_accumulated = 0;\n        bucket.clear_with(|xs| total_accumulated += xs.iter().sum::<usize>());\n        assert_eq!(total_pushed, total_accumulated);\n\n        let snapshot = bucket.data();\n        assert_eq!(snapshot.len(), 0);\n    }\n\n    #[test]\n    fn test_bucket_len_and_next_len() {\n        let bucket = AtomicBucket::new();\n        assert!(bucket.is_empty());\n\n        let snapshot = bucket.data();\n        assert_eq!(snapshot.len(), 0);\n\n        // Just making sure that `is_empty` holds as we go from\n        // the first block, to the second block, to exercise the\n        // `Block::next_len` codepath.\n        let mut i = 0;\n        while i < BLOCK_SIZE * 2 {\n            bucket.push(i);\n            assert!(!bucket.is_empty());\n            i += 1;\n        }\n    }\n}\n"
  },
  {
    "project": "rust-libp2p",
    "target": 1,
    "commit_id": "6400719ae9585f7a3620044b8fb3f86d35ef8b22",
    "func": "// Copyright 2019 Parity Technologies (UK) Ltd.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the \"Software\"),\n// to deal in the Software without restriction, including without limitation\n// the rights to use, copy, modify, merge, publish, distribute, sublicense,\n// and/or sell copies of the Software, and to permit persons to whom the\n// Software is furnished to do so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in\n// all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n// FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n// DEALINGS IN THE SOFTWARE.\n\nuse futures::{prelude::*, ready};\nuse libp2p_core::{InboundUpgrade, OutboundUpgrade, UpgradeInfo};\nuse std::{io, iter, pin::Pin, task::Context, task::Poll};\n\n#[derive(Debug, Copy, Clone)]\npub struct DeflateConfig {\n    compression: flate2::Compression,\n}\n\nimpl Default for DeflateConfig {\n    fn default() -> Self {\n        DeflateConfig {\n            compression: flate2::Compression::fast(),\n        }\n    }\n}\n\nimpl UpgradeInfo for DeflateConfig {\n    type Info = &'static [u8];\n    type InfoIter = iter::Once<Self::Info>;\n\n    fn protocol_info(&self) -> Self::InfoIter {\n        iter::once(b\"/deflate/1.0.0\")\n    }\n}\n\nimpl<C> InboundUpgrade<C> for DeflateConfig\nwhere\n    C: AsyncRead + AsyncWrite,\n{\n    type Output = DeflateOutput<C>;\n    type Error = io::Error;\n    type Future = future::Ready<Result<Self::Output, Self::Error>>;\n\n    fn upgrade_inbound(self, r: C, _: Self::Info) -> Self::Future {\n        future::ok(DeflateOutput::new(r, self.compression))\n    }\n}\n\nimpl<C> OutboundUpgrade<C> for DeflateConfig\nwhere\n    C: AsyncRead + AsyncWrite,\n{\n    type Output = DeflateOutput<C>;\n    type Error = io::Error;\n    type Future = future::Ready<Result<Self::Output, Self::Error>>;\n\n    fn upgrade_outbound(self, w: C, _: Self::Info) -> Self::Future {\n        future::ok(DeflateOutput::new(w, self.compression))\n    }\n}\n\n/// Decodes and encodes traffic using DEFLATE.\n#[derive(Debug)]\npub struct DeflateOutput<S> {\n    /// Inner stream where we read compressed data from and write compressed data to.\n    inner: S,\n    /// Internal object used to hold the state of the compression.\n    compress: flate2::Compress,\n    /// Internal object used to hold the state of the decompression.\n    decompress: flate2::Decompress,\n    /// Temporary buffer between `compress` and `inner`. Stores compressed bytes that need to be\n    /// sent out once `inner` is ready to accept more.\n    write_out: Vec<u8>,\n    /// Temporary buffer between `decompress` and `inner`. Stores compressed bytes that need to be\n    /// given to `decompress`.\n    read_interm: Vec<u8>,\n    /// When we read from `inner` and `Ok(0)` is returned, we set this to `true` so that we don't\n    /// read from it again.\n    inner_read_eof: bool,\n}\n\nimpl<S> DeflateOutput<S> {\n    fn new(inner: S, compression: flate2::Compression) -> Self {\n        DeflateOutput {\n            inner,\n            compress: flate2::Compress::new(compression, false),\n            decompress: flate2::Decompress::new(false),\n            write_out: Vec::with_capacity(256),\n            read_interm: Vec::with_capacity(256),\n            inner_read_eof: false,\n        }\n    }\n\n    /// Tries to write the content of `self.write_out` to `self.inner`.\n    /// Returns `Ready(Ok(()))` if `self.write_out` is empty.\n    fn flush_write_out(&mut self, cx: &mut Context<'_>) -> Poll<Result<(), io::Error>>\n        where S: AsyncWrite + Unpin\n    {\n        loop {\n            if self.write_out.is_empty() {\n                return Poll::Ready(Ok(()))\n            }\n\n            match AsyncWrite::poll_write(Pin::new(&mut self.inner), cx, &self.write_out) {\n                Poll::Ready(Ok(0)) => return Poll::Ready(Err(io::ErrorKind::WriteZero.into())),\n                Poll::Ready(Ok(n)) => self.write_out = self.write_out.split_off(n),\n                Poll::Ready(Err(err)) => return Poll::Ready(Err(err)),\n                Poll::Pending => return Poll::Pending,\n            };\n        }\n    }\n}\n\nimpl<S> AsyncRead for DeflateOutput<S>\n    where S: AsyncRead + Unpin\n{\n    fn poll_read(mut self: Pin<&mut Self>, cx: &mut Context<'_>, buf: &mut [u8]) -> Poll<Result<usize, io::Error>> {\n        // We use a `this` variable because the compiler doesn't allow multiple mutable borrows\n        // across a `Deref`.\n        let this = &mut *self;\n\n        loop {\n            // Read from `self.inner` into `self.read_interm` if necessary.\n            if this.read_interm.is_empty() && !this.inner_read_eof {\n                unsafe {\n                    this.read_interm.reserve(256);\n                    this.read_interm.set_len(this.read_interm.capacity());\n                }\n\n                match AsyncRead::poll_read(Pin::new(&mut this.inner), cx, &mut this.read_interm) {\n                    Poll::Ready(Ok(0)) => {\n                        this.inner_read_eof = true;\n                        this.read_interm.clear();\n                    }\n                    Poll::Ready(Ok(n)) => {\n                        this.read_interm.truncate(n)\n                    },\n                    Poll::Ready(Err(err)) => {\n                        this.read_interm.clear();\n                        return Poll::Ready(Err(err))\n                    },\n                    Poll::Pending => {\n                        this.read_interm.clear();\n                        return Poll::Pending\n                    },\n                }\n            }\n            debug_assert!(!this.read_interm.is_empty() || this.inner_read_eof);\n\n            let before_out = this.decompress.total_out();\n            let before_in = this.decompress.total_in();\n            let ret = this.decompress.decompress(&this.read_interm, buf, if this.inner_read_eof { flate2::FlushDecompress::Finish } else { flate2::FlushDecompress::None })?;\n\n            // Remove from `self.read_interm` the bytes consumed by the decompressor.\n            let consumed = (this.decompress.total_in() - before_in) as usize;\n            this.read_interm = this.read_interm.split_off(consumed);\n\n            let read = (this.decompress.total_out() - before_out) as usize;\n            if read != 0 || ret == flate2::Status::StreamEnd {\n                return Poll::Ready(Ok(read))\n            }\n        }\n    }\n}\n\nimpl<S> AsyncWrite for DeflateOutput<S>\n    where S: AsyncWrite + Unpin\n{\n    fn poll_write(mut self: Pin<&mut Self>, cx: &mut Context<'_>, buf: &[u8])\n        -> Poll<Result<usize, io::Error>>\n    {\n        // We use a `this` variable because the compiler doesn't allow multiple mutable borrows\n        // across a `Deref`.\n        let this = &mut *self;\n\n        // We don't want to accumulate too much data in `self.write_out`, so we only proceed if it\n        // is empty.\n        ready!(this.flush_write_out(cx))?;\n\n        // We special-case this, otherwise an empty buffer would make the loop below infinite.\n        if buf.is_empty() {\n            return Poll::Ready(Ok(0));\n        }\n\n        // Unfortunately, the compressor might be in a \"flushing mode\", not accepting any input\n        // data. We don't want to return `Ok(0)` in that situation, as that would be wrong.\n        // Instead, we invoke the compressor in a loop until it accepts some of our data.\n        loop {\n            let before_in = this.compress.total_in();\n            this.write_out.reserve(256);  // compress_vec uses the Vec's capacity\n            let ret = this.compress.compress_vec(buf, &mut this.write_out, flate2::FlushCompress::None)?;\n            let written = (this.compress.total_in() - before_in) as usize;\n\n            if written != 0 || ret == flate2::Status::StreamEnd {\n                return Poll::Ready(Ok(written));\n            }\n        }\n    }\n\n    fn poll_flush(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Result<(), io::Error>> {\n        // We use a `this` variable because the compiler doesn't allow multiple mutable borrows\n        // across a `Deref`.\n        let this = &mut *self;\n\n        ready!(this.flush_write_out(cx))?;\n        this.compress.compress_vec(&[], &mut this.write_out, flate2::FlushCompress::Sync)?;\n\n        loop {\n            ready!(this.flush_write_out(cx))?;\n\n            debug_assert!(this.write_out.is_empty());\n            // We ask the compressor to flush everything into `self.write_out`.\n            this.write_out.reserve(256);  // compress_vec uses the Vec's capacity\n            this.compress.compress_vec(&[], &mut this.write_out, flate2::FlushCompress::None)?;\n            if this.write_out.is_empty() {\n                break;\n            }\n        }\n\n        AsyncWrite::poll_flush(Pin::new(&mut this.inner), cx)\n    }\n\n    fn poll_close(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Result<(), io::Error>> {\n        // We use a `this` variable because the compiler doesn't allow multiple mutable borrows\n        // across a `Deref`.\n        let this = &mut *self;\n\n        loop {\n            ready!(this.flush_write_out(cx))?;\n\n            // We ask the compressor to flush everything into `self.write_out`.\n            debug_assert!(this.write_out.is_empty());\n            this.write_out.reserve(256);  // compress_vec uses the Vec's capacity\n            this.compress.compress_vec(&[], &mut this.write_out, flate2::FlushCompress::Finish)?;\n            if this.write_out.is_empty() {\n                break;\n            }\n        }\n\n        AsyncWrite::poll_close(Pin::new(&mut this.inner), cx)\n    }\n}\n"
  },
  {
    "project": "ruspiro-singleton",
    "target": 1,
    "commit_id": "0565f8ef459bd336eda8a6a63d1d50cdb581c2b3",
    "func": "/***********************************************************************************************************************\n * Copyright (c) 2019 by the authors\n *\n * Author: Andr\u00e9 Borrmann\n * License: MIT / Apache License 2.0\n **********************************************************************************************************************/\n#![doc(html_root_url = \"https://docs.rs/ruspiro-singleton/||VERSION||\")]\n#![no_std]\n#![feature(const_fn)]\n\n//! # Singleton pattern implementation\n//!\n//! Provide a cross core synchronisation safe singleton implementation pattern. The `Singleton` is intended to be used\n//! to declare crate level static variables that require safe access accross cores. This is helpful where the data\n//! structure used within the `Singleton` represents a peripheral where the crate shall only hand out a single instance\n//! to safely represent to unique existance of the peripheral.\n//!\n//! # HINT\n//! Safe lazy initialization is ensured using atomics. On the Raspberry Pi atmomic operations require the *MMU* to be \n//! configured and active. Otherwise the executing CPU core will hang when trying to execute the atomic operation.\n//!\n//! # Example\n//! ```no_run\n//! # use ruspiro_singleton::*;\n//! // define the static variable with an inizialization closure\n//! static FOO:Singleton<u32> = Singleton::new(20);\n//!\n//! // define the static variable with an inizialization closure\n//! static DEMO:Singleton<Box<Demo>> = Singleton::lazy(&|| {\n//!     Box::new(\n//!         Demo::new()\n//!     )\n//! });\n//!\n//! // define the type to be accessible as singleton\n//! struct Demo {\n//!     pub count: u32,\n//! }\n//!\n//! // implement the type that should provided as singlton\n//! impl Demo {\n//!     pub const fn new() -> Self {\n//!         Demo {\n//!             count: 0,\n//!         }\n//!     }\n//! }\n//!\n//! fn main() {\n//!     // safely use the singleton inside the closure passed to [with_mut] to update it's contents\n//!     DEMO.with_mut(|d| {\n//!         d.count += 10;\n//!     });\n//!\n//!     // safely use the singleton inside the closure passed to [with_ref] if read-only access is required\n//!     DEMO.with_mut(|d| {\n//!         println!(\"Value: {}\", d.count);\n//!     });\n//!\n//!     // you may also return a value from the singleton to work with it after the safe singleton access\n//!     let val = DEMO.with_ref(|d| {\n//!         if d.count != 0 {\n//!             true\n//!         } else {\n//!             false\n//!         }\n//!     });\n//! }\n//! ```\n\nmod lazy;\n\nuse lazy::LazyValue;\nuse ruspiro_lock::RWLock;\n\n/// The Singleton wrapper stores any type\npub struct Singleton<T: 'static> {\n    /// the inner value wrapping the contained data for safe read/write access\n    inner: RWLock<LazyValue<T>>,\n}\n\n// The Singleton need to implement Send & Sync to ensure cross core compile check mechanics\n// this is safe as the inner RWLock ensures cross core safety\nunsafe impl<T> Sync for Singleton<T> {}\nunsafe impl<T> Send for Singleton<T> {}\n\nimpl<T: 'static> Singleton<T> {\n    /// Create a new [Singleton] instance to be used in a static variable. Only ``const fn`` constructors are allowed\n    /// here.\n    /// # Example\n    /// ```no_run\n    /// # use ruspiro_singleton::*;\n    /// static FOO: Singleton<u32> = Singleton::new(20);\n    /// # fn main() {}\n    /// ```\n    pub const fn new(value: T) -> Self {\n        Singleton {\n            inner: RWLock::new(LazyValue::with_value(value)),\n        }\n    }\n\n    /// Create a new [Singleton] instance passing a closure that will be evaluated at first access to the contents of\n    /// the singleton that will provide its value\n    /// # Example\n    /// ```no_run\n    /// # use ruspiro_singleton::*;\n    /// static FOO: Singleton<String> = Singleton::lazy(&|| String::from(\"foo\"));\n    /// # fn main() {}\n    /// ```\n    pub const fn lazy<F>(init: &'static F) -> Self\n    where\n        F: Fn() -> T,\n    {\n        Self {\n            inner: RWLock::new(LazyValue::with_init(init)),\n        }\n    }\n\n    /// Take the stored singleton for whatever operation and prevent usage by other cores\n    /// Safe access to the singleton mutable instance is guarantied inside the given closure.\n    ///\n    pub fn with_mut<F, R>(&self, f: F) -> R\n    where\n        F: FnOnce(&mut T) -> R,\n    {\n        let inner = self.inner.lock();\n        // use write lock to mutably access the inner value of the singleton. As long\n        // as the write lock exists no other write or read lock is possible\n        let r = f(inner.get_mut());\n\n        // explicitly release the lock befor providing the result of the closure to the caller\n        drop(inner);\n\n        r\n    }\n\n    /// Immutable access to a singleton for a specific operation.\n    /// This access does not enforce any lock nor guarantees safe atomic access to the instance. However, it is usefull\n    /// in read-only access scenarios like inside interrupt handlers.\n    ///\n    pub fn with_ref<F, R>(&self, f: F) -> R\n    where\n        F: FnOnce(&T) -> R,\n    {\n        let inner = self.inner.read();\n        // multiple read locks are possible when accessing the inner data of the singleton\n        // all read locks are required to be release before the next write lock could happen\n        let r = f(inner.get());\n\n        // explicitly release the lock befor providing the result of the closure to the caller\n        drop(inner);\n\n        r\n    }\n}\n"
  },
  {
    "project": "tokio",
    "target": 1,
    "commit_id": "844dc9be2f95e2403dc50562333090af7d2d20a5",
    "func": "#![cfg_attr(not(feature = \"sync\"), allow(dead_code, unreachable_pub))]\n\n//! A one-shot channel is used for sending a single message between\n//! asynchronous tasks. The [`channel`] function is used to create a\n//! [`Sender`] and [`Receiver`] handle pair that form the channel.\n//!\n//! The `Sender` handle is used by the producer to send the value.\n//! The `Receiver` handle is used by the consumer to receive the value.\n//!\n//! Each handle can be used on separate tasks.\n//!\n//! # Examples\n//!\n//! ```\n//! use tokio::sync::oneshot;\n//!\n//! #[tokio::main]\n//! async fn main() {\n//!     let (tx, rx) = oneshot::channel();\n//!\n//!     tokio::spawn(async move {\n//!         if let Err(_) = tx.send(3) {\n//!             println!(\"the receiver dropped\");\n//!         }\n//!     });\n//!\n//!     match rx.await {\n//!         Ok(v) => println!(\"got = {:?}\", v),\n//!         Err(_) => println!(\"the sender dropped\"),\n//!     }\n//! }\n//! ```\n//!\n//! If the sender is dropped without sending, the receiver will fail with\n//! [`error::RecvError`]:\n//!\n//! ```\n//! use tokio::sync::oneshot;\n//!\n//! #[tokio::main]\n//! async fn main() {\n//!     let (tx, rx) = oneshot::channel::<u32>();\n//!\n//!     tokio::spawn(async move {\n//!         drop(tx);\n//!     });\n//!\n//!     match rx.await {\n//!         Ok(_) => panic!(\"This doesn't happen\"),\n//!         Err(_) => println!(\"the sender dropped\"),\n//!     }\n//! }\n//! ```\n//!\n//! To use a oneshot channel in a `tokio::select!` loop, add `&mut` in front of\n//! the channel.\n//!\n//! ```\n//! use tokio::sync::oneshot;\n//! use tokio::time::{interval, sleep, Duration};\n//!\n//! #[tokio::main]\n//! # async fn _doc() {}\n//! # #[tokio::main(flavor = \"current_thread\", start_paused = true)]\n//! async fn main() {\n//!     let (send, mut recv) = oneshot::channel();\n//!     let mut interval = interval(Duration::from_millis(100));\n//!\n//!     # let handle =\n//!     tokio::spawn(async move {\n//!         sleep(Duration::from_secs(1)).await;\n//!         send.send(\"shut down\").unwrap();\n//!     });\n//!\n//!     loop {\n//!         tokio::select! {\n//!             _ = interval.tick() => println!(\"Another 100ms\"),\n//!             msg = &mut recv => {\n//!                 println!(\"Got message: {}\", msg.unwrap());\n//!                 break;\n//!             }\n//!         }\n//!     }\n//!     # handle.await.unwrap();\n//! }\n//! ```\n//!\n//! To use a `Sender` from a destructor, put it in an [`Option`] and call\n//! [`Option::take`].\n//!\n//! ```\n//! use tokio::sync::oneshot;\n//!\n//! struct SendOnDrop {\n//!     sender: Option<oneshot::Sender<&'static str>>,\n//! }\n//! impl Drop for SendOnDrop {\n//!     fn drop(&mut self) {\n//!         if let Some(sender) = self.sender.take() {\n//!             // Using `let _ =` to ignore send errors.\n//!             let _ = sender.send(\"I got dropped!\");\n//!         }\n//!     }\n//! }\n//!\n//! #[tokio::main]\n//! # async fn _doc() {}\n//! # #[tokio::main(flavor = \"current_thread\")]\n//! async fn main() {\n//!     let (send, recv) = oneshot::channel();\n//!\n//!     let send_on_drop = SendOnDrop { sender: Some(send) };\n//!     drop(send_on_drop);\n//!\n//!     assert_eq!(recv.await, Ok(\"I got dropped!\"));\n//! }\n//! ```\n\nuse crate::loom::cell::UnsafeCell;\nuse crate::loom::sync::atomic::AtomicUsize;\nuse crate::loom::sync::Arc;\n\nuse std::fmt;\nuse std::future::Future;\nuse std::mem::MaybeUninit;\nuse std::pin::Pin;\nuse std::sync::atomic::Ordering::{self, AcqRel, Acquire};\nuse std::task::Poll::{Pending, Ready};\nuse std::task::{Context, Poll, Waker};\n\n/// Sends a value to the associated [`Receiver`].\n///\n/// A pair of both a [`Sender`] and a [`Receiver`]  are created by the\n/// [`channel`](fn@channel) function.\n///\n/// # Examples\n///\n/// ```\n/// use tokio::sync::oneshot;\n///\n/// #[tokio::main]\n/// async fn main() {\n///     let (tx, rx) = oneshot::channel();\n///\n///     tokio::spawn(async move {\n///         if let Err(_) = tx.send(3) {\n///             println!(\"the receiver dropped\");\n///         }\n///     });\n///\n///     match rx.await {\n///         Ok(v) => println!(\"got = {:?}\", v),\n///         Err(_) => println!(\"the sender dropped\"),\n///     }\n/// }\n/// ```\n///\n/// If the sender is dropped without sending, the receiver will fail with\n/// [`error::RecvError`]:\n///\n/// ```\n/// use tokio::sync::oneshot;\n///\n/// #[tokio::main]\n/// async fn main() {\n///     let (tx, rx) = oneshot::channel::<u32>();\n///\n///     tokio::spawn(async move {\n///         drop(tx);\n///     });\n///\n///     match rx.await {\n///         Ok(_) => panic!(\"This doesn't happen\"),\n///         Err(_) => println!(\"the sender dropped\"),\n///     }\n/// }\n/// ```\n///\n/// To use a `Sender` from a destructor, put it in an [`Option`] and call\n/// [`Option::take`].\n///\n/// ```\n/// use tokio::sync::oneshot;\n///\n/// struct SendOnDrop {\n///     sender: Option<oneshot::Sender<&'static str>>,\n/// }\n/// impl Drop for SendOnDrop {\n///     fn drop(&mut self) {\n///         if let Some(sender) = self.sender.take() {\n///             // Using `let _ =` to ignore send errors.\n///             let _ = sender.send(\"I got dropped!\");\n///         }\n///     }\n/// }\n///\n/// #[tokio::main]\n/// # async fn _doc() {}\n/// # #[tokio::main(flavor = \"current_thread\")]\n/// async fn main() {\n///     let (send, recv) = oneshot::channel();\n///\n///     let send_on_drop = SendOnDrop { sender: Some(send) };\n///     drop(send_on_drop);\n///\n///     assert_eq!(recv.await, Ok(\"I got dropped!\"));\n/// }\n/// ```\n///\n/// [`Option`]: std::option::Option\n/// [`Option::take`]: std::option::Option::take\n#[derive(Debug)]\npub struct Sender<T> {\n    inner: Option<Arc<Inner<T>>>,\n}\n\n/// Receives a value from the associated [`Sender`].\n///\n/// A pair of both a [`Sender`] and a [`Receiver`]  are created by the\n/// [`channel`](fn@channel) function.\n///\n/// This channel has no `recv` method because the receiver itself implements the\n/// [`Future`] trait. To receive a value, `.await` the `Receiver` object directly.\n///\n/// [`Future`]: trait@std::future::Future\n///\n/// # Examples\n///\n/// ```\n/// use tokio::sync::oneshot;\n///\n/// #[tokio::main]\n/// async fn main() {\n///     let (tx, rx) = oneshot::channel();\n///\n///     tokio::spawn(async move {\n///         if let Err(_) = tx.send(3) {\n///             println!(\"the receiver dropped\");\n///         }\n///     });\n///\n///     match rx.await {\n///         Ok(v) => println!(\"got = {:?}\", v),\n///         Err(_) => println!(\"the sender dropped\"),\n///     }\n/// }\n/// ```\n///\n/// If the sender is dropped without sending, the receiver will fail with\n/// [`error::RecvError`]:\n///\n/// ```\n/// use tokio::sync::oneshot;\n///\n/// #[tokio::main]\n/// async fn main() {\n///     let (tx, rx) = oneshot::channel::<u32>();\n///\n///     tokio::spawn(async move {\n///         drop(tx);\n///     });\n///\n///     match rx.await {\n///         Ok(_) => panic!(\"This doesn't happen\"),\n///         Err(_) => println!(\"the sender dropped\"),\n///     }\n/// }\n/// ```\n///\n/// To use a `Receiver` in a `tokio::select!` loop, add `&mut` in front of the\n/// channel.\n///\n/// ```\n/// use tokio::sync::oneshot;\n/// use tokio::time::{interval, sleep, Duration};\n///\n/// #[tokio::main]\n/// # async fn _doc() {}\n/// # #[tokio::main(flavor = \"current_thread\", start_paused = true)]\n/// async fn main() {\n///     let (send, mut recv) = oneshot::channel();\n///     let mut interval = interval(Duration::from_millis(100));\n///\n///     # let handle =\n///     tokio::spawn(async move {\n///         sleep(Duration::from_secs(1)).await;\n///         send.send(\"shut down\").unwrap();\n///     });\n///\n///     loop {\n///         tokio::select! {\n///             _ = interval.tick() => println!(\"Another 100ms\"),\n///             msg = &mut recv => {\n///                 println!(\"Got message: {}\", msg.unwrap());\n///                 break;\n///             }\n///         }\n///     }\n///     # handle.await.unwrap();\n/// }\n/// ```\n#[derive(Debug)]\npub struct Receiver<T> {\n    inner: Option<Arc<Inner<T>>>,\n}\n\npub mod error {\n    //! Oneshot error types.\n\n    use std::fmt;\n\n    /// Error returned by the `Future` implementation for `Receiver`.\n    #[derive(Debug, Eq, PartialEq)]\n    pub struct RecvError(pub(super) ());\n\n    /// Error returned by the `try_recv` function on `Receiver`.\n    #[derive(Debug, Eq, PartialEq)]\n    pub enum TryRecvError {\n        /// The send half of the channel has not yet sent a value.\n        Empty,\n\n        /// The send half of the channel was dropped without sending a value.\n        Closed,\n    }\n\n    // ===== impl RecvError =====\n\n    impl fmt::Display for RecvError {\n        fn fmt(&self, fmt: &mut fmt::Formatter<'_>) -> fmt::Result {\n            write!(fmt, \"channel closed\")\n        }\n    }\n\n    impl std::error::Error for RecvError {}\n\n    // ===== impl TryRecvError =====\n\n    impl fmt::Display for TryRecvError {\n        fn fmt(&self, fmt: &mut fmt::Formatter<'_>) -> fmt::Result {\n            match self {\n                TryRecvError::Empty => write!(fmt, \"channel empty\"),\n                TryRecvError::Closed => write!(fmt, \"channel closed\"),\n            }\n        }\n    }\n\n    impl std::error::Error for TryRecvError {}\n}\n\nuse self::error::*;\n\nstruct Inner<T> {\n    /// Manages the state of the inner cell.\n    state: AtomicUsize,\n\n    /// The value. This is set by `Sender` and read by `Receiver`. The state of\n    /// the cell is tracked by `state`.\n    value: UnsafeCell<Option<T>>,\n\n    /// The task to notify when the receiver drops without consuming the value.\n    tx_task: Task,\n\n    /// The task to notify when the value is sent.\n    rx_task: Task,\n}\n\nstruct Task(UnsafeCell<MaybeUninit<Waker>>);\n\nimpl Task {\n    unsafe fn will_wake(&self, cx: &mut Context<'_>) -> bool {\n        self.with_task(|w| w.will_wake(cx.waker()))\n    }\n\n    unsafe fn with_task<F, R>(&self, f: F) -> R\n    where\n        F: FnOnce(&Waker) -> R,\n    {\n        self.0.with(|ptr| {\n            let waker: *const Waker = (&*ptr).as_ptr();\n            f(&*waker)\n        })\n    }\n\n    unsafe fn drop_task(&self) {\n        self.0.with_mut(|ptr| {\n            let ptr: *mut Waker = (&mut *ptr).as_mut_ptr();\n            ptr.drop_in_place();\n        });\n    }\n\n    unsafe fn set_task(&self, cx: &mut Context<'_>) {\n        self.0.with_mut(|ptr| {\n            let ptr: *mut Waker = (&mut *ptr).as_mut_ptr();\n            ptr.write(cx.waker().clone());\n        });\n    }\n}\n\n#[derive(Clone, Copy)]\nstruct State(usize);\n\n/// Creates a new one-shot channel for sending single values across asynchronous\n/// tasks.\n///\n/// The function returns separate \"send\" and \"receive\" handles. The `Sender`\n/// handle is used by the producer to send the value. The `Receiver` handle is\n/// used by the consumer to receive the value.\n///\n/// Each handle can be used on separate tasks.\n///\n/// # Examples\n///\n/// ```\n/// use tokio::sync::oneshot;\n///\n/// #[tokio::main]\n/// async fn main() {\n///     let (tx, rx) = oneshot::channel();\n///\n///     tokio::spawn(async move {\n///         if let Err(_) = tx.send(3) {\n///             println!(\"the receiver dropped\");\n///         }\n///     });\n///\n///     match rx.await {\n///         Ok(v) => println!(\"got = {:?}\", v),\n///         Err(_) => println!(\"the sender dropped\"),\n///     }\n/// }\n/// ```\npub fn channel<T>() -> (Sender<T>, Receiver<T>) {\n    let inner = Arc::new(Inner {\n        state: AtomicUsize::new(State::new().as_usize()),\n        value: UnsafeCell::new(None),\n        tx_task: Task(UnsafeCell::new(MaybeUninit::uninit())),\n        rx_task: Task(UnsafeCell::new(MaybeUninit::uninit())),\n    });\n\n    let tx = Sender {\n        inner: Some(inner.clone()),\n    };\n    let rx = Receiver { inner: Some(inner) };\n\n    (tx, rx)\n}\n\nimpl<T> Sender<T> {\n    /// Attempts to send a value on this channel, returning it back if it could\n    /// not be sent.\n    ///\n    /// This method consumes `self` as only one value may ever be sent on a oneshot\n    /// channel. It is not marked async because sending a message to an oneshot\n    /// channel never requires any form of waiting.  Because of this, the `send`\n    /// method can be used in both synchronous and asynchronous code without\n    /// problems.\n    ///\n    /// A successful send occurs when it is determined that the other end of the\n    /// channel has not hung up already. An unsuccessful send would be one where\n    /// the corresponding receiver has already been deallocated. Note that a\n    /// return value of `Err` means that the data will never be received, but\n    /// a return value of `Ok` does *not* mean that the data will be received.\n    /// It is possible for the corresponding receiver to hang up immediately\n    /// after this function returns `Ok`.\n    ///\n    /// # Examples\n    ///\n    /// Send a value to another task\n    ///\n    /// ```\n    /// use tokio::sync::oneshot;\n    ///\n    /// #[tokio::main]\n    /// async fn main() {\n    ///     let (tx, rx) = oneshot::channel();\n    ///\n    ///     tokio::spawn(async move {\n    ///         if let Err(_) = tx.send(3) {\n    ///             println!(\"the receiver dropped\");\n    ///         }\n    ///     });\n    ///\n    ///     match rx.await {\n    ///         Ok(v) => println!(\"got = {:?}\", v),\n    ///         Err(_) => println!(\"the sender dropped\"),\n    ///     }\n    /// }\n    /// ```\n    pub fn send(mut self, t: T) -> Result<(), T> {\n        let inner = self.inner.take().unwrap();\n\n        inner.value.with_mut(|ptr| unsafe {\n            *ptr = Some(t);\n        });\n\n        if !inner.complete() {\n            unsafe {\n                return Err(inner.consume_value().unwrap());\n            }\n        }\n\n        Ok(())\n    }\n\n    /// Waits for the associated [`Receiver`] handle to close.\n    ///\n    /// A [`Receiver`] is closed by either calling [`close`] explicitly or the\n    /// [`Receiver`] value is dropped.\n    ///\n    /// This function is useful when paired with `select!` to abort a\n    /// computation when the receiver is no longer interested in the result.\n    ///\n    /// # Return\n    ///\n    /// Returns a `Future` which must be awaited on.\n    ///\n    /// [`Receiver`]: Receiver\n    /// [`close`]: Receiver::close\n    ///\n    /// # Examples\n    ///\n    /// Basic usage\n    ///\n    /// ```\n    /// use tokio::sync::oneshot;\n    ///\n    /// #[tokio::main]\n    /// async fn main() {\n    ///     let (mut tx, rx) = oneshot::channel::<()>();\n    ///\n    ///     tokio::spawn(async move {\n    ///         drop(rx);\n    ///     });\n    ///\n    ///     tx.closed().await;\n    ///     println!(\"the receiver dropped\");\n    /// }\n    /// ```\n    ///\n    /// Paired with select\n    ///\n    /// ```\n    /// use tokio::sync::oneshot;\n    /// use tokio::time::{self, Duration};\n    ///\n    /// async fn compute() -> String {\n    ///     // Complex computation returning a `String`\n    /// # \"hello\".to_string()\n    /// }\n    ///\n    /// #[tokio::main]\n    /// async fn main() {\n    ///     let (mut tx, rx) = oneshot::channel();\n    ///\n    ///     tokio::spawn(async move {\n    ///         tokio::select! {\n    ///             _ = tx.closed() => {\n    ///                 // The receiver dropped, no need to do any further work\n    ///             }\n    ///             value = compute() => {\n    ///                 // The send can fail if the channel was closed at the exact same\n    ///                 // time as when compute() finished, so just ignore the failure.\n    ///                 let _ = tx.send(value);\n    ///             }\n    ///         }\n    ///     });\n    ///\n    ///     // Wait for up to 10 seconds\n    ///     let _ = time::timeout(Duration::from_secs(10), rx).await;\n    /// }\n    /// ```\n    pub async fn closed(&mut self) {\n        use crate::future::poll_fn;\n\n        poll_fn(|cx| self.poll_closed(cx)).await\n    }\n\n    /// Returns `true` if the associated [`Receiver`] handle has been dropped.\n    ///\n    /// A [`Receiver`] is closed by either calling [`close`] explicitly or the\n    /// [`Receiver`] value is dropped.\n    ///\n    /// If `true` is returned, a call to `send` will always result in an error.\n    ///\n    /// [`Receiver`]: Receiver\n    /// [`close`]: Receiver::close\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use tokio::sync::oneshot;\n    ///\n    /// #[tokio::main]\n    /// async fn main() {\n    ///     let (tx, rx) = oneshot::channel();\n    ///\n    ///     assert!(!tx.is_closed());\n    ///\n    ///     drop(rx);\n    ///\n    ///     assert!(tx.is_closed());\n    ///     assert!(tx.send(\"never received\").is_err());\n    /// }\n    /// ```\n    pub fn is_closed(&self) -> bool {\n        let inner = self.inner.as_ref().unwrap();\n\n        let state = State::load(&inner.state, Acquire);\n        state.is_closed()\n    }\n\n    /// Checks whether the oneshot channel has been closed, and if not, schedules the\n    /// `Waker` in the provided `Context` to receive a notification when the channel is\n    /// closed.\n    ///\n    /// A [`Receiver`] is closed by either calling [`close`] explicitly, or when the\n    /// [`Receiver`] value is dropped.\n    ///\n    /// Note that on multiple calls to poll, only the `Waker` from the `Context` passed\n    /// to the most recent call will be scheduled to receive a wakeup.\n    ///\n    /// [`Receiver`]: struct@crate::sync::oneshot::Receiver\n    /// [`close`]: fn@crate::sync::oneshot::Receiver::close\n    ///\n    /// # Return value\n    ///\n    /// This function returns:\n    ///\n    ///  * `Poll::Pending` if the channel is still open.\n    ///  * `Poll::Ready(())` if the channel is closed.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use tokio::sync::oneshot;\n    ///\n    /// use futures::future::poll_fn;\n    ///\n    /// #[tokio::main]\n    /// async fn main() {\n    ///     let (mut tx, mut rx) = oneshot::channel::<()>();\n    ///\n    ///     tokio::spawn(async move {\n    ///         rx.close();\n    ///     });\n    ///\n    ///     poll_fn(|cx| tx.poll_closed(cx)).await;\n    ///\n    ///     println!(\"the receiver dropped\");\n    /// }\n    /// ```\n    pub fn poll_closed(&mut self, cx: &mut Context<'_>) -> Poll<()> {\n        // Keep track of task budget\n        let coop = ready!(crate::coop::poll_proceed(cx));\n\n        let inner = self.inner.as_ref().unwrap();\n\n        let mut state = State::load(&inner.state, Acquire);\n\n        if state.is_closed() {\n            coop.made_progress();\n            return Poll::Ready(());\n        }\n\n        if state.is_tx_task_set() {\n            let will_notify = unsafe { inner.tx_task.will_wake(cx) };\n\n            if !will_notify {\n                state = State::unset_tx_task(&inner.state);\n\n                if state.is_closed() {\n                    // Set the flag again so that the waker is released in drop\n                    State::set_tx_task(&inner.state);\n                    coop.made_progress();\n                    return Ready(());\n                } else {\n                    unsafe { inner.tx_task.drop_task() };\n                }\n            }\n        }\n\n        if !state.is_tx_task_set() {\n            // Attempt to set the task\n            unsafe {\n                inner.tx_task.set_task(cx);\n            }\n\n            // Update the state\n            state = State::set_tx_task(&inner.state);\n\n            if state.is_closed() {\n                coop.made_progress();\n                return Ready(());\n            }\n        }\n\n        Pending\n    }\n}\n\nimpl<T> Drop for Sender<T> {\n    fn drop(&mut self) {\n        if let Some(inner) = self.inner.as_ref() {\n            inner.complete();\n        }\n    }\n}\n\nimpl<T> Receiver<T> {\n    /// Prevents the associated [`Sender`] handle from sending a value.\n    ///\n    /// Any `send` operation which happens after calling `close` is guaranteed\n    /// to fail. After calling `close`, [`try_recv`] should be called to\n    /// receive a value if one was sent **before** the call to `close`\n    /// completed.\n    ///\n    /// This function is useful to perform a graceful shutdown and ensure that a\n    /// value will not be sent into the channel and never received.\n    ///\n    /// `close` is no-op if a message is already received or the channel\n    /// is already closed.\n    ///\n    /// [`Sender`]: Sender\n    /// [`try_recv`]: Receiver::try_recv\n    ///\n    /// # Examples\n    ///\n    /// Prevent a value from being sent\n    ///\n    /// ```\n    /// use tokio::sync::oneshot;\n    /// use tokio::sync::oneshot::error::TryRecvError;\n    ///\n    /// #[tokio::main]\n    /// async fn main() {\n    ///     let (tx, mut rx) = oneshot::channel();\n    ///\n    ///     assert!(!tx.is_closed());\n    ///\n    ///     rx.close();\n    ///\n    ///     assert!(tx.is_closed());\n    ///     assert!(tx.send(\"never received\").is_err());\n    ///\n    ///     match rx.try_recv() {\n    ///         Err(TryRecvError::Closed) => {}\n    ///         _ => unreachable!(),\n    ///     }\n    /// }\n    /// ```\n    ///\n    /// Receive a value sent **before** calling `close`\n    ///\n    /// ```\n    /// use tokio::sync::oneshot;\n    ///\n    /// #[tokio::main]\n    /// async fn main() {\n    ///     let (tx, mut rx) = oneshot::channel();\n    ///\n    ///     assert!(tx.send(\"will receive\").is_ok());\n    ///\n    ///     rx.close();\n    ///\n    ///     let msg = rx.try_recv().unwrap();\n    ///     assert_eq!(msg, \"will receive\");\n    /// }\n    /// ```\n    pub fn close(&mut self) {\n        if let Some(inner) = self.inner.as_ref() {\n            inner.close();\n        }\n    }\n\n    /// Attempts to receive a value.\n    ///\n    /// If a pending value exists in the channel, it is returned. If no value\n    /// has been sent, the current task **will not** be registered for\n    /// future notification.\n    ///\n    /// This function is useful to call from outside the context of an\n    /// asynchronous task.\n    ///\n    /// # Return\n    ///\n    /// - `Ok(T)` if a value is pending in the channel.\n    /// - `Err(TryRecvError::Empty)` if no value has been sent yet.\n    /// - `Err(TryRecvError::Closed)` if the sender has dropped without sending\n    ///   a value.\n    ///\n    /// # Examples\n    ///\n    /// `try_recv` before a value is sent, then after.\n    ///\n    /// ```\n    /// use tokio::sync::oneshot;\n    /// use tokio::sync::oneshot::error::TryRecvError;\n    ///\n    /// #[tokio::main]\n    /// async fn main() {\n    ///     let (tx, mut rx) = oneshot::channel();\n    ///\n    ///     match rx.try_recv() {\n    ///         // The channel is currently empty\n    ///         Err(TryRecvError::Empty) => {}\n    ///         _ => unreachable!(),\n    ///     }\n    ///\n    ///     // Send a value\n    ///     tx.send(\"hello\").unwrap();\n    ///\n    ///     match rx.try_recv() {\n    ///         Ok(value) => assert_eq!(value, \"hello\"),\n    ///         _ => unreachable!(),\n    ///     }\n    /// }\n    /// ```\n    ///\n    /// `try_recv` when the sender dropped before sending a value\n    ///\n    /// ```\n    /// use tokio::sync::oneshot;\n    /// use tokio::sync::oneshot::error::TryRecvError;\n    ///\n    /// #[tokio::main]\n    /// async fn main() {\n    ///     let (tx, mut rx) = oneshot::channel::<()>();\n    ///\n    ///     drop(tx);\n    ///\n    ///     match rx.try_recv() {\n    ///         // The channel will never receive a value.\n    ///         Err(TryRecvError::Closed) => {}\n    ///         _ => unreachable!(),\n    ///     }\n    /// }\n    /// ```\n    pub fn try_recv(&mut self) -> Result<T, TryRecvError> {\n        let result = if let Some(inner) = self.inner.as_ref() {\n            let state = State::load(&inner.state, Acquire);\n\n            if state.is_complete() {\n                match unsafe { inner.consume_value() } {\n                    Some(value) => Ok(value),\n                    None => Err(TryRecvError::Closed),\n                }\n            } else if state.is_closed() {\n                Err(TryRecvError::Closed)\n            } else {\n                // Not ready, this does not clear `inner`\n                return Err(TryRecvError::Empty);\n            }\n        } else {\n            Err(TryRecvError::Closed)\n        };\n\n        self.inner = None;\n        result\n    }\n}\n\nimpl<T> Drop for Receiver<T> {\n    fn drop(&mut self) {\n        if let Some(inner) = self.inner.as_ref() {\n            inner.close();\n        }\n    }\n}\n\nimpl<T> Future for Receiver<T> {\n    type Output = Result<T, RecvError>;\n\n    fn poll(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> {\n        // If `inner` is `None`, then `poll()` has already completed.\n        let ret = if let Some(inner) = self.as_ref().get_ref().inner.as_ref() {\n            ready!(inner.poll_recv(cx))?\n        } else {\n            panic!(\"called after complete\");\n        };\n\n        self.inner = None;\n        Ready(Ok(ret))\n    }\n}\n\nimpl<T> Inner<T> {\n    fn complete(&self) -> bool {\n        let prev = State::set_complete(&self.state);\n\n        if prev.is_closed() {\n            return false;\n        }\n\n        if prev.is_rx_task_set() {\n            // TODO: Consume waker?\n            unsafe {\n                self.rx_task.with_task(Waker::wake_by_ref);\n            }\n        }\n\n        true\n    }\n\n    fn poll_recv(&self, cx: &mut Context<'_>) -> Poll<Result<T, RecvError>> {\n        // Keep track of task budget\n        let coop = ready!(crate::coop::poll_proceed(cx));\n\n        // Load the state\n        let mut state = State::load(&self.state, Acquire);\n\n        if state.is_complete() {\n            coop.made_progress();\n            match unsafe { self.consume_value() } {\n                Some(value) => Ready(Ok(value)),\n                None => Ready(Err(RecvError(()))),\n            }\n        } else if state.is_closed() {\n            coop.made_progress();\n            Ready(Err(RecvError(())))\n        } else {\n            if state.is_rx_task_set() {\n                let will_notify = unsafe { self.rx_task.will_wake(cx) };\n\n                // Check if the task is still the same\n                if !will_notify {\n                    // Unset the task\n                    state = State::unset_rx_task(&self.state);\n                    if state.is_complete() {\n                        // Set the flag again so that the waker is released in drop\n                        State::set_rx_task(&self.state);\n\n                        coop.made_progress();\n                        return match unsafe { self.consume_value() } {\n                            Some(value) => Ready(Ok(value)),\n                            None => Ready(Err(RecvError(()))),\n                        };\n                    } else {\n                        unsafe { self.rx_task.drop_task() };\n                    }\n                }\n            }\n\n            if !state.is_rx_task_set() {\n                // Attempt to set the task\n                unsafe {\n                    self.rx_task.set_task(cx);\n                }\n\n                // Update the state\n                state = State::set_rx_task(&self.state);\n\n                if state.is_complete() {\n                    coop.made_progress();\n                    match unsafe { self.consume_value() } {\n                        Some(value) => Ready(Ok(value)),\n                        None => Ready(Err(RecvError(()))),\n                    }\n                } else {\n                    Pending\n                }\n            } else {\n                Pending\n            }\n        }\n    }\n\n    /// Called by `Receiver` to indicate that the value will never be received.\n    fn close(&self) {\n        let prev = State::set_closed(&self.state);\n\n        if prev.is_tx_task_set() && !prev.is_complete() {\n            unsafe {\n                self.tx_task.with_task(Waker::wake_by_ref);\n            }\n        }\n    }\n\n    /// Consumes the value. This function does not check `state`.\n    unsafe fn consume_value(&self) -> Option<T> {\n        self.value.with_mut(|ptr| (*ptr).take())\n    }\n}\n\nunsafe impl<T: Send> Send for Inner<T> {}\nunsafe impl<T: Send> Sync for Inner<T> {}\n\nfn mut_load(this: &mut AtomicUsize) -> usize {\n    this.with_mut(|v| *v)\n}\n\nimpl<T> Drop for Inner<T> {\n    fn drop(&mut self) {\n        let state = State(mut_load(&mut self.state));\n\n        if state.is_rx_task_set() {\n            unsafe {\n                self.rx_task.drop_task();\n            }\n        }\n\n        if state.is_tx_task_set() {\n            unsafe {\n                self.tx_task.drop_task();\n            }\n        }\n    }\n}\n\nimpl<T: fmt::Debug> fmt::Debug for Inner<T> {\n    fn fmt(&self, fmt: &mut fmt::Formatter<'_>) -> fmt::Result {\n        use std::sync::atomic::Ordering::Relaxed;\n\n        fmt.debug_struct(\"Inner\")\n            .field(\"state\", &State::load(&self.state, Relaxed))\n            .finish()\n    }\n}\n\nconst RX_TASK_SET: usize = 0b00001;\nconst VALUE_SENT: usize = 0b00010;\nconst CLOSED: usize = 0b00100;\nconst TX_TASK_SET: usize = 0b01000;\n\nimpl State {\n    fn new() -> State {\n        State(0)\n    }\n\n    fn is_complete(self) -> bool {\n        self.0 & VALUE_SENT == VALUE_SENT\n    }\n\n    fn set_complete(cell: &AtomicUsize) -> State {\n        // TODO: This could be `Release`, followed by an `Acquire` fence *if*\n        // the `RX_TASK_SET` flag is set. However, `loom` does not support\n        // fences yet.\n        let val = cell.fetch_or(VALUE_SENT, AcqRel);\n        State(val)\n    }\n\n    fn is_rx_task_set(self) -> bool {\n        self.0 & RX_TASK_SET == RX_TASK_SET\n    }\n\n    fn set_rx_task(cell: &AtomicUsize) -> State {\n        let val = cell.fetch_or(RX_TASK_SET, AcqRel);\n        State(val | RX_TASK_SET)\n    }\n\n    fn unset_rx_task(cell: &AtomicUsize) -> State {\n        let val = cell.fetch_and(!RX_TASK_SET, AcqRel);\n        State(val & !RX_TASK_SET)\n    }\n\n    fn is_closed(self) -> bool {\n        self.0 & CLOSED == CLOSED\n    }\n\n    fn set_closed(cell: &AtomicUsize) -> State {\n        // Acquire because we want all later writes (attempting to poll) to be\n        // ordered after this.\n        let val = cell.fetch_or(CLOSED, Acquire);\n        State(val)\n    }\n\n    fn set_tx_task(cell: &AtomicUsize) -> State {\n        let val = cell.fetch_or(TX_TASK_SET, AcqRel);\n        State(val | TX_TASK_SET)\n    }\n\n    fn unset_tx_task(cell: &AtomicUsize) -> State {\n        let val = cell.fetch_and(!TX_TASK_SET, AcqRel);\n        State(val & !TX_TASK_SET)\n    }\n\n    fn is_tx_task_set(self) -> bool {\n        self.0 & TX_TASK_SET == TX_TASK_SET\n    }\n\n    fn as_usize(self) -> usize {\n        self.0\n    }\n\n    fn load(cell: &AtomicUsize, order: Ordering) -> State {\n        let val = cell.load(order);\n        State(val)\n    }\n}\n\nimpl fmt::Debug for State {\n    fn fmt(&self, fmt: &mut fmt::Formatter<'_>) -> fmt::Result {\n        fmt.debug_struct(\"State\")\n            .field(\"is_complete\", &self.is_complete())\n            .field(\"is_closed\", &self.is_closed())\n            .field(\"is_rx_task_set\", &self.is_rx_task_set())\n            .field(\"is_tx_task_set\", &self.is_tx_task_set())\n            .finish()\n    }\n}\n"
  },
  {
    "project": "va-ts",
    "target": 1,
    "commit_id": "42798bece650f738ad4e376c98dca0cd9b1af21d",
    "func": "use std::cell::RefCell;\nuse std::collections::HashMap;\nuse std::io::{Cursor, Write};\nuse std::rc::Rc;\nuse std::time::Duration;\n\nuse crate::packet::Packet as TsPacket;\nuse crate::pes::PES;\nuse crate::pid::PID;\nuse crate::result::Result;\nuse crate::section::{WithHeader, WithSyntaxSection};\nuse crate::subtable_id::{SubtableID, SubtableIDer};\nuse crate::{EIT, PAT, PMT, SDT};\n\npub struct Buf(pub Cursor<Vec<u8>>);\n\nimpl Buf {\n    #[inline(always)]\n    fn reset(&mut self) {\n        self.0.set_position(0);\n        self.0.get_mut().clear();\n    }\n\n    #[inline(always)]\n    fn is_empty(&self) -> bool {\n        self.0.position() == 0\n    }\n\n    #[inline(always)]\n    pub fn sz(&self) -> usize {\n        self.0.position() as usize\n    }\n}\n\nimpl Default for Buf {\n    fn default() -> Self {\n        Buf(Cursor::new(Vec::with_capacity(2048)))\n    }\n}\n\npub struct Section {\n    /// parent table-id\n    table_id: SubtableID,\n\n    /// number inside table sections\n    number: u8,\n\n    /// full section size with header, data, CRC\n    sz: usize,\n\n    pub buf: Buf,\n}\n\nimpl Section {\n    fn new(table_id: SubtableID, number: u8, sz: usize) -> Section {\n        Section {\n            table_id,\n            number,\n            sz,\n            buf: Default::default(),\n        }\n    }\n\n    #[inline(always)]\n    fn into_ref(self) -> SectionRef {\n        Rc::new(RefCell::new(Box::new(self)))\n    }\n\n    /// section consumed all data\n    #[inline(always)]\n    fn done(&self) -> bool {\n        self.sz_need() == 0\n    }\n\n    /// sz need to read\n    #[inline(always)]\n    fn sz_need(&self) -> usize {\n        self.sz - self.buf.sz()\n    }\n}\n\ntype SectionRef = Rc<RefCell<Box<Section>>>;\n\npub struct Sections(pub Vec<SectionRef>);\n\nimpl Sections {\n    #[inline(always)]\n    fn get_mut(&mut self, number: u8) -> Option<&mut SectionRef> {\n        self.0.iter_mut().find(|s| s.borrow().number == number)\n    }\n\n    #[inline(always)]\n    fn push(&mut self, s: SectionRef) {\n        self.0.push(s);\n        self.0\n            .sort_unstable_by(|a, b| a.borrow().number.cmp(&b.borrow().number));\n    }\n}\n\nimpl Default for Sections {\n    fn default() -> Self {\n        Sections(Vec::with_capacity(1))\n    }\n}\n\npub struct Table {\n    /// mpeg-ts last-section-number\n    last_section_number: u8,\n    pub sections: Sections,\n}\n\nimpl Table {\n    fn new(last_section_number: u8) -> Table {\n        Table {\n            last_section_number,\n            sections: Default::default(),\n        }\n    }\n\n    #[inline(always)]\n    fn done(&self) -> bool {\n        match self.sections.0.len() {\n            0 => false,\n            n => {\n                let last = (&self.sections.0[n - 1]).borrow();\n                let first = (&self.sections.0[0]).borrow();\n\n                first.number == 0\n                    && last.number == self.last_section_number\n                    && first.done()\n                    && last.done()\n            }\n        }\n    }\n}\n\nstruct Tables {\n    map: HashMap<SubtableID, Table>,\n    /// current demuxing section\n    current: Option<SectionRef>,\n}\n\nimpl Tables {}\n\nimpl Default for Tables {\n    fn default() -> Self {\n        Tables {\n            map: HashMap::new(),\n            current: None,\n        }\n    }\n}\n\npub struct Packet {\n    pub pid: PID,\n\n    pub offset: usize,\n\n    /// presentation time stamp\n    pub pts: Option<Duration>,\n\n    /// decode time stamp\n    pub dts: Option<Duration>,\n\n    pub buf: Buf,\n\n    /// got ts PUSI\n    started: bool,\n}\n\nimpl Packet {\n    fn new(pid: PID) -> Packet {\n        Packet {\n            pid,\n            offset: 0,\n            pts: None,\n            dts: None,\n            buf: Default::default(),\n            started: false,\n        }\n    }\n}\n\n#[derive(Default)]\nstruct Packets(HashMap<PID, Packet>);\n\n/// pid, packet-constructed\n#[derive(Debug)]\nstruct PMTPids(Vec<(PID, bool)>);\n\nimpl PMTPids {\n    #[inline(always)]\n    fn has(&self, pid: PID) -> bool {\n        self.0.iter().any(|p| (*p).0 == pid)\n    }\n\n    #[inline(always)]\n    fn push_uniq(&mut self, pid: PID) {\n        if !self.has(pid) {\n            self.0.push((pid, false))\n        }\n    }\n\n    /// got pid? and pid is parsed and packet builded\n    #[inline(always)]\n    fn is_packet_builded(&self, pid: PID) -> Option<bool> {\n        self.0.iter().find(|p| p.0 == pid).map(|p| p.1)\n    }\n\n    #[inline(always)]\n    fn set_is_packet_builded(&mut self, pid: PID, v: bool) {\n        if let Some(p) = self.0.iter_mut().find(|p| p.0 == pid) {\n            p.1 = v;\n        }\n    }\n\n    /// all pids are parsed?\n    #[inline(always)]\n    #[allow(dead_code)]\n    fn are_all_packets_builded(&self) -> bool {\n        !self.0.iter().any(|p| !(*p).1)\n    }\n}\n\nimpl Default for PMTPids {\n    fn default() -> Self {\n        PMTPids(Vec::with_capacity(3))\n    }\n}\n\npub trait DemuxerEvents {\n    fn on_table(&mut self, _: SubtableID, _: &Table) {}\n    fn on_packet(&mut self, _: &Packet) {}\n}\n\n/// TODO: use tree, redix tree here\n/// TODO: add benches\npub struct Demuxer<T>\nwhere\n    T: DemuxerEvents,\n{\n    offset: usize,\n\n    pat: Tables,\n    pmt: Tables,\n    eit: Tables,\n    sdt: Tables,\n\n    #[allow(dead_code)]\n    nit: Tables,\n    #[allow(dead_code)]\n    cat: Tables,\n    #[allow(dead_code)]\n    bat: Tables,\n\n    packets: Packets,\n\n    // TODO: add PID with state(is-parsed or not)\n    //       for multiple PMTs\n    pmt_pids: PMTPids,\n\n    events: T,\n}\n\nunsafe impl<T> Send for Demuxer<T> where T: DemuxerEvents {}\n\nimpl<T> Demuxer<T>\nwhere\n    T: DemuxerEvents,\n{\n    pub fn new(events: T) -> Demuxer<T> {\n        Demuxer {\n            offset: 0,\n\n            pat: Default::default(),\n            pmt: Default::default(),\n            eit: Default::default(),\n            sdt: Default::default(),\n            nit: Default::default(),\n            cat: Default::default(),\n            bat: Default::default(),\n\n            pmt_pids: Default::default(),\n\n            packets: Default::default(),\n\n            events,\n        }\n    }\n\n    /// cache pmt pids\n    // TODO: also do via iterator\n    // TODO: .iter().collect() for lazy collection\n    #[inline(always)]\n    fn build_pmt_pids(&mut self) {\n        for (_, table) in self.pat.map.iter() {\n            for section_ref in table.sections.0.iter() {\n                let section = (*section_ref).borrow();\n                let raw = section.buf.0.get_ref().as_slice();\n                let pat = PAT::new(raw);\n\n                // TODO: refactor via iter/to-iter\n                for pid in pat\n                    .programs()\n                    .filter_map(Result::ok)\n                    .filter(|p| p.pid().is_program_map())\n                    .map(|p| PID::from(p.pid()))\n                {\n                    self.pmt_pids.push_uniq(pid)\n                }\n            }\n        }\n    }\n\n    /// build packets cache\n    // TODO: also do via iterator\n    // TODO: .iter().collect() for lazy collection\n    #[inline(always)]\n    fn build_packets(&mut self) {\n        for (_, table) in self.pmt.map.iter() {\n            for section_ref in table.sections.0.iter() {\n                let section = (*section_ref).borrow();\n                let raw = section.buf.0.get_ref().as_slice();\n                let pmt = PMT::new(raw);\n\n                // TODO: refactor via iter/to-iter\n                for pid in pmt\n                    .streams()\n                    .filter_map(Result::ok)\n                    .map(|s| PID::from(s.pid()))\n                {\n                    self.packets\n                        .0\n                        .entry(pid)\n                        .or_insert_with(|| Packet::new(pid));\n                }\n            }\n        }\n    }\n\n    // TODO: move to macros?\n    #[inline(always)]\n    fn demux_section(&mut self, pid_or_pmt: (PID, bool), pkt: &TsPacket) -> Result<()> {\n        let tables = match pid_or_pmt {\n            (PID::PAT, false) => &mut self.pat,\n            (PID::SDT, false) => &mut self.sdt,\n            (PID::EIT, false) => &mut self.eit,\n            (PID::NIT, false) => &mut self.nit,\n            (PID::CAT, false) => &mut self.cat,\n            (_, true) => &mut self.pmt,\n            _ => unreachable!(),\n        };\n\n        let buf = pkt.buf_payload_section()?;\n\n        if pkt.pusi() {\n            let (id, sz, section_number, last_section_number) = match pid_or_pmt {\n                (PID::PAT, false) => {\n                    let s = PAT::try_new(buf)?;\n                    (\n                        s.subtable_id(),\n                        s.sz(),\n                        s.section_number(),\n                        s.last_section_number(),\n                    )\n                }\n                (PID::SDT, false) => {\n                    let s = SDT::try_new(buf)?;\n                    (\n                        s.subtable_id(),\n                        s.sz(),\n                        s.section_number(),\n                        s.last_section_number(),\n                    )\n                }\n                (PID::EIT, false) => {\n                    let s = EIT::try_new(buf)?;\n                    (\n                        s.subtable_id(),\n                        s.sz(),\n                        s.section_number(),\n                        s.last_section_number(),\n                    )\n                }\n                (_, true) => {\n                    let s = PMT::try_new(buf)?;\n                    (\n                        s.subtable_id(),\n                        s.sz(),\n                        s.section_number(),\n                        s.last_section_number(),\n                    )\n                }\n                _ => unreachable!(),\n            };\n\n            let table = tables\n                .map\n                .entry(id)\n                .or_insert_with(|| Table::new(last_section_number));\n\n            let section_ref = match table.sections.get_mut(section_number) {\n                Some(section_ref) => {\n                    let mut section = (*section_ref).borrow_mut();\n                    section.buf.reset();\n                    section.sz = sz;\n\n                    section_ref.clone()\n                }\n                None => {\n                    let section_ref = Section::new(id, section_number, sz).into_ref();\n                    table.sections.push(section_ref.clone());\n                    section_ref\n                }\n            };\n\n            tables.current = Some(section_ref);\n        }\n\n        if let Some(section_ref) = &tables.current {\n            {\n                let mut section = (*section_ref).borrow_mut();\n                let sz_need = section.sz_need();\n\n                // remove null/padding bytes\n                let buf = if buf.len() > sz_need {\n                    &buf[0..sz_need]\n                } else {\n                    buf\n                };\n\n                section.buf.0.write_all(buf)?;\n            }\n\n            {\n                let section = (*section_ref).borrow();\n                if section.done() {\n                    if let Some(table) = tables.map.get(&section.table_id) {\n                        if table.done() {\n                            // emit\n                            self.events.on_table(section.table_id, &table);\n                        }\n                    }\n                }\n            }\n        }\n\n        Ok(())\n    }\n\n    pub fn demux(&mut self, raw: &[u8]) -> Result<()> {\n        if self.demux_tables(raw)? {\n            return Ok(());\n        }\n\n        self.demux_packets(raw)\n    }\n\n    /// ffmpeg::avformat_open_input analog\n    /// probe input\n    /// return: is pid handled?\n    pub fn demux_tables(&mut self, raw: &[u8]) -> Result<(bool)> {\n        self.offset += raw.len();\n\n        let pkt = TsPacket::new(&raw)?;\n        let pid = pkt.pid();\n\n        if pid.is_null() {\n            // null packet PID\n            return Ok(true);\n        }\n\n        match pid {\n            PID::PAT => {\n                self.demux_section((pid, false), &pkt)?;\n\n                // extract pids from PAT\n                if self.pmt_pids.0.is_empty() {\n                    self.pmt_pids.0.clear();\n                    self.packets.0.clear();\n                    self.build_pmt_pids();\n                }\n            }\n            PID::SDT | PID::EIT /* | PID::NIT | PID::CAT | PID::BAT */ =>\n                self.demux_section((pid, false), &pkt)?,\n\n            PID::Other(..) => {\n                // PAT not ready yet\n                // wait for PAT\n                if self.pmt_pids.0.is_empty() {\n                    return Ok(true);\n                }\n\n                match self.pmt_pids.is_packet_builded(pid) {\n                    Some(true) => { // got PMT and already builded\n                        self.demux_section((pid, true), &pkt)?;\n                    },\n                    Some(false) => { // got PMT and not builded\n                        self.demux_section((pid, true), &pkt)?;\n\n                        self.build_packets();\n\n                        self.pmt_pids.set_is_packet_builded(pid, true);\n                    },\n                    None => {return Ok(false); }\n                }\n            }\n            _ => {}\n        }\n\n        Ok(true)\n    }\n\n    /// ffmpeg::av_read_frame analog\n    pub fn demux_packets(&mut self, raw: &[u8]) -> Result<()> {\n        self.offset += raw.len();\n\n        let pkt = TsPacket::new(&raw)?;\n        let pid = pkt.pid();\n\n        if pid.is_null() // null packet PID\n        && !pid.is_other() // PID is section/table PID\n        // PAT not ready yet\n        // wait for pat\n        && !self.pmt_pids.0.is_empty()\n        {\n            return Ok(());\n        }\n\n        let mut packet = match self.packets.0.get_mut(&pid) {\n            Some(packet) => packet,\n            None => return Ok(()), // packet is not builder - wait fot PMT\n        };\n\n        let mut buf = pkt.buf_payload_pes()?;\n\n        if pkt.pusi() {\n            let pes = PES::new(buf);\n\n            if !packet.buf.is_empty() {\n                // emit\n                self.events.on_packet(packet);\n            }\n\n            packet.buf.reset();\n            packet.started = true;\n            packet.offset += self.offset + raw.len() - buf.len();\n            packet.pts = pes.pts().map(Duration::from);\n            packet.dts = pes.dts().map(Duration::from);\n\n            buf = pes.buf_seek_payload();\n        }\n\n        if packet.started {\n            packet.buf.0.write_all(buf)?;\n        }\n\n        Ok(())\n    }\n}\n\n#[cfg(test)]\nmod tests {}\n"
  },
  {
    "project": "gfwx-rs",
    "target": 1,
    "commit_id": "59521ca48f635a5a467d73f29bdbb1a6494a455d",
    "func": "use std::{\n    marker::PhantomData,\n    ops::{Index, IndexMut},\n    slice,\n};\n\npub struct Image<'a, T> {\n    data: &'a mut [T],\n    size: (usize, usize),\n    channels: usize,\n}\n\nimpl<'a, T> Image<'a, T> {\n    pub fn from_slice(data: &'a mut [T], size: (usize, usize), channels: usize) -> Image<'a, T> {\n        Image {\n            data,\n            size,\n            channels,\n        }\n    }\n\n    pub fn into_chunks_mut(self, chunk_size: usize, step: usize) -> ImageChunkIteratorMut<'a, T> {\n        let (width, height) = self.size;\n\n        ImageChunkIteratorMut {\n            data: self.data,\n            state: ImageChunkIteratorState {\n                chunk_size,\n                step,\n                x: 0,\n                y: 0,\n                channel: 0,\n                width,\n                height,\n                channels: self.channels,\n            },\n        }\n    }\n}\n\nstruct ImageChunkIteratorState {\n    chunk_size: usize,\n    step: usize,\n    pub x: usize,\n    pub y: usize,\n    channel: usize,\n    width: usize,\n    height: usize,\n    channels: usize,\n}\n\ntype Range = (usize, usize);\n\nimpl ImageChunkIteratorState {\n    pub fn next_chunk(&mut self) -> Option<(Range, Range, usize, usize)> {\n        if self.channel >= self.channels {\n            return None;\n        }\n\n        let (x, y) = (self.x, self.y);\n        let channel = self.channel;\n\n        self.x += self.chunk_size;\n\n        if self.x >= self.width {\n            self.x = 0;\n            self.y += self.chunk_size;\n        }\n\n        if self.y >= self.height {\n            self.y = 0;\n            self.channel += 1;\n        }\n\n        Some((\n            (x, (x + self.chunk_size).min(self.width)),\n            (y, (y + self.chunk_size).min(self.height)),\n            channel,\n            channel * self.width * self.height,\n        ))\n    }\n}\n\npub struct ImageChunkIteratorMut<'a, T> {\n    data: &'a mut [T],\n    state: ImageChunkIteratorState,\n}\n\npub struct ImageChunkMut<'a, T> {\n    data_ptr: *mut T,\n    data_len: usize,\n    phantom_data: PhantomData<&'a T>,\n    image_width: usize,\n    channel_size: usize,\n    channel_start: usize,\n\n    pub x_range: (usize, usize),\n    pub y_range: (usize, usize),\n    pub channel: usize,\n    pub step: usize,\n}\n\nimpl<T> ImageChunkMut<'_, T> {\n    pub unsafe fn get_unchecked(&self, y: usize, x: usize) -> &T {\n        let index = self.channel_start + y * self.image_width + x;\n\n        debug_assert!(\n            self.is_owned_zone(y, x) || !self.is_writeable_zone(y, x),\n            \"Access to mutable neighbour image chunk parts is not permitted!\"\n        );\n        debug_assert!(\n            index < self.channel_start + self.channel_size,\n            \"Cross-channel indexing is not permitted!\"\n        );\n        debug_assert!(index < self.data_len);\n\n        &*self.data_ptr.add(index)\n    }\n\n    pub unsafe fn get_unchecked_mut(&mut self, y: usize, x: usize) -> &mut T {\n        let index = self.channel_start + y * self.image_width + x;\n\n        debug_assert!(\n            self.is_owned_zone(y, x) && self.is_writeable_zone(y, x),\n            \"Write to immutable image chunk parts is not permitted!\",\n        );\n        debug_assert!(\n            index < self.channel_start + self.channel_size,\n            \"Cross-channel indexing is not permitted!\"\n        );\n        debug_assert!(index < self.data_len);\n\n        &mut *self.data_ptr.add(index)\n    }\n\n    fn is_writeable_zone(&self, y: usize, x: usize) -> bool {\n        if y == self.y_range.0 && x == self.x_range.0 {\n            return true;\n        }\n\n        if y % self.step == 0 {\n            let x_step = if (y & self.step) != 0 {\n                self.step\n            } else {\n                self.step * 2\n            };\n            if (x + (x_step - self.step)) % x_step == 0 {\n                return true;\n            }\n        }\n\n        false\n    }\n\n    fn is_owned_zone(&self, y: usize, x: usize) -> bool {\n        x >= self.x_range.0 && x < self.x_range.1 && y >= self.y_range.0 && y < self.y_range.1\n    }\n}\n\nunsafe impl<T> Send for ImageChunkMut<'_, T> {}\nunsafe impl<T> Sync for ImageChunkMut<'_, T> {}\n\nimpl<T> Index<(usize, usize)> for ImageChunkMut<'_, T> {\n    type Output = T;\n\n    fn index(&self, (y, x): (usize, usize)) -> &Self::Output {\n        let index = self.channel_start + y * self.image_width + x;\n\n        assert!(\n            self.is_owned_zone(y, x) || !self.is_writeable_zone(y, x),\n            \"Access to mutable neighbour image chunk parts is not permitted!\"\n        );\n        assert!(\n            index < self.channel_start + self.channel_size,\n            \"Cross-channel indexing is not permitted!\"\n        );\n\n        unsafe {\n            let data = slice::from_raw_parts_mut(self.data_ptr, self.data_len);\n            &data[index]\n        }\n    }\n}\n\nimpl<T> IndexMut<(usize, usize)> for ImageChunkMut<'_, T> {\n    fn index_mut(&mut self, (y, x): (usize, usize)) -> &mut Self::Output {\n        let index = self.channel_start + y * self.image_width + x;\n\n        assert!(\n            self.is_owned_zone(y, x) && self.is_writeable_zone(y, x),\n            \"Write to immutable image chunk parts is not permitted!\",\n        );\n        assert!(\n            index < self.channel_start + self.channel_size,\n            \"Cross-channel indexing is not permitted!\"\n        );\n\n        unsafe {\n            let data = slice::from_raw_parts_mut(self.data_ptr, self.data_len);\n            &mut data[index]\n        }\n    }\n}\n\nimpl<'a, T> Iterator for ImageChunkIteratorMut<'a, T> {\n    type Item = ImageChunkMut<'a, T>;\n\n    fn next(&mut self) -> Option<Self::Item> {\n        self.state\n            .next_chunk()\n            .map(|(x_range, y_range, channel, channel_start)| ImageChunkMut {\n                data_ptr: self.data.as_mut_ptr(),\n                data_len: self.data.len(),\n                phantom_data: PhantomData,\n                image_width: self.state.width,\n                channel_size: self.state.width * self.state.height,\n                channel_start,\n                channel,\n                x_range,\n                y_range,\n                step: self.state.step,\n            })\n    }\n}\n"
  },
  {
    "project": "rust-async-coap",
    "target": 1,
    "commit_id": "6a7b592a23de0c9d86ca399bf40ecfbf0bff6e62",
    "func": "// Copyright 2019 Google LLC\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     https://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n//\n\n//! # Arc Guard\n//!\n//! This crate[^1] provides the [`ArcGuard`] class, which is a container for a single object\n//! with lifetime that is bound to that of an `Arc`. This is useful for passing around boxed\n//! futures that have a lifetime that is limited to that of the object that created it.\n//!\n//! For example, the following does not compile:\n//!\n//! ```compile_fail\n//! # use async_coap::arc_guard; // Remove if spun off into own crate\n//! use futures::{future::ready,future::BoxFuture,prelude::*};\n//! use std::sync::{Arc,Weak};\n//! use arc_guard::{ArcGuard,ArcGuardExt};\n//!\n//! trait PropertyFetcher {\n//!         fn fetch(\n//!             &self,\n//!             key: &str,\n//!         ) -> BoxFuture<Option<String>>;\n//! }\n//!\n//! struct WeakFetcher {\n//!     sub_obj: Weak<Box<PropertyFetcher>>,\n//! }\n//!\n//! impl PropertyFetcher for WeakFetcher {\n//!     fn fetch(&self, key: &str) -> BoxFuture<Option<String>> {\n//!         if let Some(arc) = self.sub_obj.upgrade() {\n//!             // error[E0515]: cannot return value referencing local variable `arc`\n//!             arc.fetch(key).boxed()\n//!         } else {\n//!             ready(None).boxed()\n//!         }\n//!     }\n//! }\n//! ```\n//!\n//! If you think about it, the fact that `rustc` doesn't like this code makes perfect sense:\n//! because `sub_obj` is a weak reference, it could be dropped at any moment, violating the\n//! lifetime guarantee for the return value of `fetch()`. To fix this, we need to ensure that\n//! the value we return internally keeps an `Arc` reference to the object that created it. That's\n//! where `ArcGuard` comes in:\n//!\n//! ```\n//! # use async_coap::arc_guard; // Remove if spun off into own crate\n//! # use futures::{future::ready,future::BoxFuture,prelude::*};\n//! # use std::sync::{Arc,Weak};\n//! # use arc_guard::{ArcGuard,ArcGuardExt};\n//! #\n//! # trait PropertyFetcher {\n//! #         fn fetch(\n//! #             &self,\n//! #             key: &str,\n//! #         ) -> BoxFuture<Option<String>>;\n//! # }\n//! #\n//! # struct WeakFetcher {\n//! #     sub_obj: Weak<Box<PropertyFetcher>>,\n//! # }\n//!\n//! impl PropertyFetcher for WeakFetcher {\n//!     fn fetch(&self, key: &str) -> BoxFuture<Option<String>> {\n//!         if let Some(arc) = self.sub_obj.upgrade() {\n//!             // Compiles and works!\n//!             arc.guard(|x|x.fetch(key)).boxed()\n//!         } else {\n//!             ready(None).boxed()\n//!         }\n//!     }\n//! }\n//! ```\n//!\n//! ## Additional Examples\n//!\n//! ```\n//! # use async_coap::arc_guard; // Remove if spun off into own crate\n//! # use std::sync::{Arc,Weak};\n//! # use arc_guard::{ArcGuard,ArcGuardExt};\n//!\n//! let mut arc = Arc::new(\"foobar\".to_string());\n//!\n//! let guarded = arc.guard(|s| &s.as_str()[3..]);\n//!\n//! assert_eq!(guarded, \"bar\");\n//!\n//! // We can't get a mutable instance to the\n//! // string while `guarded` is still around.\n//! assert_eq!(Arc::get_mut(&mut arc), None);\n//!\n//! core::mem::drop(guarded);\n//!\n//! assert!(Arc::get_mut(&mut arc).is_some());\n//! ```\n//!\n//! [^1]: I would have loved to call this crate `lifeguard`, because it is a \"guard\" on the\n//!       lifetime of the contained \"head\" instance, but sadly that name was\n//!       [already taken](https://crates.io/crates/lifeguard).\n//!\n\n#![warn(missing_docs, missing_debug_implementations, rust_2018_idioms)]\n#![warn(clippy::all)]\n\nuse futures::prelude::*;\nuse pin_utils::unsafe_pinned;\nuse std::cmp::Ordering;\nuse std::ops::Deref;\nuse std::pin::Pin;\nuse std::sync::Arc;\n\n/// A container for a single object with lifetime that is bound to that of an `Arc`.\n///\n/// See [Module Documentation](index.html) for more information.\n#[derive(Debug, Clone)]\npub struct ArcGuard<RC, T> {\n    inner: T,\n    head: Arc<RC>,\n}\n\nimpl<RC, T> ArcGuard<RC, T> {\n    unsafe_pinned!(inner: T);\n\n    /// Constructs a new `ArcGuard<>` instance using the given `Arc<>` and getter closure.\n    /// The use of a closure for the getter allows for a more convenient syntax while ensuring\n    /// the lifetimes are properly accounted for.\n    ///\n    /// See the main documentation for `ArcGuard<>` for a usage example.\n    pub fn new<'head, F>(head: Arc<RC>, getter: F) -> ArcGuard<RC, T>\n    where\n        F: FnOnce(&'head RC) -> T,\n        RC: 'head,\n        T: 'head,\n    {\n        // SAFETY: This is safe because we are only using this reference to create our object,\n        // and, by holding a reference to `head`, this class ensures that it does not live longer\n        // than the contained reference.\n        ArcGuard {\n            inner: getter(unsafe { std::mem::transmute::<&RC, &RC>(&head) }),\n            head,\n        }\n    }\n\n    /// Borrows a reference to the `Arc` that is being held to preserve the underlying value.\n    pub fn head(&self) -> &Arc<RC> {\n        &self.head\n    }\n}\n\nunsafe impl<RC, T: Send> Send for ArcGuard<RC, T> {}\nunsafe impl<RC, T: Sync> Sync for ArcGuard<RC, T> {}\n\nimpl<RC, T> Deref for ArcGuard<RC, T> {\n    type Target = T;\n\n    fn deref(&self) -> &Self::Target {\n        &self.inner\n    }\n}\n\nimpl<RC, T: std::fmt::Display> std::fmt::Display for ArcGuard<RC, T> {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> Result<(), std::fmt::Error> {\n        self.inner.fmt(f)\n    }\n}\n\nimpl<RC, T: AsRef<R>, R> AsRef<R> for ArcGuard<RC, T> {\n    fn as_ref(&self) -> &R {\n        self.inner.as_ref()\n    }\n}\n\nimpl<RC, T> std::borrow::Borrow<T> for ArcGuard<RC, T> {\n    fn borrow(&self) -> &T {\n        &self.inner\n    }\n}\n\nimpl<RC, T: PartialEq<R>, R> PartialEq<R> for ArcGuard<RC, T> {\n    fn eq(&self, other: &R) -> bool {\n        self.inner.eq(other)\n    }\n}\n\nimpl<RC, T: PartialOrd<R>, R> PartialOrd<R> for ArcGuard<RC, T> {\n    fn partial_cmp(&self, other: &R) -> Option<Ordering> {\n        self.inner.partial_cmp(other)\n    }\n}\n\nimpl<RC, T: Future> Future for ArcGuard<RC, T> {\n    type Output = T::Output;\n\n    fn poll(\n        mut self: Pin<&mut Self>,\n        cx: &mut futures::task::Context<'_>,\n    ) -> futures::task::Poll<Self::Output> {\n        self.as_mut().inner().poll(cx)\n    }\n}\n\nimpl<RC, T: Stream> Stream for ArcGuard<RC, T> {\n    type Item = T::Item;\n\n    fn poll_next(\n        mut self: Pin<&mut Self>,\n        cx: &mut futures::task::Context<'_>,\n    ) -> futures::task::Poll<Option<Self::Item>> {\n        self.as_mut().inner().poll_next(cx)\n    }\n}\n\n/// A convenience trait for `Arc<>` that makes it easier to construct `ArcGuard<>` instances.\n///\n/// See [Module Documentation](index.html) for more information.\npub trait ArcGuardExt<RC> {\n    /// Convenience method for constructing `ArcGuard<>` instances.\n    ///\n    /// See [Module Documentation](index.html) for more information.\n    fn guard<'head, F, T>(&self, getter: F) -> ArcGuard<RC, T>\n    where\n        F: FnOnce(&'head RC) -> T,\n        RC: 'head,\n        T: 'head;\n}\n\nimpl<RC> ArcGuardExt<RC> for Arc<RC> {\n    fn guard<'head, F, T>(&self, getter: F) -> ArcGuard<RC, T>\n    where\n        F: FnOnce(&'head RC) -> T,\n        RC: 'head,\n        T: 'head,\n    {\n        ArcGuard::new(self.clone(), getter)\n    }\n}\n"
  },
  {
    "project": "arrow2",
    "target": 1,
    "commit_id": "a87c758a80facbfbcde4768ad42cdf4c5c2cc5a8",
    "func": "/* automatically generated by rust-bindgen 0.59.2 */\n\n/// ABI-compatible struct for [`ArrowSchema`](https://arrow.apache.org/docs/format/CDataInterface.html#structure-definitions)\n#[repr(C)]\n#[derive(Debug, Clone)]\npub struct ArrowSchema {\n    pub(super) format: *const ::std::os::raw::c_char,\n    pub(super) name: *const ::std::os::raw::c_char,\n    pub(super) metadata: *const ::std::os::raw::c_char,\n    pub(super) flags: i64,\n    pub(super) n_children: i64,\n    pub(super) children: *mut *mut ArrowSchema,\n    pub(super) dictionary: *mut ArrowSchema,\n    pub(super) release: ::std::option::Option<unsafe extern \"C\" fn(arg1: *mut ArrowSchema)>,\n    pub(super) private_data: *mut ::std::os::raw::c_void,\n}\n\n/// ABI-compatible struct for [`ArrowArray`](https://arrow.apache.org/docs/format/CDataInterface.html#structure-definitions)\n#[repr(C)]\n#[derive(Debug, Clone)]\npub struct ArrowArray {\n    pub(super) length: i64,\n    pub(super) null_count: i64,\n    pub(super) offset: i64,\n    pub(super) n_buffers: i64,\n    pub(super) n_children: i64,\n    pub(super) buffers: *mut *const ::std::os::raw::c_void,\n    pub(super) children: *mut *mut ArrowArray,\n    pub(super) dictionary: *mut ArrowArray,\n    pub(super) release: ::std::option::Option<unsafe extern \"C\" fn(arg1: *mut ArrowArray)>,\n    pub(super) private_data: *mut ::std::os::raw::c_void,\n}\n\n/// ABI-compatible struct for [`ArrowArrayStream`](https://arrow.apache.org/docs/format/CStreamInterface.html).\n#[repr(C)]\n#[derive(Debug, Clone)]\npub struct ArrowArrayStream {\n    pub(super) get_schema: ::std::option::Option<\n        unsafe extern \"C\" fn(\n            arg1: *mut ArrowArrayStream,\n            out: *mut ArrowSchema,\n        ) -> ::std::os::raw::c_int,\n    >,\n    pub(super) get_next: ::std::option::Option<\n        unsafe extern \"C\" fn(\n            arg1: *mut ArrowArrayStream,\n            out: *mut ArrowArray,\n        ) -> ::std::os::raw::c_int,\n    >,\n    pub(super) get_last_error: ::std::option::Option<\n        unsafe extern \"C\" fn(arg1: *mut ArrowArrayStream) -> *const ::std::os::raw::c_char,\n    >,\n    pub(super) release: ::std::option::Option<unsafe extern \"C\" fn(arg1: *mut ArrowArrayStream)>,\n    pub(super) private_data: *mut ::std::os::raw::c_void,\n}\n"
  }
]