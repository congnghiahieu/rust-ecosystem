[
  {
    "project": "",
    "target": 0,
    "commit_id": "7e2278e4f28e6c46f2e3233b58f08941982bad4e",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-query/sea-query-derive/tests/compile-fail/path_method.rs",
    "func": "use sea_query::Iden;\n\n#[derive(Iden)]\nenum Asset {\n    Table,\n    Id,\n    AssetName,\n    #[method]\n    Creation,\n}\n\nfn main() {}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "9ba11d92dc4e37c1af15034b37c3081231e2cee8",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-query/sea-query-derive/src/iden/write_arm.rs",
    "func": "use std::convert::TryFrom;\nuse std::marker::PhantomData;\n\nuse heck::ToSnakeCase;\nuse proc_macro2::{Span, TokenStream};\nuse quote::{quote, ToTokens, TokenStreamExt};\nuse syn::{Error, Fields, FieldsNamed, Ident, Variant};\n\nuse super::{attr::IdenAttr, error::ErrorMsg};\nuse crate::{find_attr, must_be_valid_iden};\n\npub(crate) trait WriteArm {\n    fn variant(variant: TokenStream, name: TokenStream) -> TokenStream;\n    fn flattened(variant: TokenStream, name: &Ident) -> TokenStream;\n}\npub(crate) struct IdenVariant<'a, T> {\n    ident: &'a Ident,\n    fields: &'a Fields,\n    table_name: &'a str,\n    attr: Option<IdenAttr>,\n    _p: PhantomData<T>,\n}\n\nimpl<'a, T> TryFrom<(&'a str, &'a Variant)> for IdenVariant<'a, T>\nwhere\n    T: WriteArm,\n{\n    type Error = Error;\n\n    fn try_from((table_name, value): (&'a str, &'a Variant)) -> Result<Self, Self::Error> {\n        let Variant {\n            ident,\n            fields,\n            attrs,\n            ..\n        } = value;\n        let attr = find_attr(attrs).map(IdenAttr::try_from).transpose()?;\n\n        Self::new(ident, fields, table_name, attr)\n    }\n}\n\nimpl<T> ToTokens for IdenVariant<'_, T>\nwhere\n    T: WriteArm,\n{\n    fn to_tokens(&self, tokens: &mut TokenStream) {\n        match self.fields {\n            Fields::Named(named) => self.to_tokens_from_named(named, tokens),\n            Fields::Unnamed(_) => self.to_tokens_from_unnamed(tokens),\n            Fields::Unit => self.to_tokens_from_unit(tokens),\n        }\n    }\n}\n\nimpl<'a, T> IdenVariant<'a, T>\nwhere\n    T: WriteArm,\n{\n    fn new(\n        ident: &'a Ident,\n        fields: &'a Fields,\n        table_name: &'a str,\n        attr: Option<IdenAttr>,\n    ) -> syn::Result<Self> {\n        let unsupported_error = Err(Error::new_spanned(\n            fields,\n            ErrorMsg::UnsupportedFlattenTarget,\n        ));\n        // sanity check to not have flatten on a unit variant, or variants with more than 1 field\n        if attr == Some(IdenAttr::Flatten) {\n            match fields {\n                Fields::Named(n) => {\n                    if n.named.len() != 1 {\n                        return unsupported_error;\n                    }\n                }\n                Fields::Unnamed(u) => {\n                    if u.unnamed.len() != 1 {\n                        return unsupported_error;\n                    }\n                }\n                Fields::Unit => return unsupported_error,\n            }\n        }\n\n        Ok(Self {\n            ident,\n            fields,\n            table_name,\n            attr,\n            _p: PhantomData::<T>,\n        })\n    }\n\n    fn to_tokens_from_named(&self, named: &FieldsNamed, tokens: &mut TokenStream) {\n        let ident = self.ident;\n\n        let match_arm = if self.attr == Some(IdenAttr::Flatten) {\n            // indexing is safe because len is guaranteed to be 1 from the constructor.\n            let field = &named.named[0];\n            // Unwrapping the ident is also safe because a named field always has an ident.\n            let capture = field.ident.as_ref().unwrap();\n            let variant = quote! { #ident{#capture} };\n            T::flattened(variant, capture)\n        } else {\n            let variant = quote! { #ident{..} };\n            self.write_variant_name(variant)\n        };\n\n        tokens.append_all(match_arm)\n    }\n\n    fn to_tokens_from_unnamed(&self, tokens: &mut TokenStream) {\n        let ident = self.ident;\n\n        let match_arm = if self.attr == Some(IdenAttr::Flatten) {\n            // The case where unnamed fields length is not 1 is handled by new\n            let capture = Delegated.into();\n            let variant = quote! { #ident(#capture) };\n            T::flattened(variant, &capture)\n        } else {\n            let variant = quote! { #ident(..) };\n            self.write_variant_name(variant)\n        };\n\n        tokens.append_all(match_arm)\n    }\n\n    fn to_tokens_from_unit(&self, tokens: &mut TokenStream) {\n        let ident = self.ident;\n        let variant = quote! { #ident };\n\n        tokens.append_all(self.write_variant_name(variant))\n    }\n\n    fn table_or_snake_case(&self) -> String {\n        if self.ident == \"Table\" {\n            self.table_name.to_owned()\n        } else {\n            self.ident.to_string().to_snake_case()\n        }\n    }\n\n    fn write_variant_name(&self, variant: TokenStream) -> TokenStream {\n        let name = self\n            .attr\n            .as_ref()\n            .map(|a| match a {\n                IdenAttr::Rename(name) => quote! { #name },\n                IdenAttr::Method(method) => quote! { self.#method() },\n                IdenAttr::Flatten => unreachable!(),\n            })\n            .unwrap_or_else(|| {\n                let name = self.table_or_snake_case();\n                quote! { #name }\n            });\n\n        T::variant(variant, name)\n    }\n\n    pub(crate) fn must_be_valid_iden(&self) -> bool {\n        let name: String = match &self.attr {\n            Some(a) => match a {\n                IdenAttr::Rename(name) => name.to_owned(),\n                IdenAttr::Method(_) => return false,\n                IdenAttr::Flatten => return false,\n            },\n            None => self.table_or_snake_case(),\n        };\n\n        must_be_valid_iden(&name)\n    }\n}\n\nstruct Delegated;\n\nimpl From<Delegated> for Ident {\n    fn from(_: Delegated) -> Self {\n        Ident::new(\"delegated\", Span::call_site())\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "27c3abe1db4f04a4a276bf24a26d6e70bcf5a78b",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-query/sea-query-derive/src/iden/attr.rs",
    "func": "use std::convert::{TryFrom, TryInto};\n\nuse syn::spanned::Spanned;\nuse syn::{Attribute, Error, Expr, ExprLit, Ident, Lit, LitStr, Meta};\n\nuse super::{error::ErrorMsg, path::IdenPath};\n\n#[derive(PartialEq, Eq)]\npub(crate) enum IdenAttr {\n    Rename(String),\n    Method(Ident),\n    Flatten,\n}\n\nimpl IdenAttr {\n    fn extract_method(meta: Meta) -> syn::Result<Self> {\n        match meta {\n            Meta::NameValue(nv) => match nv.value {\n                Expr::Lit(ExprLit { lit, .. }) => match lit {\n                    Lit::Str(name) => {\n                        Ok(Self::Method(Ident::new(name.value().as_str(), name.span())))\n                    }\n                    _ => Err(Error::new_spanned(nv.eq_token, ErrorMsg::WrongLiteral)),\n                },\n                _ => Err(Error::new_spanned(nv, ErrorMsg::WrongLiteral)),\n            },\n            a => Err(Error::new_spanned(\n                a,\n                ErrorMsg::WrongNamedValueFormat(IdenPath::Method, IdenPath::Method),\n            )),\n        }\n    }\n\n    fn extract_iden(meta: Meta) -> syn::Result<Self> {\n        match &meta {\n            Meta::NameValue(nv) => match &nv.value {\n                Expr::Lit(ExprLit { lit, .. }) => match lit {\n                    Lit::Str(lit) => Ok(IdenAttr::Rename(lit.value())),\n                    _ => Err(Error::new_spanned(&nv.value, ErrorMsg::WrongLiteral)),\n                },\n                _ => Err(Error::new_spanned(nv, ErrorMsg::WrongLiteral)),\n            },\n            Meta::List(list) if list.path.is_ident(\"iden\") => {\n                let mut iden_attr: Option<Self> = None;\n                list.parse_nested_meta(|nested| {\n                    if nested.path.is_ident(&IdenPath::Flatten) {\n                        iden_attr = Some(IdenAttr::Flatten);\n                        Ok(())\n                    } else if nested.path.is_ident(&IdenPath::Rename) {\n                        let value = nested.value()?;\n                        let value: LitStr = value.parse()?;\n                        iden_attr = Some(IdenAttr::Rename(value.value()));\n                        Ok(())\n                    } else if nested.path.is_ident(&IdenPath::Method) {\n                        let value = nested.value()?;\n                        let value: LitStr = value.parse()?;\n                        iden_attr = Some(IdenAttr::Method(Ident::new(&value.value(), meta.span())));\n                        Ok(())\n                    } else {\n                        Err(Error::new_spanned(\n                            &meta,\n                            ErrorMsg::UnsupportedKeyword(nested.path.get_ident().unwrap().clone()),\n                        ))\n                    }\n                })?;\n                iden_attr.ok_or(Error::new_spanned(meta, ErrorMsg::WrongListFormat))\n            }\n            a => Err(Error::new_spanned(a, ErrorMsg::WrongAttributeFormat)),\n        }\n    }\n}\n\nimpl TryFrom<&Attribute> for IdenAttr {\n    type Error = Error;\n\n    fn try_from(value: &Attribute) -> Result<Self, Self::Error> {\n        value.meta.clone().try_into()\n    }\n}\n\nimpl TryFrom<Meta> for IdenAttr {\n    type Error = Error;\n\n    fn try_from(value: Meta) -> Result<Self, Self::Error> {\n        let path = value.path();\n        if path.is_ident(&IdenPath::Method) {\n            Self::extract_method(value)\n        } else if path.is_ident(&IdenPath::Iden) {\n            Self::extract_iden(value)\n        } else {\n            todo!()\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "36d15247b3b0b7cc7750c2db9fb7304feb3c185e",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-query/src/token.rs",
    "func": "//! Tokenizer for processing SQL.\n\nuse std::fmt::Write;\nuse std::iter::Iterator;\n\n#[derive(Debug, Default)]\npub struct Tokenizer {\n    pub chars: Vec<char>,\n    pub p: usize,\n}\n\n#[derive(Debug, PartialEq, Eq)]\npub enum Token {\n    Quoted(String),\n    Unquoted(String),\n    Space(String),\n    Punctuation(String),\n}\n\nimpl Tokenizer {\n    pub fn new(string: &str) -> Self {\n        Self {\n            chars: string.chars().collect(),\n            p: 0,\n        }\n    }\n\n    pub fn iter(self) -> impl Iterator<Item = Token> {\n        self\n    }\n\n    fn get(&self) -> char {\n        self.chars[self.p]\n    }\n\n    fn inc(&mut self) {\n        self.p += 1;\n    }\n\n    fn end(&self) -> bool {\n        self.p == self.chars.len()\n    }\n\n    fn space(&mut self) -> Option<Token> {\n        let mut string = String::new();\n        while !self.end() {\n            let c = self.get();\n            if Self::is_space(c) {\n                write!(string, \"{c}\").unwrap();\n            } else {\n                break;\n            }\n            self.inc();\n        }\n        if !string.is_empty() {\n            Some(Token::Space(string))\n        } else {\n            None\n        }\n    }\n\n    fn unquoted(&mut self) -> Option<Token> {\n        let mut string = String::new();\n        let mut first = true;\n        while !self.end() {\n            let c = self.get();\n            if Self::is_alphanumeric(c) {\n                write!(string, \"{c}\").unwrap();\n                first = false;\n                self.inc();\n            } else if !first && Self::is_identifier(c) {\n                write!(string, \"{c}\").unwrap();\n                self.inc();\n            } else {\n                break;\n            }\n        }\n        if !string.is_empty() {\n            Some(Token::Unquoted(string))\n        } else {\n            None\n        }\n    }\n\n    fn quoted(&mut self) -> Option<Token> {\n        let mut string = String::new();\n        let mut first = true;\n        let mut escape = false;\n        let mut start = ' ';\n        while !self.end() {\n            let c = self.get();\n            if first && Self::is_string_delimiter_start(c) {\n                write!(string, \"{c}\").unwrap();\n                first = false;\n                start = c;\n                self.inc();\n            } else if !first && !escape && Self::is_string_delimiter_end_for(start, c) {\n                write!(string, \"{c}\").unwrap();\n                self.inc();\n                if self.end() {\n                    break;\n                }\n                if !Self::is_string_escape_for(start, self.get()) {\n                    break;\n                } else {\n                    write!(string, \"{}\", self.get()).unwrap();\n                    self.inc();\n                }\n            } else if !first {\n                escape = !escape && Self::is_escape_char(c);\n                write!(string, \"{c}\").unwrap();\n                self.inc();\n            } else {\n                break;\n            }\n        }\n        if !string.is_empty() {\n            Some(Token::Quoted(string))\n        } else {\n            None\n        }\n    }\n\n    /// unquote a quoted string\n    fn unquote(mut self) -> String {\n        let mut string = String::new();\n        let mut first = true;\n        let mut escape = false;\n        let mut start = ' ';\n        while !self.end() {\n            let c = self.get();\n            if first && Self::is_string_delimiter_start(c) {\n                first = false;\n                start = c;\n                self.inc();\n            } else if !first && !escape && Self::is_string_delimiter_end_for(start, c) {\n                self.inc();\n                if self.end() {\n                    break;\n                }\n                if !Self::is_string_escape_for(start, self.get()) {\n                    break;\n                } else {\n                    write!(string, \"{c}\").unwrap();\n                    self.inc();\n                }\n            } else if !first {\n                escape = !escape && Self::is_escape_char(c);\n                write!(string, \"{c}\").unwrap();\n                self.inc();\n            } else {\n                break;\n            }\n        }\n        string\n    }\n\n    fn punctuation(&mut self) -> Option<Token> {\n        let mut string = String::new();\n        if !self.end() {\n            let c = self.get();\n            if !Self::is_space(c) && !Self::is_alphanumeric(c) {\n                write!(string, \"{c}\").unwrap();\n                self.inc();\n            }\n        }\n        if !string.is_empty() {\n            Some(Token::Punctuation(string))\n        } else {\n            None\n        }\n    }\n\n    fn is_space(c: char) -> bool {\n        matches!(c, ' ' | '\\t' | '\\r' | '\\n')\n    }\n\n    fn is_identifier(c: char) -> bool {\n        matches!(c, '_' | '$')\n    }\n\n    fn is_alphanumeric(c: char) -> bool {\n        c.is_alphabetic() || c.is_ascii_digit()\n    }\n\n    fn is_string_delimiter_start(c: char) -> bool {\n        matches!(c, '`' | '[' | '\\'' | '\"')\n    }\n\n    fn is_string_escape_for(start: char, c: char) -> bool {\n        match start {\n            '`' => c == '`',\n            '\\'' => c == '\\'',\n            '\"' => c == '\"',\n            _ => false,\n        }\n    }\n\n    fn is_string_delimiter_end_for(start: char, c: char) -> bool {\n        match start {\n            '`' => c == '`',\n            '[' => c == ']',\n            '\\'' => c == '\\'',\n            '\"' => c == '\"',\n            _ => false,\n        }\n    }\n\n    fn is_escape_char(c: char) -> bool {\n        c == '\\\\'\n    }\n}\n\nimpl Iterator for Tokenizer {\n    type Item = Token;\n\n    fn next(&mut self) -> Option<Self::Item> {\n        if let Some(space) = self.space() {\n            return Some(space);\n        }\n        if let Some(unquoted) = self.unquoted() {\n            return Some(unquoted);\n        }\n        if let Some(quoted) = self.quoted() {\n            return Some(quoted);\n        }\n        if let Some(punctuation) = self.punctuation() {\n            return Some(punctuation);\n        }\n        None\n    }\n}\n\nimpl Token {\n    pub fn is_quoted(&self) -> bool {\n        matches!(self, Self::Quoted(_))\n    }\n\n    pub fn is_unquoted(&self) -> bool {\n        matches!(self, Self::Unquoted(_))\n    }\n\n    pub fn is_space(&self) -> bool {\n        matches!(self, Self::Space(_))\n    }\n\n    pub fn is_punctuation(&self) -> bool {\n        matches!(self, Self::Punctuation(_))\n    }\n\n    pub fn as_str(&self) -> &str {\n        match self {\n            Self::Quoted(string) => string,\n            Self::Unquoted(string) => string,\n            Self::Space(string) => string,\n            Self::Punctuation(string) => string,\n        }\n    }\n\n    pub fn unquote(&self) -> Option<String> {\n        if self.is_quoted() {\n            let tokenizer = Tokenizer::new(self.as_str());\n            Some(tokenizer.unquote())\n        } else {\n            None\n        }\n    }\n}\n\nimpl std::fmt::Display for Token {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        write!(\n            f,\n            \"{}\",\n            match self {\n                Token::Unquoted(string) => string,\n                Token::Space(string) => string,\n                Token::Quoted(string) => string,\n                Token::Punctuation(string) => string,\n            }\n        )\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use pretty_assertions::assert_eq;\n\n    #[test]\n    fn test_0() {\n        let tokenizer = Tokenizer::new(\"\");\n        let tokens: Vec<Token> = tokenizer.iter().collect();\n        assert_eq!(tokens, vec![]);\n    }\n\n    #[test]\n    fn test_1() {\n        let string = \"SELECT * FROM `character`\";\n        let tokenizer = Tokenizer::new(string);\n        let tokens: Vec<Token> = tokenizer.iter().collect();\n        assert_eq!(\n            tokens,\n            vec![\n                Token::Unquoted(\"SELECT\".to_string()),\n                Token::Space(\" \".to_string()),\n                Token::Punctuation(\"*\".to_string()),\n                Token::Space(\" \".to_string()),\n                Token::Unquoted(\"FROM\".to_string()),\n                Token::Space(\" \".to_string()),\n                Token::Quoted(\"`character`\".to_string()),\n            ]\n        );\n        assert_eq!(\n            string,\n            tokens.iter().map(|x| x.to_string()).collect::<String>()\n        );\n    }\n\n    #[test]\n    fn test_2() {\n        let string = \"SELECT * FROM `character` WHERE id = ?\";\n        let tokenizer = Tokenizer::new(string);\n        let tokens: Vec<Token> = tokenizer.iter().collect();\n        assert_eq!(\n            tokens,\n            vec![\n                Token::Unquoted(\"SELECT\".to_string()),\n                Token::Space(\" \".to_string()),\n                Token::Punctuation(\"*\".to_string()),\n                Token::Space(\" \".to_string()),\n                Token::Unquoted(\"FROM\".to_string()),\n                Token::Space(\" \".to_string()),\n                Token::Quoted(\"`character`\".to_string()),\n                Token::Space(\" \".to_string()),\n                Token::Unquoted(\"WHERE\".to_string()),\n                Token::Space(\" \".to_string()),\n                Token::Unquoted(\"id\".to_string()),\n                Token::Space(\" \".to_string()),\n                Token::Punctuation(\"=\".to_string()),\n                Token::Space(\" \".to_string()),\n                Token::Punctuation(\"?\".to_string()),\n            ]\n        );\n        assert_eq!(\n            string,\n            tokens.iter().map(|x| x.to_string()).collect::<String>()\n        );\n    }\n\n    #[test]\n    fn test_3() {\n        let string = r#\"? = \"?\" \"#;\n        let tokenizer = Tokenizer::new(string);\n        let tokens: Vec<Token> = tokenizer.iter().collect();\n        assert_eq!(\n            tokens,\n            vec![\n                Token::Punctuation(\"?\".to_string()),\n                Token::Space(\" \".to_string()),\n                Token::Punctuation(\"=\".to_string()),\n                Token::Space(\" \".to_string()),\n                Token::Quoted(r#\"\"?\"\"#.to_string()),\n                Token::Space(\" \".to_string()),\n            ]\n        );\n        assert_eq!(\n            string,\n            tokens.iter().map(|x| x.to_string()).collect::<String>()\n        );\n    }\n\n    #[test]\n    fn test_4() {\n        let string = r#\"\"a\\\"bc\"\"#;\n        let tokenizer = Tokenizer::new(string);\n        let tokens: Vec<Token> = tokenizer.iter().collect();\n        assert_eq!(tokens, vec![Token::Quoted(\"\\\"a\\\\\\\"bc\\\"\".to_string())]);\n        assert_eq!(\n            string,\n            tokens.iter().map(|x| x.to_string()).collect::<String>()\n        );\n    }\n\n    #[test]\n    fn test_5() {\n        let string = \"abc123\";\n        let tokenizer = Tokenizer::new(string);\n        let tokens: Vec<Token> = tokenizer.iter().collect();\n        assert_eq!(tokens, vec![Token::Unquoted(string.to_string())]);\n        assert_eq!(\n            string,\n            tokens.iter().map(|x| x.to_string()).collect::<String>()\n        );\n    }\n\n    #[test]\n    fn test_6() {\n        let string = \"2.3*4\";\n        let tokenizer = Tokenizer::new(string);\n        let tokens: Vec<Token> = tokenizer.iter().collect();\n        assert_eq!(\n            tokens,\n            vec![\n                Token::Unquoted(\"2\".to_string()),\n                Token::Punctuation(\".\".to_string()),\n                Token::Unquoted(\"3\".to_string()),\n                Token::Punctuation(\"*\".to_string()),\n                Token::Unquoted(\"4\".to_string()),\n            ]\n        );\n        assert_eq!(\n            string,\n            tokens.iter().map(|x| x.to_string()).collect::<String>()\n        );\n    }\n\n    #[test]\n    fn test_7() {\n        let string = r#\"\"a\\\\\" B\"#;\n        let tokenizer = Tokenizer::new(string);\n        let tokens: Vec<Token> = tokenizer.iter().collect();\n        assert_eq!(\n            tokens,\n            vec![\n                Token::Quoted(\"\\\"a\\\\\\\\\\\"\".to_string()),\n                Token::Space(\" \".to_string()),\n                Token::Unquoted(\"B\".to_string()),\n            ]\n        );\n        assert_eq!(\n            string,\n            tokens.iter().map(|x| x.to_string()).collect::<String>()\n        );\n    }\n\n    #[test]\n    fn test_8() {\n        let string = r#\"`a\"b` \"#;\n        let tokenizer = Tokenizer::new(string);\n        let tokens: Vec<Token> = tokenizer.iter().collect();\n        assert_eq!(\n            tokens,\n            vec![\n                Token::Quoted(\"`a\\\"b`\".to_string()),\n                Token::Space(\" \".to_string()),\n            ]\n        );\n        assert_eq!(\n            string,\n            tokens.iter().map(|x| x.to_string()).collect::<String>()\n        );\n    }\n\n    #[test]\n    fn test_9() {\n        let string = r\"[ab] \";\n        let tokenizer = Tokenizer::new(string);\n        let tokens: Vec<Token> = tokenizer.iter().collect();\n        assert_eq!(\n            tokens,\n            vec![\n                Token::Quoted(\"[ab]\".to_string()),\n                Token::Space(\" \".to_string()),\n            ]\n        );\n        assert_eq!(\n            string,\n            tokens.iter().map(|x| x.to_string()).collect::<String>()\n        );\n    }\n\n    #[test]\n    fn test_10() {\n        let string = r#\" 'a\"b' \"#;\n        let tokenizer = Tokenizer::new(string);\n        let tokens: Vec<Token> = tokenizer.iter().collect();\n        assert_eq!(\n            tokens,\n            vec![\n                Token::Space(\" \".to_string()),\n                Token::Quoted(\"'a\\\"b'\".to_string()),\n                Token::Space(\" \".to_string()),\n            ]\n        );\n        assert_eq!(\n            string,\n            tokens.iter().map(|x| x.to_string()).collect::<String>()\n        );\n    }\n\n    #[test]\n    fn test_11() {\n        let string = r\" `a``b` \";\n        let tokenizer = Tokenizer::new(string);\n        let tokens: Vec<Token> = tokenizer.iter().collect();\n        assert_eq!(\n            tokens,\n            vec![\n                Token::Space(\" \".to_string()),\n                Token::Quoted(\"`a``b`\".to_string()),\n                Token::Space(\" \".to_string()),\n            ]\n        );\n        assert_eq!(\n            string,\n            tokens.iter().map(|x| x.to_string()).collect::<String>()\n        );\n    }\n\n    #[test]\n    fn test_12() {\n        let string = r\" 'a''b' \";\n        let tokenizer = Tokenizer::new(string);\n        let tokens: Vec<Token> = tokenizer.iter().collect();\n        assert_eq!(\n            tokens,\n            vec![\n                Token::Space(\" \".to_string()),\n                Token::Quoted(\"'a''b'\".to_string()),\n                Token::Space(\" \".to_string()),\n            ]\n        );\n        assert_eq!(\n            string,\n            tokens.iter().map(|x| x.to_string()).collect::<String>()\n        );\n    }\n\n    #[test]\n    fn test_13() {\n        let string = r\"(?)\";\n        let tokenizer = Tokenizer::new(string);\n        let tokens: Vec<Token> = tokenizer.iter().collect();\n        assert_eq!(\n            tokens,\n            vec![\n                Token::Punctuation(\"(\".to_string()),\n                Token::Punctuation(\"?\".to_string()),\n                Token::Punctuation(\")\".to_string()),\n            ]\n        );\n        assert_eq!(\n            string,\n            tokens.iter().map(|x| x.to_string()).collect::<String>()\n        );\n    }\n\n    #[test]\n    fn test_14() {\n        let string = r\"($1 = $2)\";\n        let tokenizer = Tokenizer::new(string);\n        let tokens: Vec<Token> = tokenizer.iter().collect();\n        assert_eq!(\n            tokens,\n            vec![\n                Token::Punctuation(\"(\".to_string()),\n                Token::Punctuation(\"$\".to_string()),\n                Token::Unquoted(\"1\".to_string()),\n                Token::Space(\" \".to_string()),\n                Token::Punctuation(\"=\".to_string()),\n                Token::Space(\" \".to_string()),\n                Token::Punctuation(\"$\".to_string()),\n                Token::Unquoted(\"2\".to_string()),\n                Token::Punctuation(\")\".to_string()),\n            ]\n        );\n        assert_eq!(\n            string,\n            tokens.iter().map(|x| x.to_string()).collect::<String>()\n        );\n    }\n\n    #[test]\n    fn test_15() {\n        let string = r#\" \"Hello World\" \"#;\n        let tokenizer = Tokenizer::new(string);\n        let tokens: Vec<Token> = tokenizer.iter().collect();\n        assert_eq!(\n            tokens,\n            vec![\n                Token::Space(\" \".to_string()),\n                Token::Quoted(\"\\\"Hello World\\\"\".to_string()),\n                Token::Space(\" \".to_string()),\n            ]\n        );\n        assert_eq!(\n            string,\n            tokens.iter().map(|x| x.to_string()).collect::<String>()\n        );\n    }\n\n    #[test]\n    fn test_16() {\n        let string = \"abc_$123\";\n        let tokenizer = Tokenizer::new(string);\n        let tokens: Vec<Token> = tokenizer.iter().collect();\n        assert_eq!(tokens, vec![Token::Unquoted(string.to_string())]);\n        assert_eq!(\n            string,\n            tokens.iter().map(|x| x.to_string()).collect::<String>()\n        );\n    }\n\n    #[test]\n    fn test_17() {\n        let string = \"$abc$123\";\n        let tokenizer = Tokenizer::new(string);\n        let tokens: Vec<Token> = tokenizer.iter().collect();\n        assert_eq!(\n            tokens,\n            vec![\n                Token::Punctuation(\"$\".to_string()),\n                Token::Unquoted(\"abc$123\".to_string()),\n            ]\n        );\n        assert_eq!(\n            string,\n            tokens.iter().map(|x| x.to_string()).collect::<String>()\n        );\n    }\n\n    #[test]\n    fn test_18() {\n        let string = \"_$abc_123$\";\n        let tokenizer = Tokenizer::new(string);\n        let tokens: Vec<Token> = tokenizer.iter().collect();\n        assert_eq!(\n            tokens,\n            vec![\n                Token::Punctuation(\"_\".to_string()),\n                Token::Punctuation(\"$\".to_string()),\n                Token::Unquoted(\"abc_123$\".to_string()),\n            ]\n        );\n        assert_eq!(\n            string,\n            tokens.iter().map(|x| x.to_string()).collect::<String>()\n        );\n    }\n\n    #[test]\n    fn test_19() {\n        let string = r#\"\"a\\\"bc\"\"#;\n        let tokenizer = Tokenizer::new(string);\n        assert_eq!(tokenizer.unquote(), \"a\\\\\\\"bc\".to_owned());\n    }\n\n    #[test]\n    fn test_20() {\n        let string = r#\"\"a\"\"bc\"\"#;\n        let tokenizer = Tokenizer::new(string);\n        assert_eq!(tokenizer.unquote(), \"a\\\"bc\".to_owned());\n    }\n\n    #[test]\n    fn test_21() {\n        assert_eq!(\n            Token::Quoted(\"'a\\\\nb'\".to_owned()).unquote().unwrap(),\n            \"a\\\\nb\".to_owned()\n        );\n    }\n\n    #[test]\n    fn test_22() {\n        let string = r#\" \"Hello\\nWorld\" \"#;\n        let tokenizer = Tokenizer::new(string);\n        let tokens: Vec<Token> = tokenizer.iter().collect();\n        assert_eq!(\n            tokens,\n            vec![\n                Token::Space(\" \".to_string()),\n                Token::Quoted(\"\\\"Hello\\\\nWorld\\\"\".to_string()),\n                Token::Space(\" \".to_string()),\n            ]\n        );\n        assert_eq!(\n            string,\n            tokens.iter().map(|x| x.to_string()).collect::<String>()\n        );\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "90072feed436f76ad0492f9e80ae01789a1a202f",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-query/src/error.rs",
    "func": "//! Error types used in sea-query.\n\n/// Result type for sea-query\npub type Result<T> = std::result::Result<T, Error>;\n\n#[derive(Debug, PartialEq, Eq)]\npub enum Error {\n    /// Column and value vector having different length\n    ColValNumMismatch { col_len: usize, val_len: usize },\n}\n\nimpl std::error::Error for Error {}\n\nimpl std::fmt::Display for Error {\n    fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {\n        match self {\n            Self::ColValNumMismatch { col_len, val_len } => write!(\n                f,\n                \"Columns and values length mismatch: {col_len} != {val_len}\"\n            ),\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "8fee69b642ef5fe96941e987fe888ec0bb87d5c9",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/ratatui/ratatui/tests/terminal.rs",
    "func": "use std::error::Error;\n\nuse ratatui::{\n    backend::TestBackend,\n    layout::Rect,\n    widgets::{Block, Paragraph, Widget},\n    Terminal, TerminalOptions, Viewport,\n};\n\n#[test]\nfn swap_buffer_clears_prev_buffer() {\n    let backend = TestBackend::new(100, 50);\n    let mut terminal = Terminal::new(backend).unwrap();\n    terminal\n        .current_buffer_mut()\n        .set_string(0, 0, \"Hello\", ratatui::style::Style::reset());\n    assert_eq!(terminal.current_buffer_mut().content()[0].symbol(), \"H\");\n    terminal.swap_buffers();\n    assert_eq!(terminal.current_buffer_mut().content()[0].symbol(), \" \");\n}\n\n#[test]\nfn terminal_draw_returns_the_completed_frame() -> Result<(), Box<dyn Error>> {\n    let backend = TestBackend::new(10, 10);\n    let mut terminal = Terminal::new(backend)?;\n    let frame = terminal.draw(|f| {\n        let paragraph = Paragraph::new(\"Test\");\n        f.render_widget(paragraph, f.area());\n    })?;\n    assert_eq!(frame.buffer[(0, 0)].symbol(), \"T\");\n    assert_eq!(frame.area, Rect::new(0, 0, 10, 10));\n    terminal.backend_mut().resize(8, 8);\n    let frame = terminal.draw(|f| {\n        let paragraph = Paragraph::new(\"test\");\n        f.render_widget(paragraph, f.area());\n    })?;\n    assert_eq!(frame.buffer[(0, 0)].symbol(), \"t\");\n    assert_eq!(frame.area, Rect::new(0, 0, 8, 8));\n    Ok(())\n}\n\n#[test]\nfn terminal_draw_increments_frame_count() -> Result<(), Box<dyn Error>> {\n    let backend = TestBackend::new(10, 10);\n    let mut terminal = Terminal::new(backend)?;\n    let frame = terminal.draw(|f| {\n        assert_eq!(f.count(), 0);\n        let paragraph = Paragraph::new(\"Test\");\n        f.render_widget(paragraph, f.area());\n    })?;\n    assert_eq!(frame.count, 0);\n    let frame = terminal.draw(|f| {\n        assert_eq!(f.count(), 1);\n        let paragraph = Paragraph::new(\"test\");\n        f.render_widget(paragraph, f.area());\n    })?;\n    assert_eq!(frame.count, 1);\n    let frame = terminal.draw(|f| {\n        assert_eq!(f.count(), 2);\n        let paragraph = Paragraph::new(\"test\");\n        f.render_widget(paragraph, f.area());\n    })?;\n    assert_eq!(frame.count, 2);\n    Ok(())\n}\n\n#[test]\nfn terminal_insert_before_moves_viewport() -> Result<(), Box<dyn Error>> {\n    // When we have a terminal with 5 lines, and a single line viewport, if we insert a\n    // number of lines less than the `terminal height - viewport height` it should move\n    // viewport down to accommodate the new lines.\n\n    let backend = TestBackend::new(20, 5);\n    let mut terminal = Terminal::with_options(\n        backend,\n        TerminalOptions {\n            viewport: Viewport::Inline(1),\n        },\n    )?;\n\n    // insert_before cannot guarantee the contents of the viewport remain unharmed\n    // by potential scrolling as such it is necessary to call draw afterwards to\n    // redraw the contents of the viewport over the newly designated area.\n    terminal.insert_before(2, |buf| {\n        Paragraph::new(vec![\n            \"------ Line 1 ------\".into(),\n            \"------ Line 2 ------\".into(),\n        ])\n        .render(buf.area, buf);\n    })?;\n\n    terminal.draw(|f| {\n        let paragraph = Paragraph::new(\"[---- Viewport ----]\");\n        f.render_widget(paragraph, f.area());\n    })?;\n\n    terminal.backend().assert_buffer_lines([\n        \"------ Line 1 ------\",\n        \"------ Line 2 ------\",\n        \"[---- Viewport ----]\",\n        \"                    \",\n        \"                    \",\n    ]);\n    terminal.backend().assert_scrollback_empty();\n\n    Ok(())\n}\n\n#[test]\n#[cfg(feature = \"scrolling-regions\")]\nfn terminal_insert_before_moves_viewport_does_not_clobber() -> Result<(), Box<dyn Error>> {\n    // This is like terminal_insert_before_moves_viewport, except it draws first before calling\n    // insert_before, and doesn't draw again afterwards. When using scrolling regions, we\n    // shouldn't clobber the viewport.\n\n    let backend = TestBackend::new(20, 5);\n    let mut terminal = Terminal::with_options(\n        backend,\n        TerminalOptions {\n            viewport: Viewport::Inline(1),\n        },\n    )?;\n\n    terminal.draw(|f| {\n        let paragraph = Paragraph::new(\"[---- Viewport ----]\");\n        f.render_widget(paragraph, f.area());\n    })?;\n\n    terminal.insert_before(2, |buf| {\n        Paragraph::new(vec![\n            \"------ Line 1 ------\".into(),\n            \"------ Line 2 ------\".into(),\n        ])\n        .render(buf.area, buf);\n    })?;\n\n    terminal.backend().assert_scrollback_empty();\n    terminal.backend().assert_buffer_lines([\n        \"------ Line 1 ------\",\n        \"------ Line 2 ------\",\n        \"[---- Viewport ----]\",\n        \"                    \",\n        \"                    \",\n    ]);\n\n    Ok(())\n}\n\n#[test]\nfn terminal_insert_before_scrolls_on_large_input() -> Result<(), Box<dyn Error>> {\n    // When we have a terminal with 5 lines, and a single line viewport, if we insert many\n    // lines before the viewport (greater than `terminal height - viewport height`) it should\n    // move the viewport down to the bottom of the terminal and scroll all lines above the viewport\n    // until all have been added to the buffer.\n\n    let backend = TestBackend::new(20, 5);\n    let mut terminal = Terminal::with_options(\n        backend,\n        TerminalOptions {\n            viewport: Viewport::Inline(1),\n        },\n    )?;\n\n    terminal.insert_before(5, |buf| {\n        Paragraph::new(vec![\n            \"------ Line 1 ------\".into(),\n            \"------ Line 2 ------\".into(),\n            \"------ Line 3 ------\".into(),\n            \"------ Line 4 ------\".into(),\n            \"------ Line 5 ------\".into(),\n        ])\n        .render(buf.area, buf);\n    })?;\n\n    terminal.draw(|f| {\n        let paragraph = Paragraph::new(\"[---- Viewport ----]\");\n        f.render_widget(paragraph, f.area());\n    })?;\n\n    terminal.backend().assert_buffer_lines([\n        \"------ Line 2 ------\",\n        \"------ Line 3 ------\",\n        \"------ Line 4 ------\",\n        \"------ Line 5 ------\",\n        \"[---- Viewport ----]\",\n    ]);\n    terminal\n        .backend()\n        .assert_scrollback_lines([\"------ Line 1 ------\"]);\n\n    Ok(())\n}\n\n#[test]\n#[cfg(feature = \"scrolling-regions\")]\nfn terminal_insert_before_scrolls_on_large_input_does_not_clobber() -> Result<(), Box<dyn Error>> {\n    // This is like terminal_insert_scrolls_on_large_input, except it draws first before calling\n    // insert_before, and doesn't draw again afterwards. When using scrolling regions, we\n    // shouldn't clobber the viewport.\n\n    let backend = TestBackend::new(20, 5);\n    let mut terminal = Terminal::with_options(\n        backend,\n        TerminalOptions {\n            viewport: Viewport::Inline(1),\n        },\n    )?;\n\n    terminal.draw(|f| {\n        let paragraph = Paragraph::new(\"[---- Viewport ----]\");\n        f.render_widget(paragraph, f.area());\n    })?;\n\n    terminal.insert_before(5, |buf| {\n        Paragraph::new(vec![\n            \"------ Line 1 ------\".into(),\n            \"------ Line 2 ------\".into(),\n            \"------ Line 3 ------\".into(),\n            \"------ Line 4 ------\".into(),\n            \"------ Line 5 ------\".into(),\n        ])\n        .render(buf.area, buf);\n    })?;\n\n    terminal\n        .backend()\n        .assert_scrollback_lines([\"------ Line 1 ------\"]);\n    terminal.backend().assert_buffer_lines([\n        \"------ Line 2 ------\",\n        \"------ Line 3 ------\",\n        \"------ Line 4 ------\",\n        \"------ Line 5 ------\",\n        \"[---- Viewport ----]\",\n    ]);\n\n    Ok(())\n}\n\n#[test]\nfn terminal_insert_before_scrolls_on_many_inserts() -> Result<(), Box<dyn Error>> {\n    // This test ensures similar behaviour to `terminal_insert_before_scrolls_on_large_input`\n    // but covers a bug previously present whereby multiple small insertions\n    // (less than `terminal height - viewport height`) would have disparate behaviour to one large\n    // insertion. This was caused by an undocumented cap on the height to be inserted, which has now\n    // been removed.\n\n    let backend = TestBackend::new(20, 5);\n    let mut terminal = Terminal::with_options(\n        backend,\n        TerminalOptions {\n            viewport: Viewport::Inline(1),\n        },\n    )?;\n\n    terminal.insert_before(1, |buf| {\n        Paragraph::new(vec![\"------ Line 1 ------\".into()]).render(buf.area, buf);\n    })?;\n\n    terminal.insert_before(1, |buf| {\n        Paragraph::new(vec![\"------ Line 2 ------\".into()]).render(buf.area, buf);\n    })?;\n\n    terminal.insert_before(1, |buf| {\n        Paragraph::new(vec![\"------ Line 3 ------\".into()]).render(buf.area, buf);\n    })?;\n\n    terminal.insert_before(1, |buf| {\n        Paragraph::new(vec![\"------ Line 4 ------\".into()]).render(buf.area, buf);\n    })?;\n\n    terminal.insert_before(1, |buf| {\n        Paragraph::new(vec![\"------ Line 5 ------\".into()]).render(buf.area, buf);\n    })?;\n\n    terminal.draw(|f| {\n        let paragraph = Paragraph::new(\"[---- Viewport ----]\");\n        f.render_widget(paragraph, f.area());\n    })?;\n\n    terminal.backend().assert_buffer_lines([\n        \"------ Line 2 ------\",\n        \"------ Line 3 ------\",\n        \"------ Line 4 ------\",\n        \"------ Line 5 ------\",\n        \"[---- Viewport ----]\",\n    ]);\n    terminal\n        .backend()\n        .assert_scrollback_lines([\"------ Line 1 ------\"]);\n\n    Ok(())\n}\n\n#[test]\n#[cfg(feature = \"scrolling-regions\")]\nfn terminal_insert_before_scrolls_on_many_inserts_does_not_clobber() -> Result<(), Box<dyn Error>> {\n    // This is like terminal_insert_before_scrolls_on_many_inserts, except it draws first before\n    // calling insert_before, and doesn't draw again afterwards. When using scrolling regions, we\n    // shouldn't clobber the viewport.\n\n    let backend = TestBackend::new(20, 5);\n    let mut terminal = Terminal::with_options(\n        backend,\n        TerminalOptions {\n            viewport: Viewport::Inline(1),\n        },\n    )?;\n\n    terminal.draw(|f| {\n        let paragraph = Paragraph::new(\"[---- Viewport ----]\");\n        f.render_widget(paragraph, f.area());\n    })?;\n\n    terminal.insert_before(1, |buf| {\n        Paragraph::new(vec![\"------ Line 1 ------\".into()]).render(buf.area, buf);\n    })?;\n\n    terminal.insert_before(1, |buf| {\n        Paragraph::new(vec![\"------ Line 2 ------\".into()]).render(buf.area, buf);\n    })?;\n\n    terminal.insert_before(1, |buf| {\n        Paragraph::new(vec![\"------ Line 3 ------\".into()]).render(buf.area, buf);\n    })?;\n\n    terminal.insert_before(1, |buf| {\n        Paragraph::new(vec![\"------ Line 4 ------\".into()]).render(buf.area, buf);\n    })?;\n\n    terminal.insert_before(1, |buf| {\n        Paragraph::new(vec![\"------ Line 5 ------\".into()]).render(buf.area, buf);\n    })?;\n\n    terminal\n        .backend()\n        .assert_scrollback_lines([\"------ Line 1 ------\"]);\n    terminal.backend().assert_buffer_lines([\n        \"------ Line 2 ------\",\n        \"------ Line 3 ------\",\n        \"------ Line 4 ------\",\n        \"------ Line 5 ------\",\n        \"[---- Viewport ----]\",\n    ]);\n\n    Ok(())\n}\n\n#[test]\nfn terminal_insert_before_large_viewport() -> Result<(), Box<dyn Error>> {\n    // This test covers a bug previously present whereby doing an insert_before when the\n    // viewport covered the entire screen would cause a panic.\n\n    let backend = TestBackend::new(20, 3);\n    let mut terminal = Terminal::with_options(\n        backend,\n        TerminalOptions {\n            viewport: Viewport::Inline(3),\n        },\n    )?;\n\n    terminal.insert_before(1, |buf| {\n        Paragraph::new(vec![\"------ Line 1 ------\".into()]).render(buf.area, buf);\n    })?;\n\n    terminal.insert_before(3, |buf| {\n        Paragraph::new(vec![\n            \"------ Line 2 ------\".into(),\n            \"------ Line 3 ------\".into(),\n            \"------ Line 4 ------\".into(),\n        ])\n        .render(buf.area, buf);\n    })?;\n\n    terminal.insert_before(7, |buf| {\n        Paragraph::new(vec![\n            \"------ Line 5 ------\".into(),\n            \"------ Line 6 ------\".into(),\n            \"------ Line 7 ------\".into(),\n            \"------ Line 8 ------\".into(),\n            \"------ Line 9 ------\".into(),\n            \"----- Line 10 ------\".into(),\n            \"----- Line 11 ------\".into(),\n        ])\n        .render(buf.area, buf);\n    })?;\n\n    terminal.draw(|f| {\n        let paragraph = Paragraph::new(\"Viewport\")\n            .centered()\n            .block(Block::bordered());\n        f.render_widget(paragraph, f.area());\n    })?;\n\n    terminal.backend().assert_buffer_lines([\n        \"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\",\n        \"\u2502     Viewport     \u2502\",\n        \"\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\",\n    ]);\n    terminal.backend().assert_scrollback_lines([\n        \"------ Line 1 ------\",\n        \"------ Line 2 ------\",\n        \"------ Line 3 ------\",\n        \"------ Line 4 ------\",\n        \"------ Line 5 ------\",\n        \"------ Line 6 ------\",\n        \"------ Line 7 ------\",\n        \"------ Line 8 ------\",\n        \"------ Line 9 ------\",\n        \"----- Line 10 ------\",\n        \"----- Line 11 ------\",\n    ]);\n\n    Ok(())\n}\n\n#[test]\n#[cfg(feature = \"scrolling-regions\")]\nfn terminal_insert_before_large_viewport_does_not_clobber() -> Result<(), Box<dyn Error>> {\n    // This is like terminal_insert_before_large_viewport, except it draws first before calling\n    // insert_before, and doesn't draw again afterwards. When using scrolling regions, we shouldn't\n    // clobber the viewport.\n\n    let backend = TestBackend::new(20, 3);\n    let mut terminal = Terminal::with_options(\n        backend,\n        TerminalOptions {\n            viewport: Viewport::Inline(3),\n        },\n    )?;\n\n    terminal.draw(|f| {\n        let paragraph = Paragraph::new(\"Viewport\")\n            .centered()\n            .block(Block::bordered());\n        f.render_widget(paragraph, f.area());\n    })?;\n\n    terminal.insert_before(1, |buf| {\n        Paragraph::new(vec![\"------ Line 1 ------\".into()]).render(buf.area, buf);\n    })?;\n\n    terminal.insert_before(3, |buf| {\n        Paragraph::new(vec![\n            \"------ Line 2 ------\".into(),\n            \"------ Line 3 ------\".into(),\n            \"------ Line 4 ------\".into(),\n        ])\n        .render(buf.area, buf);\n    })?;\n\n    terminal.insert_before(7, |buf| {\n        Paragraph::new(vec![\n            \"------ Line 5 ------\".into(),\n            \"------ Line 6 ------\".into(),\n            \"------ Line 7 ------\".into(),\n            \"------ Line 8 ------\".into(),\n            \"------ Line 9 ------\".into(),\n            \"----- Line 10 ------\".into(),\n            \"----- Line 11 ------\".into(),\n        ])\n        .render(buf.area, buf);\n    })?;\n\n    terminal.backend().assert_buffer_lines([\n        \"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\",\n        \"\u2502     Viewport     \u2502\",\n        \"\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\",\n    ]);\n    terminal.backend().assert_scrollback_lines([\n        \"------ Line 1 ------\",\n        \"------ Line 2 ------\",\n        \"------ Line 3 ------\",\n        \"------ Line 4 ------\",\n        \"------ Line 5 ------\",\n        \"------ Line 6 ------\",\n        \"------ Line 7 ------\",\n        \"------ Line 8 ------\",\n        \"------ Line 9 ------\",\n        \"----- Line 10 ------\",\n        \"----- Line 11 ------\",\n    ]);\n\n    Ok(())\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "4a85cd9afb062a0a3b75b6f87ea66a2ad82c56f9",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/ratatui/ratatui/tests/widgets_barchart.rs",
    "func": "use ratatui::{\n    backend::TestBackend,\n    buffer::Buffer,\n    style::{Color, Style},\n    widgets::{Bar, BarChart, BarGroup, Block},\n    Terminal,\n};\n\n// check that bars fill up correctly up to max value\n#[test]\nfn widgets_barchart_not_full_below_max_value() {\n    let backend = TestBackend::new(30, 10);\n    let mut terminal = Terminal::new(backend).unwrap();\n    terminal\n        .draw(|f| {\n            let barchart = BarChart::default()\n                .block(Block::bordered())\n                .data(&[(\"empty\", 0), (\"half\", 50), (\"almost\", 99), (\"full\", 100)])\n                .max(100)\n                .bar_width(7)\n                .bar_gap(0);\n            f.render_widget(barchart, f.area());\n        })\n        .unwrap();\n    terminal.backend().assert_buffer_lines([\n        \"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\",\n        \"\u2502              \u2587\u2587\u2587\u2587\u2587\u2587\u2587\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2502\",\n        \"\u2502              \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2502\",\n        \"\u2502              \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2502\",\n        \"\u2502       \u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2502\",\n        \"\u2502       \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2502\",\n        \"\u2502       \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2502\",\n        \"\u2502       \u2588\u258850\u2588\u2588\u2588\u2588\u258899\u2588\u2588\u2588\u2588\u2588100\u2588\u2588\u2502\",\n        \"\u2502 empty  half  almost  full  \u2502\",\n        \"\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\",\n    ]);\n}\n\n#[test]\nfn widgets_barchart_group() {\n    const TERMINAL_HEIGHT: u16 = 11;\n    let backend = TestBackend::new(35, TERMINAL_HEIGHT);\n    let mut terminal = Terminal::new(backend).unwrap();\n    terminal\n        .draw(|f| {\n            let barchart = BarChart::default()\n                .block(Block::bordered())\n                .data(\n                    BarGroup::default().label(\"Mar\").bars(&[\n                        Bar::default()\n                            .value(10)\n                            .label(\"C1\")\n                            .style(Style::default().fg(Color::Red))\n                            .value_style(Style::default().fg(Color::Blue)),\n                        Bar::default()\n                            .value(20)\n                            .style(Style::default().fg(Color::Green))\n                            .text_value(\"20M\"),\n                    ]),\n                )\n                .data(&vec![(\"C1\", 50), (\"C2\", 40)])\n                .data(&[(\"C1\", 60), (\"C2\", 90)])\n                .data(&[(\"xx\", 10), (\"xx\", 10)])\n                .group_gap(2)\n                .bar_width(4)\n                .bar_gap(1);\n            f.render_widget(barchart, f.area());\n        })\n        .unwrap();\n\n    let mut expected = Buffer::with_lines([\n        \"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\",\n        \"\u2502                             \u2588\u2588\u2588\u2588\u2502\",\n        \"\u2502                             \u2588\u2588\u2588\u2588\u2502\",\n        \"\u2502                        \u2585\u2585\u2585\u2585 \u2588\u2588\u2588\u2588\u2502\",\n        \"\u2502            \u2587\u2587\u2587\u2587        \u2588\u2588\u2588\u2588 \u2588\u2588\u2588\u2588\u2502\",\n        \"\u2502            \u2588\u2588\u2588\u2588 \u2588\u2588\u2588\u2588   \u2588\u2588\u2588\u2588 \u2588\u2588\u2588\u2588\u2502\",\n        \"\u2502     \u2584\u2584\u2584\u2584   \u2588\u2588\u2588\u2588 \u2588\u2588\u2588\u2588   \u2588\u2588\u2588\u2588 \u2588\u2588\u2588\u2588\u2502\",\n        \"\u2502\u258610\u2586 20M\u2588   \u258850\u2588 \u258840\u2588   \u258860\u2588 \u258890\u2588\u2502\",\n        \"\u2502 C1          C1   C2     C1   C2 \u2502\",\n        \"\u2502Mar                              \u2502\",\n        \"\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\",\n    ]);\n    for y in 1..(TERMINAL_HEIGHT - 3) {\n        for x in 1..5 {\n            expected[(x, y)].set_fg(Color::Red);\n            expected[(x + 5, y)].set_fg(Color::Green);\n        }\n    }\n    expected[(2, 7)].set_fg(Color::Blue);\n    expected[(3, 7)].set_fg(Color::Blue);\n    terminal.backend().assert_buffer(&expected);\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "fd5aa9b08c78a3d1e40542863e157023192cfa2e",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/ratatui/ratatui/examples/colors_rgb.rs",
    "func": "//! # [Ratatui] `Colors_RGB` example\n//!\n//! The latest version of this example is available in the [examples] folder in the repository.\n//!\n//! Please note that the examples are designed to be run against the `main` branch of the Github\n//! repository. This means that you may not be able to compile with the latest release version on\n//! crates.io, or the one that you have installed locally.\n//!\n//! See the [examples readme] for more information on finding examples that match the version of the\n//! library you are using.\n//!\n//! [Ratatui]: https://github.com/ratatui/ratatui\n//! [examples]: https://github.com/ratatui/ratatui/blob/main/examples\n//! [examples readme]: https://github.com/ratatui/ratatui/blob/main/examples/README.md\n\n// This example shows the full range of RGB colors that can be displayed in the terminal.\n//\n// Requires a terminal that supports 24-bit color (true color) and unicode.\n//\n// This example also demonstrates how implementing the Widget trait on a mutable reference\n// allows the widget to update its state while it is being rendered. This allows the fps\n// widget to update the fps calculation and the colors widget to update a cached version of\n// the colors to render instead of recalculating them every frame.\n//\n// This is an alternative to using the `StatefulWidget` trait and a separate state struct. It\n// is useful when the state is only used by the widget and doesn't need to be shared with\n// other widgets.\n\nuse std::time::{Duration, Instant};\n\nuse color_eyre::Result;\nuse palette::{convert::FromColorUnclamped, Okhsv, Srgb};\nuse ratatui::{\n    buffer::Buffer,\n    crossterm::event::{self, Event, KeyCode, KeyEventKind},\n    layout::{Constraint, Layout, Position, Rect},\n    style::Color,\n    text::Text,\n    widgets::Widget,\n    DefaultTerminal,\n};\n\nfn main() -> Result<()> {\n    color_eyre::install()?;\n    let terminal = ratatui::init();\n    let app_result = App::default().run(terminal);\n    ratatui::restore();\n    app_result\n}\n\n#[derive(Debug, Default)]\nstruct App {\n    /// The current state of the app (running or quit)\n    state: AppState,\n\n    /// A widget that displays the current frames per second\n    fps_widget: FpsWidget,\n\n    /// A widget that displays the full range of RGB colors that can be displayed in the terminal.\n    colors_widget: ColorsWidget,\n}\n\n#[derive(Debug, Default, PartialEq, Eq)]\nenum AppState {\n    /// The app is running\n    #[default]\n    Running,\n\n    /// The user has requested the app to quit\n    Quit,\n}\n\n/// A widget that displays the current frames per second\n#[derive(Debug)]\nstruct FpsWidget {\n    /// The number of elapsed frames that have passed - used to calculate the fps\n    frame_count: usize,\n\n    /// The last instant that the fps was calculated\n    last_instant: Instant,\n\n    /// The current frames per second\n    fps: Option<f32>,\n}\n\n/// A widget that displays the full range of RGB colors that can be displayed in the terminal.\n///\n/// This widget is animated and will change colors over time.\n#[derive(Debug, Default)]\nstruct ColorsWidget {\n    /// The colors to render - should be double the height of the area as we render two rows of\n    /// pixels for each row of the widget using the half block character. This is computed any time\n    /// the size of the widget changes.\n    colors: Vec<Vec<Color>>,\n\n    /// the number of elapsed frames that have passed - used to animate the colors by shifting the\n    /// x index by the frame number\n    frame_count: usize,\n}\n\nimpl App {\n    /// Run the app\n    ///\n    /// This is the main event loop for the app.\n    pub fn run(mut self, mut terminal: DefaultTerminal) -> Result<()> {\n        while self.is_running() {\n            terminal.draw(|frame| frame.render_widget(&mut self, frame.area()))?;\n            self.handle_events()?;\n        }\n        Ok(())\n    }\n\n    const fn is_running(&self) -> bool {\n        matches!(self.state, AppState::Running)\n    }\n\n    /// Handle any events that have occurred since the last time the app was rendered.\n    ///\n    /// Currently, this only handles the q key to quit the app.\n    fn handle_events(&mut self) -> Result<()> {\n        // Ensure that the app only blocks for a period that allows the app to render at\n        // approximately 60 FPS (this doesn't account for the time to render the frame, and will\n        // also update the app immediately any time an event occurs)\n        let timeout = Duration::from_secs_f32(1.0 / 60.0);\n        if event::poll(timeout)? {\n            if let Event::Key(key) = event::read()? {\n                if key.kind == KeyEventKind::Press && key.code == KeyCode::Char('q') {\n                    self.state = AppState::Quit;\n                };\n            }\n        }\n        Ok(())\n    }\n}\n\n/// Implement the Widget trait for &mut App so that it can be rendered\n///\n/// This is implemented on a mutable reference so that the app can update its state while it is\n/// being rendered. This allows the fps widget to update the fps calculation and the colors widget\n/// to update the colors to render.\nimpl Widget for &mut App {\n    fn render(self, area: Rect, buf: &mut Buffer) {\n        use Constraint::{Length, Min};\n        let [top, colors] = Layout::vertical([Length(1), Min(0)]).areas(area);\n        let [title, fps] = Layout::horizontal([Min(0), Length(8)]).areas(top);\n        Text::from(\"colors_rgb example. Press q to quit\")\n            .centered()\n            .render(title, buf);\n        self.fps_widget.render(fps, buf);\n        self.colors_widget.render(colors, buf);\n    }\n}\n\n/// Default impl for `FpsWidget`\n///\n/// Manual impl is required because we need to initialize the `last_instant` field to the current\n/// instant.\nimpl Default for FpsWidget {\n    fn default() -> Self {\n        Self {\n            frame_count: 0,\n            last_instant: Instant::now(),\n            fps: None,\n        }\n    }\n}\n\n/// Widget impl for `FpsWidget`\n///\n/// This is implemented on a mutable reference so that we can update the frame count and fps\n/// calculation while rendering.\nimpl Widget for &mut FpsWidget {\n    fn render(self, area: Rect, buf: &mut Buffer) {\n        self.calculate_fps();\n        if let Some(fps) = self.fps {\n            let text = format!(\"{fps:.1} fps\");\n            Text::from(text).render(area, buf);\n        }\n    }\n}\n\nimpl FpsWidget {\n    /// Update the fps calculation.\n    ///\n    /// This updates the fps once a second, but only if the widget has rendered at least 2 frames\n    /// since the last calculation. This avoids noise in the fps calculation when rendering on slow\n    /// machines that can't render at least 2 frames per second.\n    #[allow(clippy::cast_precision_loss)]\n    fn calculate_fps(&mut self) {\n        self.frame_count += 1;\n        let elapsed = self.last_instant.elapsed();\n        if elapsed > Duration::from_secs(1) && self.frame_count > 2 {\n            self.fps = Some(self.frame_count as f32 / elapsed.as_secs_f32());\n            self.frame_count = 0;\n            self.last_instant = Instant::now();\n        }\n    }\n}\n\n/// Widget impl for `ColorsWidget`\n///\n/// This is implemented on a mutable reference so that we can update the frame count and store a\n/// cached version of the colors to render instead of recalculating them every frame.\nimpl Widget for &mut ColorsWidget {\n    /// Render the widget\n    fn render(self, area: Rect, buf: &mut Buffer) {\n        self.setup_colors(area);\n        let colors = &self.colors;\n        for (xi, x) in (area.left()..area.right()).enumerate() {\n            // animate the colors by shifting the x index by the frame number\n            let xi = (xi + self.frame_count) % (area.width as usize);\n            for (yi, y) in (area.top()..area.bottom()).enumerate() {\n                // render a half block character for each row of pixels with the foreground color\n                // set to the color of the pixel and the background color set to the color of the\n                // pixel below it\n                let fg = colors[yi * 2][xi];\n                let bg = colors[yi * 2 + 1][xi];\n                buf[Position::new(x, y)].set_char('\u2580').set_fg(fg).set_bg(bg);\n            }\n        }\n        self.frame_count += 1;\n    }\n}\n\nimpl ColorsWidget {\n    /// Setup the colors to render.\n    ///\n    /// This is called once per frame to setup the colors to render. It caches the colors so that\n    /// they don't need to be recalculated every frame.\n    #[allow(clippy::cast_precision_loss)]\n    fn setup_colors(&mut self, size: Rect) {\n        let Rect { width, height, .. } = size;\n        // double the height because each screen row has two rows of half block pixels\n        let height = height as usize * 2;\n        let width = width as usize;\n        // only update the colors if the size has changed since the last time we rendered\n        if self.colors.len() == height && self.colors[0].len() == width {\n            return;\n        }\n        self.colors = Vec::with_capacity(height);\n        for y in 0..height {\n            let mut row = Vec::with_capacity(width);\n            for x in 0..width {\n                let hue = x as f32 * 360.0 / width as f32;\n                let value = (height - y) as f32 / height as f32;\n                let saturation = Okhsv::max_saturation();\n                let color = Okhsv::new(hue, saturation, value);\n                let color = Srgb::<f32>::from_color_unclamped(color);\n                let color: Srgb<u8> = color.into_format();\n                let color = Color::Rgb(color.red, color.green, color.blue);\n                row.push(color);\n            }\n            self.colors.push(row);\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "65701502cec258f4549f382d9947da345e581ff6",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/ratatui/ratatui/src/lib.rs",
    "func": "// show the feature flags in the generated documentation\n#![cfg_attr(docsrs, feature(doc_cfg))]\n#![cfg_attr(docsrs, feature(doc_auto_cfg))]\n#![doc(\n    html_logo_url = \"https://raw.githubusercontent.com/ratatui/ratatui/main/assets/logo.png\",\n    html_favicon_url = \"https://raw.githubusercontent.com/ratatui/ratatui/main/assets/favicon.ico\"\n)]\n#![warn(missing_docs)]\n//! ![Demo](https://github.com/ratatui/ratatui/blob/87ae72dbc756067c97f6400d3e2a58eeb383776e/examples/demo2-destroy.gif?raw=true)\n//!\n//! <div align=\"center\">\n//!\n//! [![Crate Badge]][Crate] [![Docs Badge]][API Docs] [![CI Badge]][CI Workflow] [![Deps.rs\n//! Badge]][Deps.rs]<br> [![Codecov Badge]][Codecov] [![License Badge]](./LICENSE) [![Sponsors\n//! Badge]][GitHub Sponsors]<br> [![Discord Badge]][Discord Server] [![Matrix Badge]][Matrix]\n//! [![Forum Badge]][Forum]<br>\n//!\n//! [Ratatui Website] \u00b7 [API Docs] \u00b7 [Examples] \u00b7 [Changelog] \u00b7 [Breaking Changes]<br>\n//! [Contributing] \u00b7 [Report a bug] \u00b7 [Request a Feature] \u00b7 [Create a Pull Request]\n//!\n//! </div>\n//!\n//! # Ratatui\n//!\n//! [Ratatui][Ratatui Website] is a crate for cooking up terminal user interfaces in Rust. It is a\n//! lightweight library that provides a set of widgets and utilities to build complex Rust TUIs.\n//! Ratatui was forked from the [tui-rs] crate in 2023 in order to continue its development.\n//!\n//! ## Quickstart\n//!\n//! Add `ratatui` and `crossterm` as dependencies to your cargo.toml:\n//!\n//! ```shell\n//! cargo add ratatui crossterm\n//! ```\n//!\n//! Then you can create a simple \"Hello World\" application:\n//!\n//! ```rust,no_run\n//! use crossterm::event::{self, Event};\n//! use ratatui::{text::Text, Frame};\n//!\n//! fn main() {\n//!     let mut terminal = ratatui::init();\n//!     loop {\n//!         terminal.draw(draw).expect(\"failed to draw frame\");\n//!         if matches!(event::read().expect(\"failed to read event\"), Event::Key(_)) {\n//!             break;\n//!         }\n//!     }\n//!     ratatui::restore();\n//! }\n//!\n//! fn draw(frame: &mut Frame) {\n//!     let text = Text::raw(\"Hello World!\");\n//!     frame.render_widget(text, frame.area());\n//! }\n//! ```\n//!\n//! The full code for this example which contains a little more detail is in the [Examples]\n//! directory. For more guidance on different ways to structure your application see the\n//! [Application Patterns] and [Hello World tutorial] sections in the [Ratatui Website] and the\n//! various [Examples]. There are also several starter templates available in the [templates]\n//! repository.\n//!\n//! ## Other documentation\n//!\n//! - [Ratatui Website] - explains the library's concepts and provides step-by-step tutorials\n//! - [Ratatui Forum][Forum] - a place to ask questions and discuss the library\n//! - [API Docs] - the full API documentation for the library on docs.rs.\n//! - [Examples] - a collection of examples that demonstrate how to use the library.\n//! - [Contributing] - Please read this if you are interested in contributing to the project.\n//! - [Changelog] - generated by [git-cliff] utilizing [Conventional Commits].\n//! - [Breaking Changes] - a list of breaking changes in the library.\n//!\n//! You can also watch the [FOSDEM 2024 talk] about Ratatui which gives a brief introduction to\n//! terminal user interfaces and showcases the features of Ratatui, along with a hello world demo.\n//!\n//! ## Introduction\n//!\n//! Ratatui is based on the principle of immediate rendering with intermediate buffers. This means\n//! that for each frame, your app must render all widgets that are supposed to be part of the UI.\n//! This is in contrast to the retained mode style of rendering where widgets are updated and then\n//! automatically redrawn on the next frame. See the [Rendering] section of the [Ratatui Website]\n//! for more info.\n//!\n//! Ratatui uses [Crossterm] by default as it works on most platforms. See the [Installation]\n//! section of the [Ratatui Website] for more details on how to use other backends ([Termion] /\n//! [Termwiz]).\n//!\n//! Every application built with `ratatui` needs to implement the following steps:\n//!\n//! - Initialize the terminal\n//! - A main loop that:\n//!   - Draws the UI\n//!   - Handles input events\n//! - Restore the terminal state\n//!\n//! ### Initialize and restore the terminal\n//!\n//! The [`Terminal`] type is the main entry point for any Ratatui application. It is generic over a\n//! a choice of [`Backend`] implementations that each provide functionality to draw frames, clear\n//! the screen, hide the cursor, etc. There are backend implementations for [Crossterm], [Termion]\n//! and [Termwiz].\n//!\n//! The simplest way to initialize the terminal is to use the [`init`] function which returns a\n//! [`DefaultTerminal`] instance with the default options, enters the Alternate Screen and Raw mode\n//! and sets up a panic hook that restores the terminal in case of panic. This instance can then be\n//! used to draw frames and interact with the terminal state. (The [`DefaultTerminal`] instance is a\n//! type alias for a terminal with the [`crossterm`] backend.) The [`restore`] function restores the\n//! terminal to its original state.\n//!\n//! ```rust,no_run\n//! fn main() -> std::io::Result<()> {\n//!     let mut terminal = ratatui::init();\n//!     let result = run(&mut terminal);\n//!     ratatui::restore();\n//!     result\n//! }\n//! # fn run(terminal: &mut ratatui::DefaultTerminal) -> std::io::Result<()> { Ok(()) }\n//! ```\n//!\n//! See the [`backend` module] and the [Backends] section of the [Ratatui Website] for more info on\n//! the alternate screen and raw mode.\n//!\n//! ### Drawing the UI\n//!\n//! Drawing the UI is done by calling the [`Terminal::draw`] method on the terminal instance. This\n//! method takes a closure that is called with a [`Frame`] instance. The [`Frame`] provides the size\n//! of the area to draw to and allows the app to render any [`Widget`] using the provided\n//! [`render_widget`] method. After this closure returns, a diff is performed and only the changes\n//! are drawn to the terminal. See the [Widgets] section of the [Ratatui Website] for more info.\n//!\n//! The closure passed to the [`Terminal::draw`] method should handle the rendering of a full frame.\n//!\n//! ```rust,no_run\n//! use ratatui::{widgets::Paragraph, Frame};\n//!\n//! fn run(terminal: &mut ratatui::DefaultTerminal) -> std::io::Result<()> {\n//!     loop {\n//!         terminal.draw(|frame| draw(frame))?;\n//!         if handle_events()? {\n//!             break Ok(());\n//!         }\n//!     }\n//! }\n//!\n//! fn draw(frame: &mut Frame) {\n//!     let text = Paragraph::new(\"Hello World!\");\n//!     frame.render_widget(text, frame.area());\n//! }\n//! # fn handle_events() -> std::io::Result<bool> { Ok(false) }\n//! ```\n//!\n//! ### Handling events\n//!\n//! Ratatui does not include any input handling. Instead event handling can be implemented by\n//! calling backend library methods directly. See the [Handling Events] section of the [Ratatui\n//! Website] for more info. For example, if you are using [Crossterm], you can use the\n//! [`crossterm::event`] module to handle events.\n//!\n//! ```rust,no_run\n//! use crossterm::event::{self, Event, KeyCode, KeyEvent, KeyEventKind};\n//!\n//! fn handle_events() -> std::io::Result<bool> {\n//!     match event::read()? {\n//!         Event::Key(key) if key.kind == KeyEventKind::Press => match key.code {\n//!             KeyCode::Char('q') => return Ok(true),\n//!             // handle other key events\n//!             _ => {}\n//!         },\n//!         // handle other events\n//!         _ => {}\n//!     }\n//!     Ok(false)\n//! }\n//! ```\n//!\n//! ## Layout\n//!\n//! The library comes with a basic yet useful layout management object called [`Layout`] which\n//! allows you to split the available space into multiple areas and then render widgets in each\n//! area. This lets you describe a responsive terminal UI by nesting layouts. See the [Layout]\n//! section of the [Ratatui Website] for more info.\n//!\n//! ```rust,no_run\n//! use ratatui::{\n//!     layout::{Constraint, Layout},\n//!     widgets::Block,\n//!     Frame,\n//! };\n//!\n//! fn draw(frame: &mut Frame) {\n//!     use Constraint::{Fill, Length, Min};\n//!\n//!     let vertical = Layout::vertical([Length(1), Min(0), Length(1)]);\n//!     let [title_area, main_area, status_area] = vertical.areas(frame.area());\n//!     let horizontal = Layout::horizontal([Fill(1); 2]);\n//!     let [left_area, right_area] = horizontal.areas(main_area);\n//!\n//!     frame.render_widget(Block::bordered().title(\"Title Bar\"), title_area);\n//!     frame.render_widget(Block::bordered().title(\"Status Bar\"), status_area);\n//!     frame.render_widget(Block::bordered().title(\"Left\"), left_area);\n//!     frame.render_widget(Block::bordered().title(\"Right\"), right_area);\n//! }\n//! ```\n//!\n//! Running this example produces the following output:\n//!\n//! ```text\n//! Title Bar\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n//! \u250cLeft\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u250cRight\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n//! \u2502                    \u2502\u2502                    \u2502\n//! \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n//! Status Bar\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n//! ```\n//!\n//! ## Text and styling\n//!\n//! The [`Text`], [`Line`] and [`Span`] types are the building blocks of the library and are used in\n//! many places. [`Text`] is a list of [`Line`]s and a [`Line`] is a list of [`Span`]s. A [`Span`]\n//! is a string with a specific style.\n//!\n//! The [`style` module] provides types that represent the various styling options. The most\n//! important one is [`Style`] which represents the foreground and background colors and the text\n//! attributes of a [`Span`]. The [`style` module] also provides a [`Stylize`] trait that allows\n//! short-hand syntax to apply a style to widgets and text. See the [Styling Text] section of the\n//! [Ratatui Website] for more info.\n//!\n//! ```rust,no_run\n//! use ratatui::{\n//!     layout::{Constraint, Layout},\n//!     style::{Color, Modifier, Style, Stylize},\n//!     text::{Line, Span},\n//!     widgets::{Block, Paragraph},\n//!     Frame,\n//! };\n//!\n//! fn draw(frame: &mut Frame) {\n//!     let areas = Layout::vertical([Constraint::Length(1); 4]).split(frame.area());\n//!\n//!     let line = Line::from(vec![\n//!         Span::raw(\"Hello \"),\n//!         Span::styled(\n//!             \"World\",\n//!             Style::new()\n//!                 .fg(Color::Green)\n//!                 .bg(Color::White)\n//!                 .add_modifier(Modifier::BOLD),\n//!         ),\n//!         \"!\".red().on_light_yellow().italic(),\n//!     ]);\n//!     frame.render_widget(line, areas[0]);\n//!\n//!     // using the short-hand syntax and implicit conversions\n//!     let paragraph = Paragraph::new(\"Hello World!\".red().on_white().bold());\n//!     frame.render_widget(paragraph, areas[1]);\n//!\n//!     // style the whole widget instead of just the text\n//!     let paragraph = Paragraph::new(\"Hello World!\").style(Style::new().red().on_white());\n//!     frame.render_widget(paragraph, areas[2]);\n//!\n//!     // use the simpler short-hand syntax\n//!     let paragraph = Paragraph::new(\"Hello World!\").blue().on_yellow();\n//!     frame.render_widget(paragraph, areas[3]);\n//! }\n//! ```\n#![cfg_attr(feature = \"document-features\", doc = \"\\n## Features\")]\n#![cfg_attr(feature = \"document-features\", doc = document_features::document_features!())]\n//!\n//! [Ratatui Website]: https://ratatui.rs/\n//! [Installation]: https://ratatui.rs/installation/\n//! [Rendering]: https://ratatui.rs/concepts/rendering/\n//! [Application Patterns]: https://ratatui.rs/concepts/application-patterns/\n//! [Hello World tutorial]: https://ratatui.rs/tutorials/hello-world/\n//! [Backends]: https://ratatui.rs/concepts/backends/\n//! [Widgets]: https://ratatui.rs/how-to/widgets/\n//! [Handling Events]: https://ratatui.rs/concepts/event-handling/\n//! [Layout]: https://ratatui.rs/how-to/layout/\n//! [Styling Text]: https://ratatui.rs/how-to/render/style-text/\n//! [templates]: https://github.com/ratatui/templates/\n//! [Examples]: https://github.com/ratatui/ratatui/tree/main/ratatui/examples/README.md\n//! [Report a bug]: https://github.com/ratatui/ratatui/issues/new?labels=bug&projects=&template=bug_report.md\n//! [Request a Feature]: https://github.com/ratatui/ratatui/issues/new?labels=enhancement&projects=&template=feature_request.md\n//! [Create a Pull Request]: https://github.com/ratatui/ratatui/compare\n//! [git-cliff]: https://git-cliff.org\n//! [Conventional Commits]: https://www.conventionalcommits.org\n//! [API Docs]: https://docs.rs/ratatui\n//! [Changelog]: https://github.com/ratatui/ratatui/blob/main/CHANGELOG.md\n//! [Contributing]: https://github.com/ratatui/ratatui/blob/main/CONTRIBUTING.md\n//! [Breaking Changes]: https://github.com/ratatui/ratatui/blob/main/BREAKING-CHANGES.md\n//! [FOSDEM 2024 talk]: https://www.youtube.com/watch?v=NU0q6NOLJ20\n//! [`render_widget`]: Frame::render_widget\n//! [`Widget`]: widgets::Widget\n//! [`Layout`]: layout::Layout\n//! [`Text`]: text::Text\n//! [`Line`]: text::Line\n//! [`Span`]: text::Span\n//! [`Style`]: style::Style\n//! [`style` module]: style\n//! [`Stylize`]: style::Stylize\n//! [`Backend`]: backend::Backend\n//! [`backend` module]: backend\n//! [`crossterm::event`]: https://docs.rs/crossterm/latest/crossterm/event/index.html\n//! [Crate]: https://crates.io/crates/ratatui\n//! [Crossterm]: https://crates.io/crates/crossterm\n//! [Termion]: https://crates.io/crates/termion\n//! [Termwiz]: https://crates.io/crates/termwiz\n//! [tui-rs]: https://crates.io/crates/tui\n//! [GitHub Sponsors]: https://github.com/sponsors/ratatui\n//! [Crate Badge]: https://img.shields.io/crates/v/ratatui?logo=rust&style=flat-square&logoColor=E05D44&color=E05D44\n//! [License Badge]: https://img.shields.io/crates/l/ratatui?style=flat-square&color=1370D3\n//! [CI Badge]: https://img.shields.io/github/actions/workflow/status/ratatui/ratatui/ci.yml?style=flat-square&logo=github\n//! [CI Workflow]: https://github.com/ratatui/ratatui/actions/workflows/ci.yml\n//! [Codecov Badge]: https://img.shields.io/codecov/c/github/ratatui/ratatui?logo=codecov&style=flat-square&token=BAQ8SOKEST&color=C43AC3&logoColor=C43AC3\n//! [Codecov]: https://app.codecov.io/gh/ratatui/ratatui\n//! [Deps.rs Badge]: https://deps.rs/repo/github/ratatui/ratatui/status.svg?style=flat-square\n//! [Deps.rs]: https://deps.rs/repo/github/ratatui/ratatui\n//! [Discord Badge]: https://img.shields.io/discord/1070692720437383208?label=discord&logo=discord&style=flat-square&color=1370D3&logoColor=1370D3\n//! [Discord Server]: https://discord.gg/pMCEU9hNEj\n//! [Docs Badge]: https://img.shields.io/docsrs/ratatui?logo=rust&style=flat-square&logoColor=E05D44\n//! [Matrix Badge]: https://img.shields.io/matrix/ratatui-general%3Amatrix.org?style=flat-square&logo=matrix&label=Matrix&color=C43AC3\n//! [Matrix]: https://matrix.to/#/#ratatui:matrix.org\n//! [Forum Badge]: https://img.shields.io/discourse/likes?server=https%3A%2F%2Fforum.ratatui.rs&style=flat-square&logo=discourse&label=forum&color=C43AC3\n//! [Forum]: https://forum.ratatui.rs\n//! [Sponsors Badge]: https://img.shields.io/github/sponsors/ratatui?logo=github&style=flat-square&color=1370D3\n\n/// re-export the `palette` crate so that users don't have to add it as a dependency\n#[cfg(feature = \"palette\")]\npub use palette;\npub use ratatui_core::{\n    buffer, layout,\n    terminal::{CompletedFrame, Frame, Terminal, TerminalOptions, Viewport},\n};\n/// re-export the `crossterm` crate so that users don't have to add it as a dependency\n#[cfg(feature = \"crossterm\")]\npub use ratatui_crossterm::crossterm;\n/// re-export the `termion` crate so that users don't have to add it as a dependency\n#[cfg(all(not(windows), feature = \"termion\"))]\npub use ratatui_termion::termion;\n/// re-export the `termwiz` crate so that users don't have to add it as a dependency\n#[cfg(feature = \"termwiz\")]\npub use ratatui_termwiz::termwiz;\n\n#[cfg(feature = \"crossterm\")]\npub use crate::init::{\n    init, init_with_options, restore, try_init, try_init_with_options, try_restore, DefaultTerminal,\n};\n\n/// Re-exports for the backend implementations.\npub mod backend {\n    pub use ratatui_core::backend::{Backend, ClearType, TestBackend, WindowSize};\n    #[cfg(feature = \"crossterm\")]\n    pub use ratatui_crossterm::{CrosstermBackend, FromCrossterm, IntoCrossterm};\n    #[cfg(all(not(windows), feature = \"termion\"))]\n    pub use ratatui_termion::{FromTermion, IntoTermion, TermionBackend};\n    #[cfg(feature = \"termwiz\")]\n    pub use ratatui_termwiz::{FromTermwiz, IntoTermwiz, TermwizBackend};\n}\n\npub mod prelude;\npub use ratatui_core::{style, symbols, text};\npub mod widgets;\npub use ratatui_widgets::border;\n#[cfg(feature = \"crossterm\")]\nmod init;\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "c7b62f8aff30765a693fcf9979c3b419ea5949cf",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/ratatui/ratatui-termion/src/lib.rs",
    "func": "// show the feature flags in the generated documentation\n#![cfg_attr(docsrs, feature(doc_cfg))]\n#![cfg_attr(docsrs, feature(doc_auto_cfg))]\n#![doc(\n    html_logo_url = \"https://raw.githubusercontent.com/ratatui/ratatui/main/assets/logo.png\",\n    html_favicon_url = \"https://raw.githubusercontent.com/ratatui/ratatui/main/assets/favicon.ico\"\n)]\n#![warn(missing_docs)]\n//! This module provides the [`TermionBackend`] implementation for the [`Backend`] trait. It uses\n//! the [Termion] crate to interact with the terminal.\n//!\n//! [`Backend`]: ratatui_core::backend::Backend\n//! [Termion]: https://docs.rs/termion\n#![cfg_attr(feature = \"document-features\", doc = \"\\n## Features\")]\n#![cfg_attr(feature = \"document-features\", doc = document_features::document_features!())]\n\nuse std::{\n    fmt,\n    io::{self, Write},\n};\n\nuse ratatui_core::{\n    backend::{Backend, ClearType, WindowSize},\n    buffer::Cell,\n    layout::{Position, Size},\n    style::{Color, Modifier, Style},\n};\npub use termion;\nuse termion::{color as tcolor, color::Color as _, style as tstyle};\n\n/// A [`Backend`] implementation that uses [Termion] to render to the terminal.\n///\n/// The `TermionBackend` struct is a wrapper around a writer implementing [`Write`], which is used\n/// to send commands to the terminal. It provides methods for drawing content, manipulating the\n/// cursor, and clearing the terminal screen.\n///\n/// Most applications should not call the methods on `TermionBackend` directly, but will instead\n/// use the [`Terminal`] struct, which provides a more ergonomic interface.\n///\n/// Usually applications will enable raw mode and switch to alternate screen mode when starting.\n/// This is done by calling [`IntoRawMode::into_raw_mode()`] and\n/// [`IntoAlternateScreen::into_alternate_screen()`] on the writer before creating the backend.\n/// This is not done automatically by the backend because it is possible that the application may\n/// want to use the terminal for other purposes (like showing help text) before entering alternate\n/// screen mode. This backend automatically disable raw mode and switches back to the primary\n/// screen when the writer is dropped.\n///\n/// # Example\n///\n/// ```rust,no_run\n/// use std::io::{stderr, stdout};\n///\n/// use ratatui::{\n///     backend::TermionBackend,\n///     termion::{raw::IntoRawMode, screen::IntoAlternateScreen},\n///     Terminal,\n/// };\n///\n/// let writer = stdout().into_raw_mode()?.into_alternate_screen()?;\n/// let mut backend = TermionBackend::new(writer);\n/// // or\n/// let writer = stderr().into_raw_mode()?.into_alternate_screen()?;\n/// let backend = TermionBackend::new(stderr());\n/// let mut terminal = Terminal::new(backend)?;\n///\n/// terminal.clear()?;\n/// terminal.draw(|frame| {\n///     // -- snip --\n/// })?;\n/// # std::io::Result::Ok(())\n/// ```\n///\n/// [`IntoRawMode::into_raw_mode()`]: termion::raw::IntoRawMode\n/// [`IntoAlternateScreen::into_alternate_screen()`]: termion::screen::IntoAlternateScreen\n/// [`Terminal`]: ratatui_core::terminal::Terminal\n/// [Termion]: https://docs.rs/termion\n#[derive(Debug, Default, Clone, Eq, PartialEq, Hash)]\npub struct TermionBackend<W>\nwhere\n    W: Write,\n{\n    writer: W,\n}\n\nimpl<W> TermionBackend<W>\nwhere\n    W: Write,\n{\n    /// Creates a new Termion backend with the given writer.\n    ///\n    /// Most applications will use either [`stdout`](std::io::stdout) or\n    /// [`stderr`](std::io::stderr) as writer. See the [FAQ] to determine which one to use.\n    ///\n    /// [FAQ]: https://ratatui.rs/faq/#should-i-use-stdout-or-stderr\n    ///\n    /// # Example\n    ///\n    /// ```rust,no_run\n    /// use std::io::stdout;\n    ///\n    /// use ratatui::backend::TermionBackend;\n    ///\n    /// let backend = TermionBackend::new(stdout());\n    /// ```\n    pub const fn new(writer: W) -> Self {\n        Self { writer }\n    }\n\n    /// Gets the writer.\n    #[instability::unstable(\n        feature = \"backend-writer\",\n        issue = \"https://github.com/ratatui/ratatui/pull/991\"\n    )]\n    pub const fn writer(&self) -> &W {\n        &self.writer\n    }\n\n    /// Gets the writer as a mutable reference.\n    /// Note: writing to the writer may cause incorrect output after the write. This is due to the\n    /// way that the Terminal implements diffing Buffers.\n    #[instability::unstable(\n        feature = \"backend-writer\",\n        issue = \"https://github.com/ratatui/ratatui/pull/991\"\n    )]\n    pub fn writer_mut(&mut self) -> &mut W {\n        &mut self.writer\n    }\n}\n\nimpl<W> Write for TermionBackend<W>\nwhere\n    W: Write,\n{\n    fn write(&mut self, buf: &[u8]) -> io::Result<usize> {\n        self.writer.write(buf)\n    }\n\n    fn flush(&mut self) -> io::Result<()> {\n        self.writer.flush()\n    }\n}\n\nimpl<W> Backend for TermionBackend<W>\nwhere\n    W: Write,\n{\n    fn clear(&mut self) -> io::Result<()> {\n        self.clear_region(ClearType::All)\n    }\n\n    fn clear_region(&mut self, clear_type: ClearType) -> io::Result<()> {\n        match clear_type {\n            ClearType::All => write!(self.writer, \"{}\", termion::clear::All)?,\n            ClearType::AfterCursor => write!(self.writer, \"{}\", termion::clear::AfterCursor)?,\n            ClearType::BeforeCursor => write!(self.writer, \"{}\", termion::clear::BeforeCursor)?,\n            ClearType::CurrentLine => write!(self.writer, \"{}\", termion::clear::CurrentLine)?,\n            ClearType::UntilNewLine => write!(self.writer, \"{}\", termion::clear::UntilNewline)?,\n        };\n        self.writer.flush()\n    }\n\n    fn append_lines(&mut self, n: u16) -> io::Result<()> {\n        for _ in 0..n {\n            writeln!(self.writer)?;\n        }\n        self.writer.flush()\n    }\n\n    fn hide_cursor(&mut self) -> io::Result<()> {\n        write!(self.writer, \"{}\", termion::cursor::Hide)?;\n        self.writer.flush()\n    }\n\n    fn show_cursor(&mut self) -> io::Result<()> {\n        write!(self.writer, \"{}\", termion::cursor::Show)?;\n        self.writer.flush()\n    }\n\n    fn get_cursor_position(&mut self) -> io::Result<Position> {\n        termion::cursor::DetectCursorPos::cursor_pos(&mut self.writer)\n            .map(|(x, y)| Position { x: x - 1, y: y - 1 })\n    }\n\n    fn set_cursor_position<P: Into<Position>>(&mut self, position: P) -> io::Result<()> {\n        let Position { x, y } = position.into();\n        write!(self.writer, \"{}\", termion::cursor::Goto(x + 1, y + 1))?;\n        self.writer.flush()\n    }\n\n    fn draw<'a, I>(&mut self, content: I) -> io::Result<()>\n    where\n        I: Iterator<Item = (u16, u16, &'a Cell)>,\n    {\n        use std::fmt::Write;\n\n        let mut string = String::with_capacity(content.size_hint().0 * 3);\n        let mut fg = Color::Reset;\n        let mut bg = Color::Reset;\n        let mut modifier = Modifier::empty();\n        let mut last_pos: Option<Position> = None;\n        for (x, y, cell) in content {\n            // Move the cursor if the previous location was not (x - 1, y)\n            if !matches!(last_pos, Some(p) if x == p.x + 1 && y == p.y) {\n                write!(string, \"{}\", termion::cursor::Goto(x + 1, y + 1)).unwrap();\n            }\n            last_pos = Some(Position { x, y });\n            if cell.modifier != modifier {\n                write!(\n                    string,\n                    \"{}\",\n                    ModifierDiff {\n                        from: modifier,\n                        to: cell.modifier\n                    }\n                )\n                .unwrap();\n                modifier = cell.modifier;\n            }\n            if cell.fg != fg {\n                write!(string, \"{}\", Fg(cell.fg)).unwrap();\n                fg = cell.fg;\n            }\n            if cell.bg != bg {\n                write!(string, \"{}\", Bg(cell.bg)).unwrap();\n                bg = cell.bg;\n            }\n            string.push_str(cell.symbol());\n        }\n        write!(\n            self.writer,\n            \"{string}{}{}{}\",\n            Fg(Color::Reset),\n            Bg(Color::Reset),\n            termion::style::Reset,\n        )\n    }\n\n    fn size(&self) -> io::Result<Size> {\n        let terminal = termion::terminal_size()?;\n        Ok(Size::new(terminal.0, terminal.1))\n    }\n\n    fn window_size(&mut self) -> io::Result<WindowSize> {\n        Ok(WindowSize {\n            columns_rows: termion::terminal_size()?.into(),\n            pixels: termion::terminal_size_pixels()?.into(),\n        })\n    }\n\n    fn flush(&mut self) -> io::Result<()> {\n        self.writer.flush()\n    }\n\n    #[cfg(feature = \"scrolling-regions\")]\n    fn scroll_region_up(&mut self, region: std::ops::Range<u16>, amount: u16) -> io::Result<()> {\n        write!(\n            self.writer,\n            \"{}{}{}\",\n            SetRegion(region.start.saturating_add(1), region.end),\n            termion::scroll::Up(amount),\n            ResetRegion,\n        )?;\n        self.writer.flush()\n    }\n\n    #[cfg(feature = \"scrolling-regions\")]\n    fn scroll_region_down(&mut self, region: std::ops::Range<u16>, amount: u16) -> io::Result<()> {\n        write!(\n            self.writer,\n            \"{}{}{}\",\n            SetRegion(region.start.saturating_add(1), region.end),\n            termion::scroll::Down(amount),\n            ResetRegion,\n        )?;\n        self.writer.flush()\n    }\n}\nstruct Fg(Color);\n\nstruct Bg(Color);\n\n/// The `ModifierDiff` struct is used to calculate the difference between two `Modifier`\n/// values. This is useful when updating the terminal display, as it allows for more\n/// efficient updates by only sending the necessary changes.\nstruct ModifierDiff {\n    from: Modifier,\n    to: Modifier,\n}\n\nimpl fmt::Display for Fg {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        match self.0 {\n            Color::Reset => termion::color::Reset.write_fg(f),\n            Color::Black => termion::color::Black.write_fg(f),\n            Color::Red => termion::color::Red.write_fg(f),\n            Color::Green => termion::color::Green.write_fg(f),\n            Color::Yellow => termion::color::Yellow.write_fg(f),\n            Color::Blue => termion::color::Blue.write_fg(f),\n            Color::Magenta => termion::color::Magenta.write_fg(f),\n            Color::Cyan => termion::color::Cyan.write_fg(f),\n            Color::Gray => termion::color::White.write_fg(f),\n            Color::DarkGray => termion::color::LightBlack.write_fg(f),\n            Color::LightRed => termion::color::LightRed.write_fg(f),\n            Color::LightGreen => termion::color::LightGreen.write_fg(f),\n            Color::LightBlue => termion::color::LightBlue.write_fg(f),\n            Color::LightYellow => termion::color::LightYellow.write_fg(f),\n            Color::LightMagenta => termion::color::LightMagenta.write_fg(f),\n            Color::LightCyan => termion::color::LightCyan.write_fg(f),\n            Color::White => termion::color::LightWhite.write_fg(f),\n            Color::Indexed(i) => termion::color::AnsiValue(i).write_fg(f),\n            Color::Rgb(r, g, b) => termion::color::Rgb(r, g, b).write_fg(f),\n        }\n    }\n}\nimpl fmt::Display for Bg {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        match self.0 {\n            Color::Reset => termion::color::Reset.write_bg(f),\n            Color::Black => termion::color::Black.write_bg(f),\n            Color::Red => termion::color::Red.write_bg(f),\n            Color::Green => termion::color::Green.write_bg(f),\n            Color::Yellow => termion::color::Yellow.write_bg(f),\n            Color::Blue => termion::color::Blue.write_bg(f),\n            Color::Magenta => termion::color::Magenta.write_bg(f),\n            Color::Cyan => termion::color::Cyan.write_bg(f),\n            Color::Gray => termion::color::White.write_bg(f),\n            Color::DarkGray => termion::color::LightBlack.write_bg(f),\n            Color::LightRed => termion::color::LightRed.write_bg(f),\n            Color::LightGreen => termion::color::LightGreen.write_bg(f),\n            Color::LightBlue => termion::color::LightBlue.write_bg(f),\n            Color::LightYellow => termion::color::LightYellow.write_bg(f),\n            Color::LightMagenta => termion::color::LightMagenta.write_bg(f),\n            Color::LightCyan => termion::color::LightCyan.write_bg(f),\n            Color::White => termion::color::LightWhite.write_bg(f),\n            Color::Indexed(i) => termion::color::AnsiValue(i).write_bg(f),\n            Color::Rgb(r, g, b) => termion::color::Rgb(r, g, b).write_bg(f),\n        }\n    }\n}\n\n/// A trait for converting a Termion type to a Ratatui type.\n///\n/// This trait is necessary to avoid the orphan rule, as we cannot implement a trait for a type\n/// defined in another crate.\npub trait FromTermion<T> {\n    /// Convert the Termion type to the Ratatui type.\n    fn from_termion(termion: T) -> Self;\n}\n\n/// A trait for converting a Ratatui type to a Termion type.\n///\n/// This trait is necessary to avoid the orphan rule, as we cannot implement a trait for a type\n/// defined in another crate.\npub trait IntoTermion<T> {\n    /// Convert the Ratatui type to the Termion type.\n    fn into_termion(self) -> T;\n}\n\nmacro_rules! from_termion_for_color {\n    ($termion_color:ident, $color:ident) => {\n        impl FromTermion<tcolor::$termion_color> for Color {\n            fn from_termion(_: tcolor::$termion_color) -> Self {\n                Color::$color\n            }\n        }\n\n        impl FromTermion<tcolor::Bg<tcolor::$termion_color>> for Style {\n            fn from_termion(_: tcolor::Bg<tcolor::$termion_color>) -> Self {\n                Style::default().bg(Color::$color)\n            }\n        }\n\n        impl FromTermion<tcolor::Fg<tcolor::$termion_color>> for Style {\n            fn from_termion(_: tcolor::Fg<tcolor::$termion_color>) -> Self {\n                Style::default().fg(Color::$color)\n            }\n        }\n    };\n}\n\nfrom_termion_for_color!(Reset, Reset);\nfrom_termion_for_color!(Black, Black);\nfrom_termion_for_color!(Red, Red);\nfrom_termion_for_color!(Green, Green);\nfrom_termion_for_color!(Yellow, Yellow);\nfrom_termion_for_color!(Blue, Blue);\nfrom_termion_for_color!(Magenta, Magenta);\nfrom_termion_for_color!(Cyan, Cyan);\nfrom_termion_for_color!(White, Gray);\nfrom_termion_for_color!(LightBlack, DarkGray);\nfrom_termion_for_color!(LightRed, LightRed);\nfrom_termion_for_color!(LightGreen, LightGreen);\nfrom_termion_for_color!(LightBlue, LightBlue);\nfrom_termion_for_color!(LightYellow, LightYellow);\nfrom_termion_for_color!(LightMagenta, LightMagenta);\nfrom_termion_for_color!(LightCyan, LightCyan);\nfrom_termion_for_color!(LightWhite, White);\n\nimpl FromTermion<tcolor::AnsiValue> for Color {\n    fn from_termion(value: tcolor::AnsiValue) -> Self {\n        Self::Indexed(value.0)\n    }\n}\n\nimpl FromTermion<tcolor::Bg<tcolor::AnsiValue>> for Style {\n    fn from_termion(value: tcolor::Bg<tcolor::AnsiValue>) -> Self {\n        Self::default().bg(Color::Indexed(value.0 .0))\n    }\n}\n\nimpl FromTermion<tcolor::Fg<tcolor::AnsiValue>> for Style {\n    fn from_termion(value: tcolor::Fg<tcolor::AnsiValue>) -> Self {\n        Self::default().fg(Color::Indexed(value.0 .0))\n    }\n}\n\nimpl FromTermion<tcolor::Rgb> for Color {\n    fn from_termion(value: tcolor::Rgb) -> Self {\n        Self::Rgb(value.0, value.1, value.2)\n    }\n}\n\nimpl FromTermion<tcolor::Bg<tcolor::Rgb>> for Style {\n    fn from_termion(value: tcolor::Bg<tcolor::Rgb>) -> Self {\n        Self::default().bg(Color::Rgb(value.0 .0, value.0 .1, value.0 .2))\n    }\n}\n\nimpl FromTermion<tcolor::Fg<tcolor::Rgb>> for Style {\n    fn from_termion(value: tcolor::Fg<tcolor::Rgb>) -> Self {\n        Self::default().fg(Color::Rgb(value.0 .0, value.0 .1, value.0 .2))\n    }\n}\n\nimpl fmt::Display for ModifierDiff {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        let remove = self.from - self.to;\n        if remove.contains(Modifier::REVERSED) {\n            write!(f, \"{}\", termion::style::NoInvert)?;\n        }\n        if remove.contains(Modifier::BOLD) {\n            // XXX: the termion NoBold flag actually enables double-underline on ECMA-48 compliant\n            // terminals, and NoFaint additionally disables bold... so we use this trick to get\n            // the right semantics.\n            write!(f, \"{}\", termion::style::NoFaint)?;\n\n            if self.to.contains(Modifier::DIM) {\n                write!(f, \"{}\", termion::style::Faint)?;\n            }\n        }\n        if remove.contains(Modifier::ITALIC) {\n            write!(f, \"{}\", termion::style::NoItalic)?;\n        }\n        if remove.contains(Modifier::UNDERLINED) {\n            write!(f, \"{}\", termion::style::NoUnderline)?;\n        }\n        if remove.contains(Modifier::DIM) {\n            write!(f, \"{}\", termion::style::NoFaint)?;\n\n            // XXX: the NoFaint flag additionally disables bold as well, so we need to re-enable it\n            // here if we want it.\n            if self.to.contains(Modifier::BOLD) {\n                write!(f, \"{}\", termion::style::Bold)?;\n            }\n        }\n        if remove.contains(Modifier::CROSSED_OUT) {\n            write!(f, \"{}\", termion::style::NoCrossedOut)?;\n        }\n        if remove.contains(Modifier::SLOW_BLINK) || remove.contains(Modifier::RAPID_BLINK) {\n            write!(f, \"{}\", termion::style::NoBlink)?;\n        }\n\n        let add = self.to - self.from;\n        if add.contains(Modifier::REVERSED) {\n            write!(f, \"{}\", termion::style::Invert)?;\n        }\n        if add.contains(Modifier::BOLD) {\n            write!(f, \"{}\", termion::style::Bold)?;\n        }\n        if add.contains(Modifier::ITALIC) {\n            write!(f, \"{}\", termion::style::Italic)?;\n        }\n        if add.contains(Modifier::UNDERLINED) {\n            write!(f, \"{}\", termion::style::Underline)?;\n        }\n        if add.contains(Modifier::DIM) {\n            write!(f, \"{}\", termion::style::Faint)?;\n        }\n        if add.contains(Modifier::CROSSED_OUT) {\n            write!(f, \"{}\", termion::style::CrossedOut)?;\n        }\n        if add.contains(Modifier::SLOW_BLINK) || add.contains(Modifier::RAPID_BLINK) {\n            write!(f, \"{}\", termion::style::Blink)?;\n        }\n\n        Ok(())\n    }\n}\n\nmacro_rules! from_termion_for_modifier {\n    ($termion_modifier:ident, $modifier:ident) => {\n        impl FromTermion<tstyle::$termion_modifier> for Modifier {\n            fn from_termion(_: tstyle::$termion_modifier) -> Self {\n                Modifier::$modifier\n            }\n        }\n    };\n}\n\nfrom_termion_for_modifier!(Invert, REVERSED);\nfrom_termion_for_modifier!(Bold, BOLD);\nfrom_termion_for_modifier!(Italic, ITALIC);\nfrom_termion_for_modifier!(Underline, UNDERLINED);\nfrom_termion_for_modifier!(Faint, DIM);\nfrom_termion_for_modifier!(CrossedOut, CROSSED_OUT);\nfrom_termion_for_modifier!(Blink, SLOW_BLINK);\n\nimpl FromTermion<termion::style::Reset> for Modifier {\n    fn from_termion(_: termion::style::Reset) -> Self {\n        Self::empty()\n    }\n}\n\n/// Set scrolling region.\n#[derive(Copy, Clone, PartialEq, Eq)]\npub struct SetRegion(pub u16, pub u16);\n\nimpl fmt::Display for SetRegion {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        write!(f, \"\\x1B[{};{}r\", self.0, self.1)\n    }\n}\n\n/// Reset scrolling region.\n#[derive(Copy, Clone, PartialEq, Eq)]\npub struct ResetRegion;\n\nimpl fmt::Display for ResetRegion {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        write!(f, \"\\x1B[r\")\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use ratatui_core::style::Stylize;\n\n    use super::*;\n\n    #[test]\n    fn from_termion_color() {\n        assert_eq!(Color::from_termion(tcolor::Reset), Color::Reset);\n        assert_eq!(Color::from_termion(tcolor::Black), Color::Black);\n        assert_eq!(Color::from_termion(tcolor::Red), Color::Red);\n        assert_eq!(Color::from_termion(tcolor::Green), Color::Green);\n        assert_eq!(Color::from_termion(tcolor::Yellow), Color::Yellow);\n        assert_eq!(Color::from_termion(tcolor::Blue), Color::Blue);\n        assert_eq!(Color::from_termion(tcolor::Magenta), Color::Magenta);\n        assert_eq!(Color::from_termion(tcolor::Cyan), Color::Cyan);\n        assert_eq!(Color::from_termion(tcolor::White), Color::Gray);\n        assert_eq!(Color::from_termion(tcolor::LightBlack), Color::DarkGray);\n        assert_eq!(Color::from_termion(tcolor::LightRed), Color::LightRed);\n        assert_eq!(Color::from_termion(tcolor::LightGreen), Color::LightGreen);\n        assert_eq!(Color::from_termion(tcolor::LightBlue), Color::LightBlue);\n        assert_eq!(Color::from_termion(tcolor::LightYellow), Color::LightYellow);\n        assert_eq!(\n            Color::from_termion(tcolor::LightMagenta),\n            Color::LightMagenta\n        );\n        assert_eq!(Color::from_termion(tcolor::LightCyan), Color::LightCyan);\n        assert_eq!(Color::from_termion(tcolor::LightWhite), Color::White);\n        assert_eq!(\n            Color::from_termion(tcolor::AnsiValue(31)),\n            Color::Indexed(31)\n        );\n        assert_eq!(\n            Color::from_termion(tcolor::Rgb(1, 2, 3)),\n            Color::Rgb(1, 2, 3)\n        );\n    }\n\n    #[test]\n    fn from_termion_bg() {\n        use tc::Bg;\n        use tcolor as tc;\n\n        assert_eq!(\n            Style::from_termion(Bg(tc::Reset)),\n            Style::new().bg(Color::Reset)\n        );\n        assert_eq!(Style::from_termion(Bg(tc::Black)), Style::new().on_black());\n        assert_eq!(Style::from_termion(Bg(tc::Red)), Style::new().on_red());\n        assert_eq!(Style::from_termion(Bg(tc::Green)), Style::new().on_green());\n        assert_eq!(\n            Style::from_termion(Bg(tc::Yellow)),\n            Style::new().on_yellow()\n        );\n        assert_eq!(Style::from_termion(Bg(tc::Blue)), Style::new().on_blue());\n        assert_eq!(\n            Style::from_termion(Bg(tc::Magenta)),\n            Style::new().on_magenta()\n        );\n        assert_eq!(Style::from_termion(Bg(tc::Cyan)), Style::new().on_cyan());\n        assert_eq!(Style::from_termion(Bg(tc::White)), Style::new().on_gray());\n        assert_eq!(\n            Style::from_termion(Bg(tc::LightBlack)),\n            Style::new().on_dark_gray()\n        );\n        assert_eq!(\n            Style::from_termion(Bg(tc::LightRed)),\n            Style::new().on_light_red()\n        );\n        assert_eq!(\n            Style::from_termion(Bg(tc::LightGreen)),\n            Style::new().on_light_green()\n        );\n        assert_eq!(\n            Style::from_termion(Bg(tc::LightBlue)),\n            Style::new().on_light_blue()\n        );\n        assert_eq!(\n            Style::from_termion(Bg(tc::LightYellow)),\n            Style::new().on_light_yellow()\n        );\n        assert_eq!(\n            Style::from_termion(Bg(tc::LightMagenta)),\n            Style::new().on_light_magenta()\n        );\n        assert_eq!(\n            Style::from_termion(Bg(tc::LightCyan)),\n            Style::new().on_light_cyan()\n        );\n        assert_eq!(\n            Style::from_termion(Bg(tc::LightWhite)),\n            Style::new().on_white()\n        );\n        assert_eq!(\n            Style::from_termion(Bg(tc::AnsiValue(31))),\n            Style::new().bg(Color::Indexed(31))\n        );\n        assert_eq!(\n            Style::from_termion(Bg(tc::Rgb(1, 2, 3))),\n            Style::new().bg(Color::Rgb(1, 2, 3))\n        );\n    }\n\n    #[test]\n    fn from_termion_fg() {\n        use tc::Fg;\n        use tcolor as tc;\n\n        assert_eq!(\n            Style::from_termion(Fg(tc::Reset)),\n            Style::new().fg(Color::Reset)\n        );\n        assert_eq!(Style::from_termion(Fg(tc::Black)), Style::new().black());\n        assert_eq!(Style::from_termion(Fg(tc::Red)), Style::new().red());\n        assert_eq!(Style::from_termion(Fg(tc::Green)), Style::new().green());\n        assert_eq!(Style::from_termion(Fg(tc::Yellow)), Style::new().yellow());\n        assert_eq!(Style::from_termion(Fg(tc::Blue)), Style::default().blue());\n        assert_eq!(\n            Style::from_termion(Fg(tc::Magenta)),\n            Style::default().magenta()\n        );\n        assert_eq!(Style::from_termion(Fg(tc::Cyan)), Style::default().cyan());\n        assert_eq!(Style::from_termion(Fg(tc::White)), Style::default().gray());\n        assert_eq!(\n            Style::from_termion(Fg(tc::LightBlack)),\n            Style::new().dark_gray()\n        );\n        assert_eq!(\n            Style::from_termion(Fg(tc::LightRed)),\n            Style::new().light_red()\n        );\n        assert_eq!(\n            Style::from_termion(Fg(tc::LightGreen)),\n            Style::new().light_green()\n        );\n        assert_eq!(\n            Style::from_termion(Fg(tc::LightBlue)),\n            Style::new().light_blue()\n        );\n        assert_eq!(\n            Style::from_termion(Fg(tc::LightYellow)),\n            Style::new().light_yellow()\n        );\n        assert_eq!(\n            Style::from_termion(Fg(tc::LightMagenta)),\n            Style::new().light_magenta()\n        );\n        assert_eq!(\n            Style::from_termion(Fg(tc::LightCyan)),\n            Style::new().light_cyan()\n        );\n        assert_eq!(\n            Style::from_termion(Fg(tc::LightWhite)),\n            Style::new().white()\n        );\n        assert_eq!(\n            Style::from_termion(Fg(tc::AnsiValue(31))),\n            Style::default().fg(Color::Indexed(31))\n        );\n        assert_eq!(\n            Style::from_termion(Fg(tc::Rgb(1, 2, 3))),\n            Style::default().fg(Color::Rgb(1, 2, 3))\n        );\n    }\n\n    #[test]\n    fn from_termion_style() {\n        assert_eq!(Modifier::from_termion(tstyle::Invert), Modifier::REVERSED);\n        assert_eq!(Modifier::from_termion(tstyle::Bold), Modifier::BOLD);\n        assert_eq!(Modifier::from_termion(tstyle::Italic), Modifier::ITALIC);\n        assert_eq!(\n            Modifier::from_termion(tstyle::Underline),\n            Modifier::UNDERLINED\n        );\n        assert_eq!(Modifier::from_termion(tstyle::Faint), Modifier::DIM);\n        assert_eq!(\n            Modifier::from_termion(tstyle::CrossedOut),\n            Modifier::CROSSED_OUT\n        );\n        assert_eq!(Modifier::from_termion(tstyle::Blink), Modifier::SLOW_BLINK);\n        assert_eq!(Modifier::from_termion(tstyle::Reset), Modifier::empty());\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "2c56893c32c84501278b5701fa96b02aaf8c2449",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/ratatui/ratatui-widgets/examples/canvas.rs",
    "func": "//! # [Ratatui] `Canvas` example\n//!\n//! The latest version of this example is available in the [widget examples] folder in the\n//! repository.\n//!\n//! Please note that the examples are designed to be run against the `main` branch of the Github\n//! repository. This means that you may not be able to compile with the latest release version on\n//! crates.io, or the one that you have installed locally.\n//!\n//! See the [examples readme] for more information on finding examples that match the version of the\n//! library you are using.\n//!\n//! [Ratatui]: https://github.com/ratatui/ratatui\n//! [widget examples]: https://github.com/ratatui/ratatui/blob/main/ratatui-widgets/examples\n//! [examples readme]: https://github.com/ratatui/ratatui/blob/main/examples/README.md\n\nuse color_eyre::Result;\nuse ratatui::{\n    crossterm::event::{self, Event},\n    layout::{Constraint, Layout, Rect},\n    style::{Color, Stylize},\n    symbols::Marker,\n    text::{Line as TextLine, Span},\n    widgets::canvas::{Canvas, Line, Map, MapResolution, Rectangle},\n    DefaultTerminal, Frame,\n};\nuse ratatui_widgets::canvas::Points;\n\nfn main() -> Result<()> {\n    color_eyre::install()?;\n    let terminal = ratatui::init();\n    let result = run(terminal);\n    ratatui::restore();\n    result\n}\n\n/// Run the application.\nfn run(mut terminal: DefaultTerminal) -> Result<()> {\n    loop {\n        terminal.draw(draw)?;\n        if matches!(event::read()?, Event::Key(_)) {\n            break Ok(());\n        }\n    }\n}\n\n/// Draw the UI with a canvas widget.\nfn draw(frame: &mut Frame) {\n    let vertical = Layout::vertical([Constraint::Length(1), Constraint::Fill(1)]).spacing(1);\n    let horizontal = Layout::horizontal([Constraint::Percentage(100)]).spacing(1);\n    let [top, main] = vertical.areas(frame.area());\n    let [area] = horizontal.areas(main);\n\n    let title = TextLine::from_iter([\n        Span::from(\"Canvas Widget\").bold(),\n        Span::from(\" (Press 'q' to quit)\"),\n    ]);\n    frame.render_widget(title.centered(), top);\n\n    render_canvas(frame, area);\n}\n\n/// Renders the canvas widget with various shapes and a map.\npub fn render_canvas(frame: &mut Frame, area: Rect) {\n    let canvas = Canvas::default()\n        .x_bounds([-180.0, 180.0])\n        .y_bounds([-90.0, 90.0])\n        .marker(Marker::Braille)\n        .paint(|ctx| {\n            ctx.draw(&Map {\n                resolution: MapResolution::High,\n                color: Color::White,\n            });\n            ctx.layer();\n            ctx.draw(&Line::new(0.0, 10.0, 10.0, 10.0, Color::Blue));\n            ctx.draw(&Rectangle {\n                x: 10.0,\n                y: 20.0,\n                width: 10.0,\n                height: 10.0,\n                color: Color::Green,\n            });\n            ctx.draw(&Points {\n                coords: &[\n                    (2.3522, 48.8566),    // Paris\n                    (-122.3321, 47.6062), // Seattle\n                    (-79.3837, 43.6511),  // Toronto\n                    (32.8597, 39.9334),   // Ankara\n                ],\n                color: Color::Red,\n            });\n        });\n\n    frame.render_widget(canvas, area);\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "cf6dd64afc822a3678ab6b10b34fb2b03bc5ae65",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/ratatui/ratatui-widgets/src/logo.rs",
    "func": "//! The [`RatatuiLogo`] widget renders the Ratatui logo.\nuse indoc::indoc;\nuse ratatui_core::{buffer::Buffer, layout::Rect, text::Text, widgets::Widget};\n\n/// A widget that renders the Ratatui logo\n///\n/// The Ratatui logo takes up two lines of text and comes in two sizes: `Tiny` and `Small`. This may\n/// be used in an application's help or about screen to show that it is powered by Ratatui.\n///\n/// # Examples\n///\n/// The [Ratatui-logo] example demonstrates how to use the `RatatuiLogo` widget. This can be run by\n/// cloning the Ratatui repository and then running the following command with an optional size\n/// argument:\n///\n/// ```shell\n/// cargo run --example logo [size]\n/// ```\n///\n/// [Ratatui-logo]: https://github.com/ratatui/ratatui/blob/main/ratatui-widgets/examples/logo.rs\n///\n/// ## Tiny (default, 2x15 characters)\n///\n/// ```\n/// use ratatui::widgets::RatatuiLogo;\n///\n/// # fn draw(frame: &mut ratatui::Frame) {\n/// frame.render_widget(RatatuiLogo::tiny(), frame.area());\n/// # }\n/// ```\n///\n/// Renders:\n///\n/// ```text\n/// \u259b\u259a\u2597\u2580\u2596\u259c\u2598\u259e\u259a\u259d\u259b\u2590 \u258c\u258c\n/// \u259b\u259a\u2590\u2580\u258c\u2590 \u259b\u259c \u258c\u259d\u2584\u2598\u258c\n/// ```\n///\n/// ## Small (2x27 characters)\n///\n/// ```\n/// use ratatui::widgets::RatatuiLogo;\n///\n/// # fn draw(frame: &mut ratatui::Frame) {\n/// frame.render_widget(RatatuiLogo::small(), frame.area());\n/// # }\n/// ```\n///\n/// Renders:\n///\n/// ```text\n/// \u2588\u2580\u2580\u2584 \u2584\u2580\u2580\u2584\u259d\u259c\u259b\u2598\u2584\u2580\u2580\u2584\u259d\u259c\u259b\u2598\u2588  \u2588 \u2588\n/// \u2588\u2580\u2580\u2584 \u2588\u2580\u2580\u2588 \u2590\u258c \u2588\u2580\u2580\u2588 \u2590\u258c \u2580\u2584\u2584\u2580 \u2588\n/// ```\n#[derive(Debug, Default, Clone, Copy, PartialEq, Eq)]\npub struct RatatuiLogo {\n    size: Size,\n}\n\n/// The size of the logo\n#[derive(Debug, Default, Clone, Copy, PartialEq, Eq)]\n#[non_exhaustive]\npub enum Size {\n    /// A tiny logo\n    ///\n    /// The default size of the logo (2x15 characters)\n    ///\n    /// ```text\n    /// \u259b\u259a\u2597\u2580\u2596\u259c\u2598\u259e\u259a\u259d\u259b\u2590 \u258c\u258c\n    /// \u259b\u259a\u2590\u2580\u258c\u2590 \u259b\u259c \u258c\u259d\u2584\u2598\u258c\n    /// ```\n    #[default]\n    Tiny,\n    /// A small logo\n    ///\n    /// A slightly larger version of the logo (2x27 characters)\n    ///\n    /// ```text\n    /// \u2588\u2580\u2580\u2584 \u2584\u2580\u2580\u2584\u259d\u259c\u259b\u2598\u2584\u2580\u2580\u2584\u259d\u259c\u259b\u2598\u2588  \u2588 \u2588\n    /// \u2588\u2580\u2580\u2584 \u2588\u2580\u2580\u2588 \u2590\u258c \u2588\u2580\u2580\u2588 \u2590\u258c \u2580\u2584\u2584\u2580 \u2588\n    /// ```\n    Small,\n}\n\nimpl RatatuiLogo {\n    /// Create a new Ratatui logo widget\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use ratatui::widgets::{RatatuiLogo, RatatuiLogoSize};\n    ///\n    /// let logo = RatatuiLogo::new(RatatuiLogoSize::Tiny);\n    /// ```\n    pub const fn new(size: Size) -> Self {\n        Self { size }\n    }\n\n    /// Set the size of the logo\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use ratatui::widgets::{RatatuiLogo, RatatuiLogoSize};\n    ///\n    /// let logo = RatatuiLogo::default().size(RatatuiLogoSize::Small);\n    /// ```\n    #[must_use]\n    pub const fn size(self, size: Size) -> Self {\n        let _ = self;\n        Self { size }\n    }\n\n    /// Create a new Ratatui logo widget with a tiny size\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use ratatui::widgets::RatatuiLogo;\n    ///\n    /// let logo = RatatuiLogo::tiny();\n    /// ```\n    pub const fn tiny() -> Self {\n        Self::new(Size::Tiny)\n    }\n\n    /// Create a new Ratatui logo widget with a small size\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use ratatui::widgets::RatatuiLogo;\n    ///\n    /// let logo = RatatuiLogo::small();\n    /// ```\n    pub const fn small() -> Self {\n        Self::new(Size::Small)\n    }\n}\n\nimpl Widget for RatatuiLogo {\n    fn render(self, area: Rect, buf: &mut Buffer) {\n        let logo = self.size.as_str();\n        Text::raw(logo).render(area, buf);\n    }\n}\n\nimpl Size {\n    const fn as_str(self) -> &'static str {\n        match self {\n            Self::Tiny => Self::tiny(),\n            Self::Small => Self::small(),\n        }\n    }\n\n    const fn tiny() -> &'static str {\n        indoc! {\"\n            \u259b\u259a\u2597\u2580\u2596\u259c\u2598\u259e\u259a\u259d\u259b\u2590 \u258c\u258c\n            \u259b\u259a\u2590\u2580\u258c\u2590 \u259b\u259c \u258c\u259d\u2584\u2598\u258c\n        \"}\n    }\n\n    const fn small() -> &'static str {\n        indoc! {\"\n            \u2588\u2580\u2580\u2584 \u2584\u2580\u2580\u2584\u259d\u259c\u259b\u2598\u2584\u2580\u2580\u2584\u259d\u259c\u259b\u2598\u2588  \u2588 \u2588\n            \u2588\u2580\u2580\u2584 \u2588\u2580\u2580\u2588 \u2590\u258c \u2588\u2580\u2580\u2588 \u2590\u258c \u2580\u2584\u2584\u2580 \u2588\n        \"}\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use rstest::rstest;\n\n    use super::*;\n\n    #[rstest]\n    #[case::tiny(Size::Tiny)]\n    #[case::small(Size::Small)]\n    fn new_size(#[case] size: Size) {\n        let logo = RatatuiLogo::new(size);\n        assert_eq!(logo.size, size);\n    }\n\n    #[test]\n    fn default_logo_is_tiny() {\n        let logo = RatatuiLogo::default();\n        assert_eq!(logo.size, Size::Tiny);\n    }\n\n    #[test]\n    fn set_logo_size_to_small() {\n        let logo = RatatuiLogo::default().size(Size::Small);\n        assert_eq!(logo.size, Size::Small);\n    }\n\n    #[test]\n    fn tiny_logo_constant() {\n        let logo = RatatuiLogo::tiny();\n        assert_eq!(logo.size, Size::Tiny);\n    }\n\n    #[test]\n    fn small_logo_constant() {\n        let logo = RatatuiLogo::small();\n        assert_eq!(logo.size, Size::Small);\n    }\n\n    #[test]\n    #[rustfmt::skip]\n    fn render_tiny() {\n        let mut buf = Buffer::empty(Rect::new(0, 0, 15, 2));\n        RatatuiLogo::tiny().render(buf.area, &mut buf);\n        assert_eq!(\n            buf,\n            Buffer::with_lines([\n                \"\u259b\u259a\u2597\u2580\u2596\u259c\u2598\u259e\u259a\u259d\u259b\u2590 \u258c\u258c\",\n                \"\u259b\u259a\u2590\u2580\u258c\u2590 \u259b\u259c \u258c\u259d\u2584\u2598\u258c\",\n            ])\n        );\n    }\n\n    #[test]\n    #[rustfmt::skip]\n    fn render_small() {\n        let mut buf = Buffer::empty(Rect::new(0, 0, 27, 2));\n        RatatuiLogo::small().render(buf.area, &mut buf);\n        assert_eq!(\n            buf,\n            Buffer::with_lines([\n                \"\u2588\u2580\u2580\u2584 \u2584\u2580\u2580\u2584\u259d\u259c\u259b\u2598\u2584\u2580\u2580\u2584\u259d\u259c\u259b\u2598\u2588  \u2588 \u2588\",\n                \"\u2588\u2580\u2580\u2584 \u2588\u2580\u2580\u2588 \u2590\u258c \u2588\u2580\u2580\u2588 \u2590\u258c \u2580\u2584\u2584\u2580 \u2588\",\n            ])\n        );\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "0416a978ea456cc885220eca01e4b275e69b632f",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/alacritty/alacritty/src/panic.rs",
    "func": "use std::io::Write;\nuse std::{io, panic};\n\nuse windows_sys::Win32::UI::WindowsAndMessaging::{\n    MessageBoxW, MB_ICONERROR, MB_OK, MB_SETFOREGROUND, MB_TASKMODAL,\n};\n\nuse alacritty_terminal::tty::windows::win32_string;\n\n// Install a panic handler that renders the panic in a classical Windows error\n// dialog box as well as writes the panic to STDERR.\npub fn attach_handler() {\n    panic::set_hook(Box::new(|panic_info| {\n        let _ = writeln!(io::stderr(), \"{}\", panic_info);\n        let msg = format!(\"{}\\n\\nPress Ctrl-C to Copy\", panic_info);\n        unsafe {\n            MessageBoxW(\n                0isize,\n                win32_string(&msg).as_ptr(),\n                win32_string(\"Alacritty: Runtime Error\").as_ptr(),\n                MB_ICONERROR | MB_OK | MB_SETFOREGROUND | MB_TASKMODAL,\n            );\n        }\n    }));\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "1e14ffc334a035d034ae5e109d6af21a283f7b26",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/alacritty/alacritty/build.rs",
    "func": "use std::env;\nuse std::fs::File;\nuse std::path::Path;\nuse std::process::Command;\n\nuse gl_generator::{Api, Fallbacks, GlobalGenerator, Profile, Registry};\n\nfn main() {\n    let mut version = String::from(env!(\"CARGO_PKG_VERSION\"));\n    if let Some(commit_hash) = commit_hash() {\n        version = format!(\"{version} ({commit_hash})\");\n    }\n    println!(\"cargo:rustc-env=VERSION={version}\");\n\n    let dest = env::var(\"OUT_DIR\").unwrap();\n    let mut file = File::create(Path::new(&dest).join(\"gl_bindings.rs\")).unwrap();\n\n    Registry::new(Api::Gl, (3, 3), Profile::Core, Fallbacks::All, [\n        \"GL_ARB_blend_func_extended\",\n        \"GL_KHR_debug\",\n    ])\n    .write_bindings(GlobalGenerator, &mut file)\n    .unwrap();\n\n    #[cfg(windows)]\n    embed_resource::compile(\"./windows/alacritty.rc\", embed_resource::NONE);\n}\n\nfn commit_hash() -> Option<String> {\n    Command::new(\"git\")\n        .args([\"rev-parse\", \"--short\", \"HEAD\"])\n        .output()\n        .ok()\n        .filter(|output| output.status.success())\n        .and_then(|output| String::from_utf8(output.stdout).ok())\n        .map(|hash| hash.trim().into())\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "4db9a8b6d76fb6175a9fe7340389f6c7744e58ef",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-query/examples/postgres/src/main.rs",
    "func": "use chrono::{DateTime, FixedOffset, NaiveDate, NaiveDateTime};\n\nuse postgres::{Client, NoTls, Row};\nuse rust_decimal::Decimal;\nuse sea_query::{ColumnDef, ColumnType, Iden, Order, PostgresQueryBuilder, Query, Table};\nuse sea_query_postgres::PostgresBinder;\nuse time::{\n    macros::{date, offset, time},\n    OffsetDateTime, PrimitiveDateTime,\n};\nuse uuid::Uuid;\n\nfn main() {\n    let mut client = Client::connect(\"postgresql://sea:sea@localhost/query\", NoTls).unwrap();\n\n    // Schema\n\n    let sql = [\n        Table::drop()\n            .table(Document::Table)\n            .if_exists()\n            .build(PostgresQueryBuilder),\n        Table::create()\n            .table(Document::Table)\n            .if_not_exists()\n            .col(\n                ColumnDef::new(Document::Id)\n                    .integer()\n                    .not_null()\n                    .auto_increment()\n                    .primary_key(),\n            )\n            .col(ColumnDef::new(Document::Uuid).uuid())\n            .col(ColumnDef::new(Document::JsonField).json_binary())\n            .col(ColumnDef::new(Document::Timestamp).timestamp())\n            .col(ColumnDef::new(Document::TimestampWithTimeZone).timestamp_with_time_zone())\n            .col(ColumnDef::new(Document::Decimal).decimal())\n            .col(ColumnDef::new(Document::Array).array(ColumnType::Integer))\n            .build(PostgresQueryBuilder),\n    ]\n    .join(\"; \");\n\n    println!(\"{sql}\");\n    let result = client.batch_execute(&sql);\n    println!(\"Create table document: {result:?}\\n\");\n\n    // Create\n    let document_chrono = DocumentStructChrono {\n        id: 1,\n        uuid: Uuid::new_v4(),\n        json_field: serde_json::json! {{\n            \"a\": 25.0,\n            \"b\": \"whatever\",\n            \"c\": {\n                \"another\": \"object\",\n                \"bla\": 1\n            }\n        }},\n        timestamp: NaiveDate::from_ymd_opt(2020, 1, 1)\n            .unwrap()\n            .and_hms_opt(2, 2, 2)\n            .unwrap(),\n        timestamp_with_time_zone: DateTime::parse_from_rfc3339(\"2020-01-01T02:02:02+08:00\")\n            .unwrap(),\n        decimal: Decimal::from_i128_with_scale(3141i128, 3),\n        array: vec![3, 4, 5, 6],\n    };\n    let document_time = DocumentStructTime {\n        id: 2,\n        uuid: Uuid::new_v4(),\n        json_field: serde_json::json! {{\n            \"a\": 25.0,\n            \"b\": \"whatever\",\n            \"c\": {\n                \"another\": \"object\",\n                \"bla\": 1\n            }\n        }},\n        timestamp: date!(2020 - 1 - 1).with_time(time!(2:2:2)),\n        timestamp_with_time_zone: date!(2020 - 01 - 01)\n            .with_time(time!(02:02:02))\n            .assume_utc()\n            .to_offset(offset!(+8)),\n        decimal: Decimal::from_i128_with_scale(3141i128, 3),\n        array: vec![3, 4, 5, 6],\n    };\n\n    let (sql, values) = Query::insert()\n        .into_table(Document::Table)\n        .columns([\n            Document::Uuid,\n            Document::JsonField,\n            Document::Timestamp,\n            Document::TimestampWithTimeZone,\n            Document::Decimal,\n            Document::Array,\n        ])\n        .values_panic([\n            document_chrono.uuid.into(),\n            serde_json::to_value(document_chrono.json_field)\n                .unwrap()\n                .into(),\n            document_chrono.timestamp.into(),\n            document_chrono.timestamp_with_time_zone.into(),\n            document_chrono.decimal.into(),\n            document_chrono.array.into(),\n        ])\n        .values_panic([\n            document_time.uuid.into(),\n            serde_json::to_value(document_time.json_field)\n                .unwrap()\n                .into(),\n            document_time.timestamp.into(),\n            document_time.timestamp_with_time_zone.into(),\n            document_time.decimal.into(),\n            document_time.array.into(),\n        ])\n        .build_postgres(PostgresQueryBuilder);\n\n    let result = client.execute(sql.as_str(), &values.as_params());\n    println!(\"Insert into document: {result:?}\\n\");\n\n    // Read\n\n    let (sql, values) = Query::select()\n        .columns([\n            Document::Id,\n            Document::Uuid,\n            Document::JsonField,\n            Document::Timestamp,\n            Document::TimestampWithTimeZone,\n            Document::Decimal,\n            Document::Array,\n        ])\n        .from(Document::Table)\n        .order_by(Document::Id, Order::Desc)\n        .limit(1)\n        .build_postgres(PostgresQueryBuilder);\n\n    let rows = client.query(sql.as_str(), &values.as_params()).unwrap();\n    println!(\"Select one from document:\");\n    for row in rows.iter() {\n        let item = DocumentStructChrono::from(row);\n        println!(\"{item:?}\");\n\n        let item = DocumentStructTime::from(row);\n        println!(\"{item:?}\");\n    }\n    println!();\n}\n\n#[derive(Iden)]\nenum Document {\n    Table,\n    Id,\n    Uuid,\n    JsonField,\n    Timestamp,\n    TimestampWithTimeZone,\n    Decimal,\n    Array,\n}\n\n#[derive(Debug)]\n#[allow(dead_code)]\nstruct DocumentStructChrono {\n    id: i32,\n    uuid: Uuid,\n    json_field: serde_json::Value,\n    timestamp: NaiveDateTime,\n    timestamp_with_time_zone: DateTime<FixedOffset>,\n    decimal: Decimal,\n    array: Vec<i32>,\n}\n\n#[derive(Debug)]\n#[allow(dead_code)]\nstruct DocumentStructTime {\n    id: i32,\n    uuid: Uuid,\n    json_field: serde_json::Value,\n    timestamp: PrimitiveDateTime,\n    timestamp_with_time_zone: OffsetDateTime,\n    decimal: Decimal,\n    array: Vec<i32>,\n}\n\nimpl From<&Row> for DocumentStructChrono {\n    fn from(row: &Row) -> Self {\n        Self {\n            id: row.get(\"id\"),\n            uuid: row.get(\"uuid\"),\n            json_field: row.get(\"json_field\"),\n            timestamp: row.get(\"timestamp\"),\n            timestamp_with_time_zone: row.get(\"timestamp_with_time_zone\"),\n            decimal: row.get(\"decimal\"),\n            array: row.get(\"array\"),\n        }\n    }\n}\nimpl From<&Row> for DocumentStructTime {\n    fn from(row: &Row) -> Self {\n        Self {\n            id: row.get(\"id\"),\n            uuid: row.get(\"uuid\"),\n            json_field: row.get(\"json_field\"),\n            timestamp: row.get(\"timestamp\"),\n            timestamp_with_time_zone: row.get(\"timestamp_with_time_zone\"),\n            decimal: row.get(\"decimal\"),\n            array: row.get(\"array\"),\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "a088edfc7269507a8bfaa5f20c556893d934aaaa",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-query/tests/more-parentheses.rs",
    "func": "use sea_query::{tests_cfg::Glyph, Cond, Expr, MysqlQueryBuilder, Query};\n\n#[test]\nfn test_more_parentheses() {\n    let query = Query::select()\n        .column(Glyph::Image)\n        .from(Glyph::Table)\n        .cond_where(Cond::all())\n        .cond_where(Expr::val(1).eq(1))\n        .cond_where(Expr::val(2).eq(2))\n        .cond_where(Cond::any().add(Expr::val(3).eq(3)).add(Expr::val(4).eq(4)))\n        .to_owned();\n\n    assert_eq!(\n        query.to_string(MysqlQueryBuilder),\n        \"SELECT `image` FROM `glyph` WHERE (1 = 1) AND (2 = 2) AND ((3 = 3) OR (4 = 4))\"\n    );\n}\n\n#[test]\nfn test_more_parentheses_complex() {\n    // Add pagination\n    let mut pagination = Cond::all();\n    let lt_value = Expr::col(Glyph::Aspect)\n        .lt(1)\n        .or(Expr::col(Glyph::Aspect).is_null());\n    let lt_id = Expr::col(Glyph::Aspect)\n        .is(1)\n        .and(Expr::col(Glyph::Id).lt(10));\n    pagination = pagination.add(lt_value.or(lt_id));\n\n    // Add filtering\n    let mut all = Cond::all();\n    all = all.add(Expr::col(Glyph::Image).eq(\"png\"));\n\n    let mut nested = Cond::all();\n    nested = nested.add(Expr::col(Glyph::Table).gte(5));\n    nested = nested.add(Expr::col(Glyph::Tokens).lte(3));\n    all = all.add(nested);\n\n    let mut any = Cond::any();\n    any = any.add(Expr::col(Glyph::Image).like(\"%.jpg\"));\n    any = any.add(all);\n    let filtering = any;\n\n    // Query\n    let query = Query::select()\n        .column(Glyph::Id)\n        .from(Glyph::Table)\n        .cond_where(Cond::all())\n        .cond_where(pagination)\n        .cond_where(filtering)\n        .to_owned();\n\n    assert_eq!(\n        query.to_string(MysqlQueryBuilder),\n        \"SELECT `id` FROM `glyph` WHERE ((`aspect` < 1) OR (`aspect` IS NULL) OR ((`aspect` IS 1) AND (`id` < 10))) AND ((`image` LIKE '%.jpg') OR ((`image` = 'png') AND ((`glyph` >= 5) AND (`tokens` <= 3))))\"\n    );\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "e3da87b885cc7d98ff586ea7f459074e8657771e",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/ratatui/ratatui/examples/custom_widget.rs",
    "func": "//! # [Ratatui] Custom Widget example\n//!\n//! The latest version of this example is available in the [examples] folder in the repository.\n//!\n//! Please note that the examples are designed to be run against the `main` branch of the Github\n//! repository. This means that you may not be able to compile with the latest release version on\n//! crates.io, or the one that you have installed locally.\n//!\n//! See the [examples readme] for more information on finding examples that match the version of the\n//! library you are using.\n//!\n//! [Ratatui]: https://github.com/ratatui/ratatui\n//! [examples]: https://github.com/ratatui/ratatui/blob/main/examples\n//! [examples readme]: https://github.com/ratatui/ratatui/blob/main/examples/README.md\n\nuse std::{io::stdout, ops::ControlFlow, time::Duration};\n\nuse color_eyre::Result;\nuse ratatui::{\n    buffer::Buffer,\n    crossterm::{\n        event::{\n            self, DisableMouseCapture, EnableMouseCapture, Event, KeyCode, MouseButton, MouseEvent,\n            MouseEventKind,\n        },\n        execute,\n    },\n    layout::{Constraint, Layout, Rect},\n    style::{Color, Style},\n    text::Line,\n    widgets::{Paragraph, Widget},\n    DefaultTerminal, Frame,\n};\n\nfn main() -> Result<()> {\n    color_eyre::install()?;\n    let terminal = ratatui::init();\n    execute!(stdout(), EnableMouseCapture)?;\n    let app_result = run(terminal);\n    ratatui::restore();\n    if let Err(err) = execute!(stdout(), DisableMouseCapture) {\n        eprintln!(\"Error disabling mouse capture: {err}\");\n    }\n    app_result\n}\n\n/// A custom widget that renders a button with a label, theme and state.\n#[derive(Debug, Clone)]\nstruct Button<'a> {\n    label: Line<'a>,\n    theme: Theme,\n    state: State,\n}\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\nenum State {\n    Normal,\n    Selected,\n    Active,\n}\n\n#[derive(Debug, Clone, Copy)]\nstruct Theme {\n    text: Color,\n    background: Color,\n    highlight: Color,\n    shadow: Color,\n}\n\nconst BLUE: Theme = Theme {\n    text: Color::Rgb(16, 24, 48),\n    background: Color::Rgb(48, 72, 144),\n    highlight: Color::Rgb(64, 96, 192),\n    shadow: Color::Rgb(32, 48, 96),\n};\n\nconst RED: Theme = Theme {\n    text: Color::Rgb(48, 16, 16),\n    background: Color::Rgb(144, 48, 48),\n    highlight: Color::Rgb(192, 64, 64),\n    shadow: Color::Rgb(96, 32, 32),\n};\n\nconst GREEN: Theme = Theme {\n    text: Color::Rgb(16, 48, 16),\n    background: Color::Rgb(48, 144, 48),\n    highlight: Color::Rgb(64, 192, 64),\n    shadow: Color::Rgb(32, 96, 32),\n};\n\n/// A button with a label that can be themed.\nimpl<'a> Button<'a> {\n    pub fn new<T: Into<Line<'a>>>(label: T) -> Self {\n        Button {\n            label: label.into(),\n            theme: BLUE,\n            state: State::Normal,\n        }\n    }\n\n    pub const fn theme(mut self, theme: Theme) -> Self {\n        self.theme = theme;\n        self\n    }\n\n    pub const fn state(mut self, state: State) -> Self {\n        self.state = state;\n        self\n    }\n}\n\nimpl Widget for Button<'_> {\n    #[allow(clippy::cast_possible_truncation)]\n    fn render(self, area: Rect, buf: &mut Buffer) {\n        let (background, text, shadow, highlight) = self.colors();\n        buf.set_style(area, Style::new().bg(background).fg(text));\n\n        // render top line if there's enough space\n        if area.height > 2 {\n            buf.set_string(\n                area.x,\n                area.y,\n                \"\u2594\".repeat(area.width as usize),\n                Style::new().fg(highlight).bg(background),\n            );\n        }\n        // render bottom line if there's enough space\n        if area.height > 1 {\n            buf.set_string(\n                area.x,\n                area.y + area.height - 1,\n                \"\u2581\".repeat(area.width as usize),\n                Style::new().fg(shadow).bg(background),\n            );\n        }\n        // render label centered\n        buf.set_line(\n            area.x + (area.width.saturating_sub(self.label.width() as u16)) / 2,\n            area.y + (area.height.saturating_sub(1)) / 2,\n            &self.label,\n            area.width,\n        );\n    }\n}\n\nimpl Button<'_> {\n    const fn colors(&self) -> (Color, Color, Color, Color) {\n        let theme = self.theme;\n        match self.state {\n            State::Normal => (theme.background, theme.text, theme.shadow, theme.highlight),\n            State::Selected => (theme.highlight, theme.text, theme.shadow, theme.highlight),\n            State::Active => (theme.background, theme.text, theme.highlight, theme.shadow),\n        }\n    }\n}\n\nfn run(mut terminal: DefaultTerminal) -> Result<()> {\n    let mut selected_button: usize = 0;\n    let mut button_states = [State::Selected, State::Normal, State::Normal];\n    loop {\n        terminal.draw(|frame| draw(frame, button_states))?;\n        if !event::poll(Duration::from_millis(100))? {\n            continue;\n        }\n        match event::read()? {\n            Event::Key(key) => {\n                if key.kind != event::KeyEventKind::Press {\n                    continue;\n                }\n                if handle_key_event(key, &mut button_states, &mut selected_button).is_break() {\n                    break;\n                }\n            }\n            Event::Mouse(mouse) => {\n                handle_mouse_event(mouse, &mut button_states, &mut selected_button);\n            }\n            _ => (),\n        }\n    }\n    Ok(())\n}\n\nfn draw(frame: &mut Frame, states: [State; 3]) {\n    let vertical = Layout::vertical([\n        Constraint::Length(1),\n        Constraint::Max(3),\n        Constraint::Length(1),\n        Constraint::Min(0), // ignore remaining space\n    ]);\n    let [title, buttons, help, _] = vertical.areas(frame.area());\n\n    frame.render_widget(\n        Paragraph::new(\"Custom Widget Example (mouse enabled)\"),\n        title,\n    );\n    render_buttons(frame, buttons, states);\n    frame.render_widget(Paragraph::new(\"\u2190/\u2192: select, Space: toggle, q: quit\"), help);\n}\n\nfn render_buttons(frame: &mut Frame<'_>, area: Rect, states: [State; 3]) {\n    let horizontal = Layout::horizontal([\n        Constraint::Length(15),\n        Constraint::Length(15),\n        Constraint::Length(15),\n        Constraint::Min(0), // ignore remaining space\n    ]);\n    let [red, green, blue, _] = horizontal.areas(area);\n\n    frame.render_widget(Button::new(\"Red\").theme(RED).state(states[0]), red);\n    frame.render_widget(Button::new(\"Green\").theme(GREEN).state(states[1]), green);\n    frame.render_widget(Button::new(\"Blue\").theme(BLUE).state(states[2]), blue);\n}\n\nfn handle_key_event(\n    key: event::KeyEvent,\n    button_states: &mut [State; 3],\n    selected_button: &mut usize,\n) -> ControlFlow<()> {\n    match key.code {\n        KeyCode::Char('q') => return ControlFlow::Break(()),\n        KeyCode::Left | KeyCode::Char('h') => {\n            button_states[*selected_button] = State::Normal;\n            *selected_button = selected_button.saturating_sub(1);\n            button_states[*selected_button] = State::Selected;\n        }\n        KeyCode::Right | KeyCode::Char('l') => {\n            button_states[*selected_button] = State::Normal;\n            *selected_button = selected_button.saturating_add(1).min(2);\n            button_states[*selected_button] = State::Selected;\n        }\n        KeyCode::Char(' ') => {\n            if button_states[*selected_button] == State::Active {\n                button_states[*selected_button] = State::Normal;\n            } else {\n                button_states[*selected_button] = State::Active;\n            }\n        }\n        _ => (),\n    }\n    ControlFlow::Continue(())\n}\n\nfn handle_mouse_event(\n    mouse: MouseEvent,\n    button_states: &mut [State; 3],\n    selected_button: &mut usize,\n) {\n    match mouse.kind {\n        MouseEventKind::Moved => {\n            let old_selected_button = *selected_button;\n            *selected_button = match mouse.column {\n                x if x < 15 => 0,\n                x if x < 30 => 1,\n                _ => 2,\n            };\n            if old_selected_button != *selected_button {\n                if button_states[old_selected_button] != State::Active {\n                    button_states[old_selected_button] = State::Normal;\n                }\n                if button_states[*selected_button] != State::Active {\n                    button_states[*selected_button] = State::Selected;\n                }\n            }\n        }\n        MouseEventKind::Down(MouseButton::Left) => {\n            if button_states[*selected_button] == State::Active {\n                button_states[*selected_button] = State::Normal;\n            } else {\n                button_states[*selected_button] = State::Active;\n            }\n        }\n        _ => (),\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "8fdf5353868ecc1bd829ef00e8bdb8936e10b9c2",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/ratatui/ratatui/tests/widgets_list.rs",
    "func": "use ratatui::{\n    backend::TestBackend,\n    buffer::Buffer,\n    layout::Rect,\n    style::{Color, Style},\n    symbols,\n    text::Line,\n    widgets::{Block, Borders, HighlightSpacing, List, ListItem, ListState},\n    Terminal,\n};\nuse rstest::rstest;\n\n#[test]\nfn list_should_shows_the_length() {\n    let items = vec![\n        ListItem::new(\"Item 1\"),\n        ListItem::new(\"Item 2\"),\n        ListItem::new(\"Item 3\"),\n    ];\n    let list = List::new(items);\n    assert_eq!(list.len(), 3);\n    assert!(!list.is_empty());\n\n    let empty_list = List::default();\n    assert_eq!(empty_list.len(), 0);\n    assert!(empty_list.is_empty());\n}\n\n#[test]\nfn widgets_list_should_highlight_the_selected_item() {\n    let backend = TestBackend::new(10, 3);\n    let mut terminal = Terminal::new(backend).unwrap();\n    let mut state = ListState::default();\n    state.select(Some(1));\n    terminal\n        .draw(|f| {\n            let items = vec![\n                ListItem::new(\"Item 1\"),\n                ListItem::new(\"Item 2\"),\n                ListItem::new(\"Item 3\"),\n            ];\n            let list = List::new(items)\n                .highlight_style(Style::default().bg(Color::Yellow))\n                .highlight_symbol(\">> \");\n            f.render_stateful_widget(list, f.area(), &mut state);\n        })\n        .unwrap();\n    #[rustfmt::skip]\n    let mut expected = Buffer::with_lines([\n        \"   Item 1 \",\n        \">> Item 2 \",\n        \"   Item 3 \",\n    ]);\n    for x in 0..10 {\n        expected[(x, 1)].set_bg(Color::Yellow);\n    }\n    terminal.backend().assert_buffer(&expected);\n}\n\n#[test]\nfn widgets_list_should_highlight_the_selected_item_wide_symbol() {\n    let backend = TestBackend::new(10, 3);\n    let mut terminal = Terminal::new(backend).unwrap();\n    let mut state = ListState::default();\n\n    let wide_symbol = \"\u25b6  \";\n\n    state.select(Some(1));\n    terminal\n        .draw(|f| {\n            let items = vec![\n                ListItem::new(\"Item 1\"),\n                ListItem::new(\"Item 2\"),\n                ListItem::new(\"Item 3\"),\n            ];\n            let list = List::new(items)\n                .highlight_style(Style::default().bg(Color::Yellow))\n                .highlight_symbol(wide_symbol);\n            f.render_stateful_widget(list, f.area(), &mut state);\n        })\n        .unwrap();\n    #[rustfmt::skip]\n    let mut expected = Buffer::with_lines([\n        \"   Item 1 \",\n        \"\u25b6  Item 2 \",\n        \"   Item 3 \",\n    ]);\n    for x in 0..10 {\n        expected[(x, 1)].set_bg(Color::Yellow);\n    }\n    terminal.backend().assert_buffer(&expected);\n}\n\n#[test]\nfn widgets_list_should_truncate_items() {\n    struct TruncateTestCase<'a> {\n        selected: Option<usize>,\n        items: Vec<ListItem<'a>>,\n        expected: Buffer,\n    }\n\n    let backend = TestBackend::new(10, 2);\n    let mut terminal = Terminal::new(backend).unwrap();\n\n    let cases = [\n        // An item is selected\n        TruncateTestCase {\n            selected: Some(0),\n            items: vec![\n                ListItem::new(\"A very long line\"),\n                ListItem::new(\"A very long line\"),\n            ],\n            expected: Buffer::with_lines([\n                format!(\">> A ve{}  \", symbols::line::VERTICAL),\n                format!(\"   A ve{}  \", symbols::line::VERTICAL),\n            ]),\n        },\n        // No item is selected\n        TruncateTestCase {\n            selected: None,\n            items: vec![\n                ListItem::new(\"A very long line\"),\n                ListItem::new(\"A very long line\"),\n            ],\n            expected: Buffer::with_lines([\n                format!(\"A very {}  \", symbols::line::VERTICAL),\n                format!(\"A very {}  \", symbols::line::VERTICAL),\n            ]),\n        },\n    ];\n    for case in cases {\n        let mut state = ListState::default();\n        state.select(case.selected);\n        terminal\n            .draw(|f| {\n                let list = List::new(case.items.clone())\n                    .block(Block::new().borders(Borders::RIGHT))\n                    .highlight_symbol(\">> \");\n                f.render_stateful_widget(list, Rect::new(0, 0, 8, 2), &mut state);\n            })\n            .unwrap();\n        terminal.backend().assert_buffer(&case.expected);\n    }\n}\n\n#[test]\nfn widgets_list_should_clamp_offset_if_items_are_removed() {\n    let backend = TestBackend::new(10, 4);\n    let mut terminal = Terminal::new(backend).unwrap();\n    let mut state = ListState::default();\n\n    // render with 6 items => offset will be at 2\n    state.select(Some(5));\n    terminal\n        .draw(|f| {\n            let items = vec![\n                ListItem::new(\"Item 0\"),\n                ListItem::new(\"Item 1\"),\n                ListItem::new(\"Item 2\"),\n                ListItem::new(\"Item 3\"),\n                ListItem::new(\"Item 4\"),\n                ListItem::new(\"Item 5\"),\n            ];\n            let list = List::new(items).highlight_symbol(\">> \");\n            f.render_stateful_widget(list, f.area(), &mut state);\n        })\n        .unwrap();\n    terminal.backend().assert_buffer_lines([\n        \"   Item 2 \",\n        \"   Item 3 \",\n        \"   Item 4 \",\n        \">> Item 5 \",\n    ]);\n\n    // render again with 1 items => check offset is clamped to 1\n    state.select(Some(1));\n    terminal\n        .draw(|f| {\n            let items = vec![ListItem::new(\"Item 3\")];\n            let list = List::new(items).highlight_symbol(\">> \");\n            f.render_stateful_widget(list, f.area(), &mut state);\n        })\n        .unwrap();\n    terminal.backend().assert_buffer_lines([\n        \">> Item 3 \",\n        \"          \",\n        \"          \",\n        \"          \",\n    ]);\n}\n\n#[test]\nfn widgets_list_should_display_multiline_items() {\n    let backend = TestBackend::new(10, 6);\n    let mut terminal = Terminal::new(backend).unwrap();\n    let mut state = ListState::default();\n    state.select(Some(1));\n    terminal\n        .draw(|f| {\n            let items = vec![\n                ListItem::new(vec![Line::from(\"Item 1\"), Line::from(\"Item 1a\")]),\n                ListItem::new(vec![Line::from(\"Item 2\"), Line::from(\"Item 2b\")]),\n                ListItem::new(vec![Line::from(\"Item 3\"), Line::from(\"Item 3c\")]),\n            ];\n            let list = List::new(items)\n                .highlight_style(Style::default().bg(Color::Yellow))\n                .highlight_symbol(\">> \");\n            f.render_stateful_widget(list, f.area(), &mut state);\n        })\n        .unwrap();\n    let mut expected = Buffer::with_lines([\n        \"   Item 1 \",\n        \"   Item 1a\",\n        \">> Item 2 \",\n        \"   Item 2b\",\n        \"   Item 3 \",\n        \"   Item 3c\",\n    ]);\n    for x in 0..10 {\n        expected[(x, 2)].set_bg(Color::Yellow);\n        expected[(x, 3)].set_bg(Color::Yellow);\n    }\n    terminal.backend().assert_buffer(&expected);\n}\n\n#[test]\nfn widgets_list_should_repeat_highlight_symbol() {\n    let backend = TestBackend::new(10, 6);\n    let mut terminal = Terminal::new(backend).unwrap();\n    let mut state = ListState::default();\n    state.select(Some(1));\n    terminal\n        .draw(|f| {\n            let items = vec![\n                ListItem::new(vec![Line::from(\"Item 1\"), Line::from(\"Item 1a\")]),\n                ListItem::new(vec![Line::from(\"Item 2\"), Line::from(\"Item 2b\")]),\n                ListItem::new(vec![Line::from(\"Item 3\"), Line::from(\"Item 3c\")]),\n            ];\n            let list = List::new(items)\n                .highlight_style(Style::default().bg(Color::Yellow))\n                .highlight_symbol(\">> \")\n                .repeat_highlight_symbol(true);\n            f.render_stateful_widget(list, f.area(), &mut state);\n        })\n        .unwrap();\n    let mut expected = Buffer::with_lines([\n        \"   Item 1 \",\n        \"   Item 1a\",\n        \">> Item 2 \",\n        \">> Item 2b\",\n        \"   Item 3 \",\n        \"   Item 3c\",\n    ]);\n    for x in 0..10 {\n        expected[(x, 2)].set_bg(Color::Yellow);\n        expected[(x, 3)].set_bg(Color::Yellow);\n    }\n    terminal.backend().assert_buffer(&expected);\n}\n\n#[test]\nfn widget_list_should_not_ignore_empty_string_items() {\n    let backend = TestBackend::new(6, 4);\n    let mut terminal = Terminal::new(backend).unwrap();\n    terminal\n        .draw(|f| {\n            let items = vec![\n                ListItem::new(\"Item 1\"),\n                ListItem::new(\"\"),\n                ListItem::new(\"\"),\n                ListItem::new(\"Item 4\"),\n            ];\n\n            let list = List::new(items)\n                .style(Style::default())\n                .highlight_style(Style::default());\n\n            f.render_widget(list, f.area());\n        })\n        .unwrap();\n    terminal\n        .backend()\n        .assert_buffer_lines([\"Item 1\", \"\", \"\", \"Item 4\"]);\n}\n\n#[rstest]\n#[case::none_when_selected(None, HighlightSpacing::WhenSelected, [\n    \"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\",\n    \"\u2502Item 1       \u2502\",\n    \"\u2502Item 1a      \u2502\",\n    \"\u2502Item 2       \u2502\",\n    \"\u2502Item 2b      \u2502\",\n    \"\u2502Item 3       \u2502\",\n    \"\u2502Item 3c      \u2502\",\n    \"\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\",\n])]\n#[case::none_always(None, HighlightSpacing::Always, [\n    \"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\",\n    \"\u2502   Item 1    \u2502\",\n    \"\u2502   Item 1a   \u2502\",\n    \"\u2502   Item 2    \u2502\",\n    \"\u2502   Item 2b   \u2502\",\n    \"\u2502   Item 3    \u2502\",\n    \"\u2502   Item 3c   \u2502\",\n    \"\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\",\n])]\n#[case::none_never(None, HighlightSpacing::Never, [\n    \"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\",\n    \"\u2502Item 1       \u2502\",\n    \"\u2502Item 1a      \u2502\",\n    \"\u2502Item 2       \u2502\",\n    \"\u2502Item 2b      \u2502\",\n    \"\u2502Item 3       \u2502\",\n    \"\u2502Item 3c      \u2502\",\n    \"\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\",\n])]\n#[case::first_when_selected(Some(0), HighlightSpacing::WhenSelected, [\n    \"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\",\n    \"\u2502>> Item 1    \u2502\",\n    \"\u2502   Item 1a   \u2502\",\n    \"\u2502   Item 2    \u2502\",\n    \"\u2502   Item 2b   \u2502\",\n    \"\u2502   Item 3    \u2502\",\n    \"\u2502   Item 3c   \u2502\",\n    \"\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\",\n])]\n#[case::first_always(Some(0), HighlightSpacing::Always, [\n    \"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\",\n    \"\u2502>> Item 1    \u2502\",\n    \"\u2502   Item 1a   \u2502\",\n    \"\u2502   Item 2    \u2502\",\n    \"\u2502   Item 2b   \u2502\",\n    \"\u2502   Item 3    \u2502\",\n    \"\u2502   Item 3c   \u2502\",\n    \"\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\",\n])]\n#[case::first_never(Some(0), HighlightSpacing::Never, [\n    \"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\",\n    \"\u2502Item 1       \u2502\",\n    \"\u2502Item 1a      \u2502\",\n    \"\u2502Item 2       \u2502\",\n    \"\u2502Item 2b      \u2502\",\n    \"\u2502Item 3       \u2502\",\n    \"\u2502Item 3c      \u2502\",\n    \"\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\",\n])]\nfn widgets_list_enable_always_highlight_spacing<'line, Lines>(\n    #[case] selected: Option<usize>,\n    #[case] space: HighlightSpacing,\n    #[case] expected: Lines,\n) where\n    Lines: IntoIterator,\n    Lines::Item: Into<Line<'line>>,\n{\n    let mut state = ListState::default().with_selected(selected);\n    let backend = TestBackend::new(15, 8);\n    let mut terminal = Terminal::new(backend).unwrap();\n    terminal\n        .draw(|f| {\n            let table = List::new(vec![\n                ListItem::new(vec![Line::from(\"Item 1\"), Line::from(\"Item 1a\")]),\n                ListItem::new(vec![Line::from(\"Item 2\"), Line::from(\"Item 2b\")]),\n                ListItem::new(vec![Line::from(\"Item 3\"), Line::from(\"Item 3c\")]),\n            ])\n            .block(Block::bordered())\n            .highlight_symbol(\">> \")\n            .highlight_spacing(space);\n            f.render_stateful_widget(table, f.area(), &mut state);\n        })\n        .unwrap();\n    terminal\n        .backend()\n        .assert_buffer(&Buffer::with_lines(expected));\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "ee5132126693eb2611e5dbc01d5a25288f9b4657",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/alacritty/alacritty/src/clipboard.rs",
    "func": "use log::{debug, warn};\nuse winit::raw_window_handle::RawDisplayHandle;\n\nuse alacritty_terminal::term::ClipboardType;\n\nuse copypasta::nop_clipboard::NopClipboardContext;\n#[cfg(all(feature = \"wayland\", not(any(target_os = \"macos\", windows))))]\nuse copypasta::wayland_clipboard;\n#[cfg(all(feature = \"x11\", not(any(target_os = \"macos\", windows))))]\nuse copypasta::x11_clipboard::{Primary as X11SelectionClipboard, X11ClipboardContext};\n#[cfg(any(feature = \"x11\", target_os = \"macos\", windows))]\nuse copypasta::ClipboardContext;\nuse copypasta::ClipboardProvider;\n\npub struct Clipboard {\n    clipboard: Box<dyn ClipboardProvider>,\n    selection: Option<Box<dyn ClipboardProvider>>,\n}\n\nimpl Clipboard {\n    pub unsafe fn new(display: RawDisplayHandle) -> Self {\n        match display {\n            #[cfg(all(feature = \"wayland\", not(any(target_os = \"macos\", windows))))]\n            RawDisplayHandle::Wayland(display) => {\n                let (selection, clipboard) =\n                    wayland_clipboard::create_clipboards_from_external(display.display.as_ptr());\n                Self { clipboard: Box::new(clipboard), selection: Some(Box::new(selection)) }\n            },\n            _ => Self::default(),\n        }\n    }\n\n    /// Used for tests, to handle missing clipboard provider when built without the `x11`\n    /// feature, and as default clipboard value.\n    pub fn new_nop() -> Self {\n        Self { clipboard: Box::new(NopClipboardContext::new().unwrap()), selection: None }\n    }\n}\n\nimpl Default for Clipboard {\n    fn default() -> Self {\n        #[cfg(any(target_os = \"macos\", windows))]\n        return Self { clipboard: Box::new(ClipboardContext::new().unwrap()), selection: None };\n\n        #[cfg(all(feature = \"x11\", not(any(target_os = \"macos\", windows))))]\n        return Self {\n            clipboard: Box::new(ClipboardContext::new().unwrap()),\n            selection: Some(Box::new(X11ClipboardContext::<X11SelectionClipboard>::new().unwrap())),\n        };\n\n        #[cfg(not(any(feature = \"x11\", target_os = \"macos\", windows)))]\n        return Self::new_nop();\n    }\n}\n\nimpl Clipboard {\n    pub fn store(&mut self, ty: ClipboardType, text: impl Into<String>) {\n        let clipboard = match (ty, &mut self.selection) {\n            (ClipboardType::Selection, Some(provider)) => provider,\n            (ClipboardType::Selection, None) => return,\n            _ => &mut self.clipboard,\n        };\n\n        clipboard.set_contents(text.into()).unwrap_or_else(|err| {\n            warn!(\"Unable to store text in clipboard: {}\", err);\n        });\n    }\n\n    pub fn load(&mut self, ty: ClipboardType) -> String {\n        let clipboard = match (ty, &mut self.selection) {\n            (ClipboardType::Selection, Some(provider)) => provider,\n            _ => &mut self.clipboard,\n        };\n\n        match clipboard.get_contents() {\n            Err(err) => {\n                debug!(\"Unable to load text from clipboard: {}\", err);\n                String::new()\n            },\n            Ok(text) => text,\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "a32c02ddac5d2b0a545b22c8e09bc12a1b306d2c",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-query/sea-query-derive/src/iden/path.rs",
    "func": "use std::fmt::Display;\n\n#[derive(Debug)]\npub enum IdenPath {\n    Iden,\n    Method,\n    Rename,\n    Flatten,\n}\n\nimpl IdenPath {\n    const fn as_str(&self) -> &'static str {\n        match self {\n            IdenPath::Iden => \"iden\",\n            IdenPath::Method => \"method\",\n            IdenPath::Rename => \"rename\",\n            IdenPath::Flatten => \"flatten\",\n        }\n    }\n}\n\nimpl Display for IdenPath {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        write!(f, \"{}\", self.as_str())\n    }\n}\n\nimpl PartialEq<IdenPath> for syn::Ident {\n    fn eq(&self, other: &IdenPath) -> bool {\n        self.eq(other.as_str())\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "a64524678db181c0b389f9167fc0e65fcb2a1127",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/ratatui/ratatui-widgets/src/list/item.rs",
    "func": "use ratatui_core::{style::Style, text::Text};\n\n/// A single item in a [`List`]\n///\n/// The item's height is defined by the number of lines it contains. This can be queried using\n/// [`ListItem::height`]. Similarly, [`ListItem::width`] will return the maximum width of all\n/// lines.\n///\n/// You can set the style of an item with [`ListItem::style`] or using the [`Stylize`] trait.\n/// This [`Style`] will be combined with the [`Style`] of the inner [`Text`]. The [`Style`]\n/// of the [`Text`] will be added to the [`Style`] of the [`ListItem`].\n///\n/// You can also align a `ListItem` by aligning its underlying [`Text`] and [`Line`]s. For that,\n/// see [`Text::alignment`] and [`Line::alignment`]. On a multiline `Text`, one `Line` can override\n/// the alignment by setting it explicitly.\n///\n/// # Examples\n///\n/// You can create [`ListItem`]s from simple `&str`\n///\n/// ```rust\n/// use ratatui::widgets::ListItem;\n/// let item = ListItem::new(\"Item 1\");\n/// ```\n///\n/// Anything that can be converted to [`Text`] can be a [`ListItem`].\n///\n/// ```rust\n/// use ratatui::{text::Line, widgets::ListItem};\n///\n/// let item1: ListItem = \"Item 1\".into();\n/// let item2: ListItem = Line::raw(\"Item 2\").into();\n/// ```\n///\n/// A [`ListItem`] styled with [`Stylize`]\n///\n/// ```rust\n/// use ratatui::{style::Stylize, widgets::ListItem};\n///\n/// let item = ListItem::new(\"Item 1\").red().on_white();\n/// ```\n///\n/// If you need more control over the item's style, you can explicitly style the underlying\n/// [`Text`]\n///\n/// ```rust\n/// use ratatui::{\n///     style::Stylize,\n///     text::{Span, Text},\n///     widgets::ListItem,\n/// };\n///\n/// let mut text = Text::default();\n/// text.extend([\"Item\".blue(), Span::raw(\" \"), \"1\".bold().red()]);\n/// let item = ListItem::new(text);\n/// ```\n///\n/// A right-aligned `ListItem`\n///\n/// ```rust\n/// use ratatui::{text::Text, widgets::ListItem};\n///\n/// ListItem::new(Text::from(\"foo\").right_aligned());\n/// ```\n///\n/// [`List`]: crate::list::List\n/// [`Stylize`]: ratatui_core::style::Stylize\n/// [`Line`]: ratatui_core::text::Line\n/// [`Line::alignment`]: ratatui_core::text::Line::alignment\n#[derive(Debug, Clone, Eq, PartialEq, Hash)]\npub struct ListItem<'a> {\n    pub(crate) content: Text<'a>,\n    pub(crate) style: Style,\n}\n\nimpl<'a> ListItem<'a> {\n    /// Creates a new [`ListItem`]\n    ///\n    /// The `content` parameter accepts any value that can be converted into [`Text`].\n    ///\n    /// # Examples\n    ///\n    /// You can create [`ListItem`]s from simple `&str`\n    ///\n    /// ```rust\n    /// use ratatui::widgets::ListItem;\n    ///\n    /// let item = ListItem::new(\"Item 1\");\n    /// ```\n    ///\n    /// Anything that can be converted to [`Text`] can be a [`ListItem`].\n    ///\n    /// ```rust\n    /// use ratatui::{text::Line, widgets::ListItem};\n    ///\n    /// let item1: ListItem = \"Item 1\".into();\n    /// let item2: ListItem = Line::raw(\"Item 2\").into();\n    /// ```\n    ///\n    /// You can also create multiline items\n    ///\n    /// ```rust\n    /// use ratatui::widgets::ListItem;\n    ///\n    /// let item = ListItem::new(\"Multi-line\\nitem\");\n    /// ```\n    ///\n    /// # See also\n    ///\n    /// - [`List::new`](super::List::new) to create a list of items that can be converted to\n    ///   [`ListItem`]\n    pub fn new<T>(content: T) -> Self\n    where\n        T: Into<Text<'a>>,\n    {\n        Self {\n            content: content.into(),\n            style: Style::default(),\n        }\n    }\n\n    /// Sets the item style\n    ///\n    /// `style` accepts any type that is convertible to [`Style`] (e.g. [`Style`], [`Color`], or\n    /// your own type that implements [`Into<Style>`]).\n    ///\n    /// This [`Style`] can be overridden by the [`Style`] of the [`Text`] content.\n    ///\n    /// This is a fluent setter method which must be chained or used as it consumes self\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// use ratatui::{\n    ///     style::{Style, Stylize},\n    ///     widgets::ListItem,\n    /// };\n    ///\n    /// let item = ListItem::new(\"Item 1\").style(Style::new().red().italic());\n    /// ```\n    ///\n    /// `ListItem` also implements the [`Styled`] trait, which means you can use style shorthands\n    /// from the [`Stylize`](ratatui_core::style::Stylize) trait to set the style of the widget more\n    /// concisely.\n    ///\n    /// ```rust\n    /// use ratatui::{style::Stylize, widgets::ListItem};\n    ///\n    /// let item = ListItem::new(\"Item 1\").red().italic();\n    /// ```\n    ///\n    /// [`Styled`]: ratatui_core::style::Styled\n    /// [`ListState`]: crate::list::ListState\n    /// [`Color`]: ratatui_core::style::Color\n    #[must_use = \"method moves the value of self and returns the modified value\"]\n    pub fn style<S: Into<Style>>(mut self, style: S) -> Self {\n        self.style = style.into();\n        self\n    }\n\n    /// Returns the item height\n    ///\n    /// # Examples\n    ///\n    /// One line item\n    ///\n    /// ```rust\n    /// use ratatui::widgets::ListItem;\n    ///\n    /// let item = ListItem::new(\"Item 1\");\n    /// assert_eq!(item.height(), 1);\n    /// ```\n    ///\n    /// Two lines item (note the `\\n`)\n    ///\n    /// ```rust\n    /// use ratatui::widgets::ListItem;\n    ///\n    /// let item = ListItem::new(\"Multi-line\\nitem\");\n    /// assert_eq!(item.height(), 2);\n    /// ```\n    pub fn height(&self) -> usize {\n        self.content.height()\n    }\n\n    /// Returns the max width of all the lines\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// use ratatui::widgets::ListItem;\n    ///\n    /// let item = ListItem::new(\"12345\");\n    /// assert_eq!(item.width(), 5);\n    /// ```\n    ///\n    /// ```rust\n    /// use ratatui::widgets::ListItem;\n    ///\n    /// let item = ListItem::new(\"12345\\n1234567\");\n    /// assert_eq!(item.width(), 7);\n    /// ```\n    pub fn width(&self) -> usize {\n        self.content.width()\n    }\n}\n\nimpl<'a, T> From<T> for ListItem<'a>\nwhere\n    T: Into<Text<'a>>,\n{\n    fn from(value: T) -> Self {\n        Self::new(value)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use std::borrow::Cow;\n\n    use pretty_assertions::assert_eq;\n    use ratatui_core::{\n        style::{Color, Modifier, Stylize},\n        text::{Line, Span},\n    };\n\n    use super::*;\n\n    #[test]\n    fn new_from_str() {\n        let item = ListItem::new(\"Test item\");\n        assert_eq!(item.content, Text::from(\"Test item\"));\n        assert_eq!(item.style, Style::default());\n    }\n\n    #[test]\n    fn new_from_string() {\n        let item = ListItem::new(\"Test item\".to_string());\n        assert_eq!(item.content, Text::from(\"Test item\"));\n        assert_eq!(item.style, Style::default());\n    }\n\n    #[test]\n    fn new_from_cow_str() {\n        let item = ListItem::new(Cow::Borrowed(\"Test item\"));\n        assert_eq!(item.content, Text::from(\"Test item\"));\n        assert_eq!(item.style, Style::default());\n    }\n\n    #[test]\n    fn new_from_span() {\n        let span = Span::styled(\"Test item\", Style::default().fg(Color::Blue));\n        let item = ListItem::new(span.clone());\n        assert_eq!(item.content, Text::from(span));\n        assert_eq!(item.style, Style::default());\n    }\n\n    #[test]\n    fn new_from_spans() {\n        let spans = Line::from(vec![\n            Span::styled(\"Test \", Style::default().fg(Color::Blue)),\n            Span::styled(\"item\", Style::default().fg(Color::Red)),\n        ]);\n        let item = ListItem::new(spans.clone());\n        assert_eq!(item.content, Text::from(spans));\n        assert_eq!(item.style, Style::default());\n    }\n\n    #[test]\n    fn new_from_vec_spans() {\n        let lines = vec![\n            Line::from(vec![\n                Span::styled(\"Test \", Style::default().fg(Color::Blue)),\n                Span::styled(\"item\", Style::default().fg(Color::Red)),\n            ]),\n            Line::from(vec![\n                Span::styled(\"Second \", Style::default().fg(Color::Green)),\n                Span::styled(\"line\", Style::default().fg(Color::Yellow)),\n            ]),\n        ];\n        let item = ListItem::new(lines.clone());\n        assert_eq!(item.content, Text::from(lines));\n        assert_eq!(item.style, Style::default());\n    }\n\n    #[test]\n    fn str_into_list_item() {\n        let s = \"Test item\";\n        let item: ListItem = s.into();\n        assert_eq!(item.content, Text::from(s));\n        assert_eq!(item.style, Style::default());\n    }\n\n    #[test]\n    fn string_into_list_item() {\n        let s = String::from(\"Test item\");\n        let item: ListItem = s.clone().into();\n        assert_eq!(item.content, Text::from(s));\n        assert_eq!(item.style, Style::default());\n    }\n\n    #[test]\n    fn span_into_list_item() {\n        let s = Span::from(\"Test item\");\n        let item: ListItem = s.clone().into();\n        assert_eq!(item.content, Text::from(s));\n        assert_eq!(item.style, Style::default());\n    }\n\n    #[test]\n    fn vec_lines_into_list_item() {\n        let lines = vec![Line::raw(\"l1\"), Line::raw(\"l2\")];\n        let item: ListItem = lines.clone().into();\n        assert_eq!(item.content, Text::from(lines));\n        assert_eq!(item.style, Style::default());\n    }\n\n    #[test]\n    fn style() {\n        let item = ListItem::new(\"Test item\").style(Style::default().bg(Color::Red));\n        assert_eq!(item.content, Text::from(\"Test item\"));\n        assert_eq!(item.style, Style::default().bg(Color::Red));\n    }\n\n    #[test]\n    fn height() {\n        let item = ListItem::new(\"Test item\");\n        assert_eq!(item.height(), 1);\n\n        let item = ListItem::new(\"Test item\\nSecond line\");\n        assert_eq!(item.height(), 2);\n    }\n\n    #[test]\n    fn width() {\n        let item = ListItem::new(\"Test item\");\n        assert_eq!(item.width(), 9);\n    }\n\n    #[test]\n    fn can_be_stylized() {\n        assert_eq!(\n            ListItem::new(\"\").black().on_white().bold().not_dim().style,\n            Style::default()\n                .fg(Color::Black)\n                .bg(Color::White)\n                .add_modifier(Modifier::BOLD)\n                .remove_modifier(Modifier::DIM)\n        );\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "5b94077cd19cc1726c88739ec23ac7394a6566fd",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/alacritty/alacritty/src/config/selection.rs",
    "func": "use alacritty_config_derive::ConfigDeserialize;\nuse alacritty_terminal::term::SEMANTIC_ESCAPE_CHARS;\n\n#[derive(ConfigDeserialize, Clone, Debug, PartialEq, Eq)]\npub struct Selection {\n    pub semantic_escape_chars: String,\n    pub save_to_clipboard: bool,\n}\n\nimpl Default for Selection {\n    fn default() -> Self {\n        Self {\n            semantic_escape_chars: SEMANTIC_ESCAPE_CHARS.to_owned(),\n            save_to_clipboard: Default::default(),\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "fda1910a5e8a3a53d98d91eaa07ae4aa42abb2e5",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/alacritty/alacritty_terminal/src/tty/windows/child.rs",
    "func": "use std::ffi::c_void;\nuse std::io::Error;\nuse std::num::NonZeroU32;\nuse std::ptr;\nuse std::sync::atomic::{AtomicPtr, Ordering};\nuse std::sync::{mpsc, Arc, Mutex};\n\nuse polling::os::iocp::{CompletionPacket, PollerIocpExt};\nuse polling::{Event, Poller};\n\nuse windows_sys::Win32::Foundation::{BOOLEAN, FALSE, HANDLE};\nuse windows_sys::Win32::System::Threading::{\n    GetExitCodeProcess, GetProcessId, RegisterWaitForSingleObject, UnregisterWait, INFINITE,\n    WT_EXECUTEINWAITTHREAD, WT_EXECUTEONLYONCE,\n};\n\nuse crate::tty::ChildEvent;\n\nstruct Interest {\n    poller: Arc<Poller>,\n    event: Event,\n}\n\nstruct ChildExitSender {\n    sender: mpsc::Sender<ChildEvent>,\n    interest: Arc<Mutex<Option<Interest>>>,\n    child_handle: AtomicPtr<c_void>,\n}\n\n/// WinAPI callback to run when child process exits.\nextern \"system\" fn child_exit_callback(ctx: *mut c_void, timed_out: BOOLEAN) {\n    if timed_out != 0 {\n        return;\n    }\n\n    let event_tx: Box<_> = unsafe { Box::from_raw(ctx as *mut ChildExitSender) };\n\n    let mut exit_code = 0_u32;\n    let child_handle = event_tx.child_handle.load(Ordering::Relaxed) as HANDLE;\n    let status = unsafe { GetExitCodeProcess(child_handle, &mut exit_code) };\n    let exit_code = if status == FALSE { None } else { Some(exit_code as i32) };\n    event_tx.sender.send(ChildEvent::Exited(exit_code)).ok();\n\n    let interest = event_tx.interest.lock().unwrap();\n    if let Some(interest) = interest.as_ref() {\n        interest.poller.post(CompletionPacket::new(interest.event)).ok();\n    }\n}\n\npub struct ChildExitWatcher {\n    wait_handle: AtomicPtr<c_void>,\n    event_rx: mpsc::Receiver<ChildEvent>,\n    interest: Arc<Mutex<Option<Interest>>>,\n    child_handle: AtomicPtr<c_void>,\n    pid: Option<NonZeroU32>,\n}\n\nimpl ChildExitWatcher {\n    pub fn new(child_handle: HANDLE) -> Result<ChildExitWatcher, Error> {\n        let (event_tx, event_rx) = mpsc::channel();\n\n        let mut wait_handle: HANDLE = ptr::null_mut();\n        let interest = Arc::new(Mutex::new(None));\n        let sender_ref = Box::new(ChildExitSender {\n            sender: event_tx,\n            interest: interest.clone(),\n            child_handle: AtomicPtr::from(child_handle),\n        });\n\n        let success = unsafe {\n            RegisterWaitForSingleObject(\n                &mut wait_handle,\n                child_handle,\n                Some(child_exit_callback),\n                Box::into_raw(sender_ref).cast(),\n                INFINITE,\n                WT_EXECUTEINWAITTHREAD | WT_EXECUTEONLYONCE,\n            )\n        };\n\n        if success == 0 {\n            Err(Error::last_os_error())\n        } else {\n            let pid = unsafe { NonZeroU32::new(GetProcessId(child_handle)) };\n            Ok(ChildExitWatcher {\n                event_rx,\n                interest,\n                pid,\n                child_handle: AtomicPtr::from(child_handle),\n                wait_handle: AtomicPtr::from(wait_handle),\n            })\n        }\n    }\n\n    pub fn event_rx(&self) -> &mpsc::Receiver<ChildEvent> {\n        &self.event_rx\n    }\n\n    pub fn register(&self, poller: &Arc<Poller>, event: Event) {\n        *self.interest.lock().unwrap() = Some(Interest { poller: poller.clone(), event });\n    }\n\n    pub fn deregister(&self) {\n        *self.interest.lock().unwrap() = None;\n    }\n\n    /// Retrieve the process handle of the underlying child process.\n    ///\n    /// This function does **not** pass ownership of the raw handle to you,\n    /// and the handle is only guaranteed to be valid while the hosted application\n    /// has not yet been destroyed.\n    ///\n    /// If you terminate the process using this handle, the terminal will get a\n    /// timeout error, and the child watcher will emit an `Exited` event.\n    pub fn raw_handle(&self) -> HANDLE {\n        self.child_handle.load(Ordering::Relaxed) as HANDLE\n    }\n\n    /// Retrieve the Process ID associated to the underlying child process.\n    pub fn pid(&self) -> Option<NonZeroU32> {\n        self.pid\n    }\n}\n\nimpl Drop for ChildExitWatcher {\n    fn drop(&mut self) {\n        unsafe {\n            UnregisterWait(self.wait_handle.load(Ordering::Relaxed) as HANDLE);\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use std::os::windows::io::AsRawHandle;\n    use std::process::Command;\n    use std::sync::Arc;\n    use std::time::Duration;\n\n    use super::super::PTY_CHILD_EVENT_TOKEN;\n    use super::*;\n\n    #[test]\n    pub fn event_is_emitted_when_child_exits() {\n        const WAIT_TIMEOUT: Duration = Duration::from_millis(200);\n\n        let poller = Arc::new(Poller::new().unwrap());\n\n        let mut child = Command::new(\"cmd.exe\").spawn().unwrap();\n        let child_exit_watcher = ChildExitWatcher::new(child.as_raw_handle() as HANDLE).unwrap();\n        child_exit_watcher.register(&poller, Event::readable(PTY_CHILD_EVENT_TOKEN));\n\n        child.kill().unwrap();\n\n        // Poll for the event or fail with timeout if nothing has been sent.\n        let mut events = polling::Events::new();\n        poller.wait(&mut events, Some(WAIT_TIMEOUT)).unwrap();\n        assert_eq!(events.iter().next().unwrap().key, PTY_CHILD_EVENT_TOKEN);\n        // Verify that at least one `ChildEvent::Exited` was received.\n        assert_eq!(child_exit_watcher.event_rx().try_recv(), Ok(ChildEvent::Exited(Some(1))));\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "9809b1cd99d308059128accf573cfe1036a9f170",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/fd/src/filter/size.rs",
    "func": "use std::sync::OnceLock;\n\nuse anyhow::anyhow;\nuse regex::Regex;\n\nstatic SIZE_CAPTURES: OnceLock<Regex> = OnceLock::new();\n\n#[derive(Clone, Copy, Debug, PartialEq, Eq)]\npub enum SizeFilter {\n    Max(u64),\n    Min(u64),\n    Equals(u64),\n}\n\n// SI prefixes (powers of 10)\nconst KILO: u64 = 1000;\nconst MEGA: u64 = KILO * 1000;\nconst GIGA: u64 = MEGA * 1000;\nconst TERA: u64 = GIGA * 1000;\n\n// Binary prefixes (powers of 2)\nconst KIBI: u64 = 1024;\nconst MEBI: u64 = KIBI * 1024;\nconst GIBI: u64 = MEBI * 1024;\nconst TEBI: u64 = GIBI * 1024;\n\nimpl SizeFilter {\n    pub fn from_string(s: &str) -> anyhow::Result<Self> {\n        SizeFilter::parse_opt(s)\n            .ok_or_else(|| anyhow!(\"'{}' is not a valid size constraint. See 'fd --help'.\", s))\n    }\n\n    fn parse_opt(s: &str) -> Option<Self> {\n        let pattern =\n            SIZE_CAPTURES.get_or_init(|| Regex::new(r\"(?i)^([+-]?)(\\d+)(b|[kmgt]i?b?)$\").unwrap());\n        if !pattern.is_match(s) {\n            return None;\n        }\n\n        let captures = pattern.captures(s)?;\n        let limit_kind = captures.get(1).map_or(\"+\", |m| m.as_str());\n        let quantity = captures\n            .get(2)\n            .and_then(|v| v.as_str().parse::<u64>().ok())?;\n\n        let multiplier = match &captures.get(3).map_or(\"b\", |m| m.as_str()).to_lowercase()[..] {\n            v if v.starts_with(\"ki\") => KIBI,\n            v if v.starts_with('k') => KILO,\n            v if v.starts_with(\"mi\") => MEBI,\n            v if v.starts_with('m') => MEGA,\n            v if v.starts_with(\"gi\") => GIBI,\n            v if v.starts_with('g') => GIGA,\n            v if v.starts_with(\"ti\") => TEBI,\n            v if v.starts_with('t') => TERA,\n            \"b\" => 1,\n            _ => return None,\n        };\n\n        let size = quantity * multiplier;\n        match limit_kind {\n            \"+\" => Some(SizeFilter::Min(size)),\n            \"-\" => Some(SizeFilter::Max(size)),\n            \"\" => Some(SizeFilter::Equals(size)),\n            _ => None,\n        }\n    }\n\n    pub fn is_within(&self, size: u64) -> bool {\n        match *self {\n            SizeFilter::Max(limit) => size <= limit,\n            SizeFilter::Min(limit) => size >= limit,\n            SizeFilter::Equals(limit) => size == limit,\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    macro_rules! gen_size_filter_parse_test {\n        ($($name: ident: $val: expr,)*) => {\n            $(\n                #[test]\n                fn $name() {\n                    let (txt, expected) = $val;\n                    let actual = SizeFilter::from_string(txt).unwrap();\n                    assert_eq!(actual, expected);\n                }\n            )*\n        };\n    }\n\n    // Parsing and size conversion tests data. Ensure that each type gets properly interpreted.\n    // Call with higher base values to ensure expected multiplication (only need a couple)\n    gen_size_filter_parse_test! {\n        byte_plus:                (\"+1b\",     SizeFilter::Min(1)),\n        byte_plus_multiplier:     (\"+10b\",    SizeFilter::Min(10)),\n        byte_minus:               (\"-1b\",     SizeFilter::Max(1)),\n        kilo_plus:                (\"+1k\",     SizeFilter::Min(1000)),\n        kilo_plus_suffix:         (\"+1kb\",    SizeFilter::Min(1000)),\n        kilo_minus:               (\"-1k\",     SizeFilter::Max(1000)),\n        kilo_minus_multiplier:    (\"-100k\",   SizeFilter::Max(100_000)),\n        kilo_minus_suffix:        (\"-1kb\",    SizeFilter::Max(1000)),\n        kilo_plus_upper:          (\"+1K\",     SizeFilter::Min(1000)),\n        kilo_plus_suffix_upper:   (\"+1KB\",    SizeFilter::Min(1000)),\n        kilo_minus_upper:         (\"-1K\",     SizeFilter::Max(1000)),\n        kilo_minus_suffix_upper:  (\"-1Kb\",    SizeFilter::Max(1000)),\n        kibi_plus:                (\"+1ki\",    SizeFilter::Min(1024)),\n        kibi_plus_multiplier:     (\"+10ki\",   SizeFilter::Min(10_240)),\n        kibi_plus_suffix:         (\"+1kib\",   SizeFilter::Min(1024)),\n        kibi_minus:               (\"-1ki\",    SizeFilter::Max(1024)),\n        kibi_minus_multiplier:    (\"-100ki\",  SizeFilter::Max(102_400)),\n        kibi_minus_suffix:        (\"-1kib\",   SizeFilter::Max(1024)),\n        kibi_plus_upper:          (\"+1KI\",    SizeFilter::Min(1024)),\n        kibi_plus_suffix_upper:   (\"+1KiB\",   SizeFilter::Min(1024)),\n        kibi_minus_upper:         (\"-1Ki\",    SizeFilter::Max(1024)),\n        kibi_minus_suffix_upper:  (\"-1KIB\",   SizeFilter::Max(1024)),\n        mega_plus:                (\"+1m\",     SizeFilter::Min(1_000_000)),\n        mega_plus_suffix:         (\"+1mb\",    SizeFilter::Min(1_000_000)),\n        mega_minus:               (\"-1m\",     SizeFilter::Max(1_000_000)),\n        mega_minus_suffix:        (\"-1mb\",    SizeFilter::Max(1_000_000)),\n        mega_plus_upper:          (\"+1M\",     SizeFilter::Min(1_000_000)),\n        mega_plus_suffix_upper:   (\"+1MB\",    SizeFilter::Min(1_000_000)),\n        mega_minus_upper:         (\"-1M\",     SizeFilter::Max(1_000_000)),\n        mega_minus_suffix_upper:  (\"-1Mb\",    SizeFilter::Max(1_000_000)),\n        mebi_plus:                (\"+1mi\",    SizeFilter::Min(1_048_576)),\n        mebi_plus_suffix:         (\"+1mib\",   SizeFilter::Min(1_048_576)),\n        mebi_minus:               (\"-1mi\",    SizeFilter::Max(1_048_576)),\n        mebi_minus_suffix:        (\"-1mib\",   SizeFilter::Max(1_048_576)),\n        mebi_plus_upper:          (\"+1MI\",    SizeFilter::Min(1_048_576)),\n        mebi_plus_suffix_upper:   (\"+1MiB\",   SizeFilter::Min(1_048_576)),\n        mebi_minus_upper:         (\"-1Mi\",    SizeFilter::Max(1_048_576)),\n        mebi_minus_suffix_upper:  (\"-1MIB\",   SizeFilter::Max(1_048_576)),\n        giga_plus:                (\"+1g\",     SizeFilter::Min(1_000_000_000)),\n        giga_plus_suffix:         (\"+1gb\",    SizeFilter::Min(1_000_000_000)),\n        giga_minus:               (\"-1g\",     SizeFilter::Max(1_000_000_000)),\n        giga_minus_suffix:        (\"-1gb\",    SizeFilter::Max(1_000_000_000)),\n        giga_plus_upper:          (\"+1G\",     SizeFilter::Min(1_000_000_000)),\n        giga_plus_suffix_upper:   (\"+1GB\",    SizeFilter::Min(1_000_000_000)),\n        giga_minus_upper:         (\"-1G\",     SizeFilter::Max(1_000_000_000)),\n        giga_minus_suffix_upper:  (\"-1Gb\",    SizeFilter::Max(1_000_000_000)),\n        gibi_plus:                (\"+1gi\",    SizeFilter::Min(1_073_741_824)),\n        gibi_plus_suffix:         (\"+1gib\",   SizeFilter::Min(1_073_741_824)),\n        gibi_minus:               (\"-1gi\",    SizeFilter::Max(1_073_741_824)),\n        gibi_minus_suffix:        (\"-1gib\",   SizeFilter::Max(1_073_741_824)),\n        gibi_plus_upper:          (\"+1GI\",    SizeFilter::Min(1_073_741_824)),\n        gibi_plus_suffix_upper:   (\"+1GiB\",   SizeFilter::Min(1_073_741_824)),\n        gibi_minus_upper:         (\"-1Gi\",    SizeFilter::Max(1_073_741_824)),\n        gibi_minus_suffix_upper:  (\"-1GIB\",   SizeFilter::Max(1_073_741_824)),\n        tera_plus:                (\"+1t\",     SizeFilter::Min(1_000_000_000_000)),\n        tera_plus_suffix:         (\"+1tb\",    SizeFilter::Min(1_000_000_000_000)),\n        tera_minus:               (\"-1t\",     SizeFilter::Max(1_000_000_000_000)),\n        tera_minus_suffix:        (\"-1tb\",    SizeFilter::Max(1_000_000_000_000)),\n        tera_plus_upper:          (\"+1T\",     SizeFilter::Min(1_000_000_000_000)),\n        tera_plus_suffix_upper:   (\"+1TB\",    SizeFilter::Min(1_000_000_000_000)),\n        tera_minus_upper:         (\"-1T\",     SizeFilter::Max(1_000_000_000_000)),\n        tera_minus_suffix_upper:  (\"-1Tb\",    SizeFilter::Max(1_000_000_000_000)),\n        tebi_plus:                (\"+1ti\",    SizeFilter::Min(1_099_511_627_776)),\n        tebi_plus_suffix:         (\"+1tib\",   SizeFilter::Min(1_099_511_627_776)),\n        tebi_minus:               (\"-1ti\",    SizeFilter::Max(1_099_511_627_776)),\n        tebi_minus_suffix:        (\"-1tib\",   SizeFilter::Max(1_099_511_627_776)),\n        tebi_plus_upper:          (\"+1TI\",    SizeFilter::Min(1_099_511_627_776)),\n        tebi_plus_suffix_upper:   (\"+1TiB\",   SizeFilter::Min(1_099_511_627_776)),\n        tebi_minus_upper:         (\"-1Ti\",    SizeFilter::Max(1_099_511_627_776)),\n        tebi_minus_suffix_upper:  (\"-1TIB\",   SizeFilter::Max(1_099_511_627_776)),\n    }\n\n    /// Invalid parse testing\n    macro_rules! gen_size_filter_failure {\n        ($($name:ident: $value:expr,)*) => {\n            $(\n                #[test]\n                fn $name() {\n                    let i = SizeFilter::from_string($value);\n                    assert!(i.is_err());\n                }\n            )*\n        };\n    }\n\n    // Invalid parse data\n    gen_size_filter_failure! {\n        ensure_missing_number_returns_none: \"+g\",\n        ensure_missing_unit_returns_none: \"+18\",\n        ensure_bad_format_returns_none_1: \"$10M\",\n        ensure_bad_format_returns_none_2: \"badval\",\n        ensure_bad_format_returns_none_3: \"9999\",\n        ensure_invalid_unit_returns_none_1: \"+50a\",\n        ensure_invalid_unit_returns_none_2: \"-10v\",\n        ensure_invalid_unit_returns_none_3: \"+1Mv\",\n        ensure_bib_format_returns_none: \"+1bib\",\n        ensure_bb_format_returns_none: \"+1bb\",\n    }\n\n    #[test]\n    fn is_within_less_than() {\n        let f = SizeFilter::from_string(\"-1k\").unwrap();\n        assert!(f.is_within(999));\n    }\n\n    #[test]\n    fn is_within_less_than_equal() {\n        let f = SizeFilter::from_string(\"-1k\").unwrap();\n        assert!(f.is_within(1000));\n    }\n\n    #[test]\n    fn is_within_greater_than() {\n        let f = SizeFilter::from_string(\"+1k\").unwrap();\n        assert!(f.is_within(1001));\n    }\n\n    #[test]\n    fn is_within_greater_than_equal() {\n        let f = SizeFilter::from_string(\"+1K\").unwrap();\n        assert!(f.is_within(1000));\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "3127d393a24cffcc58074f3d6b1955cd63bf71d1",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/fd/src/filetypes.rs",
    "func": "use crate::dir_entry;\nuse crate::filesystem;\n\nuse faccess::PathExt;\n\n/// Whether or not to show\n#[derive(Default)]\npub struct FileTypes {\n    pub files: bool,\n    pub directories: bool,\n    pub symlinks: bool,\n    pub block_devices: bool,\n    pub char_devices: bool,\n    pub sockets: bool,\n    pub pipes: bool,\n    pub executables_only: bool,\n    pub empty_only: bool,\n}\n\nimpl FileTypes {\n    pub fn should_ignore(&self, entry: &dir_entry::DirEntry) -> bool {\n        if let Some(ref entry_type) = entry.file_type() {\n            (!self.files && entry_type.is_file())\n                || (!self.directories && entry_type.is_dir())\n                || (!self.symlinks && entry_type.is_symlink())\n                || (!self.block_devices && filesystem::is_block_device(*entry_type))\n                || (!self.char_devices && filesystem::is_char_device(*entry_type))\n                || (!self.sockets && filesystem::is_socket(*entry_type))\n                || (!self.pipes && filesystem::is_pipe(*entry_type))\n                || (self.executables_only && !entry.path().executable())\n                || (self.empty_only && !filesystem::is_empty(entry))\n                || !(entry_type.is_file()\n                    || entry_type.is_dir()\n                    || entry_type.is_symlink()\n                    || filesystem::is_block_device(*entry_type)\n                    || filesystem::is_char_device(*entry_type)\n                    || filesystem::is_socket(*entry_type)\n                    || filesystem::is_pipe(*entry_type))\n        } else {\n            true\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "ec653aa690dd9b5f30f3e067e5001f4739b9f09d",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/packages/rsx/src/attribute.rs",
    "func": "//! Parser for the attribute shared both by elements and components\n//!\n//! ```rust, ignore\n//! rsx! {\n//!     div {\n//!         class: \"my-class\",\n//!         onclick: move |_| println!(\"clicked\")\n//!     }\n//!\n//!     Component {\n//!         class: \"my-class\",\n//!         onclick: move |_| println!(\"clicked\")\n//!     }\n//! }\n//! ```\n\nuse super::literal::HotLiteral;\nuse crate::{innerlude::*, partial_closure::PartialClosure};\n\nuse proc_macro2::TokenStream as TokenStream2;\nuse quote::{quote, quote_spanned, ToTokens, TokenStreamExt};\nuse std::fmt::Display;\nuse syn::{\n    ext::IdentExt,\n    parse::{Parse, ParseStream},\n    parse_quote,\n    spanned::Spanned,\n    Block, Expr, ExprClosure, ExprIf, Ident, Lit, LitBool, LitFloat, LitInt, LitStr, Token,\n};\n\n/// A property value in the from of a `name: value` pair with an optional comma.\n/// Note that the colon and value are optional in the case of shorthand attributes. We keep them around\n/// to support \"lossless\" parsing in case that ever might be useful.\n#[derive(PartialEq, Eq, Clone, Debug, Hash)]\npub struct Attribute {\n    /// The name of the attribute (ident or custom)\n    ///\n    /// IE `class` or `onclick`\n    pub name: AttributeName,\n\n    /// The colon that separates the name and value - keep this for lossless parsing\n    pub colon: Option<Token![:]>,\n\n    /// The value of the attribute\n    ///\n    /// IE `class=\"my-class\"` or `onclick: move |_| println!(\"clicked\")`\n    pub value: AttributeValue,\n\n    /// The comma that separates this attribute from the next one\n    /// Used for more accurate completions\n    pub comma: Option<Token![,]>,\n\n    /// The dynamic index of this attribute - used by the template system\n    pub dyn_idx: DynIdx,\n\n    /// The element name of this attribute if it is bound to an element.\n    /// When parsed for components or freestanding, this will be None\n    pub el_name: Option<ElementName>,\n}\n\nimpl Parse for Attribute {\n    fn parse(content: ParseStream) -> syn::Result<Self> {\n        // if there's an ident not followed by a colon, it's a shorthand attribute\n        if content.peek(Ident::peek_any) && !content.peek2(Token![:]) {\n            let ident = parse_raw_ident(content)?;\n            let comma = content.parse().ok();\n\n            return Ok(Attribute {\n                name: AttributeName::BuiltIn(ident.clone()),\n                colon: None,\n                value: AttributeValue::Shorthand(ident),\n                comma,\n                dyn_idx: DynIdx::default(),\n                el_name: None,\n            });\n        }\n\n        // Parse the name as either a known or custom attribute\n        let name = match content.peek(LitStr) {\n            true => AttributeName::Custom(content.parse::<LitStr>()?),\n            false => AttributeName::BuiltIn(parse_raw_ident(content)?),\n        };\n\n        // Ensure there's a colon\n        let colon = Some(content.parse::<Token![:]>()?);\n\n        // todo: make this cleaner please\n        // if statements in attributes get automatic closing in some cases\n        // we shouldn't be handling it any differently.\n        let value = AttributeValue::parse(content)?;\n\n        let comma = content.parse::<Token![,]>().ok();\n\n        let attr = Attribute {\n            name,\n            value,\n            colon,\n            comma,\n            dyn_idx: DynIdx::default(),\n            el_name: None,\n        };\n\n        Ok(attr)\n    }\n}\n\nimpl Attribute {\n    /// Create a new attribute from a name and value\n    pub fn from_raw(name: AttributeName, value: AttributeValue) -> Self {\n        Self {\n            name,\n            colon: Default::default(),\n            value,\n            comma: Default::default(),\n            dyn_idx: Default::default(),\n            el_name: None,\n        }\n    }\n\n    /// Set the dynamic index of this attribute\n    pub fn set_dyn_idx(&self, idx: usize) {\n        self.dyn_idx.set(idx);\n    }\n\n    /// Get the dynamic index of this attribute\n    pub fn get_dyn_idx(&self) -> usize {\n        self.dyn_idx.get()\n    }\n\n    pub fn span(&self) -> proc_macro2::Span {\n        self.name.span()\n    }\n\n    pub fn as_lit(&self) -> Option<&HotLiteral> {\n        match &self.value {\n            AttributeValue::AttrLiteral(lit) => Some(lit),\n            _ => None,\n        }\n    }\n\n    /// Run this closure against the attribute if it's hotreloadable\n    pub fn with_literal(&self, f: impl FnOnce(&HotLiteral)) {\n        if let AttributeValue::AttrLiteral(ifmt) = &self.value {\n            f(ifmt);\n        }\n    }\n\n    pub fn ifmt(&self) -> Option<&IfmtInput> {\n        match &self.value {\n            AttributeValue::AttrLiteral(HotLiteral::Fmted(input)) => Some(input),\n            _ => None,\n        }\n    }\n\n    pub fn as_static_str_literal(&self) -> Option<(&AttributeName, &IfmtInput)> {\n        match &self.value {\n            AttributeValue::AttrLiteral(lit) => match &lit {\n                HotLiteral::Fmted(input) if input.is_static() => Some((&self.name, input)),\n                _ => None,\n            },\n            _ => None,\n        }\n    }\n\n    pub fn is_static_str_literal(&self) -> bool {\n        self.as_static_str_literal().is_some()\n    }\n\n    pub fn rendered_as_dynamic_attr(&self) -> TokenStream2 {\n        // Shortcut out with spreads\n        if let AttributeName::Spread(_) = self.name {\n            let AttributeValue::AttrExpr(expr) = &self.value else {\n                unreachable!(\"Spread attributes should always be expressions\")\n            };\n            return quote! { {#expr}.into_boxed_slice() };\n        }\n\n        let el_name = self\n            .el_name\n            .as_ref()\n            .expect(\"el_name rendered as a dynamic attribute should always have an el_name set\");\n\n        let ns = |name: &AttributeName| match (el_name, name) {\n            (ElementName::Ident(i), AttributeName::BuiltIn(_)) => {\n                quote! { dioxus_elements::#i::#name.1 }\n            }\n            _ => quote! { None },\n        };\n\n        let volatile = |name: &AttributeName| match (el_name, name) {\n            (ElementName::Ident(i), AttributeName::BuiltIn(_)) => {\n                quote! { dioxus_elements::#i::#name.2 }\n            }\n            _ => quote! { false },\n        };\n\n        let attribute = |name: &AttributeName| match name {\n            AttributeName::BuiltIn(name) => match el_name {\n                ElementName::Ident(_) => quote! { dioxus_elements::#el_name::#name.0 },\n                ElementName::Custom(_) => {\n                    let as_string = name.to_string();\n                    quote!(#as_string)\n                }\n            },\n            AttributeName::Custom(s) => quote! { #s },\n            AttributeName::Spread(_) => unreachable!(\"Spread attributes are handled elsewhere\"),\n        };\n\n        let attribute = {\n            let value = &self.value;\n            let name = &self.name;\n            let is_not_event = !self.name.is_likely_event();\n\n            match &self.value {\n                AttributeValue::AttrLiteral(_)\n                | AttributeValue::AttrExpr(_)\n                | AttributeValue::Shorthand(_)\n                | AttributeValue::IfExpr { .. }\n                    if is_not_event =>\n                {\n                    let name = &self.name;\n                    let ns = ns(name);\n                    let volatile = volatile(name);\n                    let attribute = attribute(name);\n                    let value = quote! { #value };\n\n                    quote! {\n                        dioxus_core::Attribute::new(\n                            #attribute,\n                            #value,\n                            #ns,\n                            #volatile\n                        )\n                    }\n                }\n                AttributeValue::EventTokens(tokens) => match &self.name {\n                    AttributeName::BuiltIn(name) => {\n                        let event_tokens_is_closure =\n                            syn::parse2::<ExprClosure>(tokens.to_token_stream()).is_ok();\n                        let function_name =\n                            quote_spanned! { tokens.span() => dioxus_elements::events::#name };\n                        let function = if event_tokens_is_closure {\n                            // If we see an explicit closure, we can call the `call_with_explicit_closure` version of the event for better type inference\n                            quote_spanned! { tokens.span() => #function_name::call_with_explicit_closure }\n                        } else {\n                            function_name\n                        };\n                        quote_spanned! { tokens.span() =>\n                            #function(#tokens)\n                        }\n                    }\n                    AttributeName::Custom(_) => unreachable!(\"Handled elsewhere in the macro\"),\n                    AttributeName::Spread(_) => unreachable!(\"Handled elsewhere in the macro\"),\n                },\n                _ => {\n                    quote_spanned! { value.span() => dioxus_elements::events::#name(#value) }\n                }\n            }\n        };\n\n        let completion_hints = self.completion_hints();\n        quote! {\n            Box::new([\n                {\n                    #completion_hints\n                    #attribute\n                }\n            ])\n        }\n        .to_token_stream()\n    }\n\n    pub fn can_be_shorthand(&self) -> bool {\n        // If it's a shorthand...\n        if matches!(self.value, AttributeValue::Shorthand(_)) {\n            return true;\n        }\n\n        // Or if it is a builtin attribute with a single ident value\n        if let (AttributeName::BuiltIn(name), AttributeValue::AttrExpr(expr)) =\n            (&self.name, &self.value)\n        {\n            if let Ok(Expr::Path(path)) = expr.as_expr() {\n                if path.path.get_ident() == Some(name) {\n                    return true;\n                }\n            }\n        }\n\n        false\n    }\n\n    /// If this is the last attribute of an element and it doesn't have a tailing comma,\n    /// we add hints so that rust analyzer completes it either as an attribute or element\n    fn completion_hints(&self) -> TokenStream2 {\n        let Attribute {\n            name,\n            value,\n            comma,\n            el_name,\n            ..\n        } = self;\n\n        // If there is a trailing comma, rust analyzer does a good job of completing the attribute by itself\n        if comma.is_some() {\n            return quote! {};\n        }\n\n        // Only add hints if the attribute is:\n        // - a built in attribute (not a literal)\n        // - an build in element (not a custom element)\n        // - a shorthand attribute\n        let (\n            Some(ElementName::Ident(el)),\n            AttributeName::BuiltIn(name),\n            AttributeValue::Shorthand(_),\n        ) = (&el_name, &name, &value)\n        else {\n            return quote! {};\n        };\n        // If the attribute is a shorthand attribute, but it is an event handler, rust analyzer already does a good job of completing the attribute by itself\n        if name.to_string().starts_with(\"on\") {\n            return quote! {};\n        }\n\n        quote! {\n            {\n                #[allow(dead_code)]\n                #[doc(hidden)]\n                mod __completions {\n                    // Autocomplete as an attribute\n                    pub use super::dioxus_elements::#el::*;\n                    // Autocomplete as an element\n                    pub use super::dioxus_elements::elements::completions::CompleteWithBraces::*;\n                    fn ignore() {\n                        #name;\n                    }\n                }\n            }\n        }\n    }\n}\n\n#[derive(PartialEq, Eq, Clone, Debug, Hash)]\npub enum AttributeName {\n    Spread(Token![..]),\n\n    /// an attribute in the form of `name: value`\n    BuiltIn(Ident),\n\n    /// an attribute in the form of `\"name\": value` - notice that the name is a string literal\n    /// this is to allow custom attributes in the case of missing built-in attributes\n    ///\n    /// we might want to change this one day to be ticked or something and simply a boolean\n    Custom(LitStr),\n}\n\nimpl AttributeName {\n    pub fn is_likely_event(&self) -> bool {\n        matches!(self, Self::BuiltIn(ident) if ident.to_string().starts_with(\"on\"))\n    }\n\n    pub fn is_likely_key(&self) -> bool {\n        matches!(self, Self::BuiltIn(ident) if ident == \"key\")\n    }\n\n    pub fn span(&self) -> proc_macro2::Span {\n        match self {\n            Self::Custom(lit) => lit.span(),\n            Self::BuiltIn(ident) => ident.span(),\n            Self::Spread(dots) => dots.span(),\n        }\n    }\n}\n\nimpl Display for AttributeName {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            Self::Custom(lit) => write!(f, \"{}\", lit.value()),\n            Self::BuiltIn(ident) => write!(f, \"{}\", ident),\n            Self::Spread(_) => write!(f, \"..\"),\n        }\n    }\n}\n\nimpl ToTokens for AttributeName {\n    fn to_tokens(&self, tokens: &mut TokenStream2) {\n        match self {\n            Self::Custom(lit) => lit.to_tokens(tokens),\n            Self::BuiltIn(ident) => ident.to_tokens(tokens),\n            Self::Spread(dots) => dots.to_tokens(tokens),\n        }\n    }\n}\n\n// ..spread attribute\n#[derive(PartialEq, Eq, Clone, Debug, Hash)]\npub struct Spread {\n    pub dots: Token![..],\n    pub expr: Expr,\n    pub dyn_idx: DynIdx,\n    pub comma: Option<Token![,]>,\n}\n\nimpl Spread {\n    pub fn span(&self) -> proc_macro2::Span {\n        self.dots.span()\n    }\n}\n\n#[derive(PartialEq, Eq, Clone, Debug, Hash)]\npub enum AttributeValue {\n    /// Just a regular shorthand attribute - an ident. Makes our parsing a bit more opaque.\n    /// attribute,\n    Shorthand(Ident),\n\n    /// Any attribute that's a literal. These get hotreloading super powers\n    ///\n    /// attribute: \"value\"\n    /// attribute: bool,\n    /// attribute: 1,\n    AttrLiteral(HotLiteral),\n\n    /// A series of tokens that represent an event handler\n    ///\n    /// We use a special type here so we can get autocomplete in the closure using partial expansion.\n    /// We also do some extra wrapping for improved type hinting since rust sometimes has trouble with\n    /// generics and closures.\n    EventTokens(PartialClosure),\n\n    /// Conditional expression\n    ///\n    /// attribute: if bool { \"value\" } else if bool { \"other value\" } else { \"default value\" }\n    ///\n    /// Currently these don't get hotreloading super powers, but they could, depending on how far\n    /// we want to go with it\n    IfExpr(IfAttributeValue),\n\n    /// attribute: some_expr\n    /// attribute: {some_expr} ?\n    AttrExpr(PartialExpr),\n}\n\nimpl Parse for AttributeValue {\n    fn parse(content: ParseStream) -> syn::Result<Self> {\n        // Attempt to parse the unterminated if statement\n        if content.peek(Token![if]) {\n            return Ok(Self::IfExpr(content.parse::<IfAttributeValue>()?));\n        }\n\n        // Use the move and/or bars as an indicator that we have an event handler\n        if content.peek(Token![move]) || content.peek(Token![|]) {\n            let value = content.parse()?;\n            return Ok(AttributeValue::EventTokens(value));\n        }\n\n        if content.peek(LitStr)\n            || content.peek(LitBool)\n            || content.peek(LitFloat)\n            || content.peek(LitInt)\n        {\n            let fork = content.fork();\n            _ = fork.parse::<Lit>().unwrap();\n\n            if content.peek2(Token![,]) || fork.is_empty() {\n                let value = content.parse()?;\n                return Ok(AttributeValue::AttrLiteral(value));\n            }\n        }\n\n        let value = content.parse::<PartialExpr>()?;\n        Ok(AttributeValue::AttrExpr(value))\n    }\n}\n\nimpl ToTokens for AttributeValue {\n    fn to_tokens(&self, tokens: &mut proc_macro2::TokenStream) {\n        match self {\n            Self::Shorthand(ident) => ident.to_tokens(tokens),\n            Self::AttrLiteral(ifmt) => ifmt.to_tokens(tokens),\n            Self::IfExpr(if_expr) => if_expr.to_tokens(tokens),\n            Self::AttrExpr(expr) => expr.to_tokens(tokens),\n            Self::EventTokens(closure) => closure.to_tokens(tokens),\n        }\n    }\n}\n\nimpl AttributeValue {\n    pub fn span(&self) -> proc_macro2::Span {\n        match self {\n            Self::Shorthand(ident) => ident.span(),\n            Self::AttrLiteral(ifmt) => ifmt.span(),\n            Self::IfExpr(if_expr) => if_expr.span(),\n            Self::AttrExpr(expr) => expr.span(),\n            Self::EventTokens(closure) => closure.span(),\n        }\n    }\n}\n\n/// A if else chain attribute value\n#[derive(PartialEq, Eq, Clone, Debug, Hash)]\npub struct IfAttributeValue {\n    pub condition: Expr,\n    pub then_value: Box<AttributeValue>,\n    pub else_value: Option<Box<AttributeValue>>,\n}\n\nimpl IfAttributeValue {\n    /// Convert the if expression to an expression that returns a string. If the unterminated case is hit, it returns an empty string\n    pub(crate) fn quote_as_string(&self, diagnostics: &mut Diagnostics) -> Expr {\n        let mut expression = quote! {};\n        let mut current_if_value = self;\n\n        let mut non_string_diagnostic = |span: proc_macro2::Span| -> Expr {\n            Element::add_merging_non_string_diagnostic(diagnostics, span);\n            parse_quote! { ::std::string::String::new() }\n        };\n\n        loop {\n            let AttributeValue::AttrLiteral(lit) = current_if_value.then_value.as_ref() else {\n                return non_string_diagnostic(current_if_value.span());\n            };\n\n            let HotLiteral::Fmted(HotReloadFormattedSegment {\n                formatted_input: new,\n                ..\n            }) = &lit\n            else {\n                return non_string_diagnostic(current_if_value.span());\n            };\n\n            let condition = &current_if_value.condition;\n            expression.extend(quote! {\n                if #condition {\n                    #new.to_string()\n                } else\n            });\n            match current_if_value.else_value.as_deref() {\n                // If the else value is another if expression, then we need to continue the loop\n                Some(AttributeValue::IfExpr(else_value)) => {\n                    current_if_value = else_value;\n                }\n                // If the else value is a literal, then we need to append it to the expression and break\n                Some(AttributeValue::AttrLiteral(lit)) => {\n                    if let HotLiteral::Fmted(new) = &lit {\n                        let fmted = &new.formatted_input;\n                        expression.extend(quote! { { #fmted.to_string() } });\n                        break;\n                    } else {\n                        return non_string_diagnostic(current_if_value.span());\n                    }\n                }\n                // If it is the end of the if expression without an else, then we need to append the default value and break\n                None => {\n                    expression.extend(quote! { { ::std::string::String::new() } });\n                    break;\n                }\n                _ => {\n                    return non_string_diagnostic(current_if_value.else_value.span());\n                }\n            }\n        }\n\n        parse_quote! {\n            {\n                #expression\n            }\n        }\n    }\n\n    fn span(&self) -> proc_macro2::Span {\n        self.then_value.span()\n    }\n\n    fn is_terminated(&self) -> bool {\n        match &self.else_value {\n            Some(attribute) => match attribute.as_ref() {\n                AttributeValue::IfExpr(if_expr) => if_expr.is_terminated(),\n                _ => true,\n            },\n            None => false,\n        }\n    }\n\n    fn contains_expression(&self) -> bool {\n        if let AttributeValue::AttrExpr(_) = &*self.then_value {\n            return true;\n        }\n        match &self.else_value {\n            Some(attribute) => match attribute.as_ref() {\n                AttributeValue::IfExpr(if_expr) => if_expr.is_terminated(),\n                AttributeValue::AttrExpr(_) => true,\n                _ => false,\n            },\n            None => false,\n        }\n    }\n\n    fn parse_attribute_value_from_block(block: &Block) -> syn::Result<Box<AttributeValue>> {\n        let stmts = &block.stmts;\n\n        if stmts.len() != 1 {\n            return Err(syn::Error::new(\n                block.span(),\n                \"Expected a single statement in the if block\",\n            ));\n        }\n\n        // either an ifmt or an expr in the block\n        let stmt = &stmts[0];\n\n        // Either it's a valid ifmt or an expression\n        match stmt {\n            syn::Stmt::Expr(exp, None) => {\n                // Try parsing the statement as an IfmtInput by passing it through tokens\n                let value: Result<HotLiteral, syn::Error> = syn::parse2(quote! { #exp });\n                Ok(match value {\n                    Ok(res) => Box::new(AttributeValue::AttrLiteral(res)),\n                    Err(_) => Box::new(AttributeValue::AttrExpr(PartialExpr::from_expr(exp))),\n                })\n            }\n            _ => Err(syn::Error::new(stmt.span(), \"Expected an expression\")),\n        }\n    }\n\n    fn to_tokens_with_terminated(\n        &self,\n        tokens: &mut TokenStream2,\n        terminated: bool,\n        contains_expression: bool,\n    ) {\n        let IfAttributeValue {\n            condition,\n            then_value,\n            else_value,\n        } = self;\n\n        // Quote an attribute value and convert the value to a string if it is formatted\n        // We always quote formatted segments as strings inside if statements so they have a consistent type\n        // This fixes https://github.com/DioxusLabs/dioxus/issues/2997\n        fn quote_attribute_value_string(\n            value: &AttributeValue,\n            contains_expression: bool,\n        ) -> TokenStream2 {\n            if let AttributeValue::AttrLiteral(HotLiteral::Fmted(fmted)) = value {\n                if let Some(str) = fmted.to_static().filter(|_| contains_expression) {\n                    // If this is actually a static string, the user may be using a static string expression in another branch\n                    // use into to convert the string to whatever the other branch is using\n                    quote! {\n                        {\n                            #[allow(clippy::useless_conversion)]\n                            #str.into()\n                        }\n                    }\n                } else {\n                    quote! { #value.to_string() }\n                }\n            } else {\n                value.to_token_stream()\n            }\n        }\n\n        let then_value = quote_attribute_value_string(then_value, terminated);\n\n        let then_value = if terminated {\n            quote! { #then_value }\n        }\n        // Otherwise we need to return an Option and a None if the else value is None\n        else {\n            quote! { Some(#then_value) }\n        };\n\n        let else_value = match else_value.as_deref() {\n            Some(AttributeValue::IfExpr(else_value)) => {\n                let mut tokens = TokenStream2::new();\n                else_value.to_tokens_with_terminated(&mut tokens, terminated, contains_expression);\n                tokens\n            }\n            Some(other) => {\n                let other = quote_attribute_value_string(other, contains_expression);\n                if terminated {\n                    quote! { #other }\n                } else {\n                    quote! { Some(#other) }\n                }\n            }\n            None => quote! { None },\n        };\n\n        tokens.append_all(quote! {\n            {\n                if #condition {\n                    #then_value\n                } else {\n                    #else_value\n                }\n            }\n        });\n    }\n}\n\nimpl Parse for IfAttributeValue {\n    fn parse(input: ParseStream) -> syn::Result<Self> {\n        let if_expr = input.parse::<ExprIf>()?;\n\n        let stmts = &if_expr.then_branch.stmts;\n\n        if stmts.len() != 1 {\n            return Err(syn::Error::new(\n                if_expr.then_branch.span(),\n                \"Expected a single statement in the if block\",\n            ));\n        }\n\n        // Parse the then branch into a single attribute value\n        let then_value = Self::parse_attribute_value_from_block(&if_expr.then_branch)?;\n\n        // If there's an else branch, parse it as a single attribute value or an if expression\n        let else_value = match if_expr.else_branch.as_ref() {\n            Some((_, else_branch)) => {\n                // The else branch if either a block or another if expression\n                let attribute_value = match else_branch.as_ref() {\n                    // If it is a block, then the else is terminated\n                    Expr::Block(block) => Self::parse_attribute_value_from_block(&block.block)?,\n                    // Otherwise try to parse it as an if expression\n                    _ => Box::new(syn::parse2(quote! { #else_branch })?),\n                };\n                Some(attribute_value)\n            }\n            None => None,\n        };\n\n        Ok(Self {\n            condition: *if_expr.cond,\n            then_value,\n            else_value,\n        })\n    }\n}\n\nimpl ToTokens for IfAttributeValue {\n    fn to_tokens(&self, tokens: &mut TokenStream2) {\n        // If the if expression is terminated, we can just return the then value\n        let terminated = self.is_terminated();\n        let contains_expression = self.contains_expression();\n        self.to_tokens_with_terminated(tokens, terminated, contains_expression)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use quote::quote;\n    use syn::parse2;\n\n    #[test]\n    fn parse_attrs() {\n        let _parsed: Attribute = parse2(quote! { name: \"value\" }).unwrap();\n        let _parsed: Attribute = parse2(quote! { name: value }).unwrap();\n        let _parsed: Attribute = parse2(quote! { name: \"value {fmt}\" }).unwrap();\n        let _parsed: Attribute = parse2(quote! { name: 123 }).unwrap();\n        let _parsed: Attribute = parse2(quote! { name: false }).unwrap();\n        let _parsed: Attribute = parse2(quote! { \"custom\": false }).unwrap();\n        let _parsed: Attribute = parse2(quote! { prop: \"blah\".to_string() }).unwrap();\n\n        // with commas\n        let _parsed: Attribute = parse2(quote! { \"custom\": false, }).unwrap();\n        let _parsed: Attribute = parse2(quote! { name: false, }).unwrap();\n\n        // with if chains\n        let parsed: Attribute = parse2(quote! { name: if true { \"value\" } }).unwrap();\n        assert!(matches!(parsed.value, AttributeValue::IfExpr(_)));\n        let parsed: Attribute =\n            parse2(quote! { name: if true { \"value\" } else { \"other\" } }).unwrap();\n        assert!(matches!(parsed.value, AttributeValue::IfExpr(_)));\n        let parsed: Attribute =\n            parse2(quote! { name: if true { \"value\" } else if false { \"other\" } }).unwrap();\n        assert!(matches!(parsed.value, AttributeValue::IfExpr(_)));\n\n        // with shorthand\n        let _parsed: Attribute = parse2(quote! { name }).unwrap();\n        let _parsed: Attribute = parse2(quote! { name, }).unwrap();\n\n        // Events - make sure they get partial expansion\n        let parsed: Attribute = parse2(quote! { onclick: |e| {} }).unwrap();\n        assert!(matches!(parsed.value, AttributeValue::EventTokens(_)));\n        let parsed: Attribute = parse2(quote! { onclick: |e| { \"value\" } }).unwrap();\n        assert!(matches!(parsed.value, AttributeValue::EventTokens(_)));\n        let parsed: Attribute = parse2(quote! { onclick: |e| { value. } }).unwrap();\n        assert!(matches!(parsed.value, AttributeValue::EventTokens(_)));\n        let parsed: Attribute = parse2(quote! { onclick: move |e| { value. } }).unwrap();\n        assert!(matches!(parsed.value, AttributeValue::EventTokens(_)));\n        let parsed: Attribute = parse2(quote! { onclick: move |e| value }).unwrap();\n        assert!(matches!(parsed.value, AttributeValue::EventTokens(_)));\n        let parsed: Attribute = parse2(quote! { onclick: |e| value, }).unwrap();\n        assert!(matches!(parsed.value, AttributeValue::EventTokens(_)));\n    }\n\n    #[test]\n    fn merge_attrs() {\n        let _a: Attribute = parse2(quote! { class: \"value1\" }).unwrap();\n        let _b: Attribute = parse2(quote! { class: \"value2\" }).unwrap();\n\n        let _b: Attribute = parse2(quote! { class: \"value2 {something}\" }).unwrap();\n        let _b: Attribute = parse2(quote! { class: if value { \"other thing\" } }).unwrap();\n        let _b: Attribute = parse2(quote! { class: if value { some_expr } }).unwrap();\n\n        let _b: Attribute = parse2(quote! { class: if value { \"some_expr\" } }).unwrap();\n        dbg!(_b);\n    }\n\n    #[test]\n    fn static_literals() {\n        let a: Attribute = parse2(quote! { class: \"value1\" }).unwrap();\n        let b: Attribute = parse2(quote! { class: \"value {some}\" }).unwrap();\n\n        assert!(a.is_static_str_literal());\n        assert!(!b.is_static_str_literal());\n    }\n\n    #[test]\n    fn partial_eqs() {\n        // Basics\n        let a: Attribute = parse2(quote! { class: \"value1\" }).unwrap();\n        let b: Attribute = parse2(quote! { class: \"value1\" }).unwrap();\n        assert_eq!(a, b);\n\n        // Exprs\n        let a: Attribute = parse2(quote! { class: var }).unwrap();\n        let b: Attribute = parse2(quote! { class: var }).unwrap();\n        assert_eq!(a, b);\n\n        // Events\n        let a: Attribute = parse2(quote! { onclick: |e| {} }).unwrap();\n        let b: Attribute = parse2(quote! { onclick: |e| {} }).unwrap();\n        let c: Attribute = parse2(quote! { onclick: move |e| {} }).unwrap();\n        assert_eq!(a, b);\n        assert_ne!(a, c);\n    }\n\n    /// Make sure reserved keywords are parsed as attributes\n    /// HTML gets annoying sometimes so we just accept them\n    #[test]\n    fn reserved_keywords() {\n        let _a: Attribute = parse2(quote! { for: \"class\" }).unwrap();\n        let _b: Attribute = parse2(quote! { type: \"class\" }).unwrap();\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "b33aeed6a31f151b7f4666a266b104cd7bf7d9a7",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/packages/desktop/src/menubar.rs",
    "func": "use tao::window::Window;\n\n#[cfg(not(any(target_os = \"ios\", target_os = \"android\")))]\npub type DioxusMenu = muda::Menu;\n#[cfg(any(target_os = \"ios\", target_os = \"android\"))]\npub type DioxusMenu = ();\n\n/// Initializes the menu bar for the window.\n#[allow(unused)]\npub fn init_menu_bar(menu: &DioxusMenu, window: &Window) {\n    #[cfg(not(any(target_os = \"ios\", target_os = \"android\")))]\n    {\n        desktop_platforms::init_menu_bar(menu, window);\n    }\n}\n\n/// Creates a standard menu bar depending on the users platform. It may be used as a starting point\n/// to further customize the menu bar and pass it to a [`WindowBuilder`](tao::window::WindowBuilder).\n/// > Note: The default menu bar enables macOS shortcuts like cut/copy/paste.\n/// > The menu bar differs per platform because of constraints introduced\n/// > by [`MenuItem`](tao::menu::MenuItem).\n#[allow(unused)]\npub fn default_menu_bar() -> DioxusMenu {\n    #[cfg(not(any(target_os = \"ios\", target_os = \"android\")))]\n    {\n        desktop_platforms::default_menu_bar()\n    }\n}\n\n#[cfg(not(any(target_os = \"ios\", target_os = \"android\")))]\nmod desktop_platforms {\n    use super::*;\n    use muda::{Menu, MenuItem, PredefinedMenuItem, Submenu};\n\n    #[allow(unused)]\n    pub fn init_menu_bar(menu: &Menu, window: &Window) {\n        #[cfg(target_os = \"windows\")]\n        {\n            use tao::platform::windows::WindowExtWindows;\n            menu.init_for_hwnd(window.hwnd());\n        }\n\n        #[cfg(target_os = \"linux\")]\n        {\n            use tao::platform::unix::WindowExtUnix;\n            menu.init_for_gtk_window(window.gtk_window(), window.default_vbox())\n                .unwrap();\n        }\n\n        #[cfg(target_os = \"macos\")]\n        {\n            use tao::platform::macos::WindowExtMacOS;\n            menu.init_for_nsapp();\n        }\n    }\n\n    pub fn default_menu_bar() -> Menu {\n        let menu = Menu::new();\n        // since it is uncommon on windows to have an \"application menu\"\n        // we add a \"window\" menu to be more consistent across platforms with the standard menu\n        let window_menu = Submenu::new(\"Window\", true);\n        window_menu\n            .append_items(&[\n                &PredefinedMenuItem::fullscreen(None),\n                &PredefinedMenuItem::separator(),\n                &PredefinedMenuItem::hide(None),\n                &PredefinedMenuItem::hide_others(None),\n                &PredefinedMenuItem::show_all(None),\n                &PredefinedMenuItem::maximize(None),\n                &PredefinedMenuItem::minimize(None),\n                &PredefinedMenuItem::close_window(None),\n                &PredefinedMenuItem::separator(),\n                &PredefinedMenuItem::quit(None),\n            ])\n            .unwrap();\n\n        let edit_menu = Submenu::new(\"Edit\", true);\n        edit_menu\n            .append_items(&[\n                &PredefinedMenuItem::undo(None),\n                &PredefinedMenuItem::redo(None),\n                &PredefinedMenuItem::separator(),\n                &PredefinedMenuItem::cut(None),\n                &PredefinedMenuItem::copy(None),\n                &PredefinedMenuItem::paste(None),\n                &PredefinedMenuItem::separator(),\n                &PredefinedMenuItem::select_all(None),\n            ])\n            .unwrap();\n\n        menu.append_items(&[&window_menu, &edit_menu]).unwrap();\n\n        if cfg!(debug_assertions) {\n            let help_menu = Submenu::new(\"Help\", true);\n\n            help_menu\n                .append_items(&[&MenuItem::with_id(\n                    \"dioxus-toggle-dev-tools\",\n                    \"Toggle Developer Tools\",\n                    true,\n                    None,\n                )])\n                .unwrap();\n\n            // By default we float the window on top in dev mode, but let the user disable it\n            help_menu\n                .append_items(&[&MenuItem::with_id(\n                    \"dioxus-float-top\",\n                    \"Float on Top (dev mode only)\",\n                    true,\n                    None,\n                )])\n                .unwrap();\n\n            _ = menu.append_items(&[&help_menu]);\n\n            #[cfg(target_os = \"macos\")]\n            {\n                help_menu.set_as_help_menu_for_nsapp();\n            }\n        }\n\n        #[cfg(target_os = \"macos\")]\n        {\n            window_menu.set_as_windows_menu_for_nsapp();\n        }\n\n        menu\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "3dfda10a17e7f54f65895fcebd25301c0b97078c",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/packages/rsx/src/forloop.rs",
    "func": "use super::*;\nuse location::DynIdx;\nuse proc_macro2::TokenStream as TokenStream2;\nuse syn::{braced, token::Brace, Expr, Pat};\n\n#[non_exhaustive]\n#[derive(PartialEq, Eq, Clone, Debug)]\npub struct ForLoop {\n    pub for_token: Token![for],\n    pub pat: Pat,\n    pub in_token: Token![in],\n    pub expr: Box<Expr>,\n    pub brace: Brace,\n    pub body: TemplateBody,\n    pub dyn_idx: DynIdx,\n}\n\nimpl Parse for ForLoop {\n    fn parse(input: ParseStream) -> Result<Self> {\n        // todo: better partial parsing\n        // A bit stolen from `ExprForLoop` in the `syn` crate\n        let for_token = input.parse()?;\n        let pat = input.call(Pat::parse_single)?;\n        let in_token = input.parse()?;\n        let expr = input.call(Expr::parse_without_eager_brace)?;\n\n        let content;\n        let brace = braced!(content in input);\n        let body = content.parse()?;\n\n        Ok(Self {\n            for_token,\n            pat,\n            in_token,\n            brace,\n            expr: Box::new(expr),\n            body,\n            dyn_idx: DynIdx::default(),\n        })\n    }\n}\n\nimpl ToTokens for ForLoop {\n    fn to_tokens(&self, tokens: &mut TokenStream2) {\n        let ForLoop {\n            pat, expr, body, ..\n        } = self;\n\n        // the temporary is important so we create a lifetime binding\n        tokens.append_all(quote! {\n            {\n                let ___nodes = (#expr).into_iter().map(|#pat| { #body }).into_dyn_node();\n                ___nodes\n            }\n        });\n    }\n}\n\n#[test]\nfn parses_for_loop() {\n    let toks = quote! {\n        for item in 0..10 {\n            div { \"cool-{item}\" }\n            div { \"cool-{item}\" }\n            div { \"cool-{item}\" }\n        }\n    };\n\n    let for_loop: ForLoop = syn::parse2(toks).unwrap();\n    assert!(for_loop.body.roots.len() == 3);\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "d6a6fb926f29ea1adbd8f8b0eb620547eb6ceb9d",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/packages/desktop/src/launch.rs",
    "func": "use crate::Config;\nuse crate::{\n    app::App,\n    ipc::{IpcMethod, UserWindowEvent},\n};\nuse dioxus_core::*;\nuse dioxus_document::eval;\nuse std::any::Any;\nuse tao::event::{Event, StartCause, WindowEvent};\n\n/// Launch the WebView and run the event loop, with configuration and root props.\n///\n/// This will block the main thread, and *must* be spawned on the main thread. This function does not assume any runtime\n/// and is equivalent to calling launch_with_props with the tokio feature disabled.\npub fn launch_virtual_dom_blocking(virtual_dom: VirtualDom, mut desktop_config: Config) -> ! {\n    let mut custom_event_handler = desktop_config.custom_event_handler.take();\n    let (event_loop, mut app) = App::new(desktop_config, virtual_dom);\n\n    event_loop.run(move |window_event, event_loop, control_flow| {\n        // Set the control flow and check if any events need to be handled in the app itself\n        app.tick(&window_event);\n\n        if let Some(ref mut f) = custom_event_handler {\n            f(&window_event, event_loop)\n        }\n\n        match window_event {\n            Event::NewEvents(StartCause::Init) => app.handle_start_cause_init(),\n            Event::LoopDestroyed => app.handle_loop_destroyed(),\n            Event::WindowEvent {\n                event, window_id, ..\n            } => match event {\n                WindowEvent::CloseRequested => app.handle_close_requested(window_id),\n                WindowEvent::Destroyed { .. } => app.window_destroyed(window_id),\n                WindowEvent::Resized(new_size) => app.resize_window(new_size),\n                _ => {}\n            },\n\n            Event::UserEvent(event) => match event {\n                UserWindowEvent::Poll(id) => app.poll_vdom(id),\n                UserWindowEvent::NewWindow => app.handle_new_window(),\n                UserWindowEvent::CloseWindow(id) => app.handle_close_msg(id),\n                UserWindowEvent::Shutdown => app.control_flow = tao::event_loop::ControlFlow::Exit,\n\n                #[cfg(any(target_os = \"windows\", target_os = \"linux\", target_os = \"macos\"))]\n                UserWindowEvent::GlobalHotKeyEvent(evnt) => app.handle_global_hotkey(evnt),\n\n                #[cfg(any(target_os = \"windows\", target_os = \"linux\", target_os = \"macos\"))]\n                UserWindowEvent::MudaMenuEvent(evnt) => app.handle_menu_event(evnt),\n\n                #[cfg(any(target_os = \"windows\", target_os = \"linux\", target_os = \"macos\"))]\n                UserWindowEvent::TrayMenuEvent(evnt) => app.handle_tray_menu_event(evnt),\n\n                #[cfg(any(target_os = \"windows\", target_os = \"linux\", target_os = \"macos\"))]\n                UserWindowEvent::TrayIconEvent(evnt) => app.handle_tray_icon_event(evnt),\n\n                #[cfg(all(feature = \"devtools\", debug_assertions))]\n                UserWindowEvent::HotReloadEvent(msg) => app.handle_hot_reload_msg(msg),\n\n                // Windows-only drag-n-drop fix events. We need to call the interpreter drag-n-drop code.\n                UserWindowEvent::WindowsDragDrop(id) => {\n                    if let Some(webview) = app.webviews.get(&id) {\n                        webview.dom.in_runtime(|| {\n                            ScopeId::ROOT.in_runtime(|| {\n                                eval(\"window.interpreter.handleWindowsDragDrop();\");\n                            });\n                        });\n                    }\n                }\n                UserWindowEvent::WindowsDragLeave(id) => {\n                    if let Some(webview) = app.webviews.get(&id) {\n                        webview.dom.in_runtime(|| {\n                            ScopeId::ROOT.in_runtime(|| {\n                                eval(\"window.interpreter.handleWindowsDragLeave();\");\n                            });\n                        });\n                    }\n                }\n                UserWindowEvent::WindowsDragOver(id, x_pos, y_pos) => {\n                    if let Some(webview) = app.webviews.get(&id) {\n                        webview.dom.in_runtime(|| {\n                            ScopeId::ROOT.in_runtime(|| {\n                                let e = eval(\n                                    r#\"\n                                    const xPos = await dioxus.recv();\n                                    const yPos = await dioxus.recv();\n                                    window.interpreter.handleWindowsDragOver(xPos, yPos)\n                                    \"#,\n                                );\n\n                                _ = e.send(x_pos);\n                                _ = e.send(y_pos);\n                            });\n                        });\n                    }\n                }\n\n                UserWindowEvent::Ipc { id, msg } => match msg.method() {\n                    IpcMethod::Initialize => app.handle_initialize_msg(id),\n                    IpcMethod::FileDialog => app.handle_file_dialog_msg(msg, id),\n                    IpcMethod::UserEvent => {}\n                    IpcMethod::Query => app.handle_query_msg(msg, id),\n                    IpcMethod::BrowserOpen => app.handle_browser_open(msg),\n                    IpcMethod::Other(_) => {}\n                },\n            },\n            _ => {}\n        }\n\n        *control_flow = app.control_flow;\n    })\n}\n\n/// Launches the WebView and runs the event loop, with configuration and root props.\npub fn launch_virtual_dom(virtual_dom: VirtualDom, desktop_config: Config) -> ! {\n    #[cfg(feature = \"tokio_runtime\")]\n    {\n        tokio::runtime::Builder::new_multi_thread()\n            .enable_all()\n            .build()\n            .unwrap()\n            .block_on(tokio::task::unconstrained(async move {\n                launch_virtual_dom_blocking(virtual_dom, desktop_config)\n            }));\n\n        unreachable!(\"The desktop launch function will never exit\")\n    }\n\n    #[cfg(not(feature = \"tokio_runtime\"))]\n    {\n        launch_virtual_dom_blocking(virtual_dom, desktop_config);\n    }\n}\n\n/// Launches the WebView and runs the event loop, with configuration and root props.\npub fn launch(\n    root: fn() -> Element,\n    contexts: Vec<Box<dyn Fn() -> Box<dyn Any> + Send + Sync>>,\n    platform_config: Vec<Box<dyn Any>>,\n) -> ! {\n    let mut virtual_dom = VirtualDom::new(root);\n\n    for context in contexts {\n        virtual_dom.insert_any_root_context(context());\n    }\n\n    let platform_config = *platform_config\n        .into_iter()\n        .find_map(|cfg| cfg.downcast::<Config>().ok())\n        .unwrap_or_default();\n\n    launch_virtual_dom(virtual_dom, platform_config)\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "00a79b27355ef802bcd1bf225b8ed23768d030ac",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/packages/desktop/src/shortcut.rs",
    "func": "#[cfg(any(\n    target_os = \"windows\",\n    target_os = \"macos\",\n    target_os = \"linux\",\n    target_os = \"dragonfly\",\n    target_os = \"freebsd\",\n    target_os = \"netbsd\",\n    target_os = \"openbsd\"\n))]\npub use global_hotkey::{\n    hotkey::{Code, HotKey},\n    Error as HotkeyError, GlobalHotKeyEvent, GlobalHotKeyManager,\n};\n\n#[cfg(any(target_os = \"ios\", target_os = \"android\"))]\npub use crate::mobile_shortcut::*;\n\nuse crate::window;\nuse dioxus_html::input_data::keyboard_types::Modifiers;\nuse slab::Slab;\nuse std::{cell::RefCell, collections::HashMap, rc::Rc, str::FromStr};\nuse tao::keyboard::ModifiersState;\n\n/// An global id for a shortcut.\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]\npub struct ShortcutHandle {\n    id: u32,\n    number: usize,\n}\n\nimpl ShortcutHandle {\n    /// Remove the shortcut.\n    pub fn remove(&self) {\n        window().remove_shortcut(*self);\n    }\n}\n\n/// An error that can occur when registering a shortcut.\n#[non_exhaustive]\n#[derive(Debug, Clone)]\npub enum ShortcutRegistryError {\n    /// The shortcut is invalid.\n    InvalidShortcut(String),\n    /// An unknown error occurred.\n    Other(Rc<dyn std::error::Error>),\n}\n\npub(crate) struct ShortcutRegistry {\n    manager: GlobalHotKeyManager,\n    shortcuts: RefCell<HashMap<u32, ShortcutInner>>,\n}\n\nstruct ShortcutInner {\n    #[allow(unused)]\n    shortcut: HotKey,\n    callbacks: Slab<Box<dyn FnMut()>>,\n}\n\nimpl ShortcutRegistry {\n    pub fn new() -> Self {\n        Self {\n            manager: GlobalHotKeyManager::new().unwrap(),\n            shortcuts: RefCell::new(HashMap::new()),\n        }\n    }\n\n    #[cfg(any(target_os = \"windows\", target_os = \"linux\", target_os = \"macos\"))]\n    pub(crate) fn call_handlers(&self, id: GlobalHotKeyEvent) {\n        if let Some(ShortcutInner { callbacks, .. }) = self.shortcuts.borrow_mut().get_mut(&id.id) {\n            for (_, callback) in callbacks.iter_mut() {\n                (callback)();\n            }\n        }\n    }\n\n    pub(crate) fn add_shortcut(\n        &self,\n        hotkey: HotKey,\n        callback: Box<dyn FnMut()>,\n    ) -> Result<ShortcutHandle, ShortcutRegistryError> {\n        let accelerator_id = hotkey.clone().id();\n\n        let mut shortcuts = self.shortcuts.borrow_mut();\n\n        if let Some(callbacks) = shortcuts.get_mut(&accelerator_id) {\n            return Ok(ShortcutHandle {\n                id: accelerator_id,\n                number: callbacks.callbacks.insert(callback),\n            });\n        };\n\n        self.manager.register(hotkey).map_err(|e| match e {\n            HotkeyError::HotKeyParseError(shortcut) => {\n                ShortcutRegistryError::InvalidShortcut(shortcut)\n            }\n            err => ShortcutRegistryError::Other(Rc::new(err)),\n        })?;\n\n        let mut shortcut = ShortcutInner {\n            shortcut: hotkey,\n            callbacks: Slab::new(),\n        };\n\n        let id = shortcut.callbacks.insert(callback);\n\n        shortcuts.insert(accelerator_id, shortcut);\n\n        Ok(ShortcutHandle {\n            id: accelerator_id,\n            number: id,\n        })\n    }\n\n    pub(crate) fn remove_shortcut(&self, id: ShortcutHandle) {\n        let mut shortcuts = self.shortcuts.borrow_mut();\n        if let Some(callbacks) = shortcuts.get_mut(&id.id) {\n            let _ = callbacks.callbacks.remove(id.number);\n            if callbacks.callbacks.is_empty() {\n                if let Some(_shortcut) = shortcuts.remove(&id.id) {\n                    let _ = self.manager.unregister(_shortcut.shortcut);\n                }\n            }\n        }\n    }\n\n    pub(crate) fn remove_all(&self) {\n        let mut shortcuts = self.shortcuts.borrow_mut();\n        let hotkeys: Vec<_> = shortcuts.drain().map(|(_, v)| v.shortcut).collect();\n        let _ = self.manager.unregister_all(&hotkeys);\n    }\n}\n\npub trait IntoAccelerator {\n    fn accelerator(&self) -> HotKey;\n}\n\nimpl IntoAccelerator for (dioxus_html::KeyCode, ModifiersState) {\n    fn accelerator(&self) -> HotKey {\n        HotKey::new(Some(self.1.into_modifiers_state()), self.0.into_key_code())\n    }\n}\n\nimpl IntoAccelerator for (ModifiersState, dioxus_html::KeyCode) {\n    fn accelerator(&self) -> HotKey {\n        HotKey::new(Some(self.0.into_modifiers_state()), self.1.into_key_code())\n    }\n}\n\nimpl IntoAccelerator for dioxus_html::KeyCode {\n    fn accelerator(&self) -> HotKey {\n        HotKey::new(None, self.into_key_code())\n    }\n}\n\nimpl IntoAccelerator for &str {\n    fn accelerator(&self) -> HotKey {\n        HotKey::from_str(self).unwrap()\n    }\n}\n\npub trait IntoModifiersState {\n    fn into_modifiers_state(self) -> Modifiers;\n}\n\nimpl IntoModifiersState for ModifiersState {\n    fn into_modifiers_state(self) -> Modifiers {\n        let mut modifiers = Modifiers::default();\n        if self.shift_key() {\n            modifiers |= Modifiers::SHIFT;\n        }\n        if self.control_key() {\n            modifiers |= Modifiers::CONTROL;\n        }\n        if self.alt_key() {\n            modifiers |= Modifiers::ALT;\n        }\n        if self.super_key() {\n            modifiers |= Modifiers::META;\n        }\n\n        modifiers\n    }\n}\n\nimpl IntoModifiersState for Modifiers {\n    fn into_modifiers_state(self) -> Modifiers {\n        self\n    }\n}\n\npub trait IntoKeyCode {\n    fn into_key_code(self) -> Code;\n}\n\nimpl IntoKeyCode for Code {\n    fn into_key_code(self) -> Code {\n        self\n    }\n}\n\nimpl IntoKeyCode for dioxus_html::KeyCode {\n    fn into_key_code(self) -> Code {\n        match self {\n            dioxus_html::KeyCode::Backspace => Code::Backspace,\n            dioxus_html::KeyCode::Tab => Code::Tab,\n            dioxus_html::KeyCode::Clear => Code::NumpadClear,\n            dioxus_html::KeyCode::Enter => Code::Enter,\n            dioxus_html::KeyCode::Shift => Code::ShiftLeft,\n            dioxus_html::KeyCode::Ctrl => Code::ControlLeft,\n            dioxus_html::KeyCode::Alt => Code::AltLeft,\n            dioxus_html::KeyCode::Pause => Code::Pause,\n            dioxus_html::KeyCode::CapsLock => Code::CapsLock,\n            dioxus_html::KeyCode::Escape => Code::Escape,\n            dioxus_html::KeyCode::Space => Code::Space,\n            dioxus_html::KeyCode::PageUp => Code::PageUp,\n            dioxus_html::KeyCode::PageDown => Code::PageDown,\n            dioxus_html::KeyCode::End => Code::End,\n            dioxus_html::KeyCode::Home => Code::Home,\n            dioxus_html::KeyCode::LeftArrow => Code::ArrowLeft,\n            dioxus_html::KeyCode::UpArrow => Code::ArrowUp,\n            dioxus_html::KeyCode::RightArrow => Code::ArrowRight,\n            dioxus_html::KeyCode::DownArrow => Code::ArrowDown,\n            dioxus_html::KeyCode::Insert => Code::Insert,\n            dioxus_html::KeyCode::Delete => Code::Delete,\n            dioxus_html::KeyCode::Num0 => Code::Numpad0,\n            dioxus_html::KeyCode::Num1 => Code::Numpad1,\n            dioxus_html::KeyCode::Num2 => Code::Numpad2,\n            dioxus_html::KeyCode::Num3 => Code::Numpad3,\n            dioxus_html::KeyCode::Num4 => Code::Numpad4,\n            dioxus_html::KeyCode::Num5 => Code::Numpad5,\n            dioxus_html::KeyCode::Num6 => Code::Numpad6,\n            dioxus_html::KeyCode::Num7 => Code::Numpad7,\n            dioxus_html::KeyCode::Num8 => Code::Numpad8,\n            dioxus_html::KeyCode::Num9 => Code::Numpad9,\n            dioxus_html::KeyCode::A => Code::KeyA,\n            dioxus_html::KeyCode::B => Code::KeyB,\n            dioxus_html::KeyCode::C => Code::KeyC,\n            dioxus_html::KeyCode::D => Code::KeyD,\n            dioxus_html::KeyCode::E => Code::KeyE,\n            dioxus_html::KeyCode::F => Code::KeyF,\n            dioxus_html::KeyCode::G => Code::KeyG,\n            dioxus_html::KeyCode::H => Code::KeyH,\n            dioxus_html::KeyCode::I => Code::KeyI,\n            dioxus_html::KeyCode::J => Code::KeyJ,\n            dioxus_html::KeyCode::K => Code::KeyK,\n            dioxus_html::KeyCode::L => Code::KeyL,\n            dioxus_html::KeyCode::M => Code::KeyM,\n            dioxus_html::KeyCode::N => Code::KeyN,\n            dioxus_html::KeyCode::O => Code::KeyO,\n            dioxus_html::KeyCode::P => Code::KeyP,\n            dioxus_html::KeyCode::Q => Code::KeyQ,\n            dioxus_html::KeyCode::R => Code::KeyR,\n            dioxus_html::KeyCode::S => Code::KeyS,\n            dioxus_html::KeyCode::T => Code::KeyT,\n            dioxus_html::KeyCode::U => Code::KeyU,\n            dioxus_html::KeyCode::V => Code::KeyV,\n            dioxus_html::KeyCode::W => Code::KeyW,\n            dioxus_html::KeyCode::X => Code::KeyX,\n            dioxus_html::KeyCode::Y => Code::KeyY,\n            dioxus_html::KeyCode::Z => Code::KeyZ,\n            dioxus_html::KeyCode::Numpad0 => Code::Numpad0,\n            dioxus_html::KeyCode::Numpad1 => Code::Numpad1,\n            dioxus_html::KeyCode::Numpad2 => Code::Numpad2,\n            dioxus_html::KeyCode::Numpad3 => Code::Numpad3,\n            dioxus_html::KeyCode::Numpad4 => Code::Numpad4,\n            dioxus_html::KeyCode::Numpad5 => Code::Numpad5,\n            dioxus_html::KeyCode::Numpad6 => Code::Numpad6,\n            dioxus_html::KeyCode::Numpad7 => Code::Numpad7,\n            dioxus_html::KeyCode::Numpad8 => Code::Numpad8,\n            dioxus_html::KeyCode::Numpad9 => Code::Numpad9,\n            dioxus_html::KeyCode::Multiply => Code::NumpadMultiply,\n            dioxus_html::KeyCode::Add => Code::NumpadAdd,\n            dioxus_html::KeyCode::Subtract => Code::NumpadSubtract,\n            dioxus_html::KeyCode::DecimalPoint => Code::NumpadDecimal,\n            dioxus_html::KeyCode::Divide => Code::NumpadDivide,\n            dioxus_html::KeyCode::F1 => Code::F1,\n            dioxus_html::KeyCode::F2 => Code::F2,\n            dioxus_html::KeyCode::F3 => Code::F3,\n            dioxus_html::KeyCode::F4 => Code::F4,\n            dioxus_html::KeyCode::F5 => Code::F5,\n            dioxus_html::KeyCode::F6 => Code::F6,\n            dioxus_html::KeyCode::F7 => Code::F7,\n            dioxus_html::KeyCode::F8 => Code::F8,\n            dioxus_html::KeyCode::F9 => Code::F9,\n            dioxus_html::KeyCode::F10 => Code::F10,\n            dioxus_html::KeyCode::F11 => Code::F11,\n            dioxus_html::KeyCode::F12 => Code::F12,\n            dioxus_html::KeyCode::NumLock => Code::NumLock,\n            dioxus_html::KeyCode::ScrollLock => Code::ScrollLock,\n            dioxus_html::KeyCode::Semicolon => Code::Semicolon,\n            dioxus_html::KeyCode::EqualSign => Code::Equal,\n            dioxus_html::KeyCode::Comma => Code::Comma,\n            dioxus_html::KeyCode::Period => Code::Period,\n            dioxus_html::KeyCode::ForwardSlash => Code::Slash,\n            dioxus_html::KeyCode::GraveAccent => Code::Backquote,\n            dioxus_html::KeyCode::OpenBracket => Code::BracketLeft,\n            dioxus_html::KeyCode::BackSlash => Code::Backslash,\n            dioxus_html::KeyCode::CloseBracket => Code::BracketRight,\n            dioxus_html::KeyCode::SingleQuote => Code::Quote,\n            key => panic!(\"Failed to convert {:?} to tao::keyboard::KeyCode, try using tao::keyboard::KeyCode directly\", key),\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "25f9a9f48d132c93c32bc0f95b37385b6c1eabbc",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/packages/router/src/hooks/use_router.rs",
    "func": "use crate::{prelude::RouterContext, utils::use_router_internal::use_router_internal};\n\n#[deprecated = \"prefer the `router()` function or `use_route` functions\"]\n#[must_use]\n/// A hook that provides access to information about the router.\npub fn use_router() -> RouterContext {\n    use_router_internal().expect(\"use_route must have access to a router\")\n}\n\n/// Acquire the router without subscribing to updates.\n#[doc(alias = \"url\")]\npub fn router() -> RouterContext {\n    dioxus_lib::prelude::consume_context()\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "3260981f60ab73df98e6b57ff2d0a84d4c1551af",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/packages/desktop/src/webview.rs",
    "func": "use crate::document::DesktopDocument;\nuse crate::element::DesktopElement;\nuse crate::file_upload::DesktopFileDragEvent;\nuse crate::menubar::DioxusMenu;\nuse crate::{\n    app::SharedContext,\n    assets::AssetHandlerRegistry,\n    edits::WryQueue,\n    file_upload::{NativeFileEngine, NativeFileHover},\n    ipc::UserWindowEvent,\n    protocol,\n    waker::tao_waker,\n    Config, DesktopContext, DesktopService,\n};\nuse dioxus_core::{Runtime, ScopeId, VirtualDom};\nuse dioxus_document::Document;\nuse dioxus_history::{History, MemoryHistory};\nuse dioxus_hooks::to_owned;\nuse dioxus_html::{HasFileData, HtmlEvent, PlatformEventData};\nuse futures_util::{pin_mut, FutureExt};\nuse std::cell::OnceCell;\nuse std::sync::Arc;\nuse std::{rc::Rc, task::Waker};\nuse wry::{DragDropEvent, RequestAsyncResponder, WebContext, WebViewBuilder};\n\n#[derive(Clone)]\npub(crate) struct WebviewEdits {\n    runtime: Rc<Runtime>,\n    pub wry_queue: WryQueue,\n    desktop_context: Rc<OnceCell<DesktopContext>>,\n}\n\nimpl WebviewEdits {\n    fn new(runtime: Rc<Runtime>, wry_queue: WryQueue) -> Self {\n        Self {\n            runtime,\n            wry_queue,\n            desktop_context: Default::default(),\n        }\n    }\n\n    fn set_desktop_context(&self, context: DesktopContext) {\n        _ = self.desktop_context.set(context);\n    }\n\n    pub fn handle_event(\n        &self,\n        request: wry::http::Request<Vec<u8>>,\n        responder: wry::RequestAsyncResponder,\n    ) {\n        let body = self.try_handle_event(request).unwrap_or_default();\n        responder.respond(wry::http::Response::new(body))\n    }\n\n    pub fn try_handle_event(\n        &self,\n        request: wry::http::Request<Vec<u8>>,\n    ) -> Result<Vec<u8>, serde_json::Error> {\n        let data_from_header = request\n            .headers()\n            .get(\"dioxus-data\")\n            .map(|f| f.as_bytes())\n            .expect(\"dioxus-data header is not a string\");\n\n        let response = match serde_json::from_slice(data_from_header) {\n            Ok(event) => {\n                // we need to wait for the mutex lock to let us munge the main thread..\n                let _lock = crate::android_sync_lock::android_runtime_lock();\n                self.handle_html_event(event)\n            }\n            Err(err) => {\n                tracing::error!(\n                    \"Error parsing user_event: {:?}.Contents: {:?}, raw: {:#?}\",\n                    err,\n                    String::from_utf8(request.body().to_vec()),\n                    request\n                );\n                SynchronousEventResponse::new(false)\n            }\n        };\n\n        let body = match serde_json::to_vec(&response) {\n            Ok(body) => body,\n            Err(err) => {\n                tracing::error!(\"failed to serialize SynchronousEventResponse: {err:?}\");\n                return Err(err);\n            }\n        };\n\n        Ok(body)\n    }\n\n    pub fn handle_html_event(&self, event: HtmlEvent) -> SynchronousEventResponse {\n        let HtmlEvent {\n            element,\n            name,\n            bubbles,\n            data,\n        } = event;\n        let Some(desktop_context) = self.desktop_context.get() else {\n            tracing::error!(\n                \"Tried to handle event before setting the desktop context on the event handler\"\n            );\n            return Default::default();\n        };\n\n        let query = desktop_context.query.clone();\n        let recent_file = desktop_context.file_hover.clone();\n\n        // check for a mounted event placeholder and replace it with a desktop specific element\n        let as_any = match data {\n            dioxus_html::EventData::Mounted => {\n                let element = DesktopElement::new(element, desktop_context.clone(), query.clone());\n                Rc::new(PlatformEventData::new(Box::new(element)))\n            }\n            dioxus_html::EventData::Drag(ref drag) => {\n                // we want to override this with a native file engine, provided by the most recent drag event\n                if drag.files().is_some() {\n                    let file_event = recent_file.current().unwrap();\n                    let paths = match file_event {\n                        wry::DragDropEvent::Enter { paths, .. } => paths,\n                        wry::DragDropEvent::Drop { paths, .. } => paths,\n                        _ => vec![],\n                    };\n                    Rc::new(PlatformEventData::new(Box::new(DesktopFileDragEvent {\n                        mouse: drag.mouse.clone(),\n                        files: Arc::new(NativeFileEngine::new(paths)),\n                    })))\n                } else {\n                    data.into_any()\n                }\n            }\n            _ => data.into_any(),\n        };\n\n        let event = dioxus_core::Event::new(as_any, bubbles);\n        self.runtime.handle_event(&name, event.clone(), element);\n\n        // Get the response from the event\n        SynchronousEventResponse::new(!event.default_action_enabled())\n    }\n}\n\npub(crate) struct WebviewInstance {\n    pub dom: VirtualDom,\n    pub edits: WebviewEdits,\n    pub desktop_context: DesktopContext,\n    pub waker: Waker,\n\n    // Wry assumes the webcontext is alive for the lifetime of the webview.\n    // We need to keep the webcontext alive, otherwise the webview will crash\n    _web_context: WebContext,\n\n    // Same with the menu.\n    // Currently it's a DioxusMenu because 1) we don't touch it and 2) we support a number of platforms\n    // like ios where muda does not give us a menu type. It sucks but alas.\n    //\n    // This would be a good thing for someone looking to contribute to fix.\n    _menu: Option<DioxusMenu>,\n}\n\nimpl WebviewInstance {\n    pub(crate) fn new(\n        mut cfg: Config,\n        dom: VirtualDom,\n        shared: Rc<SharedContext>,\n    ) -> WebviewInstance {\n        let mut window = cfg.window.clone();\n\n        // tao makes small windows for some reason, make them bigger on desktop\n        //\n        // on mobile, we want them to be `None` so tao makes them the size of the screen. Otherwise we\n        // get a window that is not the size of the screen and weird black bars.\n        #[cfg(not(any(target_os = \"ios\", target_os = \"android\")))]\n        {\n            if cfg.window.window.inner_size.is_none() {\n                window = window.with_inner_size(tao::dpi::LogicalSize::new(800.0, 600.0));\n            }\n        }\n\n        // We assume that if the icon is None in cfg, then the user just didnt set it\n        if cfg.window.window.window_icon.is_none() {\n            window = window.with_window_icon(Some(\n                tao::window::Icon::from_rgba(\n                    include_bytes!(\"./assets/default_icon.bin\").to_vec(),\n                    460,\n                    460,\n                )\n                .expect(\"image parse failed\"),\n            ));\n        }\n\n        let window = window.build(&shared.target).unwrap();\n\n        // https://developer.apple.com/documentation/appkit/nswindowcollectionbehavior/nswindowcollectionbehaviormanaged\n        #[cfg(target_os = \"macos\")]\n        {\n            use cocoa::appkit::NSWindowCollectionBehavior;\n            use cocoa::base::id;\n            use objc::{msg_send, sel, sel_impl};\n            use tao::platform::macos::WindowExtMacOS;\n\n            unsafe {\n                let window: id = window.ns_window() as id;\n                let _: () = msg_send![window, setCollectionBehavior: NSWindowCollectionBehavior::NSWindowCollectionBehaviorManaged];\n            }\n        }\n\n        let mut web_context = WebContext::new(cfg.data_dir.clone());\n        let edit_queue = WryQueue::default();\n        let asset_handlers = AssetHandlerRegistry::new();\n        let edits = WebviewEdits::new(dom.runtime(), edit_queue.clone());\n        let file_hover = NativeFileHover::default();\n        let headless = !cfg.window.window.visible;\n\n        let request_handler = {\n            to_owned![\n                cfg.custom_head,\n                cfg.custom_index,\n                cfg.root_name,\n                asset_handlers,\n                edits\n            ];\n            move |request, responder: RequestAsyncResponder| {\n                protocol::desktop_handler(\n                    request,\n                    asset_handlers.clone(),\n                    responder,\n                    &edits,\n                    custom_head.clone(),\n                    custom_index.clone(),\n                    &root_name,\n                    headless,\n                )\n            }\n        };\n\n        let ipc_handler = {\n            let window_id = window.id();\n            to_owned![shared.proxy];\n            move |payload: wry::http::Request<String>| {\n                // defer the event to the main thread\n                let body = payload.into_body();\n                if let Ok(msg) = serde_json::from_str(&body) {\n                    _ = proxy.send_event(UserWindowEvent::Ipc { id: window_id, msg });\n                }\n            }\n        };\n\n        let file_drop_handler = {\n            to_owned![file_hover];\n\n            #[cfg(windows)]\n            let (proxy, window_id) = (shared.proxy.to_owned(), window.id());\n\n            move |evt: DragDropEvent| {\n                // Update the most recent file drop event - when the event comes in from the webview we can use the\n                // most recent event to build a new event with the files in it.\n                #[cfg(not(windows))]\n                file_hover.set(evt);\n\n                // Windows webview blocks HTML-native events when the drop handler is provided.\n                // The problem is that the HTML-native events don't provide the file, so we need this.\n                // Solution: this glue code to mimic drag drop events.\n                #[cfg(windows)]\n                {\n                    file_hover.set(evt.clone());\n\n                    match evt {\n                        wry::DragDropEvent::Drop {\n                            paths: _,\n                            position: _,\n                        } => {\n                            _ = proxy.send_event(UserWindowEvent::WindowsDragDrop(window_id));\n                        }\n                        wry::DragDropEvent::Over { position } => {\n                            _ = proxy.send_event(UserWindowEvent::WindowsDragOver(\n                                window_id, position.0, position.1,\n                            ));\n                        }\n                        wry::DragDropEvent::Leave => {\n                            _ = proxy.send_event(UserWindowEvent::WindowsDragLeave(window_id));\n                        }\n                        _ => {}\n                    }\n                }\n\n                false\n            }\n        };\n\n        #[cfg(any(\n            target_os = \"windows\",\n            target_os = \"macos\",\n            target_os = \"ios\",\n            target_os = \"android\"\n        ))]\n        let mut webview = if cfg.as_child_window {\n            WebViewBuilder::new_as_child(&window)\n        } else {\n            WebViewBuilder::new(&window)\n        };\n\n        #[cfg(not(any(\n            target_os = \"windows\",\n            target_os = \"macos\",\n            target_os = \"ios\",\n            target_os = \"android\"\n        )))]\n        let mut webview = {\n            use tao::platform::unix::WindowExtUnix;\n            use wry::WebViewBuilderExtUnix;\n            let vbox = window.default_vbox().unwrap();\n            WebViewBuilder::new_gtk(vbox)\n        };\n\n        // Disable the webview default shortcuts to disable the reload shortcut\n        #[cfg(target_os = \"windows\")]\n        {\n            use wry::WebViewBuilderExtWindows;\n            webview = webview.with_browser_accelerator_keys(false);\n        }\n\n        webview = webview\n            .with_bounds(wry::Rect {\n                position: wry::dpi::Position::Logical(wry::dpi::LogicalPosition::new(0.0, 0.0)),\n                size: wry::dpi::Size::Physical(wry::dpi::PhysicalSize::new(\n                    window.inner_size().width,\n                    window.inner_size().height,\n                )),\n            })\n            .with_transparent(cfg.window.window.transparent)\n            .with_url(\"dioxus://index.html/\")\n            .with_ipc_handler(ipc_handler)\n            .with_navigation_handler(|var| {\n                // We don't want to allow any navigation\n                // We only want to serve the index file and assets\n                if var.starts_with(\"dioxus://\") || var.starts_with(\"http://dioxus.\") {\n                    true\n                } else {\n                    if var.starts_with(\"http://\") || var.starts_with(\"https://\") {\n                        _ = webbrowser::open(&var);\n                    }\n                    false\n                }\n            }) // prevent all navigations\n            .with_asynchronous_custom_protocol(String::from(\"dioxus\"), request_handler)\n            .with_web_context(&mut web_context)\n            .with_drag_drop_handler(file_drop_handler);\n\n        if let Some(color) = cfg.background_color {\n            webview = webview.with_background_color(color);\n        }\n\n        for (name, handler) in cfg.protocols.drain(..) {\n            webview = webview.with_custom_protocol(name, handler);\n        }\n\n        for (name, handler) in cfg.asynchronous_protocols.drain(..) {\n            webview = webview.with_asynchronous_custom_protocol(name, handler);\n        }\n\n        const INITIALIZATION_SCRIPT: &str = r#\"\n        if (document.addEventListener) {\n            document.addEventListener('contextmenu', function(e) {\n                e.preventDefault();\n            }, false);\n        } else {\n            document.attachEvent('oncontextmenu', function() {\n                window.event.returnValue = false;\n            });\n        }\n        \"#;\n\n        if cfg.disable_context_menu {\n            // in release mode, we don't want to show the dev tool or reload menus\n            webview = webview.with_initialization_script(INITIALIZATION_SCRIPT)\n        } else {\n            // in debug, we are okay with the reload menu showing and dev tool\n            webview = webview.with_devtools(true);\n        }\n\n        let webview = webview.build().unwrap();\n\n        let menu = if cfg!(not(any(target_os = \"android\", target_os = \"ios\"))) {\n            let menu_option = cfg.menu.into();\n            if let Some(menu) = &menu_option {\n                crate::menubar::init_menu_bar(menu, &window);\n            }\n            menu_option\n        } else {\n            None\n        };\n\n        let desktop_context = Rc::from(DesktopService::new(\n            webview,\n            window,\n            shared.clone(),\n            asset_handlers,\n            file_hover,\n        ));\n\n        // Provide the desktop context to the virtual dom and edit handler\n        edits.set_desktop_context(desktop_context.clone());\n        let provider: Rc<dyn Document> = Rc::new(DesktopDocument::new(desktop_context.clone()));\n        let history_provider: Rc<dyn History> = Rc::new(MemoryHistory::default());\n        dom.in_runtime(|| {\n            ScopeId::ROOT.provide_context(desktop_context.clone());\n            ScopeId::ROOT.provide_context(provider);\n            ScopeId::ROOT.provide_context(history_provider);\n        });\n\n        WebviewInstance {\n            dom,\n            edits,\n            waker: tao_waker(shared.proxy.clone(), desktop_context.window.id()),\n            desktop_context,\n            _menu: menu,\n            _web_context: web_context,\n        }\n    }\n\n    pub fn poll_vdom(&mut self) {\n        let mut cx = std::task::Context::from_waker(&self.waker);\n\n        // Continuously poll the virtualdom until it's pending\n        // Wait for work will return Ready when it has edits to be sent to the webview\n        // It will return Pending when it needs to be polled again - nothing is ready\n        loop {\n            // If we're waiting for a render, wait for it to finish before we continue\n            let edits_flushed_poll = self.edits.wry_queue.poll_edits_flushed(&mut cx);\n            if edits_flushed_poll.is_pending() {\n                return;\n            }\n\n            {\n                let fut = self.dom.wait_for_work();\n                pin_mut!(fut);\n\n                match fut.poll_unpin(&mut cx) {\n                    std::task::Poll::Ready(_) => {}\n                    std::task::Poll::Pending => return,\n                }\n            }\n\n            // lock the hack-ed in lock sync wry has some thread-safety issues with event handlers\n            let _lock = crate::android_sync_lock::android_runtime_lock();\n\n            self.edits\n                .wry_queue\n                .with_mutation_state_mut(|f| self.dom.render_immediate(f));\n            self.edits.wry_queue.send_edits();\n        }\n    }\n\n    #[cfg(all(feature = \"devtools\", debug_assertions))]\n    pub fn kick_stylsheets(&self) {\n        // run eval in the webview to kick the stylesheets by appending a query string\n        // we should do something less clunky than this\n        _ = self\n            .desktop_context\n            .webview\n            .evaluate_script(\"window.interpreter.kickAllStylesheetsOnPage()\");\n    }\n}\n\n/// A synchronous response to a browser event which may prevent the default browser's action\n#[derive(serde::Serialize, Default)]\npub struct SynchronousEventResponse {\n    #[serde(rename = \"preventDefault\")]\n    prevent_default: bool,\n}\n\nimpl SynchronousEventResponse {\n    /// Create a new SynchronousEventResponse\n    #[allow(unused)]\n    pub fn new(prevent_default: bool) -> Self {\n        Self { prevent_default }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "9720e7db3abe1cefa25ee13515cf6deec3ed2dd7",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/packages/router/src/hooks/use_route.rs",
    "func": "use crate::prelude::*;\nuse crate::utils::use_router_internal::use_router_internal;\n\n/// A hook that provides access to information about the current routing location.\n///\n/// > The Routable macro will define a version of this hook with an explicit type.\n///\n/// # Panic\n/// - When the calling component is not nested within a [`Router`] component.\n///\n/// # Example\n/// ```rust\n/// # use dioxus::prelude::*;\n/// # use dioxus_router::{prelude::*};\n///\n/// #[derive(Clone, Routable)]\n/// enum Route {\n///     #[route(\"/\")]\n///     Index {},\n/// }\n///\n/// #[component]\n/// fn App() -> Element {\n///     rsx! {\n///         h1 { \"App\" }\n///         Router::<Route> {}\n///     }\n/// }\n///\n/// #[component]\n/// fn Index() -> Element {\n///     let path: Route = use_route();\n///     rsx! {\n///         h2 { \"Current Path\" }\n///         p { \"{path}\" }\n///     }\n/// }\n/// #\n/// # let mut vdom = VirtualDom::new(App);\n/// # vdom.rebuild_in_place();\n/// # assert_eq!(dioxus_ssr::render(&vdom), \"<h1>App</h1><h2>Current Path</h2><p>/</p>\")\n/// ```\n#[doc(alias = \"use_url\")]\n#[must_use]\npub fn use_route<R: Routable + Clone>() -> R {\n    match use_router_internal() {\n        Some(r) => r.current(),\n        None => {\n            panic!(\"`use_route` must be called in a descendant of a Router component\")\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "c99437431303b3cc54f21b15d16ff9ab2297710f",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/packages/autofmt/tests/samples.rs",
    "func": "#![allow(deprecated)]\n\nmacro_rules! twoway {\n    (\n        $(\n\n            // doc attrs\n            $( #[doc = $doc:expr] )*\n            $name:ident,\n        )*\n    ) => {\n        $(\n            $( #[doc = $doc] )*\n            #[test]\n            fn $name() {\n                let src = include_str!(concat!(\"./samples/\", stringify!($name), \".rsx\"));\n                let formatted = dioxus_autofmt::fmt_file(src, Default::default());\n                let out = dioxus_autofmt::apply_formats(src, formatted);\n                // normalize line endings\n                let out = out.replace(\"\\r\", \"\");\n                let src = src.replace(\"\\r\", \"\");\n                pretty_assertions::assert_eq!(&src, &out);\n            }\n        )*\n    };\n}\ntwoway![\n    attributes,\n    basic_expr,\n    collapse_expr,\n    comments,\n    commentshard,\n    complex,\n    docsite,\n    emoji,\n    fat_exprs,\n    ifchain_forloop,\n    immediate_expr,\n    key,\n    letsome,\n    long_exprs,\n    long,\n    manual_props,\n    many_exprs,\n    messy_indent,\n    misplaced,\n    multirsx,\n    nested,\n    raw_strings,\n    reallylong,\n    shorthand,\n    simple,\n    skip,\n    spaces,\n    staged,\n    t2,\n    tiny,\n    tinynoopt,\n    trailing_expr,\n    oneline,\n    prop_rsx,\n    asset,\n    collapse,\n];\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "c33aeb40f2b54edbf9a9a8bb568b2f18dd38079b",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/packages/autofmt/src/indent.rs",
    "func": "#[derive(Clone, Copy, PartialEq, Eq, Debug)]\npub enum IndentType {\n    Spaces,\n    Tabs,\n}\n\n#[derive(Debug, Clone)]\npub struct IndentOptions {\n    width: usize,\n    indent_string: String,\n    split_line_attributes: bool,\n}\n\nimpl IndentOptions {\n    pub fn new(typ: IndentType, width: usize, split_line_attributes: bool) -> Self {\n        assert_ne!(width, 0, \"Cannot have an indent width of 0\");\n        Self {\n            width,\n            indent_string: match typ {\n                IndentType::Tabs => \"\\t\".into(),\n                IndentType::Spaces => \" \".repeat(width),\n            },\n            split_line_attributes,\n        }\n    }\n\n    /// Gets a string containing one indent worth of whitespace\n    pub fn indent_str(&self) -> &str {\n        &self.indent_string\n    }\n\n    /// Computes the line length in characters, counting tabs as the indent width.\n    pub fn line_length(&self, line: &str) -> usize {\n        line.chars()\n            .map(|ch| if ch == '\\t' { self.width } else { 1 })\n            .sum()\n    }\n\n    /// Estimates how many times the line has been indented.\n    pub fn count_indents(&self, mut line: &str) -> usize {\n        let mut indent = 0;\n        while !line.is_empty() {\n            // Try to count tabs\n            let num_tabs = line.chars().take_while(|ch| *ch == '\\t').count();\n            if num_tabs > 0 {\n                indent += num_tabs;\n                line = &line[num_tabs..];\n                continue;\n            }\n\n            // Try to count spaces\n            let num_spaces = line.chars().take_while(|ch| *ch == ' ').count();\n            if num_spaces >= self.width {\n                // Intentionally floor here to take only the amount of space that matches an indent\n                let num_space_indents = num_spaces / self.width;\n                indent += num_space_indents;\n                line = &line[num_space_indents * self.width..];\n                continue;\n            }\n\n            // Line starts with either non-indent characters or an unevent amount of spaces,\n            // so no more indent remains.\n            break;\n        }\n        indent\n    }\n\n    pub fn split_line_attributes(&self) -> bool {\n        self.split_line_attributes\n    }\n}\n\nimpl Default for IndentOptions {\n    fn default() -> Self {\n        Self::new(IndentType::Spaces, 4, false)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn count_indents() {\n        assert_eq!(\n            IndentOptions::new(IndentType::Spaces, 4, false).count_indents(\"no indentation here!\"),\n            0\n        );\n        assert_eq!(\n            IndentOptions::new(IndentType::Spaces, 4, false).count_indents(\"    v += 2\"),\n            1\n        );\n        assert_eq!(\n            IndentOptions::new(IndentType::Spaces, 4, false).count_indents(\"        v += 2\"),\n            2\n        );\n        assert_eq!(\n            IndentOptions::new(IndentType::Spaces, 4, false).count_indents(\"          v += 2\"),\n            2\n        );\n        assert_eq!(\n            IndentOptions::new(IndentType::Spaces, 4, false).count_indents(\"\\t\\tv += 2\"),\n            2\n        );\n        assert_eq!(\n            IndentOptions::new(IndentType::Spaces, 4, false).count_indents(\"\\t\\t  v += 2\"),\n            2\n        );\n        assert_eq!(\n            IndentOptions::new(IndentType::Spaces, 2, false).count_indents(\"    v += 2\"),\n            2\n        );\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "1053f2401dfd73781d6e397e476e0eaad3452c97",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/packages/manganis/manganis/src/lib.rs",
    "func": "#![doc = include_str!(\"../README.md\")]\n#![deny(missing_docs)]\n\nmod hash;\n#[doc(hidden)]\npub mod macro_helpers;\npub use manganis_macro::asset;\n\npub use manganis_core::{\n    Asset, AssetOptions, BundledAsset, CssAssetOptions, FolderAssetOptions, ImageAssetOptions,\n    ImageFormat, ImageSize, JsAssetOptions,\n};\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "4ee7c7c48ded632eef5b79cd7ec556a262634d52",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/packages/router-macro/src/route.rs",
    "func": "use quote::{format_ident, quote};\nuse syn::parse::Parse;\nuse syn::parse::ParseStream;\nuse syn::parse_quote;\nuse syn::Field;\nuse syn::Path;\nuse syn::Type;\nuse syn::{Ident, LitStr};\n\nuse proc_macro2::TokenStream as TokenStream2;\n\nuse crate::hash::HashFragment;\nuse crate::layout::Layout;\nuse crate::layout::LayoutId;\nuse crate::nest::Nest;\nuse crate::nest::NestId;\nuse crate::query::QuerySegment;\nuse crate::segment::create_error_type;\nuse crate::segment::parse_route_segments;\nuse crate::segment::RouteSegment;\n\nstruct RouteArgs {\n    route: LitStr,\n    comp_name: Option<Path>,\n}\n\nimpl Parse for RouteArgs {\n    fn parse(input: ParseStream<'_>) -> syn::Result<Self> {\n        let route = input.parse::<LitStr>()?;\n\n        Ok(RouteArgs {\n            route,\n            comp_name: {\n                let _ = input.parse::<syn::Token![,]>();\n                input.parse().ok()\n            },\n        })\n    }\n}\n\nstruct ChildArgs {\n    route: LitStr,\n}\n\nimpl Parse for ChildArgs {\n    fn parse(input: ParseStream<'_>) -> syn::Result<Self> {\n        let route = input.parse::<LitStr>()?;\n\n        Ok(ChildArgs { route })\n    }\n}\n\n#[derive(Debug)]\npub(crate) struct Route {\n    pub route_name: Ident,\n    pub ty: RouteType,\n    pub route: String,\n    pub segments: Vec<RouteSegment>,\n    pub query: Option<QuerySegment>,\n    pub hash: Option<HashFragment>,\n    pub nests: Vec<NestId>,\n    pub layouts: Vec<LayoutId>,\n    fields: Vec<(Ident, Type)>,\n}\n\nimpl Route {\n    pub fn parse(\n        nests: Vec<NestId>,\n        layouts: Vec<LayoutId>,\n        variant: syn::Variant,\n    ) -> syn::Result<Self> {\n        let route_attr = variant\n            .attrs\n            .iter()\n            .find(|attr| attr.path().is_ident(\"route\"));\n        let route;\n        let ty;\n        let route_name = variant.ident.clone();\n        match route_attr {\n            Some(attr) => {\n                let args = attr.parse_args::<RouteArgs>()?;\n                let comp_name = args.comp_name.unwrap_or_else(|| parse_quote!(#route_name));\n                ty = RouteType::Leaf {\n                    component: comp_name,\n                };\n                route = args.route.value();\n            }\n            None => {\n                if let Some(route_attr) = variant\n                    .attrs\n                    .iter()\n                    .find(|attr| attr.path().is_ident(\"child\"))\n                {\n                    let args = route_attr.parse_args::<ChildArgs>()?;\n                    route = args.route.value();\n                    match &variant.fields {\n                        syn::Fields::Named(fields) => {\n                            // find either a field with #[child] or a field named \"child\"\n                            let child_field = fields.named.iter().find(|f| {\n                                f.attrs\n                                    .iter()\n                                    .any(|attr| attr.path().is_ident(\"child\"))\n                                    || *f.ident.as_ref().unwrap() == \"child\"\n                            });\n                            match child_field{\n                                Some(child) => {\n                                    ty = RouteType::Child(child.clone());\n                                }\n                                None => {\n                                    return Err(syn::Error::new_spanned(\n                                        variant.clone(),\n                                        \"Routable variants with a #[child(..)] attribute must have a field named \\\"child\\\" or a field with a #[child] attribute\",\n                                    ));\n                                }\n                            }\n                        }\n                        _ => {\n                            return Err(syn::Error::new_spanned(\n                                variant.clone(),\n                                \"Routable variants with a #[child(..)] attribute must have named fields\",\n                            ))\n                        }\n                    }\n                } else {\n                    return Err(syn::Error::new_spanned(\n                            variant.clone(),\n                            \"Routable variants must either have a #[route(..)] attribute or a #[child(..)] attribute\",\n                        ));\n                }\n            }\n        };\n\n        let fields = match &variant.fields {\n            syn::Fields::Named(fields) => fields\n                .named\n                .iter()\n                .filter_map(|f| {\n                    if let RouteType::Child(child) = &ty {\n                        if f.ident == child.ident {\n                            return None;\n                        }\n                    }\n                    Some((f.ident.clone().unwrap(), f.ty.clone()))\n                })\n                .collect(),\n            _ => Vec::new(),\n        };\n\n        let (route_segments, query, hash) = {\n            parse_route_segments(\n                variant.ident.span(),\n                fields.iter().map(|f| (&f.0, &f.1)),\n                &route,\n            )?\n        };\n\n        Ok(Self {\n            ty,\n            route_name,\n            segments: route_segments,\n            route,\n            query,\n            hash,\n            nests,\n            layouts,\n            fields,\n        })\n    }\n\n    pub fn display_match(&self, nests: &[Nest]) -> TokenStream2 {\n        let name = &self.route_name;\n        let dynamic_segments = self.dynamic_segments();\n        let write_query: Option<TokenStream2> = self.query.as_ref().map(|q| q.write());\n        let write_hash = self.hash.as_ref().map(|q| q.write());\n\n        match &self.ty {\n            RouteType::Child(field) => {\n                let write_nests = self.nests.iter().map(|id| nests[id.0].write());\n                let write_segments = self.segments.iter().map(|s| s.write_segment());\n                let child = field.ident.as_ref().unwrap();\n                quote! {\n                    Self::#name { #(#dynamic_segments,)* #child } => {\n                        use std::fmt::Display;\n                        use std::fmt::Write;\n                        let mut route = String::new();\n                        {\n                            let f = &mut route;\n                            #(#write_nests)*\n                            #(#write_segments)*\n                        }\n                        if route.ends_with('/') {\n                            route.pop();\n                        }\n                        f.write_str(&route)?;\n                        #child.fmt(f)?;\n                    }\n                }\n            }\n            RouteType::Leaf { .. } => {\n                let write_nests = self.nests.iter().map(|id| nests[id.0].write());\n                let write_segments = self.segments.iter().map(|s| s.write_segment());\n                quote! {\n                    Self::#name { #(#dynamic_segments,)* } => {\n                        #(#write_nests)*\n                        #(#write_segments)*\n                        #write_query\n                        #write_hash\n                    }\n                }\n            }\n        }\n    }\n\n    pub fn routable_match(&self, layouts: &[Layout], nests: &[Nest]) -> TokenStream2 {\n        let name = &self.route_name;\n\n        let mut tokens = TokenStream2::new();\n\n        // First match all layouts\n        for (idx, layout_id) in self.layouts.iter().copied().enumerate() {\n            let render_layout = layouts[layout_id.0].routable_match(nests);\n            let dynamic_segments = self.dynamic_segments();\n            let mut field_name = None;\n            if let RouteType::Child(field) = &self.ty {\n                field_name = field.ident.as_ref();\n            }\n            let field_name = field_name.map(|f| quote!(#f,));\n            // This is a layout\n            tokens.extend(quote! {\n                #[allow(unused)]\n                (#idx, Self::#name { #(#dynamic_segments,)* #field_name .. }) => {\n                    #render_layout\n                }\n            });\n        }\n\n        // Then match the route\n        let last_index = self.layouts.len();\n        tokens.extend(match &self.ty {\n            RouteType::Child(field) => {\n                let field_name = field.ident.as_ref().unwrap();\n                quote! {\n                    #[allow(unused)]\n                    (#last_index.., Self::#name { #field_name, .. }) => {\n                        rsx! {\n                            dioxus_router::components::child_router::ChildRouter {\n                                route: #field_name,\n                                // Try to parse the current route as a parent route, and then match it as a child route\n                                parse_route_from_root_route: |__route| if let Ok(__route) = __route.parse() {\n                                    if let Self::#name { #field_name, .. } = __route {\n                                        Some(#field_name)\n                                    } else {\n                                        None\n                                    }\n                                } else {\n                                    None\n                                },\n                                // Try to parse the child route and turn it into a parent route\n                                format_route_as_root_route: |#field_name| Self::#name { #field_name: #field_name }.to_string(),\n                            }\n                        }\n                    }\n                }\n            }\n            RouteType::Leaf { component } => {\n                let dynamic_segments = self.dynamic_segments();\n                let dynamic_segments_from_route = self.dynamic_segments();\n                quote! {\n                    #[allow(unused)]\n                    (#last_index, Self::#name { #(#dynamic_segments,)* }) => {\n                        rsx! {\n                            #component {\n                                #(#dynamic_segments_from_route: #dynamic_segments_from_route,)*\n                            }\n                        }\n                    }\n                }\n            }\n        });\n\n        tokens\n    }\n\n    fn dynamic_segments(&self) -> impl Iterator<Item = TokenStream2> + '_ {\n        self.fields.iter().map(|(name, _)| {\n            quote! {#name}\n        })\n    }\n\n    pub fn construct(&self, nests: &[Nest], enum_name: Ident) -> TokenStream2 {\n        let segments = self.fields.iter().map(|(name, _)| {\n            let mut from_route = false;\n\n            for id in &self.nests {\n                let nest = &nests[id.0];\n                if nest.dynamic_segments_names().any(|i| &i == name) {\n                    from_route = true\n                }\n            }\n            for segment in &self.segments {\n                if segment.name().as_ref() == Some(name) {\n                    from_route = true\n                }\n            }\n            if let Some(query) = &self.query {\n                if query.contains_ident(name) {\n                    from_route = true\n                }\n            }\n            if let Some(hash) = &self.hash {\n                if hash.contains_ident(name) {\n                    from_route = true\n                }\n            }\n\n            if from_route {\n                quote! {#name}\n            } else {\n                quote! {#name: Default::default()}\n            }\n        });\n        match &self.ty {\n            RouteType::Child(field) => {\n                let name = &self.route_name;\n                let child_name = field.ident.as_ref().unwrap();\n\n                quote! {\n                    #enum_name::#name {\n                        #child_name,\n                        #(#segments,)*\n                    }\n                }\n            }\n            RouteType::Leaf { .. } => {\n                let name = &self.route_name;\n\n                quote! {\n                    #enum_name::#name {\n                        #(#segments,)*\n                    }\n                }\n            }\n        }\n    }\n\n    pub fn error_ident(&self) -> Ident {\n        format_ident!(\"{}ParseError\", self.route_name)\n    }\n\n    pub fn error_type(&self) -> TokenStream2 {\n        let error_name = self.error_ident();\n        let child_type = match &self.ty {\n            RouteType::Child(field) => Some(&field.ty),\n            RouteType::Leaf { .. } => None,\n        };\n\n        create_error_type(&self.route, error_name, &self.segments, child_type)\n    }\n\n    pub fn parse_query(&self) -> TokenStream2 {\n        match &self.query {\n            Some(query) => query.parse(),\n            None => quote! {},\n        }\n    }\n\n    pub fn parse_hash(&self) -> TokenStream2 {\n        match &self.hash {\n            Some(hash) => hash.parse(),\n            None => quote! {},\n        }\n    }\n}\n\n#[derive(Debug)]\npub(crate) enum RouteType {\n    Child(Field),\n    Leaf { component: Path },\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "ce96ba2a91bd676f9012f6c9b9528470d56f24af",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/packages/router-macro/src/query.rs",
    "func": "use quote::quote;\nuse syn::{Ident, Type};\n\nuse proc_macro2::TokenStream as TokenStream2;\n\n#[derive(Debug)]\npub enum QuerySegment {\n    Single(FullQuerySegment),\n    Segments(Vec<QueryArgument>),\n}\n\nimpl QuerySegment {\n    pub fn contains_ident(&self, ident: &Ident) -> bool {\n        match self {\n            QuerySegment::Single(segment) => segment.ident == *ident,\n            QuerySegment::Segments(segments) => {\n                segments.iter().any(|segment| segment.ident == *ident)\n            }\n        }\n    }\n\n    pub fn parse(&self) -> TokenStream2 {\n        match self {\n            QuerySegment::Single(segment) => segment.parse(),\n            QuerySegment::Segments(segments) => {\n                let mut tokens = TokenStream2::new();\n                tokens.extend(quote! { let split_query: std::collections::HashMap<&str, &str> = query.split('&').filter_map(|s| s.split_once('=')).collect(); });\n                for segment in segments {\n                    tokens.extend(segment.parse());\n                }\n                tokens\n            }\n        }\n    }\n\n    pub fn write(&self) -> TokenStream2 {\n        match self {\n            QuerySegment::Single(segment) => segment.write(),\n            QuerySegment::Segments(segments) => {\n                let mut tokens = TokenStream2::new();\n                tokens.extend(quote! { write!(f, \"?\")?; });\n                let mut segments_iter = segments.iter();\n                if let Some(first_segment) = segments_iter.next() {\n                    tokens.extend(first_segment.write());\n                }\n                for segment in segments_iter {\n                    tokens.extend(quote! { write!(f, \"&\")?; });\n                    tokens.extend(segment.write());\n                }\n                tokens\n            }\n        }\n    }\n\n    pub fn parse_from_str<'a>(\n        route_span: proc_macro2::Span,\n        mut fields: impl Iterator<Item = (&'a Ident, &'a Type)>,\n        query: &str,\n    ) -> syn::Result<Self> {\n        // check if the route has a query string\n        if let Some(query) = query.strip_prefix(\":..\") {\n            let query_ident = Ident::new(query, proc_macro2::Span::call_site());\n            let field = fields.find(|(name, _)| *name == &query_ident);\n\n            let ty = if let Some((_, ty)) = field {\n                ty.clone()\n            } else {\n                return Err(syn::Error::new(\n                    route_span,\n                    format!(\"Could not find a field with the name '{}'\", query_ident),\n                ));\n            };\n\n            Ok(QuerySegment::Single(FullQuerySegment {\n                ident: query_ident,\n                ty,\n            }))\n        } else {\n            let mut query_arguments = Vec::new();\n            for segment in query.split('&') {\n                if segment.is_empty() {\n                    return Err(syn::Error::new(\n                        route_span,\n                        \"Query segments should be non-empty\",\n                    ));\n                }\n                if let Some(query_argument) = segment.strip_prefix(':') {\n                    let query_ident = Ident::new(query_argument, proc_macro2::Span::call_site());\n                    let field = fields.find(|(name, _)| *name == &query_ident);\n\n                    let ty = if let Some((_, ty)) = field {\n                        ty.clone()\n                    } else {\n                        return Err(syn::Error::new(\n                            route_span,\n                            format!(\"Could not find a field with the name '{}'\", query_ident),\n                        ));\n                    };\n\n                    query_arguments.push(QueryArgument {\n                        ident: query_ident,\n                        ty,\n                    });\n                } else {\n                    return Err(syn::Error::new(\n                        route_span,\n                        \"Query segments should be a : followed by the name of the query argument\",\n                    ));\n                }\n            }\n            Ok(QuerySegment::Segments(query_arguments))\n        }\n    }\n}\n\n#[derive(Debug)]\npub struct FullQuerySegment {\n    pub ident: Ident,\n    pub ty: Type,\n}\n\nimpl FullQuerySegment {\n    pub fn parse(&self) -> TokenStream2 {\n        let ident = &self.ident;\n        let ty = &self.ty;\n        quote! {\n            let #ident = <#ty as dioxus_router::routable::FromQuery>::from_query(&*query);\n        }\n    }\n\n    pub fn write(&self) -> TokenStream2 {\n        let ident = &self.ident;\n        quote! {\n            {\n                let as_string = #ident.to_string();\n                write!(f, \"?{}\", dioxus_router::exports::urlencoding::encode(&as_string))?;\n            }\n        }\n    }\n}\n\n#[derive(Debug)]\npub struct QueryArgument {\n    pub ident: Ident,\n    pub ty: Type,\n}\n\nimpl QueryArgument {\n    pub fn parse(&self) -> TokenStream2 {\n        let ident = &self.ident;\n        let ty = &self.ty;\n        quote! {\n            let #ident = match split_query.get(stringify!(#ident)) {\n                Some(query_argument) => <#ty as dioxus_router::routable::FromQueryArgument>::from_query_argument(query_argument).unwrap_or_default(),\n                None => <#ty as Default>::default(),\n            };\n        }\n    }\n\n    pub fn write(&self) -> TokenStream2 {\n        let ident = &self.ident;\n        quote! {\n            {\n                let as_string = #ident.to_string();\n                write!(f, \"{}={}\", stringify!(#ident), dioxus_router::exports::urlencoding::encode(&as_string))?;\n            }\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "531e2626b483cd38e38a9df8b2f115a298cf0b57",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/packages/html/src/render_template.rs",
    "func": "use dioxus_core::{Template, TemplateAttribute, TemplateNode};\nuse std::fmt::Write;\n\n/// Render a template to an HTML string\n///\n/// Useful for sending over the wire. Can be used to with innerHtml to create templates with little work\npub fn render_template_to_html(template: &Template) -> String {\n    let mut out = String::new();\n\n    for root in template.roots {\n        render_template_node(root, &mut out).unwrap();\n    }\n\n    out\n}\n\nfn render_template_node(node: &TemplateNode, out: &mut String) -> std::fmt::Result {\n    match node {\n        TemplateNode::Element {\n            tag,\n            attrs,\n            children,\n            ..\n        } => {\n            write!(out, \"<{tag}\")?;\n            for attr in *attrs {\n                if let TemplateAttribute::Static { name, value, .. } = attr {\n                    write!(out, \"{name}=\\\"{value}\\\"\")?;\n                }\n            }\n            for child in *children {\n                render_template_node(child, out)?;\n            }\n            write!(out, \"</{tag}>\")?;\n        }\n        TemplateNode::Text { text: t } => write!(out, \"{t}\")?,\n        TemplateNode::Dynamic { id: _ } => write!(out, \"<!--placeholder-->\")?,\n    };\n    Ok(())\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "dfef8bcef8ec99b90e0646d630df7d774f22cc42",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/packages/const-serialize/src/lib.rs",
    "func": "#![doc = include_str!(\"../README.md\")]\n#![warn(missing_docs)]\n\nuse std::{char, mem::MaybeUninit};\n\nmod const_buffers;\nmod const_vec;\n\npub use const_buffers::ConstReadBuffer;\npub use const_serialize_macro::SerializeConst;\npub use const_vec::ConstVec;\n\n/// Plain old data for a field. Stores the offset of the field in the struct and the layout of the field.\n#[derive(Debug, Copy, Clone)]\npub struct StructFieldLayout {\n    offset: usize,\n    layout: Layout,\n}\n\nimpl StructFieldLayout {\n    /// Create a new struct field layout\n    pub const fn new(offset: usize, layout: Layout) -> Self {\n        Self { offset, layout }\n    }\n}\n\n/// Layout for a struct. The struct layout is just a list of fields with offsets\n#[derive(Debug, Copy, Clone)]\npub struct StructLayout {\n    size: usize,\n    data: &'static [StructFieldLayout],\n}\n\nimpl StructLayout {\n    /// Create a new struct layout\n    pub const fn new(size: usize, data: &'static [StructFieldLayout]) -> Self {\n        Self { size, data }\n    }\n}\n\n/// The layout for an enum. The enum layout is just a discriminate size and a tag layout.\n#[derive(Debug, Copy, Clone)]\npub struct EnumLayout {\n    size: usize,\n    discriminant: PrimitiveLayout,\n    variants_offset: usize,\n    variants: &'static [EnumVariant],\n}\n\nimpl EnumLayout {\n    /// Create a new enum layout\n    pub const fn new(\n        size: usize,\n        discriminant: PrimitiveLayout,\n        variants: &'static [EnumVariant],\n    ) -> Self {\n        let mut max_align = 1;\n        let mut i = 0;\n        while i < variants.len() {\n            let EnumVariant { align, .. } = &variants[i];\n            if *align > max_align {\n                max_align = *align;\n            }\n            i += 1;\n        }\n\n        let variants_offset = (discriminant.size / max_align) + max_align;\n\n        Self {\n            size,\n            discriminant,\n            variants_offset,\n            variants,\n        }\n    }\n}\n\n/// The layout for an enum variant. The enum variant layout is just a struct layout with a tag and alignment.\n#[derive(Debug, Copy, Clone)]\npub struct EnumVariant {\n    // Note: tags may not be sequential\n    tag: u32,\n    data: StructLayout,\n    align: usize,\n}\n\nimpl EnumVariant {\n    /// Create a new enum variant layout\n    pub const fn new(tag: u32, data: StructLayout, align: usize) -> Self {\n        Self { tag, data, align }\n    }\n}\n\n/// The layout for a constant sized array. The array layout is just a length and an item layout.\n#[derive(Debug, Copy, Clone)]\npub struct ListLayout {\n    len: usize,\n    item_layout: &'static Layout,\n}\n\nimpl ListLayout {\n    /// Create a new list layout\n    pub const fn new(len: usize, item_layout: &'static Layout) -> Self {\n        Self { len, item_layout }\n    }\n}\n\n/// The layout for a primitive type. The bytes will be reversed if the target is big endian.\n#[derive(Debug, Copy, Clone)]\npub struct PrimitiveLayout {\n    size: usize,\n}\n\nimpl PrimitiveLayout {\n    /// Create a new primitive layout\n    pub const fn new(size: usize) -> Self {\n        Self { size }\n    }\n}\n\n/// The layout for a type. This layout defines a sequence of locations and reversed or not bytes. These bytes will be copied from during serialization and copied into during deserialization.\n#[derive(Debug, Copy, Clone)]\npub enum Layout {\n    /// An enum layout\n    Enum(EnumLayout),\n    /// A struct layout\n    Struct(StructLayout),\n    /// A list layout\n    List(ListLayout),\n    /// A primitive layout\n    Primitive(PrimitiveLayout),\n}\n\nimpl Layout {\n    /// The size of the type in bytes.\n    const fn size(&self) -> usize {\n        match self {\n            Layout::Enum(layout) => layout.size,\n            Layout::Struct(layout) => layout.size,\n            Layout::List(layout) => layout.len * layout.item_layout.size(),\n            Layout::Primitive(layout) => layout.size,\n        }\n    }\n}\n\n/// A trait for types that can be serialized and deserialized in const.\n///\n/// # Safety\n/// The layout must accurately describe the memory layout of the type\npub unsafe trait SerializeConst: Sized {\n    /// The memory layout of the type. This type must have plain old data; no pointers or references.\n    const MEMORY_LAYOUT: Layout;\n    /// Assert that the memory layout of the type is the same as the size of the type\n    const _ASSERT: () = assert!(Self::MEMORY_LAYOUT.size() == std::mem::size_of::<Self>());\n}\n\nmacro_rules! impl_serialize_const {\n    ($type:ty) => {\n        unsafe impl SerializeConst for $type {\n            const MEMORY_LAYOUT: Layout = Layout::Primitive(PrimitiveLayout {\n                size: std::mem::size_of::<$type>(),\n            });\n        }\n    };\n}\n\nimpl_serialize_const!(u8);\nimpl_serialize_const!(u16);\nimpl_serialize_const!(u32);\nimpl_serialize_const!(u64);\nimpl_serialize_const!(i8);\nimpl_serialize_const!(i16);\nimpl_serialize_const!(i32);\nimpl_serialize_const!(i64);\nimpl_serialize_const!(bool);\nimpl_serialize_const!(f32);\nimpl_serialize_const!(f64);\n\nunsafe impl<const N: usize, T: SerializeConst> SerializeConst for [T; N] {\n    const MEMORY_LAYOUT: Layout = Layout::List(ListLayout {\n        len: N,\n        item_layout: &T::MEMORY_LAYOUT,\n    });\n}\n\nmacro_rules! impl_serialize_const_tuple {\n    ($($generic:ident: $generic_number:expr),*) => {\n        impl_serialize_const_tuple!(@impl ($($generic,)*) = $($generic: $generic_number),*);\n    };\n    (@impl $inner:ty = $($generic:ident: $generic_number:expr),*) => {\n        unsafe impl<$($generic: SerializeConst),*> SerializeConst for ($($generic,)*) {\n            const MEMORY_LAYOUT: Layout = {\n                Layout::Struct(StructLayout {\n                    size: std::mem::size_of::<($($generic,)*)>(),\n                    data: &[\n                        $(\n                            StructFieldLayout::new(std::mem::offset_of!($inner, $generic_number), $generic::MEMORY_LAYOUT),\n                        )*\n                    ],\n                })\n            };\n        }\n    };\n}\n\nimpl_serialize_const_tuple!(T1: 0);\nimpl_serialize_const_tuple!(T1: 0, T2: 1);\nimpl_serialize_const_tuple!(T1: 0, T2: 1, T3: 2);\nimpl_serialize_const_tuple!(T1: 0, T2: 1, T3: 2, T4: 3);\nimpl_serialize_const_tuple!(T1: 0, T2: 1, T3: 2, T4: 3, T5: 4);\nimpl_serialize_const_tuple!(T1: 0, T2: 1, T3: 2, T4: 3, T5: 4, T6: 5);\nimpl_serialize_const_tuple!(T1: 0, T2: 1, T3: 2, T4: 3, T5: 4, T6: 5, T7: 6);\nimpl_serialize_const_tuple!(T1: 0, T2: 1, T3: 2, T4: 3, T5: 4, T6: 5, T7: 6, T8: 7);\nimpl_serialize_const_tuple!(T1: 0, T2: 1, T3: 2, T4: 3, T5: 4, T6: 5, T7: 6, T8: 7, T9: 8);\nimpl_serialize_const_tuple!(T1: 0, T2: 1, T3: 2, T4: 3, T5: 4, T6: 5, T7: 6, T8: 7, T9: 8, T10: 9);\n\nconst MAX_STR_SIZE: usize = 256;\n\n/// A string that is stored in a constant sized buffer that can be serialized and deserialized at compile time\n#[derive(PartialEq, PartialOrd, Clone, Copy, Hash)]\n#[cfg_attr(feature = \"serde\", derive(serde::Serialize, serde::Deserialize))]\npub struct ConstStr {\n    #[cfg_attr(feature = \"serde\", serde(with = \"serde_bytes\"))]\n    bytes: [u8; MAX_STR_SIZE],\n    len: u32,\n}\n\n#[cfg(feature = \"serde\")]\nmod serde_bytes {\n    use serde::{Deserialize, Serializer};\n\n    pub fn serialize<S>(bytes: &[u8], serializer: S) -> Result<S::Ok, S::Error>\n    where\n        S: Serializer,\n    {\n        serializer.serialize_bytes(bytes)\n    }\n\n    pub fn deserialize<'de, D>(deserializer: D) -> Result<[u8; super::MAX_STR_SIZE], D::Error>\n    where\n        D: serde::Deserializer<'de>,\n    {\n        let bytes = Vec::<u8>::deserialize(deserializer)?;\n        bytes\n            .try_into()\n            .map_err(|_| serde::de::Error::custom(\"Failed to convert bytes to a fixed size array\"))\n    }\n}\n\nunsafe impl SerializeConst for ConstStr {\n    const MEMORY_LAYOUT: Layout = Layout::Struct(StructLayout {\n        size: std::mem::size_of::<Self>(),\n        data: &[\n            StructFieldLayout::new(\n                std::mem::offset_of!(Self, bytes),\n                Layout::List(ListLayout {\n                    len: MAX_STR_SIZE,\n                    item_layout: &Layout::Primitive(PrimitiveLayout {\n                        size: std::mem::size_of::<u8>(),\n                    }),\n                }),\n            ),\n            StructFieldLayout::new(\n                std::mem::offset_of!(Self, len),\n                Layout::Primitive(PrimitiveLayout {\n                    size: std::mem::size_of::<u32>(),\n                }),\n            ),\n        ],\n    });\n}\n\nimpl ConstStr {\n    /// Create a new constant string\n    pub const fn new(s: &str) -> Self {\n        let str_bytes = s.as_bytes();\n        let mut bytes = [0; MAX_STR_SIZE];\n        let mut i = 0;\n        while i < str_bytes.len() {\n            bytes[i] = str_bytes[i];\n            i += 1;\n        }\n        Self {\n            bytes,\n            len: str_bytes.len() as u32,\n        }\n    }\n\n    /// Get a reference to the string\n    pub const fn as_str(&self) -> &str {\n        let str_bytes = self.bytes.split_at(self.len as usize).0;\n        match std::str::from_utf8(str_bytes) {\n            Ok(s) => s,\n            Err(_) => panic!(\n                \"Invalid utf8; ConstStr should only ever be constructed from valid utf8 strings\"\n            ),\n        }\n    }\n\n    /// Get the length of the string\n    pub const fn len(&self) -> usize {\n        self.len as usize\n    }\n\n    /// Check if the string is empty\n    pub const fn is_empty(&self) -> bool {\n        self.len == 0\n    }\n\n    /// Push a character onto the string\n    pub const fn push(self, byte: char) -> Self {\n        assert!(byte.is_ascii(), \"Only ASCII bytes are supported\");\n        let (bytes, len) = char_to_bytes(byte);\n        let (str, _) = bytes.split_at(len);\n        let Ok(str) = std::str::from_utf8(str) else {\n            panic!(\"Invalid utf8; char_to_bytes should always return valid utf8 bytes\")\n        };\n        self.push_str(str)\n    }\n\n    /// Push a str onto the string\n    pub const fn push_str(self, str: &str) -> Self {\n        let Self { mut bytes, len } = self;\n        assert!(\n            str.len() + len as usize <= MAX_STR_SIZE,\n            \"String is too long\"\n        );\n        let str_bytes = str.as_bytes();\n        let new_len = len as usize + str_bytes.len();\n        let mut i = 0;\n        while i < str_bytes.len() {\n            bytes[len as usize + i] = str_bytes[i];\n            i += 1;\n        }\n        Self {\n            bytes,\n            len: new_len as u32,\n        }\n    }\n\n    /// Split the string at a byte index. The byte index must be a char boundary\n    pub const fn split_at(self, index: usize) -> (Self, Self) {\n        let (left, right) = self.bytes.split_at(index);\n        let left = match std::str::from_utf8(left) {\n            Ok(s) => s,\n            Err(_) => {\n                panic!(\"Invalid utf8; you cannot split at a byte that is not a char boundary\")\n            }\n        };\n        let right = match std::str::from_utf8(right) {\n            Ok(s) => s,\n            Err(_) => {\n                panic!(\"Invalid utf8; you cannot split at a byte that is not a char boundary\")\n            }\n        };\n        (Self::new(left), Self::new(right))\n    }\n\n    /// Split the string at the last occurrence of a character\n    pub const fn rsplit_once(&self, char: char) -> Option<(Self, Self)> {\n        let str = self.as_str();\n        let mut index = str.len() - 1;\n        // First find the bytes we are searching for\n        let (char_bytes, len) = char_to_bytes(char);\n        let (char_bytes, _) = char_bytes.split_at(len);\n        let bytes = str.as_bytes();\n\n        // Then walk backwards from the end of the string\n        loop {\n            let byte = bytes[index];\n            // Look for char boundaries in the string and check if the bytes match\n            if let Some(char_boundary_len) = utf8_char_boundary_to_char_len(byte) {\n                // Split up the string into three sections: [before_char, in_char, after_char]\n                let (before_char, after_index) = bytes.split_at(index);\n                let (in_char, after_char) = after_index.split_at(char_boundary_len as usize);\n                if in_char.len() != char_boundary_len as usize {\n                    panic!(\"in_char.len() should always be equal to char_boundary_len as usize\")\n                }\n                // Check if the bytes for the current char and the target char match\n                let mut in_char_eq = true;\n                let mut i = 0;\n                let min_len = if in_char.len() < char_bytes.len() {\n                    in_char.len()\n                } else {\n                    char_bytes.len()\n                };\n                while i < min_len {\n                    in_char_eq &= in_char[i] == char_bytes[i];\n                    i += 1;\n                }\n                // If they do, convert the bytes to strings and return the split strings\n                if in_char_eq {\n                    let Ok(before_char_str) = std::str::from_utf8(before_char) else {\n                        panic!(\"Invalid utf8; utf8_char_boundary_to_char_len should only return Some when the byte is a character boundary\")\n                    };\n                    let Ok(after_char_str) = std::str::from_utf8(after_char) else {\n                        panic!(\"Invalid utf8; utf8_char_boundary_to_char_len should only return Some when the byte is a character boundary\")\n                    };\n                    return Some((Self::new(before_char_str), Self::new(after_char_str)));\n                }\n            }\n            match index.checked_sub(1) {\n                Some(new_index) => index = new_index,\n                None => return None,\n            }\n        }\n    }\n\n    /// Split the string at the first occurrence of a character\n    pub const fn split_once(&self, char: char) -> Option<(Self, Self)> {\n        let str = self.as_str();\n        let mut index = 0;\n        // First find the bytes we are searching for\n        let (char_bytes, len) = char_to_bytes(char);\n        let (char_bytes, _) = char_bytes.split_at(len);\n        let bytes = str.as_bytes();\n\n        // Then walk forwards from the start of the string\n        while index < bytes.len() {\n            let byte = bytes[index];\n            // Look for char boundaries in the string and check if the bytes match\n            if let Some(char_boundary_len) = utf8_char_boundary_to_char_len(byte) {\n                // Split up the string into three sections: [before_char, in_char, after_char]\n                let (before_char, after_index) = bytes.split_at(index);\n                let (in_char, after_char) = after_index.split_at(char_boundary_len as usize);\n                if in_char.len() != char_boundary_len as usize {\n                    panic!(\"in_char.len() should always be equal to char_boundary_len as usize\")\n                }\n                // Check if the bytes for the current char and the target char match\n                let mut in_char_eq = true;\n                let mut i = 0;\n                let min_len = if in_char.len() < char_bytes.len() {\n                    in_char.len()\n                } else {\n                    char_bytes.len()\n                };\n                while i < min_len {\n                    in_char_eq &= in_char[i] == char_bytes[i];\n                    i += 1;\n                }\n                // If they do, convert the bytes to strings and return the split strings\n                if in_char_eq {\n                    let Ok(before_char_str) = std::str::from_utf8(before_char) else {\n                        panic!(\"Invalid utf8; utf8_char_boundary_to_char_len should only return Some when the byte is a character boundary\")\n                    };\n                    let Ok(after_char_str) = std::str::from_utf8(after_char) else {\n                        panic!(\"Invalid utf8; utf8_char_boundary_to_char_len should only return Some when the byte is a character boundary\")\n                    };\n                    return Some((Self::new(before_char_str), Self::new(after_char_str)));\n                }\n            }\n            index += 1\n        }\n        None\n    }\n}\n\nimpl std::fmt::Debug for ConstStr {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        write!(f, \"{:?}\", self.as_str())\n    }\n}\n\n#[test]\nfn test_rsplit_once() {\n    let str = ConstStr::new(\"hello world\");\n    assert_eq!(\n        str.rsplit_once(' '),\n        Some((ConstStr::new(\"hello\"), ConstStr::new(\"world\")))\n    );\n\n    let unicode_str = ConstStr::new(\"hi\ud83d\ude00hello\ud83d\ude00world\ud83d\ude00world\");\n    assert_eq!(\n        unicode_str.rsplit_once('\ud83d\ude00'),\n        Some((ConstStr::new(\"hi\ud83d\ude00hello\ud83d\ude00world\"), ConstStr::new(\"world\")))\n    );\n    assert_eq!(unicode_str.rsplit_once('\u274c'), None);\n\n    for _ in 0..100 {\n        let random_str: String = (0..rand::random::<u8>() % 50)\n            .map(|_| rand::random::<char>())\n            .collect();\n        let konst = ConstStr::new(&random_str);\n        let mut seen_chars = std::collections::HashSet::new();\n        for char in random_str.chars().rev() {\n            let (char_bytes, len) = char_to_bytes(char);\n            let char_bytes = &char_bytes[..len];\n            assert_eq!(char_bytes, char.to_string().as_bytes());\n            if seen_chars.contains(&char) {\n                continue;\n            }\n            seen_chars.insert(char);\n            let (correct_left, correct_right) = random_str.rsplit_once(char).unwrap();\n            let (left, right) = konst.rsplit_once(char).unwrap();\n            println!(\"splitting {random_str:?} at {char:?}\");\n            assert_eq!(left.as_str(), correct_left);\n            assert_eq!(right.as_str(), correct_right);\n        }\n    }\n}\n\nconst CONTINUED_CHAR_MASK: u8 = 0b10000000;\nconst BYTE_CHAR_BOUNDARIES: [u8; 4] = [0b00000000, 0b11000000, 0b11100000, 0b11110000];\n\n// Const version of https://doc.rust-lang.org/src/core/char/methods.rs.html#1765-1797\nconst fn char_to_bytes(char: char) -> ([u8; 4], usize) {\n    let code = char as u32;\n    let len = char.len_utf8();\n    let mut bytes = [0; 4];\n    match len {\n        1 => {\n            bytes[0] = code as u8;\n        }\n        2 => {\n            bytes[0] = (code >> 6 & 0x1F) as u8 | BYTE_CHAR_BOUNDARIES[1];\n            bytes[1] = (code & 0x3F) as u8 | CONTINUED_CHAR_MASK;\n        }\n        3 => {\n            bytes[0] = (code >> 12 & 0x0F) as u8 | BYTE_CHAR_BOUNDARIES[2];\n            bytes[1] = (code >> 6 & 0x3F) as u8 | CONTINUED_CHAR_MASK;\n            bytes[2] = (code & 0x3F) as u8 | CONTINUED_CHAR_MASK;\n        }\n        4 => {\n            bytes[0] = (code >> 18 & 0x07) as u8 | BYTE_CHAR_BOUNDARIES[3];\n            bytes[1] = (code >> 12 & 0x3F) as u8 | CONTINUED_CHAR_MASK;\n            bytes[2] = (code >> 6 & 0x3F) as u8 | CONTINUED_CHAR_MASK;\n            bytes[3] = (code & 0x3F) as u8 | CONTINUED_CHAR_MASK;\n        }\n        _ => panic!(\n            \"encode_utf8: need more than 4 bytes to encode the unicode character, but the buffer has 4 bytes\"\n        ),\n    };\n    (bytes, len)\n}\n\n#[test]\nfn fuzz_char_to_bytes() {\n    use std::char;\n    for _ in 0..100 {\n        let char = rand::random::<char>();\n        let (bytes, len) = char_to_bytes(char);\n        let str = std::str::from_utf8(&bytes[..len]).unwrap();\n        assert_eq!(char.to_string(), str);\n    }\n}\n\nconst fn utf8_char_boundary_to_char_len(byte: u8) -> Option<u8> {\n    match byte {\n        0b00000000..=0b01111111 => Some(1),\n        0b11000000..=0b11011111 => Some(2),\n        0b11100000..=0b11101111 => Some(3),\n        0b11110000..=0b11111111 => Some(4),\n        _ => None,\n    }\n}\n\n#[test]\nfn fuzz_utf8_byte_to_char_len() {\n    for _ in 0..100 {\n        let random_string: String = (0..rand::random::<u8>())\n            .map(|_| rand::random::<char>())\n            .collect();\n        let bytes = random_string.as_bytes();\n        let chars: std::collections::HashMap<_, _> = random_string.char_indices().collect();\n        for (i, byte) in bytes.iter().enumerate() {\n            match utf8_char_boundary_to_char_len(*byte) {\n                Some(char_len) => {\n                    let char = chars\n                        .get(&i)\n                        .unwrap_or_else(|| panic!(\"{byte:b} is not a character boundary\"));\n                    assert_eq!(char.len_utf8(), char_len as usize);\n                }\n                None => {\n                    assert!(!chars.contains_key(&i), \"{byte:b} is a character boundary\");\n                }\n            }\n        }\n    }\n}\n\n/// Serialize a struct that is stored at the pointer passed in\nconst fn serialize_const_struct(\n    ptr: *const (),\n    mut to: ConstVec<u8>,\n    layout: &StructLayout,\n) -> ConstVec<u8> {\n    let mut i = 0;\n    while i < layout.data.len() {\n        // Serialize the field at the offset pointer in the struct\n        let StructFieldLayout { offset, layout } = &layout.data[i];\n        let field = unsafe { ptr.byte_add(*offset) };\n        to = serialize_const_ptr(field, to, layout);\n        i += 1;\n    }\n    to\n}\n\n/// Serialize an enum that is stored at the pointer passed in\nconst fn serialize_const_enum(\n    ptr: *const (),\n    mut to: ConstVec<u8>,\n    layout: &EnumLayout,\n) -> ConstVec<u8> {\n    let mut discriminant = 0;\n\n    let byte_ptr = ptr as *const u8;\n    let mut offset = 0;\n    while offset < layout.discriminant.size {\n        // If the bytes are reversed, walk backwards from the end of the number when pushing bytes\n        let byte = if cfg!(target_endian = \"big\") {\n            unsafe {\n                byte_ptr\n                    .byte_add(layout.discriminant.size - offset - 1)\n                    .read()\n            }\n        } else {\n            unsafe { byte_ptr.byte_add(offset).read() }\n        };\n        to = to.push(byte);\n        discriminant |= (byte as u32) << (offset * 8);\n        offset += 1;\n    }\n\n    let mut i = 0;\n    while i < layout.variants.len() {\n        // If the variant is the discriminated one, serialize it\n        let EnumVariant { tag, data, .. } = &layout.variants[i];\n        if discriminant == *tag {\n            let data_ptr = unsafe { ptr.byte_add(layout.variants_offset) };\n            to = serialize_const_struct(data_ptr, to, data);\n            break;\n        }\n        i += 1;\n    }\n    to\n}\n\n/// Serialize a primitive type that is stored at the pointer passed in\nconst fn serialize_const_primitive(\n    ptr: *const (),\n    mut to: ConstVec<u8>,\n    layout: &PrimitiveLayout,\n) -> ConstVec<u8> {\n    let ptr = ptr as *const u8;\n    let mut offset = 0;\n    while offset < layout.size {\n        // If the bytes are reversed, walk backwards from the end of the number when pushing bytes\n        if cfg!(any(target_endian = \"big\", feature = \"test-big-endian\")) {\n            to = to.push(unsafe { ptr.byte_add(layout.size - offset - 1).read() });\n        } else {\n            to = to.push(unsafe { ptr.byte_add(offset).read() });\n        }\n        offset += 1;\n    }\n    to\n}\n\n/// Serialize a constant sized array that is stored at the pointer passed in\nconst fn serialize_const_list(\n    ptr: *const (),\n    mut to: ConstVec<u8>,\n    layout: &ListLayout,\n) -> ConstVec<u8> {\n    let len = layout.len;\n    let mut i = 0;\n    while i < len {\n        let field = unsafe { ptr.byte_add(i * layout.item_layout.size()) };\n        to = serialize_const_ptr(field, to, layout.item_layout);\n        i += 1;\n    }\n    to\n}\n\n/// Serialize a pointer to a type that is stored at the pointer passed in\nconst fn serialize_const_ptr(ptr: *const (), to: ConstVec<u8>, layout: &Layout) -> ConstVec<u8> {\n    match layout {\n        Layout::Enum(layout) => serialize_const_enum(ptr, to, layout),\n        Layout::Struct(layout) => serialize_const_struct(ptr, to, layout),\n        Layout::List(layout) => serialize_const_list(ptr, to, layout),\n        Layout::Primitive(layout) => serialize_const_primitive(ptr, to, layout),\n    }\n}\n\n/// Serialize a type into a buffer\n///\n/// # Example\n///\n/// ```rust\n/// use const_serialize::{ConstVec, SerializeConst, serialize_const};\n///\n/// #[derive(Clone, Copy, Debug, PartialEq, SerializeConst)]\n/// struct Struct {\n///     a: u32,\n///     b: u8,\n///     c: u32,\n/// }\n///\n/// let mut buffer = ConstVec::new();\n/// buffer = serialize_const(&Struct {\n///     a: 0x11111111,\n///     b: 0x22,\n///     c: 0x33333333,\n/// }, buffer);\n/// let buf = buffer.read();\n/// assert_eq!(buf.as_ref(), &[0x11, 0x11, 0x11, 0x11, 0x22, 0x33, 0x33, 0x33, 0x33]);\n/// ```\n#[must_use = \"The data is serialized into the returned buffer\"]\npub const fn serialize_const<T: SerializeConst>(data: &T, to: ConstVec<u8>) -> ConstVec<u8> {\n    let ptr = data as *const T as *const ();\n    serialize_const_ptr(ptr, to, &T::MEMORY_LAYOUT)\n}\n\n/// Deserialize a primitive type into the out buffer at the offset passed in. Returns a new version of the buffer with the data added.\nconst fn deserialize_const_primitive<'a, const N: usize>(\n    mut from: ConstReadBuffer<'a>,\n    layout: &PrimitiveLayout,\n    out: (usize, [MaybeUninit<u8>; N]),\n) -> Option<(ConstReadBuffer<'a>, [MaybeUninit<u8>; N])> {\n    let (start, mut out) = out;\n    let mut offset = 0;\n    while offset < layout.size {\n        // If the bytes are reversed, walk backwards from the end of the number when filling in bytes\n        let (from_new, value) = match from.get() {\n            Some(data) => data,\n            None => return None,\n        };\n        from = from_new;\n        if cfg!(any(target_endian = \"big\", feature = \"test-big-endian\")) {\n            out[start + layout.size - offset - 1] = MaybeUninit::new(value);\n        } else {\n            out[start + offset] = MaybeUninit::new(value);\n        }\n        offset += 1;\n    }\n    Some((from, out))\n}\n\n/// Deserialize a struct type into the out buffer at the offset passed in. Returns a new version of the buffer with the data added.\nconst fn deserialize_const_struct<'a, const N: usize>(\n    mut from: ConstReadBuffer<'a>,\n    layout: &StructLayout,\n    out: (usize, [MaybeUninit<u8>; N]),\n) -> Option<(ConstReadBuffer<'a>, [MaybeUninit<u8>; N])> {\n    let (start, mut out) = out;\n    let mut i = 0;\n    while i < layout.data.len() {\n        // Deserialize the field at the offset pointer in the struct\n        let StructFieldLayout { offset, layout } = &layout.data[i];\n        let (new_from, new_out) = match deserialize_const_ptr(from, layout, (start + *offset, out))\n        {\n            Some(data) => data,\n            None => return None,\n        };\n        from = new_from;\n        out = new_out;\n        i += 1;\n    }\n    Some((from, out))\n}\n\n/// Deserialize an enum type into the out buffer at the offset passed in. Returns a new version of the buffer with the data added.\nconst fn deserialize_const_enum<'a, const N: usize>(\n    mut from: ConstReadBuffer<'a>,\n    layout: &EnumLayout,\n    out: (usize, [MaybeUninit<u8>; N]),\n) -> Option<(ConstReadBuffer<'a>, [MaybeUninit<u8>; N])> {\n    let (start, mut out) = out;\n    let mut discriminant = 0;\n\n    // First, deserialize the discriminant\n    let mut offset = 0;\n    while offset < layout.discriminant.size {\n        // If the bytes are reversed, walk backwards from the end of the number when filling in bytes\n        let (from_new, value) = match from.get() {\n            Some(data) => data,\n            None => return None,\n        };\n        from = from_new;\n        if cfg!(target_endian = \"big\") {\n            out[start + layout.size - offset - 1] = MaybeUninit::new(value);\n            discriminant |= (value as u32) << ((layout.discriminant.size - offset - 1) * 8);\n        } else {\n            out[start + offset] = MaybeUninit::new(value);\n            discriminant |= (value as u32) << (offset * 8);\n        }\n        offset += 1;\n    }\n\n    // Then, deserialize the variant\n    let mut i = 0;\n    let mut matched_variant = false;\n    while i < layout.variants.len() {\n        // If the variant is the discriminated one, deserialize it\n        let EnumVariant { tag, data, .. } = &layout.variants[i];\n        if discriminant == *tag {\n            let offset = layout.variants_offset;\n            let (new_from, new_out) =\n                match deserialize_const_struct(from, data, (start + offset, out)) {\n                    Some(data) => data,\n                    None => return None,\n                };\n            from = new_from;\n            out = new_out;\n            matched_variant = true;\n            break;\n        }\n        i += 1;\n    }\n    if !matched_variant {\n        return None;\n    }\n\n    Some((from, out))\n}\n\n/// Deserialize a list type into the out buffer at the offset passed in. Returns a new version of the buffer with the data added.\nconst fn deserialize_const_list<'a, const N: usize>(\n    mut from: ConstReadBuffer<'a>,\n    layout: &ListLayout,\n    out: (usize, [MaybeUninit<u8>; N]),\n) -> Option<(ConstReadBuffer<'a>, [MaybeUninit<u8>; N])> {\n    let (start, mut out) = out;\n    let len = layout.len;\n    let item_layout = layout.item_layout;\n    let mut i = 0;\n    while i < len {\n        let (new_from, new_out) =\n            match deserialize_const_ptr(from, item_layout, (start + i * item_layout.size(), out)) {\n                Some(data) => data,\n                None => return None,\n            };\n        from = new_from;\n        out = new_out;\n        i += 1;\n    }\n    Some((from, out))\n}\n\n/// Deserialize a type into the out buffer at the offset passed in. Returns a new version of the buffer with the data added.\nconst fn deserialize_const_ptr<'a, const N: usize>(\n    from: ConstReadBuffer<'a>,\n    layout: &Layout,\n    out: (usize, [MaybeUninit<u8>; N]),\n) -> Option<(ConstReadBuffer<'a>, [MaybeUninit<u8>; N])> {\n    match layout {\n        Layout::Enum(layout) => deserialize_const_enum(from, layout, out),\n        Layout::Struct(layout) => deserialize_const_struct(from, layout, out),\n        Layout::List(layout) => deserialize_const_list(from, layout, out),\n        Layout::Primitive(layout) => deserialize_const_primitive(from, layout, out),\n    }\n}\n\n/// Deserialize a type into the output buffer. Accepts (Type, ConstVec<u8>) as input and returns Option<(ConstReadBuffer, Instance of type)>\n///\n/// # Example\n/// ```rust\n/// # use const_serialize::{deserialize_const, serialize_const, ConstVec, SerializeConst};\n/// #[derive(Clone, Copy, Debug, PartialEq, SerializeConst)]\n/// struct Struct {\n///     a: u32,\n///     b: u8,\n///     c: u32,\n///     d: u32,\n/// }\n///\n/// let mut buffer = ConstVec::new();\n/// buffer = serialize_const(&Struct {\n///     a: 0x11111111,\n///     b: 0x22,\n///     c: 0x33333333,\n///     d: 0x44444444,\n/// }, buffer);\n/// let buf = buffer.read();\n/// assert_eq!(deserialize_const!(Struct, buf).unwrap().1, Struct {\n///     a: 0x11111111,\n///     b: 0x22,\n///     c: 0x33333333,\n///     d: 0x44444444,\n/// });\n/// ```\n#[macro_export]\nmacro_rules! deserialize_const {\n    ($type:ty, $buffer:expr) => {\n        unsafe {\n            const __SIZE: usize = std::mem::size_of::<$type>();\n            $crate::deserialize_const_raw::<__SIZE, $type>($buffer)\n        }\n    };\n}\n\n/// Deserialize a buffer into a type. This will return None if the buffer doesn't have enough data to fill the type.\n/// # Safety\n/// N must be `std::mem::size_of::<T>()`\n#[must_use = \"The data is deserialized from the input buffer\"]\npub const unsafe fn deserialize_const_raw<const N: usize, T: SerializeConst>(\n    from: ConstReadBuffer,\n) -> Option<(ConstReadBuffer, T)> {\n    // Create uninitized memory with the size of the type\n    let out = [MaybeUninit::uninit(); N];\n    // Fill in the bytes into the buffer for the type\n    let (from, out) = match deserialize_const_ptr(from, &T::MEMORY_LAYOUT, (0, out)) {\n        Some(data) => data,\n        None => return None,\n    };\n    // Now that the memory is filled in, transmute it into the type\n    Some((from, unsafe {\n        std::mem::transmute_copy::<[MaybeUninit<u8>; N], T>(&out)\n    }))\n}\n\n/// Check if the serialized representation of two items are the same\npub const fn serialize_eq<T: SerializeConst>(first: &T, second: &T) -> bool {\n    let first_serialized = ConstVec::<u8>::new();\n    let first_serialized = serialize_const(first, first_serialized);\n    let second_serialized = ConstVec::<u8>::new();\n    let second_serialized = serialize_const(second, second_serialized);\n    let first_buf = first_serialized.as_ref();\n    let second_buf = second_serialized.as_ref();\n    if first_buf.len() != second_buf.len() {\n        return false;\n    }\n    let mut i = 0;\n    while i < first_buf.len() {\n        if first_buf[i] != second_buf[i] {\n            return false;\n        }\n        i += 1;\n    }\n    true\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "3097d6e865bf86192cd3425b29002dde735c5505",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/packages/check/src/issues.rs",
    "func": "use owo_colors::{\n    colors::{css::LightBlue, BrightRed},\n    OwoColorize, Stream,\n};\nuse std::{\n    fmt::Display,\n    path::{Path, PathBuf},\n};\n\nuse crate::metadata::{\n    AnyLoopInfo, AsyncInfo, ClosureInfo, ConditionalInfo, ForInfo, HookInfo, IfInfo, MatchInfo,\n    WhileInfo,\n};\n\n/// The result of checking a Dioxus file for issues.\npub struct IssueReport {\n    pub path: PathBuf,\n    pub crate_root: PathBuf,\n    pub file_content: String,\n    pub issues: Vec<Issue>,\n}\n\nimpl IssueReport {\n    pub fn new<S: ToString>(\n        path: PathBuf,\n        crate_root: PathBuf,\n        file_content: S,\n        issues: Vec<Issue>,\n    ) -> Self {\n        Self {\n            path,\n            crate_root,\n            file_content: file_content.to_string(),\n            issues,\n        }\n    }\n}\n\nfn lightblue(text: &str) -> String {\n    text.if_supports_color(Stream::Stderr, |text| text.fg::<LightBlue>())\n        .to_string()\n}\n\nfn brightred(text: &str) -> String {\n    text.if_supports_color(Stream::Stderr, |text| text.fg::<BrightRed>())\n        .to_string()\n}\n\nfn bold(text: &str) -> String {\n    text.if_supports_color(Stream::Stderr, |text| text.bold())\n        .to_string()\n}\n\nimpl Display for IssueReport {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        let relative_file = Path::new(&self.path)\n            .strip_prefix(&self.crate_root)\n            .unwrap_or(Path::new(&self.path))\n            .display();\n\n        let pipe_char = lightblue(\"|\");\n\n        for (i, issue) in self.issues.iter().enumerate() {\n            let hook_info = issue.hook_info();\n            let hook_span = hook_info.span;\n            let hook_name_span = hook_info.name_span;\n            let error_line = format!(\"{}: {}\", brightred(\"error\"), issue);\n            writeln!(f, \"{}\", bold(&error_line))?;\n            writeln!(\n                f,\n                \"  {} {}:{}:{}\",\n                lightblue(\"-->\"),\n                relative_file,\n                hook_span.start.line,\n                hook_span.start.column + 1\n            )?;\n            let max_line_num_len = hook_span.end.line.to_string().len();\n            writeln!(f, \"{:>max_line_num_len$} {}\", \"\", pipe_char)?;\n            for (i, line) in self.file_content.lines().enumerate() {\n                let line_num = i + 1;\n                if line_num >= hook_span.start.line && line_num <= hook_span.end.line {\n                    writeln!(\n                        f,\n                        \"{:>max_line_num_len$} {} {}\",\n                        lightblue(&line_num.to_string()),\n                        pipe_char,\n                        line,\n                    )?;\n                    if line_num == hook_span.start.line {\n                        let mut caret = String::new();\n                        for _ in 0..hook_name_span.start.column {\n                            caret.push(' ');\n                        }\n                        for _ in hook_name_span.start.column..hook_name_span.end.column {\n                            caret.push('^');\n                        }\n                        writeln!(\n                            f,\n                            \"{:>max_line_num_len$} {} {}\",\n                            \"\",\n                            pipe_char,\n                            brightred(&caret),\n                        )?;\n                    }\n                }\n            }\n\n            let note_text_prefix = format!(\n                \"{:>max_line_num_len$} {}\\n{:>max_line_num_len$} {} note:\",\n                \"\",\n                pipe_char,\n                \"\",\n                lightblue(\"=\")\n            );\n\n            match issue {\n                Issue::HookInsideConditional(\n                    _,\n                    ConditionalInfo::If(IfInfo { span: _, head_span }),\n                )\n                | Issue::HookInsideConditional(\n                    _,\n                    ConditionalInfo::Match(MatchInfo { span: _, head_span }),\n                ) => {\n                    if let Some(source_text) = &head_span.source_text {\n                        writeln!(\n                            f,\n                            \"{} `{} {{ \u2026 }}` is the conditional\",\n                            note_text_prefix, source_text,\n                        )?;\n                    }\n                }\n                Issue::HookInsideLoop(_, AnyLoopInfo::For(ForInfo { span: _, head_span }))\n                | Issue::HookInsideLoop(_, AnyLoopInfo::While(WhileInfo { span: _, head_span })) => {\n                    if let Some(source_text) = &head_span.source_text {\n                        writeln!(\n                            f,\n                            \"{} `{} {{ \u2026 }}` is the loop\",\n                            note_text_prefix, source_text,\n                        )?;\n                    }\n                }\n                Issue::HookInsideLoop(_, AnyLoopInfo::Loop(_)) => {\n                    writeln!(f, \"{} `loop {{ \u2026 }}` is the loop\", note_text_prefix,)?;\n                }\n                Issue::HookOutsideComponent(_)\n                | Issue::HookInsideClosure(_, _)\n                | Issue::HookInsideAsync(_, _) => {}\n            }\n\n            if i < self.issues.len() - 1 {\n                writeln!(f)?;\n            }\n        }\n\n        Ok(())\n    }\n}\n\n#[derive(Debug, Clone, PartialEq, Eq)]\n#[non_exhaustive]\n#[allow(clippy::enum_variant_names)] // we'll add non-hook ones in the future\n/// Issues that might be found via static analysis of a Dioxus file.\npub enum Issue {\n    /// <https://dioxuslabs.com/learn/0.6/reference/hooks#no-hooks-in-conditionals>\n    HookInsideConditional(HookInfo, ConditionalInfo),\n    /// <https://dioxuslabs.com/learn/0.6/reference/hooks#no-hooks-in-loops>\n    HookInsideLoop(HookInfo, AnyLoopInfo),\n    /// <https://dioxuslabs.com/learn/0.6/reference/hooks#no-hooks-in-closures>\n    HookInsideClosure(HookInfo, ClosureInfo),\n    HookInsideAsync(HookInfo, AsyncInfo),\n    HookOutsideComponent(HookInfo),\n}\n\nimpl Issue {\n    pub fn hook_info(&self) -> HookInfo {\n        match self {\n            Issue::HookInsideConditional(hook_info, _)\n            | Issue::HookInsideLoop(hook_info, _)\n            | Issue::HookInsideClosure(hook_info, _)\n            | Issue::HookInsideAsync(hook_info, _)\n            | Issue::HookOutsideComponent(hook_info) => hook_info.clone(),\n        }\n    }\n}\n\nimpl std::fmt::Display for Issue {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            Issue::HookInsideConditional(hook_info, conditional_info) => {\n                write!(\n                    f,\n                    \"hook called conditionally: `{}` (inside `{}`)\",\n                    hook_info.name,\n                    match conditional_info {\n                        ConditionalInfo::If(_) => \"if\",\n                        ConditionalInfo::Match(_) => \"match\",\n                    }\n                )\n            }\n            Issue::HookInsideLoop(hook_info, loop_info) => {\n                write!(\n                    f,\n                    \"hook called in a loop: `{}` (inside {})\",\n                    hook_info.name,\n                    match loop_info {\n                        AnyLoopInfo::For(_) => \"`for` loop\",\n                        AnyLoopInfo::While(_) => \"`while` loop\",\n                        AnyLoopInfo::Loop(_) => \"`loop`\",\n                    }\n                )\n            }\n            Issue::HookInsideClosure(hook_info, _) => {\n                write!(f, \"hook called in a closure: `{}`\", hook_info.name)\n            }\n            Issue::HookInsideAsync(hook_info, _) => {\n                write!(f, \"hook called in an async block: `{}`\", hook_info.name)\n            }\n            Issue::HookOutsideComponent(hook_info) => {\n                write!(\n                    f,\n                    \"hook called outside component or hook: `{}`\",\n                    hook_info.name\n                )\n            }\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use crate::check_file;\n    use indoc::indoc;\n    use pretty_assertions::assert_eq;\n\n    #[test]\n    fn test_issue_report_display_conditional_if() {\n        owo_colors::set_override(false);\n        let issue_report = check_file(\n            \"src/main.rs\".into(),\n            indoc! {r#\"\n                fn App() -> Element {\n                    if you_are_happy && you_know_it {\n                        let something = use_signal(|| \"hands\");\n                        println!(\"clap your {something}\")\n                    }\n                }\n            \"#},\n        );\n\n        let expected = indoc! {r#\"\n            error: hook called conditionally: `use_signal` (inside `if`)\n              --> src/main.rs:3:25\n              |\n            3 |         let something = use_signal(|| \"hands\");\n              |                         ^^^^^^^^^^\n              |\n              = note: `if you_are_happy && you_know_it { \u2026 }` is the conditional\n        \"#};\n\n        assert_eq!(expected, issue_report.to_string());\n    }\n\n    #[test]\n    fn test_issue_report_display_conditional_match() {\n        owo_colors::set_override(false);\n        let issue_report = check_file(\n            \"src/main.rs\".into(),\n            indoc! {r#\"\n                fn App() -> Element {\n                    match you_are_happy && you_know_it {\n                        true => {\n                            let something = use_signal(|| \"hands\");\n                            println!(\"clap your {something}\")\n                        }\n                        _ => {}\n                    }\n                }\n            \"#},\n        );\n\n        let expected = indoc! {r#\"\n            error: hook called conditionally: `use_signal` (inside `match`)\n              --> src/main.rs:4:29\n              |\n            4 |             let something = use_signal(|| \"hands\");\n              |                             ^^^^^^^^^^\n              |\n              = note: `match you_are_happy && you_know_it { \u2026 }` is the conditional\n        \"#};\n\n        assert_eq!(expected, issue_report.to_string());\n    }\n\n    #[test]\n    fn test_issue_report_display_for_loop() {\n        owo_colors::set_override(false);\n        let issue_report = check_file(\n            \"src/main.rs\".into(),\n            indoc! {r#\"\n                fn App() -> Element {\n                    for i in 0..10 {\n                        let something = use_signal(|| \"hands\");\n                        println!(\"clap your {something}\")\n                    }\n                }\n            \"#},\n        );\n\n        let expected = indoc! {r#\"\n            error: hook called in a loop: `use_signal` (inside `for` loop)\n              --> src/main.rs:3:25\n              |\n            3 |         let something = use_signal(|| \"hands\");\n              |                         ^^^^^^^^^^\n              |\n              = note: `for i in 0..10 { \u2026 }` is the loop\n        \"#};\n\n        assert_eq!(expected, issue_report.to_string());\n    }\n\n    #[test]\n    fn test_issue_report_display_while_loop() {\n        owo_colors::set_override(false);\n        let issue_report = check_file(\n            \"src/main.rs\".into(),\n            indoc! {r#\"\n                fn App() -> Element {\n                    while check_thing() {\n                        let something = use_signal(|| \"hands\");\n                        println!(\"clap your {something}\")\n                    }\n                }\n            \"#},\n        );\n\n        let expected = indoc! {r#\"\n            error: hook called in a loop: `use_signal` (inside `while` loop)\n              --> src/main.rs:3:25\n              |\n            3 |         let something = use_signal(|| \"hands\");\n              |                         ^^^^^^^^^^\n              |\n              = note: `while check_thing() { \u2026 }` is the loop\n        \"#};\n\n        assert_eq!(expected, issue_report.to_string());\n    }\n\n    #[test]\n    fn test_issue_report_display_loop() {\n        owo_colors::set_override(false);\n        let issue_report = check_file(\n            \"src/main.rs\".into(),\n            indoc! {r#\"\n                fn App() -> Element {\n                    loop {\n                        let something = use_signal(|| \"hands\");\n                        println!(\"clap your {something}\")\n                    }\n                }\n            \"#},\n        );\n\n        let expected = indoc! {r#\"\n            error: hook called in a loop: `use_signal` (inside `loop`)\n              --> src/main.rs:3:25\n              |\n            3 |         let something = use_signal(|| \"hands\");\n              |                         ^^^^^^^^^^\n              |\n              = note: `loop { \u2026 }` is the loop\n        \"#};\n\n        assert_eq!(expected, issue_report.to_string());\n    }\n\n    #[test]\n    fn test_issue_report_display_closure() {\n        owo_colors::set_override(false);\n        let issue_report = check_file(\n            \"src/main.rs\".into(),\n            indoc! {r#\"\n                fn App() -> Element {\n                    let something = || {\n                        let something = use_signal(|| \"hands\");\n                        println!(\"clap your {something}\")\n                    };\n                }\n            \"#},\n        );\n\n        let expected = indoc! {r#\"\n            error: hook called in a closure: `use_signal`\n              --> src/main.rs:3:25\n              |\n            3 |         let something = use_signal(|| \"hands\");\n              |                         ^^^^^^^^^^\n        \"#};\n\n        assert_eq!(expected, issue_report.to_string());\n    }\n\n    #[test]\n    fn test_issue_report_display_multiline_hook() {\n        owo_colors::set_override(false);\n        let issue_report = check_file(\n            \"src/main.rs\".into(),\n            indoc! {r#\"\n                fn App() -> Element {\n                    if you_are_happy && you_know_it {\n                        let something = use_signal(|| {\n                            \"hands\"\n                        });\n                        println!(\"clap your {something}\")\n                    }\n                }\n            \"#},\n        );\n\n        let expected = indoc! {r#\"\n            error: hook called conditionally: `use_signal` (inside `if`)\n              --> src/main.rs:3:25\n              |\n            3 |         let something = use_signal(|| {\n              |                         ^^^^^^^^^^\n            4 |             \"hands\"\n            5 |         });\n              |\n              = note: `if you_are_happy && you_know_it { \u2026 }` is the conditional\n        \"#};\n\n        assert_eq!(expected, issue_report.to_string());\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "7c1d93115e27e3219dee80589a7cbaebf08e503b",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/packages/document/src/eval.rs",
    "func": "#![doc = include_str!(\"../docs/eval.md\")]\n\nuse crate::error::EvalError;\nuse generational_box::GenerationalBox;\nuse std::future::{poll_fn, Future, IntoFuture};\nuse std::pin::Pin;\nuse std::task::{Context, Poll};\n\n#[doc = include_str!(\"../docs/eval.md\")]\npub struct Eval {\n    evaluator: GenerationalBox<Box<dyn Evaluator>>,\n}\n\nimpl Eval {\n    /// Create this eval from a dynamic evaluator\n    pub fn new(evaluator: GenerationalBox<Box<dyn Evaluator + 'static>>) -> Self {\n        Self { evaluator }\n    }\n\n    /// Wait until the javascript task is finished and return the result\n    pub async fn join<T: serde::de::DeserializeOwned>(self) -> Result<T, EvalError> {\n        let json_value = poll_fn(|cx| match self.evaluator.try_write() {\n            Ok(mut evaluator) => evaluator.poll_join(cx),\n            Err(_) => Poll::Ready(Err(EvalError::Finished)),\n        })\n        .await?;\n        serde_json::from_value(json_value).map_err(EvalError::Serialization)\n    }\n\n    /// Send a message to the javascript task\n    pub fn send(&self, data: impl serde::Serialize) -> Result<(), EvalError> {\n        match self.evaluator.try_read() {\n            Ok(evaluator) => {\n                evaluator.send(serde_json::to_value(data).map_err(EvalError::Serialization)?)\n            }\n            Err(_) => Err(EvalError::Finished),\n        }\n    }\n\n    /// Receive a message from the javascript task\n    pub async fn recv<T: serde::de::DeserializeOwned>(&mut self) -> Result<T, EvalError> {\n        let json_value = poll_fn(|cx| match self.evaluator.try_write() {\n            Ok(mut evaluator) => evaluator.poll_recv(cx),\n            Err(_) => Poll::Ready(Err(EvalError::Finished)),\n        })\n        .await?;\n        serde_json::from_value(json_value).map_err(EvalError::Serialization)\n    }\n}\n\nimpl IntoFuture for Eval {\n    type Output = Result<serde_json::Value, EvalError>;\n    type IntoFuture = Pin<Box<dyn Future<Output = Self::Output>>>;\n\n    fn into_future(self) -> Self::IntoFuture {\n        Box::pin(self.join().into_future())\n    }\n}\n\n/// The platform's evaluator.\npub trait Evaluator {\n    /// Sends a message to the evaluated JavaScript.\n    fn send(&self, data: serde_json::Value) -> Result<(), EvalError>;\n    /// Receive any queued messages from the evaluated JavaScript.\n    fn poll_recv(\n        &mut self,\n        context: &mut Context<'_>,\n    ) -> Poll<Result<serde_json::Value, EvalError>>;\n    /// Gets the return value of the JavaScript\n    fn poll_join(\n        &mut self,\n        context: &mut Context<'_>,\n    ) -> Poll<Result<serde_json::Value, EvalError>>;\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "ae0755c3a9b34674c625051a3995c0733947cc98",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/packages/core-macro/tests/values_memoize_in_place.rs",
    "func": "use dioxus::prelude::*;\nuse dioxus_core::ElementId;\nuse std::{any::Any, rc::Rc};\n\n#[tokio::test]\nasync fn values_memoize_in_place() {\n    thread_local! {\n        static DROP_COUNT: std::cell::RefCell<usize> = const { std::cell::RefCell::new(0) };\n    }\n\n    struct CountsDrop;\n\n    impl Drop for CountsDrop {\n        fn drop(&mut self) {\n            DROP_COUNT.with(|c| *c.borrow_mut() += 1);\n        }\n    }\n\n    fn app() -> Element {\n        let mut count = use_signal(|| 0);\n        let x = CountsDrop;\n\n        use_hook(|| {\n            spawn(async move {\n                for _ in 0..15 {\n                    tokio::time::sleep(std::time::Duration::from_millis(1)).await;\n                    count += 1;\n                }\n            });\n        });\n\n        rsx! {\n            TakesEventHandler {\n                click: move |num| {\n                    // Force the closure to own the drop counter\n                    let _ = &x;\n                    println!(\"num is {num}\");\n                },\n                number: count() / 2\n            }\n            TakesSignal { sig: count(), number: count() / 2 }\n        }\n    }\n\n    set_event_converter(Box::new(dioxus::html::SerializedHtmlEventConverter));\n    let mut dom = VirtualDom::new(app);\n\n    let mutations = dom.rebuild_to_vec();\n    println!(\"{:#?}\", mutations);\n    dom.mark_dirty(ScopeId::APP);\n    for _ in 0..40 {\n        let event = Event::new(\n            Rc::new(PlatformEventData::new(Box::<SerializedMouseData>::default())) as Rc<dyn Any>,\n            true,\n        );\n        dom.runtime().handle_event(\"click\", event, ElementId(1));\n        tokio::select! {\n            _ = tokio::time::sleep(std::time::Duration::from_millis(20)) => {},\n            _ = dom.wait_for_work() => {}\n        }\n        dom.render_immediate(&mut dioxus_core::NoOpMutations);\n    }\n    dom.render_immediate(&mut dioxus_core::NoOpMutations);\n    // As we rerun the app, the drop count should be 15 one for each render of the app component\n    let drop_count = DROP_COUNT.with(|c| *c.borrow());\n    assert_eq!(drop_count, 16);\n}\n\n// We move over event handlers in place. Make sure we do that in a way that doesn't destroy the original event handler\n#[test]\nfn cloning_event_handler_components_work() {\n    fn app() -> Element {\n        let rsx_with_event_handler_component = rsx! {\n            TakesEventHandler {\n                click: move |evt| {\n                    println!(\"Clicked {evt:?}!\");\n                },\n                number: 0\n            }\n        };\n\n        rsx! {\n            {rsx_with_event_handler_component.clone()}\n            {rsx_with_event_handler_component.clone()}\n            {rsx_with_event_handler_component.clone()}\n            {rsx_with_event_handler_component}\n        }\n    }\n\n    set_event_converter(Box::new(dioxus::html::SerializedHtmlEventConverter));\n    let mut dom = VirtualDom::new(app);\n\n    let mutations = dom.rebuild_to_vec();\n    println!(\"{:#?}\", mutations);\n    dom.mark_dirty(ScopeId::APP);\n    for _ in 0..20 {\n        let event = Event::new(\n            Rc::new(PlatformEventData::new(Box::<SerializedMouseData>::default())) as Rc<dyn Any>,\n            true,\n        );\n        dom.runtime().handle_event(\"click\", event, ElementId(1));\n        dom.render_immediate(&mut dioxus_core::NoOpMutations);\n    }\n    dom.render_immediate(&mut dioxus_core::NoOpMutations);\n}\n\n#[component]\nfn TakesEventHandler(click: EventHandler<usize>, number: usize) -> Element {\n    let first_render_click = use_hook(move || click);\n    if generation() > 0 {\n        // Make sure the event handler is memoized in place and never gets dropped\n        first_render_click(number);\n    }\n\n    rsx! {\n        button {\n            onclick: move |_| click(number),\n            \"{number}\"\n        }\n    }\n}\n\n#[component]\nfn TakesSignal(sig: ReadOnlySignal<usize>, number: usize) -> Element {\n    let first_render_sig = use_hook(move || sig);\n    if generation() > 0 {\n        // Make sure the signal is memoized in place and never gets dropped\n        println!(\"{first_render_sig}\");\n    }\n\n    rsx! {\n        button { \"{number}\" }\n    }\n}\n\n// Regression test for https://github.com/DioxusLabs/dioxus/issues/2582\n#[test]\nfn spreads_memorize_in_place() {\n    #[derive(Props, Clone, PartialEq)]\n    struct CompProps {\n        #[props(extends = GlobalAttributes)]\n        attributes: Vec<Attribute>,\n    }\n\n    let mut props = CompProps::builder().build();\n    assert!(!props.memoize(&CompProps::builder().all(\"123\").build()));\n    assert_eq!(\n        props.attributes,\n        vec![Attribute::new(\"all\", \"123\", Some(\"style\"), false)]\n    );\n\n    assert!(!props.memoize(&CompProps::builder().width(\"123\").build()));\n    assert_eq!(\n        props.attributes,\n        vec![Attribute::new(\"width\", \"123\", Some(\"style\"), false)]\n    );\n\n    assert!(!props.memoize(&CompProps::builder().build()));\n    assert_eq!(props.attributes, vec![]);\n\n    assert!(props.memoize(&CompProps::builder().build()));\n    assert_eq!(props.attributes, vec![]);\n}\n\n// Regression test for https://github.com/DioxusLabs/dioxus/issues/2331\n#[test]\nfn cloning_read_only_signal_components_work() {\n    fn app() -> Element {\n        if generation() < 5 {\n            println!(\"Generating new props\");\n            needs_update();\n        }\n\n        let read_only_signal_rsx = rsx! {\n            TakesReadOnlySignalNonClone { sig: NonCloneable(generation() as i32) }\n            TakesReadOnlySignalNum { sig: generation() as i32 }\n        };\n\n        rsx! {\n            {read_only_signal_rsx.clone()}\n            {read_only_signal_rsx}\n        }\n    }\n\n    struct NonCloneable<T>(T);\n\n    #[component]\n    fn TakesReadOnlySignalNum(sig: ReadOnlySignal<i32>) -> Element {\n        rsx! {}\n    }\n\n    #[component]\n    fn TakesReadOnlySignalNonClone(sig: ReadOnlySignal<NonCloneable<i32>>) -> Element {\n        rsx! {}\n    }\n\n    set_event_converter(Box::new(dioxus::html::SerializedHtmlEventConverter));\n    let mut dom = VirtualDom::new(app);\n\n    let mutations = dom.rebuild_to_vec();\n    println!(\"{:#?}\", mutations);\n    dom.mark_dirty(ScopeId::APP);\n    for _ in 0..20 {\n        let event = Event::new(\n            Rc::new(PlatformEventData::new(Box::<SerializedMouseData>::default())) as Rc<dyn Any>,\n            true,\n        );\n        dom.runtime().handle_event(\"click\", event, ElementId(1));\n        dom.render_immediate(&mut dioxus_core::NoOpMutations);\n    }\n    dom.render_immediate(&mut dioxus_core::NoOpMutations);\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "1a38f2b2e5e39192e978e33d521d560a78a34ad6",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/packages/core-macro/tests/rsx.rs",
    "func": "#[test]\nfn rsx() {\n    let t = trybuild::TestCases::new();\n    t.compile_fail(\"tests/rsx/trailing-comma-0.rs\");\n}\n\n/// This test ensures that automatic `into` conversion occurs for default values.\n///\n/// These are compile-time tests.\n/// See https://github.com/DioxusLabs/dioxus/issues/2373\n#[cfg(test)]\nmod test_default_into {\n    use dioxus::prelude::*;\n\n    #[derive(Props, Clone, PartialEq)]\n    struct MyCoolProps {\n        // Test different into configurations\n        #[props(into, default = true)]\n        pub val_into_w_default_val: u16,\n\n        #[props(into, default)]\n        pub val_into_w_default: u16,\n\n        #[props(default = true.into())]\n        pub val_default: u16,\n\n        // Test different into configurations with strings\n        #[props(into, default = \"abc\")]\n        pub str_into_w_default_val: String,\n\n        #[props(into, default)]\n        pub str_into_w_default: String,\n\n        #[props(default = \"abc\".into())]\n        pub str_default: String,\n\n        // Test options\n        #[props(into, default = Some(\"abc\"))]\n        pub opt_into_w_default_val: Option<String>,\n\n        #[props(into, default)]\n        pub opt_into_w_default: Option<String>,\n\n        #[props(default = Some(\"abc\"))]\n        pub opt_default: Option<String>,\n\n        // Test no default\n        #[props(into)]\n        pub some_data: bool,\n\n        pub some_other_data: bool,\n    }\n}\n/// This test ensures that read-only signals that contain an option (`Signal<Option<u16>>`)\n/// are correctly created as default when not provided.\n///\n/// These are compile-time tests.\n/// See https://github.com/DioxusLabs/dioxus/issues/2648\n#[cfg(test)]\n#[allow(unused)]\nmod test_optional_signals {\n    use dioxus::prelude::*;\n\n    // Test if test components fail to compile.\n    #[component]\n    fn UsesComponents() -> Element {\n        rsx! {\n            PropsStruct {\n                regular_read_signal: ReadOnlySignal::new(Signal::new(1234)),\n            }\n            PropsStruct {\n                optional_read_signal: 1234,\n                regular_read_signal: 123u16,\n            }\n            PropParams {}\n            PropParams {\n                opt_read_sig: 1234\n            }\n            DoubleOption {}\n            DoubleOption { optional: Some(1234) }\n        }\n    }\n\n    // Test props as struct param.\n    #[derive(Props, Clone, PartialEq)]\n    struct MyTestProps {\n        pub optional_read_signal: ReadOnlySignal<Option<u16>>,\n        pub regular_read_signal: ReadOnlySignal<u16>,\n    }\n\n    #[component]\n    fn PropsStruct(props: MyTestProps) -> Element {\n        rsx! { \"hi\" }\n    }\n\n    // Test props as params.\n    #[component]\n    fn PropParams(opt_read_sig: ReadOnlySignal<Option<u16>>) -> Element {\n        rsx! { \"hi!\" }\n    }\n\n    #[component]\n    fn DoubleOption(optional: Option<Option<u16>>) -> Element {\n        rsx! { \"hi!\" }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "abf23ae94d48aa368b5a9f68cece474c4f50eb24",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/packages/cli/src/cli/doctor.rs",
    "func": "use crate::{Result, StructuredOutput};\nuse clap::Parser;\n\n#[derive(Clone, Debug, Parser)]\npub struct Doctor {}\n\nimpl Doctor {\n    pub async fn run(self) -> Result<StructuredOutput> {\n        Ok(StructuredOutput::Success)\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "60962a6be7eb433e2189880200d28142e040579d",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/packages/cli/src/config/desktop.rs",
    "func": "use serde::{Deserialize, Serialize};\n\n/// Represents configuration items for the desktop platform.\n#[derive(Debug, Default, Clone, Serialize, Deserialize)]\npub(crate) struct DesktopConfig {}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "77048fff277cb534454f192a41eced8323cd8343",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/packages/cli/src/serve/mod.rs",
    "func": "use crate::{BuildUpdate, Builder, Error, Platform, Result, ServeArgs, TraceController, TraceSrc};\n\nmod ansi_buffer;\nmod detect;\nmod handle;\nmod output;\nmod proxy;\nmod runner;\nmod server;\nmod update;\nmod watcher;\n\npub(crate) use handle::*;\npub(crate) use output::*;\npub(crate) use runner::*;\npub(crate) use server::*;\npub(crate) use update::*;\npub(crate) use watcher::*;\n\n/// For *all* builds, the CLI spins up a dedicated webserver, file watcher, and build infrastructure to serve the project.\n///\n/// This includes web, desktop, mobile, fullstack, etc.\n///\n/// Platform specifics:\n/// -------------------\n/// - Web:         we need to attach a filesystem server to our devtools webserver to serve the project. We\n///                want to emulate GithubPages here since most folks are deploying there and expect things like\n///                basepath to match.\n/// - Desktop:     We spin up the dev server but without a filesystem server.\n/// - Mobile:      Basically the same as desktop.\n///\n/// When fullstack is enabled, we'll also build for the `server` target and then hotreload the server.\n/// The \"server\" is special here since \"fullstack\" is functionally just an addition to the regular client\n/// setup.\n///\n/// Todos(Jon):\n/// - I'd love to be able to configure the CLI while it's running so we can change settings on the fly.\n/// - I want us to be able to detect a `server_fn` in the project and then upgrade from a static server\n///   to a dynamic one on the fly.\npub(crate) async fn serve_all(mut args: ServeArgs) -> Result<()> {\n    // Redirect all logging the cli logger\n    let mut tracer = TraceController::redirect();\n\n    // Load the krate and resolve the server args against it - this might log so do it after we turn on the tracer first\n    let krate = args.load_krate().await?;\n\n    // Note that starting the builder will queue up a build immediately\n    let mut builder = Builder::start(&krate, args.build_args())?;\n    let mut devserver = WebServer::start(&krate, &args)?;\n    let mut watcher = Watcher::start(&krate, &args);\n    let mut runner = AppRunner::start(&krate);\n    let mut screen = Output::start(&args)?;\n\n    // This is our default splash screen. We might want to make this a fancier splash screen in the future\n    // Also, these commands might not be the most important, but it's all we've got enabled right now\n    tracing::info!(\n        r#\"-----------------------------------------------------------------\n                Serving your Dioxus app: {} \ud83d\ude80\n                \u2022 Press `ctrl+c` to exit the server\n                \u2022 Press `r` to rebuild the app\n                \u2022 Press `o` to open the app\n                \u2022 Press `v` to toggle verbose logging\n                \u2022 Press `/` for more commands and shortcuts\n                Learn more at https://dioxuslabs.com/learn/0.6/getting_started\n               ----------------------------------------------------------------\"#,\n        krate.executable_name()\n    );\n\n    let err: Result<(), Error> = loop {\n        // Draw the state of the server to the screen\n        screen.render(&args, &krate, &builder, &devserver, &watcher);\n\n        // And then wait for any updates before redrawing\n        let msg = tokio::select! {\n            msg = builder.wait() => ServeUpdate::BuildUpdate(msg),\n            msg = watcher.wait() => msg,\n            msg = devserver.wait() => msg,\n            msg = screen.wait() => msg,\n            msg = runner.wait() => msg,\n            msg = tracer.wait() => msg,\n        };\n\n        match msg {\n            ServeUpdate::FilesChanged { files } => {\n                if files.is_empty() || !args.should_hotreload() {\n                    continue;\n                }\n\n                let file = files[0].display().to_string();\n                let file = file.trim_start_matches(&krate.crate_dir().display().to_string());\n\n                // if change is hotreloadable, hotreload it\n                // and then send that update to all connected clients\n                if let Some(hr) = runner.attempt_hot_reload(files) {\n                    // Only send a hotreload message for templates and assets - otherwise we'll just get a full rebuild\n                    if hr.templates.is_empty()\n                        && hr.assets.is_empty()\n                        && hr.unknown_files.is_empty()\n                    {\n                        tracing::debug!(dx_src = ?TraceSrc::Dev, \"Ignoring file change: {}\", file);\n                        continue;\n                    }\n\n                    tracing::info!(dx_src = ?TraceSrc::Dev, \"Hotreloading: {}\", file);\n\n                    devserver.send_hotreload(hr).await;\n                } else if runner.should_full_rebuild {\n                    tracing::info!(dx_src = ?TraceSrc::Dev, \"Full rebuild: {}\", file);\n\n                    // Kill any running executables on Windows\n                    if cfg!(windows) {\n                        runner.kill_all();\n                    }\n\n                    // We're going to kick off a new build, interrupting the current build if it's ongoing\n                    builder.rebuild(args.build_arguments.clone());\n\n                    // Clear the hot reload changes so we don't have out-of-sync issues with changed UI\n                    runner.clear_hot_reload_changes();\n                    runner.file_map.force_rebuild();\n\n                    // Tell the server to show a loading page for any new requests\n                    devserver.start_build().await;\n                } else {\n                    tracing::warn!(\n                        \"Rebuild required but is currently paused - press `r` to rebuild manually\"\n                    )\n                }\n            }\n\n            // Run the server in the background\n            // Waiting for updates here lets us tap into when clients are added/removed\n            ServeUpdate::NewConnection => {\n                devserver\n                    .send_hotreload(runner.applied_hot_reload_changes())\n                    .await;\n\n                runner.client_connected().await;\n            }\n\n            // Received a message from the devtools server - currently we only use this for\n            // logging, so we just forward it the tui\n            ServeUpdate::WsMessage(msg) => {\n                screen.push_ws_message(Platform::Web, msg);\n            }\n\n            // Wait for logs from the build engine\n            // These will cause us to update the screen\n            // We also can check the status of the builds here in case we have multiple ongoing builds\n            ServeUpdate::BuildUpdate(update) => {\n                // Queue any logs to be printed if need be\n                screen.new_build_update(&update);\n\n                // And then update the websocketed clients with the new build status in case they want it\n                devserver.new_build_update(&update, &builder).await;\n\n                // And then open the app if it's ready\n                // todo: there might be more things to do here that require coordination with other pieces of the CLI\n                // todo: maybe we want to shuffle the runner around to send an \"open\" command instead of doing that\n                match update {\n                    BuildUpdate::Progress { .. } => {}\n                    BuildUpdate::CompilerMessage { message } => {\n                        screen.push_cargo_log(message);\n                    }\n                    BuildUpdate::BuildFailed { err } => {\n                        tracing::error!(\"Build failed: {:?}\", err);\n                    }\n                    BuildUpdate::BuildReady { bundle } => {\n                        let handle = runner\n                            .open(\n                                bundle,\n                                devserver.devserver_address(),\n                                devserver.proxied_server_address(),\n                                args.open.unwrap_or(false),\n                            )\n                            .await;\n\n                        match handle {\n                            // Update the screen + devserver with the new handle info\n                            Ok(_handle) => {\n                                devserver.send_reload_command().await;\n                            }\n\n                            Err(e) => tracing::error!(\"Failed to open app: {}\", e),\n                        }\n                    }\n                }\n            }\n\n            // If the process exited *cleanly*, we can exit\n            ServeUpdate::ProcessExited { status, platform } => {\n                if !status.success() {\n                    tracing::error!(\"Application [{platform}] exited with error: {status}\");\n                } else {\n                    tracing::info!(\n                        r#\"Application [{platform}] exited gracefully.\n               - To restart the app, press `r` to rebuild or `o` to open\n               - To exit the server, press `ctrl+c`\"#\n                    );\n                }\n\n                runner.kill(platform);\n            }\n\n            ServeUpdate::StdoutReceived { platform, msg } => {\n                screen.push_stdio(platform, msg, tracing::Level::INFO);\n            }\n\n            ServeUpdate::StderrReceived { platform, msg } => {\n                screen.push_stdio(platform, msg, tracing::Level::ERROR);\n            }\n\n            ServeUpdate::TracingLog { log } => {\n                screen.push_log(log);\n            }\n\n            ServeUpdate::RequestRebuild => {\n                // The spacing here is important-ish: we want\n                // `Full rebuild:` to line up with\n                // `Hotreloading:` to keep the alignment during long edit sessions\n                tracing::info!(\"Full rebuild: triggered manually\");\n\n                // Kill any running executables on Windows\n                if cfg!(windows) {\n                    runner.kill_all();\n                }\n\n                builder.rebuild(args.build_arguments.clone());\n                runner.file_map.force_rebuild();\n                devserver.start_build().await\n            }\n\n            ServeUpdate::OpenApp => {\n                if let Err(err) = runner.open_existing(&devserver).await {\n                    tracing::error!(\"Failed to open app: {err}\")\n                }\n            }\n\n            ServeUpdate::Redraw => {\n                // simply returning will cause a redraw\n            }\n\n            ServeUpdate::ToggleShouldRebuild => {\n                runner.should_full_rebuild = !runner.should_full_rebuild;\n                tracing::info!(\n                    \"Automatic rebuilds are currently: {}\",\n                    if runner.should_full_rebuild {\n                        \"enabled\"\n                    } else {\n                        \"disabled\"\n                    }\n                )\n            }\n\n            ServeUpdate::Exit { error } => match error {\n                Some(err) => break Err(anyhow::anyhow!(\"{}\", err).into()),\n                None => break Ok(()),\n            },\n        }\n    };\n\n    _ = devserver.shutdown().await;\n    _ = screen.shutdown();\n    builder.abort_all();\n\n    if let Err(err) = err {\n        eprintln!(\"Exiting with error: {}\", err);\n    }\n\n    Ok(())\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "eed1141b2adc6e9293798b0532add7212de06d5d",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/packages/cli/src/serve/proxy.rs",
    "func": "use crate::config::WebProxyConfig;\nuse crate::TraceSrc;\nuse crate::{Error, Result};\n\nuse anyhow::{anyhow, Context};\nuse axum::body::Body;\nuse axum::{body::Body as MyBody, response::IntoResponse};\nuse axum::{\n    http::StatusCode,\n    routing::{any, MethodRouter},\n    Router,\n};\nuse hyper::{Request, Response, Uri};\nuse hyper_util::{\n    client::legacy::{self, connect::HttpConnector},\n    rt::TokioExecutor,\n};\n\n#[derive(Debug, Clone)]\nstruct ProxyClient {\n    inner: legacy::Client<hyper_rustls::HttpsConnector<HttpConnector>, MyBody>,\n    url: Uri,\n}\n\nimpl ProxyClient {\n    fn new(url: Uri) -> Self {\n        let _ = rustls::crypto::ring::default_provider().install_default();\n        let https = hyper_rustls::HttpsConnectorBuilder::new()\n            .with_native_roots()\n            .unwrap()\n            .https_or_http()\n            .enable_all_versions()\n            .build();\n        Self {\n            inner: legacy::Client::builder(TokioExecutor::new()).build(https),\n            url,\n        }\n    }\n\n    async fn send(&self, mut req: Request<MyBody>) -> Result<Response<hyper::body::Incoming>> {\n        let mut uri_parts = req.uri().clone().into_parts();\n        uri_parts.authority = self.url.authority().cloned();\n        uri_parts.scheme = self.url.scheme().cloned();\n        *req.uri_mut() = Uri::from_parts(uri_parts).context(\"Invalid URI parts\")?;\n        self.inner\n            .request(req)\n            .await\n            .map_err(|err| crate::error::Error::Other(anyhow!(err)))\n    }\n}\n\n/// Add routes to the router handling the specified proxy config.\n///\n/// We will proxy requests directed at either:\n///\n/// - the exact path of the proxy config's backend URL, e.g. /api\n/// - the exact path with a trailing slash, e.g. /api/\n/// - any subpath of the backend URL, e.g. /api/foo/bar\npub(crate) fn add_proxy(mut router: Router, proxy: &WebProxyConfig) -> Result<Router> {\n    let url: Uri = proxy.backend.parse()?;\n    let path = url.path().to_string();\n    let trimmed_path = path.trim_start_matches('/');\n\n    if trimmed_path.is_empty() {\n        return Err(crate::Error::ProxySetup(format!(\n            \"Proxy backend URL must have a non-empty path, e.g. {}/api instead of {}\",\n            proxy.backend.trim_end_matches('/'),\n            proxy.backend\n        )));\n    }\n\n    let method_router = proxy_to(url, false, handle_proxy_error);\n\n    // api/*path\n    router = router.route(\n        &format!(\"/{}/*path\", trimmed_path.trim_end_matches('/')),\n        method_router.clone(),\n    );\n\n    // /api/\n    router = router.route(\n        &format!(\"/{}/\", trimmed_path.trim_end_matches('/')),\n        method_router.clone(),\n    );\n\n    // /api\n    router = router.route(\n        &format!(\"/{}\", trimmed_path.trim_end_matches('/')),\n        method_router,\n    );\n\n    Ok(router)\n}\n\npub(crate) fn proxy_to(\n    url: Uri,\n    nocache: bool,\n    handle_error: fn(Error) -> Response<Body>,\n) -> MethodRouter {\n    let client = ProxyClient::new(url.clone());\n\n    any(move |mut req: Request<MyBody>| async move {\n        // Prevent request loops\n        if req.headers().get(\"x-proxied-by-dioxus\").is_some() {\n            return Err(Response::builder()\n                .status(StatusCode::NOT_FOUND)\n                .body(Body::from(\n                    \"API is sharing a loopback with the dev server. Try setting a different port on the API config.\",\n                ))\n                .unwrap());\n        }\n\n        req.headers_mut().insert(\n            \"x-proxied-by-dioxus\",\n            \"true\".parse().expect(\"header value is valid\"),\n        );\n\n        // We have to throw a redirect for ws connections since the upgrade handler will not be called\n        // Our _dioxus handler will override this in the default case\n        if req.uri().scheme().map(|f| f.as_str()) == Some(\"ws\")\n            || req.uri().scheme().map(|f| f.as_str()) == Some(\"wss\")\n        {\n            let new_host = url.host().unwrap_or(\"localhost\");\n            let proxied_uri = format!(\n                \"{scheme}://{host}:{port}{path_and_query}\",\n                scheme = req.uri().scheme_str().unwrap_or(\"ws\"),\n                port = url.port().unwrap(),\n                host = new_host,\n                path_and_query = req\n                    .uri()\n                    .path_and_query()\n                    .map(|f| f.to_string())\n                    .unwrap_or_default()\n            );\n            tracing::info!(dx_src = ?TraceSrc::Dev, \"Proxied websocket request {req:?} to {proxied_uri}\");\n\n            return Ok(axum::response::Redirect::permanent(&proxied_uri).into_response());\n        }\n\n        if nocache {\n            crate::serve::insert_no_cache_headers(req.headers_mut());\n        }\n\n        let uri = req.uri().clone();\n\n        // retry with backoff\n\n        let res = client.send(req).await.map_err(handle_error);\n\n        match res {\n            Ok(res) => {\n                // log assets at a different log level\n                if uri.path().starts_with(\"/assets\")\n                    || uri.path().starts_with(\"/_dioxus\")\n                    || uri.path().starts_with(\"/public\")\n                    || uri.path().starts_with(\"/wasm\")\n                {\n                    tracing::trace!(dx_src = ?TraceSrc::Dev, \"[{}] {}\", res.status().as_u16(), uri);\n                } else {\n                    tracing::info!(dx_src = ?TraceSrc::Dev, \"[{}] {}\", res.status().as_u16(), uri);\n                }\n\n                Ok(res.into_response())\n            }\n            Err(err) => {\n                tracing::error!(dx_src = ?TraceSrc::Dev, \"[{}] {}\", err.status().as_u16(), uri);\n                Err(err)\n            }\n        }\n    })\n}\n\nfn handle_proxy_error(e: Error) -> axum::http::Response<axum::body::Body> {\n    tracing::error!(dx_src = ?TraceSrc::Dev, \"Proxy error: {}\", e);\n    axum::http::Response::builder()\n        .status(axum::http::StatusCode::INTERNAL_SERVER_ERROR)\n        .body(axum::body::Body::from(format!(\n            \"Proxy connection failed: {:#?}\",\n            e\n        )))\n        .unwrap()\n}\n\n#[cfg(test)]\nmod test {\n\n    use super::*;\n\n    use axum_server::{Handle, Server};\n\n    async fn setup_servers(mut config: WebProxyConfig) -> String {\n        let backend_router =\n            Router::new().route(\n                \"/*path\",\n                any(|request: axum::extract::Request| async move {\n                    format!(\"backend: {}\", request.uri())\n                }),\n            );\n\n        // The API backend server\n        let backend_handle_handle = Handle::new();\n        let backend_handle_handle_ = backend_handle_handle.clone();\n        tokio::spawn(async move {\n            Server::bind(\"127.0.0.1:0\".parse().unwrap())\n                .handle(backend_handle_handle_)\n                .serve(backend_router.into_make_service())\n                .await\n                .unwrap();\n        });\n\n        // Set the user's config to this dummy API we just built so we can test it\n        let backend_addr = backend_handle_handle.listening().await.unwrap();\n        config.backend = format!(\"http://{}{}\", backend_addr, config.backend);\n\n        // Now set up our actual filesystem server\n        let router = super::add_proxy(Router::new(), &config);\n        let server_handle_handle = Handle::new();\n        let server_handle_handle_ = server_handle_handle.clone();\n        tokio::spawn(async move {\n            Server::bind(\"127.0.0.1:0\".parse().unwrap())\n                .handle(server_handle_handle_)\n                .serve(router.unwrap().into_make_service())\n                .await\n                .unwrap();\n        });\n\n        // Expose *just* the filesystem web server's address\n        server_handle_handle.listening().await.unwrap().to_string()\n    }\n\n    async fn test_proxy_requests(path: String) {\n        let config = WebProxyConfig {\n            // Normally this would be an absolute URL including scheme/host/port,\n            // but in these tests we need to let the OS choose the port so tests\n            // don't conflict, so we'll concatenate the final address and this\n            // path together.\n            // So in day to day usage, use `http://localhost:8000/api` instead!\n            backend: path,\n        };\n\n        let server_addr = setup_servers(config).await;\n\n        assert_eq!(\n            reqwest::get(format!(\"http://{}/api\", server_addr))\n                .await\n                .unwrap()\n                .text()\n                .await\n                .unwrap(),\n            \"backend: /api\"\n        );\n\n        assert_eq!(\n            reqwest::get(format!(\"http://{}/api/\", server_addr))\n                .await\n                .unwrap()\n                .text()\n                .await\n                .unwrap(),\n            \"backend: /api/\"\n        );\n\n        assert_eq!(\n            reqwest::get(format!(\"http://{server_addr}/api/subpath\"))\n                .await\n                .unwrap()\n                .text()\n                .await\n                .unwrap(),\n            \"backend: /api/subpath\"\n        );\n    }\n\n    #[tokio::test]\n    async fn add_proxy() {\n        test_proxy_requests(\"/api\".to_string()).await;\n    }\n\n    #[tokio::test]\n    async fn add_proxy_trailing_slash() {\n        test_proxy_requests(\"/api/\".to_string()).await;\n    }\n\n    #[test]\n    fn add_proxy_empty_path() {\n        let config = WebProxyConfig {\n            backend: \"http://localhost:8000\".to_string(),\n        };\n        let router = super::add_proxy(Router::new(), &config);\n        match router.unwrap_err() {\n            crate::Error::ProxySetup(e) => {\n                assert_eq!(\n                    e,\n                    \"Proxy backend URL must have a non-empty path, e.g. http://localhost:8000/api instead of http://localhost:8000\"\n                );\n            }\n            e => panic!(\"Unexpected error type: {}\", e),\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "0c3649cba7a09441a266d6b910494d0fd72ada5c",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/packages/ssr/src/config.rs",
    "func": "\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "aad1e8efec87df6895f3e5c53e2784da25f8c934",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/packages/signals/examples/dependencies.rs",
    "func": "use dioxus::prelude::*;\n\nfn main() {\n    dioxus::launch(app);\n}\n\nfn app() -> Element {\n    let mut signal = use_signal(|| 0);\n\n    use_future(move || async move {\n        loop {\n            tokio::time::sleep(std::time::Duration::from_secs(1)).await;\n            signal += 1;\n        }\n    });\n\n    rsx! {\n        \"Parent count: {signal}\"\n        Child {\n            non_reactive_prop: signal()\n        }\n    }\n}\n\n#[component]\nfn Child(non_reactive_prop: i32) -> Element {\n    let mut signal = use_signal(|| 0);\n\n    // You can manually specify the dependencies with `use_reactive` for values that are not reactive like props\n    let computed = use_memo(use_reactive!(\n        |(non_reactive_prop,)| non_reactive_prop + signal()\n    ));\n    use_effect(use_reactive!(|(non_reactive_prop,)| println!(\n        \"{}\",\n        non_reactive_prop + signal()\n    )));\n    let fut = use_resource(use_reactive!(|(non_reactive_prop,)| async move {\n        tokio::time::sleep(std::time::Duration::from_secs(1)).await;\n        non_reactive_prop + signal()\n    }));\n\n    rsx! {\n        button {\n            onclick: move |_| signal += 1,\n            \"Child count: {signal}\"\n        }\n\n        \"Sum: {computed}\"\n\n        \"{fut():?}\"\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "67ae8d28674715b68dd96a5068464ad6106d6c31",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/packages/signals/src/impls.rs",
    "func": "/// This macro is used to generate a `impl Default` block for any type with the function new_maybe_sync that takes a generic `T`\n///\n/// # Example\n/// ```rust\n/// use generational_box::*;\n/// use dioxus::prelude::*;\n///\n/// struct MyCopyValue<T: 'static, S: Storage<T>> {\n///     value: CopyValue<T, S>,\n/// }\n///\n/// impl<T: 'static, S: Storage<T>> MyCopyValue<T, S> {\n///     fn new_maybe_sync(value: T) -> Self {\n///         Self { value: CopyValue::new_maybe_sync(value) }\n///     }\n/// }\n///\n/// impl<T: 'static, S: Storage<T>> Readable for MyCopyValue<T, S> {\n///     type Target = T;\n///     type Storage = S;\n///\n///     fn try_read_unchecked(\n///         &self,\n///     ) -> Result<ReadableRef<'static, Self>, generational_box::BorrowError> {\n///         self.value.try_read_unchecked()\n///     }\n///\n///     fn try_peek_unchecked(\n///         &self,\n///     ) -> Result<ReadableRef<'static, Self>, generational_box::BorrowError> {\n///         self.value.try_read_unchecked()\n///     }\n/// }\n///\n/// default_impl!(MyCopyValue<T, S: Storage<T>>);\n/// ```\n#[macro_export]\nmacro_rules! default_impl {\n    (\n        $ty:ident\n        // Accept generics\n        < T $(, $gen:ident $(: $gen_bound:path)?)* $(,)?>\n        // Accept extra bounds\n        $(\n            where\n                $(\n                    $extra_bound_ty:ident: $extra_bound:path\n                ),+\n        )?\n    ) => {\n        impl<T: Default + 'static\n            $(, $gen $(: $gen_bound)?)*\n        > Default for $ty <T $(, $gen)*>\n        $(\n            where\n                $(\n                    $extra_bound_ty: $extra_bound\n                ),+\n        )?\n        {\n            #[track_caller]\n            fn default() -> Self {\n                Self::new_maybe_sync(Default::default())\n            }\n        }\n    }\n}\n\n/// This macro is used to generate `impl Display`, `impl Debug`, `impl PartialEq`, and `impl Eq` blocks for any Readable type that takes a generic `T`\n///\n/// # Example\n/// ```rust\n/// use generational_box::*;\n/// use dioxus::prelude::*;\n///\n/// struct MyCopyValue<T: 'static, S: Storage<T>> {\n///     value: CopyValue<T, S>,\n/// }\n///\n/// impl<T: 'static, S: Storage<T>> Readable for MyCopyValue<T, S> {\n///     type Target = T;\n///     type Storage = S;\n///\n///     fn try_read_unchecked(\n///         &self,\n///     ) -> Result<ReadableRef<'static, Self>, generational_box::BorrowError> {\n///         self.value.try_read_unchecked()\n///     }\n///\n///     fn try_peek_unchecked(\n///         &self,\n///     ) -> Result<ReadableRef<'static, Self>, generational_box::BorrowError> {\n///         self.value.try_read_unchecked()\n///     }\n/// }\n///\n/// read_impls!(MyCopyValue<T, S: Storage<T>>);\n/// ```\n#[macro_export]\nmacro_rules! read_impls {\n    (\n        $ty:ident\n        // Accept generics\n        < T $(, $gen:ident $(: $gen_bound:path)?)* $(,)?>\n        // Accept extra bounds\n        $(\n            where\n                $(\n                    $extra_bound_ty:ident: $extra_bound:path\n                ),+\n        )?\n    ) => {\n        $crate::fmt_impls!{\n            $ty<\n                T\n                $(\n                    , $gen\n                    $(: $gen_bound)?\n                )*\n            >\n            $(\n                where\n                    $($extra_bound_ty: $extra_bound),*\n            )?\n        }\n        $crate::eq_impls!{\n            $ty<\n                T\n                $(\n                    , $gen\n                    $(: $gen_bound)?\n                )*\n            >\n            $(\n                where\n                    $($extra_bound_ty: $extra_bound),*\n            )?\n        }\n    };\n}\n\n/// This macro is used to generate `impl Display`, and `impl Debug` blocks for any Readable type that takes a generic `T`\n///\n/// # Example\n/// ```rust\n/// use generational_box::*;\n/// use dioxus::prelude::*;\n///\n/// struct MyCopyValue<T: 'static, S: Storage<T>> {\n///     value: CopyValue<T, S>,\n/// }\n///\n/// impl<T: 'static, S: Storage<T>> Readable for MyCopyValue<T, S> {\n///     type Target = T;\n///     type Storage = S;\n///\n///     fn try_read_unchecked(\n///         &self,\n///     ) -> Result<ReadableRef<'static, Self>, generational_box::BorrowError> {\n///         self.value.try_read_unchecked()\n///     }\n///\n///     fn try_peek_unchecked(\n///         &self,\n///     ) -> Result<ReadableRef<'static, Self>, generational_box::BorrowError> {\n///         self.value.try_read_unchecked()\n///     }\n/// }\n///\n/// fmt_impls!(MyCopyValue<T, S: Storage<T>>);\n/// ```\n#[macro_export]\nmacro_rules! fmt_impls {\n    (\n        $ty:ident\n        // Accept generics\n        < T $(, $gen:ident $(: $gen_bound:path)?)* $(,)?>\n        // Accept extra bounds\n        $(\n            where\n                $(\n                    $extra_bound_ty:ident: $extra_bound:path\n                ),+\n        )?\n    ) => {\n    impl<\n        T: std::fmt::Display + 'static\n        $(, $gen $(: $gen_bound)?)*\n    > std::fmt::Display for $ty<T $(, $gen)*>\n        $(\n            where\n                $($extra_bound_ty: $extra_bound,)*\n        )?\n    {\n        #[track_caller]\n        fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n            self.with(|v| std::fmt::Display::fmt(v, f))\n        }\n    }\n\n    impl<\n        T: std::fmt::Debug + 'static\n        $(, $gen $(: $gen_bound)?)*\n    > std::fmt::Debug for $ty<T $(, $gen)*>\n        $(\n            where\n                $($extra_bound_ty: $extra_bound,)*\n        )?\n    {\n        #[track_caller]\n        fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n            self.with(|v| std::fmt::Debug::fmt(v, f))\n        }\n    }\n};\n    }\n\n/// This macro is used to generate `impl PartialEq` blocks for any Readable type that takes a generic `T`\n///\n/// # Example\n/// ```rust\n/// use generational_box::*;\n/// use dioxus::prelude::*;\n///\n/// struct MyCopyValue<T: 'static, S: Storage<T>> {\n///     value: CopyValue<T, S>,\n/// }\n///\n/// impl<T: 'static, S: Storage<T>> Readable for MyCopyValue<T, S> {\n///     type Target = T;\n///     type Storage = S;\n///\n///     fn try_read_unchecked(\n///         &self,\n///     ) -> Result<ReadableRef<'static, Self>, generational_box::BorrowError> {\n///         self.value.try_read_unchecked()\n///     }\n///\n///     fn try_peek_unchecked(\n///         &self,\n///     ) -> Result<ReadableRef<'static, Self>, generational_box::BorrowError> {\n///         self.value.try_read_unchecked()\n///     }\n/// }\n///\n/// eq_impls!(MyCopyValue<T, S: Storage<T>>);\n/// ```\n#[macro_export]\nmacro_rules! eq_impls {\n    (\n        $ty:ident\n        // Accept generics\n        < T $(, $gen:ident $(: $gen_bound:path)?)* $(,)?>\n        // Accept extra bounds\n        $(\n            where\n                $(\n                    $extra_bound_ty:ident: $extra_bound:path\n                ),+\n        )?\n    ) => {\n        impl<\n            T: PartialEq + 'static\n            $(, $gen $(: $gen_bound)?)*\n        > PartialEq<T> for $ty<T $(, $gen)*>\n            $(\n                where\n                    $($extra_bound_ty: $extra_bound,)*\n            )?\n        {\n            #[track_caller]\n            fn eq(&self, other: &T) -> bool {\n                self.with(|v| *v == *other)\n            }\n        }\n    };\n}\n\n/// This macro is used to generate `impl Add`, `impl AddAssign`, `impl Sub`, `impl SubAssign`, `impl Mul`, `impl MulAssign`, `impl Div`, and `impl DivAssign` blocks for any Writable type that takes a generic `T`\n///\n/// # Example\n/// ```rust, ignore\n/// use generational_box::*;\n/// use dioxus::prelude::*;\n///\n/// struct MyCopyValue<T: 'static, S: Storage<T>> {\n///     value: CopyValue<T, S>,\n/// }\n///\n/// impl<T: 'static, S: Storage<T>> Readable for MyCopyValue<T, S> {\n///     type Target = T;\n///     type Storage = S;\n///\n///     fn try_read_unchecked(\n///         &self,\n///     ) -> Result<ReadableRef<'static, Self>, generational_box::BorrowError> {\n///         self.value.try_read_unchecked()\n///     }\n///\n///     fn peek_unchecked(&self) -> ReadableRef<'static, Self> {\n///         self.value.read_unchecked()\n///     }\n/// }\n///\n/// impl<T: 'static, S: Storage<T>> Writable for MyCopyValue<T, S> {\n///     fn try_write_unchecked(\n///         &self,\n///     ) -> Result<WritableRef<'static, Self>, generational_box::BorrowMutError> {\n///         self.value.try_write_unchecked()\n///\n///      }\n///\n///     //...\n/// }\n///\n/// write_impls!(MyCopyValue<T, S: Storage<T>>);\n/// ```\n#[macro_export]\nmacro_rules! write_impls {\n    (\n        $ty:ident\n        // Accept generics\n        < T $(, $gen:ident $(: $gen_bound:path)?)* $(,)?>\n        // Accept extra bounds\n        $(\n            where\n                $(\n                    $extra_bound_ty:ident: $extra_bound:path\n                ),+\n        )?) => {\n        impl<T: std::ops::Add<Output = T> + Copy + 'static\n        $(, $gen $(: $gen_bound)?)*\n        > std::ops::Add<T>\n            for $ty<T $(, $gen)*>\n        {\n            type Output = T;\n\n            #[track_caller]\n            fn add(self, rhs: T) -> Self::Output {\n                self.with(|v| *v + rhs)\n            }\n        }\n\n        impl<T: std::ops::Add<Output = T> + Copy + 'static\n        $(, $gen $(: $gen_bound)?)*\n        > std::ops::AddAssign<T>\n            for $ty<T $(, $gen)*>\n        {\n            #[track_caller]\n            fn add_assign(&mut self, rhs: T) {\n                self.with_mut(|v| *v = *v + rhs)\n            }\n        }\n\n        impl<T: std::ops::Sub<Output = T> + Copy + 'static\n        $(, $gen $(: $gen_bound)?)*\n        > std::ops::SubAssign<T>\n            for $ty<T $(, $gen)*>\n        {\n            #[track_caller]\n            fn sub_assign(&mut self, rhs: T) {\n                self.with_mut(|v| *v = *v - rhs)\n            }\n        }\n\n        impl<T: std::ops::Sub<Output = T> + Copy + 'static\n        $(, $gen $(: $gen_bound)?)*\n        > std::ops::Sub<T>\n            for $ty<T $(, $gen)*>\n        {\n            type Output = T;\n\n            #[track_caller]\n            fn sub(self, rhs: T) -> Self::Output {\n                self.with(|v| *v - rhs)\n            }\n        }\n\n        impl<T: std::ops::Mul<Output = T> + Copy + 'static\n        $(, $gen $(: $gen_bound)?)*\n        > std::ops::MulAssign<T>\n            for $ty<T $(, $gen)*>\n        {\n            #[track_caller]\n            fn mul_assign(&mut self, rhs: T) {\n                self.with_mut(|v| *v = *v * rhs)\n            }\n        }\n\n        impl<T: std::ops::Mul<Output = T> + Copy + 'static\n        $(, $gen $(: $gen_bound)?)*\n        > std::ops::Mul<T>\n            for $ty<T $(, $gen)*>\n        {\n            type Output = T;\n\n            #[track_caller]\n            fn mul(self, rhs: T) -> Self::Output {\n                self.with(|v| *v * rhs)\n            }\n        }\n\n        impl<T: std::ops::Div<Output = T> + Copy + 'static\n        $(, $gen $(: $gen_bound)?)*\n        > std::ops::DivAssign<T>\n            for $ty<T $(, $gen)*>\n        {\n            #[track_caller]\n            fn div_assign(&mut self, rhs: T) {\n                self.with_mut(|v| *v = *v / rhs)\n            }\n        }\n\n        impl<T: std::ops::Div<Output = T> + Copy + 'static\n        $(, $gen $(: $gen_bound)?)*\n        > std::ops::Div<T>\n            for $ty<T $(, $gen)*>\n        {\n            type Output = T;\n\n            #[track_caller]\n            fn div(self, rhs: T) -> Self::Output {\n                self.with(|v| *v / rhs)\n            }\n        }\n    };\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "daaad3060cad28db95181d107427bce705aeaa32",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/packages/signals/src/read.rs",
    "func": "use std::{mem::MaybeUninit, ops::Index, rc::Rc};\n\nuse generational_box::AnyStorage;\n\nuse crate::MappedSignal;\n\n/// A reference to a value that can be read from.\n#[allow(type_alias_bounds)]\npub type ReadableRef<'a, T: Readable, O = <T as Readable>::Target> =\n    <T::Storage as AnyStorage>::Ref<'a, O>;\n\n/// A trait for states that can be read from like [`crate::Signal`], [`crate::GlobalSignal`], or [`crate::ReadOnlySignal`]. You may choose to accept this trait as a parameter instead of the concrete type to allow for more flexibility in your API. For example, instead of creating two functions, one that accepts a [`crate::Signal`] and one that accepts a [`crate::GlobalSignal`], you can create one function that accepts a [`Readable`] type.\n///\n/// # Example\n/// ```rust\n/// # use dioxus::prelude::*;\n/// fn double(something_readable: &impl Readable<Target = i32>) -> i32 {\n///     something_readable.cloned() * 2\n/// }\n///\n/// static COUNT: GlobalSignal<i32> = Signal::global(|| 0);\n///\n/// fn MyComponent(count: Signal<i32>) -> Element {\n///     // Since we defined the function in terms of the readable trait, we can use it with any readable type (Signal, GlobalSignal, ReadOnlySignal, etc)\n///     let doubled = use_memo(move || double(&count));\n///     let global_count_doubled = use_memo(|| double(&COUNT));\n///     rsx! {\n///         div {\n///             \"Count local: {count}\"\n///             \"Doubled local: {doubled}\"\n///             \"Count global: {COUNT}\"\n///             \"Doubled global: {global_count_doubled}\"\n///         }\n///     }\n/// }\n/// ```\npub trait Readable {\n    /// The target type of the reference.\n    type Target: ?Sized + 'static;\n\n    /// The type of the storage this readable uses.\n    type Storage: AnyStorage;\n\n    /// Map the readable type to a new type. This lets you provide a view into a readable type without needing to clone the inner value.\n    ///\n    /// Anything that subscribes to the readable value will be rerun whenever the original value changes, even if the view does not change. If you want to memorize the view, you can use a [`crate::Memo`] instead.\n    ///\n    /// # Example\n    /// ```rust\n    /// # use dioxus::prelude::*;\n    /// fn List(list: Signal<Vec<i32>>) -> Element {\n    ///     rsx! {\n    ///         for index in 0..list.len() {\n    ///             // We can use the `map` method to provide a view into the single item in the list that the child component will render\n    ///             Item { item: list.map(move |v| &v[index]) }\n    ///         }\n    ///     }\n    /// }\n    ///\n    /// // The child component doesn't need to know that the mapped value is coming from a list\n    /// #[component]\n    /// fn Item(item: MappedSignal<i32>) -> Element {\n    ///     rsx! {\n    ///         div { \"Item: {item}\" }\n    ///     }\n    /// }\n    /// ```\n    fn map<O>(self, f: impl Fn(&Self::Target) -> &O + 'static) -> MappedSignal<O, Self::Storage>\n    where\n        Self: Clone + Sized + 'static,\n    {\n        let mapping = Rc::new(f);\n        let try_read = Rc::new({\n            let self_ = self.clone();\n            let mapping = mapping.clone();\n            move || {\n                self_\n                    .try_read_unchecked()\n                    .map(|ref_| <Self::Storage as AnyStorage>::map(ref_, |r| mapping(r)))\n            }\n        })\n            as Rc<\n                dyn Fn() -> Result<ReadableRef<'static, Self, O>, generational_box::BorrowError>\n                    + 'static,\n            >;\n        let try_peek = Rc::new({\n            let self_ = self.clone();\n            let mapping = mapping.clone();\n            move || {\n                self_\n                    .try_peek_unchecked()\n                    .map(|ref_| <Self::Storage as AnyStorage>::map(ref_, |r| mapping(r)))\n            }\n        })\n            as Rc<\n                dyn Fn() -> Result<ReadableRef<'static, Self, O>, generational_box::BorrowError>\n                    + 'static,\n            >;\n        MappedSignal::new(try_read, try_peek)\n    }\n\n    /// Get the current value of the state. If this is a signal, this will subscribe the current scope to the signal.\n    /// If the value has been dropped, this will panic. Calling this on a Signal is the same as\n    /// using the signal() syntax to read and subscribe to its value\n    #[track_caller]\n    fn read(&self) -> ReadableRef<Self> {\n        self.try_read().unwrap()\n    }\n\n    /// Try to get the current value of the state. If this is a signal, this will subscribe the current scope to the signal.\n    #[track_caller]\n    fn try_read(&self) -> Result<ReadableRef<Self>, generational_box::BorrowError> {\n        self.try_read_unchecked()\n            .map(Self::Storage::downcast_lifetime_ref)\n    }\n\n    /// Get a reference to the value without checking the lifetime. This will subscribe the current scope to the signal.\n    ///\n    /// NOTE: This method is completely safe because borrow checking is done at runtime.\n    #[track_caller]\n    fn read_unchecked(&self) -> ReadableRef<'static, Self> {\n        self.try_read_unchecked().unwrap()\n    }\n\n    /// Try to get a reference to the value without checking the lifetime. This will subscribe the current scope to the signal.\n    ///\n    /// NOTE: This method is completely safe because borrow checking is done at runtime.\n    fn try_read_unchecked(\n        &self,\n    ) -> Result<ReadableRef<'static, Self>, generational_box::BorrowError>;\n\n    /// Get the current value of the state without subscribing to updates. If the value has been dropped, this will panic.\n    ///\n    /// # Example\n    /// ```rust\n    /// # use dioxus::prelude::*;\n    /// fn MyComponent(mut count: Signal<i32>) -> Element {\n    ///     let mut event_source = use_signal(|| None);\n    ///     let doubled = use_memo(move || {\n    ///         // We want to log the value of the event_source, but we don't need to rerun the doubled value if the event_source changes (because the value of doubled doesn't depend on the event_source)\n    ///         // We can read the value with peek without subscribing to updates\n    ///         let click_count = count.peek();\n    ///         tracing::info!(\"Click count: {click_count:?}\");\n    ///         count() * 2\n    ///     });\n    ///     rsx! {\n    ///         div { \"Count: {count}\" }\n    ///         div { \"Doubled: {doubled}\" }\n    ///         button {\n    ///             onclick: move |_| {\n    ///                 event_source.set(Some(\"Click me button\"));\n    ///             },\n    ///             \"Click me\"\n    ///         }\n    ///         button {\n    ///             onclick: move |_| {\n    ///                 event_source.set(Some(\"Double me button\"));\n    ///                 count += 1;\n    ///             },\n    ///             \"Double me\"\n    ///         }\n    ///     }\n    /// }\n    /// ```\n    #[track_caller]\n    fn peek(&self) -> ReadableRef<Self> {\n        Self::Storage::downcast_lifetime_ref(self.peek_unchecked())\n    }\n\n    /// Try to peek the current value of the signal without subscribing to updates. If the value has\n    /// been dropped, this will return an error.\n    #[track_caller]\n    fn try_peek(&self) -> Result<ReadableRef<Self>, generational_box::BorrowError> {\n        self.try_peek_unchecked()\n            .map(Self::Storage::downcast_lifetime_ref)\n    }\n\n    /// Get the current value of the signal without checking the lifetime. **Unlike read, this will not subscribe the current scope to the signal which can cause parts of your UI to not update.**\n    ///\n    /// If the signal has been dropped, this will panic.\n    #[track_caller]\n    fn peek_unchecked(&self) -> ReadableRef<'static, Self> {\n        self.try_peek_unchecked().unwrap()\n    }\n\n    /// Try to peek the current value of the signal without subscribing to updates. If the value has\n    /// been dropped, this will return an error.\n    ///\n    /// NOTE: This method is completely safe because borrow checking is done at runtime.\n    fn try_peek_unchecked(\n        &self,\n    ) -> Result<ReadableRef<'static, Self>, generational_box::BorrowError>;\n\n    /// Clone the inner value and return it. If the value has been dropped, this will panic.\n    #[track_caller]\n    fn cloned(&self) -> Self::Target\n    where\n        Self::Target: Clone,\n    {\n        self.read().clone()\n    }\n\n    /// Run a function with a reference to the value. If the value has been dropped, this will panic.\n    #[track_caller]\n    fn with<O>(&self, f: impl FnOnce(&Self::Target) -> O) -> O {\n        f(&*self.read())\n    }\n\n    /// Run a function with a reference to the value. If the value has been dropped, this will panic.\n    #[track_caller]\n    fn with_peek<O>(&self, f: impl FnOnce(&Self::Target) -> O) -> O {\n        f(&*self.peek())\n    }\n\n    /// Index into the inner value and return a reference to the result. If the value has been dropped or the index is invalid, this will panic.\n    #[track_caller]\n    fn index<I>(&self, index: I) -> ReadableRef<Self, <Self::Target as std::ops::Index<I>>::Output>\n    where\n        Self::Target: std::ops::Index<I>,\n    {\n        <Self::Storage as AnyStorage>::map(self.read(), |v| v.index(index))\n    }\n\n    /// SAFETY: You must call this function directly with `self` as the argument.\n    /// This function relies on the size of the object you return from the deref\n    /// being the same as the object you pass in\n    #[doc(hidden)]\n    unsafe fn deref_impl<'a>(&self) -> &'a dyn Fn() -> Self::Target\n    where\n        Self: Sized + 'a,\n        Self::Target: Clone,\n    {\n        // https://github.com/dtolnay/case-studies/tree/master/callable-types\n\n        // First we create a closure that captures something with the Same in memory layout as Self (MaybeUninit<Self>).\n        let uninit_callable = MaybeUninit::<Self>::uninit();\n        // Then move that value into the closure. We assume that the closure now has a in memory layout of Self.\n        let uninit_closure = move || Self::read(unsafe { &*uninit_callable.as_ptr() }).clone();\n\n        // Check that the size of the closure is the same as the size of Self in case the compiler changed the layout of the closure.\n        let size_of_closure = std::mem::size_of_val(&uninit_closure);\n        assert_eq!(size_of_closure, std::mem::size_of::<Self>());\n\n        // Then cast the lifetime of the closure to the lifetime of &self.\n        fn cast_lifetime<'a, T>(_a: &T, b: &'a T) -> &'a T {\n            b\n        }\n        let reference_to_closure = cast_lifetime(\n            {\n                // The real closure that we will never use.\n                &uninit_closure\n            },\n            #[allow(clippy::missing_transmute_annotations)]\n            // We transmute self into a reference to the closure. This is safe because we know that the closure has the same memory layout as Self so &Closure == &Self.\n            unsafe {\n                std::mem::transmute(self)\n            },\n        );\n\n        // Cast the closure to a trait object.\n        reference_to_closure as &_\n    }\n}\n\n/// An extension trait for Readable<Vec<T>> that provides some convenience methods.\npub trait ReadableVecExt<T: 'static>: Readable<Target = Vec<T>> {\n    /// Returns the length of the inner vector.\n    #[track_caller]\n    fn len(&self) -> usize {\n        self.with(|v| v.len())\n    }\n\n    /// Returns true if the inner vector is empty.\n    #[track_caller]\n    fn is_empty(&self) -> bool {\n        self.with(|v| v.is_empty())\n    }\n\n    /// Get the first element of the inner vector.\n    #[track_caller]\n    fn first(&self) -> Option<ReadableRef<Self, T>> {\n        <Self::Storage as AnyStorage>::try_map(self.read(), |v| v.first())\n    }\n\n    /// Get the last element of the inner vector.\n    #[track_caller]\n    fn last(&self) -> Option<ReadableRef<Self, T>> {\n        <Self::Storage as AnyStorage>::try_map(self.read(), |v| v.last())\n    }\n\n    /// Get the element at the given index of the inner vector.\n    #[track_caller]\n    fn get(&self, index: usize) -> Option<ReadableRef<Self, T>> {\n        <Self::Storage as AnyStorage>::try_map(self.read(), |v| v.get(index))\n    }\n\n    /// Get an iterator over the values of the inner vector.\n    #[track_caller]\n    fn iter(&self) -> ReadableValueIterator<'_, Self>\n    where\n        Self: Sized,\n    {\n        ReadableValueIterator {\n            index: 0,\n            value: self,\n        }\n    }\n}\n\n/// An iterator over the values of a `Readable<Vec<T>>`.\npub struct ReadableValueIterator<'a, R> {\n    index: usize,\n    value: &'a R,\n}\n\nimpl<'a, T: 'static, R: Readable<Target = Vec<T>>> Iterator for ReadableValueIterator<'a, R> {\n    type Item = ReadableRef<'a, R, T>;\n\n    fn next(&mut self) -> Option<Self::Item> {\n        let index = self.index;\n        self.index += 1;\n        self.value.get(index)\n    }\n}\n\nimpl<T, R> ReadableVecExt<T> for R\nwhere\n    T: 'static,\n    R: Readable<Target = Vec<T>>,\n{\n}\n\n/// An extension trait for Readable<Option<T>> that provides some convenience methods.\npub trait ReadableOptionExt<T: 'static>: Readable<Target = Option<T>> {\n    /// Unwraps the inner value and clones it.\n    #[track_caller]\n    fn unwrap(&self) -> T\n    where\n        T: Clone,\n    {\n        self.as_ref().unwrap().clone()\n    }\n\n    /// Attempts to read the inner value of the Option.\n    #[track_caller]\n    fn as_ref(&self) -> Option<ReadableRef<Self, T>> {\n        <Self::Storage as AnyStorage>::try_map(self.read(), |v| v.as_ref())\n    }\n}\n\nimpl<T, R> ReadableOptionExt<T> for R\nwhere\n    T: 'static,\n    R: Readable<Target = Option<T>>,\n{\n}\n\n/// An extension trait for Readable<Option<T>> that provides some convenience methods.\npub trait ReadableResultExt<T: 'static, E: 'static>: Readable<Target = Result<T, E>> {\n    /// Unwraps the inner value and clones it.\n    #[track_caller]\n    fn unwrap(&self) -> T\n    where\n        T: Clone,\n    {\n        self.as_ref()\n            .unwrap_or_else(|_| panic!(\"Tried to unwrap a Result that was an error\"))\n            .clone()\n    }\n\n    /// Attempts to read the inner value of the Option.\n    #[track_caller]\n    fn as_ref(&self) -> Result<ReadableRef<Self, T>, ReadableRef<Self, E>> {\n        <Self::Storage as AnyStorage>::try_map(self.read(), |v| v.as_ref().ok()).ok_or(\n            <Self::Storage as AnyStorage>::map(self.read(), |v| v.as_ref().err().unwrap()),\n        )\n    }\n}\n\nimpl<T, E, R> ReadableResultExt<T, E> for R\nwhere\n    T: 'static,\n    E: 'static,\n    R: Readable<Target = Result<T, E>>,\n{\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "cd6dc731c719fe4bc47517dcc4079a12f50d61d3",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/packages/signals/src/props.rs",
    "func": "use crate::{ReadOnlySignal, Signal};\nuse dioxus_core::prelude::*;\n\n#[doc(hidden)]\npub struct SignalFromMarker<M>(std::marker::PhantomData<M>);\n\nimpl<T, O, M> SuperFrom<T, SignalFromMarker<M>> for ReadOnlySignal<O>\nwhere\n    O: SuperFrom<T, M>,\n{\n    fn super_from(input: T) -> Self {\n        ReadOnlySignal::new(Signal::new(O::super_from(input)))\n    }\n}\n\n#[test]\n#[allow(unused)]\nfn into_signal_compiles() {\n    fn takes_signal_string<M>(_: impl SuperInto<ReadOnlySignal<String>, M>) {}\n\n    fn takes_option_signal_string<M>(_: impl SuperInto<ReadOnlySignal<Option<String>>, M>) {}\n\n    fn don_t_run() {\n        takes_signal_string(\"hello world\");\n        takes_signal_string(Signal::new(String::from(\"hello world\")));\n        takes_option_signal_string(\"hello world\");\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "953ae26028b9efd0bfeec3fa8fdf9a834700ed07",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/packages/web/src/events/focus.rs",
    "func": "use dioxus_html::HasFocusData;\n\nuse super::{Synthetic, WebEventExt};\n\nimpl HasFocusData for Synthetic<web_sys::FocusEvent> {\n    fn as_any(&self) -> &dyn std::any::Any {\n        &self.event\n    }\n}\n\nimpl WebEventExt for dioxus_html::FocusData {\n    type WebEvent = web_sys::FocusEvent;\n\n    #[inline(always)]\n    fn try_as_web_event(&self) -> Option<Self::WebEvent> {\n        self.downcast::<web_sys::FocusEvent>().cloned()\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "270ca396173c98224fb85f68f2ace04d30f9a959",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/packages/web/src/events/file.rs",
    "func": "use dioxus_html::HasFileData;\n\nuse super::Synthetic;\n\nimpl HasFileData for Synthetic<web_sys::Event> {\n    #[cfg(feature = \"file_engine\")]\n    fn files(&self) -> Option<std::sync::Arc<dyn dioxus_html::FileEngine>> {\n        use wasm_bindgen::JsCast;\n\n        let files = self\n            .event\n            .dyn_ref()\n            .and_then(|input: &web_sys::HtmlInputElement| {\n                input.files().and_then(|files| {\n                    #[allow(clippy::arc_with_non_send_sync)]\n                    crate::file_engine::WebFileEngine::new(files).map(|f| {\n                        std::sync::Arc::new(f) as std::sync::Arc<dyn dioxus_html::FileEngine>\n                    })\n                })\n            });\n\n        files\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "7076bd78f5423382bd81b93fa3f1ef6c2cbd174f",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/packages/web/src/events/media.rs",
    "func": "use super::{Synthetic, WebEventExt};\nuse dioxus_html::HasMediaData;\n\nimpl HasMediaData for Synthetic<web_sys::Event> {\n    fn as_any(&self) -> &dyn std::any::Any {\n        &self.event\n    }\n}\n\nimpl WebEventExt for dioxus_html::MediaData {\n    type WebEvent = web_sys::Event;\n\n    #[inline(always)]\n    fn try_as_web_event(&self) -> Option<Self::WebEvent> {\n        self.downcast::<web_sys::Event>().cloned()\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "0ac1981037f2bfad2c9378c7999652b2101c4ace",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/packages/core/tests/task.rs",
    "func": "//! Verify that tasks get polled by the virtualdom properly, and that we escape wait_for_work safely\n\nuse std::{sync::atomic::AtomicUsize, time::Duration};\n\nuse dioxus::prelude::*;\n\nasync fn run_vdom(app: fn() -> Element) {\n    let mut dom = VirtualDom::new(app);\n\n    dom.rebuild(&mut dioxus_core::NoOpMutations);\n\n    tokio::select! {\n        _ = dom.wait_for_work() => {}\n        _ = tokio::time::sleep(Duration::from_millis(500)) => {}\n    };\n}\n\n#[tokio::test]\nasync fn running_async() {\n    static POLL_COUNT: AtomicUsize = AtomicUsize::new(0);\n\n    fn app() -> Element {\n        use_hook(|| {\n            spawn(async {\n                for x in 0..10 {\n                    tokio::time::sleep(Duration::from_micros(50)).await;\n                    POLL_COUNT.fetch_add(x, std::sync::atomic::Ordering::Relaxed);\n                }\n            });\n\n            spawn(async {\n                for x in 0..10 {\n                    tokio::time::sleep(Duration::from_micros(25)).await;\n                    POLL_COUNT.fetch_add(x * 2, std::sync::atomic::Ordering::Relaxed);\n                }\n            });\n        });\n\n        rsx!({})\n    }\n\n    run_vdom(app).await;\n\n    // By the time the tasks are finished, we should've accumulated ticks from two tasks\n    // Be warned that by setting the delay to too short, tokio might not schedule in the tasks\n    assert_eq!(\n        POLL_COUNT.fetch_add(0, std::sync::atomic::Ordering::Relaxed),\n        135\n    );\n}\n\n#[tokio::test]\nasync fn spawn_forever_persists() {\n    use std::sync::atomic::Ordering;\n    static POLL_COUNT: AtomicUsize = AtomicUsize::new(0);\n\n    fn app() -> Element {\n        if generation() > 0 {\n            rsx!(div {})\n        } else {\n            needs_update();\n            rsx!(Child {})\n        }\n    }\n\n    #[component]\n    fn Child() -> Element {\n        spawn_forever(async move {\n            for _ in 0..10 {\n                POLL_COUNT.fetch_add(1, Ordering::Relaxed);\n                tokio::time::sleep(Duration::from_millis(50)).await;\n            }\n        });\n\n        rsx!(div {})\n    }\n\n    let mut dom = VirtualDom::new(app);\n\n    dom.rebuild(&mut dioxus_core::NoOpMutations);\n    dom.render_immediate(&mut dioxus_core::NoOpMutations);\n\n    tokio::select! {\n        _ = dom.wait_for_work() => {}\n        // We intentionally wait a bit longer than 50ms*10 to make sure the test has time to finish\n        // Without the extra time, the test can fail on windows\n        _ = tokio::time::sleep(Duration::from_millis(1000)) => {}\n    };\n\n    // By the time the tasks are finished, we should've accumulated ticks from two tasks\n    // Be warned that by setting the delay to too short, tokio might not schedule in the tasks\n    assert_eq!(POLL_COUNT.load(Ordering::Relaxed), 10);\n}\n\n/// Prove that yield_now doesn't cause a deadlock\n#[tokio::test]\nasync fn yield_now_works() {\n    thread_local! {\n        static SEQUENCE: std::cell::RefCell<Vec<usize>> = const { std::cell::RefCell::new(Vec::new()) };\n    }\n\n    fn app() -> Element {\n        // these two tasks should yield to eachother\n        use_hook(|| {\n            spawn(async move {\n                for _ in 0..10 {\n                    tokio::task::yield_now().await;\n                    SEQUENCE.with(|s| s.borrow_mut().push(1));\n                }\n            })\n        });\n\n        use_hook(|| {\n            spawn(async move {\n                for _ in 0..10 {\n                    tokio::task::yield_now().await;\n                    SEQUENCE.with(|s| s.borrow_mut().push(2));\n                }\n            })\n        });\n\n        rsx!({})\n    }\n\n    run_vdom(app).await;\n\n    SEQUENCE.with(|s| assert_eq!(s.borrow().len(), 20));\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "4380c45fceae61c83a5d6e31175768344342cecb",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/packages/core/tests/fuzzing.rs",
    "func": "#![cfg(not(miri))]\n\nuse dioxus::prelude::*;\nuse dioxus_core::{AttributeValue, DynamicNode, NoOpMutations, Template, VComponent, VNode, *};\nuse std::{any::Any, cell::RefCell, cfg, collections::HashSet, default::Default, rc::Rc};\n\nfn random_ns() -> Option<&'static str> {\n    let namespace = rand::random::<u8>() % 2;\n    match namespace {\n        0 => None,\n        1 => Some(Box::leak(\n            format!(\"ns{}\", rand::random::<usize>()).into_boxed_str(),\n        )),\n        _ => unreachable!(),\n    }\n}\n\nfn create_random_attribute(attr_idx: &mut usize) -> TemplateAttribute {\n    match rand::random::<u8>() % 2 {\n        0 => TemplateAttribute::Static {\n            name: Box::leak(format!(\"attr{}\", rand::random::<usize>()).into_boxed_str()),\n            value: Box::leak(format!(\"value{}\", rand::random::<usize>()).into_boxed_str()),\n            namespace: random_ns(),\n        },\n        1 => TemplateAttribute::Dynamic {\n            id: {\n                let old_idx = *attr_idx;\n                *attr_idx += 1;\n                old_idx\n            },\n        },\n        _ => unreachable!(),\n    }\n}\n\nfn create_random_template_node(\n    dynamic_node_types: &mut Vec<DynamicNodeType>,\n    template_idx: &mut usize,\n    attr_idx: &mut usize,\n    depth: usize,\n) -> TemplateNode {\n    match rand::random::<u8>() % 4 {\n        0 => {\n            let attrs = {\n                let attrs: Vec<_> = (0..(rand::random::<usize>() % 10))\n                    .map(|_| create_random_attribute(attr_idx))\n                    .collect();\n                Box::leak(attrs.into_boxed_slice())\n            };\n            TemplateNode::Element {\n                tag: Box::leak(format!(\"tag{}\", rand::random::<usize>()).into_boxed_str()),\n                namespace: random_ns(),\n                attrs,\n                children: {\n                    if depth > 4 {\n                        &[]\n                    } else {\n                        let children: Vec<_> = (0..(rand::random::<usize>() % 3))\n                            .map(|_| {\n                                create_random_template_node(\n                                    dynamic_node_types,\n                                    template_idx,\n                                    attr_idx,\n                                    depth + 1,\n                                )\n                            })\n                            .collect();\n                        Box::leak(children.into_boxed_slice())\n                    }\n                },\n            }\n        }\n        1 => TemplateNode::Text {\n            text: Box::leak(format!(\"{}\", rand::random::<usize>()).into_boxed_str()),\n        },\n        2 => TemplateNode::Dynamic {\n            id: {\n                let old_idx = *template_idx;\n                *template_idx += 1;\n                dynamic_node_types.push(DynamicNodeType::Text);\n                old_idx\n            },\n        },\n        3 => TemplateNode::Dynamic {\n            id: {\n                let old_idx = *template_idx;\n                *template_idx += 1;\n                dynamic_node_types.push(DynamicNodeType::Other);\n                old_idx\n            },\n        },\n        _ => unreachable!(),\n    }\n}\n\nfn generate_paths(\n    node: &TemplateNode,\n    current_path: &[u8],\n    node_paths: &mut Vec<Vec<u8>>,\n    attr_paths: &mut Vec<Vec<u8>>,\n) {\n    match node {\n        TemplateNode::Element { children, attrs, .. } => {\n            for attr in *attrs {\n                match attr {\n                    TemplateAttribute::Static { .. } => {}\n                    TemplateAttribute::Dynamic { .. } => {\n                        attr_paths.push(current_path.to_vec());\n                    }\n                }\n            }\n            for (i, child) in children.iter().enumerate() {\n                let mut current_path = current_path.to_vec();\n                current_path.push(i as u8);\n                generate_paths(child, &current_path, node_paths, attr_paths);\n            }\n        }\n        TemplateNode::Text { .. } => {}\n        TemplateNode::Dynamic { .. } => {\n            node_paths.push(current_path.to_vec());\n        }\n    }\n}\n\nenum DynamicNodeType {\n    Text,\n    Other,\n}\n\nfn create_random_template(depth: usize) -> (Template, Box<[DynamicNode]>) {\n    let mut dynamic_node_types = Vec::new();\n    let mut template_idx = 0;\n    let mut attr_idx = 0;\n    let roots = (0..(1 + rand::random::<usize>() % 5))\n        .map(|_| {\n            create_random_template_node(\n                &mut dynamic_node_types,\n                &mut template_idx,\n                &mut attr_idx,\n                0,\n            )\n        })\n        .collect::<Vec<_>>();\n    assert!(!roots.is_empty());\n    let roots = Box::leak(roots.into_boxed_slice());\n    let mut node_paths = Vec::new();\n    let mut attr_paths = Vec::new();\n    for (i, root) in roots.iter().enumerate() {\n        generate_paths(root, &[i as u8], &mut node_paths, &mut attr_paths);\n    }\n    let node_paths = Box::leak(\n        node_paths\n            .into_iter()\n            .map(|v| &*Box::leak(v.into_boxed_slice()))\n            .collect::<Vec<_>>()\n            .into_boxed_slice(),\n    );\n    let attr_paths = Box::leak(\n        attr_paths\n            .into_iter()\n            .map(|v| &*Box::leak(v.into_boxed_slice()))\n            .collect::<Vec<_>>()\n            .into_boxed_slice(),\n    );\n    let dynamic_nodes = dynamic_node_types\n        .iter()\n        .map(|ty| match ty {\n            DynamicNodeType::Text => {\n                DynamicNode::Text(VText::new(format!(\"{}\", rand::random::<usize>())))\n            }\n            DynamicNodeType::Other => create_random_dynamic_node(depth + 1),\n        })\n        .collect();\n    (Template { roots, node_paths, attr_paths }, dynamic_nodes)\n}\n\nfn create_random_dynamic_node(depth: usize) -> DynamicNode {\n    let range = if depth > 5 { 1 } else { 3 };\n    match rand::random::<u8>() % range {\n        0 => DynamicNode::Placeholder(Default::default()),\n        1 => (0..(rand::random::<u8>() % 5))\n            .map(|_| {\n                VNode::new(\n                    None,\n                    Template {\n                        roots: &[TemplateNode::Dynamic { id: 0 }],\n                        node_paths: &[&[0]],\n                        attr_paths: &[],\n                    },\n                    Box::new([DynamicNode::Component(VComponent::new(\n                        create_random_element,\n                        DepthProps { depth, root: false },\n                        \"create_random_element\",\n                    ))]),\n                    Box::new([]),\n                )\n            })\n            .into_dyn_node(),\n        2 => DynamicNode::Component(VComponent::new(\n            create_random_element,\n            DepthProps { depth, root: false },\n            \"create_random_element\",\n        )),\n        _ => unreachable!(),\n    }\n}\n\nfn create_random_dynamic_attr() -> Attribute {\n    let value = match rand::random::<u8>() % 7 {\n        0 => AttributeValue::Text(format!(\"{}\", rand::random::<usize>())),\n        1 => AttributeValue::Float(rand::random()),\n        2 => AttributeValue::Int(rand::random()),\n        3 => AttributeValue::Bool(rand::random()),\n        4 => AttributeValue::any_value(rand::random::<usize>()),\n        5 => AttributeValue::None,\n        6 => {\n            let value = AttributeValue::listener(|e: Event<String>| println!(\"{:?}\", e));\n            return Attribute::new(\"ondata\", value, None, false);\n        }\n        _ => unreachable!(),\n    };\n    Attribute::new(\n        Box::leak(format!(\"attr{}\", rand::random::<usize>()).into_boxed_str()),\n        value,\n        random_ns(),\n        rand::random(),\n    )\n}\n\n#[derive(PartialEq, Props, Clone)]\nstruct DepthProps {\n    depth: usize,\n    root: bool,\n}\n\nfn create_random_element(cx: DepthProps) -> Element {\n    let last_template = use_hook(|| Rc::new(RefCell::new(None)));\n    if rand::random::<usize>() % 10 == 0 {\n        needs_update();\n    }\n    let range = if cx.root { 2 } else { 3 };\n    let node = match rand::random::<usize>() % range {\n        // Change both the template and the dynamic nodes\n        0 => {\n            let (template, dynamic_nodes) = create_random_template(cx.depth + 1);\n            last_template.replace(Some(template));\n            VNode::new(\n                None,\n                template,\n                dynamic_nodes,\n                (0..template.attr_paths.len())\n                    .map(|_| Box::new([create_random_dynamic_attr()]) as Box<[Attribute]>)\n                    .collect(),\n            )\n        }\n        // Change just the dynamic nodes\n        1 => {\n            let (template, dynamic_nodes) = match *last_template.borrow() {\n                Some(template) => (\n                    template,\n                    (0..template.node_paths.len())\n                        .map(|_| create_random_dynamic_node(cx.depth + 1))\n                        .collect(),\n                ),\n                None => create_random_template(cx.depth + 1),\n            };\n            VNode::new(\n                None,\n                template,\n                dynamic_nodes,\n                (0..template.attr_paths.len())\n                    .map(|_| Box::new([create_random_dynamic_attr()]) as Box<[Attribute]>)\n                    .collect(),\n            )\n        }\n        // Remove the template\n        _ => VNode::default(),\n    };\n    Element::Ok(node)\n}\n\n// test for panics when creating random nodes and templates\n#[test]\nfn create() {\n    let repeat_count = if cfg!(miri) { 100 } else { 1000 };\n    for _ in 0..repeat_count {\n        let mut vdom =\n            VirtualDom::new_with_props(create_random_element, DepthProps { depth: 0, root: true });\n        vdom.rebuild(&mut NoOpMutations);\n    }\n}\n\n// test for panics when diffing random nodes\n// This test will change the template every render which is not very realistic, but it helps stress the system\n#[test]\nfn diff() {\n    let repeat_count = if cfg!(miri) { 100 } else { 1000 };\n    for _ in 0..repeat_count {\n        let mut vdom =\n            VirtualDom::new_with_props(create_random_element, DepthProps { depth: 0, root: true });\n        vdom.rebuild(&mut NoOpMutations);\n        // A list of all elements that have had event listeners\n        // This is intentionally never cleared, so that we can test that calling event listeners that are removed doesn't cause a panic\n        let mut event_listeners = HashSet::new();\n        for _ in 0..100 {\n            for &id in &event_listeners {\n                println!(\"firing event on {:?}\", id);\n                let event = Event::new(\n                    std::rc::Rc::new(String::from(\"hello world\")) as Rc<dyn Any>,\n                    true,\n                );\n                vdom.runtime().handle_event(\"data\", event, id);\n            }\n            {\n                vdom.render_immediate(&mut InsertEventListenerMutationHandler(\n                    &mut event_listeners,\n                ));\n            }\n        }\n    }\n}\n\nstruct InsertEventListenerMutationHandler<'a>(&'a mut HashSet<ElementId>);\n\nimpl WriteMutations for InsertEventListenerMutationHandler<'_> {\n    fn append_children(&mut self, _: ElementId, _: usize) {}\n\n    fn assign_node_id(&mut self, _: &'static [u8], _: ElementId) {}\n\n    fn create_placeholder(&mut self, _: ElementId) {}\n\n    fn create_text_node(&mut self, _: &str, _: ElementId) {}\n\n    fn load_template(&mut self, _: Template, _: usize, _: ElementId) {}\n\n    fn replace_node_with(&mut self, _: ElementId, _: usize) {}\n\n    fn replace_placeholder_with_nodes(&mut self, _: &'static [u8], _: usize) {}\n\n    fn insert_nodes_after(&mut self, _: ElementId, _: usize) {}\n\n    fn insert_nodes_before(&mut self, _: ElementId, _: usize) {}\n\n    fn set_attribute(\n        &mut self,\n        _: &'static str,\n        _: Option<&'static str>,\n        _: &AttributeValue,\n        _: ElementId,\n    ) {\n    }\n\n    fn set_node_text(&mut self, _: &str, _: ElementId) {}\n\n    fn create_event_listener(&mut self, name: &'static str, id: ElementId) {\n        println!(\"new event listener on {:?} for {:?}\", id, name);\n        self.0.insert(id);\n    }\n\n    fn remove_event_listener(&mut self, _: &'static str, _: ElementId) {}\n\n    fn remove_node(&mut self, _: ElementId) {}\n\n    fn push_root(&mut self, _: ElementId) {}\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "7bb93fd197a0a53950c2da36d9cfe735ed4c2331",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/packages/core/tests/kitchen_sink.rs",
    "func": "use dioxus::dioxus_core::{ElementId, Mutation};\nuse dioxus::prelude::*;\nuse pretty_assertions::assert_eq;\n\nfn basic_syntax_is_a_template() -> Element {\n    let asd = 123;\n    let var = 123;\n\n    rsx! {\n        div {\n            key: \"{asd}\",\n            class: \"asd\",\n            class: \"{asd}\",\n            class: if true { \"{asd}\" },\n            class: if false { \"{asd}\" },\n            onclick: move |_| {},\n            div { \"{var}\" }\n            div {\n                h1 { \"var\" }\n                p { \"you're great!\" }\n                div { background_color: \"red\",\n                    h1 { \"var\" }\n                    div {\n                        b { \"asd\" }\n                        \"not great\"\n                    }\n                }\n                p { \"you're great!\" }\n            }\n        }\n    }\n}\n\n#[test]\nfn dual_stream() {\n    let mut dom = VirtualDom::new(basic_syntax_is_a_template);\n    let edits = dom.rebuild_to_vec();\n\n    use Mutation::*;\n    assert_eq!(edits.edits, {\n        [\n            LoadTemplate { index: 0, id: ElementId(1) },\n            SetAttribute {\n                name: \"class\",\n                value: \"asd 123 123 \".into_value(),\n                id: ElementId(1),\n                ns: None,\n            },\n            NewEventListener { name: \"click\".to_string(), id: ElementId(1) },\n            CreateTextNode { value: \"123\".to_string(), id: ElementId(2) },\n            ReplacePlaceholder { path: &[0, 0], m: 1 },\n            AppendChildren { id: ElementId(0), m: 1 },\n        ]\n    });\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "24f9299fbed67a6c2b77ff4527f017a151d643ba",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/packages/core/src/mutations.rs",
    "func": "use crate::{arena::ElementId, AttributeValue, Template};\n\n/// Something that can handle the mutations that are generated by the diffing process and apply them to the Real DOM\n///\n/// This object provides a bunch of important information for a renderer to use patch the Real Dom with the state of the\n/// VirtualDom. This includes the scopes that were modified, the templates that were discovered, and a list of changes\n/// in the form of a [`Mutation`].\n///\n/// These changes are specific to one subtree, so to patch multiple subtrees, you'd need to handle each set separately.\n///\n/// Templates, however, apply to all subtrees, not just target subtree.\n///\n/// Mutations are the only link between the RealDOM and the VirtualDOM.\npub trait WriteMutations {\n    /// Add these m children to the target element\n    ///\n    /// Id: The ID of the element being mounted to\n    /// M: The number of nodes on the stack to append to the target element\n    fn append_children(&mut self, id: ElementId, m: usize);\n\n    /// Assign the element at the given path the target ElementId.\n    ///\n    /// The path is in the form of a list of indices based on children. Templates cannot have more than 255 children per\n    /// element, hence the use of a single byte.\n    ///\n    /// Path: The path of the child of the topmost node on the stack. A path of `[]` represents the topmost node. A path of `[0]` represents the first child. `[0,1,2]` represents 1st child's 2nd child's 3rd child.\n    /// Id: The ID we're assigning to this element/placeholder. This will be used later to modify the element or replace it with another element.\n    fn assign_node_id(&mut self, path: &'static [u8], id: ElementId);\n\n    /// Create a placeholder in the DOM that we will use later.\n    ///\n    /// Dioxus currently requires the use of placeholders to maintain a re-entrance point for things like list diffing\n    ///\n    /// Id: The ID we're assigning to this element/placeholder. This will be used later to modify the element or replace it with another element.\n    fn create_placeholder(&mut self, id: ElementId);\n\n    /// Create a node specifically for text with the given value\n    ///\n    /// Value: The text content of this text node\n    /// Id: The ID we're assigning to this specific text nodes. This will be used later to modify the element or replace it with another element.\n    fn create_text_node(&mut self, value: &str, id: ElementId);\n\n    /// Load and clone an existing node from a template saved under that specific name\n    ///\n    /// Dioxus guarantees that the renderer will have already been provided the template.\n    /// When the template is picked up in the template list, it should be saved under its \"name\" - here, the name\n    ///\n    /// Name: The unique \"name\" of the template based on the template location. When paired with `rsx!`, this is autogenerated\n    /// Index: The index root we loading from the template. The template is stored as a list of nodes. This index represents the position of that root\n    /// Id: The ID we're assigning to this element being loaded from the template (This will be used later to move the element around in lists)\n    fn load_template(&mut self, template: Template, index: usize, id: ElementId);\n\n    /// Replace the target element (given by its ID) with the topmost m nodes on the stack\n    ///\n    /// id: The ID of the node we're going to replace with new nodes\n    /// m: The number of nodes on the stack to replace the target element with\n    fn replace_node_with(&mut self, id: ElementId, m: usize);\n\n    /// Replace an existing element in the template at the given path with the m nodes on the stack\n    ///\n    /// Path: The path of the child of the topmost node on the stack. A path of `[]` represents the topmost node. A path of `[0]` represents the first child. `[0,1,2]` represents 1st child's 2nd child's 3rd child.\n    /// M: The number of nodes on the stack to replace the target element with\n    fn replace_placeholder_with_nodes(&mut self, path: &'static [u8], m: usize);\n\n    /// Insert a number of nodes after a given node.\n    ///\n    /// Id: The ID of the node to insert after.\n    /// M: The number of nodes on the stack to insert after the target node.\n    fn insert_nodes_after(&mut self, id: ElementId, m: usize);\n\n    /// Insert a number of nodes before a given node.\n    ///\n    /// Id: The ID of the node to insert before.\n    /// M: The number of nodes on the stack to insert before the target node.\n    fn insert_nodes_before(&mut self, id: ElementId, m: usize);\n\n    /// Set the value of a node's attribute.\n    ///\n    /// Name: The name of the attribute to set.\n    /// NS: The (optional) namespace of the attribute. For instance, \"style\" is in the \"style\" namespace.\n    /// Value: The value of the attribute.\n    /// Id: The ID of the node to set the attribute of.\n    fn set_attribute(\n        &mut self,\n        name: &'static str,\n        ns: Option<&'static str>,\n        value: &AttributeValue,\n        id: ElementId,\n    );\n\n    /// Set the text content of a node.\n    ///\n    /// Value: The textcontent of the node\n    /// Id: The ID of the node to set the textcontent of.\n    fn set_node_text(&mut self, value: &str, id: ElementId);\n\n    /// Create a new Event Listener.\n    ///\n    /// Name: The name of the event to listen for.\n    /// Id: The ID of the node to attach the listener to.\n    fn create_event_listener(&mut self, name: &'static str, id: ElementId);\n\n    /// Remove an existing Event Listener.\n    ///\n    /// Name: The name of the event to remove.\n    /// Id: The ID of the node to remove.\n    fn remove_event_listener(&mut self, name: &'static str, id: ElementId);\n\n    /// Remove a particular node from the DOM\n    ///\n    /// Id: The ID of the node to remove.\n    fn remove_node(&mut self, id: ElementId);\n\n    /// Push the given root node onto our stack.\n    ///\n    /// Id: The ID of the root node to push.\n    fn push_root(&mut self, id: ElementId);\n}\n\n/// A `Mutation` represents a single instruction for the renderer to use to modify the UI tree to match the state\n/// of the Dioxus VirtualDom.\n///\n/// These edits can be serialized and sent over the network or through any interface\n#[derive(Debug, PartialEq)]\npub enum Mutation {\n    /// Add these m children to the target element\n    AppendChildren {\n        /// The ID of the element being mounted to\n        id: ElementId,\n\n        /// The number of nodes on the stack to append to the target element\n        m: usize,\n    },\n\n    /// Assign the element at the given path the target ElementId.\n    ///\n    /// The path is in the form of a list of indices based on children. Templates cannot have more than 255 children per\n    /// element, hence the use of a single byte.\n    AssignId {\n        /// The path of the child of the topmost node on the stack\n        ///\n        /// A path of `[]` represents the topmost node. A path of `[0]` represents the first child.\n        /// `[0,1,2]` represents 1st child's 2nd child's 3rd child.\n        path: &'static [u8],\n\n        /// The ID we're assigning to this element/placeholder.\n        ///\n        /// This will be used later to modify the element or replace it with another element.\n        id: ElementId,\n    },\n\n    /// Create a placeholder in the DOM that we will use later.\n    ///\n    /// Dioxus currently requires the use of placeholders to maintain a re-entrance point for things like list diffing\n    CreatePlaceholder {\n        /// The ID we're assigning to this element/placeholder.\n        ///\n        /// This will be used later to modify the element or replace it with another element.\n        id: ElementId,\n    },\n\n    /// Create a node specifically for text with the given value\n    CreateTextNode {\n        /// The text content of this text node\n        value: String,\n\n        /// The ID we're assigning to this specific text nodes\n        ///\n        /// This will be used later to modify the element or replace it with another element.\n        id: ElementId,\n    },\n\n    /// Load and clone an existing node from a template with a given ID\n    ///\n    /// Dioxus guarantees that the renderer will have already been provided the template.\n    /// When the template is picked up in the template list, it should be saved under its \"name\" - here, the name\n    LoadTemplate {\n        /// Which root are we loading from the template?\n        ///\n        /// The template is stored as a list of nodes. This index represents the position of that root\n        index: usize,\n\n        /// The ID we're assigning to this element being loaded from the template\n        ///\n        /// This will be used later to move the element around in lists\n        id: ElementId,\n    },\n\n    /// Replace the target element (given by its ID) with the topmost m nodes on the stack\n    ReplaceWith {\n        /// The ID of the node we're going to replace with\n        id: ElementId,\n\n        /// The number of nodes on the stack to replace the target element with\n        m: usize,\n    },\n\n    /// Replace an existing element in the template at the given path with the m nodes on the stack\n    ReplacePlaceholder {\n        /// The path of the child of the topmost node on the stack\n        ///\n        /// A path of `[]` represents the topmost node. A path of `[0]` represents the first child.\n        /// `[0,1,2]` represents 1st child's 2nd child's 3rd child.\n        path: &'static [u8],\n\n        /// The number of nodes on the stack to replace the target element with\n        m: usize,\n    },\n\n    /// Insert a number of nodes after a given node.\n    InsertAfter {\n        /// The ID of the node to insert after.\n        id: ElementId,\n\n        /// The number of nodes on the stack to insert after the target node.\n        m: usize,\n    },\n\n    /// Insert a number of nodes before a given node.\n    InsertBefore {\n        /// The ID of the node to insert before.\n        id: ElementId,\n\n        /// The number of nodes on the stack to insert before the target node.\n        m: usize,\n    },\n\n    /// Set the value of a node's attribute.\n    SetAttribute {\n        /// The name of the attribute to set.\n        name: &'static str,\n\n        /// The (optional) namespace of the attribute.\n        /// For instance, \"style\" is in the \"style\" namespace.\n        ns: Option<&'static str>,\n\n        /// The value of the attribute.\n        value: AttributeValue,\n\n        /// The ID of the node to set the attribute of.\n        id: ElementId,\n    },\n\n    /// Set the textcontent of a node.\n    SetText {\n        /// The textcontent of the node\n        value: String,\n\n        /// The ID of the node to set the textcontent of.\n        id: ElementId,\n    },\n\n    /// Create a new Event Listener.\n    NewEventListener {\n        /// The name of the event to listen for.\n        name: String,\n\n        /// The ID of the node to attach the listener to.\n        id: ElementId,\n    },\n\n    /// Remove an existing Event Listener.\n    RemoveEventListener {\n        /// The name of the event to remove.\n        name: String,\n\n        /// The ID of the node to remove.\n        id: ElementId,\n    },\n\n    /// Remove a particular node from the DOM\n    Remove {\n        /// The ID of the node to remove.\n        id: ElementId,\n    },\n\n    /// Push the given root node onto our stack.\n    PushRoot {\n        /// The ID of the root node to push.\n        id: ElementId,\n    },\n}\n\n/// A static list of mutations that can be applied to the DOM. Note: this list does not contain any `Any` attribute values\n#[derive(Debug, PartialEq, Default)]\npub struct Mutations {\n    /// Any mutations required to patch the renderer to match the layout of the VirtualDom\n    pub edits: Vec<Mutation>,\n}\n\nimpl WriteMutations for Mutations {\n    fn append_children(&mut self, id: ElementId, m: usize) {\n        self.edits.push(Mutation::AppendChildren { id, m })\n    }\n\n    fn assign_node_id(&mut self, path: &'static [u8], id: ElementId) {\n        self.edits.push(Mutation::AssignId { path, id })\n    }\n\n    fn create_placeholder(&mut self, id: ElementId) {\n        self.edits.push(Mutation::CreatePlaceholder { id })\n    }\n\n    fn create_text_node(&mut self, value: &str, id: ElementId) {\n        self.edits.push(Mutation::CreateTextNode {\n            value: value.into(),\n            id,\n        })\n    }\n\n    fn load_template(&mut self, _template: Template, index: usize, id: ElementId) {\n        self.edits.push(Mutation::LoadTemplate { index, id })\n    }\n\n    fn replace_node_with(&mut self, id: ElementId, m: usize) {\n        self.edits.push(Mutation::ReplaceWith { id, m })\n    }\n\n    fn replace_placeholder_with_nodes(&mut self, path: &'static [u8], m: usize) {\n        self.edits.push(Mutation::ReplacePlaceholder { path, m })\n    }\n\n    fn insert_nodes_after(&mut self, id: ElementId, m: usize) {\n        self.edits.push(Mutation::InsertAfter { id, m })\n    }\n\n    fn insert_nodes_before(&mut self, id: ElementId, m: usize) {\n        self.edits.push(Mutation::InsertBefore { id, m })\n    }\n\n    fn set_attribute(\n        &mut self,\n        name: &'static str,\n        ns: Option<&'static str>,\n        value: &AttributeValue,\n        id: ElementId,\n    ) {\n        self.edits.push(Mutation::SetAttribute {\n            name,\n            ns,\n            value: match value {\n                AttributeValue::Text(s) => AttributeValue::Text(s.clone()),\n                AttributeValue::Bool(b) => AttributeValue::Bool(*b),\n                AttributeValue::Float(n) => AttributeValue::Float(*n),\n                AttributeValue::Int(n) => AttributeValue::Int(*n),\n                AttributeValue::None => AttributeValue::None,\n                _ => panic!(\"Cannot serialize attribute value\"),\n            },\n            id,\n        })\n    }\n\n    fn set_node_text(&mut self, value: &str, id: ElementId) {\n        self.edits.push(Mutation::SetText {\n            value: value.into(),\n            id,\n        })\n    }\n\n    fn create_event_listener(&mut self, name: &'static str, id: ElementId) {\n        self.edits.push(Mutation::NewEventListener {\n            name: name.into(),\n            id,\n        })\n    }\n\n    fn remove_event_listener(&mut self, name: &'static str, id: ElementId) {\n        self.edits.push(Mutation::RemoveEventListener {\n            name: name.into(),\n            id,\n        })\n    }\n\n    fn remove_node(&mut self, id: ElementId) {\n        self.edits.push(Mutation::Remove { id })\n    }\n\n    fn push_root(&mut self, id: ElementId) {\n        self.edits.push(Mutation::PushRoot { id })\n    }\n}\n\n/// A struct that ignores all mutations\npub struct NoOpMutations;\n\nimpl WriteMutations for NoOpMutations {\n    fn append_children(&mut self, _: ElementId, _: usize) {}\n\n    fn assign_node_id(&mut self, _: &'static [u8], _: ElementId) {}\n\n    fn create_placeholder(&mut self, _: ElementId) {}\n\n    fn create_text_node(&mut self, _: &str, _: ElementId) {}\n\n    fn load_template(&mut self, _: Template, _: usize, _: ElementId) {}\n\n    fn replace_node_with(&mut self, _: ElementId, _: usize) {}\n\n    fn replace_placeholder_with_nodes(&mut self, _: &'static [u8], _: usize) {}\n\n    fn insert_nodes_after(&mut self, _: ElementId, _: usize) {}\n\n    fn insert_nodes_before(&mut self, _: ElementId, _: usize) {}\n\n    fn set_attribute(\n        &mut self,\n        _: &'static str,\n        _: Option<&'static str>,\n        _: &AttributeValue,\n        _: ElementId,\n    ) {\n    }\n\n    fn set_node_text(&mut self, _: &str, _: ElementId) {}\n\n    fn create_event_listener(&mut self, _: &'static str, _: ElementId) {}\n\n    fn remove_event_listener(&mut self, _: &'static str, _: ElementId) {}\n\n    fn remove_node(&mut self, _: ElementId) {}\n\n    fn push_root(&mut self, _: ElementId) {}\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "8dab6035d4b2c48c14bd508409f3de508cbc4217",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/packages/logger/src/lib.rs",
    "func": "use tracing::{\n    subscriber::{set_global_default, SetGlobalDefaultError},\n    Level,\n};\n\npub use tracing;\n\n/// Attempt to initialize the subscriber if it doesn't already exist, with default settings.\n///\n/// See [`crate::init`] for more info.\n///\n/// If you're doing setup before your `dioxus::launch` function that requires lots of logging, then\n/// it might be worth calling this earlier than launch.\n///\n/// `dioxus::launch` calls this for you automatically and won't replace any facade you've already set.\n///\n/// # Example\n///\n/// ```rust,no_run\n/// use dioxus::prelude::*;\n/// use tracing::info;\n///\n/// fn main() {\n///     dioxus::logger::initialize_default();\n///\n///     info!(\"Doing some work before launching...\");\n///\n///     dioxus::launch(App);\n/// }\n///\n/// #[component]\n/// fn App() -> Element {\n///     info!(\"App rendered\");\n///     rsx! {\n///         p { \"hi\" }\n///     }\n/// }\n/// ```\npub fn initialize_default() {\n    if tracing::dispatcher::has_been_set() {\n        return;\n    }\n\n    if cfg!(debug_assertions) {\n        _ = init(Level::DEBUG);\n    } else {\n        _ = init(Level::INFO);\n    }\n}\n\n/// Initialize `dioxus-logger` with a specified max filter.\n///\n/// Generally it is best to initialize the logger before launching your Dioxus app.\n/// Works on Web, Desktop, Fullstack, and Liveview.\n///\n/// # Example\n///\n/// ```rust,no_run\n/// use dioxus::prelude::*;\n/// use dioxus::logger::tracing::{Level, info};\n///\n/// fn main() {\n///     dioxus::logger::init(Level::INFO).expect(\"logger failed to init\");\n///     dioxus::launch(App);\n/// }\n///\n/// #[component]\n/// fn App() -> Element {\n///     info!(\"App rendered\");\n///     rsx! {\n///         p { \"hi\" }\n///     }\n/// }\n/// ```\npub fn init(level: Level) -> Result<(), SetGlobalDefaultError> {\n    /*\n    The default logger is currently set to log in fmt mode (meaning print directly to stdout)\n\n    Eventually we want to change the output mode to be `json` when running under `dx`. This would let\n    use re-format the tracing spans to be better integrated with `dx`\n    */\n\n    #[cfg(target_arch = \"wasm32\")]\n    {\n        use tracing_subscriber::layer::SubscriberExt;\n        use tracing_subscriber::Registry;\n\n        let layer_config = tracing_wasm::WASMLayerConfigBuilder::new()\n            .set_max_level(level)\n            .build();\n        let layer = tracing_wasm::WASMLayer::new(layer_config);\n        let reg = Registry::default().with(layer);\n\n        console_error_panic_hook::set_once();\n        set_global_default(reg)\n    }\n\n    #[cfg(not(target_arch = \"wasm32\"))]\n    {\n        let sub = tracing_subscriber::FmtSubscriber::builder().with_max_level(level);\n\n        if !dioxus_cli_config::is_cli_enabled() {\n            return set_global_default(sub.finish());\n        }\n\n        // todo(jon): this is a small hack to clean up logging when running under the CLI\n        // eventually we want to emit everything as json and let the CLI manage the parsing + display\n        set_global_default(sub.without_time().with_target(false).finish())\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "8515491ea8a5bf9afbd9a9e65c2e684ebe40227c",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/example-projects/fullstack-hackernews/src/main.rs",
    "func": "#![allow(non_snake_case, unused)]\nuse dioxus::prelude::*;\n// Define the Hackernews API and types\nuse chrono::{DateTime, Utc};\nuse serde::{Deserialize, Serialize};\nuse std::{\n    fmt::{Display, Formatter},\n    num::ParseIntError,\n    str::FromStr,\n};\nuse svg_attributes::to;\n\nfn main() {\n    LaunchBuilder::new()\n        .with_cfg(server_only! {\n            dioxus::fullstack::ServeConfig::builder().enable_out_of_order_streaming()\n        })\n        .launch(|| rsx! { Router::<Route> {} });\n}\n\n#[derive(Clone, Routable)]\nenum Route {\n    #[redirect(\"/\", || Route::Homepage { story: PreviewState { active_story: None } })]\n    #[route(\"/:story\")]\n    Homepage { story: PreviewState },\n}\n\npub fn App() -> Element {\n    rsx! {\n        Router::<Route> {}\n    }\n}\n\n#[component]\nfn Homepage(story: ReadOnlySignal<PreviewState>) -> Element {\n    rsx! {\n        document::Link { rel: \"stylesheet\", href: asset!(\"/assets/hackernews.css\") }\n        div { display: \"flex\", flex_direction: \"row\", width: \"100%\",\n            div {\n                width: \"50%\",\n                SuspenseBoundary {\n                    fallback: |context: SuspenseContext| rsx! {\n                        \"Loading...\"\n                    },\n                    Stories {}\n                }\n            }\n            div { width: \"50%\",\n                SuspenseBoundary {\n                    fallback: |context: SuspenseContext| rsx! {\n                        \"Loading preview...\"\n                    },\n                    Preview {\n                        story\n                    }\n                }\n            }\n        }\n    }\n}\n\n#[component]\nfn Stories() -> Element {\n    let stories: Resource<dioxus::Result<Vec<i64>>> = use_server_future(move || async move {\n        let url = format!(\"{}topstories.json\", BASE_API_URL);\n        let mut stories_ids = reqwest::get(&url).await?.json::<Vec<i64>>().await?;\n        stories_ids.truncate(30);\n        Ok(stories_ids)\n    })?;\n\n    match stories().unwrap() {\n        Ok(list) => rsx! {\n            div {\n                for story in list {\n                    ChildrenOrLoading {\n                        key: \"{story}\",\n                        StoryListing { story }\n                    }\n                }\n            }\n        },\n        Err(err) => rsx! {\"An error occurred while fetching stories {err}\"},\n    }\n}\n\n#[component]\nfn StoryListing(story: ReadOnlySignal<i64>) -> Element {\n    let story = use_server_future(move || get_story(story()))?;\n\n    let StoryItem {\n        title,\n        url,\n        by,\n        score,\n        time,\n        kids,\n        id,\n        ..\n    } = story().unwrap()?.item;\n\n    let url = url.as_deref().unwrap_or_default();\n    let hostname = url\n        .trim_start_matches(\"https://\")\n        .trim_start_matches(\"http://\")\n        .trim_start_matches(\"www.\");\n    let score = format!(\"{score} {}\", if score == 1 { \" point\" } else { \" points\" });\n    let comments = format!(\n        \"{} {}\",\n        kids.len(),\n        if kids.len() == 1 {\n            \" comment\"\n        } else {\n            \" comments\"\n        }\n    );\n    let time = time.format(\"%D %l:%M %p\");\n\n    rsx! {\n        div {\n            padding: \"0.5rem\",\n            position: \"relative\",\n            div { font_size: \"1.5rem\",\n                Link {\n                    to: Route::Homepage { story: PreviewState { active_story: Some(id) } },\n                    \"{title}\"\n                }\n                a {\n                    color: \"gray\",\n                    href: \"https://news.ycombinator.com/from?site={hostname}\",\n                    text_decoration: \"none\",\n                    \" ({hostname})\"\n                }\n            }\n            div { display: \"flex\", flex_direction: \"row\", color: \"gray\",\n                div { \"{score}\" }\n                div { padding_left: \"0.5rem\", \"by {by}\" }\n                div { padding_left: \"0.5rem\", \"{time}\" }\n                div { padding_left: \"0.5rem\", \"{comments}\" }\n            }\n        }\n    }\n}\n\n#[derive(Clone, Debug, Default)]\nstruct PreviewState {\n    active_story: Option<i64>,\n}\n\nimpl FromStr for PreviewState {\n    type Err = ParseIntError;\n\n    fn from_str(s: &str) -> Result<Self, Self::Err> {\n        let state = i64::from_str(s)?;\n        Ok(PreviewState {\n            active_story: Some(state),\n        })\n    }\n}\n\nimpl Display for PreviewState {\n    fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {\n        if let Some(id) = &self.active_story {\n            write!(f, \"{id}\")?;\n        }\n        Ok(())\n    }\n}\n\n#[component]\nfn Preview(story: ReadOnlySignal<PreviewState>) -> Element {\n    let PreviewState {\n        active_story: Some(id),\n    } = story()\n    else {\n        return rsx! {\"Hover over a story to preview it here\"};\n    };\n\n    let story = use_server_future(use_reactive!(|id| get_story(id)))?;\n\n    let story = story().unwrap()?;\n\n    rsx! {\n        div { padding: \"0.5rem\",\n            div { font_size: \"1.5rem\", a { href: story.item.url, \"{story.item.title}\" } }\n            if let Some(text) = &story.item.text { div { dangerous_inner_html: \"{text}\" } }\n            for comment in story.item.kids.iter().copied() {\n                ChildrenOrLoading {\n                    key: \"{comment}\",\n                    Comment { comment }\n                }\n            }\n        }\n    }\n}\n\n#[component]\nfn Comment(comment: i64) -> Element {\n    let comment: Resource<dioxus::Result<CommentData>> =\n        use_server_future(use_reactive!(|comment| async move {\n            let url = format!(\"{}{}{}.json\", BASE_API_URL, ITEM_API, comment);\n            let mut comment = reqwest::get(&url).await?.json::<CommentData>().await?;\n            Ok(comment)\n        }))?;\n\n    let CommentData {\n        by,\n        time,\n        text,\n        id,\n        kids,\n        ..\n    } = comment().unwrap()?;\n\n    rsx! {\n        div { padding: \"0.5rem\",\n            div { color: \"gray\", \"by {by}\" }\n            div { dangerous_inner_html: \"{text}\" }\n            for comment in kids.iter().copied() {\n                ChildrenOrLoading {\n                    key: \"{comment}\",\n                    Comment { comment }\n                }\n            }\n        }\n    }\n}\n\npub static BASE_API_URL: &str = \"https://hacker-news.firebaseio.com/v0/\";\npub static ITEM_API: &str = \"item/\";\npub static USER_API: &str = \"user/\";\nconst COMMENT_DEPTH: i64 = 1;\n\n#[derive(Clone, Debug, PartialEq, Serialize, Deserialize)]\npub struct StoryPageData {\n    #[serde(flatten)]\n    pub item: StoryItem,\n    #[serde(default)]\n    pub comments: Vec<CommentData>,\n}\n\n#[derive(Clone, Debug, PartialEq, Serialize, Deserialize)]\npub struct CommentData {\n    pub id: i64,\n    /// there will be no by field if the comment was deleted\n    #[serde(default)]\n    pub by: String,\n    #[serde(default)]\n    pub text: String,\n    #[serde(with = \"chrono::serde::ts_seconds\")]\n    pub time: DateTime<Utc>,\n    #[serde(default)]\n    pub kids: Vec<i64>,\n    pub r#type: String,\n}\n\n#[derive(Clone, Debug, PartialEq, Serialize, Deserialize)]\npub struct StoryItem {\n    pub id: i64,\n    pub title: String,\n    pub url: Option<String>,\n    pub text: Option<String>,\n    #[serde(default)]\n    pub by: String,\n    #[serde(default)]\n    pub score: i64,\n    #[serde(default)]\n    pub descendants: i64,\n    #[serde(with = \"chrono::serde::ts_seconds\")]\n    pub time: DateTime<Utc>,\n    #[serde(default)]\n    pub kids: Vec<i64>,\n    pub r#type: String,\n}\n\npub async fn get_story(id: i64) -> dioxus::Result<StoryPageData> {\n    let url = format!(\"{}{}{}.json\", BASE_API_URL, ITEM_API, id);\n    Ok(reqwest::get(&url).await?.json::<StoryPageData>().await?)\n}\n\n#[component]\nfn ChildrenOrLoading(children: Element) -> Element {\n    rsx! {\n        SuspenseBoundary {\n            fallback: |context: SuspenseContext| {\n                rsx! {\n                    if let Some(placeholder) = context.suspense_placeholder() {\n                        {placeholder}\n                    } else {\n                        LoadingIndicator {}\n                    }\n                }\n            },\n            children\n        }\n    }\n}\n\nfn LoadingIndicator() -> Element {\n    rsx! {\n        div {\n            class: \"spinner\",\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "a09999811ea46891a4e104edcd4f7da925aadc55",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/example-projects/ecommerce-site/src/api.rs",
    "func": "#![allow(unused)]\n\nuse std::fmt::Display;\n\nuse chrono::{DateTime, Utc};\nuse serde::{Deserialize, Serialize};\n\n#[derive(Serialize, Deserialize, PartialEq, Clone, Debug, Default)]\npub(crate) struct Product {\n    pub(crate) id: u32,\n    pub(crate) title: String,\n    pub(crate) price: f32,\n    pub(crate) description: String,\n    pub(crate) category: String,\n    pub(crate) image: String,\n    pub(crate) rating: Rating,\n}\n\n#[derive(Serialize, Deserialize, PartialEq, Clone, Debug, Default)]\npub(crate) struct Rating {\n    pub(crate) rate: f32,\n    pub(crate) count: u32,\n}\n\nimpl Display for Rating {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        let rounded = self.rate.round() as usize;\n        for _ in 0..rounded {\n            \"\u2605\".fmt(f)?;\n        }\n        for _ in 0..(5 - rounded) {\n            \"\u2606\".fmt(f)?;\n        }\n\n        write!(f, \" ({:01}) ({} ratings)\", self.rate, self.count)?;\n\n        Ok(())\n    }\n}\n\n#[allow(unused)]\n#[derive(Clone, Copy, Hash, PartialEq, Eq, PartialOrd)]\npub(crate) enum Sort {\n    Descending,\n    Ascending,\n}\n\nimpl Display for Sort {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            Sort::Descending => write!(f, \"desc\"),\n            Sort::Ascending => write!(f, \"asc\"),\n        }\n    }\n}\n\n// Cache up to 100 requests, invalidating them after 60 seconds\npub(crate) async fn fetch_user_carts(user_id: usize) -> Result<Vec<Cart>, reqwest::Error> {\n    reqwest::get(format!(\n        \"https://fakestoreapi.com/carts/user/{user_id}?startdate=2019-12-10&enddate=2023-01-01\"\n    ))\n    .await?\n    .json()\n    .await\n}\n\n// Cache up to 100 requests, invalidating them after 60 seconds\npub(crate) async fn fetch_user(user_id: usize) -> dioxus::Result<Product> {\n    Ok(\n        reqwest::get(format!(\"https://fakestoreapi.com/users/{user_id}\"))\n            .await?\n            .json()\n            .await?,\n    )\n}\n\n// Cache up to 100 requests, invalidating them after 60 seconds\npub(crate) async fn fetch_product(product_id: usize) -> dioxus::Result<Product> {\n    Ok(\n        reqwest::get(format!(\"https://fakestoreapi.com/products/{product_id}\"))\n            .await?\n            .json()\n            .await?,\n    )\n}\n\n// Cache up to 100 requests, invalidating them after 60 seconds\npub(crate) async fn fetch_products(count: usize, sort: Sort) -> dioxus::Result<Vec<Product>> {\n    Ok(reqwest::get(format!(\n        \"https://fakestoreapi.com/products/?sort={sort}&limit={count}\"\n    ))\n    .await?\n    .json()\n    .await?)\n}\n\n#[derive(Serialize, Deserialize)]\npub(crate) struct User {\n    id: usize,\n    email: String,\n    username: String,\n    password: String,\n    name: FullName,\n    phone: String,\n}\n\nimpl User {\n    async fn fetch_most_recent_cart(&self) -> Result<Option<Cart>, reqwest::Error> {\n        let all_carts = fetch_user_carts(self.id).await?;\n\n        Ok(all_carts.into_iter().max_by_key(|cart| cart.date))\n    }\n}\n\n#[derive(Serialize, Deserialize)]\nstruct FullName {\n    firstname: String,\n    lastname: String,\n}\n\n#[derive(Serialize, Deserialize, Clone)]\npub(crate) struct Cart {\n    id: usize,\n    #[serde(rename = \"userId\")]\n    user_id: usize,\n    data: String,\n    products: Vec<ProductInCart>,\n    date: DateTime<Utc>,\n}\n\nimpl Cart {\n    async fn update_database(&mut self) -> Result<(), reqwest::Error> {\n        let id = self.id;\n        let client = reqwest::Client::new();\n        *self = client\n            .put(format!(\"https://fakestoreapi.com/carts/{id}\"))\n            .send()\n            .await?\n            .json()\n            .await?;\n        Ok(())\n    }\n}\n\n#[derive(Serialize, Deserialize, Clone)]\npub(crate) struct ProductInCart {\n    #[serde(rename = \"productId\")]\n    product_id: usize,\n    quantity: usize,\n}\n\nimpl ProductInCart {\n    pub async fn fetch_product(&self) -> Result<Product, dioxus::CapturedError> {\n        fetch_product(self.product_id).await\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "0ba8ead6cf7c47c630bd5486b78c0a9a6cab3677",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/examples/memo_chain.rs",
    "func": "//! This example shows how you can chain memos together to create a tree of memoized values.\n//!\n//! Memos will also pause when their parent component pauses, so if you have a memo that depends on a signal, and the\n//! signal pauses, the memo will pause too.\n\nuse dioxus::prelude::*;\n\nfn main() {\n    dioxus::launch(app);\n}\n\nfn app() -> Element {\n    let mut value = use_signal(|| 0);\n    let mut depth = use_signal(|| 0_usize);\n    let items = use_memo(move || (0..depth()).map(|f| f as _).collect::<Vec<isize>>());\n    let state = use_memo(move || value() + 1);\n\n    println!(\"rendering app\");\n\n    rsx! {\n        button { onclick: move |_| value += 1, \"Increment\" }\n        button { onclick: move |_| depth += 1, \"Add depth\" }\n        button { onclick: move |_| depth -= 1, \"Remove depth\" }\n        if depth() > 0 {\n            Child { depth, items, state }\n        }\n    }\n}\n\n#[component]\nfn Child(state: Memo<isize>, items: Memo<Vec<isize>>, depth: ReadOnlySignal<usize>) -> Element {\n    // These memos don't get re-computed when early returns happen\n    let state = use_memo(move || state() + 1);\n    let item = use_memo(move || items()[depth() - 1]);\n    let depth = use_memo(move || depth() - 1);\n\n    println!(\"rendering child: {}\", depth());\n\n    rsx! {\n        h3 { \"Depth({depth})-Item({item}): {state}\"}\n        if depth() > 0 {\n            Child { depth, state, items }\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "750bd018fe3cced01bf9ed0ceb56ac699b370bef",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/examples/hydration.rs",
    "func": "//! Example: real-world usage of hydration\n//! ------------------------------------\n//!\n//! This example shows how to pre-render a page using dioxus SSR and then how to rehydrate it on the client side.\n//!\n//! To accomplish hydration on the web, you'll want to set up a slightly more sophisticated build & bundle strategy. In\n//! the official docs, we have a guide for using DioxusStudio as a build tool with pre-rendering and hydration.\n//!\n//! In this example, we pre-render the page to HTML and then pass it into the desktop configuration. This serves as a\n//! proof-of-concept for the hydration feature, but you'll probably only want to use hydration for the web.\n\nuse dioxus::desktop::Config;\nuse dioxus::prelude::*;\n\nfn main() {\n    dioxus::LaunchBuilder::desktop()\n        .with_cfg(Config::new().with_prerendered({\n            // We build the dom a first time, then pre-render it to HTML\n            let pre_rendered_dom = VirtualDom::prebuilt(app);\n\n            // We then launch the app with the pre-rendered HTML\n            dioxus_ssr::pre_render(&pre_rendered_dom)\n        }))\n        .launch(app)\n}\n\nfn app() -> Element {\n    let mut val = use_signal(|| 0);\n\n    rsx! {\n        div {\n            h1 { \"hello world. Count: {val}\" }\n            button { onclick: move |_| val += 1, \"click to increment\" }\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "47b9a00a654630c7199bb02f78e08903cccce1f9",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/examples/router.rs",
    "func": "//! An advanced usage of the router with nested routes and redirects.\n//!\n//! Dioxus implements an enum-based router, which allows you to define your routes in a type-safe way.\n//! However, since we need to bake quite a bit of logic into the enum, we have to add some extra syntax.\n//!\n//! Note that you don't need to use advanced features like nest, redirect, etc, since these can all be implemented\n//! manually, but they are provided as a convenience.\n\nuse dioxus::prelude::*;\n\nconst STYLE: Asset = asset!(\"/examples/assets/router.css\");\n\nfn main() {\n    dioxus::launch(|| {\n        rsx! {\n            document::Link { rel: \"stylesheet\", href: STYLE }\n            Router::<Route> {}\n        }\n    });\n}\n\n// Turn off rustfmt since we're doing layouts and routes in the same enum\n#[derive(Routable, Clone, Debug, PartialEq)]\n#[rustfmt::skip]\n#[allow(clippy::empty_line_after_outer_attr)]\nenum Route {\n    // Wrap Home in a Navbar Layout\n    #[layout(NavBar)]\n        // The default route is always \"/\" unless otherwise specified\n        #[route(\"/\")]\n        Home {},\n\n        // Wrap the next routes in a layout and a nest\n        #[nest(\"/blog\")]\n        #[layout(Blog)]\n            // At \"/blog\", we want to show a list of blog posts\n            #[route(\"/\")]\n            BlogList {},\n\n            // At \"/blog/:name\", we want to show a specific blog post, using the name slug\n            #[route(\"/:name\")]\n            BlogPost { name: String },\n\n        // We need to end the blog layout and nest\n        // Note we don't need either - we could've just done `/blog/` and `/blog/:name` without nesting,\n        // but it's a bit cleaner this way\n        #[end_layout]\n        #[end_nest]\n\n    // And the regular page layout\n    #[end_layout]\n\n    // Add some redirects for the `/myblog` route\n    #[nest(\"/myblog\")]\n        #[redirect(\"/\", || Route::BlogList {})]\n        #[redirect(\"/:name\", |name: String| Route::BlogPost { name })]\n    #[end_nest]\n\n    // Finally, we need to handle the 404 page\n    #[route(\"/:..route\")]\n    PageNotFound {\n        route: Vec<String>,\n    },\n}\n\n#[component]\nfn NavBar() -> Element {\n    rsx! {\n        nav { id: \"navbar\",\n            Link { to: Route::Home {}, \"Home\" }\n            Link { to: Route::BlogList {}, \"Blog\" }\n        }\n        Outlet::<Route> {}\n    }\n}\n\n#[component]\nfn Home() -> Element {\n    rsx! { h1 { \"Welcome to the Dioxus Blog!\" } }\n}\n\n#[component]\nfn Blog() -> Element {\n    rsx! {\n        h1 { \"Blog\" }\n        Outlet::<Route> {}\n    }\n}\n\n#[component]\nfn BlogList() -> Element {\n    rsx! {\n        h2 { \"Choose a post\" }\n        div { id: \"blog-list\",\n            Link { to: Route::BlogPost { name: \"Blog post 1\".into() },\n                \"Read the first blog post\"\n            }\n            Link { to: Route::BlogPost { name: \"Blog post 2\".into() },\n                \"Read the second blog post\"\n            }\n        }\n    }\n}\n\n// We can use the `name` slug to show a specific blog post\n// In theory we could read from the filesystem or a database here\n#[component]\nfn BlogPost(name: String) -> Element {\n    let contents = match name.as_str() {\n        \"Blog post 1\" => \"This is the first blog post. It's not very interesting.\",\n        \"Blog post 2\" => \"This is the second blog post. It's not very interesting either.\",\n        _ => \"This blog post doesn't exist.\",\n    };\n\n    rsx! {\n        h2 { \"{name}\" }\n        p { \"{contents}\" }\n    }\n}\n\n#[component]\nfn PageNotFound(route: Vec<String>) -> Element {\n    rsx! {\n        h1 { \"Page not found\" }\n        p { \"We are terribly sorry, but the page you requested doesn't exist.\" }\n        pre { color: \"red\", \"log:\\nattemped to navigate to: {route:?}\" }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "325a10ba77137896b67ab88279cbcf954ef749cf",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/examples/read_size.rs",
    "func": "//! Read the size of elements using the MountedData struct.\n//!\n//! Whenever an Element is finally mounted to the Dom, its data is available to be read.\n//! These fields can typically only be read asynchronously, since various renderers need to release the main thread to\n//! perform layout and painting.\n\nuse std::rc::Rc;\n\nuse dioxus::{html::geometry::euclid::Rect, prelude::*};\n\nfn main() {\n    dioxus::launch(app);\n}\n\nfn app() -> Element {\n    let mut div_element = use_signal(|| None as Option<Rc<MountedData>>);\n    let mut dimensions = use_signal(Rect::zero);\n\n    let read_dims = move |_| async move {\n        let read = div_element.read();\n        let client_rect = read.as_ref().map(|el| el.get_client_rect());\n\n        if let Some(client_rect) = client_rect {\n            if let Ok(rect) = client_rect.await {\n                dimensions.set(rect);\n            }\n        }\n    };\n\n    rsx! {\n        document::Link {\n            rel: \"stylesheet\",\n            href: asset!(\"/examples/assets/read_size.css\"),\n        }\n        div {\n            width: \"50%\",\n            height: \"50%\",\n            background_color: \"red\",\n            onmounted: move |cx| div_element.set(Some(cx.data())),\n            \"This element is {dimensions():?}\"\n        }\n\n        button { onclick: read_dims, \"Read dimensions\" }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "14129c0e36edbeda2792f78946f965603b162f38",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/examples/window_zoom.rs",
    "func": "//! Adjust the zoom of a desktop app\n//!\n//! This example shows how to adjust the zoom of a desktop app using the webview.zoom method.\n\nuse dioxus::prelude::*;\n\nfn main() {\n    dioxus::LaunchBuilder::desktop().launch(app);\n}\n\nfn app() -> Element {\n    let mut level = use_signal(|| 1.0);\n\n    rsx! {\n        h1 { \"Zoom level: {level}\" }\n        p { \"Change the zoom level of the webview by typing a number in the input below.\" }\n        input {\n            r#type: \"number\",\n            value: \"{level}\",\n            oninput: move |e| {\n                if let Ok(new_zoom) = e.value().parse::<f64>() {\n                    level.set(new_zoom);\n                    _ = dioxus::desktop::window().webview.zoom(new_zoom);\n                }\n            }\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "672f1e59d191e511d313768207d560dab8b99b93",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/json/src/lexical/rounding.rs",
    "func": "// Adapted from https://github.com/Alexhuszagh/rust-lexical.\n\n//! Defines rounding schemes for floating-point numbers.\n\nuse super::float::ExtendedFloat;\nuse super::num::*;\nuse super::shift::*;\nuse core::mem;\n\n// MASKS\n\n/// Calculate a scalar factor of 2 above the halfway point.\n#[inline]\npub(crate) fn nth_bit(n: u64) -> u64 {\n    let bits: u64 = mem::size_of::<u64>() as u64 * 8;\n    debug_assert!(n < bits, \"nth_bit() overflow in shl.\");\n\n    1 << n\n}\n\n/// Generate a bitwise mask for the lower `n` bits.\n#[inline]\npub(crate) fn lower_n_mask(n: u64) -> u64 {\n    let bits: u64 = mem::size_of::<u64>() as u64 * 8;\n    debug_assert!(n <= bits, \"lower_n_mask() overflow in shl.\");\n\n    if n == bits {\n        u64::MAX\n    } else {\n        (1 << n) - 1\n    }\n}\n\n/// Calculate the halfway point for the lower `n` bits.\n#[inline]\npub(crate) fn lower_n_halfway(n: u64) -> u64 {\n    let bits: u64 = mem::size_of::<u64>() as u64 * 8;\n    debug_assert!(n <= bits, \"lower_n_halfway() overflow in shl.\");\n\n    if n == 0 {\n        0\n    } else {\n        nth_bit(n - 1)\n    }\n}\n\n/// Calculate a bitwise mask with `n` 1 bits starting at the `bit` position.\n#[inline]\npub(crate) fn internal_n_mask(bit: u64, n: u64) -> u64 {\n    let bits: u64 = mem::size_of::<u64>() as u64 * 8;\n    debug_assert!(bit <= bits, \"internal_n_halfway() overflow in shl.\");\n    debug_assert!(n <= bits, \"internal_n_halfway() overflow in shl.\");\n    debug_assert!(bit >= n, \"internal_n_halfway() overflow in sub.\");\n\n    lower_n_mask(bit) ^ lower_n_mask(bit - n)\n}\n\n// NEAREST ROUNDING\n\n// Shift right N-bytes and round to the nearest.\n//\n// Return if we are above halfway and if we are halfway.\n#[inline]\npub(crate) fn round_nearest(fp: &mut ExtendedFloat, shift: i32) -> (bool, bool) {\n    // Extract the truncated bits using mask.\n    // Calculate if the value of the truncated bits are either above\n    // the mid-way point, or equal to it.\n    //\n    // For example, for 4 truncated bytes, the mask would be b1111\n    // and the midway point would be b1000.\n    let mask: u64 = lower_n_mask(shift as u64);\n    let halfway: u64 = lower_n_halfway(shift as u64);\n\n    let truncated_bits = fp.mant & mask;\n    let is_above = truncated_bits > halfway;\n    let is_halfway = truncated_bits == halfway;\n\n    // Bit shift so the leading bit is in the hidden bit.\n    overflowing_shr(fp, shift);\n\n    (is_above, is_halfway)\n}\n\n// Tie rounded floating point to event.\n#[inline]\npub(crate) fn tie_even(fp: &mut ExtendedFloat, is_above: bool, is_halfway: bool) {\n    // Extract the last bit after shifting (and determine if it is odd).\n    let is_odd = fp.mant & 1 == 1;\n\n    // Calculate if we need to roundup.\n    // We need to roundup if we are above halfway, or if we are odd\n    // and at half-way (need to tie-to-even).\n    if is_above || (is_odd && is_halfway) {\n        fp.mant += 1;\n    }\n}\n\n// Shift right N-bytes and round nearest, tie-to-even.\n//\n// Floating-point arithmetic uses round to nearest, ties to even,\n// which rounds to the nearest value, if the value is halfway in between,\n// round to an even value.\n#[inline]\npub(crate) fn round_nearest_tie_even(fp: &mut ExtendedFloat, shift: i32) {\n    let (is_above, is_halfway) = round_nearest(fp, shift);\n    tie_even(fp, is_above, is_halfway);\n}\n\n// DIRECTED ROUNDING\n\n// Shift right N-bytes and round towards a direction.\n//\n// Return if we have any truncated bytes.\n#[inline]\nfn round_toward(fp: &mut ExtendedFloat, shift: i32) -> bool {\n    let mask: u64 = lower_n_mask(shift as u64);\n    let truncated_bits = fp.mant & mask;\n\n    // Bit shift so the leading bit is in the hidden bit.\n    overflowing_shr(fp, shift);\n\n    truncated_bits != 0\n}\n\n// Round down.\n#[inline]\nfn downard(_: &mut ExtendedFloat, _: bool) {}\n\n// Shift right N-bytes and round toward zero.\n//\n// Floating-point arithmetic defines round toward zero, which rounds\n// towards positive zero.\n#[inline]\npub(crate) fn round_downward(fp: &mut ExtendedFloat, shift: i32) {\n    // Bit shift so the leading bit is in the hidden bit.\n    // No rounding schemes, so we just ignore everything else.\n    let is_truncated = round_toward(fp, shift);\n    downard(fp, is_truncated);\n}\n\n// ROUND TO FLOAT\n\n// Shift the ExtendedFloat fraction to the fraction bits in a native float.\n//\n// Floating-point arithmetic uses round to nearest, ties to even,\n// which rounds to the nearest value, if the value is halfway in between,\n// round to an even value.\n#[inline]\npub(crate) fn round_to_float<F, Algorithm>(fp: &mut ExtendedFloat, algorithm: Algorithm)\nwhere\n    F: Float,\n    Algorithm: FnOnce(&mut ExtendedFloat, i32),\n{\n    // Calculate the difference to allow a single calculation\n    // rather than a loop, to minimize the number of ops required.\n    // This does underflow detection.\n    let final_exp = fp.exp + F::DEFAULT_SHIFT;\n    if final_exp < F::DENORMAL_EXPONENT {\n        // We would end up with a denormal exponent, try to round to more\n        // digits. Only shift right if we can avoid zeroing out the value,\n        // which requires the exponent diff to be < M::BITS. The value\n        // is already normalized, so we shouldn't have any issue zeroing\n        // out the value.\n        let diff = F::DENORMAL_EXPONENT - fp.exp;\n        if diff <= u64::FULL {\n            // We can avoid underflow, can get a valid representation.\n            algorithm(fp, diff);\n        } else {\n            // Certain underflow, assign literal 0s.\n            fp.mant = 0;\n            fp.exp = 0;\n        }\n    } else {\n        algorithm(fp, F::DEFAULT_SHIFT);\n    }\n\n    if fp.mant & F::CARRY_MASK == F::CARRY_MASK {\n        // Roundup carried over to 1 past the hidden bit.\n        shr(fp, 1);\n    }\n}\n\n// AVOID OVERFLOW/UNDERFLOW\n\n// Avoid overflow for large values, shift left as needed.\n//\n// Shift until a 1-bit is in the hidden bit, if the mantissa is not 0.\n#[inline]\npub(crate) fn avoid_overflow<F>(fp: &mut ExtendedFloat)\nwhere\n    F: Float,\n{\n    // Calculate the difference to allow a single calculation\n    // rather than a loop, minimizing the number of ops required.\n    if fp.exp >= F::MAX_EXPONENT {\n        let diff = fp.exp - F::MAX_EXPONENT;\n        if diff <= F::MANTISSA_SIZE {\n            // Our overflow mask needs to start at the hidden bit, or at\n            // `F::MANTISSA_SIZE+1`, and needs to have `diff+1` bits set,\n            // to see if our value overflows.\n            let bit = (F::MANTISSA_SIZE + 1) as u64;\n            let n = (diff + 1) as u64;\n            let mask = internal_n_mask(bit, n);\n            if (fp.mant & mask) == 0 {\n                // If we have no 1-bit in the hidden-bit position,\n                // which is index 0, we need to shift 1.\n                let shift = diff + 1;\n                shl(fp, shift);\n            }\n        }\n    }\n}\n\n// ROUND TO NATIVE\n\n// Round an extended-precision float to a native float representation.\n#[inline]\npub(crate) fn round_to_native<F, Algorithm>(fp: &mut ExtendedFloat, algorithm: Algorithm)\nwhere\n    F: Float,\n    Algorithm: FnOnce(&mut ExtendedFloat, i32),\n{\n    // Shift all the way left, to ensure a consistent representation.\n    // The following right-shifts do not work for a non-normalized number.\n    fp.normalize();\n\n    // Round so the fraction is in a native mantissa representation,\n    // and avoid overflow/underflow.\n    round_to_float::<F, _>(fp, algorithm);\n    avoid_overflow::<F>(fp);\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "84e1b6686e8f2bb1a9940109bebaad4f189d8681",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tauri/bench/tests/files_transfer/src-tauri/src/main.rs",
    "func": "// Copyright 2019-2024 Tauri Programme within The Commons Conservancy\n// SPDX-License-Identifier: Apache-2.0\n// SPDX-License-Identifier: MIT\n\n#![cfg_attr(not(debug_assertions), windows_subsystem = \"windows\")]\n\nuse std::fs::read;\nuse tauri::{command, ipc::Response, path::BaseDirectory, AppHandle, Manager, Runtime};\n\n#[command]\nfn app_should_close(exit_code: i32) {\n  std::process::exit(exit_code);\n}\n\n#[command]\nasync fn read_file<R: Runtime>(app: AppHandle<R>) -> Result<Response, String> {\n  let path = app\n    .path()\n    .resolve(\".tauri_3mb.json\", BaseDirectory::Home)\n    .map_err(|e| e.to_string())?;\n  let contents = read(&path).map_err(|e| e.to_string())?;\n  Ok(Response::new(contents))\n}\n\nfn main() {\n  tauri::Builder::default()\n    .invoke_handler(tauri::generate_handler![app_should_close, read_file])\n    .run(tauri::generate_context!())\n    .expect(\"error while running tauri application\");\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "8e61fae590935b147b7ec1063acc76705b66de11",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tauri/bench/tests/cpu_intensive/src-tauri/src/main.rs",
    "func": "// Copyright 2019-2024 Tauri Programme within The Commons Conservancy\n// SPDX-License-Identifier: Apache-2.0\n// SPDX-License-Identifier: MIT\n\n#![cfg_attr(not(debug_assertions), windows_subsystem = \"windows\")]\n\n#[tauri::command]\nfn app_completed_successfully() {\n  std::process::exit(0);\n}\n\nfn main() {\n  tauri::Builder::default()\n    .invoke_handler(tauri::generate_handler![app_completed_successfully])\n    .run(tauri::generate_context!())\n    .expect(\"error while running tauri application\");\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "74bd93bbc35a0c77d3588ff6d1993b2e608d4598",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tauri/crates/tauri-macros/src/context.rs",
    "func": "// Copyright 2019-2024 Tauri Programme within The Commons Conservancy\n// SPDX-License-Identifier: Apache-2.0\n// SPDX-License-Identifier: MIT\n\nuse proc_macro2::{Ident, Span, TokenStream};\nuse quote::{quote, ToTokens};\nuse std::path::PathBuf;\nuse syn::{\n  parse::{Parse, ParseBuffer},\n  punctuated::Punctuated,\n  Expr, ExprLit, Lit, LitBool, LitStr, Meta, PathArguments, PathSegment, Token,\n};\nuse tauri_codegen::{context_codegen, get_config, ContextData};\nuse tauri_utils::{config::parse::does_supported_file_name_exist, platform::Target};\n\npub(crate) struct ContextItems {\n  config_file: PathBuf,\n  root: syn::Path,\n  capabilities: Option<Vec<PathBuf>>,\n  assets: Option<Expr>,\n  test: bool,\n}\n\nimpl Parse for ContextItems {\n  fn parse(input: &ParseBuffer<'_>) -> syn::parse::Result<Self> {\n    let target = std::env::var(\"TARGET\")\n      .or_else(|_| std::env::var(\"TAURI_ENV_TARGET_TRIPLE\"))\n      .as_deref()\n      .map(Target::from_triple)\n      .unwrap_or_else(|_| Target::current());\n\n    let mut root = None;\n    let mut capabilities = None;\n    let mut assets = None;\n    let mut test = false;\n    let config_file = input.parse::<LitStr>().ok().map(|raw| {\n      let _ = input.parse::<Token![,]>();\n      let path = PathBuf::from(raw.value());\n      if path.is_relative() {\n        std::env::var(\"CARGO_MANIFEST_DIR\")\n          .map(|m| PathBuf::from(m).join(path))\n          .map_err(|e| e.to_string())\n      } else {\n        Ok(path)\n      }\n      .and_then(|path| {\n        if does_supported_file_name_exist(target, &path) {\n          Ok(path)\n        } else {\n          Err(format!(\n            \"no file at path {} exists, expected tauri config file\",\n            path.display()\n          ))\n        }\n      })\n    });\n\n    while let Ok(meta) = input.parse::<Meta>() {\n      match meta {\n        Meta::Path(p) => {\n          root.replace(p);\n        }\n        Meta::NameValue(v) => {\n          let ident = v.path.require_ident()?;\n          match ident.to_string().as_str() {\n            \"capabilities\" => {\n              if let Expr::Array(array) = v.value {\n                capabilities.replace(\n                  array\n                    .elems\n                    .into_iter()\n                    .map(|e| {\n                      if let Expr::Lit(ExprLit {\n                        attrs: _,\n                        lit: Lit::Str(s),\n                      }) = e\n                      {\n                        Ok(s.value().into())\n                      } else {\n                        Err(syn::Error::new(\n                          input.span(),\n                          \"unexpected expression for capability\",\n                        ))\n                      }\n                    })\n                    .collect::<Result<Vec<_>, syn::Error>>()?,\n                );\n              } else {\n                return Err(syn::Error::new(\n                  input.span(),\n                  \"unexpected value for capabilities\",\n                ));\n              }\n            }\n            \"assets\" => {\n              assets.replace(v.value);\n            }\n            \"test\" => {\n              if let Expr::Lit(ExprLit {\n                lit: Lit::Bool(LitBool { value, .. }),\n                ..\n              }) = v.value\n              {\n                test = value;\n              } else {\n                return Err(syn::Error::new(input.span(), \"unexpected value for test\"));\n              }\n            }\n            name => {\n              return Err(syn::Error::new(\n                input.span(),\n                format!(\"unknown attribute {name}\"),\n              ));\n            }\n          }\n        }\n        Meta::List(_) => {\n          return Err(syn::Error::new(input.span(), \"unexpected list input\"));\n        }\n      }\n\n      let _ = input.parse::<Token![,]>();\n    }\n\n    Ok(Self {\n      config_file: config_file\n        .unwrap_or_else(|| {\n          std::env::var(\"CARGO_MANIFEST_DIR\")\n            .map(|m| PathBuf::from(m).join(\"tauri.conf.json\"))\n            .map_err(|e| e.to_string())\n        })\n        .map_err(|e| input.error(e))?,\n      root: root.unwrap_or_else(|| {\n        let mut segments = Punctuated::new();\n        segments.push(PathSegment {\n          ident: Ident::new(\"tauri\", Span::call_site()),\n          arguments: PathArguments::None,\n        });\n        syn::Path {\n          leading_colon: Some(Token![::](Span::call_site())),\n          segments,\n        }\n      }),\n      capabilities,\n      assets,\n      test,\n    })\n  }\n}\n\npub(crate) fn generate_context(context: ContextItems) -> TokenStream {\n  let context = get_config(&context.config_file)\n    .map_err(|e| e.to_string())\n    .map(|(config, config_parent)| ContextData {\n      dev: cfg!(not(feature = \"custom-protocol\")),\n      config,\n      config_parent,\n      root: context.root.to_token_stream(),\n      capabilities: context.capabilities,\n      assets: context.assets,\n      test: context.test,\n    })\n    .and_then(|data| context_codegen(data).map_err(|e| e.to_string()));\n\n  match context {\n    Ok(code) => code,\n    Err(error) => quote!(compile_error!(#error)),\n  }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "7fbd258dfce42b65279e2bf186c62af2a9b36b6e",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tauri/crates/tauri-macros/src/lib.rs",
    "func": "// Copyright 2019-2024 Tauri Programme within The Commons Conservancy\n// SPDX-License-Identifier: Apache-2.0\n// SPDX-License-Identifier: MIT\n\n//! Create macros for `tauri::Context`, invoke handler and commands leveraging the `tauri-codegen` crate.\n\n#![doc(\n  html_logo_url = \"https://github.com/tauri-apps/tauri/raw/dev/.github/icon.png\",\n  html_favicon_url = \"https://github.com/tauri-apps/tauri/raw/dev/.github/icon.png\"\n)]\n\nuse std::path::PathBuf;\n\nuse crate::context::ContextItems;\nuse proc_macro::TokenStream;\nuse quote::{quote, ToTokens};\nuse syn::{parse2, parse_macro_input, LitStr};\nuse tauri_codegen::image::CachedIcon;\n\nmod command;\nmod menu;\nmod mobile;\nmod runtime;\n\n#[macro_use]\nmod context;\n\n/// Mark a function as a command handler. It creates a wrapper function with the necessary glue code.\n///\n/// # Stability\n/// The output of this macro is managed internally by Tauri,\n/// and should not be accessed directly on normal applications.\n/// It may have breaking changes in the future.\n#[proc_macro_attribute]\npub fn command(attributes: TokenStream, item: TokenStream) -> TokenStream {\n  command::wrapper(attributes, item)\n}\n\n#[proc_macro_attribute]\npub fn mobile_entry_point(attributes: TokenStream, item: TokenStream) -> TokenStream {\n  mobile::entry_point(attributes, item)\n}\n\n/// Accepts a list of command functions. Creates a handler that allows commands to be called from JS with invoke().\n///\n/// # Examples\n/// ```rust,ignore\n/// use tauri_macros::{command, generate_handler};\n/// #[command]\n/// fn command_one() {\n///   println!(\"command one called\");\n/// }\n/// #[command]\n/// fn command_two() {\n///   println!(\"command two called\");\n/// }\n/// fn main() {\n///   let _handler = generate_handler![command_one, command_two];\n/// }\n/// ```\n/// # Stability\n/// The output of this macro is managed internally by Tauri,\n/// and should not be accessed directly on normal applications.\n/// It may have breaking changes in the future.\n#[proc_macro]\npub fn generate_handler(item: TokenStream) -> TokenStream {\n  parse_macro_input!(item as command::Handler).into()\n}\n\n/// Reads a Tauri config file and generates a `::tauri::Context` based on the content.\n///\n/// # Stability\n/// The output of this macro is managed internally by Tauri,\n/// and should not be accessed directly on normal applications.\n/// It may have breaking changes in the future.\n#[proc_macro]\npub fn generate_context(items: TokenStream) -> TokenStream {\n  // this macro is exported from the context module\n  let path = parse_macro_input!(items as ContextItems);\n  context::generate_context(path).into()\n}\n\n/// Adds the default type for the last parameter (assumed to be runtime) for a specific feature.\n///\n/// e.g. To default the runtime generic to type `crate::Wry` when the `wry` feature is enabled, the\n/// syntax would look like `#[default_runtime(crate::Wry, wry)`. This is **always** set for the last\n/// generic, so make sure the last generic is the runtime when using this macro.\n#[doc(hidden)]\n#[proc_macro_attribute]\npub fn default_runtime(attributes: TokenStream, input: TokenStream) -> TokenStream {\n  let attributes = parse_macro_input!(attributes as runtime::Attributes);\n  let input = parse_macro_input!(input as runtime::Input);\n  runtime::default_runtime(attributes, input).into()\n}\n\n/// Accepts a closure-like syntax to call arbitrary code on a menu item\n/// after matching against `kind` and retrieving it from `resources_table` using `rid`.\n///\n/// You can optionally pass a 5th parameter to select which item kinds\n/// to match against, by providing a `|` separated list of item kinds\n/// ```ignore\n/// do_menu_item!(resources_table, rid, kind, |i| i.set_text(text), Check | Submenu);\n/// ```\n/// You could also provide a negated list\n/// ```ignore\n/// do_menu_item!(resources_table, rid, kind, |i| i.set_text(text), !Check);\n/// do_menu_item!(resources_table, rid, kind, |i| i.set_text(text), !Check | !Submenu);\n/// ```\n/// but you can't have mixed negations and positive kinds.\n/// ```ignore\n/// do_menu_item!(resources_table, rid, kind, |i| i.set_text(text), !Check | Submenu);\n/// ```\n///\n/// #### Example\n///\n/// ```ignore\n///  let rid = 23;\n///  let kind = ItemKind::Check;\n///  let resources_table = app.resources_table();\n///  do_menu_item!(resources_table, rid, kind, |i| i.set_text(text))\n/// ```\n/// which will expand into:\n/// ```ignore\n///  let rid = 23;\n///  let kind = ItemKind::Check;\n///  let resources_table = app.resources_table();\n///  match kind {\n///  ItemKind::Submenu => {\n///    let i = resources_table.get::<Submenu<R>>(rid)?;\n///    i.set_text(text)\n///  }\n///  ItemKind::MenuItem => {\n///    let i = resources_table.get::<MenuItem<R>>(rid)?;\n///    i.set_text(text)\n///  }\n///  ItemKind::Predefined => {\n///    let i = resources_table.get::<PredefinedMenuItem<R>>(rid)?;\n///    i.set_text(text)\n///  }\n///  ItemKind::Check => {\n///    let i = resources_table.get::<CheckMenuItem<R>>(rid)?;\n///    i.set_text(text)\n///  }\n///  ItemKind::Icon => {\n///    let i = resources_table.get::<IconMenuItem<R>>(rid)?;\n///    i.set_text(text)\n///  }\n///  _ => unreachable!(),\n///  }\n/// ```\n#[proc_macro]\npub fn do_menu_item(input: TokenStream) -> TokenStream {\n  let tokens = parse_macro_input!(input as menu::DoMenuItemInput);\n  menu::do_menu_item(tokens).into()\n}\n\n/// Convert a .png or .ico icon to an Image\n/// for things like `tauri::tray::TrayIconBuilder` to consume,\n/// relative paths are resolved from `CARGO_MANIFEST_DIR`, not current file\n///\n/// ### Examples\n///\n/// ```ignore\n/// const APP_ICON: Image<'_> = include_image!(\"./icons/32x32.png\");\n///\n/// // then use it with tray\n/// TrayIconBuilder::new().icon(APP_ICON).build().unwrap();\n///\n/// // or with window\n/// WebviewWindowBuilder::new(app, \"main\", WebviewUrl::default())\n///     .icon(APP_ICON)\n///     .unwrap()\n///     .build()\n///     .unwrap();\n///\n/// // or with any other functions that takes `Image` struct\n/// ```\n///\n/// Note: this stores the image in raw pixels to the final binary,\n/// so keep the icon size (width and height) small\n/// or else it's going to bloat your final executable\n#[proc_macro]\npub fn include_image(tokens: TokenStream) -> TokenStream {\n  let path = match parse2::<LitStr>(tokens.into()) {\n    Ok(path) => path,\n    Err(err) => return err.into_compile_error().into(),\n  };\n  let path = PathBuf::from(path.value());\n  let resolved_path = if path.is_relative() {\n    if let Ok(base_dir) = std::env::var(\"CARGO_MANIFEST_DIR\").map(PathBuf::from) {\n      base_dir.join(path)\n    } else {\n      return quote!(compile_error!(\"$CARGO_MANIFEST_DIR is not defined\")).into();\n    }\n  } else {\n    path\n  };\n  if !resolved_path.exists() {\n    let error_string = format!(\n      \"Provided Image path \\\"{}\\\" doesn't exists\",\n      resolved_path.display()\n    );\n    return quote!(compile_error!(#error_string)).into();\n  }\n\n  match CachedIcon::new(&quote!(::tauri), &resolved_path).map_err(|error| error.to_string()) {\n    Ok(icon) => icon.into_token_stream(),\n    Err(error) => quote!(compile_error!(#error)),\n  }\n  .into()\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "9cc8e8f48d989cdc2ae282afcda938cc74c94084",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tauri/crates/tauri/src/lib.rs",
    "func": "// Copyright 2019-2024 Tauri Programme within The Commons Conservancy\n// SPDX-License-Identifier: Apache-2.0\n// SPDX-License-Identifier: MIT\n\n//! Tauri is a framework for building tiny, blazing fast binaries for all major desktop platforms.\n//! Developers can integrate any front-end framework that compiles to HTML, JS and CSS for building their user interface.\n//! The backend of the application is a rust-sourced binary with an API that the front-end can interact with.\n//!\n//! # Cargo features\n//!\n//! The following are a list of [Cargo features](https://doc.rust-lang.org/stable/cargo/reference/manifest.html#the-features-section) that can be enabled or disabled:\n//!\n//! - **wry** *(enabled by default)*: Enables the [wry](https://github.com/tauri-apps/wry) runtime. Only disable it if you want a custom runtime.\n//! - **common-controls-v6** *(enabled by default)*: Enables [Common Controls v6](https://learn.microsoft.com/en-us/windows/win32/controls/common-control-versions) support on Windows, mainly for the predefined `about` menu item.\n//! - **unstable**: Enables unstable features. Be careful, it might introduce breaking changes in future minor releases.\n//! - **tracing**: Enables [`tracing`](https://docs.rs/tracing/latest/tracing) for window startup, plugins, `Window::eval`, events, IPC, updater and custom protocol request handlers.\n//! - **test**: Enables the [`mod@test`] module exposing unit test helpers.\n//! - **objc-exception**: Wrap each msg_send! in a @try/@catch and panics if an exception is caught, preventing Objective-C from unwinding into Rust.\n//! - **linux-libxdo**: Enables linking to libxdo which enables Cut, Copy, Paste and SelectAll menu items to work on Linux.\n//! - **isolation**: Enables the isolation pattern. Enabled by default if the `app > security > pattern > use` config option is set to `isolation` on the `tauri.conf.json` file.\n//! - **custom-protocol**: Feature managed by the Tauri CLI. When enabled, Tauri assumes a production environment instead of a development one.\n//! - **devtools**: Enables the developer tools (Web inspector) and [`window::Window#method.open_devtools`]. Enabled by default on debug builds.\n//!   On macOS it uses private APIs, so you can't enable it if your app will be published to the App Store.\n//! - **native-tls**: Provides TLS support to connect over HTTPS.\n//! - **native-tls-vendored**: Compile and statically link to a vendored copy of OpenSSL.\n//! - **rustls-tls**: Provides TLS support to connect over HTTPS using rustls.\n//! - **process-relaunch-dangerous-allow-symlink-macos**: Allows the [`process::current_binary`] function to allow symlinks on macOS (this is dangerous, see the Security section in the documentation website).\n//! - **tray-icon**: Enables application tray icon APIs. Enabled by default if the `trayIcon` config is defined on the `tauri.conf.json` file.\n//! - **macos-private-api**: Enables features only available in **macOS**'s private APIs, currently the `transparent` window functionality and the `fullScreenEnabled` preference setting to `true`. Enabled by default if the `tauri > macosPrivateApi` config flag is set to `true` on the `tauri.conf.json` file.\n//! - **webview-data-url**: Enables usage of data URLs on the webview.\n//! - **compression** *(enabled by default): Enables asset compression. You should only disable this if you want faster compile times in release builds - it produces larger binaries.\n//! - **config-json5**: Adds support to JSON5 format for `tauri.conf.json`.\n//! - **config-toml**: Adds support to TOML format for the configuration `Tauri.toml`.\n//! - **image-ico**: Adds support to parse `.ico` image, see [`Image`].\n//! - **image-png**: Adds support to parse `.png` image, see [`Image`].\n//! - **macos-proxy**: Adds support for [`WebviewBuilder::proxy_url`] on macOS. Requires macOS 14+.\n//! - **specta**: Add support for [`specta::specta`](https://docs.rs/specta/%5E2.0.0-rc.9/specta/attr.specta.html) with Tauri arguments such as [`State`](crate::State), [`Window`](crate::Window) and [`AppHandle`](crate::AppHandle)\n//!\n//! ## Cargo allowlist features\n//!\n//! The following are a list of [Cargo features](https://doc.rust-lang.org/stable/cargo/reference/manifest.html#the-features-section) that enables commands for Tauri's API package.\n//! These features are automatically enabled by the Tauri CLI based on the `allowlist` configuration under `tauri.conf.json`.\n//!\n//! ### Protocol allowlist\n//!\n//! - **protocol-asset**: Enables the `asset` custom protocol.\n\n#![doc(\n  html_logo_url = \"https://github.com/tauri-apps/tauri/raw/dev/.github/icon.png\",\n  html_favicon_url = \"https://github.com/tauri-apps/tauri/raw/dev/.github/icon.png\"\n)]\n#![warn(missing_docs, rust_2018_idioms)]\n#![cfg_attr(docsrs, feature(doc_cfg))]\n\n/// Setups the binding that initializes an iOS plugin.\n#[cfg(target_os = \"ios\")]\n#[macro_export]\nmacro_rules! ios_plugin_binding {\n  ($fn_name: ident) => {\n    tauri::swift_rs::swift!(fn $fn_name() -> *const ::std::ffi::c_void);\n  }\n}\n#[cfg(target_os = \"macos\")]\n#[doc(hidden)]\npub use embed_plist;\npub use error::{Error, Result};\nuse ipc::{RuntimeAuthority, RuntimeCapability};\npub use resources::{Resource, ResourceId, ResourceTable};\n#[cfg(target_os = \"ios\")]\n#[doc(hidden)]\npub use swift_rs;\npub use tauri_macros::include_image;\n#[cfg(mobile)]\npub use tauri_macros::mobile_entry_point;\npub use tauri_macros::{command, generate_handler};\n\nuse tauri_utils::assets::AssetsIter;\npub use url::Url;\n\npub(crate) mod app;\npub mod async_runtime;\nmod error;\nmod event;\npub mod ipc;\nmod manager;\nmod pattern;\npub mod plugin;\npub(crate) mod protocol;\nmod resources;\nmod vibrancy;\npub mod webview;\npub mod window;\nuse tauri_runtime as runtime;\npub mod image;\n#[cfg(target_os = \"ios\")]\nmod ios;\n#[cfg(desktop)]\n#[cfg_attr(docsrs, doc(cfg(desktop)))]\npub mod menu;\n/// Path APIs.\npub mod path;\npub mod process;\n/// The allowlist scopes.\npub mod scope;\nmod state;\n\n#[cfg(all(desktop, feature = \"tray-icon\"))]\n#[cfg_attr(docsrs, doc(cfg(all(desktop, feature = \"tray-icon\"))))]\npub mod tray;\npub use tauri_utils as utils;\n\npub use http;\n\n/// A Tauri [`Runtime`] wrapper around wry.\n#[cfg(feature = \"wry\")]\n#[cfg_attr(docsrs, doc(cfg(feature = \"wry\")))]\npub type Wry = tauri_runtime_wry::Wry<EventLoopMessage>;\n/// A Tauri [`RuntimeHandle`] wrapper around wry.\n#[cfg(feature = \"wry\")]\n#[cfg_attr(docsrs, doc(cfg(feature = \"wry\")))]\npub type WryHandle = tauri_runtime_wry::WryHandle<EventLoopMessage>;\n\n#[cfg(all(feature = \"wry\", target_os = \"android\"))]\n#[cfg_attr(docsrs, doc(cfg(all(feature = \"wry\", target_os = \"android\"))))]\n#[doc(hidden)]\n#[macro_export]\nmacro_rules! android_binding {\n  ($domain:ident, $app_name:ident, $main:ident, $wry:path) => {\n    use $wry::{\n      android_setup,\n      prelude::{JClass, JNIEnv, JString},\n    };\n\n    ::tauri::wry::android_binding!($domain, $app_name, $wry);\n\n    ::tauri::tao::android_binding!(\n      $domain,\n      $app_name,\n      WryActivity,\n      android_setup,\n      $main,\n      ::tauri::tao\n    );\n\n    // be careful when renaming this, the `Java_app_tauri_plugin_PluginManager_handlePluginResponse` symbol is checked by the CLI\n    ::tauri::tao::platform::android::prelude::android_fn!(\n      app_tauri,\n      plugin,\n      PluginManager,\n      handlePluginResponse,\n      [i32, JString, JString],\n    );\n    ::tauri::tao::platform::android::prelude::android_fn!(\n      app_tauri,\n      plugin,\n      PluginManager,\n      sendChannelData,\n      [i64, JString],\n    );\n\n    // this function is a glue between PluginManager.kt > handlePluginResponse and Rust\n    #[allow(non_snake_case)]\n    pub fn handlePluginResponse(\n      mut env: JNIEnv,\n      _: JClass,\n      id: i32,\n      success: JString,\n      error: JString,\n    ) {\n      ::tauri::handle_android_plugin_response(&mut env, id, success, error);\n    }\n\n    // this function is a glue between PluginManager.kt > sendChannelData and Rust\n    #[allow(non_snake_case)]\n    pub fn sendChannelData(mut env: JNIEnv, _: JClass, id: i64, data: JString) {\n      ::tauri::send_channel_data(&mut env, id, data);\n    }\n  };\n}\n\n#[cfg(all(feature = \"wry\", target_os = \"android\"))]\n#[doc(hidden)]\npub use plugin::mobile::{handle_android_plugin_response, send_channel_data};\n#[cfg(all(feature = \"wry\", target_os = \"android\"))]\n#[doc(hidden)]\npub use tauri_runtime_wry::{tao, wry};\n\n/// A task to run on the main thread.\npub type SyncTask = Box<dyn FnOnce() + Send>;\n\nuse serde::Serialize;\nuse std::{\n  borrow::Cow,\n  collections::HashMap,\n  fmt::{self, Debug},\n  sync::MutexGuard,\n};\nuse utils::assets::{AssetKey, CspHash, EmbeddedAssets};\n\n#[cfg(feature = \"wry\")]\n#[cfg_attr(docsrs, doc(cfg(feature = \"wry\")))]\npub use tauri_runtime_wry::webview_version;\n\n#[cfg(target_os = \"macos\")]\n#[cfg_attr(docsrs, doc(cfg(target_os = \"macos\")))]\npub use runtime::ActivationPolicy;\n\n#[cfg(target_os = \"macos\")]\npub use self::utils::TitleBarStyle;\n\npub use self::event::{Event, EventId, EventTarget};\npub use {\n  self::app::{\n    App, AppHandle, AssetResolver, Builder, CloseRequestApi, RunEvent, UriSchemeContext,\n    UriSchemeResponder, WebviewEvent, WindowEvent,\n  },\n  self::manager::Asset,\n  self::runtime::{\n    dpi::{LogicalPosition, LogicalSize, PhysicalPosition, PhysicalSize, Pixel, Position, Size},\n    webview::WebviewAttributes,\n    window::{CursorIcon, DragDropEvent, WindowSizeConstraints},\n    DeviceEventFilter, Rect, UserAttentionType,\n  },\n  self::state::{State, StateManager},\n  self::utils::{\n    config::{Config, WebviewUrl},\n    Env, PackageInfo, Theme,\n  },\n  self::webview::{Webview, WebviewWindow, WebviewWindowBuilder},\n  self::window::{Monitor, Window},\n  scope::*,\n};\n\n#[cfg(feature = \"unstable\")]\n#[cfg_attr(docsrs, doc(cfg(feature = \"unstable\")))]\npub use {self::webview::WebviewBuilder, self::window::WindowBuilder};\n\n/// The Tauri version.\npub const VERSION: &str = env!(\"CARGO_PKG_VERSION\");\n\n#[cfg(target_os = \"ios\")]\n#[doc(hidden)]\npub fn log_stdout() {\n  use std::{\n    ffi::CString,\n    fs::File,\n    io::{BufRead, BufReader},\n    os::unix::prelude::*,\n    thread,\n  };\n\n  let mut logpipe: [RawFd; 2] = Default::default();\n  unsafe {\n    libc::pipe(logpipe.as_mut_ptr());\n    libc::dup2(logpipe[1], libc::STDOUT_FILENO);\n    libc::dup2(logpipe[1], libc::STDERR_FILENO);\n  }\n  thread::spawn(move || unsafe {\n    let file = File::from_raw_fd(logpipe[0]);\n    let mut reader = BufReader::new(file);\n    let mut buffer = String::new();\n    loop {\n      buffer.clear();\n      if let Ok(len) = reader.read_line(&mut buffer) {\n        if len == 0 {\n          break;\n        } else if let Ok(msg) = CString::new(buffer.as_bytes())\n          .map_err(|_| ())\n          .and_then(|c| c.into_string().map_err(|_| ()))\n        {\n          log::info!(\"{}\", msg);\n        }\n      }\n    }\n  });\n}\n\n/// The user event type.\n#[derive(Debug, Clone)]\npub enum EventLoopMessage {\n  /// An event from a menu item, could be on the window menu bar, application menu bar (on macOS) or tray icon menu.\n  #[cfg(desktop)]\n  MenuEvent(menu::MenuEvent),\n  /// An event from a menu item, could be on the window menu bar, application menu bar (on macOS) or tray icon menu.\n  #[cfg(all(desktop, feature = \"tray-icon\"))]\n  #[cfg_attr(docsrs, doc(cfg(all(desktop, feature = \"tray-icon\"))))]\n  TrayIconEvent(tray::TrayIconEvent),\n}\n\n/// The webview runtime interface. A wrapper around [`runtime::Runtime`] with the proper user event type associated.\npub trait Runtime: runtime::Runtime<EventLoopMessage> {}\n/// The webview runtime handle. A wrapper arond [`runtime::RuntimeHandle`] with the proper user event type associated.\npub trait RuntimeHandle: runtime::RuntimeHandle<EventLoopMessage> {}\n\nimpl<W: runtime::Runtime<EventLoopMessage>> Runtime for W {}\nimpl<R: runtime::RuntimeHandle<EventLoopMessage>> RuntimeHandle for R {}\n\n/// Reads the config file at compile time and generates a [`Context`] based on its content.\n///\n/// The default config file path is a `tauri.conf.json` file inside the Cargo manifest directory of\n/// the crate being built.\n///\n/// # Custom Config Path\n///\n/// You may pass a string literal to this macro to specify a custom path for the Tauri config file.\n/// If the path is relative, it will be search for relative to the Cargo manifest of the compiling\n/// crate.\n///\n/// # Note\n///\n/// This macro should not be called if you are using [`tauri-build`] to generate the context from\n/// inside your build script as it will just cause excess computations that will be discarded. Use\n/// either the [`tauri-build`] method or this macro - not both.\n///\n/// [`tauri-build`]: https://docs.rs/tauri-build\npub use tauri_macros::generate_context;\n\n/// Include a [`Context`] that was generated by [`tauri-build`] inside your build script.\n///\n/// You should either use [`tauri-build`] and this macro to include the compile time generated code,\n/// or [`generate_context!`]. Do not use both at the same time, as they generate the same code and\n/// will cause excess computations that will be discarded.\n///\n/// [`tauri-build`]: https://docs.rs/tauri-build\n#[macro_export]\nmacro_rules! tauri_build_context {\n  () => {\n    include!(concat!(env!(\"OUT_DIR\"), \"/tauri-build-context.rs\"))\n  };\n}\n\npub use pattern::Pattern;\n\n/// Whether we are running in development mode or not.\npub const fn is_dev() -> bool {\n  !cfg!(feature = \"custom-protocol\")\n}\n\n/// Represents a container of file assets that are retrievable during runtime.\npub trait Assets<R: Runtime>: Send + Sync + 'static {\n  /// Initialize the asset provider.\n  fn setup(&self, app: &App<R>) {\n    let _ = app;\n  }\n\n  /// Get the content of the passed [`AssetKey`].\n  fn get(&self, key: &AssetKey) -> Option<Cow<'_, [u8]>>;\n\n  /// Iterator for the assets.\n  fn iter(&self) -> Box<tauri_utils::assets::AssetsIter<'_>>;\n\n  /// Gets the hashes for the CSP tag of the HTML on the given path.\n  fn csp_hashes(&self, html_path: &AssetKey) -> Box<dyn Iterator<Item = CspHash<'_>> + '_>;\n}\n\nimpl<R: Runtime> Assets<R> for EmbeddedAssets {\n  fn get(&self, key: &AssetKey) -> Option<Cow<'_, [u8]>> {\n    EmbeddedAssets::get(self, key)\n  }\n\n  fn iter(&self) -> Box<AssetsIter<'_>> {\n    EmbeddedAssets::iter(self)\n  }\n\n  fn csp_hashes(&self, html_path: &AssetKey) -> Box<dyn Iterator<Item = CspHash<'_>> + '_> {\n    EmbeddedAssets::csp_hashes(self, html_path)\n  }\n}\n\n/// User supplied data required inside of a Tauri application.\n///\n/// # Stability\n/// This is the output of the [`generate_context`] macro, and is not considered part of the stable API.\n/// Unless you know what you are doing and are prepared for this type to have breaking changes, do not create it yourself.\n#[tauri_macros::default_runtime(Wry, wry)]\npub struct Context<R: Runtime> {\n  pub(crate) config: Config,\n  #[cfg(dev)]\n  pub(crate) config_parent: Option<std::path::PathBuf>,\n  /// Asset provider.\n  pub assets: Box<dyn Assets<R>>,\n  pub(crate) default_window_icon: Option<image::Image<'static>>,\n  pub(crate) app_icon: Option<Vec<u8>>,\n  #[cfg(all(desktop, feature = \"tray-icon\"))]\n  pub(crate) tray_icon: Option<image::Image<'static>>,\n  pub(crate) package_info: PackageInfo,\n  pub(crate) pattern: Pattern,\n  pub(crate) runtime_authority: RuntimeAuthority,\n  pub(crate) plugin_global_api_scripts: Option<&'static [&'static str]>,\n}\n\nimpl<R: Runtime> fmt::Debug for Context<R> {\n  fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n    let mut d = f.debug_struct(\"Context\");\n    d.field(\"config\", &self.config)\n      .field(\"default_window_icon\", &self.default_window_icon)\n      .field(\"app_icon\", &self.app_icon)\n      .field(\"package_info\", &self.package_info)\n      .field(\"pattern\", &self.pattern)\n      .field(\"plugin_global_api_scripts\", &self.plugin_global_api_scripts);\n\n    #[cfg(all(desktop, feature = \"tray-icon\"))]\n    d.field(\"tray_icon\", &self.tray_icon);\n\n    d.finish()\n  }\n}\n\nimpl<R: Runtime> Context<R> {\n  /// The config the application was prepared with.\n  #[inline(always)]\n  pub fn config(&self) -> &Config {\n    &self.config\n  }\n\n  /// A mutable reference to the config the application was prepared with.\n  #[inline(always)]\n  pub fn config_mut(&mut self) -> &mut Config {\n    &mut self.config\n  }\n\n  /// The assets to be served directly by Tauri.\n  #[inline(always)]\n  pub fn assets(&self) -> &dyn Assets<R> {\n    self.assets.as_ref()\n  }\n\n  /// Replace the [`Assets`] implementation and returns the previous value so you can use it as a fallback if desired.\n  #[inline(always)]\n  pub fn set_assets(&mut self, assets: Box<dyn Assets<R>>) -> Box<dyn Assets<R>> {\n    std::mem::replace(&mut self.assets, assets)\n  }\n\n  /// The default window icon Tauri should use when creating windows.\n  #[inline(always)]\n  pub fn default_window_icon(&self) -> Option<&image::Image<'_>> {\n    self.default_window_icon.as_ref()\n  }\n\n  /// Set the default window icon Tauri should use when creating windows.\n  #[inline(always)]\n  pub fn set_default_window_icon(&mut self, icon: Option<image::Image<'static>>) {\n    self.default_window_icon = icon;\n  }\n\n  /// The icon to use on the tray icon.\n  #[cfg(all(desktop, feature = \"tray-icon\"))]\n  #[cfg_attr(docsrs, doc(cfg(all(desktop, feature = \"tray-icon\"))))]\n  #[inline(always)]\n  pub fn tray_icon(&self) -> Option<&image::Image<'_>> {\n    self.tray_icon.as_ref()\n  }\n\n  /// Set the icon to use on the tray icon.\n  #[cfg(all(desktop, feature = \"tray-icon\"))]\n  #[cfg_attr(docsrs, doc(cfg(all(desktop, feature = \"tray-icon\"))))]\n  #[inline(always)]\n  pub fn set_tray_icon(&mut self, icon: Option<image::Image<'static>>) {\n    self.tray_icon = icon;\n  }\n\n  /// Package information.\n  #[inline(always)]\n  pub fn package_info(&self) -> &PackageInfo {\n    &self.package_info\n  }\n\n  /// A mutable reference to the package information.\n  #[inline(always)]\n  pub fn package_info_mut(&mut self) -> &mut PackageInfo {\n    &mut self.package_info\n  }\n\n  /// The application pattern.\n  #[inline(always)]\n  pub fn pattern(&self) -> &Pattern {\n    &self.pattern\n  }\n\n  /// A mutable reference to the resolved ACL.\n  ///\n  /// # Stability\n  ///\n  /// This API is unstable.\n  #[doc(hidden)]\n  #[inline(always)]\n  pub fn runtime_authority_mut(&mut self) -> &mut RuntimeAuthority {\n    &mut self.runtime_authority\n  }\n\n  /// Create a new [`Context`] from the minimal required items.\n  #[inline(always)]\n  #[allow(clippy::too_many_arguments)]\n  pub fn new(\n    config: Config,\n    assets: Box<dyn Assets<R>>,\n    default_window_icon: Option<image::Image<'static>>,\n    app_icon: Option<Vec<u8>>,\n    package_info: PackageInfo,\n    pattern: Pattern,\n    runtime_authority: RuntimeAuthority,\n    plugin_global_api_scripts: Option<&'static [&'static str]>,\n  ) -> Self {\n    Self {\n      config,\n      #[cfg(dev)]\n      config_parent: None,\n      assets,\n      default_window_icon,\n      app_icon,\n      #[cfg(all(desktop, feature = \"tray-icon\"))]\n      tray_icon: None,\n      package_info,\n      pattern,\n      runtime_authority,\n      plugin_global_api_scripts,\n    }\n  }\n\n  #[cfg(dev)]\n  #[doc(hidden)]\n  pub fn with_config_parent(&mut self, config_parent: impl AsRef<std::path::Path>) {\n    self\n      .config_parent\n      .replace(config_parent.as_ref().to_owned());\n  }\n}\n\n// TODO: expand these docs\n/// Manages a running application.\npub trait Manager<R: Runtime>: sealed::ManagerBase<R> {\n  /// The application handle associated with this manager.\n  fn app_handle(&self) -> &AppHandle<R> {\n    self.managed_app_handle()\n  }\n\n  /// The [`Config`] the manager was created with.\n  fn config(&self) -> &Config {\n    self.manager().config()\n  }\n\n  /// The [`PackageInfo`] the manager was created with.\n  fn package_info(&self) -> &PackageInfo {\n    self.manager().package_info()\n  }\n\n  /// Fetch a single window from the manager.\n  #[cfg(feature = \"unstable\")]\n  #[cfg_attr(docsrs, doc(cfg(feature = \"unstable\")))]\n  fn get_window(&self, label: &str) -> Option<Window<R>> {\n    self.manager().get_window(label)\n  }\n\n  /// Fetch the focused window. Returns `None` if there is not any focused window.\n  #[cfg(feature = \"unstable\")]\n  #[cfg_attr(docsrs, doc(cfg(feature = \"unstable\")))]\n  fn get_focused_window(&self) -> Option<Window<R>> {\n    self.manager().get_focused_window()\n  }\n\n  /// Fetch all managed windows.\n  #[cfg(feature = \"unstable\")]\n  #[cfg_attr(docsrs, doc(cfg(feature = \"unstable\")))]\n  fn windows(&self) -> HashMap<String, Window<R>> {\n    self.manager().windows()\n  }\n\n  /// Fetch a single webview from the manager.\n  #[cfg(feature = \"unstable\")]\n  #[cfg_attr(docsrs, doc(cfg(feature = \"unstable\")))]\n  fn get_webview(&self, label: &str) -> Option<Webview<R>> {\n    self.manager().get_webview(label)\n  }\n\n  /// Fetch all managed webviews.\n  #[cfg(feature = \"unstable\")]\n  #[cfg_attr(docsrs, doc(cfg(feature = \"unstable\")))]\n  fn webviews(&self) -> HashMap<String, Webview<R>> {\n    self.manager().webviews()\n  }\n\n  /// Fetch a single webview window from the manager.\n  fn get_webview_window(&self, label: &str) -> Option<WebviewWindow<R>> {\n    self.manager().get_webview(label).and_then(|webview| {\n      let window = webview.window();\n      if window.is_webview_window() {\n        Some(WebviewWindow {\n          window: window.clone(),\n          webview,\n        })\n      } else {\n        None\n      }\n    })\n  }\n\n  /// Fetch all managed webview windows.\n  fn webview_windows(&self) -> HashMap<String, WebviewWindow<R>> {\n    self\n      .manager()\n      .webviews()\n      .into_iter()\n      .filter_map(|(label, webview)| {\n        let window = webview.window();\n        if window.is_webview_window() {\n          Some((\n            label,\n            WebviewWindow {\n              window: window.clone(),\n              webview,\n            },\n          ))\n        } else {\n          None\n        }\n      })\n      .collect::<HashMap<_, _>>()\n  }\n\n  /// Add `state` to the state managed by the application.\n  ///\n  /// If the state for the `T` type has previously been set, the state is unchanged and false is returned. Otherwise true is returned.\n  ///\n  /// Managed state can be retrieved by any command handler via the\n  /// [`State`] guard. In particular, if a value of type `T`\n  /// is managed by Tauri, adding `State<T>` to the list of arguments in a\n  /// command handler instructs Tauri to retrieve the managed value.\n  /// Additionally, [`state`](Self#method.state) can be used to retrieve the value manually.\n  ///\n  /// # Mutability\n  ///\n  /// Since the managed state is global and must be [`Send`] + [`Sync`], mutations can only happen through interior mutability:\n  ///\n  /// ```rust,no_run\n  /// use std::{collections::HashMap, sync::Mutex};\n  /// use tauri::State;\n  /// // here we use Mutex to achieve interior mutability\n  /// struct Storage {\n  ///   store: Mutex<HashMap<u64, String>>,\n  /// }\n  /// struct Connection;\n  /// struct DbConnection {\n  ///   db: Mutex<Option<Connection>>,\n  /// }\n  ///\n  /// #[tauri::command]\n  /// fn connect(connection: State<DbConnection>) {\n  ///   // initialize the connection, mutating the state with interior mutability\n  ///   *connection.db.lock().unwrap() = Some(Connection {});\n  /// }\n  ///\n  /// #[tauri::command]\n  /// fn storage_insert(key: u64, value: String, storage: State<Storage>) {\n  ///   // mutate the storage behind the Mutex\n  ///   storage.store.lock().unwrap().insert(key, value);\n  /// }\n  ///\n  /// tauri::Builder::default()\n  ///   .manage(Storage { store: Default::default() })\n  ///   .manage(DbConnection { db: Default::default() })\n  ///   .invoke_handler(tauri::generate_handler![connect, storage_insert])\n  ///   // on an actual app, remove the string argument\n  ///   .run(tauri::generate_context!(\"test/fixture/src-tauri/tauri.conf.json\"))\n  ///   .expect(\"error while running tauri application\");\n  /// ```\n  ///\n  /// # Examples\n  ///\n  /// ```rust,no_run\n  /// use tauri::{Manager, State};\n  ///\n  /// struct MyInt(isize);\n  /// struct MyString(String);\n  ///\n  /// #[tauri::command]\n  /// fn int_command(state: State<MyInt>) -> String {\n  ///     format!(\"The stateful int is: {}\", state.0)\n  /// }\n  ///\n  /// #[tauri::command]\n  /// fn string_command<'r>(state: State<'r, MyString>) {\n  ///     println!(\"state: {}\", state.inner().0);\n  /// }\n  ///\n  /// tauri::Builder::default()\n  ///   .setup(|app| {\n  ///     app.manage(MyInt(0));\n  ///     app.manage(MyString(\"tauri\".into()));\n  ///     // `MyInt` is already managed, so `manage()` returns false\n  ///     assert!(!app.manage(MyInt(1)));\n  ///     // read the `MyInt` managed state with the turbofish syntax\n  ///     let int = app.state::<MyInt>();\n  ///     assert_eq!(int.0, 0);\n  ///     // read the `MyString` managed state with the `State` guard\n  ///     let val: State<MyString> = app.state();\n  ///     assert_eq!(val.0, \"tauri\");\n  ///     Ok(())\n  ///   })\n  ///   .invoke_handler(tauri::generate_handler![int_command, string_command])\n  ///   // on an actual app, remove the string argument\n  ///   .run(tauri::generate_context!(\"test/fixture/src-tauri/tauri.conf.json\"))\n  ///   .expect(\"error while running tauri application\");\n  /// ```\n  fn manage<T>(&self, state: T) -> bool\n  where\n    T: Send + Sync + 'static,\n  {\n    self.manager().state().set(state)\n  }\n\n  /// Removes the state managed by the application for T. Returns the state if it was actually removed.\n  fn unmanage<T>(&self) -> Option<T>\n  where\n    T: Send + Sync + 'static,\n  {\n    self.manager().state().unmanage()\n  }\n\n  /// Retrieves the managed state for the type `T`.\n  ///\n  /// # Panics\n  ///\n  /// Panics if the state for the type `T` has not been previously [managed](Self::manage).\n  /// Use [try_state](Self::try_state) for a non-panicking version.\n  fn state<T>(&self) -> State<'_, T>\n  where\n    T: Send + Sync + 'static,\n  {\n    self\n      .manager()\n      .state\n      .try_get()\n      .expect(\"state() called before manage() for given type\")\n  }\n\n  /// Attempts to retrieve the managed state for the type `T`.\n  ///\n  /// Returns `Some` if the state has previously been [managed](Self::manage). Otherwise returns `None`.\n  fn try_state<T>(&self) -> Option<State<'_, T>>\n  where\n    T: Send + Sync + 'static,\n  {\n    self.manager().state.try_get()\n  }\n\n  /// Get a reference to the resources table of this manager.\n  fn resources_table(&self) -> MutexGuard<'_, ResourceTable>;\n\n  /// Gets the managed [`Env`].\n  fn env(&self) -> Env {\n    self.state::<Env>().inner().clone()\n  }\n\n  /// Gets the scope for the asset protocol.\n  #[cfg(feature = \"protocol-asset\")]\n  fn asset_protocol_scope(&self) -> scope::fs::Scope {\n    self.state::<Scopes>().inner().asset_protocol.clone()\n  }\n\n  /// The path resolver.\n  fn path(&self) -> &crate::path::PathResolver<R> {\n    self.state::<crate::path::PathResolver<R>>().inner()\n  }\n\n  /// Adds a capability to the app.\n  ///\n  /// Note that by default every capability file in the `src-tauri/capabilities` folder\n  /// are automatically enabled unless specific capabilities are configured in [`tauri.conf.json > app > security > capabilities`],\n  /// so you should use a different director for the runtime-added capabilities or use [tauri_build::Attributes::capabilities_path_pattern].\n  ///\n  /// # Examples\n  /// ```\n  /// use tauri::Manager;\n  ///\n  /// tauri::Builder::default()\n  ///   .setup(|app| {\n  ///     #[cfg(feature = \"beta\")]\n  ///     app.add_capability(include_str!(\"../capabilities/beta/cap.json\"));\n  ///\n  ///     #[cfg(feature = \"stable\")]\n  ///     app.add_capability(include_str!(\"../capabilities/stable/cap.json\"));\n  ///     Ok(())\n  ///   });\n  /// ```\n  ///\n  /// The above example assumes the following directory layout:\n  /// ```md\n  /// \u251c\u2500\u2500 capabilities\n  /// \u2502   \u251c\u2500\u2500 app (default capabilities used by any app flavor)\n  /// |   |   |-- cap.json\n  /// \u2502   \u251c\u2500\u2500 beta (capabilities only added to a `beta` flavor)\n  /// |   |   |-- cap.json\n  /// \u2502   \u251c\u2500\u2500 stable (capabilities only added to a `stable` flavor)\n  /// |       |-- cap.json\n  /// ```\n  ///\n  /// For this layout to be properly parsed by Tauri, we need to change the build script to\n  ///\n  /// ```skip\n  /// // only pick up capabilities in the capabilities/app folder by default\n  /// let attributes = tauri_build::Attributes::new().capabilities_path_pattern(\"./capabilities/app/*.json\");\n  /// tauri_build::try_build(attributes).unwrap();\n  /// ```\n  ///\n  /// [`tauri.conf.json > app > security > capabilities`]: https://tauri.app/reference/config/#capabilities\n  /// [tauri_build::Attributes::capabilities_path_pattern]: https://docs.rs/tauri-build/2/tauri_build/struct.Attributes.html#method.capabilities_path_pattern\n  fn add_capability(&self, capability: impl RuntimeCapability) -> Result<()> {\n    self\n      .manager()\n      .runtime_authority\n      .lock()\n      .unwrap()\n      .add_capability(capability)\n  }\n}\n\n/// Listen to events.\npub trait Listener<R: Runtime>: sealed::ManagerBase<R> {\n  /// Listen to an emitted event on this manager.\n  ///\n  /// # Examples\n  /// ```\n  /// use tauri::{Manager, Listener, Emitter};\n  ///\n  /// #[tauri::command]\n  /// fn synchronize(window: tauri::Window) {\n  ///   // emits the synchronized event to all windows\n  ///   window.emit(\"synchronized\", ());\n  /// }\n  ///\n  /// tauri::Builder::default()\n  ///   .setup(|app| {\n  ///     app.listen(\"synchronized\", |event| {\n  ///       println!(\"app is in sync\");\n  ///     });\n  ///     Ok(())\n  ///   })\n  ///   .invoke_handler(tauri::generate_handler![synchronize]);\n  /// ```\n  fn listen<F>(&self, event: impl Into<String>, handler: F) -> EventId\n  where\n    F: Fn(Event) + Send + 'static;\n\n  /// Listen to an event on this manager only once.\n  ///\n  /// See [`Self::listen`] for more information.\n  fn once<F>(&self, event: impl Into<String>, handler: F) -> EventId\n  where\n    F: FnOnce(Event) + Send + 'static;\n\n  /// Remove an event listener.\n  ///\n  /// # Examples\n  /// ```\n  /// use tauri::{Manager, Listener};\n  ///\n  /// tauri::Builder::default()\n  ///   .setup(|app| {\n  ///     let handle = app.handle().clone();\n  ///     let handler = app.listen_any(\"ready\", move |event| {\n  ///       println!(\"app is ready\");\n  ///\n  ///       // we no longer need to listen to the event\n  ///       // we also could have used `app.once_global` instead\n  ///       handle.unlisten(event.id());\n  ///     });\n  ///\n  ///     // stop listening to the event when you do not need it anymore\n  ///     app.unlisten(handler);\n  ///\n  ///\n  ///     Ok(())\n  ///   });\n  /// ```\n  fn unlisten(&self, id: EventId);\n\n  /// Listen to an emitted event to any [target](EventTarget).\n  ///\n  /// # Examples\n  /// ```\n  /// use tauri::{Manager, Emitter, Listener};\n  ///\n  /// #[tauri::command]\n  /// fn synchronize(window: tauri::Window) {\n  ///   // emits the synchronized event to all windows\n  ///   window.emit(\"synchronized\", ());\n  /// }\n  ///\n  /// tauri::Builder::default()\n  ///   .setup(|app| {\n  ///     app.listen_any(\"synchronized\", |event| {\n  ///       println!(\"app is in sync\");\n  ///     });\n  ///     Ok(())\n  ///   })\n  ///   .invoke_handler(tauri::generate_handler![synchronize]);\n  /// ```\n  fn listen_any<F>(&self, event: impl Into<String>, handler: F) -> EventId\n  where\n    F: Fn(Event) + Send + 'static,\n  {\n    self\n      .manager()\n      .listen(event.into(), EventTarget::Any, handler)\n  }\n\n  /// Listens once to an emitted event to any [target](EventTarget) .\n  ///\n  /// See [`Self::listen_any`] for more information.\n  fn once_any<F>(&self, event: impl Into<String>, handler: F) -> EventId\n  where\n    F: FnOnce(Event) + Send + 'static,\n  {\n    self.manager().once(event.into(), EventTarget::Any, handler)\n  }\n}\n\n/// Emit events.\npub trait Emitter<R: Runtime>: sealed::ManagerBase<R> {\n  /// Emits an event to all [targets](EventTarget).\n  ///\n  /// # Examples\n  /// ```\n  /// use tauri::Emitter;\n  ///\n  /// #[tauri::command]\n  /// fn synchronize(app: tauri::AppHandle) {\n  ///   // emits the synchronized event to all webviews\n  ///   app.emit(\"synchronized\", ());\n  /// }\n  /// ```\n  fn emit<S: Serialize + Clone>(&self, event: &str, payload: S) -> Result<()>;\n\n  /// Emits an event to all [targets](EventTarget) matching the given target.\n  ///\n  /// # Examples\n  /// ```\n  /// use tauri::{Emitter, EventTarget};\n  ///\n  /// #[tauri::command]\n  /// fn download(app: tauri::AppHandle) {\n  ///   for i in 1..100 {\n  ///     std::thread::sleep(std::time::Duration::from_millis(150));\n  ///     // emit a download progress event to all listeners\n  ///     app.emit_to(EventTarget::any(), \"download-progress\", i);\n  ///     // emit an event to listeners that used App::listen or AppHandle::listen\n  ///     app.emit_to(EventTarget::app(), \"download-progress\", i);\n  ///     // emit an event to any webview/window/webviewWindow matching the given label\n  ///     app.emit_to(\"updater\", \"download-progress\", i); // similar to using EventTarget::labeled\n  ///     app.emit_to(EventTarget::labeled(\"updater\"), \"download-progress\", i);\n  ///     // emit an event to listeners that used WebviewWindow::listen\n  ///     app.emit_to(EventTarget::webview_window(\"updater\"), \"download-progress\", i);\n  ///   }\n  /// }\n  /// ```\n  fn emit_to<I, S>(&self, target: I, event: &str, payload: S) -> Result<()>\n  where\n    I: Into<EventTarget>,\n    S: Serialize + Clone;\n\n  /// Emits an event to all [targets](EventTarget) based on the given filter.\n  ///\n  /// # Examples\n  /// ```\n  /// use tauri::{Emitter, EventTarget};\n  ///\n  /// #[tauri::command]\n  /// fn download(app: tauri::AppHandle) {\n  ///   for i in 1..100 {\n  ///     std::thread::sleep(std::time::Duration::from_millis(150));\n  ///     // emit a download progress event to the updater window\n  ///     app.emit_filter(\"download-progress\", i, |t| match t {\n  ///       EventTarget::WebviewWindow { label } => label == \"main\",\n  ///       _ => false,\n  ///     });\n  ///   }\n  /// }\n  /// ```\n  fn emit_filter<S, F>(&self, event: &str, payload: S, filter: F) -> Result<()>\n  where\n    S: Serialize + Clone,\n    F: Fn(&EventTarget) -> bool;\n}\n\n/// Prevent implementation details from leaking out of the [`Manager`] trait.\npub(crate) mod sealed {\n  use super::Runtime;\n  use crate::{app::AppHandle, manager::AppManager};\n  use std::sync::Arc;\n\n  /// A running [`Runtime`] or a dispatcher to it.\n  pub enum RuntimeOrDispatch<'r, R: Runtime> {\n    /// Reference to the running [`Runtime`].\n    Runtime(&'r R),\n\n    /// Handle to the running [`Runtime`].\n    RuntimeHandle(R::Handle),\n\n    /// A dispatcher to the running [`Runtime`].\n    Dispatch(R::WindowDispatcher),\n  }\n\n  /// Managed handle to the application runtime.\n  pub trait ManagerBase<R: Runtime> {\n    fn manager(&self) -> &AppManager<R>;\n    fn manager_owned(&self) -> Arc<AppManager<R>>;\n    fn runtime(&self) -> RuntimeOrDispatch<'_, R>;\n    fn managed_app_handle(&self) -> &AppHandle<R>;\n  }\n}\n\nstruct UnsafeSend<T>(T);\nunsafe impl<T> Send for UnsafeSend<T> {}\n\nimpl<T> UnsafeSend<T> {\n  fn take(self) -> T {\n    self.0\n  }\n}\n\n#[allow(unused)]\nmacro_rules! run_main_thread {\n  ($handle:ident, $ex:expr) => {{\n    use std::sync::mpsc::channel;\n    let (tx, rx) = channel();\n    let task = move || {\n      let f = $ex;\n      let _ = tx.send(f());\n    };\n    $handle\n      .run_on_main_thread(task)\n      .and_then(|_| rx.recv().map_err(|_| crate::Error::FailedToReceiveMessage))\n  }};\n}\n\n#[allow(unused)]\npub(crate) use run_main_thread;\n\n#[cfg(any(test, feature = \"test\"))]\n#[cfg_attr(docsrs, doc(cfg(feature = \"test\")))]\npub mod test;\n\n#[cfg(feature = \"specta\")]\nconst _: () = {\n  use specta::{datatype::DataType, function::FunctionArg, TypeMap};\n\n  impl<T: Send + Sync + 'static> FunctionArg for crate::State<'_, T> {\n    fn to_datatype(_: &mut TypeMap) -> Option<DataType> {\n      None\n    }\n  }\n\n  impl<R: crate::Runtime> FunctionArg for crate::AppHandle<R> {\n    fn to_datatype(_: &mut TypeMap) -> Option<DataType> {\n      None\n    }\n  }\n\n  impl<R: crate::Runtime> FunctionArg for crate::Window<R> {\n    fn to_datatype(_: &mut TypeMap) -> Option<DataType> {\n      None\n    }\n  }\n\n  impl<R: crate::Runtime> FunctionArg for crate::Webview<R> {\n    fn to_datatype(_: &mut TypeMap) -> Option<DataType> {\n      None\n    }\n  }\n\n  impl<R: crate::Runtime> FunctionArg for crate::WebviewWindow<R> {\n    fn to_datatype(_: &mut TypeMap) -> Option<DataType> {\n      None\n    }\n  }\n};\n\n#[cfg(test)]\nmod tests {\n  use cargo_toml::Manifest;\n  use std::{env::var, fs::read_to_string, path::PathBuf, sync::OnceLock};\n\n  static MANIFEST: OnceLock<Manifest> = OnceLock::new();\n  const CHECKED_FEATURES: &str = include_str!(concat!(env!(\"OUT_DIR\"), \"/checked_features\"));\n\n  fn get_manifest() -> &'static Manifest {\n    MANIFEST.get_or_init(|| {\n      let manifest_dir = PathBuf::from(var(\"CARGO_MANIFEST_DIR\").unwrap());\n      Manifest::from_path(manifest_dir.join(\"Cargo.toml\")).expect(\"failed to parse Cargo manifest\")\n    })\n  }\n\n  #[test]\n  fn features_are_documented() {\n    let manifest_dir = PathBuf::from(var(\"CARGO_MANIFEST_DIR\").unwrap());\n    let lib_code = read_to_string(manifest_dir.join(\"src/lib.rs\")).expect(\"failed to read lib.rs\");\n\n    for f in get_manifest().features.keys() {\n      if !(f.starts_with(\"__\") || f == \"default\" || lib_code.contains(&format!(\"*{f}**\"))) {\n        panic!(\"Feature {f} is not documented\");\n      }\n    }\n  }\n\n  #[test]\n  fn aliased_features_exist() {\n    let checked_features = CHECKED_FEATURES.split(',');\n    let manifest = get_manifest();\n    for checked_feature in checked_features {\n      if !manifest.features.iter().any(|(f, _)| f == checked_feature) {\n        panic!(\n          \"Feature {checked_feature} was checked in the alias build step but it does not exist in crates/tauri/Cargo.toml\"\n        );\n      }\n    }\n  }\n}\n\n#[cfg(test)]\nmod test_utils {\n  use proptest::prelude::*;\n\n  pub fn assert_send<T: Send>() {}\n  pub fn assert_sync<T: Sync>() {}\n\n  #[allow(dead_code)]\n  pub fn assert_not_allowlist_error<T>(res: anyhow::Result<T>) {\n    if let Err(e) = res {\n      assert!(!e.to_string().contains(\"not on the allowlist\"));\n    }\n  }\n\n  proptest! {\n    #![proptest_config(ProptestConfig::with_cases(10000))]\n    #[test]\n    // check to see if spawn executes a function.\n    fn check_spawn_task(task in \"[a-z]+\") {\n      // create dummy task function\n      let dummy_task = async move {\n        let _ = format!(\"{task}-run-dummy-task\");\n      };\n      // call spawn\n      crate::async_runtime::spawn(dummy_task);\n    }\n  }\n}\n\n/// Simple dependency-free string encoder using [Z85].\nmod z85 {\n  const TABLE: &[u8; 85] =\n    b\"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ.-:+=^!/*?&<>()[]{}@%$#\";\n\n  /// Encode bytes with [Z85].\n  ///\n  /// # Panics\n  ///\n  /// Will panic if the input bytes are not a multiple of 4.\n  pub fn encode(bytes: &[u8]) -> String {\n    assert_eq!(bytes.len() % 4, 0);\n\n    let mut buf = String::with_capacity(bytes.len() * 5 / 4);\n    for chunk in bytes.chunks_exact(4) {\n      let mut chars = [0u8; 5];\n      let mut chunk = u32::from_be_bytes(chunk.try_into().unwrap()) as usize;\n      for byte in chars.iter_mut().rev() {\n        *byte = TABLE[chunk % 85];\n        chunk /= 85;\n      }\n\n      buf.push_str(std::str::from_utf8(&chars).unwrap());\n    }\n\n    buf\n  }\n\n  #[cfg(test)]\n  mod tests {\n    #[test]\n    fn encode() {\n      assert_eq!(\n        super::encode(&[0x86, 0x4F, 0xD2, 0x6F, 0xB5, 0x59, 0xF7, 0x5B]),\n        \"HelloWorld\"\n      );\n    }\n  }\n}\n\n/// Generate a random 128-bit [Z85] encoded [`String`].\n///\n/// [Z85]: https://rfc.zeromq.org/spec/32/\npub(crate) fn generate_invoke_key() -> Result<String> {\n  let mut bytes = [0u8; 16];\n  getrandom::getrandom(&mut bytes)?;\n  Ok(z85::encode(&bytes))\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "2ea4ea34a0ee0725ea80a98bcc7431d9be20bb01",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tauri/crates/tauri/src/image/mod.rs",
    "func": "// Copyright 2019-2024 Tauri Programme within The Commons Conservancy\n// SPDX-License-Identifier: Apache-2.0\n// SPDX-License-Identifier: MIT\n\n//! Image types used by this crate and also referenced by the JavaScript API layer.\n\npub(crate) mod plugin;\n\nuse std::borrow::Cow;\nuse std::sync::Arc;\n\nuse crate::{Resource, ResourceId, ResourceTable};\n\n/// An RGBA Image in row-major order from top to bottom.\n#[derive(Debug, Clone)]\npub struct Image<'a> {\n  rgba: Cow<'a, [u8]>,\n  width: u32,\n  height: u32,\n}\n\nimpl Resource for Image<'static> {}\n\nimpl Image<'static> {\n  /// Creates a new Image using RGBA data, in row-major order from top to bottom, and with specified width and height.\n  ///\n  /// Similar to [`Self::new`] but avoids cloning the rgba data to get an owned Image.\n  pub const fn new_owned(rgba: Vec<u8>, width: u32, height: u32) -> Self {\n    Self {\n      rgba: Cow::Owned(rgba),\n      width,\n      height,\n    }\n  }\n}\n\nimpl<'a> Image<'a> {\n  /// Creates a new Image using RGBA data, in row-major order from top to bottom, and with specified width and height.\n  pub const fn new(rgba: &'a [u8], width: u32, height: u32) -> Self {\n    Self {\n      rgba: Cow::Borrowed(rgba),\n      width,\n      height,\n    }\n  }\n\n  /// Creates a new image using the provided bytes.\n  ///\n  /// Only `ico` and `png` are supported (based on activated feature flag).\n  #[cfg(any(feature = \"image-ico\", feature = \"image-png\"))]\n  #[cfg_attr(docsrs, doc(cfg(any(feature = \"image-ico\", feature = \"image-png\"))))]\n  pub fn from_bytes(bytes: &[u8]) -> crate::Result<Self> {\n    use image::GenericImageView;\n\n    let img = image::load_from_memory(bytes)?;\n    let pixels = img\n      .pixels()\n      .flat_map(|(_, _, pixel)| pixel.0)\n      .collect::<Vec<_>>();\n    Ok(Self {\n      rgba: Cow::Owned(pixels),\n      width: img.width(),\n      height: img.height(),\n    })\n  }\n\n  /// Creates a new image using the provided path.\n  ///\n  /// Only `ico` and `png` are supported (based on activated feature flag).\n  #[cfg(any(feature = \"image-ico\", feature = \"image-png\"))]\n  #[cfg_attr(docsrs, doc(cfg(any(feature = \"image-ico\", feature = \"image-png\"))))]\n  pub fn from_path<P: AsRef<std::path::Path>>(path: P) -> crate::Result<Self> {\n    let bytes = std::fs::read(path)?;\n    Self::from_bytes(&bytes)\n  }\n\n  /// Returns the RGBA data for this image, in row-major order from top to bottom.\n  pub fn rgba(&'a self) -> &'a [u8] {\n    &self.rgba\n  }\n\n  /// Returns the width of this image.\n  pub fn width(&self) -> u32 {\n    self.width\n  }\n\n  /// Returns the height of this image.\n  pub fn height(&self) -> u32 {\n    self.height\n  }\n\n  /// Convert into a 'static owned [`Image`].\n  /// This will allocate.\n  pub fn to_owned(self) -> Image<'static> {\n    Image {\n      rgba: match self.rgba {\n        Cow::Owned(v) => Cow::Owned(v),\n        Cow::Borrowed(v) => Cow::Owned(v.to_vec()),\n      },\n      height: self.height,\n      width: self.width,\n    }\n  }\n}\n\nimpl<'a> From<Image<'a>> for crate::runtime::Icon<'a> {\n  fn from(img: Image<'a>) -> Self {\n    Self {\n      rgba: img.rgba,\n      width: img.width,\n      height: img.height,\n    }\n  }\n}\n\n#[cfg(desktop)]\nimpl TryFrom<Image<'_>> for muda::Icon {\n  type Error = crate::Error;\n\n  fn try_from(img: Image<'_>) -> Result<Self, Self::Error> {\n    muda::Icon::from_rgba(img.rgba.to_vec(), img.width, img.height).map_err(Into::into)\n  }\n}\n\n#[cfg(all(desktop, feature = \"tray-icon\"))]\nimpl TryFrom<Image<'_>> for tray_icon::Icon {\n  type Error = crate::Error;\n\n  fn try_from(img: Image<'_>) -> Result<Self, Self::Error> {\n    tray_icon::Icon::from_rgba(img.rgba.to_vec(), img.width, img.height).map_err(Into::into)\n  }\n}\n\n/// An image type that accepts file paths, raw bytes, previously loaded images and image objects.\n/// This type is meant to be used along the [transformImage](https://v2.tauri.app/reference/javascript/api/namespaceimage/#transformimage) API.\n///\n/// # Stability\n///\n/// The stability of the variants are not guaranteed, and matching against them is not recommended.\n/// Use [`JsImage::into_img`] instead.\n#[derive(serde::Deserialize)]\n#[serde(untagged)]\n#[non_exhaustive]\npub enum JsImage {\n  /// A reference to a image in the filesystem.\n  #[non_exhaustive]\n  Path(std::path::PathBuf),\n  /// Image from raw bytes.\n  #[non_exhaustive]\n  Bytes(Vec<u8>),\n  /// An image that was previously loaded with the API and is stored in the resource table.\n  #[non_exhaustive]\n  Resource(ResourceId),\n  /// Raw RGBA definition of an image.\n  #[non_exhaustive]\n  Rgba {\n    /// Image bytes.\n    rgba: Vec<u8>,\n    /// Image width.\n    width: u32,\n    /// Image height.\n    height: u32,\n  },\n}\n\nimpl JsImage {\n  /// Converts this intermediate image format into an actual [`Image`].\n  ///\n  /// This will retrieve the image from the passed [`ResourceTable`] if it is [`JsImage::Resource`]\n  /// and will return an error if it doesn't exist in the passed [`ResourceTable`] so make sure\n  /// the passed [`ResourceTable`] is the same one used to store the image, usually this should be\n  /// the webview [resources table](crate::webview::Webview::resources_table).\n  pub fn into_img(self, resources_table: &ResourceTable) -> crate::Result<Arc<Image<'_>>> {\n    match self {\n      Self::Resource(rid) => resources_table.get::<Image<'static>>(rid),\n      #[cfg(any(feature = \"image-ico\", feature = \"image-png\"))]\n      Self::Path(path) => Image::from_path(path).map(Arc::new).map_err(Into::into),\n\n      #[cfg(any(feature = \"image-ico\", feature = \"image-png\"))]\n      Self::Bytes(bytes) => Image::from_bytes(&bytes).map(Arc::new).map_err(Into::into),\n\n      Self::Rgba {\n        rgba,\n        width,\n        height,\n      } => Ok(Arc::new(Image::new_owned(rgba, width, height))),\n\n      #[cfg(not(any(feature = \"image-ico\", feature = \"image-png\")))]\n      _ => Err(\n        std::io::Error::new(\n          std::io::ErrorKind::InvalidInput,\n          format!(\n            \"expected RGBA image data, found {}\",\n            match self {\n              JsImage::Path(_) => \"a file path\",\n              JsImage::Bytes(_) => \"raw bytes\",\n              _ => unreachable!(),\n            }\n          ),\n        )\n        .into(),\n      ),\n    }\n  }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "45eda7471e1d94d9ec92f1c4818950d1fde54345",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tauri/crates/tauri/src/menu/builders/mod.rs",
    "func": "// Copyright 2019-2024 Tauri Programme within The Commons Conservancy\n// SPDX-License-Identifier: Apache-2.0\n// SPDX-License-Identifier: MIT\n\n#![cfg(desktop)]\n\n//! A module containing menu builder types\n\nmod menu;\npub use menu::MenuBuilder;\npub use menu::SubmenuBuilder;\nmod normal;\npub use normal::MenuItemBuilder;\nmod check;\npub use check::CheckMenuItemBuilder;\nmod icon;\npub use icon::IconMenuItemBuilder;\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "bf945da5473cbc6baad8285f4c5d26dc6e0af410",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tauri/crates/tauri/src/protocol/mod.rs",
    "func": "// Copyright 2019-2024 Tauri Programme within The Commons Conservancy\n// SPDX-License-Identifier: Apache-2.0\n// SPDX-License-Identifier: MIT\n\n#[cfg(feature = \"protocol-asset\")]\npub mod asset;\n#[cfg(feature = \"isolation\")]\npub mod isolation;\npub mod tauri;\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "19fd95e3e7e055f6c78d1724d12451e34294666b",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tauri/crates/tauri-bundler/src/bundle/windows/util.rs",
    "func": "// Copyright 2019-2024 Tauri Programme within The Commons Conservancy\n// SPDX-License-Identifier: Apache-2.0\n// SPDX-License-Identifier: MIT\n\nuse std::{\n  fs::create_dir_all,\n  path::{Path, PathBuf},\n};\n\nuse crate::utils::http_utils::download;\n\npub const WEBVIEW2_BOOTSTRAPPER_URL: &str = \"https://go.microsoft.com/fwlink/p/?LinkId=2124703\";\npub const WEBVIEW2_OFFLINE_INSTALLER_X86_URL: &str =\n  \"https://go.microsoft.com/fwlink/?linkid=2099617\";\npub const WEBVIEW2_OFFLINE_INSTALLER_X64_URL: &str =\n  \"https://go.microsoft.com/fwlink/?linkid=2124701\";\npub const WEBVIEW2_URL_PREFIX: &str =\n  \"https://msedge.sf.dl.delivery.mp.microsoft.com/filestreamingservice/files/\";\npub const NSIS_OUTPUT_FOLDER_NAME: &str = \"nsis\";\npub const NSIS_UPDATER_OUTPUT_FOLDER_NAME: &str = \"nsis-updater\";\npub const WIX_OUTPUT_FOLDER_NAME: &str = \"msi\";\npub const WIX_UPDATER_OUTPUT_FOLDER_NAME: &str = \"msi-updater\";\n\npub fn webview2_guid_path(url: &str) -> crate::Result<(String, String)> {\n  let agent = ureq::AgentBuilder::new().try_proxy_from_env(true).build();\n  let response = agent.head(url).call().map_err(Box::new)?;\n  let final_url = response.get_url();\n  let remaining_url = final_url.strip_prefix(WEBVIEW2_URL_PREFIX).ok_or_else(|| {\n    anyhow::anyhow!(\n      \"WebView2 URL prefix mismatch. Expected `{}`, found `{}`.\",\n      WEBVIEW2_URL_PREFIX,\n      final_url\n    )\n  })?;\n  let (guid, filename) = remaining_url.split_once('/').ok_or_else(|| {\n    anyhow::anyhow!(\n      \"WebView2 URL format mismatch. Expected `<GUID>/<FILENAME>`, found `{}`.\",\n      remaining_url\n    )\n  })?;\n  Ok((guid.into(), filename.into()))\n}\n\npub fn download_webview2_bootstrapper(base_path: &Path) -> crate::Result<PathBuf> {\n  let file_path = base_path.join(\"MicrosoftEdgeWebview2Setup.exe\");\n  if !file_path.exists() {\n    std::fs::write(&file_path, download(WEBVIEW2_BOOTSTRAPPER_URL)?)?;\n  }\n  Ok(file_path)\n}\n\npub fn download_webview2_offline_installer(base_path: &Path, arch: &str) -> crate::Result<PathBuf> {\n  let url = if arch == \"x64\" {\n    WEBVIEW2_OFFLINE_INSTALLER_X64_URL\n  } else {\n    WEBVIEW2_OFFLINE_INSTALLER_X86_URL\n  };\n  let (guid, filename) = webview2_guid_path(url)?;\n  let dir_path = base_path.join(guid);\n  let file_path = dir_path.join(filename);\n  if !file_path.exists() {\n    create_dir_all(dir_path)?;\n    std::fs::write(&file_path, download(url)?)?;\n  }\n  Ok(file_path)\n}\n\n#[cfg(target_os = \"windows\")]\npub fn os_bitness<'a>() -> Option<&'a str> {\n  use windows_sys::Win32::System::SystemInformation::{\n    GetNativeSystemInfo, PROCESSOR_ARCHITECTURE_AMD64, PROCESSOR_ARCHITECTURE_INTEL, SYSTEM_INFO,\n  };\n\n  let mut system_info: SYSTEM_INFO = unsafe { std::mem::zeroed() };\n  unsafe { GetNativeSystemInfo(&mut system_info) };\n  match unsafe { system_info.Anonymous.Anonymous.wProcessorArchitecture } {\n    PROCESSOR_ARCHITECTURE_INTEL => Some(\"x86\"),\n    PROCESSOR_ARCHITECTURE_AMD64 => Some(\"x64\"),\n    _ => None,\n  }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "2843076c3b1c6879279fd8bf563fa4e07a8dd9d2",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tauri/crates/tauri-cli/src/build.rs",
    "func": "// Copyright 2019-2024 Tauri Programme within The Commons Conservancy\n// SPDX-License-Identifier: Apache-2.0\n// SPDX-License-Identifier: MIT\n\nuse crate::{\n  bundle::BundleFormat,\n  helpers::{\n    self,\n    app_paths::tauri_dir,\n    config::{get as get_config, ConfigHandle, FrontendDist},\n  },\n  interface::{AppInterface, Interface},\n  ConfigValue, Result,\n};\nuse anyhow::Context;\nuse clap::{ArgAction, Parser};\nuse std::env::set_current_dir;\nuse tauri_utils::platform::Target;\n\n#[derive(Debug, Clone, Parser)]\n#[clap(\n  about = \"Build your app in release mode and generate bundles and installers\",\n  long_about = \"Build your app in release mode and generate bundles and installers. It makes use of the `build.frontendDist` property from your `tauri.conf.json` file. It also runs your `build.beforeBuildCommand` which usually builds your frontend into `build.frontendDist`. This will also run `build.beforeBundleCommand` before generating the bundles and installers of your app.\"\n)]\npub struct Options {\n  /// Binary to use to build the application, defaults to `cargo`\n  #[clap(short, long)]\n  pub runner: Option<String>,\n  /// Builds with the debug flag\n  #[clap(short, long)]\n  pub debug: bool,\n  /// Target triple to build against.\n  ///\n  /// It must be one of the values outputted by `$rustc --print target-list` or `universal-apple-darwin` for an universal macOS application.\n  ///\n  /// Note that compiling an universal macOS application requires both `aarch64-apple-darwin` and `x86_64-apple-darwin` targets to be installed.\n  #[clap(short, long)]\n  pub target: Option<String>,\n  /// Space or comma separated list of features to activate\n  #[clap(short, long, action = ArgAction::Append, num_args(0..))]\n  pub features: Option<Vec<String>>,\n  /// Space or comma separated list of bundles to package.\n  ///\n  /// Note that the `updater` bundle is not automatically added so you must specify it if the updater is enabled.\n  #[clap(short, long, action = ArgAction::Append, num_args(0..), value_delimiter = ',')]\n  pub bundles: Option<Vec<BundleFormat>>,\n  /// Skip the bundling step even if `bundle > active` is `true` in tauri config.\n  #[clap(long)]\n  pub no_bundle: bool,\n  /// JSON string or path to JSON file to merge with tauri.conf.json\n  #[clap(short, long)]\n  pub config: Option<ConfigValue>,\n  /// Command line arguments passed to the runner. Use `--` to explicitly mark the start of the arguments.\n  pub args: Vec<String>,\n  /// Skip prompting for values\n  #[clap(long, env = \"CI\")]\n  pub ci: bool,\n}\n\npub fn command(mut options: Options, verbosity: u8) -> Result<()> {\n  crate::helpers::app_paths::resolve();\n\n  let ci = options.ci;\n\n  let target = options\n    .target\n    .as_deref()\n    .map(Target::from_triple)\n    .unwrap_or_else(Target::current);\n\n  let config = get_config(target, options.config.as_ref().map(|c| &c.0))?;\n\n  let mut interface = AppInterface::new(\n    config.lock().unwrap().as_ref().unwrap(),\n    options.target.clone(),\n  )?;\n\n  setup(&interface, &mut options, config.clone(), false)?;\n\n  let config_guard = config.lock().unwrap();\n  let config_ = config_guard.as_ref().unwrap();\n\n  let app_settings = interface.app_settings();\n  let interface_options = options.clone().into();\n\n  let out_dir = app_settings.out_dir(&interface_options)?;\n\n  let bin_path = interface.build(interface_options)?;\n\n  log::info!(action =\"Built\"; \"application at: {}\", tauri_utils::display_path(&bin_path));\n\n  let app_settings = interface.app_settings();\n\n  if !options.no_bundle && (config_.bundle.active || options.bundles.is_some()) {\n    crate::bundle::bundle(\n      &options.into(),\n      verbosity,\n      ci,\n      &interface,\n      &app_settings,\n      config_,\n      &out_dir,\n    )?;\n  }\n\n  Ok(())\n}\n\npub fn setup(\n  interface: &AppInterface,\n  options: &mut Options,\n  config: ConfigHandle,\n  mobile: bool,\n) -> Result<()> {\n  let tauri_path = tauri_dir();\n  set_current_dir(tauri_path).with_context(|| \"failed to change current working directory\")?;\n\n  let config_guard = config.lock().unwrap();\n  let config_ = config_guard.as_ref().unwrap();\n\n  let bundle_identifier_source = config_\n    .find_bundle_identifier_overwriter()\n    .unwrap_or_else(|| \"tauri.conf.json\".into());\n\n  if config_.identifier == \"com.tauri.dev\" {\n    log::error!(\n      \"You must change the bundle identifier in `{} identifier`. The default value `com.tauri.dev` is not allowed as it must be unique across applications.\",\n      bundle_identifier_source\n    );\n    std::process::exit(1);\n  }\n\n  if config_\n    .identifier\n    .chars()\n    .any(|ch| !(ch.is_alphanumeric() || ch == '-' || ch == '.'))\n  {\n    log::error!(\n      \"The bundle identifier \\\"{}\\\" set in `{} identifier`. The bundle identifier string must contain only alphanumeric characters (A-Z, a-z, and 0-9), hyphens (-), and periods (.).\",\n      config_.identifier,\n      bundle_identifier_source\n    );\n    std::process::exit(1);\n  }\n\n  if let Some(before_build) = config_.build.before_build_command.clone() {\n    helpers::run_hook(\"beforeBuildCommand\", before_build, interface, options.debug)?;\n  }\n\n  if let Some(FrontendDist::Directory(web_asset_path)) = &config_.build.frontend_dist {\n    if !web_asset_path.exists() {\n      let absolute_path = web_asset_path\n        .parent()\n        .and_then(|p| p.canonicalize().ok())\n        .map(|p| p.join(web_asset_path.file_name().unwrap()))\n        .unwrap_or_else(|| std::env::current_dir().unwrap().join(web_asset_path));\n      return Err(anyhow::anyhow!(\n          \"Unable to find your web assets, did you forget to build your web app? Your frontendDist is set to \\\"{}\\\" (which is `{}`).\",\n          web_asset_path.display(), absolute_path.display(),\n        ));\n    }\n    if web_asset_path.canonicalize()?.file_name() == Some(std::ffi::OsStr::new(\"src-tauri\")) {\n      return Err(anyhow::anyhow!(\n          \"The configured frontendDist is the `src-tauri` folder. Please isolate your web assets on a separate folder and update `tauri.conf.json > build > frontendDist`.\",\n        ));\n    }\n\n    let mut out_folders = Vec::new();\n    for folder in &[\"node_modules\", \"src-tauri\", \"target\"] {\n      if web_asset_path.join(folder).is_dir() {\n        out_folders.push(folder.to_string());\n      }\n    }\n    if !out_folders.is_empty() {\n      return Err(anyhow::anyhow!(\n          \"The configured frontendDist includes the `{:?}` {}. Please isolate your web assets on a separate folder and update `tauri.conf.json > build > frontendDist`.\",\n          out_folders,\n          if out_folders.len() == 1 { \"folder\" }else { \"folders\" }\n        )\n      );\n    }\n  }\n\n  if options.runner.is_none() {\n    options.runner.clone_from(&config_.build.runner);\n  }\n\n  options\n    .features\n    .get_or_insert(Vec::new())\n    .extend(config_.build.features.clone().unwrap_or_default());\n  interface.build_options(&mut options.args, &mut options.features, mobile);\n\n  Ok(())\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "1e4522e0d8c89c7e7a0cc1fc26ceaaa73ad21c71",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tauri/crates/tauri-build/src/static_vcruntime.rs",
    "func": "// Copyright 2019-2024 Tauri Programme within The Commons Conservancy\n// SPDX-License-Identifier: Apache-2.0\n// SPDX-License-Identifier: MIT\n\n// taken from <https://github.com/ChrisDenton/static_vcruntime/>\n// we're not using static_vcruntime directly because we want this for debug builds too\n\nuse std::{env, fs, io::Write, path::Path};\n\npub fn build() {\n  override_msvcrt_lib();\n\n  // Disable conflicting libraries that aren't hard coded by Rust\n  println!(\"cargo:rustc-link-arg=/NODEFAULTLIB:libvcruntimed.lib\");\n  println!(\"cargo:rustc-link-arg=/NODEFAULTLIB:vcruntime.lib\");\n  println!(\"cargo:rustc-link-arg=/NODEFAULTLIB:vcruntimed.lib\");\n  println!(\"cargo:rustc-link-arg=/NODEFAULTLIB:libcmtd.lib\");\n  println!(\"cargo:rustc-link-arg=/NODEFAULTLIB:msvcrt.lib\");\n  println!(\"cargo:rustc-link-arg=/NODEFAULTLIB:msvcrtd.lib\");\n  println!(\"cargo:rustc-link-arg=/NODEFAULTLIB:libucrt.lib\");\n  println!(\"cargo:rustc-link-arg=/NODEFAULTLIB:libucrtd.lib\");\n  // Set the libraries we want.\n  println!(\"cargo:rustc-link-arg=/DEFAULTLIB:libcmt.lib\");\n  println!(\"cargo:rustc-link-arg=/DEFAULTLIB:libvcruntime.lib\");\n  println!(\"cargo:rustc-link-arg=/DEFAULTLIB:ucrt.lib\");\n}\n\n/// Override the hard-coded msvcrt.lib by replacing it with a (mostly) empty object file.\nfn override_msvcrt_lib() {\n  // Get the right machine type for the empty library.\n  let arch = std::env::var(\"CARGO_CFG_TARGET_ARCH\");\n  let machine: &[u8] = if arch.as_deref() == Ok(\"x86_64\") {\n    &[0x64, 0x86]\n  } else if arch.as_deref() == Ok(\"x86\") {\n    &[0x4C, 0x01]\n  } else {\n    return;\n  };\n  let bytes: &[u8] = &[\n    1, 0, 94, 3, 96, 98, 60, 0, 0, 0, 1, 0, 0, 0, 0, 0, 132, 1, 46, 100, 114, 101, 99, 116, 118,\n    101, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 60, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n    10, 16, 0, 46, 100, 114, 101, 99, 116, 118, 101, 0, 0, 0, 0, 1, 0, 0, 0, 3, 0, 4, 0, 0, 0,\n  ];\n\n  // Write the empty \"msvcrt.lib\" to the output directory.\n  let out_dir = env::var(\"OUT_DIR\").unwrap();\n  let path = Path::new(&out_dir).join(\"msvcrt.lib\");\n  let f = fs::OpenOptions::new()\n    .write(true)\n    .create_new(true)\n    .open(path);\n  if let Ok(mut f) = f {\n    f.write_all(machine).unwrap();\n    f.write_all(bytes).unwrap();\n  }\n  // Add the output directory to the native library path.\n  println!(\"cargo:rustc-link-search=native={out_dir}\");\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "950a550bccf5ae476e0895792ca9765de10b047a",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tauri/crates/tauri-build/src/mobile.rs",
    "func": "// Copyright 2019-2024 Tauri Programme within The Commons Conservancy\n// SPDX-License-Identifier: Apache-2.0\n// SPDX-License-Identifier: MIT\n\nuse std::{fs::write, path::PathBuf};\n\nuse anyhow::{Context, Result};\nuse semver::Version;\nuse tauri_utils::{config::Config, write_if_changed};\n\nuse crate::is_dev;\n\npub fn generate_gradle_files(project_dir: PathBuf, config: &Config) -> Result<()> {\n  let gradle_settings_path = project_dir.join(\"tauri.settings.gradle\");\n  let app_build_gradle_path = project_dir.join(\"app\").join(\"tauri.build.gradle.kts\");\n  let app_tauri_properties_path = project_dir.join(\"app\").join(\"tauri.properties\");\n\n  let mut gradle_settings =\n    \"// THIS IS AN AUTOGENERATED FILE. DO NOT EDIT THIS FILE DIRECTLY.\\n\".to_string();\n  let mut app_build_gradle = \"// THIS IS AN AUTOGENERATED FILE. DO NOT EDIT THIS FILE DIRECTLY.\nval implementation by configurations\ndependencies {\"\n    .to_string();\n  let mut app_tauri_properties = Vec::new();\n\n  for (env, value) in std::env::vars_os() {\n    let env = env.to_string_lossy();\n    if env.starts_with(\"DEP_\") && env.ends_with(\"_ANDROID_LIBRARY_PATH\") {\n      let name_len = env.len() - \"DEP_\".len() - \"_ANDROID_LIBRARY_PATH\".len();\n      let mut plugin_name = env\n        .chars()\n        .skip(\"DEP_\".len())\n        .take(name_len)\n        .collect::<String>()\n        .to_lowercase()\n        .replace('_', \"-\");\n      if plugin_name == \"tauri\" {\n        plugin_name = \"tauri-android\".into();\n      }\n      let plugin_path = PathBuf::from(value);\n\n      gradle_settings.push_str(&format!(\"include ':{plugin_name}'\"));\n      gradle_settings.push('\\n');\n      gradle_settings.push_str(&format!(\n        \"project(':{plugin_name}').projectDir = new File({:?})\",\n        tauri_utils::display_path(plugin_path)\n      ));\n      gradle_settings.push('\\n');\n\n      app_build_gradle.push('\\n');\n      app_build_gradle.push_str(&format!(r#\"  implementation(project(\":{plugin_name}\"))\"#));\n    }\n  }\n\n  app_build_gradle.push_str(\"\\n}\");\n\n  if let Some(version) = config.version.as_ref() {\n    app_tauri_properties.push(format!(\"tauri.android.versionName={version}\"));\n    if let Some(version_code) = config.bundle.android.version_code.as_ref() {\n      app_tauri_properties.push(format!(\"tauri.android.versionCode={version_code}\"));\n    } else if let Ok(version) = Version::parse(version) {\n      let mut version_code = version.major * 1000000 + version.minor * 1000 + version.patch;\n\n      if is_dev() {\n        version_code = version_code.clamp(1, 2100000000);\n      }\n\n      if version_code == 0 {\n        return Err(anyhow::anyhow!(\n              \"You must change the `version` in `tauri.conf.json`. The default value `0.0.0` is not allowed for Android package and must be at least `0.0.1`.\"\n            ));\n      } else if version_code > 2100000000 {\n        return Err(anyhow::anyhow!(\n          \"Invalid version code {}. Version code must be between 1 and 2100000000. You must change the `version` in `tauri.conf.json`.\",\n          version_code\n        ));\n      }\n\n      app_tauri_properties.push(format!(\"tauri.android.versionCode={version_code}\"));\n    }\n  }\n\n  // Overwrite only if changed to not trigger rebuilds\n  write_if_changed(&gradle_settings_path, gradle_settings)\n    .context(\"failed to write tauri.settings.gradle\")?;\n\n  write_if_changed(&app_build_gradle_path, app_build_gradle)\n    .context(\"failed to write tauri.build.gradle.kts\")?;\n\n  if !app_tauri_properties.is_empty() {\n    let app_tauri_properties_content = format!(\n      \"// THIS IS AN AUTOGENERATED FILE. DO NOT EDIT THIS FILE DIRECTLY.\\n{}\",\n      app_tauri_properties.join(\"\\n\")\n    );\n    if std::fs::read_to_string(&app_tauri_properties_path)\n      .map(|o| o != app_tauri_properties_content)\n      .unwrap_or(true)\n    {\n      write(&app_tauri_properties_path, app_tauri_properties_content)\n        .context(\"failed to write tauri.properties\")?;\n    }\n  }\n\n  println!(\"cargo:rerun-if-changed={}\", gradle_settings_path.display());\n  println!(\"cargo:rerun-if-changed={}\", app_build_gradle_path.display());\n  if !app_tauri_properties.is_empty() {\n    println!(\n      \"cargo:rerun-if-changed={}\",\n      app_tauri_properties_path.display()\n    );\n  }\n\n  Ok(())\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "4bedb55b5e1f8e1ec01750ebd9c8e22db879a729",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tauri/crates/tauri-build/src/codegen/context.rs",
    "func": "// Copyright 2019-2024 Tauri Programme within The Commons Conservancy\n// SPDX-License-Identifier: Apache-2.0\n// SPDX-License-Identifier: MIT\n\nuse anyhow::{Context, Result};\nuse std::{\n  env::var,\n  fs::{create_dir_all, File},\n  io::{BufWriter, Write},\n  path::{Path, PathBuf},\n};\nuse tauri_codegen::{context_codegen, ContextData};\nuse tauri_utils::config::FrontendDist;\n\n// TODO docs\n/// A builder for generating a Tauri application context during compile time.\n#[cfg_attr(docsrs, doc(cfg(feature = \"codegen\")))]\n#[derive(Debug)]\npub struct CodegenContext {\n  config_path: PathBuf,\n  out_file: PathBuf,\n  capabilities: Option<Vec<PathBuf>>,\n}\n\nimpl Default for CodegenContext {\n  fn default() -> Self {\n    Self {\n      config_path: PathBuf::from(\"tauri.conf.json\"),\n      out_file: PathBuf::from(\"tauri-build-context.rs\"),\n      capabilities: None,\n    }\n  }\n}\n\nimpl CodegenContext {\n  /// Create a new [`CodegenContext`] builder that is already filled with the default options.\n  pub fn new() -> Self {\n    Self::default()\n  }\n\n  /// Set the path to the `tauri.conf.json` (relative to the package's directory).\n  ///\n  /// This defaults to a file called `tauri.conf.json` inside of the current working directory of\n  /// the package compiling; does not need to be set manually if that config file is in the same\n  /// directory as your `Cargo.toml`.\n  #[must_use]\n  pub fn config_path(mut self, config_path: impl Into<PathBuf>) -> Self {\n    self.config_path = config_path.into();\n    self\n  }\n\n  /// Sets the output file's path.\n  ///\n  /// **Note:** This path should be relative to the `OUT_DIR`.\n  ///\n  /// Don't set this if you are using [`tauri::tauri_build_context!`] as that helper macro\n  /// expects the default value. This option can be useful if you are not using the helper and\n  /// instead using [`std::include!`] on the generated code yourself.\n  ///\n  /// Defaults to `tauri-build-context.rs`.\n  ///\n  /// [`tauri::tauri_build_context!`]: https://docs.rs/tauri/latest/tauri/macro.tauri_build_context.html\n  #[must_use]\n  pub fn out_file(mut self, filename: PathBuf) -> Self {\n    self.out_file = filename;\n    self\n  }\n\n  /// Adds a capability file to the generated context.\n  #[must_use]\n  pub fn capability<P: AsRef<Path>>(mut self, path: P) -> Self {\n    self\n      .capabilities\n      .get_or_insert_with(Default::default)\n      .push(path.as_ref().to_path_buf());\n    self\n  }\n\n  /// Generate the code and write it to the output file - returning the path it was saved to.\n  ///\n  /// Unless you are doing something special with this builder, you don't need to do anything with\n  /// the returned output path.\n  pub(crate) fn try_build(self) -> Result<PathBuf> {\n    let (config, config_parent) = tauri_codegen::get_config(&self.config_path)?;\n\n    // rerun if changed\n    match &config.build.frontend_dist {\n      Some(FrontendDist::Directory(p)) => {\n        let dist_path = config_parent.join(p);\n        if dist_path.exists() {\n          println!(\"cargo:rerun-if-changed={}\", dist_path.display());\n        }\n      }\n      Some(FrontendDist::Files(files)) => {\n        for path in files {\n          println!(\n            \"cargo:rerun-if-changed={}\",\n            config_parent.join(path).display()\n          );\n        }\n      }\n      _ => (),\n    }\n    for icon in &config.bundle.icon {\n      println!(\n        \"cargo:rerun-if-changed={}\",\n        config_parent.join(icon).display()\n      );\n    }\n    if let Some(tray_icon) = config.app.tray_icon.as_ref().map(|t| &t.icon_path) {\n      println!(\n        \"cargo:rerun-if-changed={}\",\n        config_parent.join(tray_icon).display()\n      );\n    }\n\n    #[cfg(target_os = \"macos\")]\n    {\n      let info_plist_path = config_parent.join(\"Info.plist\");\n      if info_plist_path.exists() {\n        println!(\"cargo:rerun-if-changed={}\", info_plist_path.display());\n      }\n    }\n\n    let code = context_codegen(ContextData {\n      dev: crate::is_dev(),\n      config,\n      config_parent,\n      // it's very hard to have a build script for unit tests, so assume this is always called from\n      // outside the tauri crate, making the ::tauri root valid.\n      root: quote::quote!(::tauri),\n      capabilities: self.capabilities,\n      assets: None,\n      test: false,\n    })?;\n\n    // get the full output file path\n    let out = var(\"OUT_DIR\")\n      .map(PathBuf::from)\n      .map(|path| path.join(&self.out_file))\n      .with_context(|| \"unable to find OUT_DIR during tauri-build\")?;\n\n    // make sure any nested directories in OUT_DIR are created\n    let parent = out.parent().with_context(|| {\n      \"`Codegen` could not find the parent to `out_file` while creating the file\"\n    })?;\n    create_dir_all(parent)?;\n\n    let mut file = File::create(&out).map(BufWriter::new).with_context(|| {\n      format!(\n        \"Unable to create output file during tauri-build {}\",\n        out.display()\n      )\n    })?;\n\n    writeln!(file, \"{code}\").with_context(|| {\n      format!(\n        \"Unable to write tokenstream to out file during tauri-build {}\",\n        out.display()\n      )\n    })?;\n\n    Ok(out)\n  }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "0f38d173bb9c73babacb0b812a42bd199111181f",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/tests/how_to_test_apps.rs",
    "func": "//! Demonstrates simple integration testing of Bevy applications.\n//!\n//! By substituting [`DefaultPlugins`] with [`MinimalPlugins`], Bevy can run completely headless.\n//!\n//! The list of minimal plugins does not include things like window or input handling. The downside\n//! of this is that resources or entities associated with those systems (for example:\n//! `ButtonInput::<KeyCode>`) need to be manually added, either directly or via e.g.\n//! [`InputPlugin`]. The upside, however, is that the test has complete control over these\n//! resources, meaning we can fake user input, fake the window being moved around, and more.\nuse bevy::prelude::*;\n\n#[derive(Component)]\nstruct Player {\n    mana: u32,\n}\n\nimpl Default for Player {\n    fn default() -> Self {\n        Self { mana: 10 }\n    }\n}\n\n/// Splitting a Bevy project into multiple smaller plugins can make it more testable. We can\n/// write tests for individual plugins in isolation, as well as for the entire project.\nfn game_plugin(app: &mut App) {\n    app.add_systems(Startup, (spawn_player, window_title_system).chain());\n    app.add_systems(Update, spell_casting);\n}\n\nfn window_title_system(mut windows: Query<&mut Window>) {\n    for (index, mut window) in windows.iter_mut().enumerate() {\n        window.title = format!(\"This is window {index}!\");\n    }\n}\n\nfn spawn_player(mut commands: Commands) {\n    commands.spawn(Player::default());\n}\n\nfn spell_casting(mut player: Query<&mut Player>, keyboard_input: Res<ButtonInput<KeyCode>>) {\n    if keyboard_input.just_pressed(KeyCode::Space) {\n        let Ok(mut player) = player.get_single_mut() else {\n            return;\n        };\n\n        if player.mana > 0 {\n            player.mana -= 1;\n        }\n    }\n}\n\nfn create_test_app() -> App {\n    let mut app = App::new();\n\n    // Note the use of `MinimalPlugins` instead of `DefaultPlugins`, as described above.\n    app.add_plugins(MinimalPlugins);\n    // Inserting a `KeyCode` input resource allows us to inject keyboard inputs, as if the user had\n    // pressed them.\n    app.insert_resource(ButtonInput::<KeyCode>::default());\n\n    // Spawning a fake window allows testing systems that require a window.\n    app.world_mut().spawn(Window::default());\n\n    app\n}\n\n#[test]\nfn test_player_spawn() {\n    let mut app = create_test_app();\n    app.add_plugins(game_plugin);\n\n    // The `update` function needs to be called at least once for the startup\n    // systems to run.\n    app.update();\n\n    // Now that the startup systems have run, we can check if the player has\n    // spawned as expected.\n    let expected = Player::default();\n    let actual = app.world_mut().query::<&Player>().get_single(app.world());\n    assert!(actual.is_ok(), \"There should be exactly 1 player.\");\n    assert_eq!(\n        expected.mana,\n        actual.unwrap().mana,\n        \"Player does not have expected starting mana.\"\n    );\n}\n\n#[test]\nfn test_spell_casting() {\n    let mut app = create_test_app();\n    app.add_plugins(game_plugin);\n\n    // Simulate pressing space to trigger the spell casting system.\n    app.world_mut()\n        .resource_mut::<ButtonInput<KeyCode>>()\n        .press(KeyCode::Space);\n    // Allow the systems to recognize the input event.\n    app.update();\n\n    let expected = Player::default();\n    let actual = app.world_mut().query::<&Player>().single(app.world());\n    assert_eq!(\n        expected.mana - 1,\n        actual.mana,\n        \"A single mana point should have been used.\"\n    );\n\n    // Clear the `just_pressed` status for all `KeyCode`s\n    app.world_mut()\n        .resource_mut::<ButtonInput<KeyCode>>()\n        .clear();\n    app.update();\n\n    // No extra spells have been cast, so no mana should have been used.\n    let after_keypress_event = app.world_mut().query::<&Player>().single(app.world());\n    assert_eq!(\n        expected.mana - 1,\n        after_keypress_event.mana,\n        \"No further mana should have been used.\"\n    );\n}\n\n#[test]\nfn test_window_title() {\n    let mut app = create_test_app();\n    app.add_plugins(game_plugin);\n\n    app.update();\n\n    let window = app.world_mut().query::<&Window>().single(app.world());\n    assert_eq!(window.title, \"This is window 0!\");\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "0bc2421afe9871c0c3d8259a96138d591251e562",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/benches/benches/bevy_ecs/observers/propagation.rs",
    "func": "use bevy_ecs::{\n    component::Component, entity::Entity, event::Event, observer::Trigger, world::World,\n};\nuse bevy_hierarchy::{BuildChildren, Parent};\n\nuse criterion::{black_box, Criterion};\nuse rand::SeedableRng;\nuse rand::{seq::IteratorRandom, Rng};\nuse rand_chacha::ChaCha8Rng;\n\nconst DENSITY: usize = 20; // percent of nodes with listeners\nconst ENTITY_DEPTH: usize = 64;\nconst ENTITY_WIDTH: usize = 200;\nconst N_EVENTS: usize = 500;\nfn deterministic_rand() -> ChaCha8Rng {\n    ChaCha8Rng::seed_from_u64(42)\n}\n\npub fn event_propagation(criterion: &mut Criterion) {\n    let mut group = criterion.benchmark_group(\"event_propagation\");\n    group.warm_up_time(core::time::Duration::from_millis(500));\n    group.measurement_time(core::time::Duration::from_secs(4));\n\n    group.bench_function(\"single_event_type\", |bencher| {\n        let mut world = World::new();\n        let (roots, leaves, nodes) = spawn_listener_hierarchy(&mut world);\n        add_listeners_to_hierarchy::<DENSITY, 1>(&roots, &leaves, &nodes, &mut world);\n\n        bencher.iter(|| {\n            send_events::<1, N_EVENTS>(&mut world, &leaves);\n        });\n    });\n\n    group.bench_function(\"single_event_type_no_listeners\", |bencher| {\n        let mut world = World::new();\n        let (roots, leaves, nodes) = spawn_listener_hierarchy(&mut world);\n        add_listeners_to_hierarchy::<DENSITY, 1>(&roots, &leaves, &nodes, &mut world);\n\n        bencher.iter(|| {\n            // no listeners to observe TestEvent<9>\n            send_events::<9, N_EVENTS>(&mut world, &leaves);\n        });\n    });\n\n    group.bench_function(\"four_event_types\", |bencher| {\n        let mut world = World::new();\n        let (roots, leaves, nodes) = spawn_listener_hierarchy(&mut world);\n        const FRAC_N_EVENTS_4: usize = N_EVENTS / 4;\n        const FRAC_DENSITY_4: usize = DENSITY / 4;\n        add_listeners_to_hierarchy::<FRAC_DENSITY_4, 1>(&roots, &leaves, &nodes, &mut world);\n        add_listeners_to_hierarchy::<FRAC_DENSITY_4, 2>(&roots, &leaves, &nodes, &mut world);\n        add_listeners_to_hierarchy::<FRAC_DENSITY_4, 3>(&roots, &leaves, &nodes, &mut world);\n        add_listeners_to_hierarchy::<FRAC_DENSITY_4, 4>(&roots, &leaves, &nodes, &mut world);\n\n        bencher.iter(|| {\n            send_events::<1, FRAC_N_EVENTS_4>(&mut world, &leaves);\n            send_events::<2, FRAC_N_EVENTS_4>(&mut world, &leaves);\n            send_events::<3, FRAC_N_EVENTS_4>(&mut world, &leaves);\n            send_events::<4, FRAC_N_EVENTS_4>(&mut world, &leaves);\n        });\n    });\n\n    group.finish();\n}\n\n#[derive(Clone, Component)]\nstruct TestEvent<const N: usize> {}\n\nimpl<const N: usize> Event for TestEvent<N> {\n    type Traversal = &'static Parent;\n    const AUTO_PROPAGATE: bool = true;\n}\n\nfn send_events<const N: usize, const N_EVENTS: usize>(world: &mut World, leaves: &Vec<Entity>) {\n    let target = leaves.iter().choose(&mut rand::thread_rng()).unwrap();\n\n    (0..N_EVENTS).for_each(|_| {\n        world.trigger_targets(TestEvent::<N> {}, *target);\n    });\n}\n\nfn spawn_listener_hierarchy(world: &mut World) -> (Vec<Entity>, Vec<Entity>, Vec<Entity>) {\n    let mut roots = vec![];\n    let mut leaves = vec![];\n    let mut nodes = vec![];\n    for _ in 0..ENTITY_WIDTH {\n        let mut parent = world.spawn_empty().id();\n        roots.push(parent);\n        for _ in 0..ENTITY_DEPTH {\n            let child = world.spawn_empty().id();\n            nodes.push(child);\n\n            world.entity_mut(parent).add_child(child);\n            parent = child;\n        }\n        nodes.pop();\n        leaves.push(parent);\n    }\n    (roots, leaves, nodes)\n}\n\nfn add_listeners_to_hierarchy<const DENSITY: usize, const N: usize>(\n    roots: &Vec<Entity>,\n    leaves: &Vec<Entity>,\n    nodes: &Vec<Entity>,\n    world: &mut World,\n) {\n    for e in roots.iter() {\n        world.entity_mut(*e).observe(empty_listener::<N>);\n    }\n    for e in leaves.iter() {\n        world.entity_mut(*e).observe(empty_listener::<N>);\n    }\n    let mut rng = deterministic_rand();\n    for e in nodes.iter() {\n        if rng.gen_bool(DENSITY as f64 / 100.0) {\n            world.entity_mut(*e).observe(empty_listener::<N>);\n        }\n    }\n}\n\nfn empty_listener<const N: usize>(trigger: Trigger<TestEvent<N>>) {\n    black_box(trigger);\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "cb094a2c7b22b86678caeba3bd3858aea616899d",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/benches/benches/bevy_ecs/iteration/iter_simple_foreach_wide_sparse_set.rs",
    "func": "use bevy_ecs::prelude::*;\nuse glam::*;\n\n#[derive(Component, Copy, Clone)]\nstruct Transform(Mat4);\n\n#[derive(Component, Copy, Clone)]\n#[component(storage = \"SparseSet\")]\nstruct Position<const X: usize>(Vec3);\n\n#[derive(Component, Copy, Clone)]\nstruct Rotation(Vec3);\n\n#[derive(Component, Copy, Clone)]\n#[component(storage = \"SparseSet\")]\nstruct Velocity<const X: usize>(Vec3);\n\npub struct Benchmark<'w>(\n    World,\n    QueryState<(\n        &'w Velocity<0>,\n        &'w mut Position<0>,\n        &'w Velocity<1>,\n        &'w mut Position<1>,\n        &'w Velocity<2>,\n        &'w mut Position<2>,\n        &'w Velocity<3>,\n        &'w mut Position<3>,\n        &'w Velocity<4>,\n        &'w mut Position<4>,\n    )>,\n);\n\nimpl<'w> Benchmark<'w> {\n    pub fn new() -> Self {\n        let mut world = World::new();\n\n        world.spawn_batch(\n            core::iter::repeat((\n                Transform(Mat4::from_scale(Vec3::ONE)),\n                Rotation(Vec3::X),\n                Position::<0>(Vec3::X),\n                Velocity::<0>(Vec3::X),\n                Position::<1>(Vec3::X),\n                Velocity::<1>(Vec3::X),\n                Position::<2>(Vec3::X),\n                Velocity::<2>(Vec3::X),\n                Position::<3>(Vec3::X),\n                Velocity::<3>(Vec3::X),\n                Position::<4>(Vec3::X),\n                Velocity::<4>(Vec3::X),\n            ))\n            .take(10_000),\n        );\n\n        let query = world.query();\n        Self(world, query)\n    }\n\n    #[inline(never)]\n    pub fn run(&mut self) {\n        self.1.iter_mut(&mut self.0).for_each(|mut item| {\n            item.1 .0 += item.0 .0;\n            item.3 .0 += item.2 .0;\n            item.5 .0 += item.4 .0;\n            item.7 .0 += item.6 .0;\n        });\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "5609f6db31b05a423efb53b07093a8e2671cf339",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/benches/benches/bevy_ecs/iteration/iter_simple_system.rs",
    "func": "use bevy_ecs::prelude::*;\nuse glam::*;\n\n#[derive(Component, Copy, Clone)]\nstruct Transform(Mat4);\n\n#[derive(Component, Copy, Clone)]\nstruct Position(Vec3);\n\n#[derive(Component, Copy, Clone)]\nstruct Rotation(Vec3);\n\n#[derive(Component, Copy, Clone)]\nstruct Velocity(Vec3);\n\npub struct Benchmark(World, Box<dyn System<In = (), Out = ()>>);\n\nimpl Benchmark {\n    pub fn new() -> Self {\n        let mut world = World::new();\n\n        world.spawn_batch(\n            core::iter::repeat((\n                Transform(Mat4::from_scale(Vec3::ONE)),\n                Position(Vec3::X),\n                Rotation(Vec3::X),\n                Velocity(Vec3::X),\n            ))\n            .take(10_000),\n        );\n\n        fn query_system(mut query: Query<(&Velocity, &mut Position)>) {\n            for (velocity, mut position) in &mut query {\n                position.0 += velocity.0;\n            }\n        }\n\n        let mut system = IntoSystem::into_system(query_system);\n        system.initialize(&mut world);\n        system.update_archetype_component_access(world.as_unsafe_world_cell());\n        Self(world, Box::new(system))\n    }\n\n    #[inline(never)]\n    pub fn run(&mut self) {\n        self.1.run((), &mut self.0);\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "5e500a9cd37829fc5c7b1897393a26573726820a",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/benches/benches/bevy_ecs/world/mod.rs",
    "func": "use criterion::criterion_group;\n\nmod commands;\nuse commands::*;\n\nmod despawn;\nuse despawn::*;\n\nmod despawn_recursive;\nuse despawn_recursive::*;\n\nmod spawn;\nuse spawn::*;\n\nmod world_get;\nuse world_get::*;\n\nmod entity_hash;\nuse entity_hash::*;\n\ncriterion_group!(\n    world_benches,\n    empty_commands,\n    spawn_commands,\n    insert_commands,\n    fake_commands,\n    zero_sized_commands,\n    medium_sized_commands,\n    large_sized_commands,\n    world_entity,\n    world_get,\n    world_query_get,\n    world_query_iter,\n    world_query_for_each,\n    world_spawn,\n    world_despawn,\n    world_despawn_recursive,\n    query_get,\n    query_get_many::<2>,\n    query_get_many::<5>,\n    query_get_many::<10>,\n    entity_set_build_and_lookup\n);\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "93bec6bbe6df4b66aa7525092de81e53ea1635f7",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/benches/benches/bevy_render/torus.rs",
    "func": "use criterion::{black_box, criterion_group, criterion_main, Criterion};\n\nuse bevy_render::mesh::TorusMeshBuilder;\n\nfn torus(c: &mut Criterion) {\n    c.bench_function(\"build_torus\", |b| {\n        b.iter(|| black_box(TorusMeshBuilder::new(black_box(0.5), black_box(1.0))));\n    });\n}\n\ncriterion_group!(benches, torus,);\ncriterion_main!(benches);\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "6b744e319952426691a949cd35e923313be4f579",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/benches/benches/bevy_reflect/list.rs",
    "func": "use core::{iter, time::Duration};\n\nuse bevy_reflect::{DynamicList, List};\nuse criterion::{\n    black_box, criterion_group, criterion_main, measurement::Measurement, BatchSize,\n    BenchmarkGroup, BenchmarkId, Criterion, Throughput,\n};\n\ncriterion_group!(\n    benches,\n    concrete_list_apply,\n    concrete_list_clone_dynamic,\n    dynamic_list_apply,\n    dynamic_list_push\n);\ncriterion_main!(benches);\n\nconst WARM_UP_TIME: Duration = Duration::from_millis(500);\nconst MEASUREMENT_TIME: Duration = Duration::from_secs(4);\n\n// log10 scaling\nconst SIZES: [usize; 5] = [100_usize, 316, 1000, 3162, 10000];\n\nfn list_apply<M, LBase, LPatch, F1, F2, F3>(\n    group: &mut BenchmarkGroup<M>,\n    bench_name: &str,\n    f_base: F1,\n    f_patch: F3,\n) where\n    M: Measurement,\n    LBase: List,\n    LPatch: List,\n    F1: Fn(usize) -> F2,\n    F2: Fn() -> LBase,\n    F3: Fn(usize) -> LPatch,\n{\n    for size in SIZES {\n        group.throughput(Throughput::Elements(size as u64));\n\n        group.bench_with_input(\n            BenchmarkId::new(bench_name, size),\n            &size,\n            |bencher, &size| {\n                let f_base = f_base(size);\n                let patch = f_patch(size);\n                bencher.iter_batched(\n                    f_base,\n                    |mut base| base.apply(black_box(&patch)),\n                    BatchSize::SmallInput,\n                );\n            },\n        );\n    }\n}\n\nfn concrete_list_apply(criterion: &mut Criterion) {\n    let mut group = criterion.benchmark_group(\"concrete_list_apply\");\n    group.warm_up_time(WARM_UP_TIME);\n    group.measurement_time(MEASUREMENT_TIME);\n\n    let empty_base = |_: usize| Vec::<u64>::new;\n    let full_base = |size: usize| move || iter::repeat(0).take(size).collect::<Vec<u64>>();\n    let patch = |size: usize| iter::repeat(1).take(size).collect::<Vec<u64>>();\n\n    list_apply(&mut group, \"empty_base_concrete_patch\", empty_base, patch);\n\n    list_apply(&mut group, \"empty_base_dynamic_patch\", empty_base, |size| {\n        patch(size).clone_dynamic()\n    });\n\n    list_apply(&mut group, \"same_len_concrete_patch\", full_base, patch);\n\n    list_apply(&mut group, \"same_len_dynamic_patch\", full_base, |size| {\n        patch(size).clone_dynamic()\n    });\n\n    group.finish();\n}\n\nfn concrete_list_clone_dynamic(criterion: &mut Criterion) {\n    let mut group = criterion.benchmark_group(\"concrete_list_clone_dynamic\");\n    group.warm_up_time(WARM_UP_TIME);\n    group.measurement_time(MEASUREMENT_TIME);\n\n    for size in SIZES {\n        group.throughput(Throughput::Elements(size as u64));\n\n        group.bench_with_input(\n            BenchmarkId::from_parameter(size),\n            &size,\n            |bencher, &size| {\n                let v = iter::repeat(0).take(size).collect::<Vec<_>>();\n\n                bencher.iter(|| black_box(&v).clone_dynamic());\n            },\n        );\n    }\n\n    group.finish();\n}\n\nfn dynamic_list_push(criterion: &mut Criterion) {\n    let mut group = criterion.benchmark_group(\"dynamic_list_push\");\n    group.warm_up_time(WARM_UP_TIME);\n    group.measurement_time(MEASUREMENT_TIME);\n\n    for size in SIZES {\n        group.throughput(Throughput::Elements(size as u64));\n\n        group.bench_with_input(\n            BenchmarkId::from_parameter(size),\n            &size,\n            |bencher, &size| {\n                let src = iter::repeat(()).take(size).collect::<Vec<_>>();\n                let dst = DynamicList::default();\n\n                bencher.iter_batched(\n                    || (src.clone(), dst.clone_dynamic()),\n                    |(src, mut dst)| {\n                        for item in src {\n                            dst.push(item);\n                        }\n                    },\n                    BatchSize::SmallInput,\n                );\n            },\n        );\n    }\n\n    group.finish();\n}\n\nfn dynamic_list_apply(criterion: &mut Criterion) {\n    let mut group = criterion.benchmark_group(\"dynamic_list_apply\");\n    group.warm_up_time(WARM_UP_TIME);\n    group.measurement_time(MEASUREMENT_TIME);\n\n    let empty_base = |_: usize| || Vec::<u64>::new().clone_dynamic();\n    let full_base = |size: usize| move || iter::repeat(0).take(size).collect::<Vec<u64>>();\n    let patch = |size: usize| iter::repeat(1).take(size).collect::<Vec<u64>>();\n\n    list_apply(&mut group, \"empty_base_concrete_patch\", empty_base, patch);\n\n    list_apply(&mut group, \"empty_base_dynamic_patch\", empty_base, |size| {\n        patch(size).clone_dynamic()\n    });\n\n    list_apply(&mut group, \"same_len_concrete_patch\", full_base, patch);\n\n    list_apply(&mut group, \"same_len_dynamic_patch\", full_base, |size| {\n        patch(size).clone_dynamic()\n    });\n\n    group.finish();\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "8ff07c3bd27a21be1c01de10d4611e3e67aac0e4",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/benches/benches/bevy_reflect/map.rs",
    "func": "use core::{fmt::Write, iter, time::Duration};\n\nuse bevy_reflect::{DynamicMap, Map};\nuse bevy_utils::HashMap;\nuse criterion::{\n    black_box, criterion_group, criterion_main, measurement::Measurement, BatchSize,\n    BenchmarkGroup, BenchmarkId, Criterion, Throughput,\n};\n\ncriterion_group!(\n    benches,\n    concrete_map_apply,\n    dynamic_map_apply,\n    dynamic_map_get,\n    dynamic_map_insert\n);\ncriterion_main!(benches);\n\nconst WARM_UP_TIME: Duration = Duration::from_millis(500);\nconst MEASUREMENT_TIME: Duration = Duration::from_secs(4);\nconst SIZES: [usize; 5] = [100, 316, 1000, 3162, 10000];\n\n/// Generic benchmark for applying one `Map` to another.\n///\n/// `f_base` is a function which takes an input size and produces a generator\n/// for new base maps. `f_patch` is a function which produces a map to be\n/// applied to the base map.\nfn map_apply<M, MBase, MPatch, F1, F2, F3>(\n    group: &mut BenchmarkGroup<M>,\n    bench_name: &str,\n    f_base: F1,\n    f_patch: F3,\n) where\n    M: Measurement,\n    MBase: Map,\n    MPatch: Map,\n    F1: Fn(usize) -> F2,\n    F2: Fn() -> MBase,\n    F3: Fn(usize) -> MPatch,\n{\n    for size in SIZES {\n        group.throughput(Throughput::Elements(size as u64));\n        group.bench_with_input(\n            BenchmarkId::new(bench_name, size),\n            &size,\n            |bencher, &size| {\n                let f_base = f_base(size);\n                bencher.iter_batched(\n                    || (f_base(), f_patch(size)),\n                    |(mut base, patch)| base.apply(black_box(&patch)),\n                    BatchSize::SmallInput,\n                );\n            },\n        );\n    }\n}\n\nfn concrete_map_apply(criterion: &mut Criterion) {\n    let mut group = criterion.benchmark_group(\"concrete_map_apply\");\n    group.warm_up_time(WARM_UP_TIME);\n    group.measurement_time(MEASUREMENT_TIME);\n\n    let empty_base = |_: usize| HashMap::<u64, u64>::default;\n\n    let key_range_base = |size: usize| {\n        move || {\n            (0..size as u64)\n                .zip(iter::repeat(0))\n                .collect::<HashMap<u64, u64>>()\n        }\n    };\n\n    let key_range_patch = |size: usize| {\n        (0..size as u64)\n            .zip(iter::repeat(1))\n            .collect::<HashMap<u64, u64>>()\n    };\n\n    let disjoint_patch = |size: usize| {\n        (size as u64..2 * size as u64)\n            .zip(iter::repeat(1))\n            .collect::<HashMap<u64, u64>>()\n    };\n\n    map_apply(\n        &mut group,\n        \"empty_base_concrete_patch\",\n        empty_base,\n        key_range_patch,\n    );\n\n    map_apply(&mut group, \"empty_base_dynamic_patch\", empty_base, |size| {\n        key_range_patch(size).clone_dynamic()\n    });\n\n    map_apply(\n        &mut group,\n        \"same_keys_concrete_patch\",\n        key_range_base,\n        key_range_patch,\n    );\n\n    map_apply(\n        &mut group,\n        \"same_keys_dynamic_patch\",\n        key_range_base,\n        |size| key_range_patch(size).clone_dynamic(),\n    );\n\n    map_apply(\n        &mut group,\n        \"disjoint_keys_concrete_patch\",\n        key_range_base,\n        disjoint_patch,\n    );\n\n    map_apply(\n        &mut group,\n        \"disjoint_keys_dynamic_patch\",\n        key_range_base,\n        |size| disjoint_patch(size).clone_dynamic(),\n    );\n}\n\nfn u64_to_n_byte_key(k: u64, n: usize) -> String {\n    let mut key = String::with_capacity(n);\n    write!(&mut key, \"{}\", k).unwrap();\n\n    // Pad key to n bytes.\n    key.extend(iter::repeat('\\0').take(n - key.len()));\n    key\n}\n\nfn dynamic_map_apply(criterion: &mut Criterion) {\n    let mut group = criterion.benchmark_group(\"dynamic_map_apply\");\n    group.warm_up_time(WARM_UP_TIME);\n    group.measurement_time(MEASUREMENT_TIME);\n\n    let empty_base = |_: usize| DynamicMap::default;\n\n    let key_range_base = |size: usize| {\n        move || {\n            (0..size as u64)\n                .zip(iter::repeat(0))\n                .collect::<HashMap<u64, u64>>()\n                .clone_dynamic()\n        }\n    };\n\n    let key_range_patch = |size: usize| {\n        (0..size as u64)\n            .zip(iter::repeat(1))\n            .collect::<HashMap<u64, u64>>()\n    };\n\n    let disjoint_patch = |size: usize| {\n        (size as u64..2 * size as u64)\n            .zip(iter::repeat(1))\n            .collect::<HashMap<u64, u64>>()\n    };\n\n    map_apply(\n        &mut group,\n        \"empty_base_concrete_patch\",\n        empty_base,\n        key_range_patch,\n    );\n\n    map_apply(&mut group, \"empty_base_dynamic_patch\", empty_base, |size| {\n        key_range_patch(size).clone_dynamic()\n    });\n\n    map_apply(\n        &mut group,\n        \"same_keys_concrete_patch\",\n        key_range_base,\n        key_range_patch,\n    );\n\n    map_apply(\n        &mut group,\n        \"same_keys_dynamic_patch\",\n        key_range_base,\n        |size| key_range_patch(size).clone_dynamic(),\n    );\n\n    map_apply(\n        &mut group,\n        \"disjoint_keys_concrete_patch\",\n        key_range_base,\n        disjoint_patch,\n    );\n\n    map_apply(\n        &mut group,\n        \"disjoint_keys_dynamic_patch\",\n        key_range_base,\n        |size| disjoint_patch(size).clone_dynamic(),\n    );\n}\n\nfn dynamic_map_get(criterion: &mut Criterion) {\n    let mut group = criterion.benchmark_group(\"dynamic_map_get\");\n    group.warm_up_time(WARM_UP_TIME);\n    group.measurement_time(MEASUREMENT_TIME);\n\n    for size in SIZES {\n        group.throughput(Throughput::Elements(size as u64));\n        group.bench_with_input(\n            BenchmarkId::new(\"u64_keys\", size),\n            &size,\n            |bencher, &size| {\n                let mut map = DynamicMap::default();\n                for i in 0..size as u64 {\n                    map.insert(i, i);\n                }\n\n                bencher.iter(|| {\n                    for i in 0..size as u64 {\n                        let key = black_box(i);\n                        black_box(assert!(map.get(&key).is_some()));\n                    }\n                });\n            },\n        );\n    }\n\n    for size in SIZES {\n        group.throughput(Throughput::Elements(size as u64));\n        group.bench_with_input(\n            BenchmarkId::new(\"64_byte_keys\", size),\n            &size,\n            |bencher, &size| {\n                let mut map = DynamicMap::default();\n                let mut keys = Vec::with_capacity(size);\n                for i in 0..size as u64 {\n                    let key = u64_to_n_byte_key(i, 64);\n                    map.insert(key.clone(), i);\n                    keys.push(key);\n                }\n\n                bencher.iter(|| {\n                    for key in keys.iter().take(size) {\n                        let key = black_box(key);\n                        assert!(map.get(key).is_some());\n                    }\n                });\n            },\n        );\n    }\n}\n\nfn dynamic_map_insert(criterion: &mut Criterion) {\n    let mut group = criterion.benchmark_group(\"dynamic_map_insert\");\n    group.warm_up_time(WARM_UP_TIME);\n    group.measurement_time(MEASUREMENT_TIME);\n\n    for size in SIZES {\n        group.throughput(Throughput::Elements(size as u64));\n        group.bench_with_input(\n            BenchmarkId::new(\"u64_keys\", size),\n            &size,\n            |bencher, &size| {\n                bencher.iter_batched(\n                    DynamicMap::default,\n                    |mut map| {\n                        for i in 0..size as u64 {\n                            let key = black_box(i);\n                            black_box(map.insert(key, i));\n                        }\n                    },\n                    BatchSize::SmallInput,\n                );\n            },\n        );\n    }\n\n    for size in SIZES {\n        group.throughput(Throughput::Elements(size as u64));\n        group.bench_with_input(\n            BenchmarkId::new(\"64_byte_keys\", size),\n            &size,\n            |bencher, &size| {\n                let mut keys = Vec::with_capacity(size);\n                for i in 0..size {\n                    let key = u64_to_n_byte_key(i as u64, 64);\n                    keys.push(key);\n                }\n\n                bencher.iter_batched(\n                    || (DynamicMap::default(), keys.clone()),\n                    |(mut map, keys)| {\n                        for (i, key) in keys.into_iter().enumerate() {\n                            let key = black_box(key);\n                            map.insert(key, i);\n                        }\n                    },\n                    BatchSize::SmallInput,\n                );\n            },\n        );\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "ca89436ca2d774b54f197ad9241f40d0f39eb728",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/tools/compile_fail_utils/tests/example_tests/import.rs",
    "func": "// You can import anything defined in the dependencies table of the crate.\nuse ui_test::Config;\n\nfn wrong_type() {\n    let _ = Config::this_function_does_not_exist();\n    //~^ E0599\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "1dacff2cd0228a606834ce3a331b3c1368baeef0",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/tools/ci/src/commands/format.rs",
    "func": "use crate::{Flag, Prepare, PreparedCommand};\nuse argh::FromArgs;\nuse xshell::cmd;\n\n/// Check code formatting.\n#[derive(FromArgs, Default)]\n#[argh(subcommand, name = \"format\")]\npub struct FormatCommand {}\n\nimpl Prepare for FormatCommand {\n    fn prepare<'a>(&self, sh: &'a xshell::Shell, _flags: Flag) -> Vec<PreparedCommand<'a>> {\n        vec![PreparedCommand::new::<Self>(\n            cmd!(sh, \"cargo fmt --all -- --check\"),\n            \"Please run 'cargo fmt --all' to format your code.\",\n        )]\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "6be2272f9cb7c37895f28602a53dedd396832ed0",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/tools/ci/src/commands/clippy.rs",
    "func": "use crate::{Flag, Prepare, PreparedCommand};\nuse argh::FromArgs;\nuse xshell::cmd;\n\n/// Check for clippy warnings and errors.\n#[derive(FromArgs, Default)]\n#[argh(subcommand, name = \"clippy\")]\npub struct ClippyCommand {}\n\nimpl Prepare for ClippyCommand {\n    fn prepare<'a>(&self, sh: &'a xshell::Shell, _flags: Flag) -> Vec<PreparedCommand<'a>> {\n        vec![PreparedCommand::new::<Self>(\n            cmd!(\n                sh,\n                \"cargo clippy --workspace --all-targets --all-features -- -Dwarnings\"\n            ),\n            \"Please fix clippy errors in output above.\",\n        )]\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "16177f080274aef93ec1f6b7a780eb4d5e76dc8f",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/tools/build-templated-pages/src/features.rs",
    "func": "use core::cmp::Ordering;\nuse std::fs::File;\n\nuse serde::Serialize;\nuse tera::{Context, Tera};\nuse toml_edit::DocumentMut;\n\nuse crate::Command;\n\n#[derive(Debug, Serialize, PartialEq, Eq)]\nstruct Feature {\n    name: String,\n    description: String,\n    is_default: bool,\n}\n\nimpl Ord for Feature {\n    fn cmp(&self, other: &Self) -> Ordering {\n        self.name.cmp(&other.name)\n    }\n}\n\nimpl PartialOrd for Feature {\n    fn partial_cmp(&self, other: &Self) -> Option<Ordering> {\n        Some(self.cmp(other))\n    }\n}\n\nfn parse_features(panic_on_missing: bool) -> Vec<Feature> {\n    let manifest_file = std::fs::read_to_string(\"Cargo.toml\").unwrap();\n    let manifest = manifest_file.parse::<DocumentMut>().unwrap();\n\n    let features = manifest[\"features\"].as_table().unwrap();\n    let default: Vec<_> = features\n        .get(\"default\")\n        .unwrap()\n        .as_array()\n        .unwrap()\n        .iter()\n        .flat_map(|v| {\n            core::iter::once(v.as_str().unwrap().to_string()).chain(\n                features\n                    .get(v.as_str().unwrap())\n                    .unwrap()\n                    .as_array()\n                    .unwrap()\n                    .iter()\n                    .map(|v| v.as_str().unwrap().to_string()),\n            )\n        })\n        .collect();\n\n    features\n        .get_values()\n        .iter()\n        .flat_map(|(key, _)| {\n            let key = key[0];\n\n            if key == \"default\" {\n                None\n            } else {\n                let name = key\n                    .as_repr()\n                    .unwrap()\n                    .as_raw()\n                    .as_str()\n                    .unwrap()\n                    .to_string();\n                if let Some(description) = key.leaf_decor().prefix() {\n                    let description = description.as_str().unwrap().to_string();\n                    if !description.starts_with(\"\\n# \") || !description.ends_with('\\n') {\n                        panic!(\"Missing description for feature {name}\");\n                    }\n                    let description = description\n                        .strip_prefix(\"\\n# \")\n                        .unwrap()\n                        .strip_suffix('\\n')\n                        .unwrap()\n                        .to_string();\n                    Some(Feature {\n                        is_default: default.contains(&name),\n                        name,\n                        description,\n                    })\n                } else if panic_on_missing {\n                    panic!(\"Missing description for feature {name}\");\n                } else {\n                    None\n                }\n            }\n        })\n        .collect()\n}\n\npub(crate) fn check(what_to_run: Command) {\n    let mut features = parse_features(what_to_run.contains(Command::CHECK_MISSING));\n    features.sort();\n\n    if what_to_run.contains(Command::UPDATE) {\n        let mut context = Context::new();\n        context.insert(\"features\", &features);\n        Tera::new(\"docs-template/*.md.tpl\")\n            .expect(\"error parsing template\")\n            .render_to(\n                \"features.md.tpl\",\n                &context,\n                File::create(\"docs/cargo_features.md\").expect(\"error creating file\"),\n            )\n            .expect(\"error rendering template\");\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "8da3c3ba66b5439d760775a49fc530e0166912f8",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_state/src/state/transitions.rs",
    "func": "use core::{marker::PhantomData, mem};\n\nuse bevy_ecs::{\n    event::{Event, EventReader, EventWriter},\n    schedule::{IntoSystemSetConfigs, Schedule, ScheduleLabel, Schedules, SystemSet},\n    system::{Commands, In, ResMut},\n    world::World,\n};\n\nuse super::{resources::State, states::States};\n\n/// The label of a [`Schedule`] that **only** runs whenever [`State<S>`] enters the provided state.\n///\n/// This schedule ignores identity transitions.\n#[derive(ScheduleLabel, Clone, Debug, PartialEq, Eq, Hash)]\npub struct OnEnter<S: States>(pub S);\n\n/// The label of a [`Schedule`] that **only** runs whenever [`State<S>`] exits the provided state.\n///\n/// This schedule ignores identity transitions.\n#[derive(ScheduleLabel, Clone, Debug, PartialEq, Eq, Hash)]\npub struct OnExit<S: States>(pub S);\n\n/// The label of a [`Schedule`] that **only** runs whenever [`State<S>`]\n/// exits AND enters the provided `exited` and `entered` states.\n///\n/// Systems added to this schedule are always ran *after* [`OnExit`], and *before* [`OnEnter`].\n///\n/// This schedule will run on identity transitions.\n#[derive(ScheduleLabel, Clone, Debug, PartialEq, Eq, Hash)]\npub struct OnTransition<S: States> {\n    /// The state being exited.\n    pub exited: S,\n    /// The state being entered.\n    pub entered: S,\n}\n\n/// Runs [state transitions](States).\n///\n/// By default, it will be triggered after `PreUpdate`, but\n/// you can manually trigger it at arbitrary times by creating an exclusive\n/// system to run the schedule.\n///\n/// ```rust\n/// use bevy_state::prelude::*;\n/// use bevy_ecs::prelude::*;\n///\n/// fn run_state_transitions(world: &mut World) {\n///     let _ = world.try_run_schedule(StateTransition);\n/// }\n/// ```\n#[derive(ScheduleLabel, Clone, Debug, PartialEq, Eq, Hash)]\npub struct StateTransition;\n\n/// Event sent when any state transition of `S` happens.\n/// This includes identity transitions, where `exited` and `entered` have the same value.\n///\n/// If you know exactly what state you want to respond to ahead of time, consider [`OnEnter`], [`OnTransition`], or [`OnExit`]\n#[derive(Debug, Copy, Clone, PartialEq, Eq, Event)]\npub struct StateTransitionEvent<S: States> {\n    /// The state being exited.\n    pub exited: Option<S>,\n    /// The state being entered.\n    pub entered: Option<S>,\n}\n\n/// Applies state transitions and runs transitions schedules in order.\n///\n/// These system sets are run sequentially, in the order of the enum variants.\n#[derive(SystemSet, Clone, Debug, PartialEq, Eq, Hash)]\npub enum StateTransitionSteps {\n    /// States apply their transitions from [`NextState`](super::NextState)\n    /// and compute functions based on their parent states.\n    DependentTransitions,\n    /// Exit schedules are executed in leaf to root order\n    ExitSchedules,\n    /// Transition schedules are executed in arbitrary order.\n    TransitionSchedules,\n    /// Enter schedules are executed in root to leaf order.\n    EnterSchedules,\n}\n\n#[derive(SystemSet, Clone, Debug, PartialEq, Eq, Hash)]\n/// System set that runs exit schedule(s) for state `S`.\npub struct ExitSchedules<S: States>(PhantomData<S>);\n\nimpl<S: States> Default for ExitSchedules<S> {\n    fn default() -> Self {\n        Self(Default::default())\n    }\n}\n\n#[derive(SystemSet, Clone, Debug, PartialEq, Eq, Hash)]\n/// System set that runs transition schedule(s) for state `S`.\npub struct TransitionSchedules<S: States>(PhantomData<S>);\n\nimpl<S: States> Default for TransitionSchedules<S> {\n    fn default() -> Self {\n        Self(Default::default())\n    }\n}\n\n#[derive(SystemSet, Clone, Debug, PartialEq, Eq, Hash)]\n/// System set that runs enter schedule(s) for state `S`.\npub struct EnterSchedules<S: States>(PhantomData<S>);\n\nimpl<S: States> Default for EnterSchedules<S> {\n    fn default() -> Self {\n        Self(Default::default())\n    }\n}\n\n/// System set that applies transitions for state `S`.\n#[derive(SystemSet, Clone, Debug, PartialEq, Eq, Hash)]\npub(crate) struct ApplyStateTransition<S: States>(PhantomData<S>);\n\nimpl<S: States> Default for ApplyStateTransition<S> {\n    fn default() -> Self {\n        Self(Default::default())\n    }\n}\n\n/// This function actually applies a state change, and registers the required\n/// schedules for downstream computed states and transition schedules.\n///\n/// The `new_state` is an option to allow for removal - `None` will trigger the\n/// removal of the `State<S>` resource from the [`World`].\npub(crate) fn internal_apply_state_transition<S: States>(\n    mut event: EventWriter<StateTransitionEvent<S>>,\n    mut commands: Commands,\n    current_state: Option<ResMut<State<S>>>,\n    new_state: Option<S>,\n) {\n    match new_state {\n        Some(entered) => {\n            match current_state {\n                // If the [`State<S>`] resource exists, and the state is not the one we are\n                // entering - we need to set the new value, compute dependent states, send transition events\n                // and register transition schedules.\n                Some(mut state_resource) => {\n                    let exited = match *state_resource == entered {\n                        true => entered.clone(),\n                        false => mem::replace(&mut state_resource.0, entered.clone()),\n                    };\n\n                    // Transition events are sent even for same state transitions\n                    // Although enter and exit schedules are not run by default.\n                    event.send(StateTransitionEvent {\n                        exited: Some(exited.clone()),\n                        entered: Some(entered.clone()),\n                    });\n                }\n                None => {\n                    // If the [`State<S>`] resource does not exist, we create it, compute dependent states, send a transition event and register the `OnEnter` schedule.\n                    commands.insert_resource(State(entered.clone()));\n\n                    event.send(StateTransitionEvent {\n                        exited: None,\n                        entered: Some(entered.clone()),\n                    });\n                }\n            };\n        }\n        None => {\n            // We first remove the [`State<S>`] resource, and if one existed we compute dependent states, send a transition event and run the `OnExit` schedule.\n            if let Some(resource) = current_state {\n                commands.remove_resource::<State<S>>();\n\n                event.send(StateTransitionEvent {\n                    exited: Some(resource.get().clone()),\n                    entered: None,\n                });\n            }\n        }\n    }\n}\n\n/// Sets up the schedules and systems for handling state transitions\n/// within a [`World`].\n///\n/// Runs automatically when using `App` to insert states, but needs to\n/// be added manually in other situations.\npub fn setup_state_transitions_in_world(world: &mut World) {\n    let mut schedules = world.get_resource_or_init::<Schedules>();\n    if schedules.contains(StateTransition) {\n        return;\n    }\n    let mut schedule = Schedule::new(StateTransition);\n    schedule.configure_sets(\n        (\n            StateTransitionSteps::DependentTransitions,\n            StateTransitionSteps::ExitSchedules,\n            StateTransitionSteps::TransitionSchedules,\n            StateTransitionSteps::EnterSchedules,\n        )\n            .chain(),\n    );\n    schedules.insert(schedule);\n}\n\n/// Returns the latest state transition event of type `S`, if any are available.\npub fn last_transition<S: States>(\n    mut reader: EventReader<StateTransitionEvent<S>>,\n) -> Option<StateTransitionEvent<S>> {\n    reader.read().last().cloned()\n}\n\npub(crate) fn run_enter<S: States>(\n    transition: In<Option<StateTransitionEvent<S>>>,\n    world: &mut World,\n) {\n    let Some(transition) = transition.0 else {\n        return;\n    };\n    if transition.entered == transition.exited {\n        return;\n    }\n    let Some(entered) = transition.entered else {\n        return;\n    };\n\n    let _ = world.try_run_schedule(OnEnter(entered));\n}\n\npub(crate) fn run_exit<S: States>(\n    transition: In<Option<StateTransitionEvent<S>>>,\n    world: &mut World,\n) {\n    let Some(transition) = transition.0 else {\n        return;\n    };\n    if transition.entered == transition.exited {\n        return;\n    }\n    let Some(exited) = transition.exited else {\n        return;\n    };\n\n    let _ = world.try_run_schedule(OnExit(exited));\n}\n\npub(crate) fn run_transition<S: States>(\n    transition: In<Option<StateTransitionEvent<S>>>,\n    world: &mut World,\n) {\n    let Some(transition) = transition.0 else {\n        return;\n    };\n    let Some(exited) = transition.exited else {\n        return;\n    };\n    let Some(entered) = transition.entered else {\n        return;\n    };\n\n    let _ = world.try_run_schedule(OnTransition { exited, entered });\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "333d41006bae633fa8aaac1be0403750b7580d0b",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_core_pipeline/src/auto_exposure/settings.rs",
    "func": "use core::ops::RangeInclusive;\n\nuse super::compensation_curve::AutoExposureCompensationCurve;\nuse bevy_asset::Handle;\nuse bevy_ecs::{prelude::Component, reflect::ReflectComponent};\nuse bevy_image::Image;\nuse bevy_reflect::{std_traits::ReflectDefault, Reflect};\nuse bevy_render::extract_component::ExtractComponent;\nuse bevy_utils::default;\n\n/// Component that enables auto exposure for an HDR-enabled 2d or 3d camera.\n///\n/// Auto exposure adjusts the exposure of the camera automatically to\n/// simulate the human eye's ability to adapt to different lighting conditions.\n///\n/// Bevy's implementation builds a 64 bin histogram of the scene's luminance,\n/// and then adjusts the exposure so that the average brightness of the final\n/// render will be middle gray. Because it's using a histogram, some details can\n/// be selectively ignored or emphasized. Outliers like shadows and specular\n/// highlights can be ignored, and certain areas can be given more (or less)\n/// weight based on a mask.\n///\n/// # Usage Notes\n///\n/// **Auto Exposure requires compute shaders and is not compatible with WebGL2.**\n#[derive(Component, Clone, Reflect, ExtractComponent)]\n#[reflect(Component, Default)]\npub struct AutoExposure {\n    /// The range of exposure values for the histogram.\n    ///\n    /// Pixel values below this range will be ignored, and pixel values above this range will be\n    /// clamped in the sense that they will count towards the highest bin in the histogram.\n    /// The default value is `-8.0..=8.0`.\n    pub range: RangeInclusive<f32>,\n\n    /// The portion of the histogram to consider when metering.\n    ///\n    /// By default, the darkest 10% and the brightest 10% of samples are ignored,\n    /// so the default value is `0.10..=0.90`.\n    pub filter: RangeInclusive<f32>,\n\n    /// The speed at which the exposure adapts from dark to bright scenes, in F-stops per second.\n    pub speed_brighten: f32,\n\n    /// The speed at which the exposure adapts from bright to dark scenes, in F-stops per second.\n    pub speed_darken: f32,\n\n    /// The distance in F-stops from the target exposure from where to transition from animating\n    /// in linear fashion to animating exponentially. This helps against jittering when the\n    /// target exposure keeps on changing slightly from frame to frame, while still maintaining\n    /// a relatively slow animation for big changes in scene brightness.\n    ///\n    /// ```text\n    /// ev\n    ///                       \u2794\u25cf\u2510\n    /// |              \u2b08         \u251c exponential section\n    /// \u2502        \u2b08               \u2518\n    /// \u2502    \u2b08                   \u2510\n    /// \u2502  \u2b08                     \u251c linear section\n    /// \u2502\u2b08                       \u2518\n    /// \u25cf\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 time\n    /// ```\n    ///\n    /// The default value is 1.5.\n    pub exponential_transition_distance: f32,\n\n    /// The mask to apply when metering. The mask will cover the entire screen, where:\n    /// * `(0.0, 0.0)` is the top-left corner,\n    /// * `(1.0, 1.0)` is the bottom-right corner.\n    ///\n    /// Only the red channel of the texture is used.\n    /// The sample at the current screen position will be used to weight the contribution\n    /// of each pixel to the histogram:\n    /// * 0.0 means the pixel will not contribute to the histogram,\n    /// * 1.0 means the pixel will contribute fully to the histogram.\n    ///\n    /// The default value is a white image, so all pixels contribute equally.\n    ///\n    /// # Usage Notes\n    ///\n    /// The mask is quantized to 16 discrete levels because of limitations in the compute shader\n    /// implementation.\n    pub metering_mask: Handle<Image>,\n\n    /// Exposure compensation curve to apply after metering.\n    /// The default value is a flat line at 0.0.\n    /// For more information, see [`AutoExposureCompensationCurve`].\n    pub compensation_curve: Handle<AutoExposureCompensationCurve>,\n}\n\n#[deprecated(since = \"0.15.0\", note = \"Renamed to `AutoExposure`\")]\npub type AutoExposureSettings = AutoExposure;\n\nimpl Default for AutoExposure {\n    fn default() -> Self {\n        Self {\n            range: -8.0..=8.0,\n            filter: 0.10..=0.90,\n            speed_brighten: 3.0,\n            speed_darken: 1.0,\n            exponential_transition_distance: 1.5,\n            metering_mask: default(),\n            compensation_curve: default(),\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "583cc8ef1f6e8cafa8291ea72d9346ced6b966d9",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_core_pipeline/src/auto_exposure/compensation_curve.rs",
    "func": "use bevy_asset::prelude::*;\nuse bevy_ecs::system::{lifetimeless::SRes, SystemParamItem};\nuse bevy_math::{cubic_splines::CubicGenerator, FloatExt, Vec2};\nuse bevy_reflect::prelude::*;\nuse bevy_render::{\n    render_asset::{RenderAsset, RenderAssetUsages},\n    render_resource::{\n        Extent3d, ShaderType, TextureDescriptor, TextureDimension, TextureFormat, TextureUsages,\n        TextureView, UniformBuffer,\n    },\n    renderer::{RenderDevice, RenderQueue},\n};\nuse thiserror::Error;\n\nconst LUT_SIZE: usize = 256;\n\n/// An auto exposure compensation curve.\n/// This curve is used to map the average log luminance of a scene to an\n/// exposure compensation value, to allow for fine control over the final exposure.\n#[derive(Asset, Reflect, Debug, Clone)]\n#[reflect(Default)]\npub struct AutoExposureCompensationCurve {\n    /// The minimum log luminance value in the curve. (the x-axis)\n    min_log_lum: f32,\n    /// The maximum log luminance value in the curve. (the x-axis)\n    max_log_lum: f32,\n    /// The minimum exposure compensation value in the curve. (the y-axis)\n    min_compensation: f32,\n    /// The maximum exposure compensation value in the curve. (the y-axis)\n    max_compensation: f32,\n    /// The lookup table for the curve. Uploaded to the GPU as a 1D texture.\n    /// Each value in the LUT is a `u8` representing a normalized exposure compensation value:\n    /// * `0` maps to `min_compensation`\n    /// * `255` maps to `max_compensation`\n    ///\n    /// The position in the LUT corresponds to the normalized log luminance value.\n    /// * `0` maps to `min_log_lum`\n    /// * `LUT_SIZE - 1` maps to `max_log_lum`\n    lut: [u8; LUT_SIZE],\n}\n\n/// Various errors that can occur when constructing an [`AutoExposureCompensationCurve`].\n#[derive(Error, Debug)]\npub enum AutoExposureCompensationCurveError {\n    /// The curve couldn't be built in the first place.\n    #[error(\"curve could not be constructed from the given data\")]\n    InvalidCurve,\n    /// A discontinuity was found in the curve.\n    #[error(\"discontinuity found between curve segments\")]\n    DiscontinuityFound,\n    /// The curve is not monotonically increasing on the x-axis.\n    #[error(\"curve is not monotonically increasing on the x-axis\")]\n    NotMonotonic,\n}\n\nimpl Default for AutoExposureCompensationCurve {\n    fn default() -> Self {\n        Self {\n            min_log_lum: 0.0,\n            max_log_lum: 0.0,\n            min_compensation: 0.0,\n            max_compensation: 0.0,\n            lut: [0; LUT_SIZE],\n        }\n    }\n}\n\nimpl AutoExposureCompensationCurve {\n    const SAMPLES_PER_SEGMENT: usize = 64;\n\n    /// Build an [`AutoExposureCompensationCurve`] from a [`CubicGenerator<Vec2>`], where:\n    /// - x represents the average log luminance of the scene in EV-100;\n    /// - y represents the exposure compensation value in F-stops.\n    ///\n    /// # Errors\n    ///\n    /// If the curve is not monotonically increasing on the x-axis,\n    /// returns [`AutoExposureCompensationCurveError::NotMonotonic`].\n    ///\n    /// If a discontinuity is found between curve segments,\n    /// returns [`AutoExposureCompensationCurveError::DiscontinuityFound`].\n    ///\n    /// # Example\n    ///\n    /// ```\n    /// # use bevy_asset::prelude::*;\n    /// # use bevy_math::vec2;\n    /// # use bevy_math::cubic_splines::*;\n    /// # use bevy_core_pipeline::auto_exposure::AutoExposureCompensationCurve;\n    /// # let mut compensation_curves = Assets::<AutoExposureCompensationCurve>::default();\n    /// let curve: Handle<AutoExposureCompensationCurve> = compensation_curves.add(\n    ///     AutoExposureCompensationCurve::from_curve(LinearSpline::new([\n    ///         vec2(-4.0, -2.0),\n    ///         vec2(0.0, 0.0),\n    ///         vec2(2.0, 0.0),\n    ///         vec2(4.0, 2.0),\n    ///     ]))\n    ///     .unwrap()\n    /// );\n    /// ```\n    pub fn from_curve<T>(curve: T) -> Result<Self, AutoExposureCompensationCurveError>\n    where\n        T: CubicGenerator<Vec2>,\n    {\n        let Ok(curve) = curve.to_curve() else {\n            return Err(AutoExposureCompensationCurveError::InvalidCurve);\n        };\n\n        let min_log_lum = curve.position(0.0).x;\n        let max_log_lum = curve.position(curve.segments().len() as f32).x;\n        let log_lum_range = max_log_lum - min_log_lum;\n\n        let mut lut = [0.0; LUT_SIZE];\n\n        let mut previous = curve.position(0.0);\n        let mut min_compensation = previous.y;\n        let mut max_compensation = previous.y;\n\n        for segment in curve {\n            if segment.position(0.0) != previous {\n                return Err(AutoExposureCompensationCurveError::DiscontinuityFound);\n            }\n\n            for i in 1..Self::SAMPLES_PER_SEGMENT {\n                let current = segment.position(i as f32 / (Self::SAMPLES_PER_SEGMENT - 1) as f32);\n\n                if current.x < previous.x {\n                    return Err(AutoExposureCompensationCurveError::NotMonotonic);\n                }\n\n                // Find the range of LUT entries that this line segment covers.\n                let (lut_begin, lut_end) = (\n                    ((previous.x - min_log_lum) / log_lum_range) * (LUT_SIZE - 1) as f32,\n                    ((current.x - min_log_lum) / log_lum_range) * (LUT_SIZE - 1) as f32,\n                );\n                let lut_inv_range = 1.0 / (lut_end - lut_begin);\n\n                // Iterate over all LUT entries whose pixel centers fall within the current segment.\n                #[allow(clippy::needless_range_loop)]\n                for i in lut_begin.ceil() as usize..=lut_end.floor() as usize {\n                    let t = (i as f32 - lut_begin) * lut_inv_range;\n                    lut[i] = previous.y.lerp(current.y, t);\n                    min_compensation = min_compensation.min(lut[i]);\n                    max_compensation = max_compensation.max(lut[i]);\n                }\n\n                previous = current;\n            }\n        }\n\n        let compensation_range = max_compensation - min_compensation;\n\n        Ok(Self {\n            min_log_lum,\n            max_log_lum,\n            min_compensation,\n            max_compensation,\n            lut: if compensation_range > 0.0 {\n                let scale = 255.0 / compensation_range;\n                lut.map(|f: f32| ((f - min_compensation) * scale) as u8)\n            } else {\n                [0; LUT_SIZE]\n            },\n        })\n    }\n}\n\n/// The GPU-representation of an [`AutoExposureCompensationCurve`].\n/// Consists of a [`TextureView`] with the curve's data,\n/// and a [`UniformBuffer`] with the curve's extents.\npub struct GpuAutoExposureCompensationCurve {\n    pub(super) texture_view: TextureView,\n    pub(super) extents: UniformBuffer<AutoExposureCompensationCurveUniform>,\n}\n\n#[derive(ShaderType, Clone, Copy)]\npub(super) struct AutoExposureCompensationCurveUniform {\n    min_log_lum: f32,\n    inv_log_lum_range: f32,\n    min_compensation: f32,\n    compensation_range: f32,\n}\n\nimpl RenderAsset for GpuAutoExposureCompensationCurve {\n    type SourceAsset = AutoExposureCompensationCurve;\n    type Param = (SRes<RenderDevice>, SRes<RenderQueue>);\n\n    fn asset_usage(_: &Self::SourceAsset) -> RenderAssetUsages {\n        RenderAssetUsages::RENDER_WORLD\n    }\n\n    fn prepare_asset(\n        source: Self::SourceAsset,\n        _: AssetId<Self::SourceAsset>,\n        (render_device, render_queue): &mut SystemParamItem<Self::Param>,\n    ) -> Result<Self, bevy_render::render_asset::PrepareAssetError<Self::SourceAsset>> {\n        let texture = render_device.create_texture_with_data(\n            render_queue,\n            &TextureDescriptor {\n                label: None,\n                size: Extent3d {\n                    width: LUT_SIZE as u32,\n                    height: 1,\n                    depth_or_array_layers: 1,\n                },\n                mip_level_count: 1,\n                sample_count: 1,\n                dimension: TextureDimension::D1,\n                format: TextureFormat::R8Unorm,\n                usage: TextureUsages::COPY_DST | TextureUsages::TEXTURE_BINDING,\n                view_formats: &[TextureFormat::R8Unorm],\n            },\n            Default::default(),\n            &source.lut,\n        );\n\n        let texture_view = texture.create_view(&Default::default());\n\n        let mut extents = UniformBuffer::from(AutoExposureCompensationCurveUniform {\n            min_log_lum: source.min_log_lum,\n            inv_log_lum_range: 1.0 / (source.max_log_lum - source.min_log_lum),\n            min_compensation: source.min_compensation,\n            compensation_range: source.max_compensation - source.min_compensation,\n        });\n\n        extents.write_buffer(render_device, render_queue);\n\n        Ok(GpuAutoExposureCompensationCurve {\n            texture_view,\n            extents,\n        })\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "695e7eb1cfaa2dce4fd35bf531d73728c153483b",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_dev_tools/src/ci_testing/systems.rs",
    "func": "use super::config::*;\nuse bevy_app::AppExit;\nuse bevy_ecs::prelude::*;\nuse bevy_render::view::screenshot::{save_to_disk, Screenshot};\nuse bevy_utils::tracing::{debug, info};\n\npub(crate) fn send_events(world: &mut World, mut current_frame: Local<u32>) {\n    let mut config = world.resource_mut::<CiTestingConfig>();\n\n    // Take all events for the current frame, leaving all the remaining alone.\n    let events = core::mem::take(&mut config.events);\n    let (to_run, remaining): (Vec<_>, _) = events\n        .into_iter()\n        .partition(|event| event.0 == *current_frame);\n    config.events = remaining;\n\n    for CiTestingEventOnFrame(_, event) in to_run {\n        debug!(\"Handling event: {:?}\", event);\n        match event {\n            CiTestingEvent::AppExit => {\n                world.send_event(AppExit::Success);\n                info!(\"Exiting after {} frames. Test successful!\", *current_frame);\n            }\n            CiTestingEvent::Screenshot => {\n                let path = format!(\"./screenshot-{}.png\", *current_frame);\n                world\n                    .spawn(Screenshot::primary_window())\n                    .observe(save_to_disk(path));\n                info!(\"Took a screenshot at frame {}.\", *current_frame);\n            }\n            // Custom events are forwarded to the world.\n            CiTestingEvent::Custom(event_string) => {\n                world.send_event(CiTestingCustomEvent(event_string));\n            }\n        }\n    }\n\n    *current_frame += 1;\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "8eeccd8c940486d9fc78c3174a26a824d5cfab66",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_dev_tools/src/ui_debug_overlay/mod.rs",
    "func": "//! A visual representation of UI node sizes.\nuse core::any::{Any, TypeId};\n\nuse bevy_app::{App, Plugin, PostUpdate};\nuse bevy_color::Hsla;\nuse bevy_core::Name;\nuse bevy_core_pipeline::core_2d::Camera2d;\nuse bevy_ecs::{prelude::*, system::SystemParam};\nuse bevy_gizmos::{config::GizmoConfigStore, prelude::Gizmos, AppGizmoBuilder};\nuse bevy_hierarchy::{Children, Parent};\nuse bevy_math::{Vec2, Vec3Swizzles};\nuse bevy_render::{\n    camera::RenderTarget,\n    prelude::*,\n    view::{RenderLayers, VisibilitySystems},\n};\nuse bevy_transform::{prelude::GlobalTransform, TransformSystem};\nuse bevy_ui::{ComputedNode, DefaultUiCamera, Display, Node, TargetCamera, UiScale};\nuse bevy_utils::{default, warn_once};\nuse bevy_window::{PrimaryWindow, Window, WindowRef};\n\nuse inset::InsetGizmo;\n\nuse self::inset::UiGizmosDebug;\n\nmod inset;\n\n/// The [`Camera::order`] index used by the layout debug camera.\npub const LAYOUT_DEBUG_CAMERA_ORDER: isize = 255;\n/// The [`RenderLayers`] used by the debug gizmos and the debug camera.\npub const LAYOUT_DEBUG_LAYERS: RenderLayers = RenderLayers::layer(16);\n\n#[derive(Clone, Copy)]\nstruct LayoutRect {\n    pos: Vec2,\n    size: Vec2,\n}\n\nimpl LayoutRect {\n    fn new(trans: &GlobalTransform, node: &ComputedNode, scale: f32) -> Self {\n        let mut this = Self {\n            pos: trans.translation().xy() * scale,\n            size: node.size() * scale,\n        };\n        this.pos -= this.size / 2.;\n        this\n    }\n}\n\n#[derive(Component, Debug, Clone, Default)]\nstruct DebugOverlayCamera;\n\n/// The debug overlay options.\n#[derive(Resource, Clone, Default)]\npub struct UiDebugOptions {\n    /// Whether the overlay is enabled.\n    pub enabled: bool,\n    layout_gizmos_camera: Option<Entity>,\n}\nimpl UiDebugOptions {\n    /// This will toggle the enabled field, setting it to false if true and true if false.\n    pub fn toggle(&mut self) {\n        self.enabled = !self.enabled;\n    }\n}\n\n/// The system responsible to change the [`Camera`] config based on changes in [`UiDebugOptions`] and [`GizmoConfig`](bevy_gizmos::prelude::GizmoConfig).\nfn update_debug_camera(\n    mut gizmo_config: ResMut<GizmoConfigStore>,\n    mut options: ResMut<UiDebugOptions>,\n    mut cmds: Commands,\n    mut debug_cams: Query<&mut Camera, With<DebugOverlayCamera>>,\n) {\n    if !options.is_changed() && !gizmo_config.is_changed() {\n        return;\n    }\n    if !options.enabled {\n        let Some(cam) = options.layout_gizmos_camera else {\n            return;\n        };\n        let Ok(mut cam) = debug_cams.get_mut(cam) else {\n            return;\n        };\n        cam.is_active = false;\n        if let Some((config, _)) = gizmo_config.get_config_mut_dyn(&TypeId::of::<UiGizmosDebug>()) {\n            config.enabled = false;\n        }\n    } else {\n        let spawn_cam = || {\n            cmds.spawn((\n                Camera2d,\n                OrthographicProjection {\n                    far: 1000.0,\n                    viewport_origin: Vec2::new(0.0, 0.0),\n                    ..OrthographicProjection::default_3d()\n                },\n                Camera {\n                    order: LAYOUT_DEBUG_CAMERA_ORDER,\n                    clear_color: ClearColorConfig::None,\n                    ..default()\n                },\n                LAYOUT_DEBUG_LAYERS.clone(),\n                DebugOverlayCamera,\n                Name::new(\"Layout Debug Camera\"),\n            ))\n            .id()\n        };\n        if let Some((config, _)) = gizmo_config.get_config_mut_dyn(&TypeId::of::<UiGizmosDebug>()) {\n            config.enabled = true;\n            config.render_layers = LAYOUT_DEBUG_LAYERS.clone();\n        }\n        let cam = *options.layout_gizmos_camera.get_or_insert_with(spawn_cam);\n        let Ok(mut cam) = debug_cams.get_mut(cam) else {\n            return;\n        };\n        cam.is_active = true;\n    }\n}\n\n/// The function that goes over every children of given [`Entity`], skipping the not visible ones and drawing the gizmos outlines.\nfn outline_nodes(outline: &OutlineParam, draw: &mut InsetGizmo, this_entity: Entity, scale: f32) {\n    let Ok(to_iter) = outline.children.get(this_entity) else {\n        return;\n    };\n\n    for (entity, trans, node, computed_node, children) in outline.nodes.iter_many(to_iter) {\n        if matches!(node.display, Display::None) {\n            continue;\n        }\n\n        if let Ok(view_visibility) = outline.view_visibility.get(entity) {\n            if !view_visibility.get() {\n                continue;\n            }\n        }\n        let rect = LayoutRect::new(trans, computed_node, scale);\n        outline_node(entity, rect, draw);\n        if children.is_some() {\n            outline_nodes(outline, draw, entity, scale);\n        }\n        draw.clear_scope(rect);\n    }\n}\n\ntype NodesQuery = (\n    Entity,\n    &'static GlobalTransform,\n    &'static Node,\n    &'static ComputedNode,\n    Option<&'static Children>,\n);\n\n#[derive(SystemParam)]\nstruct OutlineParam<'w, 's> {\n    gizmo_config: Res<'w, GizmoConfigStore>,\n    children: Query<'w, 's, &'static Children>,\n    nodes: Query<'w, 's, NodesQuery>,\n    view_visibility: Query<'w, 's, &'static ViewVisibility>,\n    ui_scale: Res<'w, UiScale>,\n}\n\ntype CameraQuery<'w, 's> = Query<'w, 's, &'static Camera, With<DebugOverlayCamera>>;\n\n#[derive(SystemParam)]\nstruct CameraParam<'w, 's> {\n    debug_camera: Query<'w, 's, &'static Camera, With<DebugOverlayCamera>>,\n    cameras: Query<'w, 's, &'static Camera, Without<DebugOverlayCamera>>,\n    primary_window: Query<'w, 's, &'static Window, With<PrimaryWindow>>,\n    default_ui_camera: DefaultUiCamera<'w, 's>,\n}\n\n/// system responsible for drawing the gizmos lines around all the node roots, iterating recursively through all visible children.\nfn outline_roots(\n    outline: OutlineParam,\n    draw: Gizmos<UiGizmosDebug>,\n    cam: CameraParam,\n    roots: Query<\n        (\n            Entity,\n            &GlobalTransform,\n            &ComputedNode,\n            Option<&ViewVisibility>,\n            Option<&TargetCamera>,\n        ),\n        Without<Parent>,\n    >,\n    window: Query<&Window, With<PrimaryWindow>>,\n    nonprimary_windows: Query<&Window, Without<PrimaryWindow>>,\n    options: Res<UiDebugOptions>,\n) {\n    if !options.enabled {\n        return;\n    }\n    if !nonprimary_windows.is_empty() {\n        warn_once!(\n            \"The layout debug view only uses the primary window scale, \\\n            you might notice gaps between container lines\"\n        );\n    }\n    let window_scale = window.get_single().map_or(1., Window::scale_factor);\n    let scale_factor = outline.ui_scale.0;\n\n    // We let the line be defined by the window scale alone\n    let line_width = outline\n        .gizmo_config\n        .get_config_dyn(&UiGizmosDebug.type_id())\n        .map_or(2., |(config, _)| config.line.width)\n        / window_scale;\n    let mut draw = InsetGizmo::new(draw, cam.debug_camera, line_width);\n    for (entity, trans, node, view_visibility, maybe_target_camera) in &roots {\n        if let Some(view_visibility) = view_visibility {\n            // If the entity isn't visible, we will not draw any lines.\n            if !view_visibility.get() {\n                continue;\n            }\n        }\n        // We skip ui in other windows that are not the primary one\n        if let Some(camera_entity) = maybe_target_camera\n            .map(|target| target.0)\n            .or(cam.default_ui_camera.get())\n        {\n            let Ok(camera) = cam.cameras.get(camera_entity) else {\n                // The camera wasn't found. Either the Camera don't exist or the Camera is the debug Camera, that we want to skip and warn\n                warn_once!(\"Camera {:?} wasn't found for debug overlay\", camera_entity);\n                continue;\n            };\n            match camera.target {\n                RenderTarget::Window(window_ref) => {\n                    if let WindowRef::Entity(window_entity) = window_ref {\n                        if cam.primary_window.get(window_entity).is_err() {\n                            // This window isn't the primary, so we skip this root.\n                            continue;\n                        }\n                    }\n                }\n                // Hard to know the results of this, better skip this target.\n                _ => continue,\n            }\n        }\n\n        let rect = LayoutRect::new(trans, node, scale_factor);\n        outline_node(entity, rect, &mut draw);\n        outline_nodes(&outline, &mut draw, entity, scale_factor);\n    }\n}\n\n/// Function responsible for drawing the gizmos lines around the given Entity\nfn outline_node(entity: Entity, rect: LayoutRect, draw: &mut InsetGizmo) {\n    let color = Hsla::sequential_dispersed(entity.index());\n\n    draw.rect_2d(rect, color.into());\n    draw.set_scope(rect);\n}\n\n/// The debug overlay plugin.\n///\n/// This spawns a new camera with a low order, and draws gizmo.\n///\n/// Note that due to limitation with [`bevy_gizmos`], multiple windows with this feature\n/// enabled isn't supported and the lines are only drawn in the [`PrimaryWindow`]\npub struct DebugUiPlugin;\nimpl Plugin for DebugUiPlugin {\n    fn build(&self, app: &mut App) {\n        app.init_resource::<UiDebugOptions>()\n            .init_gizmo_group::<UiGizmosDebug>()\n            .add_systems(\n                PostUpdate,\n                (\n                    update_debug_camera,\n                    outline_roots\n                        .after(TransformSystem::TransformPropagate)\n                        // This needs to run before VisibilityPropagate so it can relies on ViewVisibility\n                        .before(VisibilitySystems::VisibilityPropagate),\n                )\n                    .chain(),\n            );\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "28aebeb188f727f5f064e65a5ce076bfbd833386",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_math/src/bounding/raycast2d.rs",
    "func": "use super::{Aabb2d, BoundingCircle, IntersectsVolume};\nuse crate::{\n    ops::{self, FloatPow},\n    Dir2, Ray2d, Vec2,\n};\n\n#[cfg(feature = \"bevy_reflect\")]\nuse bevy_reflect::Reflect;\n\n/// A raycast intersection test for 2D bounding volumes\n#[derive(Clone, Debug)]\n#[cfg_attr(feature = \"bevy_reflect\", derive(Reflect), reflect(Debug))]\npub struct RayCast2d {\n    /// The ray for the test\n    pub ray: Ray2d,\n    /// The maximum distance for the ray\n    pub max: f32,\n    /// The multiplicative inverse direction of the ray\n    direction_recip: Vec2,\n}\n\nimpl RayCast2d {\n    /// Construct a [`RayCast2d`] from an origin, [`Dir2`], and max distance.\n    pub fn new(origin: Vec2, direction: Dir2, max: f32) -> Self {\n        Self::from_ray(Ray2d { origin, direction }, max)\n    }\n\n    /// Construct a [`RayCast2d`] from a [`Ray2d`] and max distance.\n    pub fn from_ray(ray: Ray2d, max: f32) -> Self {\n        Self {\n            ray,\n            direction_recip: ray.direction.recip(),\n            max,\n        }\n    }\n\n    /// Get the cached multiplicative inverse of the direction of the ray.\n    pub fn direction_recip(&self) -> Vec2 {\n        self.direction_recip\n    }\n\n    /// Get the distance of an intersection with an [`Aabb2d`], if any.\n    pub fn aabb_intersection_at(&self, aabb: &Aabb2d) -> Option<f32> {\n        let (min_x, max_x) = if self.ray.direction.x.is_sign_positive() {\n            (aabb.min.x, aabb.max.x)\n        } else {\n            (aabb.max.x, aabb.min.x)\n        };\n        let (min_y, max_y) = if self.ray.direction.y.is_sign_positive() {\n            (aabb.min.y, aabb.max.y)\n        } else {\n            (aabb.max.y, aabb.min.y)\n        };\n\n        // Calculate the minimum/maximum time for each axis based on how much the direction goes that\n        // way. These values can get arbitrarily large, or even become NaN, which is handled by the\n        // min/max operations below\n        let tmin_x = (min_x - self.ray.origin.x) * self.direction_recip.x;\n        let tmin_y = (min_y - self.ray.origin.y) * self.direction_recip.y;\n        let tmax_x = (max_x - self.ray.origin.x) * self.direction_recip.x;\n        let tmax_y = (max_y - self.ray.origin.y) * self.direction_recip.y;\n\n        // An axis that is not relevant to the ray direction will be NaN. When one of the arguments\n        // to min/max is NaN, the other argument is used.\n        // An axis for which the direction is the wrong way will return an arbitrarily large\n        // negative value.\n        let tmin = tmin_x.max(tmin_y).max(0.);\n        let tmax = tmax_y.min(tmax_x).min(self.max);\n\n        if tmin <= tmax {\n            Some(tmin)\n        } else {\n            None\n        }\n    }\n\n    /// Get the distance of an intersection with a [`BoundingCircle`], if any.\n    pub fn circle_intersection_at(&self, circle: &BoundingCircle) -> Option<f32> {\n        let offset = self.ray.origin - circle.center;\n        let projected = offset.dot(*self.ray.direction);\n        let closest_point = offset - projected * *self.ray.direction;\n        let distance_squared = circle.radius().squared() - closest_point.length_squared();\n        if distance_squared < 0.\n            || ops::copysign(projected.squared(), -projected) < -distance_squared\n        {\n            None\n        } else {\n            let toi = -projected - ops::sqrt(distance_squared);\n            if toi > self.max {\n                None\n            } else {\n                Some(toi.max(0.))\n            }\n        }\n    }\n}\n\nimpl IntersectsVolume<Aabb2d> for RayCast2d {\n    fn intersects(&self, volume: &Aabb2d) -> bool {\n        self.aabb_intersection_at(volume).is_some()\n    }\n}\n\nimpl IntersectsVolume<BoundingCircle> for RayCast2d {\n    fn intersects(&self, volume: &BoundingCircle) -> bool {\n        self.circle_intersection_at(volume).is_some()\n    }\n}\n\n/// An intersection test that casts an [`Aabb2d`] along a ray.\n#[derive(Clone, Debug)]\n#[cfg_attr(feature = \"bevy_reflect\", derive(Reflect), reflect(Debug))]\npub struct AabbCast2d {\n    /// The ray along which to cast the bounding volume\n    pub ray: RayCast2d,\n    /// The aabb that is being cast\n    pub aabb: Aabb2d,\n}\n\nimpl AabbCast2d {\n    /// Construct an [`AabbCast2d`] from an [`Aabb2d`], origin, [`Dir2`], and max distance.\n    pub fn new(aabb: Aabb2d, origin: Vec2, direction: Dir2, max: f32) -> Self {\n        Self::from_ray(aabb, Ray2d { origin, direction }, max)\n    }\n\n    /// Construct an [`AabbCast2d`] from an [`Aabb2d`], [`Ray2d`], and max distance.\n    pub fn from_ray(aabb: Aabb2d, ray: Ray2d, max: f32) -> Self {\n        Self {\n            ray: RayCast2d::from_ray(ray, max),\n            aabb,\n        }\n    }\n\n    /// Get the distance at which the [`Aabb2d`]s collide, if at all.\n    pub fn aabb_collision_at(&self, mut aabb: Aabb2d) -> Option<f32> {\n        aabb.min -= self.aabb.max;\n        aabb.max -= self.aabb.min;\n        self.ray.aabb_intersection_at(&aabb)\n    }\n}\n\nimpl IntersectsVolume<Aabb2d> for AabbCast2d {\n    fn intersects(&self, volume: &Aabb2d) -> bool {\n        self.aabb_collision_at(*volume).is_some()\n    }\n}\n\n/// An intersection test that casts a [`BoundingCircle`] along a ray.\n#[derive(Clone, Debug)]\n#[cfg_attr(feature = \"bevy_reflect\", derive(Reflect), reflect(Debug))]\npub struct BoundingCircleCast {\n    /// The ray along which to cast the bounding volume\n    pub ray: RayCast2d,\n    /// The circle that is being cast\n    pub circle: BoundingCircle,\n}\n\nimpl BoundingCircleCast {\n    /// Construct a [`BoundingCircleCast`] from a [`BoundingCircle`], origin, [`Dir2`], and max distance.\n    pub fn new(circle: BoundingCircle, origin: Vec2, direction: Dir2, max: f32) -> Self {\n        Self::from_ray(circle, Ray2d { origin, direction }, max)\n    }\n\n    /// Construct a [`BoundingCircleCast`] from a [`BoundingCircle`], [`Ray2d`], and max distance.\n    pub fn from_ray(circle: BoundingCircle, ray: Ray2d, max: f32) -> Self {\n        Self {\n            ray: RayCast2d::from_ray(ray, max),\n            circle,\n        }\n    }\n\n    /// Get the distance at which the [`BoundingCircle`]s collide, if at all.\n    pub fn circle_collision_at(&self, mut circle: BoundingCircle) -> Option<f32> {\n        circle.center -= self.circle.center;\n        circle.circle.radius += self.circle.radius();\n        self.ray.circle_intersection_at(&circle)\n    }\n}\n\nimpl IntersectsVolume<BoundingCircle> for BoundingCircleCast {\n    fn intersects(&self, volume: &BoundingCircle) -> bool {\n        self.circle_collision_at(*volume).is_some()\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    const EPSILON: f32 = 0.001;\n\n    #[test]\n    fn test_ray_intersection_circle_hits() {\n        for (test, volume, expected_distance) in &[\n            (\n                // Hit the center of a centered bounding circle\n                RayCast2d::new(Vec2::Y * -5., Dir2::Y, 90.),\n                BoundingCircle::new(Vec2::ZERO, 1.),\n                4.,\n            ),\n            (\n                // Hit the center of a centered bounding circle, but from the other side\n                RayCast2d::new(Vec2::Y * 5., -Dir2::Y, 90.),\n                BoundingCircle::new(Vec2::ZERO, 1.),\n                4.,\n            ),\n            (\n                // Hit the center of an offset circle\n                RayCast2d::new(Vec2::ZERO, Dir2::Y, 90.),\n                BoundingCircle::new(Vec2::Y * 3., 2.),\n                1.,\n            ),\n            (\n                // Just barely hit the circle before the max distance\n                RayCast2d::new(Vec2::X, Dir2::Y, 1.),\n                BoundingCircle::new(Vec2::ONE, 0.01),\n                0.99,\n            ),\n            (\n                // Hit a circle off-center\n                RayCast2d::new(Vec2::X, Dir2::Y, 90.),\n                BoundingCircle::new(Vec2::Y * 5., 2.),\n                3.268,\n            ),\n            (\n                // Barely hit a circle on the side\n                RayCast2d::new(Vec2::X * 0.99999, Dir2::Y, 90.),\n                BoundingCircle::new(Vec2::Y * 5., 1.),\n                4.996,\n            ),\n        ] {\n            assert!(\n                test.intersects(volume),\n                \"Case:\\n  Test: {test:?}\\n  Volume: {volume:?}\\n  Expected distance: {expected_distance:?}\",\n            );\n            let actual_distance = test.circle_intersection_at(volume).unwrap();\n            assert!(\n                ops::abs(actual_distance - expected_distance) < EPSILON,\n                \"Case:\\n  Test: {test:?}\\n  Volume: {volume:?}\\n  Expected distance: {expected_distance:?}\\n  Actual distance: {actual_distance}\",\n            );\n\n            let inverted_ray = RayCast2d::new(test.ray.origin, -test.ray.direction, test.max);\n            assert!(\n                !inverted_ray.intersects(volume),\n                \"Case:\\n  Test: {test:?}\\n  Volume: {volume:?}\\n  Expected distance: {expected_distance:?}\",\n            );\n        }\n    }\n\n    #[test]\n    fn test_ray_intersection_circle_misses() {\n        for (test, volume) in &[\n            (\n                // The ray doesn't go in the right direction\n                RayCast2d::new(Vec2::ZERO, Dir2::X, 90.),\n                BoundingCircle::new(Vec2::Y * 2., 1.),\n            ),\n            (\n                // Ray's alignment isn't enough to hit the circle\n                RayCast2d::new(Vec2::ZERO, Dir2::from_xy(1., 1.).unwrap(), 90.),\n                BoundingCircle::new(Vec2::Y * 2., 1.),\n            ),\n            (\n                // The ray's maximum distance isn't high enough\n                RayCast2d::new(Vec2::ZERO, Dir2::Y, 0.5),\n                BoundingCircle::new(Vec2::Y * 2., 1.),\n            ),\n        ] {\n            assert!(\n                !test.intersects(volume),\n                \"Case:\\n  Test: {test:?}\\n  Volume: {volume:?}\",\n            );\n        }\n    }\n\n    #[test]\n    fn test_ray_intersection_circle_inside() {\n        let volume = BoundingCircle::new(Vec2::splat(0.5), 1.);\n        for origin in &[Vec2::X, Vec2::Y, Vec2::ONE, Vec2::ZERO] {\n            for direction in &[Dir2::X, Dir2::Y, -Dir2::X, -Dir2::Y] {\n                for max in &[0., 1., 900.] {\n                    let test = RayCast2d::new(*origin, *direction, *max);\n\n                    assert!(\n                        test.intersects(&volume),\n                        \"Case:\\n  origin: {origin:?}\\n  Direction: {direction:?}\\n  Max: {max}\",\n                    );\n\n                    let actual_distance = test.circle_intersection_at(&volume);\n                    assert_eq!(\n                        actual_distance,\n                        Some(0.),\n                        \"Case:\\n  origin: {origin:?}\\n  Direction: {direction:?}\\n  Max: {max}\",\n                    );\n                }\n            }\n        }\n    }\n\n    #[test]\n    fn test_ray_intersection_aabb_hits() {\n        for (test, volume, expected_distance) in &[\n            (\n                // Hit the center of a centered aabb\n                RayCast2d::new(Vec2::Y * -5., Dir2::Y, 90.),\n                Aabb2d::new(Vec2::ZERO, Vec2::ONE),\n                4.,\n            ),\n            (\n                // Hit the center of a centered aabb, but from the other side\n                RayCast2d::new(Vec2::Y * 5., -Dir2::Y, 90.),\n                Aabb2d::new(Vec2::ZERO, Vec2::ONE),\n                4.,\n            ),\n            (\n                // Hit the center of an offset aabb\n                RayCast2d::new(Vec2::ZERO, Dir2::Y, 90.),\n                Aabb2d::new(Vec2::Y * 3., Vec2::splat(2.)),\n                1.,\n            ),\n            (\n                // Just barely hit the aabb before the max distance\n                RayCast2d::new(Vec2::X, Dir2::Y, 1.),\n                Aabb2d::new(Vec2::ONE, Vec2::splat(0.01)),\n                0.99,\n            ),\n            (\n                // Hit an aabb off-center\n                RayCast2d::new(Vec2::X, Dir2::Y, 90.),\n                Aabb2d::new(Vec2::Y * 5., Vec2::splat(2.)),\n                3.,\n            ),\n            (\n                // Barely hit an aabb on corner\n                RayCast2d::new(Vec2::X * -0.001, Dir2::from_xy(1., 1.).unwrap(), 90.),\n                Aabb2d::new(Vec2::Y * 2., Vec2::ONE),\n                1.414,\n            ),\n        ] {\n            assert!(\n                test.intersects(volume),\n                \"Case:\\n  Test: {test:?}\\n  Volume: {volume:?}\\n  Expected distance: {expected_distance:?}\",\n            );\n            let actual_distance = test.aabb_intersection_at(volume).unwrap();\n            assert!(\n                ops::abs(actual_distance - expected_distance) < EPSILON,\n                \"Case:\\n  Test: {test:?}\\n  Volume: {volume:?}\\n  Expected distance: {expected_distance:?}\\n  Actual distance: {actual_distance}\",\n            );\n\n            let inverted_ray = RayCast2d::new(test.ray.origin, -test.ray.direction, test.max);\n            assert!(\n                !inverted_ray.intersects(volume),\n                \"Case:\\n  Test: {test:?}\\n  Volume: {volume:?}\\n  Expected distance: {expected_distance:?}\",\n            );\n        }\n    }\n\n    #[test]\n    fn test_ray_intersection_aabb_misses() {\n        for (test, volume) in &[\n            (\n                // The ray doesn't go in the right direction\n                RayCast2d::new(Vec2::ZERO, Dir2::X, 90.),\n                Aabb2d::new(Vec2::Y * 2., Vec2::ONE),\n            ),\n            (\n                // Ray's alignment isn't enough to hit the aabb\n                RayCast2d::new(Vec2::ZERO, Dir2::from_xy(1., 0.99).unwrap(), 90.),\n                Aabb2d::new(Vec2::Y * 2., Vec2::ONE),\n            ),\n            (\n                // The ray's maximum distance isn't high enough\n                RayCast2d::new(Vec2::ZERO, Dir2::Y, 0.5),\n                Aabb2d::new(Vec2::Y * 2., Vec2::ONE),\n            ),\n        ] {\n            assert!(\n                !test.intersects(volume),\n                \"Case:\\n  Test: {test:?}\\n  Volume: {volume:?}\",\n            );\n        }\n    }\n\n    #[test]\n    fn test_ray_intersection_aabb_inside() {\n        let volume = Aabb2d::new(Vec2::splat(0.5), Vec2::ONE);\n        for origin in &[Vec2::X, Vec2::Y, Vec2::ONE, Vec2::ZERO] {\n            for direction in &[Dir2::X, Dir2::Y, -Dir2::X, -Dir2::Y] {\n                for max in &[0., 1., 900.] {\n                    let test = RayCast2d::new(*origin, *direction, *max);\n\n                    assert!(\n                        test.intersects(&volume),\n                        \"Case:\\n  origin: {origin:?}\\n  Direction: {direction:?}\\n  Max: {max}\",\n                    );\n\n                    let actual_distance = test.aabb_intersection_at(&volume);\n                    assert_eq!(\n                        actual_distance,\n                        Some(0.),\n                        \"Case:\\n  origin: {origin:?}\\n  Direction: {direction:?}\\n  Max: {max}\",\n                    );\n                }\n            }\n        }\n    }\n\n    #[test]\n    fn test_aabb_cast_hits() {\n        for (test, volume, expected_distance) in &[\n            (\n                // Hit the center of the aabb, that a ray would've also hit\n                AabbCast2d::new(Aabb2d::new(Vec2::ZERO, Vec2::ONE), Vec2::ZERO, Dir2::Y, 90.),\n                Aabb2d::new(Vec2::Y * 5., Vec2::ONE),\n                3.,\n            ),\n            (\n                // Hit the center of the aabb, but from the other side\n                AabbCast2d::new(\n                    Aabb2d::new(Vec2::ZERO, Vec2::ONE),\n                    Vec2::Y * 10.,\n                    -Dir2::Y,\n                    90.,\n                ),\n                Aabb2d::new(Vec2::Y * 5., Vec2::ONE),\n                3.,\n            ),\n            (\n                // Hit the edge of the aabb, that a ray would've missed\n                AabbCast2d::new(\n                    Aabb2d::new(Vec2::ZERO, Vec2::ONE),\n                    Vec2::X * 1.5,\n                    Dir2::Y,\n                    90.,\n                ),\n                Aabb2d::new(Vec2::Y * 5., Vec2::ONE),\n                3.,\n            ),\n            (\n                // Hit the edge of the aabb, by casting an off-center AABB\n                AabbCast2d::new(\n                    Aabb2d::new(Vec2::X * -2., Vec2::ONE),\n                    Vec2::X * 3.,\n                    Dir2::Y,\n                    90.,\n                ),\n                Aabb2d::new(Vec2::Y * 5., Vec2::ONE),\n                3.,\n            ),\n        ] {\n            assert!(\n                test.intersects(volume),\n                \"Case:\\n  Test: {test:?}\\n  Volume: {volume:?}\\n  Expected distance: {expected_distance:?}\",\n            );\n            let actual_distance = test.aabb_collision_at(*volume).unwrap();\n            assert!(\n                ops::abs(actual_distance - expected_distance) < EPSILON,\n                \"Case:\\n  Test: {test:?}\\n  Volume: {volume:?}\\n  Expected distance: {expected_distance:?}\\n  Actual distance: {actual_distance}\",\n            );\n\n            let inverted_ray =\n                RayCast2d::new(test.ray.ray.origin, -test.ray.ray.direction, test.ray.max);\n            assert!(\n                !inverted_ray.intersects(volume),\n                \"Case:\\n  Test: {test:?}\\n  Volume: {volume:?}\\n  Expected distance: {expected_distance:?}\",\n            );\n        }\n    }\n\n    #[test]\n    fn test_circle_cast_hits() {\n        for (test, volume, expected_distance) in &[\n            (\n                // Hit the center of the bounding circle, that a ray would've also hit\n                BoundingCircleCast::new(\n                    BoundingCircle::new(Vec2::ZERO, 1.),\n                    Vec2::ZERO,\n                    Dir2::Y,\n                    90.,\n                ),\n                BoundingCircle::new(Vec2::Y * 5., 1.),\n                3.,\n            ),\n            (\n                // Hit the center of the bounding circle, but from the other side\n                BoundingCircleCast::new(\n                    BoundingCircle::new(Vec2::ZERO, 1.),\n                    Vec2::Y * 10.,\n                    -Dir2::Y,\n                    90.,\n                ),\n                BoundingCircle::new(Vec2::Y * 5., 1.),\n                3.,\n            ),\n            (\n                // Hit the bounding circle off-center, that a ray would've missed\n                BoundingCircleCast::new(\n                    BoundingCircle::new(Vec2::ZERO, 1.),\n                    Vec2::X * 1.5,\n                    Dir2::Y,\n                    90.,\n                ),\n                BoundingCircle::new(Vec2::Y * 5., 1.),\n                3.677,\n            ),\n            (\n                // Hit the bounding circle off-center, by casting a circle that is off-center\n                BoundingCircleCast::new(\n                    BoundingCircle::new(Vec2::X * -1.5, 1.),\n                    Vec2::X * 3.,\n                    Dir2::Y,\n                    90.,\n                ),\n                BoundingCircle::new(Vec2::Y * 5., 1.),\n                3.677,\n            ),\n        ] {\n            assert!(\n                test.intersects(volume),\n                \"Case:\\n  Test: {test:?}\\n  Volume: {volume:?}\\n  Expected distance: {expected_distance:?}\",\n            );\n            let actual_distance = test.circle_collision_at(*volume).unwrap();\n            assert!(\n                ops::abs(actual_distance - expected_distance) < EPSILON,\n                \"Case:\\n  Test: {test:?}\\n  Volume: {volume:?}\\n  Expected distance: {expected_distance:?}\\n  Actual distance: {actual_distance}\",\n            );\n\n            let inverted_ray =\n                RayCast2d::new(test.ray.ray.origin, -test.ray.ray.direction, test.ray.max);\n            assert!(\n                !inverted_ray.intersects(volume),\n                \"Case:\\n  Test: {test:?}\\n  Volume: {volume:?}\\n  Expected distance: {expected_distance:?}\",\n            );\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "a9ff656fa59d43e9527709c1777914803282f062",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_math/src/bounding/bounded2d/primitive_impls.rs",
    "func": "//! Contains [`Bounded2d`] implementations for [geometric primitives](crate::primitives).\n\nuse crate::{\n    ops,\n    primitives::{\n        Annulus, Arc2d, Capsule2d, Circle, CircularSector, CircularSegment, Ellipse, Line2d,\n        Plane2d, Polygon, Polyline2d, Rectangle, RegularPolygon, Rhombus, Segment2d, Triangle2d,\n    },\n    Dir2, Isometry2d, Mat2, Rot2, Vec2,\n};\nuse core::f32::consts::{FRAC_PI_2, PI, TAU};\n\n#[cfg(feature = \"alloc\")]\nuse crate::primitives::{BoxedPolygon, BoxedPolyline2d};\n\nuse smallvec::SmallVec;\n\nuse super::{Aabb2d, Bounded2d, BoundingCircle};\n\nimpl Bounded2d for Circle {\n    fn aabb_2d(&self, isometry: impl Into<Isometry2d>) -> Aabb2d {\n        let isometry = isometry.into();\n        Aabb2d::new(isometry.translation, Vec2::splat(self.radius))\n    }\n\n    fn bounding_circle(&self, isometry: impl Into<Isometry2d>) -> BoundingCircle {\n        let isometry = isometry.into();\n        BoundingCircle::new(isometry.translation, self.radius)\n    }\n}\n\n// Compute the axis-aligned bounding points of a rotated arc, used for computing the AABB of arcs and derived shapes.\n// The return type has room for 7 points so that the CircularSector code can add an additional point.\n#[inline]\nfn arc_bounding_points(arc: Arc2d, rotation: impl Into<Rot2>) -> SmallVec<[Vec2; 7]> {\n    // Otherwise, the extreme points will always be either the endpoints or the axis-aligned extrema of the arc's circle.\n    // We need to compute which axis-aligned extrema are actually contained within the rotated arc.\n    let mut bounds = SmallVec::<[Vec2; 7]>::new();\n    let rotation = rotation.into();\n    bounds.push(rotation * arc.left_endpoint());\n    bounds.push(rotation * arc.right_endpoint());\n\n    // The half-angles are measured from a starting point of \u03c0/2, being the angle of Vec2::Y.\n    // Compute the normalized angles of the endpoints with the rotation taken into account, and then\n    // check if we are looking for an angle that is between or outside them.\n    let left_angle = ops::rem_euclid(FRAC_PI_2 + arc.half_angle + rotation.as_radians(), TAU);\n    let right_angle = ops::rem_euclid(FRAC_PI_2 - arc.half_angle + rotation.as_radians(), TAU);\n    let inverted = left_angle < right_angle;\n    for extremum in [Vec2::X, Vec2::Y, Vec2::NEG_X, Vec2::NEG_Y] {\n        let angle = ops::rem_euclid(extremum.to_angle(), TAU);\n        // If inverted = true, then right_angle > left_angle, so we are looking for an angle that is not between them.\n        // There's a chance that this condition fails due to rounding error, if the endpoint angle is juuuust shy of the axis.\n        // But in that case, the endpoint itself is within rounding error of the axis and will define the bounds just fine.\n        #[allow(clippy::nonminimal_bool)]\n        if !inverted && angle >= right_angle && angle <= left_angle\n            || inverted && (angle >= right_angle || angle <= left_angle)\n        {\n            bounds.push(extremum * arc.radius);\n        }\n    }\n    bounds\n}\n\nimpl Bounded2d for Arc2d {\n    fn aabb_2d(&self, isometry: impl Into<Isometry2d>) -> Aabb2d {\n        // If our arc covers more than a circle, just return the bounding box of the circle.\n        if self.half_angle >= PI {\n            return Circle::new(self.radius).aabb_2d(isometry);\n        }\n\n        let isometry = isometry.into();\n\n        Aabb2d::from_point_cloud(\n            Isometry2d::from_translation(isometry.translation),\n            &arc_bounding_points(*self, isometry.rotation),\n        )\n    }\n\n    fn bounding_circle(&self, isometry: impl Into<Isometry2d>) -> BoundingCircle {\n        let isometry = isometry.into();\n\n        // There are two possibilities for the bounding circle.\n        if self.is_major() {\n            // If the arc is major, then the widest distance between two points is a diameter of the arc's circle;\n            // therefore, that circle is the bounding radius.\n            BoundingCircle::new(isometry.translation, self.radius)\n        } else {\n            // Otherwise, the widest distance between two points is the chord,\n            // so a circle of that diameter around the midpoint will contain the entire arc.\n            let center = isometry.rotation * self.chord_midpoint();\n            BoundingCircle::new(center + isometry.translation, self.half_chord_length())\n        }\n    }\n}\n\nimpl Bounded2d for CircularSector {\n    fn aabb_2d(&self, isometry: impl Into<Isometry2d>) -> Aabb2d {\n        let isometry = isometry.into();\n\n        // If our sector covers more than a circle, just return the bounding box of the circle.\n        if self.half_angle() >= PI {\n            return Circle::new(self.radius()).aabb_2d(isometry);\n        }\n\n        // Otherwise, we use the same logic as for Arc2d, above, just with the circle's center as an additional possibility.\n        let mut bounds = arc_bounding_points(self.arc, isometry.rotation);\n        bounds.push(Vec2::ZERO);\n\n        Aabb2d::from_point_cloud(Isometry2d::from_translation(isometry.translation), &bounds)\n    }\n\n    fn bounding_circle(&self, isometry: impl Into<Isometry2d>) -> BoundingCircle {\n        if self.arc.is_major() {\n            let isometry = isometry.into();\n\n            // If the arc is major, that is, greater than a semicircle,\n            // then bounding circle is just the circle defining the sector.\n            BoundingCircle::new(isometry.translation, self.arc.radius)\n        } else {\n            // However, when the arc is minor,\n            // we need our bounding circle to include both endpoints of the arc as well as the circle center.\n            // This means we need the circumcircle of those three points.\n            // The circumcircle will always have a greater curvature than the circle itself, so it will contain\n            // the entire circular sector.\n            Triangle2d::new(\n                Vec2::ZERO,\n                self.arc.left_endpoint(),\n                self.arc.right_endpoint(),\n            )\n            .bounding_circle(isometry)\n        }\n    }\n}\n\nimpl Bounded2d for CircularSegment {\n    fn aabb_2d(&self, isometry: impl Into<Isometry2d>) -> Aabb2d {\n        self.arc.aabb_2d(isometry)\n    }\n\n    fn bounding_circle(&self, isometry: impl Into<Isometry2d>) -> BoundingCircle {\n        self.arc.bounding_circle(isometry)\n    }\n}\n\nimpl Bounded2d for Ellipse {\n    fn aabb_2d(&self, isometry: impl Into<Isometry2d>) -> Aabb2d {\n        let isometry = isometry.into();\n\n        //           V = (hh * cos(beta), hh * sin(beta))\n        //      #####*#####\n        //   ###     |     ###\n        //  #     hh |        #\n        // #         *---------* U = (hw * cos(alpha), hw * sin(alpha))\n        //  #            hw   #\n        //   ###           ###\n        //      ###########\n\n        let (hw, hh) = (self.half_size.x, self.half_size.y);\n\n        // Sine and cosine of rotation angle alpha.\n        let (alpha_sin, alpha_cos) = isometry.rotation.sin_cos();\n\n        // Sine and cosine of alpha + pi/2. We can avoid the trigonometric functions:\n        // sin(beta) = sin(alpha + pi/2) = cos(alpha)\n        // cos(beta) = cos(alpha + pi/2) = -sin(alpha)\n        let (beta_sin, beta_cos) = (alpha_cos, -alpha_sin);\n\n        // Compute points U and V, the extremes of the ellipse\n        let (ux, uy) = (hw * alpha_cos, hw * alpha_sin);\n        let (vx, vy) = (hh * beta_cos, hh * beta_sin);\n\n        let half_size = Vec2::new(ops::hypot(ux, vx), ops::hypot(uy, vy));\n\n        Aabb2d::new(isometry.translation, half_size)\n    }\n\n    fn bounding_circle(&self, isometry: impl Into<Isometry2d>) -> BoundingCircle {\n        let isometry = isometry.into();\n        BoundingCircle::new(isometry.translation, self.semi_major())\n    }\n}\n\nimpl Bounded2d for Annulus {\n    fn aabb_2d(&self, isometry: impl Into<Isometry2d>) -> Aabb2d {\n        let isometry = isometry.into();\n        Aabb2d::new(isometry.translation, Vec2::splat(self.outer_circle.radius))\n    }\n\n    fn bounding_circle(&self, isometry: impl Into<Isometry2d>) -> BoundingCircle {\n        let isometry = isometry.into();\n        BoundingCircle::new(isometry.translation, self.outer_circle.radius)\n    }\n}\n\nimpl Bounded2d for Rhombus {\n    fn aabb_2d(&self, isometry: impl Into<Isometry2d>) -> Aabb2d {\n        let isometry = isometry.into();\n\n        let [rotated_x_half_diagonal, rotated_y_half_diagonal] = [\n            isometry.rotation * Vec2::new(self.half_diagonals.x, 0.0),\n            isometry.rotation * Vec2::new(0.0, self.half_diagonals.y),\n        ];\n        let aabb_half_extent = rotated_x_half_diagonal\n            .abs()\n            .max(rotated_y_half_diagonal.abs());\n\n        Aabb2d {\n            min: -aabb_half_extent + isometry.translation,\n            max: aabb_half_extent + isometry.translation,\n        }\n    }\n\n    fn bounding_circle(&self, isometry: impl Into<Isometry2d>) -> BoundingCircle {\n        let isometry = isometry.into();\n        BoundingCircle::new(isometry.translation, self.circumradius())\n    }\n}\n\nimpl Bounded2d for Plane2d {\n    fn aabb_2d(&self, isometry: impl Into<Isometry2d>) -> Aabb2d {\n        let isometry = isometry.into();\n\n        let normal = isometry.rotation * *self.normal;\n        let facing_x = normal == Vec2::X || normal == Vec2::NEG_X;\n        let facing_y = normal == Vec2::Y || normal == Vec2::NEG_Y;\n\n        // Dividing `f32::MAX` by 2.0 is helpful so that we can do operations\n        // like growing or shrinking the AABB without breaking things.\n        let half_width = if facing_x { 0.0 } else { f32::MAX / 2.0 };\n        let half_height = if facing_y { 0.0 } else { f32::MAX / 2.0 };\n        let half_size = Vec2::new(half_width, half_height);\n\n        Aabb2d::new(isometry.translation, half_size)\n    }\n\n    fn bounding_circle(&self, isometry: impl Into<Isometry2d>) -> BoundingCircle {\n        let isometry = isometry.into();\n        BoundingCircle::new(isometry.translation, f32::MAX / 2.0)\n    }\n}\n\nimpl Bounded2d for Line2d {\n    fn aabb_2d(&self, isometry: impl Into<Isometry2d>) -> Aabb2d {\n        let isometry = isometry.into();\n\n        let direction = isometry.rotation * *self.direction;\n\n        // Dividing `f32::MAX` by 2.0 is helpful so that we can do operations\n        // like growing or shrinking the AABB without breaking things.\n        let max = f32::MAX / 2.0;\n        let half_width = if direction.x == 0.0 { 0.0 } else { max };\n        let half_height = if direction.y == 0.0 { 0.0 } else { max };\n        let half_size = Vec2::new(half_width, half_height);\n\n        Aabb2d::new(isometry.translation, half_size)\n    }\n\n    fn bounding_circle(&self, isometry: impl Into<Isometry2d>) -> BoundingCircle {\n        let isometry = isometry.into();\n        BoundingCircle::new(isometry.translation, f32::MAX / 2.0)\n    }\n}\n\nimpl Bounded2d for Segment2d {\n    fn aabb_2d(&self, isometry: impl Into<Isometry2d>) -> Aabb2d {\n        let isometry = isometry.into();\n\n        // Rotate the segment by `rotation`\n        let direction = isometry.rotation * *self.direction;\n        let half_size = (self.half_length * direction).abs();\n\n        Aabb2d::new(isometry.translation, half_size)\n    }\n\n    fn bounding_circle(&self, isometry: impl Into<Isometry2d>) -> BoundingCircle {\n        let isometry = isometry.into();\n        BoundingCircle::new(isometry.translation, self.half_length)\n    }\n}\n\nimpl<const N: usize> Bounded2d for Polyline2d<N> {\n    fn aabb_2d(&self, isometry: impl Into<Isometry2d>) -> Aabb2d {\n        Aabb2d::from_point_cloud(isometry, &self.vertices)\n    }\n\n    fn bounding_circle(&self, isometry: impl Into<Isometry2d>) -> BoundingCircle {\n        BoundingCircle::from_point_cloud(isometry, &self.vertices)\n    }\n}\n\n#[cfg(feature = \"alloc\")]\nimpl Bounded2d for BoxedPolyline2d {\n    fn aabb_2d(&self, isometry: impl Into<Isometry2d>) -> Aabb2d {\n        Aabb2d::from_point_cloud(isometry, &self.vertices)\n    }\n\n    fn bounding_circle(&self, isometry: impl Into<Isometry2d>) -> BoundingCircle {\n        BoundingCircle::from_point_cloud(isometry, &self.vertices)\n    }\n}\n\nimpl Bounded2d for Triangle2d {\n    fn aabb_2d(&self, isometry: impl Into<Isometry2d>) -> Aabb2d {\n        let isometry = isometry.into();\n        let [a, b, c] = self.vertices.map(|vtx| isometry.rotation * vtx);\n\n        let min = Vec2::new(a.x.min(b.x).min(c.x), a.y.min(b.y).min(c.y));\n        let max = Vec2::new(a.x.max(b.x).max(c.x), a.y.max(b.y).max(c.y));\n\n        Aabb2d {\n            min: min + isometry.translation,\n            max: max + isometry.translation,\n        }\n    }\n\n    fn bounding_circle(&self, isometry: impl Into<Isometry2d>) -> BoundingCircle {\n        let isometry = isometry.into();\n        let [a, b, c] = self.vertices;\n\n        // The points of the segment opposite to the obtuse or right angle if one exists\n        let side_opposite_to_non_acute = if (b - a).dot(c - a) <= 0.0 {\n            Some((b, c))\n        } else if (c - b).dot(a - b) <= 0.0 {\n            Some((c, a))\n        } else if (a - c).dot(b - c) <= 0.0 {\n            Some((a, b))\n        } else {\n            // The triangle is acute.\n            None\n        };\n\n        // Find the minimum bounding circle. If the triangle is obtuse, the circle passes through two vertices.\n        // Otherwise, it's the circumcircle and passes through all three.\n        if let Some((point1, point2)) = side_opposite_to_non_acute {\n            // The triangle is obtuse or right, so the minimum bounding circle's diameter is equal to the longest side.\n            // We can compute the minimum bounding circle from the line segment of the longest side.\n            let (segment, center) = Segment2d::from_points(point1, point2);\n            segment.bounding_circle(isometry * Isometry2d::from_translation(center))\n        } else {\n            // The triangle is acute, so the smallest bounding circle is the circumcircle.\n            let (Circle { radius }, circumcenter) = self.circumcircle();\n            BoundingCircle::new(isometry * circumcenter, radius)\n        }\n    }\n}\n\nimpl Bounded2d for Rectangle {\n    fn aabb_2d(&self, isometry: impl Into<Isometry2d>) -> Aabb2d {\n        let isometry = isometry.into();\n\n        // Compute the AABB of the rotated rectangle by transforming the half-extents\n        // by an absolute rotation matrix.\n        let (sin, cos) = isometry.rotation.sin_cos();\n        let abs_rot_mat =\n            Mat2::from_cols_array(&[ops::abs(cos), ops::abs(sin), ops::abs(sin), ops::abs(cos)]);\n        let half_size = abs_rot_mat * self.half_size;\n\n        Aabb2d::new(isometry.translation, half_size)\n    }\n\n    fn bounding_circle(&self, isometry: impl Into<Isometry2d>) -> BoundingCircle {\n        let isometry = isometry.into();\n        let radius = self.half_size.length();\n        BoundingCircle::new(isometry.translation, radius)\n    }\n}\n\nimpl<const N: usize> Bounded2d for Polygon<N> {\n    fn aabb_2d(&self, isometry: impl Into<Isometry2d>) -> Aabb2d {\n        Aabb2d::from_point_cloud(isometry, &self.vertices)\n    }\n\n    fn bounding_circle(&self, isometry: impl Into<Isometry2d>) -> BoundingCircle {\n        BoundingCircle::from_point_cloud(isometry, &self.vertices)\n    }\n}\n\n#[cfg(feature = \"alloc\")]\nimpl Bounded2d for BoxedPolygon {\n    fn aabb_2d(&self, isometry: impl Into<Isometry2d>) -> Aabb2d {\n        Aabb2d::from_point_cloud(isometry, &self.vertices)\n    }\n\n    fn bounding_circle(&self, isometry: impl Into<Isometry2d>) -> BoundingCircle {\n        BoundingCircle::from_point_cloud(isometry, &self.vertices)\n    }\n}\n\nimpl Bounded2d for RegularPolygon {\n    fn aabb_2d(&self, isometry: impl Into<Isometry2d>) -> Aabb2d {\n        let isometry = isometry.into();\n\n        let mut min = Vec2::ZERO;\n        let mut max = Vec2::ZERO;\n\n        for vertex in self.vertices(isometry.rotation.as_radians()) {\n            min = min.min(vertex);\n            max = max.max(vertex);\n        }\n\n        Aabb2d {\n            min: min + isometry.translation,\n            max: max + isometry.translation,\n        }\n    }\n\n    fn bounding_circle(&self, isometry: impl Into<Isometry2d>) -> BoundingCircle {\n        let isometry = isometry.into();\n        BoundingCircle::new(isometry.translation, self.circumcircle.radius)\n    }\n}\n\nimpl Bounded2d for Capsule2d {\n    fn aabb_2d(&self, isometry: impl Into<Isometry2d>) -> Aabb2d {\n        let isometry = isometry.into();\n\n        // Get the line segment between the hemicircles of the rotated capsule\n        let segment = Segment2d {\n            // Multiplying a normalized vector (Vec2::Y) with a rotation returns a normalized vector.\n            direction: isometry.rotation * Dir2::Y,\n            half_length: self.half_length,\n        };\n        let (a, b) = (segment.point1(), segment.point2());\n\n        // Expand the line segment by the capsule radius to get the capsule half-extents\n        let min = a.min(b) - Vec2::splat(self.radius);\n        let max = a.max(b) + Vec2::splat(self.radius);\n\n        Aabb2d {\n            min: min + isometry.translation,\n            max: max + isometry.translation,\n        }\n    }\n\n    fn bounding_circle(&self, isometry: impl Into<Isometry2d>) -> BoundingCircle {\n        let isometry = isometry.into();\n        BoundingCircle::new(isometry.translation, self.radius + self.half_length)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use core::f32::consts::{FRAC_PI_2, FRAC_PI_3, FRAC_PI_4, FRAC_PI_6, TAU};\n\n    use approx::assert_abs_diff_eq;\n    use glam::Vec2;\n\n    use crate::{\n        bounding::Bounded2d,\n        ops::{self, FloatPow},\n        primitives::{\n            Annulus, Arc2d, Capsule2d, Circle, CircularSector, CircularSegment, Ellipse, Line2d,\n            Plane2d, Polygon, Polyline2d, Rectangle, RegularPolygon, Rhombus, Segment2d,\n            Triangle2d,\n        },\n        Dir2, Isometry2d, Rot2,\n    };\n\n    #[test]\n    fn circle() {\n        let circle = Circle { radius: 1.0 };\n        let translation = Vec2::new(2.0, 1.0);\n        let isometry = Isometry2d::from_translation(translation);\n\n        let aabb = circle.aabb_2d(isometry);\n        assert_eq!(aabb.min, Vec2::new(1.0, 0.0));\n        assert_eq!(aabb.max, Vec2::new(3.0, 2.0));\n\n        let bounding_circle = circle.bounding_circle(isometry);\n        assert_eq!(bounding_circle.center, translation);\n        assert_eq!(bounding_circle.radius(), 1.0);\n    }\n\n    #[test]\n    // Arcs and circular segments have the same bounding shapes so they share test cases.\n    fn arc_and_segment() {\n        struct TestCase {\n            #[allow(unused)]\n            name: &'static str,\n            arc: Arc2d,\n            translation: Vec2,\n            rotation: f32,\n            aabb_min: Vec2,\n            aabb_max: Vec2,\n            bounding_circle_center: Vec2,\n            bounding_circle_radius: f32,\n        }\n\n        impl TestCase {\n            fn isometry(&self) -> Isometry2d {\n                Isometry2d::new(self.translation, self.rotation.into())\n            }\n        }\n\n        // The apothem of an arc covering 1/6th of a circle.\n        let apothem = ops::sqrt(3.0) / 2.0;\n        let tests = [\n            // Test case: a basic minor arc\n            TestCase {\n                name: \"1/6th circle untransformed\",\n                arc: Arc2d::from_radians(1.0, FRAC_PI_3),\n                translation: Vec2::ZERO,\n                rotation: 0.0,\n                aabb_min: Vec2::new(-0.5, apothem),\n                aabb_max: Vec2::new(0.5, 1.0),\n                bounding_circle_center: Vec2::new(0.0, apothem),\n                bounding_circle_radius: 0.5,\n            },\n            // Test case: a smaller arc, verifying that radius scaling works\n            TestCase {\n                name: \"1/6th circle with radius 0.5\",\n                arc: Arc2d::from_radians(0.5, FRAC_PI_3),\n                translation: Vec2::ZERO,\n                rotation: 0.0,\n                aabb_min: Vec2::new(-0.25, apothem / 2.0),\n                aabb_max: Vec2::new(0.25, 0.5),\n                bounding_circle_center: Vec2::new(0.0, apothem / 2.0),\n                bounding_circle_radius: 0.25,\n            },\n            // Test case: a larger arc, verifying that radius scaling works\n            TestCase {\n                name: \"1/6th circle with radius 2.0\",\n                arc: Arc2d::from_radians(2.0, FRAC_PI_3),\n                translation: Vec2::ZERO,\n                rotation: 0.0,\n                aabb_min: Vec2::new(-1.0, 2.0 * apothem),\n                aabb_max: Vec2::new(1.0, 2.0),\n                bounding_circle_center: Vec2::new(0.0, 2.0 * apothem),\n                bounding_circle_radius: 1.0,\n            },\n            // Test case: translation of a minor arc\n            TestCase {\n                name: \"1/6th circle translated\",\n                arc: Arc2d::from_radians(1.0, FRAC_PI_3),\n                translation: Vec2::new(2.0, 3.0),\n                rotation: 0.0,\n                aabb_min: Vec2::new(1.5, 3.0 + apothem),\n                aabb_max: Vec2::new(2.5, 4.0),\n                bounding_circle_center: Vec2::new(2.0, 3.0 + apothem),\n                bounding_circle_radius: 0.5,\n            },\n            // Test case: rotation of a minor arc\n            TestCase {\n                name: \"1/6th circle rotated\",\n                arc: Arc2d::from_radians(1.0, FRAC_PI_3),\n                translation: Vec2::ZERO,\n                // Rotate left by 1/12 of a circle, so the right endpoint is on the y-axis.\n                rotation: FRAC_PI_6,\n                aabb_min: Vec2::new(-apothem, 0.5),\n                aabb_max: Vec2::new(0.0, 1.0),\n                // The exact coordinates here are not obvious, but can be computed by constructing\n                // an altitude from the midpoint of the chord to the y-axis and using the right triangle\n                // similarity theorem.\n                bounding_circle_center: Vec2::new(-apothem / 2.0, apothem.squared()),\n                bounding_circle_radius: 0.5,\n            },\n            // Test case: handling of axis-aligned extrema\n            TestCase {\n                name: \"1/4er circle rotated to be axis-aligned\",\n                arc: Arc2d::from_radians(1.0, FRAC_PI_2),\n                translation: Vec2::ZERO,\n                // Rotate right by 1/8 of a circle, so the right endpoint is on the x-axis and the left endpoint is on the y-axis.\n                rotation: -FRAC_PI_4,\n                aabb_min: Vec2::ZERO,\n                aabb_max: Vec2::splat(1.0),\n                bounding_circle_center: Vec2::splat(0.5),\n                bounding_circle_radius: ops::sqrt(2.0) / 2.0,\n            },\n            // Test case: a basic major arc\n            TestCase {\n                name: \"5/6th circle untransformed\",\n                arc: Arc2d::from_radians(1.0, 5.0 * FRAC_PI_3),\n                translation: Vec2::ZERO,\n                rotation: 0.0,\n                aabb_min: Vec2::new(-1.0, -apothem),\n                aabb_max: Vec2::new(1.0, 1.0),\n                bounding_circle_center: Vec2::ZERO,\n                bounding_circle_radius: 1.0,\n            },\n            // Test case: a translated major arc\n            TestCase {\n                name: \"5/6th circle translated\",\n                arc: Arc2d::from_radians(1.0, 5.0 * FRAC_PI_3),\n                translation: Vec2::new(2.0, 3.0),\n                rotation: 0.0,\n                aabb_min: Vec2::new(1.0, 3.0 - apothem),\n                aabb_max: Vec2::new(3.0, 4.0),\n                bounding_circle_center: Vec2::new(2.0, 3.0),\n                bounding_circle_radius: 1.0,\n            },\n            // Test case: a rotated major arc, with inverted left/right angles\n            TestCase {\n                name: \"5/6th circle rotated\",\n                arc: Arc2d::from_radians(1.0, 5.0 * FRAC_PI_3),\n                translation: Vec2::ZERO,\n                // Rotate left by 1/12 of a circle, so the left endpoint is on the y-axis.\n                rotation: FRAC_PI_6,\n                aabb_min: Vec2::new(-1.0, -1.0),\n                aabb_max: Vec2::new(1.0, 1.0),\n                bounding_circle_center: Vec2::ZERO,\n                bounding_circle_radius: 1.0,\n            },\n        ];\n\n        for test in tests {\n            #[cfg(feature = \"std\")]\n            println!(\"subtest case: {}\", test.name);\n            let segment: CircularSegment = test.arc.into();\n\n            let arc_aabb = test.arc.aabb_2d(test.isometry());\n            assert_abs_diff_eq!(test.aabb_min, arc_aabb.min);\n            assert_abs_diff_eq!(test.aabb_max, arc_aabb.max);\n            let segment_aabb = segment.aabb_2d(test.isometry());\n            assert_abs_diff_eq!(test.aabb_min, segment_aabb.min);\n            assert_abs_diff_eq!(test.aabb_max, segment_aabb.max);\n\n            let arc_bounding_circle = test.arc.bounding_circle(test.isometry());\n            assert_abs_diff_eq!(test.bounding_circle_center, arc_bounding_circle.center);\n            assert_abs_diff_eq!(test.bounding_circle_radius, arc_bounding_circle.radius());\n            let segment_bounding_circle = segment.bounding_circle(test.isometry());\n            assert_abs_diff_eq!(test.bounding_circle_center, segment_bounding_circle.center);\n            assert_abs_diff_eq!(\n                test.bounding_circle_radius,\n                segment_bounding_circle.radius()\n            );\n        }\n    }\n\n    #[test]\n    fn circular_sector() {\n        struct TestCase {\n            #[allow(unused)]\n            name: &'static str,\n            arc: Arc2d,\n            translation: Vec2,\n            rotation: f32,\n            aabb_min: Vec2,\n            aabb_max: Vec2,\n            bounding_circle_center: Vec2,\n            bounding_circle_radius: f32,\n        }\n\n        impl TestCase {\n            fn isometry(&self) -> Isometry2d {\n                Isometry2d::new(self.translation, self.rotation.into())\n            }\n        }\n\n        // The apothem of an arc covering 1/6th of a circle.\n        let apothem = ops::sqrt(3.0) / 2.0;\n        let inv_sqrt_3 = ops::sqrt(3.0).recip();\n        let tests = [\n            // Test case: An sector whose arc is minor, but whose bounding circle is not the circumcircle of the endpoints and center\n            TestCase {\n                name: \"1/3rd circle\",\n                arc: Arc2d::from_radians(1.0, TAU / 3.0),\n                translation: Vec2::ZERO,\n                rotation: 0.0,\n                aabb_min: Vec2::new(-apothem, 0.0),\n                aabb_max: Vec2::new(apothem, 1.0),\n                bounding_circle_center: Vec2::new(0.0, 0.5),\n                bounding_circle_radius: apothem,\n            },\n            // The remaining test cases are selected as for arc_and_segment.\n            TestCase {\n                name: \"1/6th circle untransformed\",\n                arc: Arc2d::from_radians(1.0, FRAC_PI_3),\n                translation: Vec2::ZERO,\n                rotation: 0.0,\n                aabb_min: Vec2::new(-0.5, 0.0),\n                aabb_max: Vec2::new(0.5, 1.0),\n                // The bounding circle is a circumcircle of an equilateral triangle with side length 1.\n                // The distance from the corner to the center of such a triangle is 1/sqrt(3).\n                bounding_circle_center: Vec2::new(0.0, inv_sqrt_3),\n                bounding_circle_radius: inv_sqrt_3,\n            },\n            TestCase {\n                name: \"1/6th circle with radius 0.5\",\n                arc: Arc2d::from_radians(0.5, FRAC_PI_3),\n                translation: Vec2::ZERO,\n                rotation: 0.0,\n                aabb_min: Vec2::new(-0.25, 0.0),\n                aabb_max: Vec2::new(0.25, 0.5),\n                bounding_circle_center: Vec2::new(0.0, inv_sqrt_3 / 2.0),\n                bounding_circle_radius: inv_sqrt_3 / 2.0,\n            },\n            TestCase {\n                name: \"1/6th circle with radius 2.0\",\n                arc: Arc2d::from_radians(2.0, FRAC_PI_3),\n                translation: Vec2::ZERO,\n                rotation: 0.0,\n                aabb_min: Vec2::new(-1.0, 0.0),\n                aabb_max: Vec2::new(1.0, 2.0),\n                bounding_circle_center: Vec2::new(0.0, 2.0 * inv_sqrt_3),\n                bounding_circle_radius: 2.0 * inv_sqrt_3,\n            },\n            TestCase {\n                name: \"1/6th circle translated\",\n                arc: Arc2d::from_radians(1.0, FRAC_PI_3),\n                translation: Vec2::new(2.0, 3.0),\n                rotation: 0.0,\n                aabb_min: Vec2::new(1.5, 3.0),\n                aabb_max: Vec2::new(2.5, 4.0),\n                bounding_circle_center: Vec2::new(2.0, 3.0 + inv_sqrt_3),\n                bounding_circle_radius: inv_sqrt_3,\n            },\n            TestCase {\n                name: \"1/6th circle rotated\",\n                arc: Arc2d::from_radians(1.0, FRAC_PI_3),\n                translation: Vec2::ZERO,\n                // Rotate left by 1/12 of a circle, so the right endpoint is on the y-axis.\n                rotation: FRAC_PI_6,\n                aabb_min: Vec2::new(-apothem, 0.0),\n                aabb_max: Vec2::new(0.0, 1.0),\n                // The x-coordinate is now the inradius of the equilateral triangle, which is sqrt(3)/2.\n                bounding_circle_center: Vec2::new(-inv_sqrt_3 / 2.0, 0.5),\n                bounding_circle_radius: inv_sqrt_3,\n            },\n            TestCase {\n                name: \"1/4er circle rotated to be axis-aligned\",\n                arc: Arc2d::from_radians(1.0, FRAC_PI_2),\n                translation: Vec2::ZERO,\n                // Rotate right by 1/8 of a circle, so the right endpoint is on the x-axis and the left endpoint is on the y-axis.\n                rotation: -FRAC_PI_4,\n                aabb_min: Vec2::ZERO,\n                aabb_max: Vec2::splat(1.0),\n                bounding_circle_center: Vec2::splat(0.5),\n                bounding_circle_radius: ops::sqrt(2.0) / 2.0,\n            },\n            TestCase {\n                name: \"5/6th circle untransformed\",\n                arc: Arc2d::from_radians(1.0, 5.0 * FRAC_PI_3),\n                translation: Vec2::ZERO,\n                rotation: 0.0,\n                aabb_min: Vec2::new(-1.0, -apothem),\n                aabb_max: Vec2::new(1.0, 1.0),\n                bounding_circle_center: Vec2::ZERO,\n                bounding_circle_radius: 1.0,\n            },\n            TestCase {\n                name: \"5/6th circle translated\",\n                arc: Arc2d::from_radians(1.0, 5.0 * FRAC_PI_3),\n                translation: Vec2::new(2.0, 3.0),\n                rotation: 0.0,\n                aabb_min: Vec2::new(1.0, 3.0 - apothem),\n                aabb_max: Vec2::new(3.0, 4.0),\n                bounding_circle_center: Vec2::new(2.0, 3.0),\n                bounding_circle_radius: 1.0,\n            },\n            TestCase {\n                name: \"5/6th circle rotated\",\n                arc: Arc2d::from_radians(1.0, 5.0 * FRAC_PI_3),\n                translation: Vec2::ZERO,\n                // Rotate left by 1/12 of a circle, so the left endpoint is on the y-axis.\n                rotation: FRAC_PI_6,\n                aabb_min: Vec2::new(-1.0, -1.0),\n                aabb_max: Vec2::new(1.0, 1.0),\n                bounding_circle_center: Vec2::ZERO,\n                bounding_circle_radius: 1.0,\n            },\n        ];\n\n        for test in tests {\n            #[cfg(feature = \"std\")]\n            println!(\"subtest case: {}\", test.name);\n            let sector: CircularSector = test.arc.into();\n\n            let aabb = sector.aabb_2d(test.isometry());\n            assert_abs_diff_eq!(test.aabb_min, aabb.min);\n            assert_abs_diff_eq!(test.aabb_max, aabb.max);\n\n            let bounding_circle = sector.bounding_circle(test.isometry());\n            assert_abs_diff_eq!(test.bounding_circle_center, bounding_circle.center);\n            assert_abs_diff_eq!(test.bounding_circle_radius, bounding_circle.radius());\n        }\n    }\n\n    #[test]\n    fn ellipse() {\n        let ellipse = Ellipse::new(1.0, 0.5);\n        let translation = Vec2::new(2.0, 1.0);\n        let isometry = Isometry2d::from_translation(translation);\n\n        let aabb = ellipse.aabb_2d(isometry);\n        assert_eq!(aabb.min, Vec2::new(1.0, 0.5));\n        assert_eq!(aabb.max, Vec2::new(3.0, 1.5));\n\n        let bounding_circle = ellipse.bounding_circle(isometry);\n        assert_eq!(bounding_circle.center, translation);\n        assert_eq!(bounding_circle.radius(), 1.0);\n    }\n\n    #[test]\n    fn annulus() {\n        let annulus = Annulus::new(1.0, 2.0);\n        let translation = Vec2::new(2.0, 1.0);\n        let rotation = Rot2::radians(1.0);\n        let isometry = Isometry2d::new(translation, rotation);\n\n        let aabb = annulus.aabb_2d(isometry);\n        assert_eq!(aabb.min, Vec2::new(0.0, -1.0));\n        assert_eq!(aabb.max, Vec2::new(4.0, 3.0));\n\n        let bounding_circle = annulus.bounding_circle(isometry);\n        assert_eq!(bounding_circle.center, translation);\n        assert_eq!(bounding_circle.radius(), 2.0);\n    }\n\n    #[test]\n    fn rhombus() {\n        let rhombus = Rhombus::new(2.0, 1.0);\n        let translation = Vec2::new(2.0, 1.0);\n        let rotation = Rot2::radians(FRAC_PI_4);\n        let isometry = Isometry2d::new(translation, rotation);\n\n        let aabb = rhombus.aabb_2d(isometry);\n        assert_eq!(aabb.min, Vec2::new(1.2928932, 0.29289323));\n        assert_eq!(aabb.max, Vec2::new(2.7071068, 1.7071068));\n\n        let bounding_circle = rhombus.bounding_circle(isometry);\n        assert_eq!(bounding_circle.center, translation);\n        assert_eq!(bounding_circle.radius(), 1.0);\n\n        let rhombus = Rhombus::new(0.0, 0.0);\n        let translation = Vec2::new(0.0, 0.0);\n        let isometry = Isometry2d::new(translation, rotation);\n\n        let aabb = rhombus.aabb_2d(isometry);\n        assert_eq!(aabb.min, Vec2::new(0.0, 0.0));\n        assert_eq!(aabb.max, Vec2::new(0.0, 0.0));\n\n        let bounding_circle = rhombus.bounding_circle(isometry);\n        assert_eq!(bounding_circle.center, translation);\n        assert_eq!(bounding_circle.radius(), 0.0);\n    }\n\n    #[test]\n    fn plane() {\n        let translation = Vec2::new(2.0, 1.0);\n        let isometry = Isometry2d::from_translation(translation);\n\n        let aabb1 = Plane2d::new(Vec2::X).aabb_2d(isometry);\n        assert_eq!(aabb1.min, Vec2::new(2.0, -f32::MAX / 2.0));\n        assert_eq!(aabb1.max, Vec2::new(2.0, f32::MAX / 2.0));\n\n        let aabb2 = Plane2d::new(Vec2::Y).aabb_2d(isometry);\n        assert_eq!(aabb2.min, Vec2::new(-f32::MAX / 2.0, 1.0));\n        assert_eq!(aabb2.max, Vec2::new(f32::MAX / 2.0, 1.0));\n\n        let aabb3 = Plane2d::new(Vec2::ONE).aabb_2d(isometry);\n        assert_eq!(aabb3.min, Vec2::new(-f32::MAX / 2.0, -f32::MAX / 2.0));\n        assert_eq!(aabb3.max, Vec2::new(f32::MAX / 2.0, f32::MAX / 2.0));\n\n        let bounding_circle = Plane2d::new(Vec2::Y).bounding_circle(isometry);\n        assert_eq!(bounding_circle.center, translation);\n        assert_eq!(bounding_circle.radius(), f32::MAX / 2.0);\n    }\n\n    #[test]\n    fn line() {\n        let translation = Vec2::new(2.0, 1.0);\n        let isometry = Isometry2d::from_translation(translation);\n\n        let aabb1 = Line2d { direction: Dir2::Y }.aabb_2d(isometry);\n        assert_eq!(aabb1.min, Vec2::new(2.0, -f32::MAX / 2.0));\n        assert_eq!(aabb1.max, Vec2::new(2.0, f32::MAX / 2.0));\n\n        let aabb2 = Line2d { direction: Dir2::X }.aabb_2d(isometry);\n        assert_eq!(aabb2.min, Vec2::new(-f32::MAX / 2.0, 1.0));\n        assert_eq!(aabb2.max, Vec2::new(f32::MAX / 2.0, 1.0));\n\n        let aabb3 = Line2d {\n            direction: Dir2::from_xy(1.0, 1.0).unwrap(),\n        }\n        .aabb_2d(isometry);\n        assert_eq!(aabb3.min, Vec2::new(-f32::MAX / 2.0, -f32::MAX / 2.0));\n        assert_eq!(aabb3.max, Vec2::new(f32::MAX / 2.0, f32::MAX / 2.0));\n\n        let bounding_circle = Line2d { direction: Dir2::Y }.bounding_circle(isometry);\n        assert_eq!(bounding_circle.center, translation);\n        assert_eq!(bounding_circle.radius(), f32::MAX / 2.0);\n    }\n\n    #[test]\n    fn segment() {\n        let translation = Vec2::new(2.0, 1.0);\n        let isometry = Isometry2d::from_translation(translation);\n        let segment = Segment2d::from_points(Vec2::new(-1.0, -0.5), Vec2::new(1.0, 0.5)).0;\n\n        let aabb = segment.aabb_2d(isometry);\n        assert_eq!(aabb.min, Vec2::new(1.0, 0.5));\n        assert_eq!(aabb.max, Vec2::new(3.0, 1.5));\n\n        let bounding_circle = segment.bounding_circle(isometry);\n        assert_eq!(bounding_circle.center, translation);\n        assert_eq!(bounding_circle.radius(), ops::hypot(1.0, 0.5));\n    }\n\n    #[test]\n    fn polyline() {\n        let polyline = Polyline2d::<4>::new([\n            Vec2::ONE,\n            Vec2::new(-1.0, 1.0),\n            Vec2::NEG_ONE,\n            Vec2::new(1.0, -1.0),\n        ]);\n        let translation = Vec2::new(2.0, 1.0);\n        let isometry = Isometry2d::from_translation(translation);\n\n        let aabb = polyline.aabb_2d(isometry);\n        assert_eq!(aabb.min, Vec2::new(1.0, 0.0));\n        assert_eq!(aabb.max, Vec2::new(3.0, 2.0));\n\n        let bounding_circle = polyline.bounding_circle(isometry);\n        assert_eq!(bounding_circle.center, translation);\n        assert_eq!(bounding_circle.radius(), core::f32::consts::SQRT_2);\n    }\n\n    #[test]\n    fn acute_triangle() {\n        let acute_triangle =\n            Triangle2d::new(Vec2::new(0.0, 1.0), Vec2::NEG_ONE, Vec2::new(1.0, -1.0));\n        let translation = Vec2::new(2.0, 1.0);\n        let isometry = Isometry2d::from_translation(translation);\n\n        let aabb = acute_triangle.aabb_2d(isometry);\n        assert_eq!(aabb.min, Vec2::new(1.0, 0.0));\n        assert_eq!(aabb.max, Vec2::new(3.0, 2.0));\n\n        // For acute triangles, the center is the circumcenter\n        let (Circle { radius }, circumcenter) = acute_triangle.circumcircle();\n        let bounding_circle = acute_triangle.bounding_circle(isometry);\n        assert_eq!(bounding_circle.center, circumcenter + translation);\n        assert_eq!(bounding_circle.radius(), radius);\n    }\n\n    #[test]\n    fn obtuse_triangle() {\n        let obtuse_triangle = Triangle2d::new(\n            Vec2::new(0.0, 1.0),\n            Vec2::new(-10.0, -1.0),\n            Vec2::new(10.0, -1.0),\n        );\n        let translation = Vec2::new(2.0, 1.0);\n        let isometry = Isometry2d::from_translation(translation);\n\n        let aabb = obtuse_triangle.aabb_2d(isometry);\n        assert_eq!(aabb.min, Vec2::new(-8.0, 0.0));\n        assert_eq!(aabb.max, Vec2::new(12.0, 2.0));\n\n        // For obtuse and right triangles, the center is the midpoint of the longest side (diameter of bounding circle)\n        let bounding_circle = obtuse_triangle.bounding_circle(isometry);\n        assert_eq!(bounding_circle.center, translation - Vec2::Y);\n        assert_eq!(bounding_circle.radius(), 10.0);\n    }\n\n    #[test]\n    fn rectangle() {\n        let rectangle = Rectangle::new(2.0, 1.0);\n        let translation = Vec2::new(2.0, 1.0);\n\n        let aabb = rectangle.aabb_2d(Isometry2d::new(translation, Rot2::radians(FRAC_PI_4)));\n        let expected_half_size = Vec2::splat(1.0606601);\n        assert_eq!(aabb.min, translation - expected_half_size);\n        assert_eq!(aabb.max, translation + expected_half_size);\n\n        let bounding_circle = rectangle.bounding_circle(Isometry2d::from_translation(translation));\n        assert_eq!(bounding_circle.center, translation);\n        assert_eq!(bounding_circle.radius(), ops::hypot(1.0, 0.5));\n    }\n\n    #[test]\n    fn polygon() {\n        let polygon = Polygon::<4>::new([\n            Vec2::ONE,\n            Vec2::new(-1.0, 1.0),\n            Vec2::NEG_ONE,\n            Vec2::new(1.0, -1.0),\n        ]);\n        let translation = Vec2::new(2.0, 1.0);\n        let isometry = Isometry2d::from_translation(translation);\n\n        let aabb = polygon.aabb_2d(isometry);\n        assert_eq!(aabb.min, Vec2::new(1.0, 0.0));\n        assert_eq!(aabb.max, Vec2::new(3.0, 2.0));\n\n        let bounding_circle = polygon.bounding_circle(isometry);\n        assert_eq!(bounding_circle.center, translation);\n        assert_eq!(bounding_circle.radius(), core::f32::consts::SQRT_2);\n    }\n\n    #[test]\n    fn regular_polygon() {\n        let regular_polygon = RegularPolygon::new(1.0, 5);\n        let translation = Vec2::new(2.0, 1.0);\n        let isometry = Isometry2d::from_translation(translation);\n\n        let aabb = regular_polygon.aabb_2d(isometry);\n        assert!((aabb.min - (translation - Vec2::new(0.9510565, 0.8090169))).length() < 1e-6);\n        assert!((aabb.max - (translation + Vec2::new(0.9510565, 1.0))).length() < 1e-6);\n\n        let bounding_circle = regular_polygon.bounding_circle(isometry);\n        assert_eq!(bounding_circle.center, translation);\n        assert_eq!(bounding_circle.radius(), 1.0);\n    }\n\n    #[test]\n    fn capsule() {\n        let capsule = Capsule2d::new(0.5, 2.0);\n        let translation = Vec2::new(2.0, 1.0);\n        let isometry = Isometry2d::from_translation(translation);\n\n        let aabb = capsule.aabb_2d(isometry);\n        assert_eq!(aabb.min, translation - Vec2::new(0.5, 1.5));\n        assert_eq!(aabb.max, translation + Vec2::new(0.5, 1.5));\n\n        let bounding_circle = capsule.bounding_circle(isometry);\n        assert_eq!(bounding_circle.center, translation);\n        assert_eq!(bounding_circle.radius(), 1.5);\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "c6c340f3879bef63cc4c3f3e59fc48ccdfaebfc8",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_math/src/bounding/bounded3d/extrusion.rs",
    "func": "use core::f32::consts::FRAC_PI_2;\n\nuse glam::{Vec2, Vec3A, Vec3Swizzles};\n\nuse crate::{\n    bounding::{BoundingCircle, BoundingVolume},\n    ops,\n    primitives::{\n        Capsule2d, Cuboid, Cylinder, Ellipse, Extrusion, Line2d, Polygon, Polyline2d, Primitive2d,\n        Rectangle, RegularPolygon, Segment2d, Triangle2d,\n    },\n    Isometry2d, Isometry3d, Quat, Rot2,\n};\n\n#[cfg(feature = \"alloc\")]\nuse crate::primitives::{BoxedPolygon, BoxedPolyline2d};\n\nuse crate::{bounding::Bounded2d, primitives::Circle};\n\nuse super::{Aabb3d, Bounded3d, BoundingSphere};\n\nimpl BoundedExtrusion for Circle {\n    fn extrusion_aabb_3d(&self, half_depth: f32, isometry: impl Into<Isometry3d>) -> Aabb3d {\n        // Reference: http://iquilezles.org/articles/diskbbox/\n\n        let isometry = isometry.into();\n\n        let segment_dir = isometry.rotation * Vec3A::Z;\n        let top = (segment_dir * half_depth).abs();\n\n        let e = (Vec3A::ONE - segment_dir * segment_dir).max(Vec3A::ZERO);\n        let half_size = self.radius * Vec3A::new(ops::sqrt(e.x), ops::sqrt(e.y), ops::sqrt(e.z));\n\n        Aabb3d {\n            min: isometry.translation - half_size - top,\n            max: isometry.translation + half_size + top,\n        }\n    }\n}\n\nimpl BoundedExtrusion for Ellipse {\n    fn extrusion_aabb_3d(&self, half_depth: f32, isometry: impl Into<Isometry3d>) -> Aabb3d {\n        let isometry = isometry.into();\n        let Vec2 { x: a, y: b } = self.half_size;\n        let normal = isometry.rotation * Vec3A::Z;\n        let conjugate_rot = isometry.rotation.conjugate();\n\n        let [max_x, max_y, max_z] = Vec3A::AXES.map(|axis| {\n            let Some(axis) = (conjugate_rot * axis.reject_from(normal))\n                .xy()\n                .try_normalize()\n            else {\n                return Vec3A::ZERO;\n            };\n\n            if axis.element_product() == 0. {\n                return isometry.rotation * Vec3A::new(a * axis.y, b * axis.x, 0.);\n            }\n            let m = -axis.x / axis.y;\n            let signum = axis.signum();\n\n            let y = signum.y * b * b / ops::sqrt(b * b + m * m * a * a);\n            let x = signum.x * a * ops::sqrt(1. - y * y / b / b);\n            isometry.rotation * Vec3A::new(x, y, 0.)\n        });\n\n        let half_size = Vec3A::new(max_x.x, max_y.y, max_z.z).abs() + (normal * half_depth).abs();\n        Aabb3d::new(isometry.translation, half_size)\n    }\n}\n\nimpl BoundedExtrusion for Line2d {\n    fn extrusion_aabb_3d(&self, half_depth: f32, isometry: impl Into<Isometry3d>) -> Aabb3d {\n        let isometry = isometry.into();\n        let dir = isometry.rotation * Vec3A::from(self.direction.extend(0.));\n        let half_depth = (isometry.rotation * Vec3A::new(0., 0., half_depth)).abs();\n\n        let max = f32::MAX / 2.;\n        let half_size = Vec3A::new(\n            if dir.x == 0. { half_depth.x } else { max },\n            if dir.y == 0. { half_depth.y } else { max },\n            if dir.z == 0. { half_depth.z } else { max },\n        );\n\n        Aabb3d::new(isometry.translation, half_size)\n    }\n}\n\nimpl BoundedExtrusion for Segment2d {\n    fn extrusion_aabb_3d(&self, half_depth: f32, isometry: impl Into<Isometry3d>) -> Aabb3d {\n        let isometry = isometry.into();\n        let half_size = isometry.rotation * Vec3A::from(self.point1().extend(0.));\n        let depth = isometry.rotation * Vec3A::new(0., 0., half_depth);\n\n        Aabb3d::new(isometry.translation, half_size.abs() + depth.abs())\n    }\n}\n\nimpl<const N: usize> BoundedExtrusion for Polyline2d<N> {\n    fn extrusion_aabb_3d(&self, half_depth: f32, isometry: impl Into<Isometry3d>) -> Aabb3d {\n        let isometry = isometry.into();\n        let aabb =\n            Aabb3d::from_point_cloud(isometry, self.vertices.map(|v| v.extend(0.)).into_iter());\n        let depth = isometry.rotation * Vec3A::new(0., 0., half_depth);\n\n        aabb.grow(depth.abs())\n    }\n}\n\n#[cfg(feature = \"alloc\")]\nimpl BoundedExtrusion for BoxedPolyline2d {\n    fn extrusion_aabb_3d(&self, half_depth: f32, isometry: impl Into<Isometry3d>) -> Aabb3d {\n        let isometry = isometry.into();\n        let aabb = Aabb3d::from_point_cloud(isometry, self.vertices.iter().map(|v| v.extend(0.)));\n        let depth = isometry.rotation * Vec3A::new(0., 0., half_depth);\n\n        aabb.grow(depth.abs())\n    }\n}\n\nimpl BoundedExtrusion for Triangle2d {\n    fn extrusion_aabb_3d(&self, half_depth: f32, isometry: impl Into<Isometry3d>) -> Aabb3d {\n        let isometry = isometry.into();\n        let aabb = Aabb3d::from_point_cloud(isometry, self.vertices.iter().map(|v| v.extend(0.)));\n        let depth = isometry.rotation * Vec3A::new(0., 0., half_depth);\n\n        aabb.grow(depth.abs())\n    }\n}\n\nimpl BoundedExtrusion for Rectangle {\n    fn extrusion_aabb_3d(&self, half_depth: f32, isometry: impl Into<Isometry3d>) -> Aabb3d {\n        Cuboid {\n            half_size: self.half_size.extend(half_depth),\n        }\n        .aabb_3d(isometry)\n    }\n}\n\nimpl<const N: usize> BoundedExtrusion for Polygon<N> {\n    fn extrusion_aabb_3d(&self, half_depth: f32, isometry: impl Into<Isometry3d>) -> Aabb3d {\n        let isometry = isometry.into();\n        let aabb =\n            Aabb3d::from_point_cloud(isometry, self.vertices.map(|v| v.extend(0.)).into_iter());\n        let depth = isometry.rotation * Vec3A::new(0., 0., half_depth);\n\n        aabb.grow(depth.abs())\n    }\n}\n\n#[cfg(feature = \"alloc\")]\nimpl BoundedExtrusion for BoxedPolygon {\n    fn extrusion_aabb_3d(&self, half_depth: f32, isometry: impl Into<Isometry3d>) -> Aabb3d {\n        let isometry = isometry.into();\n        let aabb = Aabb3d::from_point_cloud(isometry, self.vertices.iter().map(|v| v.extend(0.)));\n        let depth = isometry.rotation * Vec3A::new(0., 0., half_depth);\n\n        aabb.grow(depth.abs())\n    }\n}\n\nimpl BoundedExtrusion for RegularPolygon {\n    fn extrusion_aabb_3d(&self, half_depth: f32, isometry: impl Into<Isometry3d>) -> Aabb3d {\n        let isometry = isometry.into();\n        let aabb = Aabb3d::from_point_cloud(\n            isometry,\n            self.vertices(0.).into_iter().map(|v| v.extend(0.)),\n        );\n        let depth = isometry.rotation * Vec3A::new(0., 0., half_depth);\n\n        aabb.grow(depth.abs())\n    }\n}\n\nimpl BoundedExtrusion for Capsule2d {\n    fn extrusion_aabb_3d(&self, half_depth: f32, isometry: impl Into<Isometry3d>) -> Aabb3d {\n        let isometry = isometry.into();\n        let aabb = Cylinder {\n            half_height: half_depth,\n            radius: self.radius,\n        }\n        .aabb_3d(isometry.rotation * Quat::from_rotation_x(FRAC_PI_2));\n\n        let up = isometry.rotation * Vec3A::new(0., self.half_length, 0.);\n        let half_size = aabb.max + up.abs();\n        Aabb3d::new(isometry.translation, half_size)\n    }\n}\n\nimpl<T: BoundedExtrusion> Bounded3d for Extrusion<T> {\n    fn aabb_3d(&self, isometry: impl Into<Isometry3d>) -> Aabb3d {\n        self.base_shape.extrusion_aabb_3d(self.half_depth, isometry)\n    }\n\n    fn bounding_sphere(&self, isometry: impl Into<Isometry3d>) -> BoundingSphere {\n        self.base_shape\n            .extrusion_bounding_sphere(self.half_depth, isometry)\n    }\n}\n\n/// A trait implemented on 2D shapes which determines the 3D bounding volumes of their extrusions.\n///\n/// Since default implementations can be inferred from 2D bounding volumes, this allows a `Bounded2d`\n/// implementation on some shape `MyShape` to be extrapolated to a `Bounded3d` implementation on\n/// `Extrusion<MyShape>` without supplying any additional data; e.g.:\n/// `impl BoundedExtrusion for MyShape {}`\npub trait BoundedExtrusion: Primitive2d + Bounded2d {\n    /// Get an axis-aligned bounding box for an extrusion with this shape as a base and the given `half_depth`, transformed by the given `translation` and `rotation`.\n    fn extrusion_aabb_3d(&self, half_depth: f32, isometry: impl Into<Isometry3d>) -> Aabb3d {\n        let isometry = isometry.into();\n        let cap_normal = isometry.rotation * Vec3A::Z;\n        let conjugate_rot = isometry.rotation.conjugate();\n\n        // The `(halfsize, offset)` for each axis\n        let axis_values = Vec3A::AXES.map(|ax| {\n            // This is the direction of the line of intersection of a plane with the `ax` normal and the plane containing the cap of the extrusion.\n            let intersect_line = ax.cross(cap_normal);\n            if intersect_line.length_squared() <= f32::EPSILON {\n                return (0., 0.);\n            };\n\n            // This is the normal vector of the intersection line rotated to be in the XY-plane\n            let line_normal = (conjugate_rot * intersect_line).yx();\n            let angle = line_normal.to_angle();\n\n            // Since the plane containing the caps of the extrusion is not guaranteed to be orthogonal to the `ax` plane, only a certain \"scale\" factor\n            // of the `Aabb2d` will actually go towards the dimensions of the `Aabb3d`\n            let scale = cap_normal.reject_from(ax).length();\n\n            // Calculate the `Aabb2d` of the base shape. The shape is rotated so that the line of intersection is parallel to the Y axis in the `Aabb2d` calculations.\n            // This guarantees that the X value of the `Aabb2d` is closest to the `ax` plane\n            let aabb2d = self.aabb_2d(Rot2::radians(angle));\n            (aabb2d.half_size().x * scale, aabb2d.center().x * scale)\n        });\n\n        let offset = Vec3A::from_array(axis_values.map(|(_, offset)| offset));\n        let cap_size = Vec3A::from_array(axis_values.map(|(max_val, _)| max_val)).abs();\n        let depth = isometry.rotation * Vec3A::new(0., 0., half_depth);\n\n        Aabb3d::new(isometry.translation - offset, cap_size + depth.abs())\n    }\n\n    /// Get a bounding sphere for an extrusion of the `base_shape` with the given `half_depth` with the given translation and rotation\n    fn extrusion_bounding_sphere(\n        &self,\n        half_depth: f32,\n        isometry: impl Into<Isometry3d>,\n    ) -> BoundingSphere {\n        let isometry = isometry.into();\n\n        // We calculate the bounding circle of the base shape.\n        // Since each of the extrusions bases will have the same distance from its center,\n        // and they are just shifted along the Z-axis, the minimum bounding sphere will be the bounding sphere\n        // of the cylinder defined by the two bounding circles of the bases for any base shape\n        let BoundingCircle {\n            center,\n            circle: Circle { radius },\n        } = self.bounding_circle(Isometry2d::IDENTITY);\n        let radius = ops::hypot(radius, half_depth);\n        let center = isometry * Vec3A::from(center.extend(0.));\n\n        BoundingSphere::new(center, radius)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use core::f32::consts::FRAC_PI_4;\n\n    use glam::{EulerRot, Quat, Vec2, Vec3, Vec3A};\n\n    use crate::{\n        bounding::{Bounded3d, BoundingVolume},\n        ops,\n        primitives::{\n            Capsule2d, Circle, Ellipse, Extrusion, Line2d, Polygon, Polyline2d, Rectangle,\n            RegularPolygon, Segment2d, Triangle2d,\n        },\n        Dir2, Isometry3d,\n    };\n\n    #[test]\n    fn circle() {\n        let cylinder = Extrusion::new(Circle::new(0.5), 2.0);\n        let translation = Vec3::new(2.0, 1.0, 0.0);\n\n        let aabb = cylinder.aabb_3d(translation);\n        assert_eq!(aabb.center(), Vec3A::from(translation));\n        assert_eq!(aabb.half_size(), Vec3A::new(0.5, 0.5, 1.0));\n\n        let bounding_sphere = cylinder.bounding_sphere(translation);\n        assert_eq!(bounding_sphere.center, translation.into());\n        assert_eq!(bounding_sphere.radius(), ops::hypot(1.0, 0.5));\n    }\n\n    #[test]\n    fn ellipse() {\n        let extrusion = Extrusion::new(Ellipse::new(2.0, 0.5), 4.0);\n        let translation = Vec3::new(3., 4., 5.);\n        let rotation = Quat::from_euler(EulerRot::ZYX, FRAC_PI_4, FRAC_PI_4, FRAC_PI_4);\n        let isometry = Isometry3d::new(translation, rotation);\n\n        let aabb = extrusion.aabb_3d(isometry);\n        assert_eq!(aabb.center(), Vec3A::from(translation));\n        assert_eq!(aabb.half_size(), Vec3A::new(2.709784, 1.3801551, 2.436141));\n\n        let bounding_sphere = extrusion.bounding_sphere(isometry);\n        assert_eq!(bounding_sphere.center, translation.into());\n        assert_eq!(bounding_sphere.radius(), ops::sqrt(8f32));\n    }\n\n    #[test]\n    fn line() {\n        let extrusion = Extrusion::new(\n            Line2d {\n                direction: Dir2::new_unchecked(Vec2::Y),\n            },\n            4.,\n        );\n        let translation = Vec3::new(3., 4., 5.);\n        let rotation = Quat::from_rotation_y(FRAC_PI_4);\n        let isometry = Isometry3d::new(translation, rotation);\n\n        let aabb = extrusion.aabb_3d(isometry);\n        assert_eq!(aabb.min, Vec3A::new(1.5857864, f32::MIN / 2., 3.5857865));\n        assert_eq!(aabb.max, Vec3A::new(4.4142136, f32::MAX / 2., 6.414213));\n\n        let bounding_sphere = extrusion.bounding_sphere(isometry);\n        assert_eq!(bounding_sphere.center(), translation.into());\n        assert_eq!(bounding_sphere.radius(), f32::MAX / 2.);\n    }\n\n    #[test]\n    fn rectangle() {\n        let extrusion = Extrusion::new(Rectangle::new(2.0, 1.0), 4.0);\n        let translation = Vec3::new(3., 4., 5.);\n        let rotation = Quat::from_rotation_z(FRAC_PI_4);\n        let isometry = Isometry3d::new(translation, rotation);\n\n        let aabb = extrusion.aabb_3d(isometry);\n        assert_eq!(aabb.center(), translation.into());\n        assert_eq!(aabb.half_size(), Vec3A::new(1.0606602, 1.0606602, 2.));\n\n        let bounding_sphere = extrusion.bounding_sphere(isometry);\n        assert_eq!(bounding_sphere.center, translation.into());\n        assert_eq!(bounding_sphere.radius(), 2.291288);\n    }\n\n    #[test]\n    fn segment() {\n        let extrusion = Extrusion::new(Segment2d::new(Dir2::new_unchecked(Vec2::NEG_Y), 3.), 4.0);\n        let translation = Vec3::new(3., 4., 5.);\n        let rotation = Quat::from_rotation_x(FRAC_PI_4);\n        let isometry = Isometry3d::new(translation, rotation);\n\n        let aabb = extrusion.aabb_3d(isometry);\n        assert_eq!(aabb.center(), translation.into());\n        assert_eq!(aabb.half_size(), Vec3A::new(0., 2.4748735, 2.4748735));\n\n        let bounding_sphere = extrusion.bounding_sphere(isometry);\n        assert_eq!(bounding_sphere.center, translation.into());\n        assert_eq!(bounding_sphere.radius(), 2.5);\n    }\n\n    #[test]\n    fn polyline() {\n        let polyline = Polyline2d::<4>::new([\n            Vec2::ONE,\n            Vec2::new(-1.0, 1.0),\n            Vec2::NEG_ONE,\n            Vec2::new(1.0, -1.0),\n        ]);\n        let extrusion = Extrusion::new(polyline, 3.0);\n        let translation = Vec3::new(3., 4., 5.);\n        let rotation = Quat::from_rotation_x(FRAC_PI_4);\n        let isometry = Isometry3d::new(translation, rotation);\n\n        let aabb = extrusion.aabb_3d(isometry);\n        assert_eq!(aabb.center(), translation.into());\n        assert_eq!(aabb.half_size(), Vec3A::new(1., 1.7677668, 1.7677668));\n\n        let bounding_sphere = extrusion.bounding_sphere(isometry);\n        assert_eq!(bounding_sphere.center, translation.into());\n        assert_eq!(bounding_sphere.radius(), 2.0615528);\n    }\n\n    #[test]\n    fn triangle() {\n        let triangle = Triangle2d::new(\n            Vec2::new(0.0, 1.0),\n            Vec2::new(-10.0, -1.0),\n            Vec2::new(10.0, -1.0),\n        );\n        let extrusion = Extrusion::new(triangle, 3.0);\n        let translation = Vec3::new(3., 4., 5.);\n        let rotation = Quat::from_rotation_x(FRAC_PI_4);\n        let isometry = Isometry3d::new(translation, rotation);\n\n        let aabb = extrusion.aabb_3d(isometry);\n        assert_eq!(aabb.center(), translation.into());\n        assert_eq!(aabb.half_size(), Vec3A::new(10., 1.7677668, 1.7677668));\n\n        let bounding_sphere = extrusion.bounding_sphere(isometry);\n        assert_eq!(\n            bounding_sphere.center,\n            Vec3A::new(3.0, 3.2928934, 4.2928934)\n        );\n        assert_eq!(bounding_sphere.radius(), 10.111875);\n    }\n\n    #[test]\n    fn polygon() {\n        let polygon = Polygon::<4>::new([\n            Vec2::ONE,\n            Vec2::new(-1.0, 1.0),\n            Vec2::NEG_ONE,\n            Vec2::new(1.0, -1.0),\n        ]);\n        let extrusion = Extrusion::new(polygon, 3.0);\n        let translation = Vec3::new(3., 4., 5.);\n        let rotation = Quat::from_rotation_x(FRAC_PI_4);\n        let isometry = Isometry3d::new(translation, rotation);\n\n        let aabb = extrusion.aabb_3d(isometry);\n        assert_eq!(aabb.center(), translation.into());\n        assert_eq!(aabb.half_size(), Vec3A::new(1., 1.7677668, 1.7677668));\n\n        let bounding_sphere = extrusion.bounding_sphere(isometry);\n        assert_eq!(bounding_sphere.center, translation.into());\n        assert_eq!(bounding_sphere.radius(), 2.0615528);\n    }\n\n    #[test]\n    fn regular_polygon() {\n        let extrusion = Extrusion::new(RegularPolygon::new(2.0, 7), 4.0);\n        let translation = Vec3::new(3., 4., 5.);\n        let rotation = Quat::from_rotation_x(FRAC_PI_4);\n        let isometry = Isometry3d::new(translation, rotation);\n\n        let aabb = extrusion.aabb_3d(isometry);\n        assert_eq!(\n            aabb.center(),\n            Vec3A::from(translation) + Vec3A::new(0., 0.0700254, 0.0700254)\n        );\n        assert_eq!(\n            aabb.half_size(),\n            Vec3A::new(1.9498558, 2.7584014, 2.7584019)\n        );\n\n        let bounding_sphere = extrusion.bounding_sphere(isometry);\n        assert_eq!(bounding_sphere.center, translation.into());\n        assert_eq!(bounding_sphere.radius(), ops::sqrt(8f32));\n    }\n\n    #[test]\n    fn capsule() {\n        let extrusion = Extrusion::new(Capsule2d::new(0.5, 2.0), 4.0);\n        let translation = Vec3::new(3., 4., 5.);\n        let rotation = Quat::from_rotation_x(FRAC_PI_4);\n        let isometry = Isometry3d::new(translation, rotation);\n\n        let aabb = extrusion.aabb_3d(isometry);\n        assert_eq!(aabb.center(), translation.into());\n        assert_eq!(aabb.half_size(), Vec3A::new(0.5, 2.4748735, 2.4748735));\n\n        let bounding_sphere = extrusion.bounding_sphere(isometry);\n        assert_eq!(bounding_sphere.center, translation.into());\n        assert_eq!(bounding_sphere.radius(), 2.5);\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "7ebc47f12a90bf0c6d5c0771b33f3fe981032c00",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_derive/compile_fail/tests/deref_derive/invalid_item_fail.rs",
    "func": "use bevy_derive::Deref;\n\n#[derive(Deref)]\n//~^ ERROR: cannot be derived on field-less structs\nstruct UnitStruct;\n\n#[derive(Deref)]\n//~^ ERROR: can only be derived on structs\nenum Enum {}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "241a6be1f9fcc28ea09f695936c0e81fac84b86f",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_text/src/text2d.rs",
    "func": "use crate::pipeline::CosmicFontSystem;\nuse crate::{\n    ComputedTextBlock, Font, FontAtlasSets, LineBreak, PositionedGlyph, SwashCache, TextBounds,\n    TextColor, TextError, TextFont, TextLayout, TextLayoutInfo, TextPipeline, TextReader, TextRoot,\n    TextSpanAccess, TextWriter, YAxisOrientation,\n};\nuse bevy_asset::Assets;\nuse bevy_color::LinearRgba;\nuse bevy_derive::{Deref, DerefMut};\nuse bevy_ecs::{\n    change_detection::{DetectChanges, Ref},\n    component::{require, Component},\n    entity::Entity,\n    prelude::{ReflectComponent, With},\n    query::{Changed, Without},\n    system::{Commands, Local, Query, Res, ResMut},\n};\nuse bevy_image::Image;\nuse bevy_math::Vec2;\nuse bevy_reflect::{prelude::ReflectDefault, Reflect};\nuse bevy_render::sync_world::TemporaryRenderEntity;\nuse bevy_render::view::Visibility;\nuse bevy_render::{\n    primitives::Aabb,\n    view::{NoFrustumCulling, ViewVisibility},\n    Extract,\n};\nuse bevy_sprite::{Anchor, ExtractedSprite, ExtractedSprites, SpriteSource, TextureAtlasLayout};\nuse bevy_transform::components::Transform;\nuse bevy_transform::prelude::GlobalTransform;\nuse bevy_utils::HashSet;\nuse bevy_window::{PrimaryWindow, Window};\n\n/// [`Text2dBundle`] was removed in favor of required components.\n/// The core component is now [`Text2d`] which can contain a single text segment.\n/// Indexed access to segments can be done with the new [`Text2dReader`] and [`Text2dWriter`] system params.\n/// Additional segments can be added through children with [`TextSpan`](crate::text::TextSpan).\n/// Text configuration can be done with [`TextLayout`], [`TextFont`] and [`TextColor`],\n/// while sprite-related configuration uses [`TextBounds`] and [`Anchor`] components.\n#[deprecated(\n    since = \"0.15.0\",\n    note = \"Text2dBundle has been migrated to required components. Follow the documentation for more information.\"\n)]\npub struct Text2dBundle {}\n\n/// The top-level 2D text component.\n///\n/// Adding `Text2d` to an entity will pull in required components for setting up 2d text.\n/// [Example usage.](https://github.com/bevyengine/bevy/blob/latest/examples/2d/text2d.rs)\n///\n/// The string in this component is the first 'text span' in a hierarchy of text spans that are collected into\n/// a [`ComputedTextBlock`]. See [`TextSpan`](crate::TextSpan) for the component used by children of entities with [`Text2d`].\n///\n/// With `Text2d` the `justify` field of [`TextLayout`] only affects the internal alignment of a block of text and not its\n/// relative position, which is controlled by the [`Anchor`] component.\n/// This means that for a block of text consisting of only one line that doesn't wrap, the `justify` field will have no effect.\n///\n///\n/// ```\n/// # use bevy_asset::Handle;\n/// # use bevy_color::Color;\n/// # use bevy_color::palettes::basic::BLUE;\n/// # use bevy_ecs::world::World;\n/// # use bevy_text::{Font, JustifyText, Text2d, TextLayout, TextFont, TextColor};\n/// #\n/// # let font_handle: Handle<Font> = Default::default();\n/// # let mut world = World::default();\n/// #\n/// // Basic usage.\n/// world.spawn(Text2d::new(\"hello world!\"));\n///\n/// // With non-default style.\n/// world.spawn((\n///     Text2d::new(\"hello world!\"),\n///     TextFont {\n///         font: font_handle.clone().into(),\n///         font_size: 60.0,\n///         ..Default::default()\n///     },\n///     TextColor(BLUE.into()),\n/// ));\n///\n/// // With text justification.\n/// world.spawn((\n///     Text2d::new(\"hello world\\nand bevy!\"),\n///     TextLayout::new_with_justify(JustifyText::Center)\n/// ));\n/// ```\n#[derive(Component, Clone, Debug, Default, Deref, DerefMut, Reflect)]\n#[reflect(Component, Default, Debug)]\n#[require(\n    TextLayout,\n    TextFont,\n    TextColor,\n    TextBounds,\n    Anchor,\n    SpriteSource,\n    Visibility,\n    Transform\n)]\npub struct Text2d(pub String);\n\nimpl Text2d {\n    /// Makes a new 2d text component.\n    pub fn new(text: impl Into<String>) -> Self {\n        Self(text.into())\n    }\n}\n\nimpl TextRoot for Text2d {}\n\nimpl TextSpanAccess for Text2d {\n    fn read_span(&self) -> &str {\n        self.as_str()\n    }\n    fn write_span(&mut self) -> &mut String {\n        &mut *self\n    }\n}\n\nimpl From<&str> for Text2d {\n    fn from(value: &str) -> Self {\n        Self(String::from(value))\n    }\n}\n\nimpl From<String> for Text2d {\n    fn from(value: String) -> Self {\n        Self(value)\n    }\n}\n\n/// 2d alias for [`TextReader`].\npub type Text2dReader<'w, 's> = TextReader<'w, 's, Text2d>;\n\n/// 2d alias for [`TextWriter`].\npub type Text2dWriter<'w, 's> = TextWriter<'w, 's, Text2d>;\n\n/// This system extracts the sprites from the 2D text components and adds them to the\n/// \"render world\".\npub fn extract_text2d_sprite(\n    mut commands: Commands,\n    mut extracted_sprites: ResMut<ExtractedSprites>,\n    texture_atlases: Extract<Res<Assets<TextureAtlasLayout>>>,\n    windows: Extract<Query<&Window, With<PrimaryWindow>>>,\n    text2d_query: Extract<\n        Query<(\n            Entity,\n            &ViewVisibility,\n            &ComputedTextBlock,\n            &TextLayoutInfo,\n            &Anchor,\n            &GlobalTransform,\n        )>,\n    >,\n    text_styles: Extract<Query<(&TextFont, &TextColor)>>,\n) {\n    // TODO: Support window-independent scaling: https://github.com/bevyengine/bevy/issues/5621\n    let scale_factor = windows\n        .get_single()\n        .map(|window| window.resolution.scale_factor())\n        .unwrap_or(1.0);\n    let scaling = GlobalTransform::from_scale(Vec2::splat(scale_factor.recip()).extend(1.));\n\n    for (\n        original_entity,\n        view_visibility,\n        computed_block,\n        text_layout_info,\n        anchor,\n        global_transform,\n    ) in text2d_query.iter()\n    {\n        if !view_visibility.get() {\n            continue;\n        }\n\n        let text_anchor = -(anchor.as_vec() + 0.5);\n        let alignment_translation = text_layout_info.size * text_anchor;\n        let transform = *global_transform\n            * GlobalTransform::from_translation(alignment_translation.extend(0.))\n            * scaling;\n        let mut color = LinearRgba::WHITE;\n        let mut current_span = usize::MAX;\n        for PositionedGlyph {\n            position,\n            atlas_info,\n            span_index,\n            ..\n        } in &text_layout_info.glyphs\n        {\n            if *span_index != current_span {\n                color = text_styles\n                    .get(\n                        computed_block\n                            .entities()\n                            .get(*span_index)\n                            .map(|t| t.entity)\n                            .unwrap_or(Entity::PLACEHOLDER),\n                    )\n                    .map(|(_, text_color)| LinearRgba::from(text_color.0))\n                    .unwrap_or_default();\n                current_span = *span_index;\n            }\n            let atlas = texture_atlases.get(&atlas_info.texture_atlas).unwrap();\n\n            extracted_sprites.sprites.insert(\n                (\n                    commands.spawn(TemporaryRenderEntity).id(),\n                    original_entity.into(),\n                ),\n                ExtractedSprite {\n                    transform: transform * GlobalTransform::from_translation(position.extend(0.)),\n                    color,\n                    rect: Some(atlas.textures[atlas_info.location.glyph_index].as_rect()),\n                    custom_size: None,\n                    image_handle_id: atlas_info.texture.id(),\n                    flip_x: false,\n                    flip_y: false,\n                    anchor: Anchor::Center.as_vec(),\n                    original_entity: Some(original_entity),\n                },\n            );\n        }\n    }\n}\n\n/// Updates the layout and size information whenever the text or style is changed.\n/// This information is computed by the [`TextPipeline`] on insertion, then stored.\n///\n/// ## World Resources\n///\n/// [`ResMut<Assets<Image>>`](Assets<Image>) -- This system only adds new [`Image`] assets.\n/// It does not modify or observe existing ones.\n#[allow(clippy::too_many_arguments)]\npub fn update_text2d_layout(\n    mut last_scale_factor: Local<f32>,\n    // Text items which should be reprocessed again, generally when the font hasn't loaded yet.\n    mut queue: Local<HashSet<Entity>>,\n    mut textures: ResMut<Assets<Image>>,\n    fonts: Res<Assets<Font>>,\n    windows: Query<&Window, With<PrimaryWindow>>,\n    mut texture_atlases: ResMut<Assets<TextureAtlasLayout>>,\n    mut font_atlas_sets: ResMut<FontAtlasSets>,\n    mut text_pipeline: ResMut<TextPipeline>,\n    mut text_query: Query<(\n        Entity,\n        Ref<TextLayout>,\n        Ref<TextBounds>,\n        &mut TextLayoutInfo,\n        &mut ComputedTextBlock,\n    )>,\n    mut text_reader: Text2dReader,\n    mut font_system: ResMut<CosmicFontSystem>,\n    mut swash_cache: ResMut<SwashCache>,\n) {\n    // TODO: Support window-independent scaling: https://github.com/bevyengine/bevy/issues/5621\n    let scale_factor = windows\n        .get_single()\n        .map(|window| window.resolution.scale_factor())\n        .unwrap_or(1.0);\n\n    let inverse_scale_factor = scale_factor.recip();\n\n    let factor_changed = *last_scale_factor != scale_factor;\n    *last_scale_factor = scale_factor;\n\n    for (entity, block, bounds, text_layout_info, mut computed) in &mut text_query {\n        if factor_changed\n            || computed.needs_rerender()\n            || bounds.is_changed()\n            || queue.remove(&entity)\n        {\n            let text_bounds = TextBounds {\n                width: if block.linebreak == LineBreak::NoWrap {\n                    None\n                } else {\n                    bounds.width.map(|width| scale_value(width, scale_factor))\n                },\n                height: bounds\n                    .height\n                    .map(|height| scale_value(height, scale_factor)),\n            };\n\n            let text_layout_info = text_layout_info.into_inner();\n            match text_pipeline.queue_text(\n                text_layout_info,\n                &fonts,\n                text_reader.iter(entity),\n                scale_factor.into(),\n                &block,\n                text_bounds,\n                &mut font_atlas_sets,\n                &mut texture_atlases,\n                &mut textures,\n                YAxisOrientation::BottomToTop,\n                computed.as_mut(),\n                &mut font_system,\n                &mut swash_cache,\n            ) {\n                Err(TextError::NoSuchFont) => {\n                    // There was an error processing the text layout, let's add this entity to the\n                    // queue for further processing\n                    queue.insert(entity);\n                }\n                Err(e @ (TextError::FailedToAddGlyph(_) | TextError::FailedToGetGlyphImage(_))) => {\n                    panic!(\"Fatal error when processing text: {e}.\");\n                }\n                Ok(()) => {\n                    text_layout_info.size.x =\n                        scale_value(text_layout_info.size.x, inverse_scale_factor);\n                    text_layout_info.size.y =\n                        scale_value(text_layout_info.size.y, inverse_scale_factor);\n                }\n            }\n        }\n    }\n}\n\n/// Scales `value` by `factor`.\npub fn scale_value(value: f32, factor: f32) -> f32 {\n    value * factor\n}\n\n/// System calculating and inserting an [`Aabb`] component to entities with some\n/// [`TextLayoutInfo`] and [`Anchor`] components, and without a [`NoFrustumCulling`] component.\n///\n/// Used in system set [`VisibilitySystems::CalculateBounds`](bevy_render::view::VisibilitySystems::CalculateBounds).\npub fn calculate_bounds_text2d(\n    mut commands: Commands,\n    mut text_to_update_aabb: Query<\n        (Entity, &TextLayoutInfo, &Anchor, Option<&mut Aabb>),\n        (Changed<TextLayoutInfo>, Without<NoFrustumCulling>),\n    >,\n) {\n    for (entity, layout_info, anchor, aabb) in &mut text_to_update_aabb {\n        // `Anchor::as_vec` gives us an offset relative to the text2d bounds, by negating it and scaling\n        // by the logical size we compensate the transform offset in local space to get the center.\n        let center = (-anchor.as_vec() * layout_info.size).extend(0.0).into();\n        // Distance in local space from the center to the x and y limits of the text2d bounds.\n        let half_extents = (layout_info.size / 2.0).extend(0.0).into();\n        if let Some(mut aabb) = aabb {\n            *aabb = Aabb {\n                center,\n                half_extents,\n            };\n        } else {\n            commands.entity(entity).try_insert(Aabb {\n                center,\n                half_extents,\n            });\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n\n    use bevy_app::{App, Update};\n    use bevy_asset::{load_internal_binary_asset, Handle};\n    use bevy_ecs::schedule::IntoSystemConfigs;\n\n    use crate::{detect_text_needs_rerender, TextIterScratch};\n\n    use super::*;\n\n    const FIRST_TEXT: &str = \"Sample text.\";\n    const SECOND_TEXT: &str = \"Another, longer sample text.\";\n\n    fn setup() -> (App, Entity) {\n        let mut app = App::new();\n        app.init_resource::<Assets<Font>>()\n            .init_resource::<Assets<Image>>()\n            .init_resource::<Assets<TextureAtlasLayout>>()\n            .init_resource::<FontAtlasSets>()\n            .init_resource::<TextPipeline>()\n            .init_resource::<CosmicFontSystem>()\n            .init_resource::<SwashCache>()\n            .init_resource::<TextIterScratch>()\n            .add_systems(\n                Update,\n                (\n                    detect_text_needs_rerender::<Text2d>,\n                    update_text2d_layout,\n                    calculate_bounds_text2d,\n                )\n                    .chain(),\n            );\n\n        // A font is needed to ensure the text is laid out with an actual size.\n        load_internal_binary_asset!(\n            app,\n            Handle::default(),\n            \"FiraMono-subset.ttf\",\n            |bytes: &[u8], _path: String| { Font::try_from_bytes(bytes.to_vec()).unwrap() }\n        );\n\n        let entity = app.world_mut().spawn(Text2d::new(FIRST_TEXT)).id();\n\n        (app, entity)\n    }\n\n    #[test]\n    fn calculate_bounds_text2d_create_aabb() {\n        let (mut app, entity) = setup();\n\n        assert!(!app\n            .world()\n            .get_entity(entity)\n            .expect(\"Could not find entity\")\n            .contains::<Aabb>());\n\n        // Creates the AABB after text layouting.\n        app.update();\n\n        let aabb = app\n            .world()\n            .get_entity(entity)\n            .expect(\"Could not find entity\")\n            .get::<Aabb>()\n            .expect(\"Text should have an AABB\");\n\n        // Text2D AABB does not have a depth.\n        assert_eq!(aabb.center.z, 0.0);\n        assert_eq!(aabb.half_extents.z, 0.0);\n\n        // AABB has an actual size.\n        assert!(aabb.half_extents.x > 0.0 && aabb.half_extents.y > 0.0);\n    }\n\n    #[test]\n    fn calculate_bounds_text2d_update_aabb() {\n        let (mut app, entity) = setup();\n\n        // Creates the initial AABB after text layouting.\n        app.update();\n\n        let first_aabb = *app\n            .world()\n            .get_entity(entity)\n            .expect(\"Could not find entity\")\n            .get::<Aabb>()\n            .expect(\"Could not find initial AABB\");\n\n        let mut entity_ref = app\n            .world_mut()\n            .get_entity_mut(entity)\n            .expect(\"Could not find entity\");\n        *entity_ref\n            .get_mut::<Text2d>()\n            .expect(\"Missing Text2d on entity\") = Text2d::new(SECOND_TEXT);\n\n        // Recomputes the AABB.\n        app.update();\n\n        let second_aabb = *app\n            .world()\n            .get_entity(entity)\n            .expect(\"Could not find entity\")\n            .get::<Aabb>()\n            .expect(\"Could not find second AABB\");\n\n        // Check that the height is the same, but the width is greater.\n        approx::assert_abs_diff_eq!(first_aabb.half_extents.y, second_aabb.half_extents.y);\n        assert!(FIRST_TEXT.len() < SECOND_TEXT.len());\n        assert!(first_aabb.half_extents.x < second_aabb.half_extents.x);\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "408dbdedf661a9409a690e254b9166a7c9c01822",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_ecs/compile_fail/tests/ui/system_param_derive_readonly.rs",
    "func": "use bevy_ecs::prelude::*;\nuse bevy_ecs::system::{ReadOnlySystemParam, SystemParam, SystemState};\n\n#[derive(Component)]\nstruct Foo;\n\n#[derive(SystemParam)]\nstruct Mutable<'w, 's> {\n    a: Query<'w, 's, &'static mut Foo>,\n}\n\nfn main() {\n\n    let mut world = World::default();\n    let state = SystemState::<Mutable>::new(&mut world);\n    state.get(&world);\n    //~^ E0277\n}\n\nfn assert_readonly<P>()\nwhere\n    P: ReadOnlySystemParam,\n{\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "2d3da0acfb8befa45b4df1e8477bce1b613e0b54",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_ecs/compile_fail/tests/ui/query_iter_combinations_mut_iterator_safety.rs",
    "func": "use bevy_ecs::prelude::*;\n\n#[derive(Component)]\nstruct A(usize);\n\nfn system(mut query: Query<&mut A>) {\n    let iter = query.iter_combinations_mut();\n\n    is_iterator(iter)\n    //~^ E0277\n}\n\nfn is_iterator<T: Iterator>(_iter: T) {}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "707f02f5808d93b246eb4414016a31c896e5dba6",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_ecs/src/world/deferred_world.rs",
    "func": "use core::ops::Deref;\n\nuse crate::{\n    archetype::Archetype,\n    change_detection::MutUntyped,\n    component::{ComponentId, Mutable},\n    entity::Entity,\n    event::{Event, EventId, Events, SendBatchIds},\n    observer::{Observers, TriggerTargets},\n    prelude::{Component, QueryState},\n    query::{QueryData, QueryFilter},\n    system::{Commands, Query, Resource},\n    traversal::Traversal,\n    world::{error::EntityFetchError, WorldEntityFetch},\n};\n\nuse super::{unsafe_world_cell::UnsafeWorldCell, Mut, World};\n\n/// A [`World`] reference that disallows structural ECS changes.\n/// This includes initializing resources, registering components or spawning entities.\npub struct DeferredWorld<'w> {\n    // SAFETY: Implementors must not use this reference to make structural changes\n    world: UnsafeWorldCell<'w>,\n}\n\nimpl<'w> Deref for DeferredWorld<'w> {\n    type Target = World;\n\n    fn deref(&self) -> &Self::Target {\n        // SAFETY: Structural changes cannot be made through &World\n        unsafe { self.world.world() }\n    }\n}\n\nimpl<'w> UnsafeWorldCell<'w> {\n    /// Turn self into a [`DeferredWorld`]\n    ///\n    /// # Safety\n    /// Caller must ensure there are no outstanding mutable references to world and no\n    /// outstanding references to the world's command queue, resource or component data\n    #[inline]\n    pub unsafe fn into_deferred(self) -> DeferredWorld<'w> {\n        DeferredWorld { world: self }\n    }\n}\n\nimpl<'w> From<&'w mut World> for DeferredWorld<'w> {\n    fn from(world: &'w mut World) -> DeferredWorld<'w> {\n        DeferredWorld {\n            world: world.as_unsafe_world_cell(),\n        }\n    }\n}\n\nimpl<'w> DeferredWorld<'w> {\n    /// Reborrow self as a new instance of [`DeferredWorld`]\n    #[inline]\n    pub fn reborrow(&mut self) -> DeferredWorld {\n        DeferredWorld { world: self.world }\n    }\n\n    /// Creates a [`Commands`] instance that pushes to the world's command queue\n    #[inline]\n    pub fn commands(&mut self) -> Commands {\n        // SAFETY: &mut self ensure that there are no outstanding accesses to the queue\n        let command_queue = unsafe { self.world.get_raw_command_queue() };\n        // SAFETY: command_queue is stored on world and always valid while the world exists\n        unsafe { Commands::new_raw_from_entities(command_queue, self.world.entities()) }\n    }\n\n    /// Retrieves a mutable reference to the given `entity`'s [`Component`] of the given type.\n    /// Returns `None` if the `entity` does not have a [`Component`] of the given type.\n    #[inline]\n    pub fn get_mut<T: Component<Mutability = Mutable>>(\n        &mut self,\n        entity: Entity,\n    ) -> Option<Mut<T>> {\n        // SAFETY:\n        // - `as_unsafe_world_cell` is the only thing that is borrowing world\n        // - `as_unsafe_world_cell` provides mutable permission to everything\n        // - `&mut self` ensures no other borrows on world data\n        unsafe { self.world.get_entity(entity)?.get_mut() }\n    }\n\n    /// Returns [`EntityMut`]s that expose read and write operations for the\n    /// given `entities`, returning [`Err`] if any of the given entities do not\n    /// exist. Instead of immediately unwrapping the value returned from this\n    /// function, prefer [`World::entity_mut`].\n    ///\n    /// This function supports fetching a single entity or multiple entities:\n    /// - Pass an [`Entity`] to receive a single [`EntityMut`].\n    /// - Pass a slice of [`Entity`]s to receive a [`Vec<EntityMut>`].\n    /// - Pass an array of [`Entity`]s to receive an equally-sized array of [`EntityMut`]s.\n    /// - Pass an [`&EntityHashSet`] to receive an [`EntityHashMap<EntityMut>`].\n    ///\n    /// **As [`DeferredWorld`] does not allow structural changes, all returned\n    /// references are [`EntityMut`]s, which do not allow structural changes\n    /// (i.e. adding/removing components or despawning the entity).**\n    ///\n    /// # Errors\n    ///\n    /// - Returns [`EntityFetchError::NoSuchEntity`] if any of the given `entities` do not exist in the world.\n    ///     - Only the first entity found to be missing will be returned.\n    /// - Returns [`EntityFetchError::AliasedMutability`] if the same entity is requested multiple times.\n    ///\n    /// # Examples\n    ///\n    /// For examples, see [`DeferredWorld::entity_mut`].\n    ///\n    /// [`EntityMut`]: crate::world::EntityMut\n    /// [`&EntityHashSet`]: crate::entity::EntityHashSet\n    /// [`EntityHashMap<EntityMut>`]: crate::entity::EntityHashMap\n    #[inline]\n    pub fn get_entity_mut<F: WorldEntityFetch>(\n        &mut self,\n        entities: F,\n    ) -> Result<F::DeferredMut<'_>, EntityFetchError> {\n        let cell = self.as_unsafe_world_cell();\n        // SAFETY: `&mut self` gives mutable access to the entire world,\n        // and prevents any other access to the world.\n        unsafe { entities.fetch_deferred_mut(cell) }\n    }\n\n    /// Returns [`EntityMut`]s that expose read and write operations for the\n    /// given `entities`. This will panic if any of the given entities do not\n    /// exist. Use [`DeferredWorld::get_entity_mut`] if you want to check for\n    /// entity existence instead of implicitly panicking.\n    ///\n    /// This function supports fetching a single entity or multiple entities:\n    /// - Pass an [`Entity`] to receive a single [`EntityMut`].\n    /// - Pass a slice of [`Entity`]s to receive a [`Vec<EntityMut>`].\n    /// - Pass an array of [`Entity`]s to receive an equally-sized array of [`EntityMut`]s.\n    /// - Pass an [`&EntityHashSet`] to receive an [`EntityHashMap<EntityMut>`].\n    ///\n    /// **As [`DeferredWorld`] does not allow structural changes, all returned\n    /// references are [`EntityMut`]s, which do not allow structural changes\n    /// (i.e. adding/removing components or despawning the entity).**\n    ///\n    /// # Panics\n    ///\n    /// If any of the given `entities` do not exist in the world.\n    ///\n    /// # Examples\n    ///\n    /// ## Single [`Entity`]\n    ///\n    /// ```\n    /// # use bevy_ecs::{prelude::*, world::DeferredWorld};\n    /// #[derive(Component)]\n    /// struct Position {\n    ///   x: f32,\n    ///   y: f32,\n    /// }\n    ///\n    /// # let mut world = World::new();\n    /// # let entity = world.spawn(Position { x: 0.0, y: 0.0 }).id();\n    /// let mut world: DeferredWorld = // ...\n    /// #   DeferredWorld::from(&mut world);\n    ///\n    /// let mut entity_mut = world.entity_mut(entity);\n    /// let mut position = entity_mut.get_mut::<Position>().unwrap();\n    /// position.y = 1.0;\n    /// assert_eq!(position.x, 0.0);\n    /// ```\n    ///\n    /// ## Array of [`Entity`]s\n    ///\n    /// ```\n    /// # use bevy_ecs::{prelude::*, world::DeferredWorld};\n    /// #[derive(Component)]\n    /// struct Position {\n    ///   x: f32,\n    ///   y: f32,\n    /// }\n    ///\n    /// # let mut world = World::new();\n    /// # let e1 = world.spawn(Position { x: 0.0, y: 0.0 }).id();\n    /// # let e2 = world.spawn(Position { x: 1.0, y: 1.0 }).id();\n    /// let mut world: DeferredWorld = // ...\n    /// #   DeferredWorld::from(&mut world);\n    ///\n    /// let [mut e1_ref, mut e2_ref] = world.entity_mut([e1, e2]);\n    /// let mut e1_position = e1_ref.get_mut::<Position>().unwrap();\n    /// e1_position.x = 1.0;\n    /// assert_eq!(e1_position.x, 1.0);\n    /// let mut e2_position = e2_ref.get_mut::<Position>().unwrap();\n    /// e2_position.x = 2.0;\n    /// assert_eq!(e2_position.x, 2.0);\n    /// ```\n    ///\n    /// ## Slice of [`Entity`]s\n    ///\n    /// ```\n    /// # use bevy_ecs::{prelude::*, world::DeferredWorld};\n    /// #[derive(Component)]\n    /// struct Position {\n    ///   x: f32,\n    ///   y: f32,\n    /// }\n    ///\n    /// # let mut world = World::new();\n    /// # let e1 = world.spawn(Position { x: 0.0, y: 1.0 }).id();\n    /// # let e2 = world.spawn(Position { x: 0.0, y: 1.0 }).id();\n    /// # let e3 = world.spawn(Position { x: 0.0, y: 1.0 }).id();\n    /// let mut world: DeferredWorld = // ...\n    /// #   DeferredWorld::from(&mut world);\n    ///\n    /// let ids = vec![e1, e2, e3];\n    /// for mut eref in world.entity_mut(&ids[..]) {\n    ///     let mut pos = eref.get_mut::<Position>().unwrap();\n    ///     pos.y = 2.0;\n    ///     assert_eq!(pos.y, 2.0);\n    /// }\n    /// ```\n    ///\n    /// ## [`&EntityHashSet`]\n    ///\n    /// ```\n    /// # use bevy_ecs::{prelude::*, entity::EntityHashSet, world::DeferredWorld};\n    /// #[derive(Component)]\n    /// struct Position {\n    ///   x: f32,\n    ///   y: f32,\n    /// }\n    ///\n    /// # let mut world = World::new();\n    /// # let e1 = world.spawn(Position { x: 0.0, y: 1.0 }).id();\n    /// # let e2 = world.spawn(Position { x: 0.0, y: 1.0 }).id();\n    /// # let e3 = world.spawn(Position { x: 0.0, y: 1.0 }).id();\n    /// let mut world: DeferredWorld = // ...\n    /// #   DeferredWorld::from(&mut world);\n    ///\n    /// let ids = EntityHashSet::from_iter([e1, e2, e3]);\n    /// for (_id, mut eref) in world.entity_mut(&ids) {\n    ///     let mut pos = eref.get_mut::<Position>().unwrap();\n    ///     pos.y = 2.0;\n    ///     assert_eq!(pos.y, 2.0);\n    /// }\n    /// ```\n    ///\n    /// [`EntityMut`]: crate::world::EntityMut\n    /// [`&EntityHashSet`]: crate::entity::EntityHashSet\n    /// [`EntityHashMap<EntityMut>`]: crate::entity::EntityHashMap\n    #[inline]\n    pub fn entity_mut<F: WorldEntityFetch>(&mut self, entities: F) -> F::DeferredMut<'_> {\n        self.get_entity_mut(entities).unwrap()\n    }\n\n    /// Returns [`Query`] for the given [`QueryState`], which is used to efficiently\n    /// run queries on the [`World`] by storing and reusing the [`QueryState`].\n    ///\n    /// # Panics\n    /// If state is from a different world then self\n    #[inline]\n    pub fn query<'s, D: QueryData, F: QueryFilter>(\n        &mut self,\n        state: &'s mut QueryState<D, F>,\n    ) -> Query<'_, 's, D, F> {\n        state.validate_world(self.world.id());\n        state.update_archetypes(self);\n        // SAFETY: We ran validate_world to ensure our state matches\n        unsafe {\n            let world_cell = self.world;\n            Query::new(\n                world_cell,\n                state,\n                world_cell.last_change_tick(),\n                world_cell.change_tick(),\n            )\n        }\n    }\n\n    /// Gets a mutable reference to the resource of the given type\n    ///\n    /// # Panics\n    ///\n    /// Panics if the resource does not exist.\n    /// Use [`get_resource_mut`](DeferredWorld::get_resource_mut) instead if you want to handle this case.\n    #[inline]\n    #[track_caller]\n    pub fn resource_mut<R: Resource>(&mut self) -> Mut<'_, R> {\n        match self.get_resource_mut() {\n            Some(x) => x,\n            None => panic!(\n                \"Requested resource {} does not exist in the `World`.\n                Did you forget to add it using `app.insert_resource` / `app.init_resource`?\n                Resources are also implicitly added via `app.add_event`,\n                and can be added by plugins.\",\n                core::any::type_name::<R>()\n            ),\n        }\n    }\n\n    /// Gets a mutable reference to the resource of the given type if it exists\n    #[inline]\n    pub fn get_resource_mut<R: Resource>(&mut self) -> Option<Mut<'_, R>> {\n        // SAFETY: &mut self ensure that there are no outstanding accesses to the resource\n        unsafe { self.world.get_resource_mut() }\n    }\n\n    /// Gets a mutable reference to the non-send resource of the given type, if it exists.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the resource does not exist.\n    /// Use [`get_non_send_resource_mut`](World::get_non_send_resource_mut) instead if you want to handle this case.\n    ///\n    /// This function will panic if it isn't called from the same thread that the resource was inserted from.\n    #[inline]\n    #[track_caller]\n    pub fn non_send_resource_mut<R: 'static>(&mut self) -> Mut<'_, R> {\n        match self.get_non_send_resource_mut() {\n            Some(x) => x,\n            None => panic!(\n                \"Requested non-send resource {} does not exist in the `World`.\n                Did you forget to add it using `app.insert_non_send_resource` / `app.init_non_send_resource`?\n                Non-send resources can also be added by plugins.\",\n                core::any::type_name::<R>()\n            ),\n        }\n    }\n\n    /// Gets a mutable reference to the non-send resource of the given type, if it exists.\n    /// Otherwise returns `None`.\n    ///\n    /// # Panics\n    /// This function will panic if it isn't called from the same thread that the resource was inserted from.\n    #[inline]\n    pub fn get_non_send_resource_mut<R: 'static>(&mut self) -> Option<Mut<'_, R>> {\n        // SAFETY: &mut self ensure that there are no outstanding accesses to the resource\n        unsafe { self.world.get_non_send_resource_mut() }\n    }\n\n    /// Sends an [`Event`].\n    /// This method returns the [ID](`EventId`) of the sent `event`,\n    /// or [`None`] if the `event` could not be sent.\n    #[inline]\n    pub fn send_event<E: Event>(&mut self, event: E) -> Option<EventId<E>> {\n        self.send_event_batch(core::iter::once(event))?.next()\n    }\n\n    /// Sends the default value of the [`Event`] of type `E`.\n    /// This method returns the [ID](`EventId`) of the sent `event`,\n    /// or [`None`] if the `event` could not be sent.\n    #[inline]\n    pub fn send_event_default<E: Event + Default>(&mut self) -> Option<EventId<E>> {\n        self.send_event(E::default())\n    }\n\n    /// Sends a batch of [`Event`]s from an iterator.\n    /// This method returns the [IDs](`EventId`) of the sent `events`,\n    /// or [`None`] if the `event` could not be sent.\n    #[inline]\n    pub fn send_event_batch<E: Event>(\n        &mut self,\n        events: impl IntoIterator<Item = E>,\n    ) -> Option<SendBatchIds<E>> {\n        let Some(mut events_resource) = self.get_resource_mut::<Events<E>>() else {\n            bevy_utils::tracing::error!(\n                \"Unable to send event `{}`\\n\\tEvent must be added to the app with `add_event()`\\n\\thttps://docs.rs/bevy/*/bevy/app/struct.App.html#method.add_event \",\n                core::any::type_name::<E>()\n            );\n            return None;\n        };\n        Some(events_resource.send_batch(events))\n    }\n\n    /// Gets a pointer to the resource with the id [`ComponentId`] if it exists.\n    /// The returned pointer may be used to modify the resource, as long as the mutable borrow\n    /// of the [`World`] is still valid.\n    ///\n    /// **You should prefer to use the typed API [`World::get_resource_mut`] where possible and only\n    /// use this in cases where the actual types are not known at compile time.**\n    #[inline]\n    pub fn get_resource_mut_by_id(&mut self, component_id: ComponentId) -> Option<MutUntyped<'_>> {\n        // SAFETY: &mut self ensure that there are no outstanding accesses to the resource\n        unsafe { self.world.get_resource_mut_by_id(component_id) }\n    }\n\n    /// Gets a `!Send` resource to the resource with the id [`ComponentId`] if it exists.\n    /// The returned pointer may be used to modify the resource, as long as the mutable borrow\n    /// of the [`World`] is still valid.\n    ///\n    /// **You should prefer to use the typed API [`World::get_resource_mut`] where possible and only\n    /// use this in cases where the actual types are not known at compile time.**\n    ///\n    /// # Panics\n    /// This function will panic if it isn't called from the same thread that the resource was inserted from.\n    #[inline]\n    pub fn get_non_send_mut_by_id(&mut self, component_id: ComponentId) -> Option<MutUntyped<'_>> {\n        // SAFETY: &mut self ensure that there are no outstanding accesses to the resource\n        unsafe { self.world.get_non_send_resource_mut_by_id(component_id) }\n    }\n\n    /// Retrieves a mutable untyped reference to the given `entity`'s [`Component`] of the given [`ComponentId`].\n    /// Returns `None` if the `entity` does not have a [`Component`] of the given type.\n    ///\n    /// **You should prefer to use the typed API [`World::get_mut`] where possible and only\n    /// use this in cases where the actual types are not known at compile time.**\n    #[inline]\n    pub fn get_mut_by_id(\n        &mut self,\n        entity: Entity,\n        component_id: ComponentId,\n    ) -> Option<MutUntyped<'_>> {\n        // SAFETY: &mut self ensure that there are no outstanding accesses to the resource\n        unsafe {\n            self.world\n                .get_entity(entity)?\n                .get_mut_by_id(component_id)\n                .ok()\n        }\n    }\n\n    /// Triggers all `on_add` hooks for [`ComponentId`] in target.\n    ///\n    /// # Safety\n    /// Caller must ensure [`ComponentId`] in target exist in self.\n    #[inline]\n    pub(crate) unsafe fn trigger_on_add(\n        &mut self,\n        archetype: &Archetype,\n        entity: Entity,\n        targets: impl Iterator<Item = ComponentId>,\n    ) {\n        if archetype.has_add_hook() {\n            for component_id in targets {\n                // SAFETY: Caller ensures that these components exist\n                let hooks = unsafe { self.components().get_info_unchecked(component_id) }.hooks();\n                if let Some(hook) = hooks.on_add {\n                    hook(DeferredWorld { world: self.world }, entity, component_id);\n                }\n            }\n        }\n    }\n\n    /// Triggers all `on_insert` hooks for [`ComponentId`] in target.\n    ///\n    /// # Safety\n    /// Caller must ensure [`ComponentId`] in target exist in self.\n    #[inline]\n    pub(crate) unsafe fn trigger_on_insert(\n        &mut self,\n        archetype: &Archetype,\n        entity: Entity,\n        targets: impl Iterator<Item = ComponentId>,\n    ) {\n        if archetype.has_insert_hook() {\n            for component_id in targets {\n                // SAFETY: Caller ensures that these components exist\n                let hooks = unsafe { self.components().get_info_unchecked(component_id) }.hooks();\n                if let Some(hook) = hooks.on_insert {\n                    hook(DeferredWorld { world: self.world }, entity, component_id);\n                }\n            }\n        }\n    }\n\n    /// Triggers all `on_replace` hooks for [`ComponentId`] in target.\n    ///\n    /// # Safety\n    /// Caller must ensure [`ComponentId`] in target exist in self.\n    #[inline]\n    pub(crate) unsafe fn trigger_on_replace(\n        &mut self,\n        archetype: &Archetype,\n        entity: Entity,\n        targets: impl Iterator<Item = ComponentId>,\n    ) {\n        if archetype.has_replace_hook() {\n            for component_id in targets {\n                // SAFETY: Caller ensures that these components exist\n                let hooks = unsafe { self.components().get_info_unchecked(component_id) }.hooks();\n                if let Some(hook) = hooks.on_replace {\n                    hook(DeferredWorld { world: self.world }, entity, component_id);\n                }\n            }\n        }\n    }\n\n    /// Triggers all `on_remove` hooks for [`ComponentId`] in target.\n    ///\n    /// # Safety\n    /// Caller must ensure [`ComponentId`] in target exist in self.\n    #[inline]\n    pub(crate) unsafe fn trigger_on_remove(\n        &mut self,\n        archetype: &Archetype,\n        entity: Entity,\n        targets: impl Iterator<Item = ComponentId>,\n    ) {\n        if archetype.has_remove_hook() {\n            for component_id in targets {\n                // SAFETY: Caller ensures that these components exist\n                let hooks = unsafe { self.components().get_info_unchecked(component_id) }.hooks();\n                if let Some(hook) = hooks.on_remove {\n                    hook(DeferredWorld { world: self.world }, entity, component_id);\n                }\n            }\n        }\n    }\n\n    /// Triggers all event observers for [`ComponentId`] in target.\n    ///\n    /// # Safety\n    /// Caller must ensure observers listening for `event` can accept ZST pointers\n    #[inline]\n    pub(crate) unsafe fn trigger_observers(\n        &mut self,\n        event: ComponentId,\n        entity: Entity,\n        components: impl Iterator<Item = ComponentId> + Clone,\n    ) {\n        Observers::invoke::<_>(\n            self.reborrow(),\n            event,\n            entity,\n            components,\n            &mut (),\n            &mut false,\n        );\n    }\n\n    /// Triggers all event observers for [`ComponentId`] in target.\n    ///\n    /// # Safety\n    /// Caller must ensure `E` is accessible as the type represented by `event`\n    #[inline]\n    pub(crate) unsafe fn trigger_observers_with_data<E, T>(\n        &mut self,\n        event: ComponentId,\n        mut entity: Entity,\n        components: &[ComponentId],\n        data: &mut E,\n        mut propagate: bool,\n    ) where\n        T: Traversal<E>,\n    {\n        loop {\n            Observers::invoke::<_>(\n                self.reborrow(),\n                event,\n                entity,\n                components.iter().copied(),\n                data,\n                &mut propagate,\n            );\n            if !propagate {\n                break;\n            }\n            if let Some(traverse_to) = self\n                .get_entity(entity)\n                .ok()\n                .and_then(|entity| entity.get_components::<T>())\n                .and_then(|item| T::traverse(item, data))\n            {\n                entity = traverse_to;\n            } else {\n                break;\n            }\n        }\n    }\n\n    /// Sends a \"global\" [`Trigger`](crate::observer::Trigger) without any targets.\n    pub fn trigger<T: Event>(&mut self, trigger: impl Event) {\n        self.commands().trigger(trigger);\n    }\n\n    /// Sends a [`Trigger`](crate::observer::Trigger) with the given `targets`.\n    pub fn trigger_targets(\n        &mut self,\n        trigger: impl Event,\n        targets: impl TriggerTargets + Send + Sync + 'static,\n    ) {\n        self.commands().trigger_targets(trigger, targets);\n    }\n\n    /// Gets an [`UnsafeWorldCell`] containing the underlying world.\n    ///\n    /// # Safety\n    /// - must only be used to make non-structural ECS changes\n    #[inline]\n    pub(crate) fn as_unsafe_world_cell(&mut self) -> UnsafeWorldCell {\n        self.world\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "093bb8652022746345448da265cb18103b93cc31",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_ecs/src/identifier/masks.rs",
    "func": "use core::num::NonZero;\n\nuse super::kinds::IdKind;\n\n/// Mask for extracting the value portion of a 32-bit high segment. This\n/// yields 31-bits of total value, as the final bit (the most significant)\n/// is reserved as a flag bit. Can be negated to extract the flag bit.\npub(crate) const HIGH_MASK: u32 = 0x7FFF_FFFF;\n\n/// Abstraction over masks needed to extract values/components of an [`super::Identifier`].\npub(crate) struct IdentifierMask;\n\nimpl IdentifierMask {\n    /// Returns the low component from a `u64` value\n    #[inline(always)]\n    pub(crate) const fn get_low(value: u64) -> u32 {\n        // This will truncate to the lowest 32 bits\n        value as u32\n    }\n\n    /// Returns the high component from a `u64` value\n    #[inline(always)]\n    pub(crate) const fn get_high(value: u64) -> u32 {\n        // This will discard the lowest 32 bits\n        (value >> u32::BITS) as u32\n    }\n\n    /// Pack a low and high `u32` values into a single `u64` value.\n    #[inline(always)]\n    pub(crate) const fn pack_into_u64(low: u32, high: u32) -> u64 {\n        ((high as u64) << u32::BITS) | (low as u64)\n    }\n\n    /// Pack the [`IdKind`] bits into a high segment.\n    #[inline(always)]\n    pub(crate) const fn pack_kind_into_high(value: u32, kind: IdKind) -> u32 {\n        value | ((kind as u32) << 24)\n    }\n\n    /// Extract the value component from a high segment of an [`super::Identifier`].\n    #[inline(always)]\n    pub(crate) const fn extract_value_from_high(value: u32) -> u32 {\n        value & HIGH_MASK\n    }\n\n    /// Extract the ID kind component from a high segment of an [`super::Identifier`].\n    #[inline(always)]\n    pub(crate) const fn extract_kind_from_high(value: u32) -> IdKind {\n        // The negated HIGH_MASK will extract just the bit we need for kind.\n        let kind_mask = !HIGH_MASK;\n        let bit = value & kind_mask;\n\n        if bit == kind_mask {\n            IdKind::Placeholder\n        } else {\n            IdKind::Entity\n        }\n    }\n\n    /// Offsets a masked generation value by the specified amount, wrapping to 1 instead of 0.\n    /// Will never be greater than [`HIGH_MASK`] or less than `1`, and increments are masked to\n    /// never be greater than [`HIGH_MASK`].\n    #[inline(always)]\n    pub(crate) const fn inc_masked_high_by(lhs: NonZero<u32>, rhs: u32) -> NonZero<u32> {\n        let lo = (lhs.get() & HIGH_MASK).wrapping_add(rhs & HIGH_MASK);\n        // Checks high 32 bit for whether we have overflowed 31 bits.\n        let overflowed = lo >> 31;\n\n        // SAFETY:\n        // - Adding the overflow flag will offset overflows to start at 1 instead of 0\n        // - The sum of `0x7FFF_FFFF` + `u32::MAX` + 1 (overflow) == `0x7FFF_FFFF`\n        // - If the operation doesn't overflow at 31 bits, no offsetting takes place\n        unsafe { NonZero::<u32>::new_unchecked(lo.wrapping_add(overflowed) & HIGH_MASK) }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn get_u64_parts() {\n        // Two distinct bit patterns per low/high component\n        let value: u64 = 0x7FFF_FFFF_0000_000C;\n\n        assert_eq!(IdentifierMask::get_low(value), 0x0000_000C);\n        assert_eq!(IdentifierMask::get_high(value), 0x7FFF_FFFF);\n    }\n\n    #[test]\n    fn extract_kind() {\n        // All bits are ones.\n        let high: u32 = 0xFFFF_FFFF;\n\n        assert_eq!(\n            IdentifierMask::extract_kind_from_high(high),\n            IdKind::Placeholder\n        );\n\n        // Second and second to last bits are ones.\n        let high: u32 = 0x4000_0002;\n\n        assert_eq!(IdentifierMask::extract_kind_from_high(high), IdKind::Entity);\n    }\n\n    #[test]\n    fn extract_high_value() {\n        // All bits are ones.\n        let high: u32 = 0xFFFF_FFFF;\n\n        // Excludes the most significant bit as that is a flag bit.\n        assert_eq!(IdentifierMask::extract_value_from_high(high), 0x7FFF_FFFF);\n\n        // Start bit and end bit are ones.\n        let high: u32 = 0x8000_0001;\n\n        assert_eq!(IdentifierMask::extract_value_from_high(high), 0x0000_0001);\n\n        // Classic bit pattern.\n        let high: u32 = 0xDEAD_BEEF;\n\n        assert_eq!(IdentifierMask::extract_value_from_high(high), 0x5EAD_BEEF);\n    }\n\n    #[test]\n    fn pack_kind_bits() {\n        // All bits are ones expect the most significant bit, which is zero\n        let high: u32 = 0x7FFF_FFFF;\n\n        assert_eq!(\n            IdentifierMask::pack_kind_into_high(high, IdKind::Placeholder),\n            0xFFFF_FFFF\n        );\n\n        // Arbitrary bit pattern\n        let high: u32 = 0x00FF_FF00;\n\n        assert_eq!(\n            IdentifierMask::pack_kind_into_high(high, IdKind::Entity),\n            // Remains unchanged as before\n            0x00FF_FF00\n        );\n\n        // Bit pattern that almost spells a word\n        let high: u32 = 0x40FF_EEEE;\n\n        assert_eq!(\n            IdentifierMask::pack_kind_into_high(high, IdKind::Placeholder),\n            0xC0FF_EEEE // Milk and no sugar, please.\n        );\n    }\n\n    #[test]\n    fn pack_into_u64() {\n        let high: u32 = 0x7FFF_FFFF;\n        let low: u32 = 0x0000_00CC;\n\n        assert_eq!(\n            IdentifierMask::pack_into_u64(low, high),\n            0x7FFF_FFFF_0000_00CC\n        );\n    }\n\n    #[test]\n    fn incrementing_masked_nonzero_high_is_safe() {\n        // Adding from lowest value with lowest to highest increment\n        // No result should ever be greater than 0x7FFF_FFFF or HIGH_MASK\n        assert_eq!(\n            NonZero::<u32>::MIN,\n            IdentifierMask::inc_masked_high_by(NonZero::<u32>::MIN, 0)\n        );\n        assert_eq!(\n            NonZero::<u32>::new(2).unwrap(),\n            IdentifierMask::inc_masked_high_by(NonZero::<u32>::MIN, 1)\n        );\n        assert_eq!(\n            NonZero::<u32>::new(3).unwrap(),\n            IdentifierMask::inc_masked_high_by(NonZero::<u32>::MIN, 2)\n        );\n        assert_eq!(\n            NonZero::<u32>::MIN,\n            IdentifierMask::inc_masked_high_by(NonZero::<u32>::MIN, HIGH_MASK)\n        );\n        assert_eq!(\n            NonZero::<u32>::MIN,\n            IdentifierMask::inc_masked_high_by(NonZero::<u32>::MIN, u32::MAX)\n        );\n        // Adding from absolute highest value with lowest to highest increment\n        // No result should ever be greater than 0x7FFF_FFFF or HIGH_MASK\n        assert_eq!(\n            NonZero::<u32>::new(HIGH_MASK).unwrap(),\n            IdentifierMask::inc_masked_high_by(NonZero::<u32>::MAX, 0)\n        );\n        assert_eq!(\n            NonZero::<u32>::MIN,\n            IdentifierMask::inc_masked_high_by(NonZero::<u32>::MAX, 1)\n        );\n        assert_eq!(\n            NonZero::<u32>::new(2).unwrap(),\n            IdentifierMask::inc_masked_high_by(NonZero::<u32>::MAX, 2)\n        );\n        assert_eq!(\n            NonZero::<u32>::new(HIGH_MASK).unwrap(),\n            IdentifierMask::inc_masked_high_by(NonZero::<u32>::MAX, HIGH_MASK)\n        );\n        assert_eq!(\n            NonZero::<u32>::new(HIGH_MASK).unwrap(),\n            IdentifierMask::inc_masked_high_by(NonZero::<u32>::MAX, u32::MAX)\n        );\n        // Adding from actual highest value with lowest to highest increment\n        // No result should ever be greater than 0x7FFF_FFFF or HIGH_MASK\n        assert_eq!(\n            NonZero::<u32>::new(HIGH_MASK).unwrap(),\n            IdentifierMask::inc_masked_high_by(NonZero::<u32>::new(HIGH_MASK).unwrap(), 0)\n        );\n        assert_eq!(\n            NonZero::<u32>::MIN,\n            IdentifierMask::inc_masked_high_by(NonZero::<u32>::new(HIGH_MASK).unwrap(), 1)\n        );\n        assert_eq!(\n            NonZero::<u32>::new(2).unwrap(),\n            IdentifierMask::inc_masked_high_by(NonZero::<u32>::new(HIGH_MASK).unwrap(), 2)\n        );\n        assert_eq!(\n            NonZero::<u32>::new(HIGH_MASK).unwrap(),\n            IdentifierMask::inc_masked_high_by(NonZero::<u32>::new(HIGH_MASK).unwrap(), HIGH_MASK)\n        );\n        assert_eq!(\n            NonZero::<u32>::new(HIGH_MASK).unwrap(),\n            IdentifierMask::inc_masked_high_by(NonZero::<u32>::new(HIGH_MASK).unwrap(), u32::MAX)\n        );\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "01bdd8ab7eb8a3700eef87b3874020c995927841",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_mesh/src/mesh.rs",
    "func": "use bevy_transform::components::Transform;\npub use wgpu_types::PrimitiveTopology;\n\nuse super::{\n    face_area_normal, face_normal, generate_tangents_for_mesh, scale_normal, FourIterators,\n    GenerateTangentsError, Indices, MeshAttributeData, MeshTrianglesError, MeshVertexAttribute,\n    MeshVertexAttributeId, MeshVertexBufferLayout, MeshVertexBufferLayoutRef,\n    MeshVertexBufferLayouts, MeshWindingInvertError, VertexAttributeValues, VertexBufferLayout,\n    VertexFormatSize,\n};\nuse alloc::collections::BTreeMap;\nuse bevy_asset::{Asset, Handle, RenderAssetUsages};\nuse bevy_image::Image;\nuse bevy_math::{primitives::Triangle3d, *};\nuse bevy_reflect::Reflect;\nuse bevy_utils::tracing::warn;\nuse bytemuck::cast_slice;\nuse wgpu_types::{VertexAttribute, VertexFormat, VertexStepMode};\n\npub const INDEX_BUFFER_ASSET_INDEX: u64 = 0;\npub const VERTEX_ATTRIBUTE_BUFFER_ID: u64 = 10;\n\n/// A 3D object made out of vertices representing triangles, lines, or points,\n/// with \"attribute\" values for each vertex.\n///\n/// Meshes can be automatically generated by a bevy `AssetLoader` (generally by loading a `Gltf` file),\n/// or by converting a [primitive](bevy_math::primitives) using [`into`](Into).\n/// It is also possible to create one manually. They can be edited after creation.\n///\n/// Meshes can be rendered with a `Mesh2d` and `MeshMaterial2d`\n/// or `Mesh3d` and `MeshMaterial3d` for 2D and 3D respectively.\n///\n/// A [`Mesh`] in Bevy is equivalent to a \"primitive\" in the glTF format, for a\n/// glTF Mesh representation, see `GltfMesh`.\n///\n/// ## Manual creation\n///\n/// The following function will construct a flat mesh, to be rendered with a\n/// `StandardMaterial` or `ColorMaterial`:\n///\n/// ```\n/// # use bevy_mesh::{Mesh, Indices, PrimitiveTopology};\n/// # use bevy_asset::RenderAssetUsages;\n/// fn create_simple_parallelogram() -> Mesh {\n///     // Create a new mesh using a triangle list topology, where each set of 3 vertices composes a triangle.\n///     Mesh::new(PrimitiveTopology::TriangleList, RenderAssetUsages::default())\n///         // Add 4 vertices, each with its own position attribute (coordinate in\n///         // 3D space), for each of the corners of the parallelogram.\n///         .with_inserted_attribute(\n///             Mesh::ATTRIBUTE_POSITION,\n///             vec![[0.0, 0.0, 0.0], [1.0, 2.0, 0.0], [2.0, 2.0, 0.0], [1.0, 0.0, 0.0]]\n///         )\n///         // Assign a UV coordinate to each vertex.\n///         .with_inserted_attribute(\n///             Mesh::ATTRIBUTE_UV_0,\n///             vec![[0.0, 1.0], [0.5, 0.0], [1.0, 0.0], [0.5, 1.0]]\n///         )\n///         // Assign normals (everything points outwards)\n///         .with_inserted_attribute(\n///             Mesh::ATTRIBUTE_NORMAL,\n///             vec![[0.0, 0.0, 1.0], [0.0, 0.0, 1.0], [0.0, 0.0, 1.0], [0.0, 0.0, 1.0]]\n///         )\n///         // After defining all the vertices and their attributes, build each triangle using the\n///         // indices of the vertices that make it up in a counter-clockwise order.\n///         .with_inserted_indices(Indices::U32(vec![\n///             // First triangle\n///             0, 3, 1,\n///             // Second triangle\n///             1, 3, 2\n///         ]))\n/// }\n/// ```\n///\n/// You can see how it looks like [here](https://github.com/bevyengine/bevy/blob/main/assets/docs/Mesh.png),\n/// used in a `Mesh3d` with a square bevy logo texture, with added axis, points,\n/// lines and text for clarity.\n///\n/// ## Other examples\n///\n/// For further visualization, explanation, and examples, see the built-in Bevy examples,\n/// and the [implementation of the built-in shapes](https://github.com/bevyengine/bevy/tree/main/crates/bevy_mesh/src/primitives).\n/// In particular, [generate_custom_mesh](https://github.com/bevyengine/bevy/blob/main/examples/3d/generate_custom_mesh.rs)\n/// teaches you to access and modify the attributes of a [`Mesh`] after creating it.\n///\n/// ## Common points of confusion\n///\n/// - UV maps in Bevy start at the top-left, see [`ATTRIBUTE_UV_0`](Mesh::ATTRIBUTE_UV_0),\n///     other APIs can have other conventions, `OpenGL` starts at bottom-left.\n/// - It is possible and sometimes useful for multiple vertices to have the same\n///     [position attribute](Mesh::ATTRIBUTE_POSITION) value,\n///     it's a common technique in 3D modeling for complex UV mapping or other calculations.\n/// - Bevy performs frustum culling based on the `Aabb` of meshes, which is calculated\n///     and added automatically for new meshes only. If a mesh is modified, the entity's `Aabb`\n///     needs to be updated manually or deleted so that it is re-calculated.\n///\n/// ## Use with `StandardMaterial`\n///\n/// To render correctly with `StandardMaterial`, a mesh needs to have properly defined:\n/// - [`UVs`](Mesh::ATTRIBUTE_UV_0): Bevy needs to know how to map a texture onto the mesh\n///     (also true for `ColorMaterial`).\n/// - [`Normals`](Mesh::ATTRIBUTE_NORMAL): Bevy needs to know how light interacts with your mesh.\n///     [0.0, 0.0, 1.0] is very common for simple flat meshes on the XY plane,\n///     because simple meshes are smooth and they don't require complex light calculations.\n/// - Vertex winding order: by default, `StandardMaterial.cull_mode` is `Some(Face::Back)`,\n///     which means that Bevy would *only* render the \"front\" of each triangle, which\n///     is the side of the triangle from where the vertices appear in a *counter-clockwise* order.\n#[derive(Asset, Debug, Clone, Reflect)]\npub struct Mesh {\n    #[reflect(ignore)]\n    primitive_topology: PrimitiveTopology,\n    /// `std::collections::BTreeMap` with all defined vertex attributes (Positions, Normals, ...)\n    /// for this mesh. Attribute ids to attribute values.\n    /// Uses a [`BTreeMap`] because, unlike `HashMap`, it has a defined iteration order,\n    /// which allows easy stable `VertexBuffers` (i.e. same buffer order)\n    #[reflect(ignore)]\n    attributes: BTreeMap<MeshVertexAttributeId, MeshAttributeData>,\n    indices: Option<Indices>,\n    morph_targets: Option<Handle<Image>>,\n    morph_target_names: Option<Vec<String>>,\n    pub asset_usage: RenderAssetUsages,\n}\n\nimpl Mesh {\n    /// Where the vertex is located in space. Use in conjunction with [`Mesh::insert_attribute`]\n    /// or [`Mesh::with_inserted_attribute`].\n    ///\n    /// The format of this attribute is [`VertexFormat::Float32x3`].\n    pub const ATTRIBUTE_POSITION: MeshVertexAttribute =\n        MeshVertexAttribute::new(\"Vertex_Position\", 0, VertexFormat::Float32x3);\n\n    /// The direction the vertex normal is facing in.\n    /// Use in conjunction with [`Mesh::insert_attribute`] or [`Mesh::with_inserted_attribute`].\n    ///\n    /// The format of this attribute is [`VertexFormat::Float32x3`].\n    pub const ATTRIBUTE_NORMAL: MeshVertexAttribute =\n        MeshVertexAttribute::new(\"Vertex_Normal\", 1, VertexFormat::Float32x3);\n\n    /// Texture coordinates for the vertex. Use in conjunction with [`Mesh::insert_attribute`]\n    /// or [`Mesh::with_inserted_attribute`].\n    ///\n    /// Generally `[0.,0.]` is mapped to the top left of the texture, and `[1.,1.]` to the bottom-right.\n    ///\n    /// By default values outside will be clamped per pixel not for the vertex,\n    /// \"stretching\" the borders of the texture.\n    /// This behavior can be useful in some cases, usually when the borders have only\n    /// one color, for example a logo, and you want to \"extend\" those borders.\n    ///\n    /// For different mapping outside of `0..=1` range,\n    /// see [`ImageAddressMode`](bevy_image::ImageAddressMode).\n    ///\n    /// The format of this attribute is [`VertexFormat::Float32x2`].\n    pub const ATTRIBUTE_UV_0: MeshVertexAttribute =\n        MeshVertexAttribute::new(\"Vertex_Uv\", 2, VertexFormat::Float32x2);\n\n    /// Alternate texture coordinates for the vertex. Use in conjunction with\n    /// [`Mesh::insert_attribute`] or [`Mesh::with_inserted_attribute`].\n    ///\n    /// Typically, these are used for lightmaps, textures that provide\n    /// precomputed illumination.\n    ///\n    /// The format of this attribute is [`VertexFormat::Float32x2`].\n    pub const ATTRIBUTE_UV_1: MeshVertexAttribute =\n        MeshVertexAttribute::new(\"Vertex_Uv_1\", 3, VertexFormat::Float32x2);\n\n    /// The direction of the vertex tangent. Used for normal mapping.\n    /// Usually generated with [`generate_tangents`](Mesh::generate_tangents) or\n    /// [`with_generated_tangents`](Mesh::with_generated_tangents).\n    ///\n    /// The format of this attribute is [`VertexFormat::Float32x4`].\n    pub const ATTRIBUTE_TANGENT: MeshVertexAttribute =\n        MeshVertexAttribute::new(\"Vertex_Tangent\", 4, VertexFormat::Float32x4);\n\n    /// Per vertex coloring. Use in conjunction with [`Mesh::insert_attribute`]\n    /// or [`Mesh::with_inserted_attribute`].\n    ///\n    /// The format of this attribute is [`VertexFormat::Float32x4`].\n    pub const ATTRIBUTE_COLOR: MeshVertexAttribute =\n        MeshVertexAttribute::new(\"Vertex_Color\", 5, VertexFormat::Float32x4);\n\n    /// Per vertex joint transform matrix weight. Use in conjunction with [`Mesh::insert_attribute`]\n    /// or [`Mesh::with_inserted_attribute`].\n    ///\n    /// The format of this attribute is [`VertexFormat::Float32x4`].\n    pub const ATTRIBUTE_JOINT_WEIGHT: MeshVertexAttribute =\n        MeshVertexAttribute::new(\"Vertex_JointWeight\", 6, VertexFormat::Float32x4);\n\n    /// Per vertex joint transform matrix index. Use in conjunction with [`Mesh::insert_attribute`]\n    /// or [`Mesh::with_inserted_attribute`].\n    ///\n    /// The format of this attribute is [`VertexFormat::Uint16x4`].\n    pub const ATTRIBUTE_JOINT_INDEX: MeshVertexAttribute =\n        MeshVertexAttribute::new(\"Vertex_JointIndex\", 7, VertexFormat::Uint16x4);\n\n    /// Construct a new mesh. You need to provide a [`PrimitiveTopology`] so that the\n    /// renderer knows how to treat the vertex data. Most of the time this will be\n    /// [`PrimitiveTopology::TriangleList`].\n    pub fn new(primitive_topology: PrimitiveTopology, asset_usage: RenderAssetUsages) -> Self {\n        Mesh {\n            primitive_topology,\n            attributes: Default::default(),\n            indices: None,\n            morph_targets: None,\n            morph_target_names: None,\n            asset_usage,\n        }\n    }\n\n    /// Returns the topology of the mesh.\n    pub fn primitive_topology(&self) -> PrimitiveTopology {\n        self.primitive_topology\n    }\n\n    /// Sets the data for a vertex attribute (position, normal, etc.). The name will\n    /// often be one of the associated constants such as [`Mesh::ATTRIBUTE_POSITION`].\n    ///\n    /// `Aabb` of entities with modified mesh are not updated automatically.\n    ///\n    /// # Panics\n    /// Panics when the format of the values does not match the attribute's format.\n    #[inline]\n    pub fn insert_attribute(\n        &mut self,\n        attribute: MeshVertexAttribute,\n        values: impl Into<VertexAttributeValues>,\n    ) {\n        let values = values.into();\n        let values_format = VertexFormat::from(&values);\n        if values_format != attribute.format {\n            panic!(\n                \"Failed to insert attribute. Invalid attribute format for {}. Given format is {values_format:?} but expected {:?}\",\n                attribute.name, attribute.format\n            );\n        }\n\n        self.attributes\n            .insert(attribute.id, MeshAttributeData { attribute, values });\n    }\n\n    /// Consumes the mesh and returns a mesh with data set for a vertex attribute (position, normal, etc.).\n    /// The name will often be one of the associated constants such as [`Mesh::ATTRIBUTE_POSITION`].\n    ///\n    /// (Alternatively, you can use [`Mesh::insert_attribute`] to mutate an existing mesh in-place)\n    ///\n    /// `Aabb` of entities with modified mesh are not updated automatically.\n    ///\n    /// # Panics\n    /// Panics when the format of the values does not match the attribute's format.\n    #[must_use]\n    #[inline]\n    pub fn with_inserted_attribute(\n        mut self,\n        attribute: MeshVertexAttribute,\n        values: impl Into<VertexAttributeValues>,\n    ) -> Self {\n        self.insert_attribute(attribute, values);\n        self\n    }\n\n    /// Removes the data for a vertex attribute\n    pub fn remove_attribute(\n        &mut self,\n        attribute: impl Into<MeshVertexAttributeId>,\n    ) -> Option<VertexAttributeValues> {\n        self.attributes\n            .remove(&attribute.into())\n            .map(|data| data.values)\n    }\n\n    /// Consumes the mesh and returns a mesh without the data for a vertex attribute\n    ///\n    /// (Alternatively, you can use [`Mesh::remove_attribute`] to mutate an existing mesh in-place)\n    #[must_use]\n    pub fn with_removed_attribute(mut self, attribute: impl Into<MeshVertexAttributeId>) -> Self {\n        self.remove_attribute(attribute);\n        self\n    }\n\n    #[inline]\n    pub fn contains_attribute(&self, id: impl Into<MeshVertexAttributeId>) -> bool {\n        self.attributes.contains_key(&id.into())\n    }\n\n    /// Retrieves the data currently set to the vertex attribute with the specified `name`.\n    #[inline]\n    pub fn attribute(\n        &self,\n        id: impl Into<MeshVertexAttributeId>,\n    ) -> Option<&VertexAttributeValues> {\n        self.attributes.get(&id.into()).map(|data| &data.values)\n    }\n\n    /// Retrieves the data currently set to the vertex attribute with the specified `name` mutably.\n    #[inline]\n    pub fn attribute_mut(\n        &mut self,\n        id: impl Into<MeshVertexAttributeId>,\n    ) -> Option<&mut VertexAttributeValues> {\n        self.attributes\n            .get_mut(&id.into())\n            .map(|data| &mut data.values)\n    }\n\n    /// Returns an iterator that yields references to the data of each vertex attribute.\n    pub fn attributes(\n        &self,\n    ) -> impl Iterator<Item = (&MeshVertexAttribute, &VertexAttributeValues)> {\n        self.attributes\n            .values()\n            .map(|data| (&data.attribute, &data.values))\n    }\n\n    /// Returns an iterator that yields mutable references to the data of each vertex attribute.\n    pub fn attributes_mut(\n        &mut self,\n    ) -> impl Iterator<Item = (&MeshVertexAttribute, &mut VertexAttributeValues)> {\n        self.attributes\n            .values_mut()\n            .map(|data| (&data.attribute, &mut data.values))\n    }\n\n    /// Sets the vertex indices of the mesh. They describe how triangles are constructed out of the\n    /// vertex attributes and are therefore only useful for the [`PrimitiveTopology`] variants\n    /// that use triangles.\n    #[inline]\n    pub fn insert_indices(&mut self, indices: Indices) {\n        self.indices = Some(indices);\n    }\n\n    /// Consumes the mesh and returns a mesh with the given vertex indices. They describe how triangles\n    /// are constructed out of the vertex attributes and are therefore only useful for the\n    /// [`PrimitiveTopology`] variants that use triangles.\n    ///\n    /// (Alternatively, you can use [`Mesh::insert_indices`] to mutate an existing mesh in-place)\n    #[must_use]\n    #[inline]\n    pub fn with_inserted_indices(mut self, indices: Indices) -> Self {\n        self.insert_indices(indices);\n        self\n    }\n\n    /// Retrieves the vertex `indices` of the mesh.\n    #[inline]\n    pub fn indices(&self) -> Option<&Indices> {\n        self.indices.as_ref()\n    }\n\n    /// Retrieves the vertex `indices` of the mesh mutably.\n    #[inline]\n    pub fn indices_mut(&mut self) -> Option<&mut Indices> {\n        self.indices.as_mut()\n    }\n\n    /// Removes the vertex `indices` from the mesh and returns them.\n    #[inline]\n    pub fn remove_indices(&mut self) -> Option<Indices> {\n        core::mem::take(&mut self.indices)\n    }\n\n    /// Consumes the mesh and returns a mesh without the vertex `indices` of the mesh.\n    ///\n    /// (Alternatively, you can use [`Mesh::remove_indices`] to mutate an existing mesh in-place)\n    #[must_use]\n    pub fn with_removed_indices(mut self) -> Self {\n        self.remove_indices();\n        self\n    }\n\n    /// Returns the size of a vertex in bytes.\n    pub fn get_vertex_size(&self) -> u64 {\n        self.attributes\n            .values()\n            .map(|data| data.attribute.format.get_size())\n            .sum()\n    }\n\n    /// Returns the size required for the vertex buffer in bytes.\n    pub fn get_vertex_buffer_size(&self) -> usize {\n        let vertex_size = self.get_vertex_size() as usize;\n        let vertex_count = self.count_vertices();\n        vertex_count * vertex_size\n    }\n\n    /// Computes and returns the index data of the mesh as bytes.\n    /// This is used to transform the index data into a GPU friendly format.\n    pub fn get_index_buffer_bytes(&self) -> Option<&[u8]> {\n        self.indices.as_ref().map(|indices| match &indices {\n            Indices::U16(indices) => cast_slice(&indices[..]),\n            Indices::U32(indices) => cast_slice(&indices[..]),\n        })\n    }\n\n    /// Get this `Mesh`'s [`MeshVertexBufferLayout`], used in `SpecializedMeshPipeline`.\n    pub fn get_mesh_vertex_buffer_layout(\n        &self,\n        mesh_vertex_buffer_layouts: &mut MeshVertexBufferLayouts,\n    ) -> MeshVertexBufferLayoutRef {\n        let mut attributes = Vec::with_capacity(self.attributes.len());\n        let mut attribute_ids = Vec::with_capacity(self.attributes.len());\n        let mut accumulated_offset = 0;\n        for (index, data) in self.attributes.values().enumerate() {\n            attribute_ids.push(data.attribute.id);\n            attributes.push(VertexAttribute {\n                offset: accumulated_offset,\n                format: data.attribute.format,\n                shader_location: index as u32,\n            });\n            accumulated_offset += data.attribute.format.get_size();\n        }\n\n        let layout = MeshVertexBufferLayout {\n            layout: VertexBufferLayout {\n                array_stride: accumulated_offset,\n                step_mode: VertexStepMode::Vertex,\n                attributes,\n            },\n            attribute_ids,\n        };\n        mesh_vertex_buffer_layouts.insert(layout)\n    }\n\n    /// Counts all vertices of the mesh.\n    ///\n    /// If the attributes have different vertex counts, the smallest is returned.\n    pub fn count_vertices(&self) -> usize {\n        let mut vertex_count: Option<usize> = None;\n        for (attribute_id, attribute_data) in &self.attributes {\n            let attribute_len = attribute_data.values.len();\n            if let Some(previous_vertex_count) = vertex_count {\n                if previous_vertex_count != attribute_len {\n                    let name = self\n                        .attributes\n                        .get(attribute_id)\n                        .map(|data| data.attribute.name.to_string())\n                        .unwrap_or_else(|| format!(\"{attribute_id:?}\"));\n\n                    warn!(\"{name} has a different vertex count ({attribute_len}) than other attributes ({previous_vertex_count}) in this mesh, \\\n                        all attributes will be truncated to match the smallest.\");\n                    vertex_count = Some(core::cmp::min(previous_vertex_count, attribute_len));\n                }\n            } else {\n                vertex_count = Some(attribute_len);\n            }\n        }\n\n        vertex_count.unwrap_or(0)\n    }\n\n    /// Computes and returns the vertex data of the mesh as bytes.\n    /// Therefore the attributes are located in the order of their [`MeshVertexAttribute::id`].\n    /// This is used to transform the vertex data into a GPU friendly format.\n    ///\n    /// If the vertex attributes have different lengths, they are all truncated to\n    /// the length of the smallest.\n    ///\n    /// This is a convenience method which allocates a Vec.\n    /// Prefer pre-allocating and using [`Mesh::write_packed_vertex_buffer_data`] when possible.\n    pub fn create_packed_vertex_buffer_data(&self) -> Vec<u8> {\n        let mut attributes_interleaved_buffer = vec![0; self.get_vertex_buffer_size()];\n        self.write_packed_vertex_buffer_data(&mut attributes_interleaved_buffer);\n        attributes_interleaved_buffer\n    }\n\n    /// Computes and write the vertex data of the mesh into a mutable byte slice.\n    /// The attributes are located in the order of their [`MeshVertexAttribute::id`].\n    /// This is used to transform the vertex data into a GPU friendly format.\n    ///\n    /// If the vertex attributes have different lengths, they are all truncated to\n    /// the length of the smallest.\n    pub fn write_packed_vertex_buffer_data(&self, slice: &mut [u8]) {\n        let vertex_size = self.get_vertex_size() as usize;\n        let vertex_count = self.count_vertices();\n        // bundle into interleaved buffers\n        let mut attribute_offset = 0;\n        for attribute_data in self.attributes.values() {\n            let attribute_size = attribute_data.attribute.format.get_size() as usize;\n            let attributes_bytes = attribute_data.values.get_bytes();\n            for (vertex_index, attribute_bytes) in attributes_bytes\n                .chunks_exact(attribute_size)\n                .take(vertex_count)\n                .enumerate()\n            {\n                let offset = vertex_index * vertex_size + attribute_offset;\n                slice[offset..offset + attribute_size].copy_from_slice(attribute_bytes);\n            }\n\n            attribute_offset += attribute_size;\n        }\n    }\n\n    /// Duplicates the vertex attributes so that no vertices are shared.\n    ///\n    /// This can dramatically increase the vertex count, so make sure this is what you want.\n    /// Does nothing if no [Indices] are set.\n    #[allow(clippy::match_same_arms)]\n    pub fn duplicate_vertices(&mut self) {\n        fn duplicate<T: Copy>(values: &[T], indices: impl Iterator<Item = usize>) -> Vec<T> {\n            indices.map(|i| values[i]).collect()\n        }\n\n        let Some(indices) = self.indices.take() else {\n            return;\n        };\n\n        for attributes in self.attributes.values_mut() {\n            let indices = indices.iter();\n            match &mut attributes.values {\n                VertexAttributeValues::Float32(vec) => *vec = duplicate(vec, indices),\n                VertexAttributeValues::Sint32(vec) => *vec = duplicate(vec, indices),\n                VertexAttributeValues::Uint32(vec) => *vec = duplicate(vec, indices),\n                VertexAttributeValues::Float32x2(vec) => *vec = duplicate(vec, indices),\n                VertexAttributeValues::Sint32x2(vec) => *vec = duplicate(vec, indices),\n                VertexAttributeValues::Uint32x2(vec) => *vec = duplicate(vec, indices),\n                VertexAttributeValues::Float32x3(vec) => *vec = duplicate(vec, indices),\n                VertexAttributeValues::Sint32x3(vec) => *vec = duplicate(vec, indices),\n                VertexAttributeValues::Uint32x3(vec) => *vec = duplicate(vec, indices),\n                VertexAttributeValues::Sint32x4(vec) => *vec = duplicate(vec, indices),\n                VertexAttributeValues::Uint32x4(vec) => *vec = duplicate(vec, indices),\n                VertexAttributeValues::Float32x4(vec) => *vec = duplicate(vec, indices),\n                VertexAttributeValues::Sint16x2(vec) => *vec = duplicate(vec, indices),\n                VertexAttributeValues::Snorm16x2(vec) => *vec = duplicate(vec, indices),\n                VertexAttributeValues::Uint16x2(vec) => *vec = duplicate(vec, indices),\n                VertexAttributeValues::Unorm16x2(vec) => *vec = duplicate(vec, indices),\n                VertexAttributeValues::Sint16x4(vec) => *vec = duplicate(vec, indices),\n                VertexAttributeValues::Snorm16x4(vec) => *vec = duplicate(vec, indices),\n                VertexAttributeValues::Uint16x4(vec) => *vec = duplicate(vec, indices),\n                VertexAttributeValues::Unorm16x4(vec) => *vec = duplicate(vec, indices),\n                VertexAttributeValues::Sint8x2(vec) => *vec = duplicate(vec, indices),\n                VertexAttributeValues::Snorm8x2(vec) => *vec = duplicate(vec, indices),\n                VertexAttributeValues::Uint8x2(vec) => *vec = duplicate(vec, indices),\n                VertexAttributeValues::Unorm8x2(vec) => *vec = duplicate(vec, indices),\n                VertexAttributeValues::Sint8x4(vec) => *vec = duplicate(vec, indices),\n                VertexAttributeValues::Snorm8x4(vec) => *vec = duplicate(vec, indices),\n                VertexAttributeValues::Uint8x4(vec) => *vec = duplicate(vec, indices),\n                VertexAttributeValues::Unorm8x4(vec) => *vec = duplicate(vec, indices),\n            }\n        }\n    }\n\n    /// Consumes the mesh and returns a mesh with no shared vertices.\n    ///\n    /// This can dramatically increase the vertex count, so make sure this is what you want.\n    /// Does nothing if no [`Indices`] are set.\n    ///\n    /// (Alternatively, you can use [`Mesh::duplicate_vertices`] to mutate an existing mesh in-place)\n    #[must_use]\n    pub fn with_duplicated_vertices(mut self) -> Self {\n        self.duplicate_vertices();\n        self\n    }\n\n    /// Inverts the winding of the indices such that all counter-clockwise triangles are now\n    /// clockwise and vice versa.\n    /// For lines, their start and end indices are flipped.\n    ///\n    /// Does nothing if no [`Indices`] are set.\n    /// If this operation succeeded, an [`Ok`] result is returned.\n    pub fn invert_winding(&mut self) -> Result<(), MeshWindingInvertError> {\n        fn invert<I>(\n            indices: &mut [I],\n            topology: PrimitiveTopology,\n        ) -> Result<(), MeshWindingInvertError> {\n            match topology {\n                PrimitiveTopology::TriangleList => {\n                    // Early return if the index count doesn't match\n                    if indices.len() % 3 != 0 {\n                        return Err(MeshWindingInvertError::AbruptIndicesEnd);\n                    }\n                    for chunk in indices.chunks_mut(3) {\n                        // This currently can only be optimized away with unsafe, rework this when `feature(slice_as_chunks)` gets stable.\n                        let [_, b, c] = chunk else {\n                            return Err(MeshWindingInvertError::AbruptIndicesEnd);\n                        };\n                        core::mem::swap(b, c);\n                    }\n                    Ok(())\n                }\n                PrimitiveTopology::LineList => {\n                    // Early return if the index count doesn't match\n                    if indices.len() % 2 != 0 {\n                        return Err(MeshWindingInvertError::AbruptIndicesEnd);\n                    }\n                    indices.reverse();\n                    Ok(())\n                }\n                PrimitiveTopology::TriangleStrip | PrimitiveTopology::LineStrip => {\n                    indices.reverse();\n                    Ok(())\n                }\n                _ => Err(MeshWindingInvertError::WrongTopology),\n            }\n        }\n        match &mut self.indices {\n            Some(Indices::U16(vec)) => invert(vec, self.primitive_topology),\n            Some(Indices::U32(vec)) => invert(vec, self.primitive_topology),\n            None => Ok(()),\n        }\n    }\n\n    /// Consumes the mesh and returns a mesh with inverted winding of the indices such\n    /// that all counter-clockwise triangles are now clockwise and vice versa.\n    ///\n    /// Does nothing if no [`Indices`] are set.\n    pub fn with_inverted_winding(mut self) -> Result<Self, MeshWindingInvertError> {\n        self.invert_winding().map(|_| self)\n    }\n\n    /// Calculates the [`Mesh::ATTRIBUTE_NORMAL`] of a mesh.\n    /// If the mesh is indexed, this defaults to smooth normals. Otherwise, it defaults to flat\n    /// normals.\n    ///\n    /// # Panics\n    /// Panics if [`Mesh::ATTRIBUTE_POSITION`] is not of type `float3`.\n    /// Panics if the mesh has any other topology than [`PrimitiveTopology::TriangleList`].\n    ///\n    /// FIXME: This should handle more cases since this is called as a part of gltf\n    /// mesh loading where we can't really blame users for loading meshes that might\n    /// not conform to the limitations here!\n    pub fn compute_normals(&mut self) {\n        assert!(\n            matches!(self.primitive_topology, PrimitiveTopology::TriangleList),\n            \"`compute_normals` can only work on `TriangleList`s\"\n        );\n        if self.indices().is_none() {\n            self.compute_flat_normals();\n        } else {\n            self.compute_smooth_normals();\n        }\n    }\n\n    /// Calculates the [`Mesh::ATTRIBUTE_NORMAL`] of a mesh.\n    ///\n    /// # Panics\n    /// Panics if [`Indices`] are set or [`Mesh::ATTRIBUTE_POSITION`] is not of type `float3`.\n    /// Panics if the mesh has any other topology than [`PrimitiveTopology::TriangleList`].\n    /// Consider calling [`Mesh::duplicate_vertices`] or exporting your mesh with normal\n    /// attributes.\n    ///\n    /// FIXME: This should handle more cases since this is called as a part of gltf\n    /// mesh loading where we can't really blame users for loading meshes that might\n    /// not conform to the limitations here!\n    pub fn compute_flat_normals(&mut self) {\n        assert!(\n            self.indices().is_none(),\n            \"`compute_flat_normals` can't work on indexed geometry. Consider calling either `Mesh::compute_smooth_normals` or `Mesh::duplicate_vertices` followed by `Mesh::compute_flat_normals`.\"\n        );\n        assert!(\n            matches!(self.primitive_topology, PrimitiveTopology::TriangleList),\n            \"`compute_flat_normals` can only work on `TriangleList`s\"\n        );\n\n        let positions = self\n            .attribute(Mesh::ATTRIBUTE_POSITION)\n            .unwrap()\n            .as_float3()\n            .expect(\"`Mesh::ATTRIBUTE_POSITION` vertex attributes should be of type `float3`\");\n\n        let normals: Vec<_> = positions\n            .chunks_exact(3)\n            .map(|p| face_normal(p[0], p[1], p[2]))\n            .flat_map(|normal| [normal; 3])\n            .collect();\n\n        self.insert_attribute(Mesh::ATTRIBUTE_NORMAL, normals);\n    }\n\n    /// Calculates the [`Mesh::ATTRIBUTE_NORMAL`] of an indexed mesh, smoothing normals for shared\n    /// vertices.\n    ///\n    /// # Panics\n    /// Panics if [`Mesh::ATTRIBUTE_POSITION`] is not of type `float3`.\n    /// Panics if the mesh has any other topology than [`PrimitiveTopology::TriangleList`].\n    /// Panics if the mesh does not have indices defined.\n    ///\n    /// FIXME: This should handle more cases since this is called as a part of gltf\n    /// mesh loading where we can't really blame users for loading meshes that might\n    /// not conform to the limitations here!\n    pub fn compute_smooth_normals(&mut self) {\n        assert!(\n            matches!(self.primitive_topology, PrimitiveTopology::TriangleList),\n            \"`compute_smooth_normals` can only work on `TriangleList`s\"\n        );\n        assert!(\n            self.indices().is_some(),\n            \"`compute_smooth_normals` can only work on indexed meshes\"\n        );\n\n        let positions = self\n            .attribute(Mesh::ATTRIBUTE_POSITION)\n            .unwrap()\n            .as_float3()\n            .expect(\"`Mesh::ATTRIBUTE_POSITION` vertex attributes should be of type `float3`\");\n\n        let mut normals = vec![Vec3::ZERO; positions.len()];\n\n        self.indices()\n            .unwrap()\n            .iter()\n            .collect::<Vec<usize>>()\n            .chunks_exact(3)\n            .for_each(|face| {\n                let [a, b, c] = [face[0], face[1], face[2]];\n                let normal = Vec3::from(face_area_normal(positions[a], positions[b], positions[c]));\n                [a, b, c].iter().for_each(|pos| {\n                    normals[*pos] += normal;\n                });\n            });\n\n        // average (smooth) normals for shared vertices...\n        // TODO: support different methods of weighting the average\n        for normal in &mut normals {\n            *normal = normal.try_normalize().unwrap_or(Vec3::ZERO);\n        }\n\n        self.insert_attribute(Mesh::ATTRIBUTE_NORMAL, normals);\n    }\n\n    /// Consumes the mesh and returns a mesh with calculated [`Mesh::ATTRIBUTE_NORMAL`].\n    /// If the mesh is indexed, this defaults to smooth normals. Otherwise, it defaults to flat\n    /// normals.\n    ///\n    /// (Alternatively, you can use [`Mesh::compute_normals`] to mutate an existing mesh in-place)\n    ///\n    /// # Panics\n    /// Panics if [`Mesh::ATTRIBUTE_POSITION`] is not of type `float3`.\n    /// Panics if the mesh has any other topology than [`PrimitiveTopology::TriangleList`].\n    #[must_use]\n    pub fn with_computed_normals(mut self) -> Self {\n        self.compute_normals();\n        self\n    }\n\n    /// Consumes the mesh and returns a mesh with calculated [`Mesh::ATTRIBUTE_NORMAL`].\n    ///\n    /// (Alternatively, you can use [`Mesh::compute_flat_normals`] to mutate an existing mesh in-place)\n    ///\n    /// # Panics\n    /// Panics if [`Mesh::ATTRIBUTE_POSITION`] is not of type `float3`.\n    /// Panics if the mesh has any other topology than [`PrimitiveTopology::TriangleList`].\n    /// Panics if the mesh has indices defined\n    #[must_use]\n    pub fn with_computed_flat_normals(mut self) -> Self {\n        self.compute_flat_normals();\n        self\n    }\n\n    /// Consumes the mesh and returns a mesh with calculated [`Mesh::ATTRIBUTE_NORMAL`].\n    ///\n    /// (Alternatively, you can use [`Mesh::compute_smooth_normals`] to mutate an existing mesh in-place)\n    ///\n    /// # Panics\n    /// Panics if [`Mesh::ATTRIBUTE_POSITION`] is not of type `float3`.\n    /// Panics if the mesh has any other topology than [`PrimitiveTopology::TriangleList`].\n    /// Panics if the mesh does not have indices defined.\n    #[must_use]\n    pub fn with_computed_smooth_normals(mut self) -> Self {\n        self.compute_smooth_normals();\n        self\n    }\n\n    /// Generate tangents for the mesh using the `mikktspace` algorithm.\n    ///\n    /// Sets the [`Mesh::ATTRIBUTE_TANGENT`] attribute if successful.\n    /// Requires a [`PrimitiveTopology::TriangleList`] topology and the [`Mesh::ATTRIBUTE_POSITION`], [`Mesh::ATTRIBUTE_NORMAL`] and [`Mesh::ATTRIBUTE_UV_0`] attributes set.\n    pub fn generate_tangents(&mut self) -> Result<(), GenerateTangentsError> {\n        let tangents = generate_tangents_for_mesh(self)?;\n        self.insert_attribute(Mesh::ATTRIBUTE_TANGENT, tangents);\n        Ok(())\n    }\n\n    /// Consumes the mesh and returns a mesh with tangents generated using the `mikktspace` algorithm.\n    ///\n    /// The resulting mesh will have the [`Mesh::ATTRIBUTE_TANGENT`] attribute if successful.\n    ///\n    /// (Alternatively, you can use [`Mesh::generate_tangents`] to mutate an existing mesh in-place)\n    ///\n    /// Requires a [`PrimitiveTopology::TriangleList`] topology and the [`Mesh::ATTRIBUTE_POSITION`], [`Mesh::ATTRIBUTE_NORMAL`] and [`Mesh::ATTRIBUTE_UV_0`] attributes set.\n    pub fn with_generated_tangents(mut self) -> Result<Mesh, GenerateTangentsError> {\n        self.generate_tangents()?;\n        Ok(self)\n    }\n\n    /// Merges the [`Mesh`] data of `other` with `self`. The attributes and indices of `other` will be appended to `self`.\n    ///\n    /// Note that attributes of `other` that don't exist on `self` will be ignored.\n    ///\n    /// `Aabb` of entities with modified mesh are not updated automatically.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the vertex attribute values of `other` are incompatible with `self`.\n    /// For example, [`VertexAttributeValues::Float32`] is incompatible with [`VertexAttributeValues::Float32x3`].\n    #[allow(clippy::match_same_arms)]\n    pub fn merge(&mut self, other: &Mesh) {\n        use VertexAttributeValues::*;\n\n        // The indices of `other` should start after the last vertex of `self`.\n        let index_offset = self.count_vertices();\n\n        // Extend attributes of `self` with attributes of `other`.\n        for (attribute, values) in self.attributes_mut() {\n            let enum_variant_name = values.enum_variant_name();\n            if let Some(other_values) = other.attribute(attribute.id) {\n                match (values, other_values) {\n                    (Float32(vec1), Float32(vec2)) => vec1.extend(vec2),\n                    (Sint32(vec1), Sint32(vec2)) => vec1.extend(vec2),\n                    (Uint32(vec1), Uint32(vec2)) => vec1.extend(vec2),\n                    (Float32x2(vec1), Float32x2(vec2)) => vec1.extend(vec2),\n                    (Sint32x2(vec1), Sint32x2(vec2)) => vec1.extend(vec2),\n                    (Uint32x2(vec1), Uint32x2(vec2)) => vec1.extend(vec2),\n                    (Float32x3(vec1), Float32x3(vec2)) => vec1.extend(vec2),\n                    (Sint32x3(vec1), Sint32x3(vec2)) => vec1.extend(vec2),\n                    (Uint32x3(vec1), Uint32x3(vec2)) => vec1.extend(vec2),\n                    (Sint32x4(vec1), Sint32x4(vec2)) => vec1.extend(vec2),\n                    (Uint32x4(vec1), Uint32x4(vec2)) => vec1.extend(vec2),\n                    (Float32x4(vec1), Float32x4(vec2)) => vec1.extend(vec2),\n                    (Sint16x2(vec1), Sint16x2(vec2)) => vec1.extend(vec2),\n                    (Snorm16x2(vec1), Snorm16x2(vec2)) => vec1.extend(vec2),\n                    (Uint16x2(vec1), Uint16x2(vec2)) => vec1.extend(vec2),\n                    (Unorm16x2(vec1), Unorm16x2(vec2)) => vec1.extend(vec2),\n                    (Sint16x4(vec1), Sint16x4(vec2)) => vec1.extend(vec2),\n                    (Snorm16x4(vec1), Snorm16x4(vec2)) => vec1.extend(vec2),\n                    (Uint16x4(vec1), Uint16x4(vec2)) => vec1.extend(vec2),\n                    (Unorm16x4(vec1), Unorm16x4(vec2)) => vec1.extend(vec2),\n                    (Sint8x2(vec1), Sint8x2(vec2)) => vec1.extend(vec2),\n                    (Snorm8x2(vec1), Snorm8x2(vec2)) => vec1.extend(vec2),\n                    (Uint8x2(vec1), Uint8x2(vec2)) => vec1.extend(vec2),\n                    (Unorm8x2(vec1), Unorm8x2(vec2)) => vec1.extend(vec2),\n                    (Sint8x4(vec1), Sint8x4(vec2)) => vec1.extend(vec2),\n                    (Snorm8x4(vec1), Snorm8x4(vec2)) => vec1.extend(vec2),\n                    (Uint8x4(vec1), Uint8x4(vec2)) => vec1.extend(vec2),\n                    (Unorm8x4(vec1), Unorm8x4(vec2)) => vec1.extend(vec2),\n                    _ => panic!(\n                        \"Incompatible vertex attribute types {} and {}\",\n                        enum_variant_name,\n                        other_values.enum_variant_name()\n                    ),\n                }\n            }\n        }\n\n        // Extend indices of `self` with indices of `other`.\n        if let (Some(indices), Some(other_indices)) = (self.indices_mut(), other.indices()) {\n            indices.extend(other_indices.iter().map(|i| (i + index_offset) as u32));\n        }\n    }\n\n    /// Transforms the vertex positions, normals, and tangents of the mesh by the given [`Transform`].\n    ///\n    /// `Aabb` of entities with modified mesh are not updated automatically.\n    pub fn transformed_by(mut self, transform: Transform) -> Self {\n        self.transform_by(transform);\n        self\n    }\n\n    /// Transforms the vertex positions, normals, and tangents of the mesh in place by the given [`Transform`].\n    ///\n    /// `Aabb` of entities with modified mesh are not updated automatically.\n    pub fn transform_by(&mut self, transform: Transform) {\n        // Needed when transforming normals and tangents\n        let scale_recip = 1. / transform.scale;\n        debug_assert!(\n            transform.scale.yzx() * transform.scale.zxy() != Vec3::ZERO,\n            \"mesh transform scale cannot be zero on more than one axis\"\n        );\n\n        if let Some(VertexAttributeValues::Float32x3(ref mut positions)) =\n            self.attribute_mut(Mesh::ATTRIBUTE_POSITION)\n        {\n            // Apply scale, rotation, and translation to vertex positions\n            positions\n                .iter_mut()\n                .for_each(|pos| *pos = transform.transform_point(Vec3::from_slice(pos)).to_array());\n        }\n\n        // No need to transform normals or tangents if rotation is near identity and scale is uniform\n        if transform.rotation.is_near_identity()\n            && transform.scale.x == transform.scale.y\n            && transform.scale.y == transform.scale.z\n        {\n            return;\n        }\n\n        if let Some(VertexAttributeValues::Float32x3(ref mut normals)) =\n            self.attribute_mut(Mesh::ATTRIBUTE_NORMAL)\n        {\n            // Transform normals, taking into account non-uniform scaling and rotation\n            normals.iter_mut().for_each(|normal| {\n                *normal = (transform.rotation\n                    * scale_normal(Vec3::from_array(*normal), scale_recip))\n                .to_array();\n            });\n        }\n\n        if let Some(VertexAttributeValues::Float32x3(ref mut tangents)) =\n            self.attribute_mut(Mesh::ATTRIBUTE_TANGENT)\n        {\n            // Transform tangents, taking into account non-uniform scaling and rotation\n            tangents.iter_mut().for_each(|tangent| {\n                let scaled_tangent = Vec3::from_slice(tangent) * transform.scale;\n                *tangent = (transform.rotation * scaled_tangent.normalize_or_zero()).to_array();\n            });\n        }\n    }\n\n    /// Translates the vertex positions of the mesh by the given [`Vec3`].\n    ///\n    /// `Aabb` of entities with modified mesh are not updated automatically.\n    pub fn translated_by(mut self, translation: Vec3) -> Self {\n        self.translate_by(translation);\n        self\n    }\n\n    /// Translates the vertex positions of the mesh in place by the given [`Vec3`].\n    ///\n    /// `Aabb` of entities with modified mesh are not updated automatically.\n    pub fn translate_by(&mut self, translation: Vec3) {\n        if translation == Vec3::ZERO {\n            return;\n        }\n\n        if let Some(VertexAttributeValues::Float32x3(ref mut positions)) =\n            self.attribute_mut(Mesh::ATTRIBUTE_POSITION)\n        {\n            // Apply translation to vertex positions\n            positions\n                .iter_mut()\n                .for_each(|pos| *pos = (Vec3::from_slice(pos) + translation).to_array());\n        }\n    }\n\n    /// Rotates the vertex positions, normals, and tangents of the mesh by the given [`Quat`].\n    ///\n    /// `Aabb` of entities with modified mesh are not updated automatically.\n    pub fn rotated_by(mut self, rotation: Quat) -> Self {\n        self.rotate_by(rotation);\n        self\n    }\n\n    /// Rotates the vertex positions, normals, and tangents of the mesh in place by the given [`Quat`].\n    ///\n    /// `Aabb` of entities with modified mesh are not updated automatically.\n    pub fn rotate_by(&mut self, rotation: Quat) {\n        if let Some(VertexAttributeValues::Float32x3(ref mut positions)) =\n            self.attribute_mut(Mesh::ATTRIBUTE_POSITION)\n        {\n            // Apply rotation to vertex positions\n            positions\n                .iter_mut()\n                .for_each(|pos| *pos = (rotation * Vec3::from_slice(pos)).to_array());\n        }\n\n        // No need to transform normals or tangents if rotation is near identity\n        if rotation.is_near_identity() {\n            return;\n        }\n\n        if let Some(VertexAttributeValues::Float32x3(ref mut normals)) =\n            self.attribute_mut(Mesh::ATTRIBUTE_NORMAL)\n        {\n            // Transform normals\n            normals.iter_mut().for_each(|normal| {\n                *normal = (rotation * Vec3::from_slice(normal).normalize_or_zero()).to_array();\n            });\n        }\n\n        if let Some(VertexAttributeValues::Float32x3(ref mut tangents)) =\n            self.attribute_mut(Mesh::ATTRIBUTE_TANGENT)\n        {\n            // Transform tangents\n            tangents.iter_mut().for_each(|tangent| {\n                *tangent = (rotation * Vec3::from_slice(tangent).normalize_or_zero()).to_array();\n            });\n        }\n    }\n\n    /// Scales the vertex positions, normals, and tangents of the mesh by the given [`Vec3`].\n    ///\n    /// `Aabb` of entities with modified mesh are not updated automatically.\n    pub fn scaled_by(mut self, scale: Vec3) -> Self {\n        self.scale_by(scale);\n        self\n    }\n\n    /// Scales the vertex positions, normals, and tangents of the mesh in place by the given [`Vec3`].\n    ///\n    /// `Aabb` of entities with modified mesh are not updated automatically.\n    pub fn scale_by(&mut self, scale: Vec3) {\n        // Needed when transforming normals and tangents\n        let scale_recip = 1. / scale;\n        debug_assert!(\n            scale.yzx() * scale.zxy() != Vec3::ZERO,\n            \"mesh transform scale cannot be zero on more than one axis\"\n        );\n\n        if let Some(VertexAttributeValues::Float32x3(ref mut positions)) =\n            self.attribute_mut(Mesh::ATTRIBUTE_POSITION)\n        {\n            // Apply scale to vertex positions\n            positions\n                .iter_mut()\n                .for_each(|pos| *pos = (scale * Vec3::from_slice(pos)).to_array());\n        }\n\n        // No need to transform normals or tangents if scale is uniform\n        if scale.x == scale.y && scale.y == scale.z {\n            return;\n        }\n\n        if let Some(VertexAttributeValues::Float32x3(ref mut normals)) =\n            self.attribute_mut(Mesh::ATTRIBUTE_NORMAL)\n        {\n            // Transform normals, taking into account non-uniform scaling\n            normals.iter_mut().for_each(|normal| {\n                *normal = scale_normal(Vec3::from_array(*normal), scale_recip).to_array();\n            });\n        }\n\n        if let Some(VertexAttributeValues::Float32x3(ref mut tangents)) =\n            self.attribute_mut(Mesh::ATTRIBUTE_TANGENT)\n        {\n            // Transform tangents, taking into account non-uniform scaling\n            tangents.iter_mut().for_each(|tangent| {\n                let scaled_tangent = Vec3::from_slice(tangent) * scale;\n                *tangent = scaled_tangent.normalize_or_zero().to_array();\n            });\n        }\n    }\n\n    /// Whether this mesh has morph targets.\n    pub fn has_morph_targets(&self) -> bool {\n        self.morph_targets.is_some()\n    }\n\n    /// Set [morph targets] image for this mesh. This requires a \"morph target image\". See [`MorphTargetImage`](crate::morph::MorphTargetImage) for info.\n    ///\n    /// [morph targets]: https://en.wikipedia.org/wiki/Morph_target_animation\n    pub fn set_morph_targets(&mut self, morph_targets: Handle<Image>) {\n        self.morph_targets = Some(morph_targets);\n    }\n\n    pub fn morph_targets(&self) -> Option<&Handle<Image>> {\n        self.morph_targets.as_ref()\n    }\n\n    /// Consumes the mesh and returns a mesh with the given [morph targets].\n    ///\n    /// This requires a \"morph target image\". See [`MorphTargetImage`](crate::morph::MorphTargetImage) for info.\n    ///\n    /// (Alternatively, you can use [`Mesh::set_morph_targets`] to mutate an existing mesh in-place)\n    ///\n    /// [morph targets]: https://en.wikipedia.org/wiki/Morph_target_animation\n    #[must_use]\n    pub fn with_morph_targets(mut self, morph_targets: Handle<Image>) -> Self {\n        self.set_morph_targets(morph_targets);\n        self\n    }\n\n    /// Sets the names of each morph target. This should correspond to the order of the morph targets in `set_morph_targets`.\n    pub fn set_morph_target_names(&mut self, names: Vec<String>) {\n        self.morph_target_names = Some(names);\n    }\n\n    /// Consumes the mesh and returns a mesh with morph target names.\n    /// Names should correspond to the order of the morph targets in `set_morph_targets`.\n    ///\n    /// (Alternatively, you can use [`Mesh::set_morph_target_names`] to mutate an existing mesh in-place)\n    #[must_use]\n    pub fn with_morph_target_names(mut self, names: Vec<String>) -> Self {\n        self.set_morph_target_names(names);\n        self\n    }\n\n    /// Gets a list of all morph target names, if they exist.\n    pub fn morph_target_names(&self) -> Option<&[String]> {\n        self.morph_target_names.as_deref()\n    }\n\n    /// Normalize joint weights so they sum to 1.\n    pub fn normalize_joint_weights(&mut self) {\n        if let Some(joints) = self.attribute_mut(Self::ATTRIBUTE_JOINT_WEIGHT) {\n            let VertexAttributeValues::Float32x4(ref mut joints) = joints else {\n                panic!(\"unexpected joint weight format\");\n            };\n\n            for weights in joints.iter_mut() {\n                // force negative weights to zero\n                weights.iter_mut().for_each(|w| *w = w.max(0.0));\n\n                let sum: f32 = weights.iter().sum();\n                if sum == 0.0 {\n                    // all-zero weights are invalid\n                    weights[0] = 1.0;\n                } else {\n                    let recip = sum.recip();\n                    for weight in weights.iter_mut() {\n                        *weight *= recip;\n                    }\n                }\n            }\n        }\n    }\n\n    /// Get a list of this Mesh's [triangles] as an iterator if possible.\n    ///\n    /// Returns an error if any of the following conditions are met (see [`MeshTrianglesError`]):\n    /// * The Mesh's [primitive topology] is not `TriangleList` or `TriangleStrip`.\n    /// * The Mesh is missing position or index data.\n    /// * The Mesh's position data has the wrong format (not `Float32x3`).\n    ///\n    /// [primitive topology]: PrimitiveTopology\n    /// [triangles]: Triangle3d\n    pub fn triangles(&self) -> Result<impl Iterator<Item = Triangle3d> + '_, MeshTrianglesError> {\n        let Some(position_data) = self.attribute(Mesh::ATTRIBUTE_POSITION) else {\n            return Err(MeshTrianglesError::MissingPositions);\n        };\n\n        let Some(vertices) = position_data.as_float3() else {\n            return Err(MeshTrianglesError::PositionsFormat);\n        };\n\n        let Some(indices) = self.indices() else {\n            return Err(MeshTrianglesError::MissingIndices);\n        };\n\n        match self.primitive_topology {\n            PrimitiveTopology::TriangleList => {\n                // When indices reference out-of-bounds vertex data, the triangle is omitted.\n                // This implicitly truncates the indices to a multiple of 3.\n                let iterator = match indices {\n                    Indices::U16(vec) => FourIterators::First(\n                        vec.as_slice()\n                            .chunks_exact(3)\n                            .flat_map(move |indices| indices_to_triangle(vertices, indices)),\n                    ),\n                    Indices::U32(vec) => FourIterators::Second(\n                        vec.as_slice()\n                            .chunks_exact(3)\n                            .flat_map(move |indices| indices_to_triangle(vertices, indices)),\n                    ),\n                };\n\n                return Ok(iterator);\n            }\n\n            PrimitiveTopology::TriangleStrip => {\n                // When indices reference out-of-bounds vertex data, the triangle is omitted.\n                // If there aren't enough indices to make a triangle, then an empty vector will be\n                // returned.\n                let iterator = match indices {\n                    Indices::U16(vec) => {\n                        FourIterators::Third(vec.as_slice().windows(3).enumerate().flat_map(\n                            move |(i, indices)| {\n                                if i % 2 == 0 {\n                                    indices_to_triangle(vertices, indices)\n                                } else {\n                                    indices_to_triangle(\n                                        vertices,\n                                        &[indices[1], indices[0], indices[2]],\n                                    )\n                                }\n                            },\n                        ))\n                    }\n                    Indices::U32(vec) => {\n                        FourIterators::Fourth(vec.as_slice().windows(3).enumerate().flat_map(\n                            move |(i, indices)| {\n                                if i % 2 == 0 {\n                                    indices_to_triangle(vertices, indices)\n                                } else {\n                                    indices_to_triangle(\n                                        vertices,\n                                        &[indices[1], indices[0], indices[2]],\n                                    )\n                                }\n                            },\n                        ))\n                    }\n                };\n\n                return Ok(iterator);\n            }\n\n            _ => {\n                return Err(MeshTrianglesError::WrongTopology);\n            }\n        };\n\n        fn indices_to_triangle<T: TryInto<usize> + Copy>(\n            vertices: &[[f32; 3]],\n            indices: &[T],\n        ) -> Option<Triangle3d> {\n            let vert0: Vec3 = Vec3::from(*vertices.get(indices[0].try_into().ok()?)?);\n            let vert1: Vec3 = Vec3::from(*vertices.get(indices[1].try_into().ok()?)?);\n            let vert2: Vec3 = Vec3::from(*vertices.get(indices[2].try_into().ok()?)?);\n            Some(Triangle3d {\n                vertices: [vert0, vert1, vert2],\n            })\n        }\n    }\n}\n\nimpl core::ops::Mul<Mesh> for Transform {\n    type Output = Mesh;\n\n    fn mul(self, rhs: Mesh) -> Self::Output {\n        rhs.transformed_by(self)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::Mesh;\n    use crate::mesh::{Indices, MeshWindingInvertError, VertexAttributeValues};\n    use crate::PrimitiveTopology;\n    use bevy_asset::RenderAssetUsages;\n    use bevy_math::primitives::Triangle3d;\n    use bevy_math::Vec3;\n    use bevy_transform::components::Transform;\n\n    #[test]\n    #[should_panic]\n    fn panic_invalid_format() {\n        let _mesh = Mesh::new(\n            PrimitiveTopology::TriangleList,\n            RenderAssetUsages::default(),\n        )\n        .with_inserted_attribute(Mesh::ATTRIBUTE_UV_0, vec![[0.0, 0.0, 0.0]]);\n    }\n\n    #[test]\n    fn transform_mesh() {\n        let mesh = Mesh::new(\n            PrimitiveTopology::TriangleList,\n            RenderAssetUsages::default(),\n        )\n        .with_inserted_attribute(\n            Mesh::ATTRIBUTE_POSITION,\n            vec![[-1., -1., 2.], [1., -1., 2.], [0., 1., 2.]],\n        )\n        .with_inserted_attribute(\n            Mesh::ATTRIBUTE_NORMAL,\n            vec![\n                Vec3::new(-1., -1., 1.).normalize().to_array(),\n                Vec3::new(1., -1., 1.).normalize().to_array(),\n                [0., 0., 1.],\n            ],\n        )\n        .with_inserted_attribute(Mesh::ATTRIBUTE_UV_0, vec![[0., 0.], [1., 0.], [0.5, 1.]]);\n\n        let mesh = mesh.transformed_by(\n            Transform::from_translation(Vec3::splat(-2.)).with_scale(Vec3::new(2., 0., -1.)),\n        );\n\n        if let Some(VertexAttributeValues::Float32x3(positions)) =\n            mesh.attribute(Mesh::ATTRIBUTE_POSITION)\n        {\n            // All positions are first scaled resulting in `vec![[-2, 0., -2.], [2., 0., -2.], [0., 0., -2.]]`\n            // and then shifted by `-2.` along each axis\n            assert_eq!(\n                positions,\n                &vec![[-4.0, -2.0, -4.0], [0.0, -2.0, -4.0], [-2.0, -2.0, -4.0]]\n            );\n        } else {\n            panic!(\"Mesh does not have a position attribute\");\n        }\n\n        if let Some(VertexAttributeValues::Float32x3(normals)) =\n            mesh.attribute(Mesh::ATTRIBUTE_NORMAL)\n        {\n            assert_eq!(normals, &vec![[0., -1., 0.], [0., -1., 0.], [0., 0., -1.]]);\n        } else {\n            panic!(\"Mesh does not have a normal attribute\");\n        }\n\n        if let Some(VertexAttributeValues::Float32x2(uvs)) = mesh.attribute(Mesh::ATTRIBUTE_UV_0) {\n            assert_eq!(uvs, &vec![[0., 0.], [1., 0.], [0.5, 1.]]);\n        } else {\n            panic!(\"Mesh does not have a uv attribute\");\n        }\n    }\n\n    #[test]\n    fn point_list_mesh_invert_winding() {\n        let mesh = Mesh::new(PrimitiveTopology::PointList, RenderAssetUsages::default())\n            .with_inserted_indices(Indices::U32(vec![]));\n        assert!(matches!(\n            mesh.with_inverted_winding(),\n            Err(MeshWindingInvertError::WrongTopology)\n        ));\n    }\n\n    #[test]\n    fn line_list_mesh_invert_winding() {\n        let mesh = Mesh::new(PrimitiveTopology::LineList, RenderAssetUsages::default())\n            .with_inserted_indices(Indices::U32(vec![0, 1, 1, 2, 2, 3]));\n        let mesh = mesh.with_inverted_winding().unwrap();\n        assert_eq!(\n            mesh.indices().unwrap().iter().collect::<Vec<usize>>(),\n            vec![3, 2, 2, 1, 1, 0]\n        );\n    }\n\n    #[test]\n    fn line_list_mesh_invert_winding_fail() {\n        let mesh = Mesh::new(PrimitiveTopology::LineList, RenderAssetUsages::default())\n            .with_inserted_indices(Indices::U32(vec![0, 1, 1]));\n        assert!(matches!(\n            mesh.with_inverted_winding(),\n            Err(MeshWindingInvertError::AbruptIndicesEnd)\n        ));\n    }\n\n    #[test]\n    fn line_strip_mesh_invert_winding() {\n        let mesh = Mesh::new(PrimitiveTopology::LineStrip, RenderAssetUsages::default())\n            .with_inserted_indices(Indices::U32(vec![0, 1, 2, 3]));\n        let mesh = mesh.with_inverted_winding().unwrap();\n        assert_eq!(\n            mesh.indices().unwrap().iter().collect::<Vec<usize>>(),\n            vec![3, 2, 1, 0]\n        );\n    }\n\n    #[test]\n    fn triangle_list_mesh_invert_winding() {\n        let mesh = Mesh::new(\n            PrimitiveTopology::TriangleList,\n            RenderAssetUsages::default(),\n        )\n        .with_inserted_indices(Indices::U32(vec![\n            0, 3, 1, // First triangle\n            1, 3, 2, // Second triangle\n        ]));\n        let mesh = mesh.with_inverted_winding().unwrap();\n        assert_eq!(\n            mesh.indices().unwrap().iter().collect::<Vec<usize>>(),\n            vec![\n                0, 1, 3, // First triangle\n                1, 2, 3, // Second triangle\n            ]\n        );\n    }\n\n    #[test]\n    fn triangle_list_mesh_invert_winding_fail() {\n        let mesh = Mesh::new(\n            PrimitiveTopology::TriangleList,\n            RenderAssetUsages::default(),\n        )\n        .with_inserted_indices(Indices::U32(vec![0, 3, 1, 2]));\n        assert!(matches!(\n            mesh.with_inverted_winding(),\n            Err(MeshWindingInvertError::AbruptIndicesEnd)\n        ));\n    }\n\n    #[test]\n    fn triangle_strip_mesh_invert_winding() {\n        let mesh = Mesh::new(\n            PrimitiveTopology::TriangleStrip,\n            RenderAssetUsages::default(),\n        )\n        .with_inserted_indices(Indices::U32(vec![0, 1, 2, 3]));\n        let mesh = mesh.with_inverted_winding().unwrap();\n        assert_eq!(\n            mesh.indices().unwrap().iter().collect::<Vec<usize>>(),\n            vec![3, 2, 1, 0]\n        );\n    }\n\n    #[test]\n    fn compute_smooth_normals() {\n        let mut mesh = Mesh::new(\n            PrimitiveTopology::TriangleList,\n            RenderAssetUsages::default(),\n        );\n\n        //  z      y\n        //  |    /\n        //  3---2\n        //  | /  \\\n        //  0-----1--x\n\n        mesh.insert_attribute(\n            Mesh::ATTRIBUTE_POSITION,\n            vec![[0., 0., 0.], [1., 0., 0.], [0., 1., 0.], [0., 0., 1.]],\n        );\n        mesh.insert_indices(Indices::U16(vec![0, 1, 2, 0, 2, 3]));\n        mesh.compute_smooth_normals();\n        let normals = mesh\n            .attribute(Mesh::ATTRIBUTE_NORMAL)\n            .unwrap()\n            .as_float3()\n            .unwrap();\n        assert_eq!(4, normals.len());\n        // 0\n        assert_eq!(Vec3::new(1., 0., 1.).normalize().to_array(), normals[0]);\n        // 1\n        assert_eq!([0., 0., 1.], normals[1]);\n        // 2\n        assert_eq!(Vec3::new(1., 0., 1.).normalize().to_array(), normals[2]);\n        // 3\n        assert_eq!([1., 0., 0.], normals[3]);\n    }\n\n    #[test]\n    fn compute_smooth_normals_proportionate() {\n        let mut mesh = Mesh::new(\n            PrimitiveTopology::TriangleList,\n            RenderAssetUsages::default(),\n        );\n\n        //  z      y\n        //  |    /\n        //  3---2..\n        //  | /    \\\n        //  0-------1---x\n\n        mesh.insert_attribute(\n            Mesh::ATTRIBUTE_POSITION,\n            vec![[0., 0., 0.], [2., 0., 0.], [0., 1., 0.], [0., 0., 1.]],\n        );\n        mesh.insert_indices(Indices::U16(vec![0, 1, 2, 0, 2, 3]));\n        mesh.compute_smooth_normals();\n        let normals = mesh\n            .attribute(Mesh::ATTRIBUTE_NORMAL)\n            .unwrap()\n            .as_float3()\n            .unwrap();\n        assert_eq!(4, normals.len());\n        // 0\n        assert_eq!(Vec3::new(1., 0., 2.).normalize().to_array(), normals[0]);\n        // 1\n        assert_eq!([0., 0., 1.], normals[1]);\n        // 2\n        assert_eq!(Vec3::new(1., 0., 2.).normalize().to_array(), normals[2]);\n        // 3\n        assert_eq!([1., 0., 0.], normals[3]);\n    }\n\n    #[test]\n    fn triangles_from_triangle_list() {\n        let mut mesh = Mesh::new(\n            PrimitiveTopology::TriangleList,\n            RenderAssetUsages::default(),\n        );\n        mesh.insert_attribute(\n            Mesh::ATTRIBUTE_POSITION,\n            vec![[0., 0., 0.], [1., 0., 0.], [1., 1., 0.], [0., 1., 0.]],\n        );\n        mesh.insert_indices(Indices::U32(vec![0, 1, 2, 2, 3, 0]));\n        assert_eq!(\n            vec![\n                Triangle3d {\n                    vertices: [\n                        Vec3::new(0., 0., 0.),\n                        Vec3::new(1., 0., 0.),\n                        Vec3::new(1., 1., 0.),\n                    ]\n                },\n                Triangle3d {\n                    vertices: [\n                        Vec3::new(1., 1., 0.),\n                        Vec3::new(0., 1., 0.),\n                        Vec3::new(0., 0., 0.),\n                    ]\n                }\n            ],\n            mesh.triangles().unwrap().collect::<Vec<Triangle3d>>()\n        );\n    }\n\n    #[test]\n    fn triangles_from_triangle_strip() {\n        let mut mesh = Mesh::new(\n            PrimitiveTopology::TriangleStrip,\n            RenderAssetUsages::default(),\n        );\n        // Triangles: (0, 1, 2), (2, 1, 3), (2, 3, 4), (4, 3, 5)\n        //\n        // 4 - 5\n        // | \\ |\n        // 2 - 3\n        // | \\ |\n        // 0 - 1\n        let positions: Vec<Vec3> = [\n            [0., 0., 0.],\n            [1., 0., 0.],\n            [0., 1., 0.],\n            [1., 1., 0.],\n            [0., 2., 0.],\n            [1., 2., 0.],\n        ]\n        .into_iter()\n        .map(Vec3::from_array)\n        .collect();\n        mesh.insert_attribute(Mesh::ATTRIBUTE_POSITION, positions.clone());\n        mesh.insert_indices(Indices::U32(vec![0, 1, 2, 3, 4, 5]));\n        assert_eq!(\n            vec![\n                Triangle3d {\n                    vertices: [positions[0], positions[1], positions[2]]\n                },\n                Triangle3d {\n                    vertices: [positions[2], positions[1], positions[3]]\n                },\n                Triangle3d {\n                    vertices: [positions[2], positions[3], positions[4]]\n                },\n                Triangle3d {\n                    vertices: [positions[4], positions[3], positions[5]]\n                },\n            ],\n            mesh.triangles().unwrap().collect::<Vec<Triangle3d>>()\n        );\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "7ea8cde3204aedd4f355e28fcca0a433d10e2a24",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_mesh/src/primitives/extrusion.rs",
    "func": "use bevy_math::{\n    primitives::{Annulus, Capsule2d, Circle, Ellipse, Extrusion, Primitive2d},\n    Vec2, Vec3,\n};\n\nuse super::{MeshBuilder, Meshable};\nuse crate::{Indices, Mesh, PrimitiveTopology, VertexAttributeValues};\n\n/// A type representing a segment of the perimeter of an extrudable mesh.\npub enum PerimeterSegment {\n    /// This segment of the perimeter will be shaded smooth.\n    ///\n    /// This has the effect of rendering the segment's faces with softened edges, so it is appropriate for curved shapes.\n    ///\n    /// The normals for the vertices that are part of this segment will be calculated based on the positions of their neighbors.\n    /// Each normal is interpolated between the normals of the two line segments connecting it with its neighbors.\n    /// Closer vertices have a stronger effect on the normal than more distant ones.\n    ///\n    /// Since the vertices corresponding to the first and last indices do not have two neighboring vertices, their normals must be provided manually.\n    Smooth {\n        /// The normal of the first vertex.\n        first_normal: Vec2,\n        /// The normal of the last vertex.\n        last_normal: Vec2,\n        /// A list of indices representing this segment of the perimeter of the mesh.\n        ///\n        /// The indices must be ordered such that the *outside* of the mesh is to the right\n        /// when walking along the vertices of the mesh in the order provided by the indices.\n        ///\n        /// For geometry to be rendered, you must provide at least two indices.\n        indices: Vec<u32>,\n    },\n    /// This segment of the perimeter will be shaded flat.\n    ///\n    /// This has the effect of rendering the segment's faces with hard edges.\n    Flat {\n        /// A list of indices representing this segment of the perimeter of the mesh.\n        ///\n        /// The indices must be ordered such that the *outside* of the mesh is to the right\n        /// when walking along the vertices of the mesh in the order provided by indices.\n        ///\n        /// For geometry to be rendered, you must provide at least two indices.\n        indices: Vec<u32>,\n    },\n}\n\nimpl PerimeterSegment {\n    /// Returns the amount of vertices each 'layer' of the extrusion should include for this perimeter segment.\n    ///\n    /// A layer is the set of vertices sharing a common Z value or depth.\n    fn vertices_per_layer(&self) -> u32 {\n        match self {\n            PerimeterSegment::Smooth { indices, .. } => indices.len() as u32,\n            PerimeterSegment::Flat { indices } => 2 * (indices.len() as u32 - 1),\n        }\n    }\n\n    /// Returns the amount of indices each 'segment' of the extrusion should include for this perimeter segment.\n    ///\n    /// A segment is the set of faces on the mantel of the extrusion between two layers of vertices.\n    fn indices_per_segment(&self) -> usize {\n        match self {\n            PerimeterSegment::Smooth { indices, .. } | PerimeterSegment::Flat { indices } => {\n                6 * (indices.len() - 1)\n            }\n        }\n    }\n}\n\n/// A trait required for implementing `Meshable` for `Extrusion<T>`.\n///\n/// ## Warning\n///\n/// By implementing this trait you guarantee that the `primitive_topology` of the mesh returned by\n/// this builder is [`PrimitiveTopology::TriangleList`]\n/// and that your mesh has a [`Mesh::ATTRIBUTE_POSITION`] attribute.\npub trait Extrudable: MeshBuilder {\n    /// A list of the indices each representing a part of the perimeter of the mesh.\n    fn perimeter(&self) -> Vec<PerimeterSegment>;\n}\n\nimpl<P> Meshable for Extrusion<P>\nwhere\n    P: Primitive2d + Meshable,\n    P::Output: Extrudable,\n{\n    type Output = ExtrusionBuilder<P>;\n\n    fn mesh(&self) -> Self::Output {\n        ExtrusionBuilder {\n            base_builder: self.base_shape.mesh(),\n            half_depth: self.half_depth,\n            segments: 1,\n        }\n    }\n}\n\n/// A builder used for creating a [`Mesh`] with an [`Extrusion`] shape.\npub struct ExtrusionBuilder<P>\nwhere\n    P: Primitive2d + Meshable,\n    P::Output: Extrudable,\n{\n    pub base_builder: P::Output,\n    pub half_depth: f32,\n    pub segments: usize,\n}\n\nimpl<P> ExtrusionBuilder<P>\nwhere\n    P: Primitive2d + Meshable,\n    P::Output: Extrudable,\n{\n    /// Create a new `ExtrusionBuilder<P>` from a given `base_shape` and the full `depth` of the extrusion.\n    pub fn new(base_shape: &P, depth: f32) -> Self {\n        Self {\n            base_builder: base_shape.mesh(),\n            half_depth: depth / 2.,\n            segments: 1,\n        }\n    }\n\n    /// Sets the number of segments along the depth of the extrusion.\n    /// Must be greater than `0` for the geometry of the mantel to be generated.\n    pub fn segments(mut self, segments: usize) -> Self {\n        self.segments = segments;\n        self\n    }\n}\n\nimpl ExtrusionBuilder<Circle> {\n    /// Sets the number of vertices used for the circle mesh at each end of the extrusion.\n    pub fn resolution(mut self, resolution: u32) -> Self {\n        self.base_builder.resolution = resolution;\n        self\n    }\n}\n\nimpl ExtrusionBuilder<Ellipse> {\n    /// Sets the number of vertices used for the ellipse mesh at each end of the extrusion.\n    pub fn resolution(mut self, resolution: u32) -> Self {\n        self.base_builder.resolution = resolution;\n        self\n    }\n}\n\nimpl ExtrusionBuilder<Annulus> {\n    /// Sets the number of vertices used in constructing the concentric circles of the annulus mesh at each end of the extrusion.\n    pub fn resolution(mut self, resolution: u32) -> Self {\n        self.base_builder.resolution = resolution;\n        self\n    }\n}\n\nimpl ExtrusionBuilder<Capsule2d> {\n    /// Sets the number of vertices used for each hemicircle at the ends of the extrusion.\n    pub fn resolution(mut self, resolution: u32) -> Self {\n        self.base_builder.resolution = resolution;\n        self\n    }\n}\n\nimpl<P> MeshBuilder for ExtrusionBuilder<P>\nwhere\n    P: Primitive2d + Meshable,\n    P::Output: Extrudable,\n{\n    fn build(&self) -> Mesh {\n        // Create and move the base mesh to the front\n        let mut front_face =\n            self.base_builder\n                .build()\n                .translated_by(Vec3::new(0., 0., self.half_depth));\n\n        // Move the uvs of the front face to be between (0., 0.) and (0.5, 0.5)\n        if let Some(VertexAttributeValues::Float32x2(uvs)) =\n            front_face.attribute_mut(Mesh::ATTRIBUTE_UV_0)\n        {\n            for uv in uvs {\n                *uv = uv.map(|coord| coord * 0.5);\n            }\n        }\n\n        let back_face = {\n            let topology = front_face.primitive_topology();\n            // Flip the normals, etc. and move mesh to the back\n            let mut back_face = front_face.clone().scaled_by(Vec3::new(1., 1., -1.));\n\n            // Move the uvs of the back face to be between (0.5, 0.) and (1., 0.5)\n            if let Some(VertexAttributeValues::Float32x2(uvs)) =\n                back_face.attribute_mut(Mesh::ATTRIBUTE_UV_0)\n            {\n                for uv in uvs {\n                    *uv = [uv[0] + 0.5, uv[1]];\n                }\n            }\n\n            // By swapping the first and second indices of each triangle we invert the winding order thus making the mesh visible from the other side\n            if let Some(indices) = back_face.indices_mut() {\n                match topology {\n                    PrimitiveTopology::TriangleList => match indices {\n                        Indices::U16(indices) => {\n                            indices.chunks_exact_mut(3).for_each(|arr| arr.swap(1, 0));\n                        }\n                        Indices::U32(indices) => {\n                            indices.chunks_exact_mut(3).for_each(|arr| arr.swap(1, 0));\n                        }\n                    },\n                    _ => {\n                        panic!(\"Meshes used with Extrusions must have a primitive topology of `PrimitiveTopology::TriangleList`\");\n                    }\n                };\n            }\n            back_face\n        };\n\n        // An extrusion of depth 0 does not need a mantel\n        if self.half_depth == 0. {\n            front_face.merge(&back_face);\n            return front_face;\n        }\n\n        let mantel = {\n            let Some(VertexAttributeValues::Float32x3(cap_verts)) =\n                front_face.attribute(Mesh::ATTRIBUTE_POSITION)\n            else {\n                panic!(\"The base mesh did not have vertex positions\");\n            };\n\n            debug_assert!(self.segments > 0);\n\n            let layers = self.segments + 1;\n            let layer_depth_delta = self.half_depth * 2.0 / self.segments as f32;\n\n            let perimeter = self.base_builder.perimeter();\n            let (vert_count, index_count) =\n                perimeter\n                    .iter()\n                    .fold((0, 0), |(verts, indices), perimeter| {\n                        (\n                            verts + layers * perimeter.vertices_per_layer() as usize,\n                            indices + self.segments * perimeter.indices_per_segment(),\n                        )\n                    });\n            let mut positions = Vec::with_capacity(vert_count);\n            let mut normals = Vec::with_capacity(vert_count);\n            let mut indices = Vec::with_capacity(index_count);\n            let mut uvs = Vec::with_capacity(vert_count);\n\n            // Compute the amount of horizontal space allocated to each segment of the perimeter.\n            let uv_segment_delta = 1. / perimeter.len() as f32;\n            for (i, segment) in perimeter.into_iter().enumerate() {\n                // The start of the x range of the area of the current perimeter-segment.\n                let uv_start = i as f32 * uv_segment_delta;\n\n                match segment {\n                    PerimeterSegment::Flat {\n                        indices: segment_indices,\n                    } => {\n                        let uv_delta = uv_segment_delta / (segment_indices.len() - 1) as f32;\n                        for i in 0..(segment_indices.len() - 1) {\n                            let uv_x = uv_start + uv_delta * i as f32;\n                            // Get the positions for the current and the next index.\n                            let a = cap_verts[segment_indices[i] as usize];\n                            let b = cap_verts[segment_indices[i + 1] as usize];\n\n                            // Get the index of the next vertex added to the mantel.\n                            let index = positions.len() as u32;\n\n                            // Push the positions of the two indices and their equivalent points on each layer.\n                            for i in 0..layers {\n                                let i = i as f32;\n                                let z = a[2] - layer_depth_delta * i;\n                                positions.push([a[0], a[1], z]);\n                                positions.push([b[0], b[1], z]);\n\n                                // UVs for the mantel are between (0, 0.5) and (1, 1).\n                                let uv_y = 0.5 + 0.5 * i / self.segments as f32;\n                                uvs.push([uv_x, uv_y]);\n                                uvs.push([uv_x + uv_delta, uv_y]);\n                            }\n\n                            // The normal is calculated to be the normal of the line segment connecting a and b.\n                            let n = Vec3::from_array([b[1] - a[1], a[0] - b[0], 0.])\n                                .normalize_or_zero()\n                                .to_array();\n                            normals.extend_from_slice(&vec![n; 2 * layers]);\n\n                            // Add the indices for the vertices created above to the mesh.\n                            for i in 0..self.segments as u32 {\n                                let base_index = index + 2 * i;\n                                indices.extend_from_slice(&[\n                                    base_index,\n                                    base_index + 2,\n                                    base_index + 1,\n                                    base_index + 1,\n                                    base_index + 2,\n                                    base_index + 3,\n                                ]);\n                            }\n                        }\n                    }\n                    PerimeterSegment::Smooth {\n                        first_normal,\n                        last_normal,\n                        indices: segment_indices,\n                    } => {\n                        let uv_delta = uv_segment_delta / (segment_indices.len() - 1) as f32;\n\n                        // Since the indices for this segment will be added after its vertices have been added,\n                        // we need to store the index of the first vertex that is part of this segment.\n                        let base_index = positions.len() as u32;\n\n                        // If there is a first vertex, we need to add it and its counterparts on each layer.\n                        // The normal is provided by `segment.first_normal`.\n                        if let Some(i) = segment_indices.first() {\n                            let p = cap_verts[*i as usize];\n                            for i in 0..layers {\n                                let i = i as f32;\n                                let z = p[2] - layer_depth_delta * i;\n                                positions.push([p[0], p[1], z]);\n\n                                let uv_y = 0.5 + 0.5 * i / self.segments as f32;\n                                uvs.push([uv_start, uv_y]);\n                            }\n                            normals.extend_from_slice(&vec![\n                                first_normal.extend(0.).to_array();\n                                layers\n                            ]);\n                        }\n\n                        // For all points inbetween the first and last vertices, we can automatically compute the normals.\n                        for i in 1..(segment_indices.len() - 1) {\n                            let uv_x = uv_start + uv_delta * i as f32;\n\n                            // Get the positions for the last, current and the next index.\n                            let a = cap_verts[segment_indices[i - 1] as usize];\n                            let b = cap_verts[segment_indices[i] as usize];\n                            let c = cap_verts[segment_indices[i + 1] as usize];\n\n                            // Add the current vertex and its counterparts on each layer.\n                            for i in 0..layers {\n                                let i = i as f32;\n                                let z = b[2] - layer_depth_delta * i;\n                                positions.push([b[0], b[1], z]);\n\n                                let uv_y = 0.5 + 0.5 * i / self.segments as f32;\n                                uvs.push([uv_x, uv_y]);\n                            }\n\n                            // The normal for the current vertices can be calculated based on the two neighboring vertices.\n                            // The normal is interpolated between the normals of the two line segments connecting the current vertex with its neighbors.\n                            // Closer vertices have a stronger effect on the normal than more distant ones.\n                            let n = {\n                                let ab = Vec2::from_slice(&b) - Vec2::from_slice(&a);\n                                let bc = Vec2::from_slice(&c) - Vec2::from_slice(&b);\n                                let n = ab.normalize_or_zero() + bc.normalize_or_zero();\n                                Vec2::new(n.y, -n.x)\n                                    .normalize_or_zero()\n                                    .extend(0.)\n                                    .to_array()\n                            };\n                            normals.extend_from_slice(&vec![n; layers]);\n                        }\n\n                        // If there is a last vertex, we need to add it and its counterparts on each layer.\n                        // The normal is provided by `segment.last_normal`.\n                        if let Some(i) = segment_indices.last() {\n                            let p = cap_verts[*i as usize];\n                            for i in 0..layers {\n                                let i = i as f32;\n                                let z = p[2] - layer_depth_delta * i;\n                                positions.push([p[0], p[1], z]);\n\n                                let uv_y = 0.5 + 0.5 * i / self.segments as f32;\n                                uvs.push([uv_start + uv_segment_delta, uv_y]);\n                            }\n                            normals.extend_from_slice(&vec![\n                                last_normal.extend(0.).to_array();\n                                layers\n                            ]);\n                        }\n\n                        let columns = segment_indices.len() as u32;\n                        let segments = self.segments as u32;\n                        let layers = segments + 1;\n                        for s in 0..segments {\n                            for column in 0..(columns - 1) {\n                                let index = base_index + s + column * layers;\n                                indices.extend_from_slice(&[\n                                    index,\n                                    index + 1,\n                                    index + layers,\n                                    index + layers,\n                                    index + 1,\n                                    index + layers + 1,\n                                ]);\n                            }\n                        }\n                    }\n                }\n            }\n\n            Mesh::new(PrimitiveTopology::TriangleList, front_face.asset_usage)\n                .with_inserted_indices(Indices::U32(indices))\n                .with_inserted_attribute(Mesh::ATTRIBUTE_POSITION, positions)\n                .with_inserted_attribute(Mesh::ATTRIBUTE_NORMAL, normals)\n                .with_inserted_attribute(Mesh::ATTRIBUTE_UV_0, uvs)\n        };\n\n        front_face.merge(&back_face);\n        front_face.merge(&mantel);\n        front_face\n    }\n}\n\nimpl<P> From<Extrusion<P>> for Mesh\nwhere\n    P: Primitive2d + Meshable,\n    P::Output: Extrudable,\n{\n    fn from(value: Extrusion<P>) -> Self {\n        value.mesh().build()\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "53690a410988fcefbe8d7ab3f5adec675af6c706",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_gizmos/src/rounded_box.rs",
    "func": "//! Additional [`GizmoBuffer`] Functions -- Rounded cuboids and rectangles\n//!\n//! Includes the implementation of [`GizmoBuffer::rounded_rect`], [`GizmoBuffer::rounded_rect_2d`] and [`GizmoBuffer::rounded_cuboid`].\n//! and assorted support items.\n\nuse core::f32::consts::FRAC_PI_2;\n\nuse crate::{gizmos::GizmoBuffer, prelude::GizmoConfigGroup};\nuse bevy_color::Color;\nuse bevy_math::{Isometry2d, Isometry3d, Quat, Vec2, Vec3};\nuse bevy_transform::components::Transform;\n\n/// A builder returned by [`GizmoBuffer::rounded_rect`] and [`GizmoBuffer::rounded_rect_2d`]\npub struct RoundedRectBuilder<'a, Config, Clear>\nwhere\n    Config: GizmoConfigGroup,\n    Clear: 'static + Send + Sync,\n{\n    size: Vec2,\n    gizmos: &'a mut GizmoBuffer<Config, Clear>,\n    config: RoundedBoxConfig,\n}\n/// A builder returned by [`GizmoBuffer::rounded_cuboid`]\npub struct RoundedCuboidBuilder<'a, Config, Clear>\nwhere\n    Config: GizmoConfigGroup,\n    Clear: 'static + Send + Sync,\n{\n    size: Vec3,\n    gizmos: &'a mut GizmoBuffer<Config, Clear>,\n    config: RoundedBoxConfig,\n}\nstruct RoundedBoxConfig {\n    isometry: Isometry3d,\n    color: Color,\n    corner_radius: f32,\n    arc_resolution: u32,\n}\n\nimpl<Config, Clear> RoundedRectBuilder<'_, Config, Clear>\nwhere\n    Config: GizmoConfigGroup,\n    Clear: 'static + Send + Sync,\n{\n    /// Change the radius of the corners to be `corner_radius`.\n    /// The default corner radius is [min axis of size] / 10.0\n    pub fn corner_radius(mut self, corner_radius: f32) -> Self {\n        self.config.corner_radius = corner_radius;\n        self\n    }\n\n    /// Change the resolution of the arcs at the corners of the rectangle.\n    /// The default value is 8\n    pub fn arc_resolution(mut self, arc_resolution: u32) -> Self {\n        self.config.arc_resolution = arc_resolution;\n        self\n    }\n}\n\nimpl<Config, Clear> RoundedCuboidBuilder<'_, Config, Clear>\nwhere\n    Config: GizmoConfigGroup,\n    Clear: 'static + Send + Sync,\n{\n    /// Change the radius of the edges to be `edge_radius`.\n    /// The default edge radius is [min axis of size] / 10.0\n    pub fn edge_radius(mut self, edge_radius: f32) -> Self {\n        self.config.corner_radius = edge_radius;\n        self\n    }\n\n    /// Change the resolution of the arcs at the edges of the cuboid.\n    /// The default value is 8\n    pub fn arc_resolution(mut self, arc_resolution: u32) -> Self {\n        self.config.arc_resolution = arc_resolution;\n        self\n    }\n}\n\nimpl<Config, Clear> Drop for RoundedRectBuilder<'_, Config, Clear>\nwhere\n    Config: GizmoConfigGroup,\n    Clear: 'static + Send + Sync,\n{\n    fn drop(&mut self) {\n        if !self.gizmos.enabled {\n            return;\n        }\n        let config = &self.config;\n\n        // Calculate inner and outer half size and ensure that the edge_radius is <= any half_length\n        let mut outer_half_size = self.size.abs() / 2.0;\n        let inner_half_size =\n            (outer_half_size - Vec2::splat(config.corner_radius.abs())).max(Vec2::ZERO);\n        let corner_radius = (outer_half_size - inner_half_size).min_element();\n        let mut inner_half_size = outer_half_size - Vec2::splat(corner_radius);\n\n        if config.corner_radius < 0. {\n            core::mem::swap(&mut outer_half_size, &mut inner_half_size);\n        }\n\n        // Handle cases where the rectangle collapses into simpler shapes\n        if outer_half_size.x * outer_half_size.y == 0. {\n            self.gizmos.line(\n                config.isometry * -outer_half_size.extend(0.),\n                config.isometry * outer_half_size.extend(0.),\n                config.color,\n            );\n            return;\n        }\n        if corner_radius == 0. {\n            self.gizmos.rect(config.isometry, self.size, config.color);\n            return;\n        }\n\n        let vertices = [\n            // top right\n            Vec3::new(inner_half_size.x, outer_half_size.y, 0.),\n            Vec3::new(inner_half_size.x, inner_half_size.y, 0.),\n            Vec3::new(outer_half_size.x, inner_half_size.y, 0.),\n            // bottom right\n            Vec3::new(outer_half_size.x, -inner_half_size.y, 0.),\n            Vec3::new(inner_half_size.x, -inner_half_size.y, 0.),\n            Vec3::new(inner_half_size.x, -outer_half_size.y, 0.),\n            // bottom left\n            Vec3::new(-inner_half_size.x, -outer_half_size.y, 0.),\n            Vec3::new(-inner_half_size.x, -inner_half_size.y, 0.),\n            Vec3::new(-outer_half_size.x, -inner_half_size.y, 0.),\n            // top left\n            Vec3::new(-outer_half_size.x, inner_half_size.y, 0.),\n            Vec3::new(-inner_half_size.x, inner_half_size.y, 0.),\n            Vec3::new(-inner_half_size.x, outer_half_size.y, 0.),\n        ]\n        .map(|vec3| config.isometry * vec3);\n\n        for chunk in vertices.chunks_exact(3) {\n            self.gizmos\n                .short_arc_3d_between(chunk[1], chunk[0], chunk[2], config.color)\n                .resolution(config.arc_resolution);\n        }\n\n        let edges = if config.corner_radius > 0. {\n            [\n                (vertices[2], vertices[3]),\n                (vertices[5], vertices[6]),\n                (vertices[8], vertices[9]),\n                (vertices[11], vertices[0]),\n            ]\n        } else {\n            [\n                (vertices[0], vertices[5]),\n                (vertices[3], vertices[8]),\n                (vertices[6], vertices[11]),\n                (vertices[9], vertices[2]),\n            ]\n        };\n\n        for (start, end) in edges {\n            self.gizmos.line(start, end, config.color);\n        }\n    }\n}\n\nimpl<Config, Clear> Drop for RoundedCuboidBuilder<'_, Config, Clear>\nwhere\n    Config: GizmoConfigGroup,\n    Clear: 'static + Send + Sync,\n{\n    fn drop(&mut self) {\n        if !self.gizmos.enabled {\n            return;\n        }\n        let config = &self.config;\n\n        // Calculate inner and outer half size and ensure that the edge_radius is <= any half_length\n        let outer_half_size = self.size.abs() / 2.0;\n        let inner_half_size =\n            (outer_half_size - Vec3::splat(config.corner_radius.abs())).max(Vec3::ZERO);\n        let mut edge_radius = (outer_half_size - inner_half_size).min_element();\n        let inner_half_size = outer_half_size - Vec3::splat(edge_radius);\n        edge_radius *= config.corner_radius.signum();\n\n        // Handle cases where the rounded cuboid collapses into simpler shapes\n        if edge_radius == 0.0 {\n            let transform = Transform::from_translation(config.isometry.translation.into())\n                .with_rotation(config.isometry.rotation)\n                .with_scale(self.size);\n            self.gizmos.cuboid(transform, config.color);\n            return;\n        }\n\n        let rects = [\n            (\n                Vec3::X,\n                Vec2::new(self.size.z, self.size.y),\n                Quat::from_rotation_y(FRAC_PI_2),\n            ),\n            (\n                Vec3::Y,\n                Vec2::new(self.size.x, self.size.z),\n                Quat::from_rotation_x(FRAC_PI_2),\n            ),\n            (Vec3::Z, Vec2::new(self.size.x, self.size.y), Quat::IDENTITY),\n        ];\n\n        for (position, size, rotation) in rects {\n            let local_position = position * inner_half_size;\n            self.gizmos\n                .rounded_rect(\n                    config.isometry * Isometry3d::new(local_position, rotation),\n                    size,\n                    config.color,\n                )\n                .arc_resolution(config.arc_resolution)\n                .corner_radius(edge_radius);\n\n            self.gizmos\n                .rounded_rect(\n                    config.isometry * Isometry3d::new(-local_position, rotation),\n                    size,\n                    config.color,\n                )\n                .arc_resolution(config.arc_resolution)\n                .corner_radius(edge_radius);\n        }\n    }\n}\n\nimpl<Config, Clear> GizmoBuffer<Config, Clear>\nwhere\n    Config: GizmoConfigGroup,\n    Clear: 'static + Send + Sync,\n{\n    /// Draw a wireframe rectangle with rounded corners in 3D.\n    ///\n    /// This should be called for each frame the rectangle needs to be rendered.\n    ///\n    /// # Arguments\n    ///\n    /// - `isometry` defines the translation and rotation of the rectangle.\n    ///              - the translation specifies the center of the rectangle\n    ///              - defines orientation of the rectangle, by default we\n    ///                assume the rectangle is contained in a plane parallel\n    ///                to the XY plane.\n    /// - `size`: defines the size of the rectangle. This refers to the 'outer size', similar to a bounding box.\n    /// - `color`: color of the rectangle\n    ///\n    /// # Builder methods\n    ///\n    /// - The corner radius can be adjusted with the `.corner_radius(...)` method.\n    /// - The resolution of the arcs at each corner (i.e. the level of detail) can be adjusted with the\n    ///     `.arc_resolution(...)` method.\n    ///\n    /// # Example\n    /// ```\n    /// # use bevy_gizmos::prelude::*;\n    /// # use bevy_math::prelude::*;\n    /// # use bevy_color::palettes::css::GREEN;\n    /// fn system(mut gizmos: Gizmos) {\n    ///     gizmos.rounded_rect(\n    ///         Isometry3d::IDENTITY,\n    ///         Vec2::ONE,\n    ///         GREEN\n    ///         )\n    ///         .corner_radius(0.25)\n    ///         .arc_resolution(10);\n    /// }\n    /// # bevy_ecs::system::assert_is_system(system);\n    /// ```\n    pub fn rounded_rect(\n        &mut self,\n        isometry: impl Into<Isometry3d>,\n        size: Vec2,\n        color: impl Into<Color>,\n    ) -> RoundedRectBuilder<'_, Config, Clear> {\n        let corner_radius = size.min_element() * DEFAULT_CORNER_RADIUS;\n        RoundedRectBuilder {\n            gizmos: self,\n            config: RoundedBoxConfig {\n                isometry: isometry.into(),\n                color: color.into(),\n                corner_radius,\n                arc_resolution: DEFAULT_ARC_RESOLUTION,\n            },\n            size,\n        }\n    }\n\n    /// Draw a wireframe rectangle with rounded corners in 2D.\n    ///\n    /// This should be called for each frame the rectangle needs to be rendered.\n    ///\n    /// # Arguments\n    ///\n    /// - `isometry` defines the translation and rotation of the rectangle.\n    ///              - the translation specifies the center of the rectangle\n    ///              - defines orientation of the rectangle, by default we\n    ///                assume the rectangle aligned with all axes.\n    /// - `size`: defines the size of the rectangle. This refers to the 'outer size', similar to a bounding box.\n    /// - `color`: color of the rectangle\n    ///\n    /// # Builder methods\n    ///\n    /// - The corner radius can be adjusted with the `.corner_radius(...)` method.\n    /// - The resolution of the arcs at each corner (i.e. the level of detail) can be adjusted with the\n    ///     `.arc_resolution(...)` method.\n    ///\n    /// # Example\n    /// ```\n    /// # use bevy_gizmos::prelude::*;\n    /// # use bevy_math::prelude::*;\n    /// # use bevy_color::palettes::css::GREEN;\n    /// fn system(mut gizmos: Gizmos) {\n    ///     gizmos.rounded_rect_2d(\n    ///         Isometry2d::IDENTITY,\n    ///         Vec2::ONE,\n    ///         GREEN\n    ///         )\n    ///         .corner_radius(0.25)\n    ///         .arc_resolution(10);\n    /// }\n    /// # bevy_ecs::system::assert_is_system(system);\n    /// ```\n    pub fn rounded_rect_2d(\n        &mut self,\n        isometry: impl Into<Isometry2d>,\n        size: Vec2,\n        color: impl Into<Color>,\n    ) -> RoundedRectBuilder<'_, Config, Clear> {\n        let isometry = isometry.into();\n        let corner_radius = size.min_element() * DEFAULT_CORNER_RADIUS;\n        RoundedRectBuilder {\n            gizmos: self,\n            config: RoundedBoxConfig {\n                isometry: Isometry3d::new(\n                    isometry.translation.extend(0.0),\n                    Quat::from_rotation_z(isometry.rotation.as_radians()),\n                ),\n                color: color.into(),\n                corner_radius,\n                arc_resolution: DEFAULT_ARC_RESOLUTION,\n            },\n            size,\n        }\n    }\n\n    /// Draw a wireframe cuboid with rounded corners in 3D.\n    ///\n    /// This should be called for each frame the cuboid needs to be rendered.\n    ///\n    /// # Arguments\n    ///\n    /// - `isometry` defines the translation and rotation of the cuboid.\n    ///              - the translation specifies the center of the cuboid\n    ///              - defines orientation of the cuboid, by default we\n    ///                assume the cuboid aligned with all axes.\n    /// - `size`: defines the size of the cuboid. This refers to the 'outer size', similar to a bounding box.\n    /// - `color`: color of the cuboid\n    ///\n    /// # Builder methods\n    ///\n    /// - The edge radius can be adjusted with the `.edge_radius(...)` method.\n    /// - The resolution of the arcs at each edge (i.e. the level of detail) can be adjusted with the\n    ///     `.arc_resolution(...)` method.\n    ///\n    /// # Example\n    /// ```\n    /// # use bevy_gizmos::prelude::*;\n    /// # use bevy_math::prelude::*;\n    /// # use bevy_color::palettes::css::GREEN;\n    /// fn system(mut gizmos: Gizmos) {\n    ///     gizmos.rounded_cuboid(\n    ///         Isometry3d::IDENTITY,\n    ///         Vec3::ONE,\n    ///         GREEN\n    ///         )\n    ///         .edge_radius(0.25)\n    ///         .arc_resolution(10);\n    /// }\n    /// # bevy_ecs::system::assert_is_system(system);\n    /// ```\n    pub fn rounded_cuboid(\n        &mut self,\n        isometry: impl Into<Isometry3d>,\n        size: Vec3,\n        color: impl Into<Color>,\n    ) -> RoundedCuboidBuilder<'_, Config, Clear> {\n        let corner_radius = size.min_element() * DEFAULT_CORNER_RADIUS;\n        RoundedCuboidBuilder {\n            gizmos: self,\n            config: RoundedBoxConfig {\n                isometry: isometry.into(),\n                color: color.into(),\n                corner_radius,\n                arc_resolution: DEFAULT_ARC_RESOLUTION,\n            },\n            size,\n        }\n    }\n}\n\nconst DEFAULT_ARC_RESOLUTION: u32 = 8;\nconst DEFAULT_CORNER_RADIUS: f32 = 0.1;\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "fb76e97e838dc64c373cac63ec83021cb7a21436",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_gizmos/src/curves.rs",
    "func": "//! Additional [`GizmoBuffer`] Functions -- Curves\n//!\n//! Includes the implementation of [`GizmoBuffer::curve_2d`],\n//! [`GizmoBuffer::curve_3d`] and assorted support items.\n\nuse bevy_color::Color;\nuse bevy_math::{curve::Curve, Vec2, Vec3};\n\nuse crate::{gizmos::GizmoBuffer, prelude::GizmoConfigGroup};\n\nimpl<Config, Clear> GizmoBuffer<Config, Clear>\nwhere\n    Config: GizmoConfigGroup,\n    Clear: 'static + Send + Sync,\n{\n    /// Draw a curve, at the given time points, sampling in 2D.\n    ///\n    /// This should be called for each frame the curve needs to be rendered.\n    ///\n    /// Samples of time points outside of the curve's domain will be filtered out and won't\n    /// contribute to the rendering. If you wish to render the curve outside of its domain you need\n    /// to create a new curve with an extended domain.\n    ///\n    /// # Arguments\n    /// - `curve_2d` some type that implements the [`Curve`] trait and samples `Vec2`s\n    /// - `times` some iterable type yielding `f32` which will be used for sampling the curve\n    /// - `color` the color of the curve\n    ///\n    /// # Example\n    /// ```\n    /// # use bevy_gizmos::prelude::*;\n    /// # use bevy_math::prelude::*;\n    /// # use bevy_color::palettes::basic::{RED};\n    /// fn system(mut gizmos: Gizmos) {\n    ///     let domain = Interval::UNIT;\n    ///     let curve = FunctionCurve::new(domain, |t| Vec2::from(t.sin_cos()));\n    ///     gizmos.curve_2d(curve, (0..=100).map(|n| n as f32 / 100.0), RED);\n    /// }\n    /// # bevy_ecs::system::assert_is_system(system);\n    /// ```\n    pub fn curve_2d(\n        &mut self,\n        curve_2d: impl Curve<Vec2>,\n        times: impl IntoIterator<Item = f32>,\n        color: impl Into<Color>,\n    ) {\n        self.linestrip_2d(curve_2d.sample_iter(times).flatten(), color);\n    }\n\n    /// Draw a curve, at the given time points, sampling in 3D.\n    ///\n    /// This should be called for each frame the curve needs to be rendered.\n    ///\n    /// Samples of time points outside of the curve's domain will be filtered out and won't\n    /// contribute to the rendering. If you wish to render the curve outside of its domain you need\n    /// to create a new curve with an extended domain.\n    ///\n    /// # Arguments\n    /// - `curve_3d` some type that implements the [`Curve`] trait and samples `Vec3`s\n    /// - `times` some iterable type yielding `f32` which will be used for sampling the curve\n    /// - `color` the color of the curve\n    ///\n    /// # Example\n    /// ```\n    /// # use bevy_gizmos::prelude::*;\n    /// # use bevy_math::prelude::*;\n    /// # use bevy_color::palettes::basic::{RED};\n    /// fn system(mut gizmos: Gizmos) {\n    ///     let domain = Interval::UNIT;\n    ///     let curve = FunctionCurve::new(domain, |t| {\n    ///         let (x,y) = t.sin_cos();\n    ///         Vec3::new(x, y, t)\n    ///     });\n    ///     gizmos.curve_3d(curve, (0..=100).map(|n| n as f32 / 100.0), RED);\n    /// }\n    /// # bevy_ecs::system::assert_is_system(system);\n    /// ```\n    pub fn curve_3d(\n        &mut self,\n        curve_3d: impl Curve<Vec3>,\n        times: impl IntoIterator<Item = f32>,\n        color: impl Into<Color>,\n    ) {\n        self.linestrip(curve_3d.sample_iter(times).flatten(), color);\n    }\n\n    /// Draw a curve, at the given time points, sampling in 2D, with a color gradient.\n    ///\n    /// This should be called for each frame the curve needs to be rendered.\n    ///\n    /// Samples of time points outside of the curve's domain will be filtered out and won't\n    /// contribute to the rendering. If you wish to render the curve outside of its domain you need\n    /// to create a new curve with an extended domain.\n    ///\n    /// # Arguments\n    /// - `curve_2d` some type that implements the [`Curve`] trait and samples `Vec2`s\n    /// - `times_with_colors` some iterable type yielding `f32` which will be used for sampling\n    ///   the curve together with the color at this position\n    ///\n    /// # Example\n    /// ```\n    /// # use bevy_gizmos::prelude::*;\n    /// # use bevy_math::prelude::*;\n    /// # use bevy_color::{Mix, palettes::basic::{GREEN, RED}};\n    /// fn system(mut gizmos: Gizmos) {\n    ///     let domain = Interval::UNIT;\n    ///     let curve = FunctionCurve::new(domain, |t| Vec2::from(t.sin_cos()));\n    ///     gizmos.curve_gradient_2d(\n    ///         curve,\n    ///         (0..=100).map(|n| n as f32 / 100.0)\n    ///                  .map(|t| (t, GREEN.mix(&RED, t)))\n    ///     );\n    /// }\n    /// # bevy_ecs::system::assert_is_system(system);\n    /// ```\n    pub fn curve_gradient_2d<C>(\n        &mut self,\n        curve_2d: impl Curve<Vec2>,\n        times_with_colors: impl IntoIterator<Item = (f32, C)>,\n    ) where\n        C: Into<Color>,\n    {\n        self.linestrip_gradient_2d(\n            times_with_colors\n                .into_iter()\n                .filter_map(|(time, color)| curve_2d.sample(time).map(|sample| (sample, color))),\n        );\n    }\n\n    /// Draw a curve, at the given time points, sampling in 3D, with a color gradient.\n    ///\n    /// This should be called for each frame the curve needs to be rendered.\n    ///\n    /// Samples of time points outside of the curve's domain will be filtered out and won't\n    /// contribute to the rendering. If you wish to render the curve outside of its domain you need\n    /// to create a new curve with an extended domain.\n    ///\n    /// # Arguments\n    /// - `curve_3d` some type that implements the [`Curve`] trait and samples `Vec3`s\n    /// - `times_with_colors` some iterable type yielding `f32` which will be used for sampling\n    ///   the curve together with the color at this position\n    ///\n    /// # Example\n    /// ```\n    /// # use bevy_gizmos::prelude::*;\n    /// # use bevy_math::prelude::*;\n    /// # use bevy_color::{Mix, palettes::basic::{GREEN, RED}};\n    /// fn system(mut gizmos: Gizmos) {\n    ///     let domain = Interval::UNIT;\n    ///     let curve = FunctionCurve::new(domain, |t| {\n    ///         let (x,y) = t.sin_cos();\n    ///         Vec3::new(x, y, t)\n    ///     });\n    ///     gizmos.curve_gradient_3d(\n    ///         curve,\n    ///         (0..=100).map(|n| n as f32 / 100.0)\n    ///                  .map(|t| (t, GREEN.mix(&RED, t)))\n    ///     );\n    /// }\n    /// # bevy_ecs::system::assert_is_system(system);\n    /// ```\n    pub fn curve_gradient_3d<C>(\n        &mut self,\n        curve_3d: impl Curve<Vec3>,\n        times_with_colors: impl IntoIterator<Item = (f32, C)>,\n    ) where\n        C: Into<Color>,\n    {\n        self.linestrip_gradient(\n            times_with_colors\n                .into_iter()\n                .filter_map(|(time, color)| curve_3d.sample(time).map(|sample| (sample, color))),\n        );\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "e407011e42e0f5f98e3174bc92d396fdadf25d49",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_gizmos/src/primitives/dim2.rs",
    "func": "//! A module for rendering each of the 2D [`bevy_math::primitives`] with [`GizmoBuffer`].\n\nuse core::f32::consts::{FRAC_PI_2, PI};\n\nuse super::helpers::*;\n\nuse bevy_color::Color;\nuse bevy_math::{\n    primitives::{\n        Annulus, Arc2d, BoxedPolygon, BoxedPolyline2d, Capsule2d, Circle, CircularSector,\n        CircularSegment, Ellipse, Line2d, Plane2d, Polygon, Polyline2d, Primitive2d, Rectangle,\n        RegularPolygon, Rhombus, Segment2d, Triangle2d,\n    },\n    Dir2, Isometry2d, Rot2, Vec2,\n};\n\nuse crate::{gizmos::GizmoBuffer, prelude::GizmoConfigGroup};\n\n// some magic number since using directions as offsets will result in lines of length 1 pixel\nconst MIN_LINE_LEN: f32 = 50.0;\nconst HALF_MIN_LINE_LEN: f32 = 25.0;\n// length used to simulate infinite lines\nconst INFINITE_LEN: f32 = 100_000.0;\n\n/// A trait for rendering 2D geometric primitives (`P`) with [`GizmoBuffer`].\npub trait GizmoPrimitive2d<P: Primitive2d> {\n    /// The output of `primitive_2d`. This is a builder to set non-default values.\n    type Output<'a>\n    where\n        Self: 'a;\n\n    /// Renders a 2D primitive with its associated details.\n    fn primitive_2d(\n        &mut self,\n        primitive: &P,\n        isometry: impl Into<Isometry2d>,\n        color: impl Into<Color>,\n    ) -> Self::Output<'_>;\n}\n\n// direction 2d\n\nimpl<Config, Clear> GizmoPrimitive2d<Dir2> for GizmoBuffer<Config, Clear>\nwhere\n    Config: GizmoConfigGroup,\n    Clear: 'static + Send + Sync,\n{\n    type Output<'a>\n        = ()\n    where\n        Self: 'a;\n\n    fn primitive_2d(\n        &mut self,\n        primitive: &Dir2,\n        isometry: impl Into<Isometry2d>,\n        color: impl Into<Color>,\n    ) -> Self::Output<'_> {\n        if !self.enabled {\n            return;\n        }\n        let isometry = isometry.into();\n        let start = Vec2::ZERO;\n        let end = *primitive * MIN_LINE_LEN;\n        self.arrow_2d(isometry * start, isometry * end, color);\n    }\n}\n\n// arc 2d\n\nimpl<Config, Clear> GizmoPrimitive2d<Arc2d> for GizmoBuffer<Config, Clear>\nwhere\n    Config: GizmoConfigGroup,\n    Clear: 'static + Send + Sync,\n{\n    type Output<'a>\n        = ()\n    where\n        Self: 'a;\n\n    fn primitive_2d(\n        &mut self,\n        primitive: &Arc2d,\n        isometry: impl Into<Isometry2d>,\n        color: impl Into<Color>,\n    ) -> Self::Output<'_> {\n        if !self.enabled {\n            return;\n        }\n\n        let isometry = isometry.into();\n        let start_iso = isometry * Isometry2d::from_rotation(Rot2::radians(-primitive.half_angle));\n\n        self.arc_2d(\n            start_iso,\n            primitive.half_angle * 2.0,\n            primitive.radius,\n            color,\n        );\n    }\n}\n\n// circle 2d\n\nimpl<Config, Clear> GizmoPrimitive2d<Circle> for GizmoBuffer<Config, Clear>\nwhere\n    Config: GizmoConfigGroup,\n    Clear: 'static + Send + Sync,\n{\n    type Output<'a>\n        = crate::circles::Ellipse2dBuilder<'a, Config, Clear>\n    where\n        Self: 'a;\n\n    fn primitive_2d(\n        &mut self,\n        primitive: &Circle,\n        isometry: impl Into<Isometry2d>,\n        color: impl Into<Color>,\n    ) -> Self::Output<'_> {\n        self.circle_2d(isometry, primitive.radius, color)\n    }\n}\n\n// circular sector 2d\n\nimpl<Config, Clear> GizmoPrimitive2d<CircularSector> for GizmoBuffer<Config, Clear>\nwhere\n    Config: GizmoConfigGroup,\n    Clear: 'static + Send + Sync,\n{\n    type Output<'a>\n        = ()\n    where\n        Self: 'a;\n\n    fn primitive_2d(\n        &mut self,\n        primitive: &CircularSector,\n        isometry: impl Into<Isometry2d>,\n        color: impl Into<Color>,\n    ) -> Self::Output<'_> {\n        if !self.enabled {\n            return;\n        }\n\n        let isometry = isometry.into();\n        let color = color.into();\n\n        let start_iso =\n            isometry * Isometry2d::from_rotation(Rot2::radians(-primitive.arc.half_angle));\n        let end_iso = isometry * Isometry2d::from_rotation(Rot2::radians(primitive.arc.half_angle));\n\n        // we need to draw the arc part of the sector, and the two lines connecting the arc and the center\n        self.arc_2d(\n            start_iso,\n            primitive.arc.half_angle * 2.0,\n            primitive.arc.radius,\n            color,\n        );\n\n        let end_position = primitive.arc.radius * Vec2::Y;\n        self.line_2d(isometry * Vec2::ZERO, start_iso * end_position, color);\n        self.line_2d(isometry * Vec2::ZERO, end_iso * end_position, color);\n    }\n}\n\n// circular segment 2d\n\nimpl<Config, Clear> GizmoPrimitive2d<CircularSegment> for GizmoBuffer<Config, Clear>\nwhere\n    Config: GizmoConfigGroup,\n    Clear: 'static + Send + Sync,\n{\n    type Output<'a>\n        = ()\n    where\n        Self: 'a;\n\n    fn primitive_2d(\n        &mut self,\n        primitive: &CircularSegment,\n        isometry: impl Into<Isometry2d>,\n        color: impl Into<Color>,\n    ) -> Self::Output<'_> {\n        if !self.enabled {\n            return;\n        }\n\n        let isometry = isometry.into();\n        let color = color.into();\n\n        let start_iso =\n            isometry * Isometry2d::from_rotation(Rot2::radians(-primitive.arc.half_angle));\n        let end_iso = isometry * Isometry2d::from_rotation(Rot2::radians(primitive.arc.half_angle));\n\n        // we need to draw the arc part of the segment, and the line connecting the two ends\n        self.arc_2d(\n            start_iso,\n            primitive.arc.half_angle * 2.0,\n            primitive.arc.radius,\n            color,\n        );\n\n        let position = primitive.arc.radius * Vec2::Y;\n        self.line_2d(start_iso * position, end_iso * position, color);\n    }\n}\n\n// ellipse 2d\n\nimpl<Config, Clear> GizmoPrimitive2d<Ellipse> for GizmoBuffer<Config, Clear>\nwhere\n    Config: GizmoConfigGroup,\n    Clear: 'static + Send + Sync,\n{\n    type Output<'a>\n        = crate::circles::Ellipse2dBuilder<'a, Config, Clear>\n    where\n        Self: 'a;\n\n    fn primitive_2d<'a>(\n        &mut self,\n        primitive: &Ellipse,\n        isometry: impl Into<Isometry2d>,\n        color: impl Into<Color>,\n    ) -> Self::Output<'_> {\n        self.ellipse_2d(isometry, primitive.half_size, color)\n    }\n}\n\n// annulus 2d\n\n/// Builder for configuring the drawing options of [`Annulus`].\npub struct Annulus2dBuilder<'a, Config, Clear>\nwhere\n    Config: GizmoConfigGroup,\n    Clear: 'static + Send + Sync,\n{\n    gizmos: &'a mut GizmoBuffer<Config, Clear>,\n    isometry: Isometry2d,\n    inner_radius: f32,\n    outer_radius: f32,\n    color: Color,\n    inner_resolution: u32,\n    outer_resolution: u32,\n}\n\nimpl<Config, Clear> Annulus2dBuilder<'_, Config, Clear>\nwhere\n    Config: GizmoConfigGroup,\n    Clear: 'static + Send + Sync,\n{\n    /// Set the number of line-segments for each circle of the annulus.\n    pub fn resolution(mut self, resolution: u32) -> Self {\n        self.outer_resolution = resolution;\n        self.inner_resolution = resolution;\n        self\n    }\n\n    /// Set the number of line-segments for the outer circle of the annulus.\n    pub fn outer_resolution(mut self, resolution: u32) -> Self {\n        self.outer_resolution = resolution;\n        self\n    }\n\n    /// Set the number of line-segments for the inner circle of the annulus.\n    pub fn inner_resolution(mut self, resolution: u32) -> Self {\n        self.inner_resolution = resolution;\n        self\n    }\n}\n\nimpl<Config, Clear> GizmoPrimitive2d<Annulus> for GizmoBuffer<Config, Clear>\nwhere\n    Config: GizmoConfigGroup,\n    Clear: 'static + Send + Sync,\n{\n    type Output<'a>\n        = Annulus2dBuilder<'a, Config, Clear>\n    where\n        Self: 'a;\n\n    fn primitive_2d(\n        &mut self,\n        primitive: &Annulus,\n        isometry: impl Into<Isometry2d>,\n        color: impl Into<Color>,\n    ) -> Self::Output<'_> {\n        Annulus2dBuilder {\n            gizmos: self,\n            isometry: isometry.into(),\n            inner_radius: primitive.inner_circle.radius,\n            outer_radius: primitive.outer_circle.radius,\n            color: color.into(),\n            inner_resolution: crate::circles::DEFAULT_CIRCLE_RESOLUTION,\n            outer_resolution: crate::circles::DEFAULT_CIRCLE_RESOLUTION,\n        }\n    }\n}\n\nimpl<Config, Clear> Drop for Annulus2dBuilder<'_, Config, Clear>\nwhere\n    Config: GizmoConfigGroup,\n    Clear: 'static + Send + Sync,\n{\n    fn drop(&mut self) {\n        if !self.gizmos.enabled {\n            return;\n        }\n\n        let Annulus2dBuilder {\n            gizmos,\n            isometry,\n            inner_radius,\n            outer_radius,\n            inner_resolution,\n            outer_resolution,\n            color,\n            ..\n        } = self;\n\n        gizmos\n            .circle_2d(*isometry, *outer_radius, *color)\n            .resolution(*outer_resolution);\n        gizmos\n            .circle_2d(*isometry, *inner_radius, *color)\n            .resolution(*inner_resolution);\n    }\n}\n\n// rhombus 2d\n\nimpl<Config, Clear> GizmoPrimitive2d<Rhombus> for GizmoBuffer<Config, Clear>\nwhere\n    Config: GizmoConfigGroup,\n    Clear: 'static + Send + Sync,\n{\n    type Output<'a>\n        = ()\n    where\n        Self: 'a;\n\n    fn primitive_2d(\n        &mut self,\n        primitive: &Rhombus,\n        isometry: impl Into<Isometry2d>,\n        color: impl Into<Color>,\n    ) -> Self::Output<'_> {\n        if !self.enabled {\n            return;\n        };\n        let isometry = isometry.into();\n        let [a, b, c, d] =\n            [(1.0, 0.0), (0.0, 1.0), (-1.0, 0.0), (0.0, -1.0)].map(|(sign_x, sign_y)| {\n                Vec2::new(\n                    primitive.half_diagonals.x * sign_x,\n                    primitive.half_diagonals.y * sign_y,\n                )\n            });\n        let positions = [a, b, c, d, a].map(|vec2| isometry * vec2);\n        self.linestrip_2d(positions, color);\n    }\n}\n\n// capsule 2d\n\nimpl<Config, Clear> GizmoPrimitive2d<Capsule2d> for GizmoBuffer<Config, Clear>\nwhere\n    Config: GizmoConfigGroup,\n    Clear: 'static + Send + Sync,\n{\n    type Output<'a>\n        = ()\n    where\n        Self: 'a;\n\n    fn primitive_2d(\n        &mut self,\n        primitive: &Capsule2d,\n        isometry: impl Into<Isometry2d>,\n        color: impl Into<Color>,\n    ) -> Self::Output<'_> {\n        let isometry = isometry.into();\n        let polymorphic_color: Color = color.into();\n\n        if !self.enabled {\n            return;\n        }\n\n        // transform points from the reference unit square to capsule \"rectangle\"\n        let [top_left, top_right, bottom_left, bottom_right, top_center, bottom_center] = [\n            [-1.0, 1.0],\n            [1.0, 1.0],\n            [-1.0, -1.0],\n            [1.0, -1.0],\n            // just reuse the pipeline for these points as well\n            [0.0, 1.0],\n            [0.0, -1.0],\n        ]\n        .map(|[sign_x, sign_y]| Vec2::X * sign_x + Vec2::Y * sign_y)\n        .map(|reference_point| {\n            let scaling = Vec2::X * primitive.radius + Vec2::Y * primitive.half_length;\n            reference_point * scaling\n        })\n        .map(|vec2| isometry * vec2);\n\n        // draw left and right side of capsule \"rectangle\"\n        self.line_2d(bottom_left, top_left, polymorphic_color);\n        self.line_2d(bottom_right, top_right, polymorphic_color);\n\n        let start_angle_top = isometry.rotation.as_radians() - FRAC_PI_2;\n        let start_angle_bottom = isometry.rotation.as_radians() + FRAC_PI_2;\n\n        // draw arcs\n        self.arc_2d(\n            Isometry2d::new(top_center, Rot2::radians(start_angle_top)),\n            PI,\n            primitive.radius,\n            polymorphic_color,\n        );\n        self.arc_2d(\n            Isometry2d::new(bottom_center, Rot2::radians(start_angle_bottom)),\n            PI,\n            primitive.radius,\n            polymorphic_color,\n        );\n    }\n}\n\n// line 2d\n//\n/// Builder for configuring the drawing options of [`Line2d`].\npub struct Line2dBuilder<'a, Config, Clear>\nwhere\n    Config: GizmoConfigGroup,\n    Clear: 'static + Send + Sync,\n{\n    gizmos: &'a mut GizmoBuffer<Config, Clear>,\n\n    direction: Dir2, // Direction of the line\n\n    isometry: Isometry2d,\n    color: Color, // color of the line\n\n    draw_arrow: bool, // decides whether to indicate the direction of the line with an arrow\n}\n\nimpl<Config, Clear> Line2dBuilder<'_, Config, Clear>\nwhere\n    Config: GizmoConfigGroup,\n    Clear: 'static + Send + Sync,\n{\n    /// Set the drawing mode of the line (arrow vs. plain line)\n    pub fn draw_arrow(mut self, is_enabled: bool) -> Self {\n        self.draw_arrow = is_enabled;\n        self\n    }\n}\n\nimpl<Config, Clear> GizmoPrimitive2d<Line2d> for GizmoBuffer<Config, Clear>\nwhere\n    Config: GizmoConfigGroup,\n    Clear: 'static + Send + Sync,\n{\n    type Output<'a>\n        = Line2dBuilder<'a, Config, Clear>\n    where\n        Self: 'a;\n\n    fn primitive_2d(\n        &mut self,\n        primitive: &Line2d,\n        isometry: impl Into<Isometry2d>,\n        color: impl Into<Color>,\n    ) -> Self::Output<'_> {\n        Line2dBuilder {\n            gizmos: self,\n            direction: primitive.direction,\n            isometry: isometry.into(),\n            color: color.into(),\n            draw_arrow: false,\n        }\n    }\n}\n\nimpl<Config, Clear> Drop for Line2dBuilder<'_, Config, Clear>\nwhere\n    Config: GizmoConfigGroup,\n    Clear: 'static + Send + Sync,\n{\n    fn drop(&mut self) {\n        if !self.gizmos.enabled {\n            return;\n        }\n\n        let [start, end] = [1.0, -1.0]\n            .map(|sign| sign * INFINITE_LEN)\n            // offset the line from the origin infinitely into the given direction\n            .map(|length| self.direction * length)\n            // transform the line with the given isometry\n            .map(|offset| self.isometry * offset);\n\n        self.gizmos.line_2d(start, end, self.color);\n\n        // optionally draw an arrow head at the center of the line\n        if self.draw_arrow {\n            self.gizmos.arrow_2d(\n                self.isometry * (-self.direction * MIN_LINE_LEN),\n                self.isometry * Vec2::ZERO,\n                self.color,\n            );\n        }\n    }\n}\n\n// plane 2d\n\nimpl<Config, Clear> GizmoPrimitive2d<Plane2d> for GizmoBuffer<Config, Clear>\nwhere\n    Config: GizmoConfigGroup,\n    Clear: 'static + Send + Sync,\n{\n    type Output<'a>\n        = ()\n    where\n        Self: 'a;\n\n    fn primitive_2d(\n        &mut self,\n        primitive: &Plane2d,\n        isometry: impl Into<Isometry2d>,\n        color: impl Into<Color>,\n    ) -> Self::Output<'_> {\n        let isometry = isometry.into();\n        let polymorphic_color: Color = color.into();\n\n        if !self.enabled {\n            return;\n        }\n        // draw normal of the plane (orthogonal to the plane itself)\n        let normal = primitive.normal;\n        let normal_segment = Segment2d {\n            direction: normal,\n            half_length: HALF_MIN_LINE_LEN,\n        };\n        self.primitive_2d(\n            &normal_segment,\n            // offset the normal so it starts on the plane line\n            Isometry2d::new(isometry * (HALF_MIN_LINE_LEN * normal), isometry.rotation),\n            polymorphic_color,\n        )\n        .draw_arrow(true);\n\n        // draw the plane line\n        let direction = Dir2::new_unchecked(-normal.perp());\n        self.primitive_2d(&Line2d { direction }, isometry, polymorphic_color)\n            .draw_arrow(false);\n\n        // draw an arrow such that the normal is always left side of the plane with respect to the\n        // planes direction. This is to follow the \"counter-clockwise\" convention\n        self.arrow_2d(\n            isometry * Vec2::ZERO,\n            isometry * (MIN_LINE_LEN * direction),\n            polymorphic_color,\n        );\n    }\n}\n\n// segment 2d\n\n/// Builder for configuring the drawing options of [`Segment2d`].\npub struct Segment2dBuilder<'a, Config, Clear>\nwhere\n    Config: GizmoConfigGroup,\n    Clear: 'static + Send + Sync,\n{\n    gizmos: &'a mut GizmoBuffer<Config, Clear>,\n\n    direction: Dir2,  // Direction of the line segment\n    half_length: f32, // Half-length of the line segment\n\n    isometry: Isometry2d, // isometric transformation of the line segment\n    color: Color,         // color of the line segment\n\n    draw_arrow: bool, // decides whether to draw just a line or an arrow\n}\n\nimpl<Config, Clear> Segment2dBuilder<'_, Config, Clear>\nwhere\n    Config: GizmoConfigGroup,\n    Clear: 'static + Send + Sync,\n{\n    /// Set the drawing mode of the line (arrow vs. plain line)\n    pub fn draw_arrow(mut self, is_enabled: bool) -> Self {\n        self.draw_arrow = is_enabled;\n        self\n    }\n}\n\nimpl<Config, Clear> GizmoPrimitive2d<Segment2d> for GizmoBuffer<Config, Clear>\nwhere\n    Config: GizmoConfigGroup,\n    Clear: 'static + Send + Sync,\n{\n    type Output<'a>\n        = Segment2dBuilder<'a, Config, Clear>\n    where\n        Self: 'a;\n\n    fn primitive_2d(\n        &mut self,\n        primitive: &Segment2d,\n        isometry: impl Into<Isometry2d>,\n        color: impl Into<Color>,\n    ) -> Self::Output<'_> {\n        Segment2dBuilder {\n            gizmos: self,\n            direction: primitive.direction,\n            half_length: primitive.half_length,\n\n            isometry: isometry.into(),\n            color: color.into(),\n\n            draw_arrow: Default::default(),\n        }\n    }\n}\n\nimpl<Config, Clear> Drop for Segment2dBuilder<'_, Config, Clear>\nwhere\n    Config: GizmoConfigGroup,\n    Clear: 'static + Send + Sync,\n{\n    fn drop(&mut self) {\n        if !self.gizmos.enabled {\n            return;\n        }\n\n        let direction = self.direction * self.half_length;\n        let start = self.isometry * (-direction);\n        let end = self.isometry * direction;\n\n        if self.draw_arrow {\n            self.gizmos.arrow_2d(start, end, self.color);\n        } else {\n            self.gizmos.line_2d(start, end, self.color);\n        }\n    }\n}\n\n// polyline 2d\n\nimpl<const N: usize, Config, Clear> GizmoPrimitive2d<Polyline2d<N>> for GizmoBuffer<Config, Clear>\nwhere\n    Config: GizmoConfigGroup,\n    Clear: 'static + Send + Sync,\n{\n    type Output<'a>\n        = ()\n    where\n        Self: 'a;\n\n    fn primitive_2d(\n        &mut self,\n        primitive: &Polyline2d<N>,\n        isometry: impl Into<Isometry2d>,\n        color: impl Into<Color>,\n    ) -> Self::Output<'_> {\n        if !self.enabled {\n            return;\n        }\n\n        let isometry = isometry.into();\n\n        self.linestrip_2d(\n            primitive\n                .vertices\n                .iter()\n                .copied()\n                .map(|vec2| isometry * vec2),\n            color,\n        );\n    }\n}\n\n// boxed polyline 2d\n\nimpl<Config, Clear> GizmoPrimitive2d<BoxedPolyline2d> for GizmoBuffer<Config, Clear>\nwhere\n    Config: GizmoConfigGroup,\n    Clear: 'static + Send + Sync,\n{\n    type Output<'a>\n        = ()\n    where\n        Self: 'a;\n\n    fn primitive_2d(\n        &mut self,\n        primitive: &BoxedPolyline2d,\n        isometry: impl Into<Isometry2d>,\n        color: impl Into<Color>,\n    ) -> Self::Output<'_> {\n        if !self.enabled {\n            return;\n        }\n\n        let isometry = isometry.into();\n\n        self.linestrip_2d(\n            primitive\n                .vertices\n                .iter()\n                .copied()\n                .map(|vec2| isometry * vec2),\n            color,\n        );\n    }\n}\n\n// triangle 2d\n\nimpl<Config, Clear> GizmoPrimitive2d<Triangle2d> for GizmoBuffer<Config, Clear>\nwhere\n    Config: GizmoConfigGroup,\n    Clear: 'static + Send + Sync,\n{\n    type Output<'a>\n        = ()\n    where\n        Self: 'a;\n\n    fn primitive_2d(\n        &mut self,\n        primitive: &Triangle2d,\n        isometry: impl Into<Isometry2d>,\n        color: impl Into<Color>,\n    ) -> Self::Output<'_> {\n        if !self.enabled {\n            return;\n        }\n\n        let isometry = isometry.into();\n\n        let [a, b, c] = primitive.vertices;\n        let positions = [a, b, c, a].map(|vec2| isometry * vec2);\n        self.linestrip_2d(positions, color);\n    }\n}\n\n// rectangle 2d\n\nimpl<Config, Clear> GizmoPrimitive2d<Rectangle> for GizmoBuffer<Config, Clear>\nwhere\n    Config: GizmoConfigGroup,\n    Clear: 'static + Send + Sync,\n{\n    type Output<'a>\n        = ()\n    where\n        Self: 'a;\n\n    fn primitive_2d(\n        &mut self,\n        primitive: &Rectangle,\n        isometry: impl Into<Isometry2d>,\n        color: impl Into<Color>,\n    ) -> Self::Output<'_> {\n        if !self.enabled {\n            return;\n        }\n\n        let isometry = isometry.into();\n\n        let [a, b, c, d] =\n            [(1.0, 1.0), (1.0, -1.0), (-1.0, -1.0), (-1.0, 1.0)].map(|(sign_x, sign_y)| {\n                Vec2::new(\n                    primitive.half_size.x * sign_x,\n                    primitive.half_size.y * sign_y,\n                )\n            });\n        let positions = [a, b, c, d, a].map(|vec2| isometry * vec2);\n        self.linestrip_2d(positions, color);\n    }\n}\n\n// polygon 2d\n\nimpl<const N: usize, Config, Clear> GizmoPrimitive2d<Polygon<N>> for GizmoBuffer<Config, Clear>\nwhere\n    Config: GizmoConfigGroup,\n    Clear: 'static + Send + Sync,\n{\n    type Output<'a>\n        = ()\n    where\n        Self: 'a;\n\n    fn primitive_2d(\n        &mut self,\n        primitive: &Polygon<N>,\n        isometry: impl Into<Isometry2d>,\n        color: impl Into<Color>,\n    ) -> Self::Output<'_> {\n        if !self.enabled {\n            return;\n        }\n\n        let isometry = isometry.into();\n\n        // Check if the polygon needs a closing point\n        let closing_point = {\n            let first = primitive.vertices.first();\n            (primitive.vertices.last() != first)\n                .then_some(first)\n                .flatten()\n                .cloned()\n        };\n\n        self.linestrip_2d(\n            primitive\n                .vertices\n                .iter()\n                .copied()\n                .chain(closing_point)\n                .map(|vec2| isometry * vec2),\n            color,\n        );\n    }\n}\n\n// boxed polygon 2d\n\nimpl<Config, Clear> GizmoPrimitive2d<BoxedPolygon> for GizmoBuffer<Config, Clear>\nwhere\n    Config: GizmoConfigGroup,\n    Clear: 'static + Send + Sync,\n{\n    type Output<'a>\n        = ()\n    where\n        Self: 'a;\n\n    fn primitive_2d(\n        &mut self,\n        primitive: &BoxedPolygon,\n        isometry: impl Into<Isometry2d>,\n        color: impl Into<Color>,\n    ) -> Self::Output<'_> {\n        if !self.enabled {\n            return;\n        }\n\n        let isometry = isometry.into();\n\n        let closing_point = {\n            let first = primitive.vertices.first();\n            (primitive.vertices.last() != first)\n                .then_some(first)\n                .flatten()\n                .cloned()\n        };\n        self.linestrip_2d(\n            primitive\n                .vertices\n                .iter()\n                .copied()\n                .chain(closing_point)\n                .map(|vec2| isometry * vec2),\n            color,\n        );\n    }\n}\n\n// regular polygon 2d\n\nimpl<Config, Clear> GizmoPrimitive2d<RegularPolygon> for GizmoBuffer<Config, Clear>\nwhere\n    Config: GizmoConfigGroup,\n    Clear: 'static + Send + Sync,\n{\n    type Output<'a>\n        = ()\n    where\n        Self: 'a;\n\n    fn primitive_2d(\n        &mut self,\n        primitive: &RegularPolygon,\n        isometry: impl Into<Isometry2d>,\n        color: impl Into<Color>,\n    ) -> Self::Output<'_> {\n        if !self.enabled {\n            return;\n        }\n\n        let isometry = isometry.into();\n\n        let points = (0..=primitive.sides)\n            .map(|n| single_circle_coordinate(primitive.circumcircle.radius, primitive.sides, n))\n            .map(|vec2| isometry * vec2);\n        self.linestrip_2d(points, color);\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "9f57e014029c7668e18435cd5564ef43447eb77e",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_animation/src/animation_curves.rs",
    "func": "//! The [`AnimationCurve`] trait and adaptors that allow curves to implement it.\n//!\n//! # Overview\n//!\n//! The flow of curves into the animation system generally begins with something that\n//! implements the [`Curve`] trait. Let's imagine, for example, that we have some\n//! `Curve<Vec3>` that we want to use to animate something. That could be defined in\n//! a number of different ways, but let's imagine that we've defined it [using a function]:\n//!\n//!     # use bevy_math::curve::{Curve, Interval, FunctionCurve};\n//!     # use bevy_math::vec3;\n//!     let wobble_curve = FunctionCurve::new(\n//!         Interval::UNIT,\n//!         |t| { vec3(t.cos(), 0.0, 0.0) },\n//!     );\n//!\n//! Okay, so we have a curve, but the animation system also needs to know, in some way,\n//! how the values from this curve should actually be used. That is, it needs to know what\n//! to animate! That's what [`AnimationCurve`] is for. In particular, what we need to do\n//! is take our curve and turn it into an `AnimationCurve` which will be usable by the\n//! animation system.\n//!\n//! For instance, let's imagine that we want to use the `Vec3` output\n//! from our curve to animate the [translation component of a `Transform`]. For this, there is\n//! the adaptor [`AnimatableCurve`], which wraps any [`Curve`] and [`AnimatableProperty`] and turns it into an\n//! [`AnimationCurve`] that will use the given curve to animate the entity's property:\n//!\n//!     # use bevy_math::curve::{Curve, Interval, FunctionCurve};\n//!     # use bevy_math::vec3;\n//!     # use bevy_transform::components::Transform;\n//!     # use bevy_animation::{animated_field, animation_curves::*};\n//!     # let wobble_curve = FunctionCurve::new(\n//!     #     Interval::UNIT,\n//!     #     |t| vec3(t.cos(), 0.0, 0.0)\n//!     # );\n//!     let wobble_animation = AnimatableCurve::new(animated_field!(Transform::translation), wobble_curve);\n//!\n//! And finally, this [`AnimationCurve`] needs to be added to an [`AnimationClip`] in order to\n//! actually animate something. This is what that looks like:\n//!\n//!     # use bevy_math::curve::{Curve, Interval, FunctionCurve};\n//!     # use bevy_animation::{AnimationClip, AnimationTargetId, animated_field, animation_curves::*};\n//!     # use bevy_transform::components::Transform;\n//!     # use bevy_core::Name;\n//!     # use bevy_math::vec3;\n//!     # let wobble_curve = FunctionCurve::new(\n//!     #     Interval::UNIT,\n//!     #     |t| { vec3(t.cos(), 0.0, 0.0) },\n//!     # );\n//!     # let wobble_animation = AnimatableCurve::new(animated_field!(Transform::translation), wobble_curve);\n//!     # let animation_target_id = AnimationTargetId::from(&Name::new(\"Test\"));\n//!     let mut animation_clip = AnimationClip::default();\n//!     animation_clip.add_curve_to_target(\n//!         animation_target_id,\n//!         wobble_animation,\n//!     );\n//!\n//! # Making animation curves\n//!\n//! The overview showed one example, but in general there are a few different ways of going from\n//! a [`Curve`], which produces time-related data of some kind, to an [`AnimationCurve`], which\n//! knows how to apply that data to an entity.\n//!\n//! ## Animated Fields\n//!\n//! The [`animated_field`] macro (which returns an [`AnimatedField`]), in combination with [`AnimatableCurve`]\n//! is the easiest way to make an animation curve (see the example above).\n//!\n//! This will select a field on a component and pass it to a [`Curve`] with a type that matches the field.\n//!\n//! ## Animatable Properties\n//!\n//! Animation of arbitrary aspects of entities can be accomplished using [`AnimatableProperty`] in\n//! conjunction with [`AnimatableCurve`]. See the documentation [there] for details.\n//!\n//! ## Custom [`AnimationCurve`] and [`AnimationCurveEvaluator`]\n//!\n//! This is the lowest-level option with the most control, but it is also the most complicated.\n//!\n//! [using a function]: bevy_math::curve::FunctionCurve\n//! [translation component of a `Transform`]: bevy_transform::prelude::Transform::translation\n//! [`AnimationClip`]: crate::AnimationClip\n//! [there]: AnimatableProperty\n//! [`animated_field`]: crate::animated_field\n\nuse core::{\n    any::TypeId,\n    fmt::{self, Debug, Formatter},\n    marker::PhantomData,\n};\n\nuse bevy_ecs::component::{Component, Mutable};\nuse bevy_math::curve::{\n    cores::{UnevenCore, UnevenCoreError},\n    iterable::IterableCurve,\n    Curve, Interval,\n};\nuse bevy_reflect::{FromReflect, Reflect, Reflectable, TypeInfo, Typed};\nuse bevy_render::mesh::morph::MorphWeights;\n\nuse crate::{\n    graph::AnimationNodeIndex,\n    prelude::{Animatable, BlendInput},\n    AnimationEntityMut, AnimationEvaluationError,\n};\nuse bevy_utils::Hashed;\nuse downcast_rs::{impl_downcast, Downcast};\n\n/// A value on a component that Bevy can animate.\n///\n/// You can implement this trait on a unit struct in order to support animating\n/// custom components other than transforms and morph weights. Use that type in\n/// conjunction with [`AnimatableCurve`] (and perhaps [`AnimatableKeyframeCurve`]\n/// to define the animation itself).\n/// For example, in order to animate field of view, you might use:\n///\n///     # use bevy_animation::{prelude::AnimatableProperty, AnimationEntityMut, AnimationEvaluationError, animation_curves::EvaluatorId};\n///     # use bevy_reflect::Reflect;\n///     # use std::any::TypeId;\n///     # use bevy_render::camera::PerspectiveProjection;\n///     #[derive(Reflect)]\n///     struct FieldOfViewProperty;\n///\n///     impl AnimatableProperty for FieldOfViewProperty {\n///         type Property = f32;\n///         fn get_mut<'a>(&self, entity: &'a mut AnimationEntityMut) -> Result<&'a mut Self::Property, AnimationEvaluationError> {\n///            let component = entity\n///                .get_mut::<PerspectiveProjection>()\n///                .ok_or(\n///                     AnimationEvaluationError::ComponentNotPresent(\n///                         TypeId::of::<PerspectiveProjection>()\n///                    )\n///                 )?\n///                 .into_inner();\n///             Ok(&mut component.fov)\n///         }\n///\n///         fn evaluator_id(&self) -> EvaluatorId {\n///             EvaluatorId::Type(TypeId::of::<Self>())\n///         }\n///     }\n///\n/// You can then create an [`AnimationClip`] to animate this property like so:\n///\n///     # use bevy_animation::{AnimationClip, AnimationTargetId, VariableCurve, AnimationEntityMut, AnimationEvaluationError, animation_curves::EvaluatorId};\n///     # use bevy_animation::prelude::{AnimatableProperty, AnimatableKeyframeCurve, AnimatableCurve};\n///     # use bevy_core::Name;\n///     # use bevy_reflect::Reflect;\n///     # use bevy_render::camera::PerspectiveProjection;\n///     # use std::any::TypeId;\n///     # let animation_target_id = AnimationTargetId::from(&Name::new(\"Test\"));\n///     # #[derive(Reflect, Clone)]\n///     # struct FieldOfViewProperty;\n///     # impl AnimatableProperty for FieldOfViewProperty {\n///     #    type Property = f32;\n///     #    fn get_mut<'a>(&self, entity: &'a mut AnimationEntityMut) -> Result<&'a mut Self::Property, AnimationEvaluationError> {\n///     #       let component = entity\n///     #           .get_mut::<PerspectiveProjection>()\n///     #           .ok_or(\n///     #                AnimationEvaluationError::ComponentNotPresent(\n///     #                    TypeId::of::<PerspectiveProjection>()\n///     #               )\n///     #            )?\n///     #            .into_inner();\n///     #        Ok(&mut component.fov)\n///     #    }\n///     #    fn evaluator_id(&self) -> EvaluatorId {\n///     #        EvaluatorId::Type(TypeId::of::<Self>())\n///     #    }\n///     # }\n///     let mut animation_clip = AnimationClip::default();\n///     animation_clip.add_curve_to_target(\n///         animation_target_id,\n///         AnimatableCurve::new(\n///             FieldOfViewProperty,\n///             AnimatableKeyframeCurve::new([\n///                 (0.0, core::f32::consts::PI / 4.0),\n///                 (1.0, core::f32::consts::PI / 3.0),\n///             ]).expect(\"Failed to create font size curve\")\n///         )\n///     );\n///\n/// Here, the use of [`AnimatableKeyframeCurve`] creates a curve out of the given keyframe time-value\n/// pairs, using the [`Animatable`] implementation of `f32` to interpolate between them. The\n/// invocation of [`AnimatableCurve::new`] with `FieldOfViewProperty` indicates that the `f32`\n/// output from that curve is to be used to animate the font size of a `PerspectiveProjection` component (as\n/// configured above).\n///\n/// [`AnimationClip`]: crate::AnimationClip\npub trait AnimatableProperty: Send + Sync + 'static {\n    /// The animated property type.\n    type Property: Animatable;\n\n    /// Retrieves the property from the given `entity`.\n    fn get_mut<'a>(\n        &self,\n        entity: &'a mut AnimationEntityMut,\n    ) -> Result<&'a mut Self::Property, AnimationEvaluationError>;\n\n    /// The [`EvaluatorId`] used to look up the [`AnimationCurveEvaluator`] for this [`AnimatableProperty`].\n    /// For a given animated property, this ID should always be the same to allow things like animation blending to occur.\n    fn evaluator_id(&self) -> EvaluatorId;\n}\n\n/// A [`Component`] field that can be animated, defined by a function that reads the component and returns\n/// the accessed field / property.\n///\n/// The best way to create an instance of this type is via the [`animated_field`] macro.\n///\n/// `C` is the component being animated, `A` is the type of the [`Animatable`] field on the component, and `F` is an accessor\n/// function that accepts a reference to `C` and retrieves the field `A`.\n///\n/// [`animated_field`]: crate::animated_field\n#[derive(Clone)]\npub struct AnimatedField<C, A, F: Fn(&mut C) -> &mut A> {\n    func: F,\n    /// A pre-hashed (component-type-id, reflected-field-index) pair, uniquely identifying a component field\n    evaluator_id: Hashed<(TypeId, usize)>,\n    marker: PhantomData<(C, A)>,\n}\n\nimpl<C, A, F> AnimatableProperty for AnimatedField<C, A, F>\nwhere\n    C: Component<Mutability = Mutable>,\n    A: Animatable + Clone + Sync + Debug,\n    F: Fn(&mut C) -> &mut A + Send + Sync + 'static,\n{\n    type Property = A;\n    fn get_mut<'a>(\n        &self,\n        entity: &'a mut AnimationEntityMut,\n    ) -> Result<&'a mut A, AnimationEvaluationError> {\n        let c = entity\n            .get_mut::<C>()\n            .ok_or_else(|| AnimationEvaluationError::ComponentNotPresent(TypeId::of::<C>()))?;\n        Ok((self.func)(c.into_inner()))\n    }\n\n    fn evaluator_id(&self) -> EvaluatorId {\n        EvaluatorId::ComponentField(&self.evaluator_id)\n    }\n}\n\nimpl<C: Typed, P, F: Fn(&mut C) -> &mut P + 'static> AnimatedField<C, P, F> {\n    /// Creates a new instance of [`AnimatedField`]. This operates under the assumption that\n    /// `C` is a reflect-able struct with named fields, and that `field_name` is a valid field on that struct.\n    ///\n    /// # Panics\n    /// If the type of `C` is not a struct with named fields or if the `field_name` does not exist.\n    pub fn new_unchecked(field_name: &str, func: F) -> Self {\n        let TypeInfo::Struct(struct_info) = C::type_info() else {\n            panic!(\"Only structs are supported in `AnimatedField::new_unchecked`\")\n        };\n\n        let field_index = struct_info\n            .index_of(field_name)\n            .expect(\"Field name should exist\");\n\n        Self {\n            func,\n            evaluator_id: Hashed::new((TypeId::of::<C>(), field_index)),\n            marker: PhantomData,\n        }\n    }\n}\n\n/// This trait collects the additional requirements on top of [`Curve<T>`] needed for a\n/// curve to be used as an [`AnimationCurve`].\npub trait AnimationCompatibleCurve<T>: Curve<T> + Debug + Clone + Reflectable {}\n\nimpl<T, C> AnimationCompatibleCurve<T> for C where C: Curve<T> + Debug + Clone + Reflectable {}\n\n/// This type allows the conversion of a [curve] valued in the [property type] of an\n/// [`AnimatableProperty`] into an [`AnimationCurve`] which animates that property.\n///\n/// [curve]: Curve\n/// [property type]: AnimatableProperty::Property\n#[derive(Reflect, FromReflect)]\n#[reflect(from_reflect = false)]\npub struct AnimatableCurve<P, C> {\n    /// The property selector, which defines what component to access and how to access\n    /// a property on that component.\n    pub property: P,\n\n    /// The inner [curve] whose values are used to animate the property.\n    ///\n    /// [curve]: Curve\n    pub curve: C,\n}\n\n/// An [`AnimatableCurveEvaluator`] for [`AnimatableProperty`] instances.\n///\n/// You shouldn't ordinarily need to instantiate one of these manually. Bevy\n/// will automatically do so when you use an [`AnimatableCurve`] instance.\n#[derive(Reflect)]\npub struct AnimatableCurveEvaluator<A: Animatable> {\n    evaluator: BasicAnimationCurveEvaluator<A>,\n    property: Box<dyn AnimatableProperty<Property = A>>,\n}\n\nimpl<P, C> AnimatableCurve<P, C>\nwhere\n    P: AnimatableProperty,\n    C: AnimationCompatibleCurve<P::Property>,\n{\n    /// Create an [`AnimatableCurve`] (and thus an [`AnimationCurve`]) from a curve\n    /// valued in an [animatable property].\n    ///\n    /// [animatable property]: AnimatableProperty::Property\n    pub fn new(property: P, curve: C) -> Self {\n        Self { property, curve }\n    }\n}\n\nimpl<P, C> Clone for AnimatableCurve<P, C>\nwhere\n    C: Clone,\n    P: Clone,\n{\n    fn clone(&self) -> Self {\n        Self {\n            curve: self.curve.clone(),\n            property: self.property.clone(),\n        }\n    }\n}\n\nimpl<P, C> Debug for AnimatableCurve<P, C>\nwhere\n    C: Debug,\n{\n    fn fmt(&self, f: &mut Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"AnimatableCurve\")\n            .field(\"curve\", &self.curve)\n            .finish()\n    }\n}\n\nimpl<P: Send + Sync + 'static, C> AnimationCurve for AnimatableCurve<P, C>\nwhere\n    P: AnimatableProperty + Clone,\n    C: AnimationCompatibleCurve<P::Property> + Clone,\n{\n    fn clone_value(&self) -> Box<dyn AnimationCurve> {\n        Box::new(self.clone())\n    }\n\n    fn domain(&self) -> Interval {\n        self.curve.domain()\n    }\n\n    fn evaluator_id(&self) -> EvaluatorId {\n        self.property.evaluator_id()\n    }\n\n    fn create_evaluator(&self) -> Box<dyn AnimationCurveEvaluator> {\n        Box::new(AnimatableCurveEvaluator::<P::Property> {\n            evaluator: BasicAnimationCurveEvaluator::default(),\n            property: Box::new(self.property.clone()),\n        })\n    }\n\n    fn apply(\n        &self,\n        curve_evaluator: &mut dyn AnimationCurveEvaluator,\n        t: f32,\n        weight: f32,\n        graph_node: AnimationNodeIndex,\n    ) -> Result<(), AnimationEvaluationError> {\n        let curve_evaluator = curve_evaluator\n            .downcast_mut::<AnimatableCurveEvaluator<P::Property>>()\n            .unwrap();\n        let value = self.curve.sample_clamped(t);\n        curve_evaluator\n            .evaluator\n            .stack\n            .push(BasicAnimationCurveEvaluatorStackElement {\n                value,\n                weight,\n                graph_node,\n            });\n        Ok(())\n    }\n}\n\nimpl<A: Animatable> AnimationCurveEvaluator for AnimatableCurveEvaluator<A> {\n    fn blend(&mut self, graph_node: AnimationNodeIndex) -> Result<(), AnimationEvaluationError> {\n        self.evaluator.combine(graph_node, /*additive=*/ false)\n    }\n\n    fn add(&mut self, graph_node: AnimationNodeIndex) -> Result<(), AnimationEvaluationError> {\n        self.evaluator.combine(graph_node, /*additive=*/ true)\n    }\n\n    fn push_blend_register(\n        &mut self,\n        weight: f32,\n        graph_node: AnimationNodeIndex,\n    ) -> Result<(), AnimationEvaluationError> {\n        self.evaluator.push_blend_register(weight, graph_node)\n    }\n\n    fn commit<'a>(\n        &mut self,\n        mut entity: AnimationEntityMut<'a>,\n    ) -> Result<(), AnimationEvaluationError> {\n        let property = self.property.get_mut(&mut entity)?;\n        *property = self\n            .evaluator\n            .stack\n            .pop()\n            .ok_or_else(inconsistent::<AnimatableCurveEvaluator<A>>)?\n            .value;\n        Ok(())\n    }\n}\n\n/// This type allows an [`IterableCurve`] valued in `f32` to be used as an [`AnimationCurve`]\n/// that animates [morph weights].\n///\n/// [morph weights]: MorphWeights\n#[derive(Debug, Clone, Reflect, FromReflect)]\n#[reflect(from_reflect = false)]\npub struct WeightsCurve<C>(pub C);\n\n#[derive(Reflect)]\nstruct WeightsCurveEvaluator {\n    /// The values of the stack, in which each element is a list of morph target\n    /// weights.\n    ///\n    /// The stack elements are concatenated and tightly packed together.\n    ///\n    /// The number of elements in this stack will always be a multiple of\n    /// [`Self::morph_target_count`].\n    stack_morph_target_weights: Vec<f32>,\n\n    /// The blend weights and graph node indices for each element of the stack.\n    ///\n    /// This should have as many elements as there are stack nodes. In other\n    /// words, `Self::stack_morph_target_weights.len() *\n    /// Self::morph_target_counts as usize ==\n    /// Self::stack_blend_weights_and_graph_nodes`.\n    stack_blend_weights_and_graph_nodes: Vec<(f32, AnimationNodeIndex)>,\n\n    /// The morph target weights in the blend register, if any.\n    ///\n    /// This field should be ignored if [`Self::blend_register_blend_weight`] is\n    /// `None`. If non-empty, it will always have [`Self::morph_target_count`]\n    /// elements in it.\n    blend_register_morph_target_weights: Vec<f32>,\n\n    /// The weight in the blend register.\n    ///\n    /// This will be `None` if the blend register is empty. In that case,\n    /// [`Self::blend_register_morph_target_weights`] will be empty.\n    blend_register_blend_weight: Option<f32>,\n\n    /// The number of morph targets that are to be animated.\n    morph_target_count: Option<u32>,\n}\n\nimpl<C> AnimationCurve for WeightsCurve<C>\nwhere\n    C: IterableCurve<f32> + Debug + Clone + Reflectable,\n{\n    fn clone_value(&self) -> Box<dyn AnimationCurve> {\n        Box::new(self.clone())\n    }\n\n    fn domain(&self) -> Interval {\n        self.0.domain()\n    }\n\n    fn evaluator_id(&self) -> EvaluatorId {\n        EvaluatorId::Type(TypeId::of::<WeightsCurveEvaluator>())\n    }\n\n    fn create_evaluator(&self) -> Box<dyn AnimationCurveEvaluator> {\n        Box::new(WeightsCurveEvaluator {\n            stack_morph_target_weights: vec![],\n            stack_blend_weights_and_graph_nodes: vec![],\n            blend_register_morph_target_weights: vec![],\n            blend_register_blend_weight: None,\n            morph_target_count: None,\n        })\n    }\n\n    fn apply(\n        &self,\n        curve_evaluator: &mut dyn AnimationCurveEvaluator,\n        t: f32,\n        weight: f32,\n        graph_node: AnimationNodeIndex,\n    ) -> Result<(), AnimationEvaluationError> {\n        let curve_evaluator = curve_evaluator\n            .downcast_mut::<WeightsCurveEvaluator>()\n            .unwrap();\n\n        let prev_morph_target_weights_len = curve_evaluator.stack_morph_target_weights.len();\n        curve_evaluator\n            .stack_morph_target_weights\n            .extend(self.0.sample_iter_clamped(t));\n        curve_evaluator.morph_target_count = Some(\n            (curve_evaluator.stack_morph_target_weights.len() - prev_morph_target_weights_len)\n                as u32,\n        );\n\n        curve_evaluator\n            .stack_blend_weights_and_graph_nodes\n            .push((weight, graph_node));\n        Ok(())\n    }\n}\n\nimpl WeightsCurveEvaluator {\n    fn combine(\n        &mut self,\n        graph_node: AnimationNodeIndex,\n        additive: bool,\n    ) -> Result<(), AnimationEvaluationError> {\n        let Some(&(_, top_graph_node)) = self.stack_blend_weights_and_graph_nodes.last() else {\n            return Ok(());\n        };\n        if top_graph_node != graph_node {\n            return Ok(());\n        }\n\n        let (weight_to_blend, _) = self.stack_blend_weights_and_graph_nodes.pop().unwrap();\n        let stack_iter = self.stack_morph_target_weights.drain(\n            (self.stack_morph_target_weights.len() - self.morph_target_count.unwrap() as usize)..,\n        );\n\n        match self.blend_register_blend_weight {\n            None => {\n                self.blend_register_blend_weight = Some(weight_to_blend);\n                self.blend_register_morph_target_weights.clear();\n\n                // In the additive case, the values pushed onto the blend register need\n                // to be scaled by the weight.\n                if additive {\n                    self.blend_register_morph_target_weights\n                        .extend(stack_iter.map(|m| m * weight_to_blend));\n                } else {\n                    self.blend_register_morph_target_weights.extend(stack_iter);\n                }\n            }\n\n            Some(ref mut current_weight) => {\n                *current_weight += weight_to_blend;\n                for (dest, src) in self\n                    .blend_register_morph_target_weights\n                    .iter_mut()\n                    .zip(stack_iter)\n                {\n                    if additive {\n                        *dest += src * weight_to_blend;\n                    } else {\n                        *dest = f32::interpolate(dest, &src, weight_to_blend / *current_weight);\n                    }\n                }\n            }\n        }\n\n        Ok(())\n    }\n}\n\nimpl AnimationCurveEvaluator for WeightsCurveEvaluator {\n    fn blend(&mut self, graph_node: AnimationNodeIndex) -> Result<(), AnimationEvaluationError> {\n        self.combine(graph_node, /*additive=*/ false)\n    }\n\n    fn add(&mut self, graph_node: AnimationNodeIndex) -> Result<(), AnimationEvaluationError> {\n        self.combine(graph_node, /*additive=*/ true)\n    }\n\n    fn push_blend_register(\n        &mut self,\n        weight: f32,\n        graph_node: AnimationNodeIndex,\n    ) -> Result<(), AnimationEvaluationError> {\n        if self.blend_register_blend_weight.take().is_some() {\n            self.stack_morph_target_weights\n                .append(&mut self.blend_register_morph_target_weights);\n            self.stack_blend_weights_and_graph_nodes\n                .push((weight, graph_node));\n        }\n        Ok(())\n    }\n\n    fn commit<'a>(\n        &mut self,\n        mut entity: AnimationEntityMut<'a>,\n    ) -> Result<(), AnimationEvaluationError> {\n        if self.stack_morph_target_weights.is_empty() {\n            return Ok(());\n        }\n\n        // Compute the index of the first morph target in the last element of\n        // the stack.\n        let index_of_first_morph_target =\n            self.stack_morph_target_weights.len() - self.morph_target_count.unwrap() as usize;\n\n        for (dest, src) in entity\n            .get_mut::<MorphWeights>()\n            .ok_or_else(|| {\n                AnimationEvaluationError::ComponentNotPresent(TypeId::of::<MorphWeights>())\n            })?\n            .weights_mut()\n            .iter_mut()\n            .zip(self.stack_morph_target_weights[index_of_first_morph_target..].iter())\n        {\n            *dest = *src;\n        }\n        self.stack_morph_target_weights.clear();\n        self.stack_blend_weights_and_graph_nodes.clear();\n        Ok(())\n    }\n}\n\n#[derive(Reflect)]\nstruct BasicAnimationCurveEvaluator<A>\nwhere\n    A: Animatable,\n{\n    stack: Vec<BasicAnimationCurveEvaluatorStackElement<A>>,\n    blend_register: Option<(A, f32)>,\n}\n\n#[derive(Reflect)]\nstruct BasicAnimationCurveEvaluatorStackElement<A>\nwhere\n    A: Animatable,\n{\n    value: A,\n    weight: f32,\n    graph_node: AnimationNodeIndex,\n}\n\nimpl<A> Default for BasicAnimationCurveEvaluator<A>\nwhere\n    A: Animatable,\n{\n    fn default() -> Self {\n        BasicAnimationCurveEvaluator {\n            stack: vec![],\n            blend_register: None,\n        }\n    }\n}\n\nimpl<A> BasicAnimationCurveEvaluator<A>\nwhere\n    A: Animatable,\n{\n    fn combine(\n        &mut self,\n        graph_node: AnimationNodeIndex,\n        additive: bool,\n    ) -> Result<(), AnimationEvaluationError> {\n        let Some(top) = self.stack.last() else {\n            return Ok(());\n        };\n        if top.graph_node != graph_node {\n            return Ok(());\n        }\n\n        let BasicAnimationCurveEvaluatorStackElement {\n            value: value_to_blend,\n            weight: weight_to_blend,\n            graph_node: _,\n        } = self.stack.pop().unwrap();\n\n        match self.blend_register.take() {\n            None => {\n                self.initialize_blend_register(value_to_blend, weight_to_blend, additive);\n            }\n            Some((mut current_value, mut current_weight)) => {\n                current_weight += weight_to_blend;\n\n                if additive {\n                    current_value = A::blend(\n                        [\n                            BlendInput {\n                                weight: 1.0,\n                                value: current_value,\n                                additive: true,\n                            },\n                            BlendInput {\n                                weight: weight_to_blend,\n                                value: value_to_blend,\n                                additive: true,\n                            },\n                        ]\n                        .into_iter(),\n                    );\n                } else {\n                    current_value = A::interpolate(\n                        &current_value,\n                        &value_to_blend,\n                        weight_to_blend / current_weight,\n                    );\n                }\n\n                self.blend_register = Some((current_value, current_weight));\n            }\n        }\n\n        Ok(())\n    }\n\n    fn initialize_blend_register(&mut self, value: A, weight: f32, additive: bool) {\n        if additive {\n            let scaled_value = A::blend(\n                [BlendInput {\n                    weight,\n                    value,\n                    additive: true,\n                }]\n                .into_iter(),\n            );\n            self.blend_register = Some((scaled_value, weight));\n        } else {\n            self.blend_register = Some((value, weight));\n        }\n    }\n\n    fn push_blend_register(\n        &mut self,\n        weight: f32,\n        graph_node: AnimationNodeIndex,\n    ) -> Result<(), AnimationEvaluationError> {\n        if let Some((value, _)) = self.blend_register.take() {\n            self.stack.push(BasicAnimationCurveEvaluatorStackElement {\n                value,\n                weight,\n                graph_node,\n            });\n        }\n        Ok(())\n    }\n}\n\n/// A low-level trait that provides control over how curves are actually applied\n/// to entities by the animation system.\n///\n/// Typically, this will not need to be implemented manually, since it is\n/// automatically implemented by [`AnimatableCurve`] and other curves used by\n/// the animation system (e.g. those that animate parts of transforms or morph\n/// weights). However, this can be implemented manually when `AnimatableCurve`\n/// is not sufficiently expressive.\n///\n/// In many respects, this behaves like a type-erased form of [`Curve`], where\n/// the output type of the curve is remembered only in the components that are\n/// mutated in the implementation of [`apply`].\n///\n/// [`apply`]: AnimationCurve::apply\npub trait AnimationCurve: Debug + Send + Sync + 'static {\n    /// Returns a boxed clone of this value.\n    fn clone_value(&self) -> Box<dyn AnimationCurve>;\n\n    /// The range of times for which this animation is defined.\n    fn domain(&self) -> Interval;\n\n    /// Returns the type ID of the [`AnimationCurveEvaluator`].\n    ///\n    /// This must match the type returned by [`Self::create_evaluator`]. It must\n    /// be a single type that doesn't depend on the type of the curve.\n    fn evaluator_id(&self) -> EvaluatorId;\n\n    /// Returns a newly-instantiated [`AnimationCurveEvaluator`] for use with\n    /// this curve.\n    ///\n    /// All curve types must return the same type of\n    /// [`AnimationCurveEvaluator`]. The returned value must match the type\n    /// returned by [`Self::evaluator_id`].\n    fn create_evaluator(&self) -> Box<dyn AnimationCurveEvaluator>;\n\n    /// Samples the curve at the given time `t`, and pushes the sampled value\n    /// onto the evaluation stack of the `curve_evaluator`.\n    ///\n    /// The `curve_evaluator` parameter points to the value returned by\n    /// [`Self::create_evaluator`], upcast to an `&mut dyn\n    /// AnimationCurveEvaluator`. Typically, implementations of [`Self::apply`]\n    /// will want to downcast the `curve_evaluator` parameter to the concrete\n    /// type [`Self::evaluator_id`] in order to push values of the appropriate\n    /// type onto its evaluation stack.\n    ///\n    /// Be sure not to confuse the `t` and `weight` values. The former\n    /// determines the position at which the *curve* is sampled, while `weight`\n    /// ultimately determines how much the *stack values* will be blended\n    /// together (see the definition of [`AnimationCurveEvaluator::blend`]).\n    fn apply(\n        &self,\n        curve_evaluator: &mut dyn AnimationCurveEvaluator,\n        t: f32,\n        weight: f32,\n        graph_node: AnimationNodeIndex,\n    ) -> Result<(), AnimationEvaluationError>;\n}\n\n/// The [`EvaluatorId`] is used to look up the [`AnimationCurveEvaluator`] for an [`AnimatableProperty`].\n/// For a given animated property, this ID should always be the same to allow things like animation blending to occur.\n#[derive(Clone)]\npub enum EvaluatorId<'a> {\n    /// Corresponds to a specific field on a specific component type.\n    /// The `TypeId` should correspond to the component type, and the `usize`\n    /// should correspond to the Reflect-ed field index of the field.\n    //\n    // IMPLEMENTATION NOTE: The Hashed<(TypeId, usize) is intentionally cheap to clone, as it will be cloned per frame by the evaluator\n    // Switching the field index `usize` for something like a field name `String` would probably be too expensive to justify\n    ComponentField(&'a Hashed<(TypeId, usize)>),\n    /// Corresponds to a custom property of a given type. This should be the [`TypeId`]\n    /// of the custom [`AnimatableProperty`].\n    Type(TypeId),\n}\n\n/// A low-level trait for use in [`crate::VariableCurve`] that provides fine\n/// control over how animations are evaluated.\n///\n/// You can implement this trait when the generic [`AnimatableCurveEvaluator`]\n/// isn't sufficiently-expressive for your needs. For example, [`MorphWeights`]\n/// implements this trait instead of using [`AnimatableCurveEvaluator`] because\n/// it needs to animate arbitrarily many weights at once, which can't be done\n/// with [`Animatable`] as that works on fixed-size values only.\n///\n/// If you implement this trait, you should also implement [`AnimationCurve`] on\n/// your curve type, as that trait allows creating instances of this one.\n///\n/// Implementations of [`AnimatableCurveEvaluator`] should maintain a *stack* of\n/// (value, weight, node index) triples, as well as a *blend register*, which is\n/// either a (value, weight) pair or empty. *Value* here refers to an instance\n/// of the value being animated: for example, [`Vec3`] in the case of\n/// translation keyframes.  The stack stores intermediate values generated while\n/// evaluating the [`crate::graph::AnimationGraph`], while the blend register\n/// stores the result of a blend operation.\n///\n/// [`Vec3`]: bevy_math::Vec3\npub trait AnimationCurveEvaluator: Downcast + Send + Sync + 'static {\n    /// Blends the top element of the stack with the blend register.\n    ///\n    /// The semantics of this method are as follows:\n    ///\n    /// 1. Pop the top element of the stack. Call its value v\u2098 and its weight\n    ///    w\u2098. If the stack was empty, return success.\n    ///\n    /// 2. If the blend register is empty, set the blend register value to v\u2098\n    ///    and the blend register weight to w\u2098; then, return success.\n    ///\n    /// 3. If the blend register is nonempty, call its current value v\u2099 and its\n    ///    current weight w\u2099. Then, set the value of the blend register to\n    ///    `interpolate(v\u2099, v\u2098, w\u2098 / (w\u2098 + w\u2099))`, and set the weight of the blend\n    ///    register to w\u2098 + w\u2099.\n    ///\n    /// 4. Return success.\n    fn blend(&mut self, graph_node: AnimationNodeIndex) -> Result<(), AnimationEvaluationError>;\n\n    /// Additively blends the top element of the stack with the blend register.\n    ///\n    /// The semantics of this method are as follows:\n    ///\n    /// 1. Pop the top element of the stack. Call its value v\u2098 and its weight\n    ///    w\u2098. If the stack was empty, return success.\n    ///\n    /// 2. If the blend register is empty, set the blend register value to v\u2098\n    ///    and the blend register weight to w\u2098; then, return success.\n    ///\n    /// 3. If the blend register is nonempty, call its current value v\u2099.\n    ///    Then, set the value of the blend register to v\u2099 + v\u2098w\u2098.\n    ///\n    /// 4. Return success.\n    fn add(&mut self, graph_node: AnimationNodeIndex) -> Result<(), AnimationEvaluationError>;\n\n    /// Pushes the current value of the blend register onto the stack.\n    ///\n    /// If the blend register is empty, this method does nothing successfully.\n    /// Otherwise, this method pushes the current value of the blend register\n    /// onto the stack, alongside the weight and graph node supplied to this\n    /// function. The weight present in the blend register is discarded; only\n    /// the weight parameter to this function is pushed onto the stack. The\n    /// blend register is emptied after this process.\n    fn push_blend_register(\n        &mut self,\n        weight: f32,\n        graph_node: AnimationNodeIndex,\n    ) -> Result<(), AnimationEvaluationError>;\n\n    /// Pops the top value off the stack and writes it into the appropriate\n    /// component.\n    ///\n    /// If the stack is empty, this method does nothing successfully. Otherwise,\n    /// it pops the top value off the stack, fetches the associated component\n    /// from either the `transform` or `entity` values as appropriate, and\n    /// updates the appropriate property with the value popped from the stack.\n    /// The weight and node index associated with the popped stack element are\n    /// discarded. After doing this, the stack is emptied.\n    ///\n    /// The property on the component must be overwritten with the value from\n    /// the stack, not blended with it.\n    fn commit<'a>(\n        &mut self,\n        entity: AnimationEntityMut<'a>,\n    ) -> Result<(), AnimationEvaluationError>;\n}\n\nimpl_downcast!(AnimationCurveEvaluator);\n\n/// A [curve] defined by keyframes with values in an [animatable] type.\n///\n/// The keyframes are interpolated using the type's [`Animatable::interpolate`] implementation.\n///\n/// [curve]: Curve\n/// [animatable]: Animatable\n#[derive(Debug, Clone, Reflect)]\npub struct AnimatableKeyframeCurve<T> {\n    core: UnevenCore<T>,\n}\n\nimpl<T> Curve<T> for AnimatableKeyframeCurve<T>\nwhere\n    T: Animatable + Clone,\n{\n    #[inline]\n    fn domain(&self) -> Interval {\n        self.core.domain()\n    }\n\n    #[inline]\n    fn sample_clamped(&self, t: f32) -> T {\n        // `UnevenCore::sample_with` is implicitly clamped.\n        self.core.sample_with(t, <T as Animatable>::interpolate)\n    }\n\n    #[inline]\n    fn sample_unchecked(&self, t: f32) -> T {\n        self.sample_clamped(t)\n    }\n}\n\nimpl<T> AnimatableKeyframeCurve<T>\nwhere\n    T: Animatable,\n{\n    /// Create a new [`AnimatableKeyframeCurve`] from the given `keyframes`. The values of this\n    /// curve are interpolated from the keyframes using the output type's implementation of\n    /// [`Animatable::interpolate`].\n    ///\n    /// There must be at least two samples in order for this method to succeed.\n    pub fn new(keyframes: impl IntoIterator<Item = (f32, T)>) -> Result<Self, UnevenCoreError> {\n        Ok(Self {\n            core: UnevenCore::new(keyframes)?,\n        })\n    }\n}\n\nfn inconsistent<P>() -> AnimationEvaluationError\nwhere\n    P: 'static + ?Sized,\n{\n    AnimationEvaluationError::InconsistentEvaluatorImplementation(TypeId::of::<P>())\n}\n\n/// Returns an [`AnimatedField`] with a given `$component` and `$field`.\n///\n/// This can be used in the following way:\n///\n/// ```\n/// # use bevy_animation::{animation_curves::AnimatedField, animated_field};\n/// # use bevy_ecs::component::Component;\n/// # use bevy_math::Vec3;\n/// # use bevy_reflect::Reflect;\n/// #[derive(Component, Reflect)]\n/// struct Transform {\n///     translation: Vec3,\n/// }\n///\n/// let field = animated_field!(Transform::translation);\n/// ```\n#[macro_export]\nmacro_rules! animated_field {\n    ($component:ident::$field:ident) => {\n        AnimatedField::new_unchecked(stringify!($field), |component: &mut $component| {\n            &mut component.$field\n        })\n    };\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "8b59bbfafc2f66f4aa00ebe2a6a20d5b7432cc98",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_window/src/system.rs",
    "func": "use crate::{ClosingWindow, PrimaryWindow, Window, WindowCloseRequested};\n\nuse bevy_app::AppExit;\nuse bevy_ecs::prelude::*;\n\n/// Exit the application when there are no open windows.\n///\n/// This system is added by the [`WindowPlugin`] in the default configuration.\n/// To disable this behavior, set `close_when_requested` (on the [`WindowPlugin`]) to `false`.\n/// Ensure that you read the caveats documented on that field if doing so.\n///\n/// [`WindowPlugin`]: crate::WindowPlugin\npub fn exit_on_all_closed(mut app_exit_events: EventWriter<AppExit>, windows: Query<&Window>) {\n    if windows.is_empty() {\n        bevy_utils::tracing::info!(\"No windows are open, exiting\");\n        app_exit_events.send(AppExit::Success);\n    }\n}\n\n/// Exit the application when the primary window has been closed\n///\n/// This system is added by the [`WindowPlugin`]\n///\n/// [`WindowPlugin`]: crate::WindowPlugin\npub fn exit_on_primary_closed(\n    mut app_exit_events: EventWriter<AppExit>,\n    windows: Query<(), (With<Window>, With<PrimaryWindow>)>,\n) {\n    if windows.is_empty() {\n        bevy_utils::tracing::info!(\"Primary window was closed, exiting\");\n        app_exit_events.send(AppExit::Success);\n    }\n}\n\n/// Close windows in response to [`WindowCloseRequested`] (e.g.  when the close button is pressed).\n///\n/// This system is added by the [`WindowPlugin`] in the default configuration.\n/// To disable this behavior, set `close_when_requested` (on the [`WindowPlugin`]) to `false`.\n/// Ensure that you read the caveats documented on that field if doing so.\n///\n/// [`WindowPlugin`]: crate::WindowPlugin\npub fn close_when_requested(\n    mut commands: Commands,\n    mut closed: EventReader<WindowCloseRequested>,\n    closing: Query<Entity, With<ClosingWindow>>,\n) {\n    // This was inserted by us on the last frame so now we can despawn the window\n    for window in closing.iter() {\n        commands.entity(window).despawn();\n    }\n    // Mark the window as closing so we can despawn it on the next frame\n    for event in closed.read() {\n        // When spamming the window close button on windows (other platforms too probably)\n        // we may receive a `WindowCloseRequested` for a window we've just despawned in the above\n        // loop.\n        commands.entity(event.window).try_insert(ClosingWindow);\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "cfb9a81afc4797c849aeee0a2a92bcebd4206e0d",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_asset/src/io/embedded/embedded_watcher.rs",
    "func": "use crate::io::{\n    file::{get_asset_path, get_base_path, new_asset_event_debouncer, FilesystemEventHandler},\n    memory::Dir,\n    AssetSourceEvent, AssetWatcher,\n};\nuse alloc::sync::Arc;\nuse bevy_utils::{tracing::warn, Duration, HashMap};\nuse notify_debouncer_full::{notify::RecommendedWatcher, Debouncer, RecommendedCache};\nuse parking_lot::RwLock;\nuse std::{\n    fs::File,\n    io::{BufReader, Read},\n    path::{Path, PathBuf},\n};\n\n/// A watcher for assets stored in the `embedded` asset source. Embedded assets are assets whose\n/// bytes have been embedded into the Rust binary using the [`embedded_asset`](crate::embedded_asset) macro.\n/// This watcher will watch for changes to the \"source files\", read the contents of changed files from the file system\n/// and overwrite the initial static bytes of the file embedded in the binary with the new dynamically loaded bytes.\npub struct EmbeddedWatcher {\n    _watcher: Debouncer<RecommendedWatcher, RecommendedCache>,\n}\n\nimpl EmbeddedWatcher {\n    pub fn new(\n        dir: Dir,\n        root_paths: Arc<RwLock<HashMap<Box<Path>, PathBuf>>>,\n        sender: crossbeam_channel::Sender<AssetSourceEvent>,\n        debounce_wait_time: Duration,\n    ) -> Self {\n        let root = get_base_path();\n        let handler = EmbeddedEventHandler {\n            dir,\n            root: root.clone(),\n            sender,\n            root_paths,\n            last_event: None,\n        };\n        let watcher = new_asset_event_debouncer(root, debounce_wait_time, handler).unwrap();\n        Self { _watcher: watcher }\n    }\n}\n\nimpl AssetWatcher for EmbeddedWatcher {}\n\n/// A [`FilesystemEventHandler`] that uses [`EmbeddedAssetRegistry`](crate::io::embedded::EmbeddedAssetRegistry) to hot-reload\n/// binary-embedded Rust source files. This will read the contents of changed files from the file system and overwrite\n/// the initial static bytes from the file embedded in the binary.\npub(crate) struct EmbeddedEventHandler {\n    sender: crossbeam_channel::Sender<AssetSourceEvent>,\n    root_paths: Arc<RwLock<HashMap<Box<Path>, PathBuf>>>,\n    root: PathBuf,\n    dir: Dir,\n    last_event: Option<AssetSourceEvent>,\n}\nimpl FilesystemEventHandler for EmbeddedEventHandler {\n    fn begin(&mut self) {\n        self.last_event = None;\n    }\n\n    fn get_path(&self, absolute_path: &Path) -> Option<(PathBuf, bool)> {\n        let (local_path, is_meta) = get_asset_path(&self.root, absolute_path);\n        let final_path = self.root_paths.read().get(local_path.as_path())?.clone();\n        if is_meta {\n            warn!(\"Meta file asset hot-reloading is not supported yet: {final_path:?}\");\n        }\n        Some((final_path, false))\n    }\n\n    fn handle(&mut self, absolute_paths: &[PathBuf], event: AssetSourceEvent) {\n        if self.last_event.as_ref() != Some(&event) {\n            if let AssetSourceEvent::ModifiedAsset(path) = &event {\n                if let Ok(file) = File::open(&absolute_paths[0]) {\n                    let mut reader = BufReader::new(file);\n                    let mut buffer = Vec::new();\n\n                    // Read file into vector.\n                    if reader.read_to_end(&mut buffer).is_ok() {\n                        self.dir.insert_asset(path, buffer);\n                    }\n                }\n            }\n            self.last_event = Some(event.clone());\n            self.sender.send(event).unwrap();\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "2972d2be380443d7f65dea2c11ddb3d179459aa5",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_render/macros/src/as_bind_group.rs",
    "func": "use bevy_macro_utils::{get_lit_bool, get_lit_str, BevyManifest, Symbol};\nuse proc_macro::TokenStream;\nuse proc_macro2::{Ident, Span};\nuse quote::{quote, ToTokens};\nuse syn::{\n    parse::{Parse, ParseStream},\n    punctuated::Punctuated,\n    token::Comma,\n    Data, DataStruct, Error, Fields, Lit, LitInt, LitStr, Meta, MetaList, Result,\n};\n\nconst UNIFORM_ATTRIBUTE_NAME: Symbol = Symbol(\"uniform\");\nconst TEXTURE_ATTRIBUTE_NAME: Symbol = Symbol(\"texture\");\nconst STORAGE_TEXTURE_ATTRIBUTE_NAME: Symbol = Symbol(\"storage_texture\");\nconst SAMPLER_ATTRIBUTE_NAME: Symbol = Symbol(\"sampler\");\nconst STORAGE_ATTRIBUTE_NAME: Symbol = Symbol(\"storage\");\nconst BIND_GROUP_DATA_ATTRIBUTE_NAME: Symbol = Symbol(\"bind_group_data\");\nconst BINDLESS_ATTRIBUTE_NAME: Symbol = Symbol(\"bindless\");\n\n#[derive(Copy, Clone, Debug)]\nenum BindingType {\n    Uniform,\n    Texture,\n    StorageTexture,\n    Sampler,\n    Storage,\n}\n\n#[derive(Clone)]\nenum BindingState<'a> {\n    Free,\n    Occupied {\n        binding_type: BindingType,\n        ident: &'a Ident,\n    },\n    OccupiedConvertedUniform,\n    OccupiedMergeableUniform {\n        uniform_fields: Vec<&'a syn::Field>,\n    },\n}\n\npub fn derive_as_bind_group(ast: syn::DeriveInput) -> Result<TokenStream> {\n    let manifest = BevyManifest::default();\n    let render_path = manifest.get_path(\"bevy_render\");\n    let image_path = manifest.get_path(\"bevy_image\");\n    let asset_path = manifest.get_path(\"bevy_asset\");\n    let ecs_path = manifest.get_path(\"bevy_ecs\");\n\n    let mut binding_states: Vec<BindingState> = Vec::new();\n    let mut binding_impls = Vec::new();\n    let mut binding_layouts = Vec::new();\n    let mut attr_prepared_data_ident = None;\n    let mut attr_bindless_count = None;\n\n    // `actual_bindless_slot_count` holds the actual number of bindless slots\n    // per bind group, taking into account whether the current platform supports\n    // bindless resources.\n    let actual_bindless_slot_count = Ident::new(\"actual_bindless_slot_count\", Span::call_site());\n\n    // The `BufferBindingType` and corresponding `BufferUsages` used for\n    // uniforms. We need this because bindless uniforms don't exist, so in\n    // bindless mode we must promote uniforms to storage buffers.\n    let uniform_binding_type = Ident::new(\"uniform_binding_type\", Span::call_site());\n    let uniform_buffer_usages = Ident::new(\"uniform_buffer_usages\", Span::call_site());\n\n    // Read struct-level attributes\n    for attr in &ast.attrs {\n        if let Some(attr_ident) = attr.path().get_ident() {\n            if attr_ident == BIND_GROUP_DATA_ATTRIBUTE_NAME {\n                if let Ok(prepared_data_ident) =\n                    attr.parse_args_with(|input: ParseStream| input.parse::<Ident>())\n                {\n                    attr_prepared_data_ident = Some(prepared_data_ident);\n                }\n            } else if attr_ident == UNIFORM_ATTRIBUTE_NAME {\n                let (binding_index, converted_shader_type) = get_uniform_binding_attr(attr)?;\n                binding_impls.push(quote! {{\n                    use #render_path::render_resource::AsBindGroupShaderType;\n                    let mut buffer = #render_path::render_resource::encase::UniformBuffer::new(Vec::new());\n                    let converted: #converted_shader_type = self.as_bind_group_shader_type(&images);\n                    buffer.write(&converted).unwrap();\n                    (\n                        #binding_index,\n                        #render_path::render_resource::OwnedBindingResource::Buffer(render_device.create_buffer_with_data(\n                            &#render_path::render_resource::BufferInitDescriptor {\n                                label: None,\n                                usage: #uniform_buffer_usages,\n                                contents: buffer.as_ref(),\n                            },\n                        ))\n                    )\n                }});\n\n                binding_layouts.push(quote!{\n                    #render_path::render_resource::BindGroupLayoutEntry {\n                        binding: #binding_index,\n                        visibility: #render_path::render_resource::ShaderStages::all(),\n                        ty: #render_path::render_resource::BindingType::Buffer {\n                            ty: #uniform_binding_type,\n                            has_dynamic_offset: false,\n                            min_binding_size: Some(<#converted_shader_type as #render_path::render_resource::ShaderType>::min_size()),\n                        },\n                        count: #actual_bindless_slot_count,\n                    }\n                });\n\n                let required_len = binding_index as usize + 1;\n                if required_len > binding_states.len() {\n                    binding_states.resize(required_len, BindingState::Free);\n                }\n                binding_states[binding_index as usize] = BindingState::OccupiedConvertedUniform;\n            } else if attr_ident == BINDLESS_ATTRIBUTE_NAME {\n                if let Ok(count_lit) =\n                    attr.parse_args_with(|input: ParseStream| input.parse::<Lit>())\n                {\n                    attr_bindless_count = Some(count_lit);\n                }\n            }\n        }\n    }\n\n    let fields = match &ast.data {\n        Data::Struct(DataStruct {\n            fields: Fields::Named(fields),\n            ..\n        }) => &fields.named,\n        _ => {\n            return Err(Error::new_spanned(\n                ast,\n                \"Expected a struct with named fields\",\n            ));\n        }\n    };\n\n    // Read field-level attributes\n    for field in fields {\n        // Search ahead for texture attributes so we can use them with any\n        // corresponding sampler attribute.\n        let mut tex_attrs = None;\n        for attr in &field.attrs {\n            let Some(attr_ident) = attr.path().get_ident() else {\n                continue;\n            };\n            if attr_ident == TEXTURE_ATTRIBUTE_NAME {\n                let (_binding_index, nested_meta_items) = get_binding_nested_attr(attr)?;\n                tex_attrs = Some(get_texture_attrs(nested_meta_items)?);\n            }\n        }\n\n        for attr in &field.attrs {\n            let Some(attr_ident) = attr.path().get_ident() else {\n                continue;\n            };\n\n            let binding_type = if attr_ident == UNIFORM_ATTRIBUTE_NAME {\n                BindingType::Uniform\n            } else if attr_ident == TEXTURE_ATTRIBUTE_NAME {\n                BindingType::Texture\n            } else if attr_ident == STORAGE_TEXTURE_ATTRIBUTE_NAME {\n                BindingType::StorageTexture\n            } else if attr_ident == SAMPLER_ATTRIBUTE_NAME {\n                BindingType::Sampler\n            } else if attr_ident == STORAGE_ATTRIBUTE_NAME {\n                BindingType::Storage\n            } else {\n                continue;\n            };\n\n            let (binding_index, nested_meta_items) = get_binding_nested_attr(attr)?;\n\n            let field_name = field.ident.as_ref().unwrap();\n            let required_len = binding_index as usize + 1;\n            if required_len > binding_states.len() {\n                binding_states.resize(required_len, BindingState::Free);\n            }\n\n            match &mut binding_states[binding_index as usize] {\n                value @ BindingState::Free => {\n                    *value = match binding_type {\n                        BindingType::Uniform => BindingState::OccupiedMergeableUniform {\n                            uniform_fields: vec![field],\n                        },\n                        _ => {\n                            // only populate bind group entries for non-uniforms\n                            // uniform entries are deferred until the end\n                            BindingState::Occupied {\n                                binding_type,\n                                ident: field_name,\n                            }\n                        }\n                    }\n                }\n                BindingState::Occupied {\n                    binding_type,\n                    ident: occupied_ident,\n                } => {\n                    return Err(Error::new_spanned(\n                        attr,\n                        format!(\"The '{field_name}' field cannot be assigned to binding {binding_index} because it is already occupied by the field '{occupied_ident}' of type {binding_type:?}.\")\n                    ));\n                }\n                BindingState::OccupiedConvertedUniform => {\n                    return Err(Error::new_spanned(\n                        attr,\n                        format!(\"The '{field_name}' field cannot be assigned to binding {binding_index} because it is already occupied by a struct-level uniform binding at the same index.\")\n                    ));\n                }\n                BindingState::OccupiedMergeableUniform { uniform_fields } => match binding_type {\n                    BindingType::Uniform => {\n                        uniform_fields.push(field);\n                    }\n                    _ => {\n                        return Err(Error::new_spanned(\n                                attr,\n                                format!(\"The '{field_name}' field cannot be assigned to binding {binding_index} because it is already occupied by a {:?}.\", BindingType::Uniform)\n                            ));\n                    }\n                },\n            }\n\n            match binding_type {\n                BindingType::Uniform => {\n                    // uniform codegen is deferred to account for combined uniform bindings\n                }\n                BindingType::Storage => {\n                    let StorageAttrs {\n                        visibility,\n                        read_only,\n                        buffer,\n                    } = get_storage_binding_attr(nested_meta_items)?;\n                    let visibility =\n                        visibility.hygienic_quote(&quote! { #render_path::render_resource });\n\n                    let field_name = field.ident.as_ref().unwrap();\n\n                    if buffer {\n                        binding_impls.push(quote! {\n                            (\n                                #binding_index,\n                                #render_path::render_resource::OwnedBindingResource::Buffer({\n                                    self.#field_name.clone()\n                                })\n                            )\n                        });\n                    } else {\n                        binding_impls.push(quote! {\n                        (\n                            #binding_index,\n                            #render_path::render_resource::OwnedBindingResource::Buffer({\n                                let handle: &#asset_path::Handle<#render_path::storage::ShaderStorageBuffer> = (&self.#field_name);\n                                storage_buffers.get(handle).ok_or_else(|| #render_path::render_resource::AsBindGroupError::RetryNextUpdate)?.buffer.clone()\n                            })\n                        )\n                        });\n                    }\n\n                    binding_layouts.push(quote! {\n                        #render_path::render_resource::BindGroupLayoutEntry {\n                            binding: #binding_index,\n                            visibility: #visibility,\n                            ty: #render_path::render_resource::BindingType::Buffer {\n                                ty: #render_path::render_resource::BufferBindingType::Storage { read_only: #read_only },\n                                has_dynamic_offset: false,\n                                min_binding_size: None,\n                            },\n                            count: #actual_bindless_slot_count,\n                        }\n                    });\n                }\n                BindingType::StorageTexture => {\n                    let StorageTextureAttrs {\n                        dimension,\n                        image_format,\n                        access,\n                        visibility,\n                    } = get_storage_texture_binding_attr(nested_meta_items)?;\n\n                    let visibility =\n                        visibility.hygienic_quote(&quote! { #render_path::render_resource });\n\n                    let fallback_image = get_fallback_image(&render_path, dimension);\n\n                    // insert fallible texture-based entries at 0 so that if we fail here, we exit before allocating any buffers\n                    binding_impls.insert(0, quote! {\n                        ( #binding_index,\n                          #render_path::render_resource::OwnedBindingResource::TextureView(\n                                #dimension,\n                                {\n                                    let handle: Option<&#asset_path::Handle<#image_path::Image>> = (&self.#field_name).into();\n                                    if let Some(handle) = handle {\n                                        images.get(handle).ok_or_else(|| #render_path::render_resource::AsBindGroupError::RetryNextUpdate)?.texture_view.clone()\n                                    } else {\n                                        #fallback_image.texture_view.clone()\n                                    }\n                                }\n                            )\n                        )\n                    });\n\n                    binding_layouts.push(quote! {\n                        #render_path::render_resource::BindGroupLayoutEntry {\n                            binding: #binding_index,\n                            visibility: #visibility,\n                            ty: #render_path::render_resource::BindingType::StorageTexture {\n                                access: #render_path::render_resource::StorageTextureAccess::#access,\n                                format: #render_path::render_resource::TextureFormat::#image_format,\n                                view_dimension: #render_path::render_resource::#dimension,\n                            },\n                            count: #actual_bindless_slot_count,\n                        }\n                    });\n                }\n                BindingType::Texture => {\n                    let TextureAttrs {\n                        dimension,\n                        sample_type,\n                        multisampled,\n                        visibility,\n                    } = tex_attrs.as_ref().unwrap();\n\n                    let visibility =\n                        visibility.hygienic_quote(&quote! { #render_path::render_resource });\n\n                    let fallback_image = get_fallback_image(&render_path, *dimension);\n\n                    // insert fallible texture-based entries at 0 so that if we fail here, we exit before allocating any buffers\n                    binding_impls.insert(0, quote! {\n                        (\n                            #binding_index,\n                            #render_path::render_resource::OwnedBindingResource::TextureView(\n                                #render_path::render_resource::#dimension,\n                                {\n                                    let handle: Option<&#asset_path::Handle<#image_path::Image>> = (&self.#field_name).into();\n                                    if let Some(handle) = handle {\n                                        images.get(handle).ok_or_else(|| #render_path::render_resource::AsBindGroupError::RetryNextUpdate)?.texture_view.clone()\n                                    } else {\n                                        #fallback_image.texture_view.clone()\n                                    }\n                                }\n                            )\n                        )\n                    });\n\n                    binding_layouts.push(quote! {\n                        #render_path::render_resource::BindGroupLayoutEntry {\n                            binding: #binding_index,\n                            visibility: #visibility,\n                            ty: #render_path::render_resource::BindingType::Texture {\n                                multisampled: #multisampled,\n                                sample_type: #render_path::render_resource::#sample_type,\n                                view_dimension: #render_path::render_resource::#dimension,\n                            },\n                            count: #actual_bindless_slot_count,\n                        }\n                    });\n                }\n                BindingType::Sampler => {\n                    let SamplerAttrs {\n                        sampler_binding_type,\n                        visibility,\n                        ..\n                    } = get_sampler_attrs(nested_meta_items)?;\n                    let TextureAttrs { dimension, .. } = tex_attrs\n                        .as_ref()\n                        .expect(\"sampler attribute must have matching texture attribute\");\n\n                    let visibility =\n                        visibility.hygienic_quote(&quote! { #render_path::render_resource });\n\n                    let fallback_image = get_fallback_image(&render_path, *dimension);\n\n                    let expected_samplers = match sampler_binding_type {\n                        SamplerBindingType::Filtering => {\n                            quote!( [#render_path::render_resource::TextureSampleType::Float { filterable: true }] )\n                        }\n                        SamplerBindingType::NonFiltering => quote!([\n                            #render_path::render_resource::TextureSampleType::Float { filterable: false },\n                            #render_path::render_resource::TextureSampleType::Sint,\n                            #render_path::render_resource::TextureSampleType::Uint,\n                        ]),\n                        SamplerBindingType::Comparison => {\n                            quote!( [#render_path::render_resource::TextureSampleType::Depth] )\n                        }\n                    };\n\n                    // insert fallible texture-based entries at 0 so that if we fail here, we exit before allocating any buffers\n                    binding_impls.insert(0, quote! {\n                        (\n                            #binding_index,\n                            #render_path::render_resource::OwnedBindingResource::Sampler({\n                                let handle: Option<&#asset_path::Handle<#image_path::Image>> = (&self.#field_name).into();\n                                if let Some(handle) = handle {\n                                    let image = images.get(handle).ok_or_else(|| #render_path::render_resource::AsBindGroupError::RetryNextUpdate)?;\n\n                                    let Some(sample_type) = image.texture_format.sample_type(None, Some(render_device.features())) else {\n                                        return Err(#render_path::render_resource::AsBindGroupError::InvalidSamplerType(\n                                            #binding_index,\n                                            \"None\".to_string(),\n                                            format!(\"{:?}\", #expected_samplers),\n                                        ));\n                                    };\n\n                                    let valid = #expected_samplers.contains(&sample_type);\n\n                                    if !valid {\n                                        return Err(#render_path::render_resource::AsBindGroupError::InvalidSamplerType(\n                                            #binding_index,\n                                            format!(\"{:?}\", sample_type),\n                                            format!(\"{:?}\", #expected_samplers),\n                                        ));\n                                    }\n                                    image.sampler.clone()\n                                } else {\n                                    #fallback_image.sampler.clone()\n                                }\n                            })\n                        )\n                    });\n\n                    binding_layouts.push(quote!{\n                        #render_path::render_resource::BindGroupLayoutEntry {\n                            binding: #binding_index,\n                            visibility: #visibility,\n                            ty: #render_path::render_resource::BindingType::Sampler(#render_path::render_resource::#sampler_binding_type),\n                            count: #actual_bindless_slot_count,\n                        }\n                    });\n                }\n            }\n        }\n    }\n\n    // Produce impls for fields with uniform bindings\n    let struct_name = &ast.ident;\n    let struct_name_literal = struct_name.to_string();\n    let struct_name_literal = struct_name_literal.as_str();\n    let mut field_struct_impls = Vec::new();\n\n    let uniform_binding_type_declarations = match attr_bindless_count {\n        Some(_) => {\n            quote! {\n                let (#uniform_binding_type, #uniform_buffer_usages) =\n                    if render_device.features().contains(\n                        #render_path::settings::WgpuFeatures::BUFFER_BINDING_ARRAY |\n                        #render_path::settings::WgpuFeatures::TEXTURE_BINDING_ARRAY\n                    ) && render_device.limits().max_storage_buffers_per_shader_stage > 0 {\n                        (\n                            #render_path::render_resource::BufferBindingType::Storage { read_only: true },\n                            #render_path::render_resource::BufferUsages::STORAGE,\n                        )\n                    } else {\n                        (\n                            #render_path::render_resource::BufferBindingType::Uniform,\n                            #render_path::render_resource::BufferUsages::UNIFORM,\n                        )\n                    };\n            }\n        }\n        None => {\n            quote! {\n                let (#uniform_binding_type, #uniform_buffer_usages) = (\n                    #render_path::render_resource::BufferBindingType::Uniform,\n                    #render_path::render_resource::BufferUsages::UNIFORM,\n                );\n            }\n        }\n    };\n\n    for (binding_index, binding_state) in binding_states.iter().enumerate() {\n        let binding_index = binding_index as u32;\n        if let BindingState::OccupiedMergeableUniform { uniform_fields } = binding_state {\n            // single field uniform bindings for a given index can use a straightforward binding\n            if uniform_fields.len() == 1 {\n                let field = &uniform_fields[0];\n                let field_name = field.ident.as_ref().unwrap();\n                let field_ty = &field.ty;\n                binding_impls.push(quote! {{\n                    let mut buffer = #render_path::render_resource::encase::UniformBuffer::new(Vec::new());\n                    buffer.write(&self.#field_name).unwrap();\n                    (\n                        #binding_index,\n                        #render_path::render_resource::OwnedBindingResource::Buffer(render_device.create_buffer_with_data(\n                            &#render_path::render_resource::BufferInitDescriptor {\n                                label: None,\n                                usage: #render_path::render_resource::BufferUsages::COPY_DST | #uniform_buffer_usages,\n                                contents: buffer.as_ref(),\n                            },\n                        ))\n                    )\n                }});\n\n                binding_layouts.push(quote!{\n                    #render_path::render_resource::BindGroupLayoutEntry {\n                        binding: #binding_index,\n                        visibility: #render_path::render_resource::ShaderStages::all(),\n                        ty: #render_path::render_resource::BindingType::Buffer {\n                            ty: #uniform_binding_type,\n                            has_dynamic_offset: false,\n                            min_binding_size: Some(<#field_ty as #render_path::render_resource::ShaderType>::min_size()),\n                        },\n                        count: actual_bindless_slot_count,\n                    }\n                });\n            // multi-field uniform bindings for a given index require an intermediate struct to derive ShaderType\n            } else {\n                let uniform_struct_name = Ident::new(\n                    &format!(\"_{struct_name}AsBindGroupUniformStructBindGroup{binding_index}\"),\n                    Span::call_site(),\n                );\n\n                let field_name = uniform_fields.iter().map(|f| f.ident.as_ref().unwrap());\n                let field_type = uniform_fields.iter().map(|f| &f.ty);\n                field_struct_impls.push(quote! {\n                    #[derive(#render_path::render_resource::ShaderType)]\n                    struct #uniform_struct_name<'a> {\n                        #(#field_name: &'a #field_type,)*\n                    }\n                });\n\n                let field_name = uniform_fields.iter().map(|f| f.ident.as_ref().unwrap());\n                binding_impls.push(quote! {{\n                    let mut buffer = #render_path::render_resource::encase::UniformBuffer::new(Vec::new());\n                    buffer.write(&#uniform_struct_name {\n                        #(#field_name: &self.#field_name,)*\n                    }).unwrap();\n                    (\n                        #binding_index,\n                        #render_path::render_resource::OwnedBindingResource::Buffer(render_device.create_buffer_with_data(\n                            &#render_path::render_resource::BufferInitDescriptor {\n                                label: None,\n                                usage: #render_path::render_resource::BufferUsages::COPY_DST | #uniform_buffer_usages,\n                                contents: buffer.as_ref(),\n                            },\n                        ))\n                    )\n                }});\n\n                binding_layouts.push(quote!{\n                    #render_path::render_resource::BindGroupLayoutEntry {\n                        binding: #binding_index,\n                        visibility: #render_path::render_resource::ShaderStages::all(),\n                        ty: #render_path::render_resource::BindingType::Buffer {\n                            ty: #uniform_binding_type,\n                            has_dynamic_offset: false,\n                            min_binding_size: Some(<#uniform_struct_name as #render_path::render_resource::ShaderType>::min_size()),\n                        },\n                        count: actual_bindless_slot_count,\n                    }\n                });\n            }\n        }\n    }\n\n    let generics = ast.generics;\n    let (impl_generics, ty_generics, where_clause) = generics.split_for_impl();\n\n    let (prepared_data, get_prepared_data) = if let Some(prepared) = attr_prepared_data_ident {\n        let get_prepared_data = quote! { self.into() };\n        (quote! {#prepared}, get_prepared_data)\n    } else {\n        let prepared_data = quote! { () };\n        (prepared_data.clone(), prepared_data)\n    };\n\n    // Calculate the actual number of bindless slots, taking hardware\n    // limitations into account.\n    let (bindless_slot_count, actual_bindless_slot_count_declaration) = match attr_bindless_count {\n        Some(bindless_count) => (\n            quote! { const BINDLESS_SLOT_COUNT: Option<u32> = Some(#bindless_count); },\n            quote! {\n                let #actual_bindless_slot_count = if render_device.features().contains(\n                    #render_path::settings::WgpuFeatures::BUFFER_BINDING_ARRAY |\n                    #render_path::settings::WgpuFeatures::TEXTURE_BINDING_ARRAY\n                ) && render_device.limits().max_storage_buffers_per_shader_stage > 0 {\n                    ::core::num::NonZeroU32::new(#bindless_count)\n                } else {\n                    None\n                };\n            },\n        ),\n        None => (\n            TokenStream::new().into(),\n            quote! { let #actual_bindless_slot_count: Option<::core::num::NonZeroU32> = None; },\n        ),\n    };\n\n    Ok(TokenStream::from(quote! {\n        #(#field_struct_impls)*\n\n        impl #impl_generics #render_path::render_resource::AsBindGroup for #struct_name #ty_generics #where_clause {\n            type Data = #prepared_data;\n\n            type Param = (\n                #ecs_path::system::lifetimeless::SRes<#render_path::render_asset::RenderAssets<#render_path::texture::GpuImage>>,\n                #ecs_path::system::lifetimeless::SRes<#render_path::texture::FallbackImage>,\n                #ecs_path::system::lifetimeless::SRes<#render_path::render_asset::RenderAssets<#render_path::storage::GpuShaderStorageBuffer>>,\n            );\n\n            #bindless_slot_count\n\n            fn label() -> Option<&'static str> {\n                Some(#struct_name_literal)\n            }\n\n            fn unprepared_bind_group(\n                &self,\n                layout: &#render_path::render_resource::BindGroupLayout,\n                render_device: &#render_path::renderer::RenderDevice,\n                (images, fallback_image, storage_buffers): &mut #ecs_path::system::SystemParamItem<'_, '_, Self::Param>,\n            ) -> Result<#render_path::render_resource::UnpreparedBindGroup<Self::Data>, #render_path::render_resource::AsBindGroupError> {\n                #uniform_binding_type_declarations\n\n                let bindings = #render_path::render_resource::BindingResources(vec![#(#binding_impls,)*]);\n\n                Ok(#render_path::render_resource::UnpreparedBindGroup {\n                    bindings,\n                    data: #get_prepared_data,\n                })\n            }\n\n            fn bind_group_layout_entries(render_device: &#render_path::renderer::RenderDevice) -> Vec<#render_path::render_resource::BindGroupLayoutEntry> {\n                #actual_bindless_slot_count_declaration\n                #uniform_binding_type_declarations\n\n                vec![#(#binding_layouts,)*]\n            }\n        }\n    }))\n}\n\nfn get_fallback_image(\n    render_path: &syn::Path,\n    dimension: BindingTextureDimension,\n) -> proc_macro2::TokenStream {\n    quote! {\n        match #render_path::render_resource::#dimension {\n            #render_path::render_resource::TextureViewDimension::D1 => &fallback_image.d1,\n            #render_path::render_resource::TextureViewDimension::D2 => &fallback_image.d2,\n            #render_path::render_resource::TextureViewDimension::D2Array => &fallback_image.d2_array,\n            #render_path::render_resource::TextureViewDimension::Cube => &fallback_image.cube,\n            #render_path::render_resource::TextureViewDimension::CubeArray => &fallback_image.cube_array,\n            #render_path::render_resource::TextureViewDimension::D3 => &fallback_image.d3,\n        }\n    }\n}\n\n/// Represents the arguments for the `uniform` binding attribute.\n///\n/// If parsed, represents an attribute\n/// like `#[uniform(LitInt, Ident)]`\nstruct UniformBindingMeta {\n    lit_int: LitInt,\n    _comma: Comma,\n    ident: Ident,\n}\n\n/// Represents the arguments for any general binding attribute.\n///\n/// If parsed, represents an attribute\n/// like `#[foo(LitInt, ...)]` where the rest is optional [`Meta`].\nenum BindingMeta {\n    IndexOnly(LitInt),\n    IndexWithOptions(BindingIndexOptions),\n}\n\n/// Represents the arguments for an attribute with a list of arguments.\n///\n/// This represents, for example, `#[texture(0, dimension = \"2d_array\")]`.\nstruct BindingIndexOptions {\n    lit_int: LitInt,\n    _comma: Comma,\n    meta_list: Punctuated<Meta, Comma>,\n}\n\nimpl Parse for BindingMeta {\n    fn parse(input: ParseStream) -> Result<Self> {\n        if input.peek2(Comma) {\n            input.parse().map(Self::IndexWithOptions)\n        } else {\n            input.parse().map(Self::IndexOnly)\n        }\n    }\n}\n\nimpl Parse for BindingIndexOptions {\n    fn parse(input: ParseStream) -> Result<Self> {\n        Ok(Self {\n            lit_int: input.parse()?,\n            _comma: input.parse()?,\n            meta_list: input.parse_terminated(Meta::parse, Comma)?,\n        })\n    }\n}\n\nimpl Parse for UniformBindingMeta {\n    fn parse(input: ParseStream) -> Result<Self> {\n        Ok(Self {\n            lit_int: input.parse()?,\n            _comma: input.parse()?,\n            ident: input.parse()?,\n        })\n    }\n}\n\nfn get_uniform_binding_attr(attr: &syn::Attribute) -> Result<(u32, Ident)> {\n    let uniform_binding_meta = attr.parse_args_with(UniformBindingMeta::parse)?;\n\n    let binding_index = uniform_binding_meta.lit_int.base10_parse()?;\n    let ident = uniform_binding_meta.ident;\n\n    Ok((binding_index, ident))\n}\n\nfn get_binding_nested_attr(attr: &syn::Attribute) -> Result<(u32, Vec<Meta>)> {\n    let binding_meta = attr.parse_args_with(BindingMeta::parse)?;\n\n    match binding_meta {\n        BindingMeta::IndexOnly(lit_int) => Ok((lit_int.base10_parse()?, Vec::new())),\n        BindingMeta::IndexWithOptions(BindingIndexOptions {\n            lit_int,\n            _comma: _,\n            meta_list,\n        }) => Ok((lit_int.base10_parse()?, meta_list.into_iter().collect())),\n    }\n}\n\n#[derive(Default)]\nenum ShaderStageVisibility {\n    #[default]\n    All,\n    None,\n    Flags(VisibilityFlags),\n}\n\n#[derive(Default)]\nstruct VisibilityFlags {\n    vertex: bool,\n    fragment: bool,\n    compute: bool,\n}\n\nimpl ShaderStageVisibility {\n    fn vertex_fragment() -> Self {\n        Self::Flags(VisibilityFlags::vertex_fragment())\n    }\n\n    fn compute() -> Self {\n        Self::Flags(VisibilityFlags::compute())\n    }\n}\n\nimpl VisibilityFlags {\n    fn vertex_fragment() -> Self {\n        Self {\n            vertex: true,\n            fragment: true,\n            ..Default::default()\n        }\n    }\n\n    fn compute() -> Self {\n        Self {\n            compute: true,\n            ..Default::default()\n        }\n    }\n}\n\nimpl ShaderStageVisibility {\n    fn hygienic_quote(&self, path: &proc_macro2::TokenStream) -> proc_macro2::TokenStream {\n        match self {\n            ShaderStageVisibility::All => quote! { #path::ShaderStages::all() },\n            ShaderStageVisibility::None => quote! { #path::ShaderStages::NONE },\n            ShaderStageVisibility::Flags(flags) => {\n                let mut quoted = Vec::new();\n\n                if flags.vertex {\n                    quoted.push(quote! { #path::ShaderStages::VERTEX });\n                }\n                if flags.fragment {\n                    quoted.push(quote! { #path::ShaderStages::FRAGMENT });\n                }\n                if flags.compute {\n                    quoted.push(quote! { #path::ShaderStages::COMPUTE });\n                }\n\n                quote! { #(#quoted)|* }\n            }\n        }\n    }\n}\n\nconst VISIBILITY: Symbol = Symbol(\"visibility\");\nconst VISIBILITY_VERTEX: Symbol = Symbol(\"vertex\");\nconst VISIBILITY_FRAGMENT: Symbol = Symbol(\"fragment\");\nconst VISIBILITY_COMPUTE: Symbol = Symbol(\"compute\");\nconst VISIBILITY_ALL: Symbol = Symbol(\"all\");\nconst VISIBILITY_NONE: Symbol = Symbol(\"none\");\n\nfn get_visibility_flag_value(meta_list: &MetaList) -> Result<ShaderStageVisibility> {\n    let mut flags = Vec::new();\n\n    meta_list.parse_nested_meta(|meta| {\n        flags.push(meta.path);\n        Ok(())\n    })?;\n\n    if flags.is_empty() {\n        return Err(Error::new_spanned(\n            meta_list,\n            \"Invalid visibility format. Must be `visibility(flags)`, flags can be `all`, `none`, or a list-combination of `vertex`, `fragment` and/or `compute`.\"\n        ));\n    }\n\n    if flags.len() == 1 {\n        if let Some(flag) = flags.first() {\n            if flag == VISIBILITY_ALL {\n                return Ok(ShaderStageVisibility::All);\n            } else if flag == VISIBILITY_NONE {\n                return Ok(ShaderStageVisibility::None);\n            }\n        }\n    }\n\n    let mut visibility = VisibilityFlags::default();\n\n    for flag in flags {\n        if flag == VISIBILITY_VERTEX {\n            visibility.vertex = true;\n        } else if flag == VISIBILITY_FRAGMENT {\n            visibility.fragment = true;\n        } else if flag == VISIBILITY_COMPUTE {\n            visibility.compute = true;\n        } else {\n            return Err(Error::new_spanned(\n                flag,\n                \"Not a valid visibility flag. Must be `all`, `none`, or a list-combination of `vertex`, `fragment` and/or `compute`.\"\n            ));\n        }\n    }\n\n    Ok(ShaderStageVisibility::Flags(visibility))\n}\n\n#[derive(Clone, Copy, Default)]\nenum BindingTextureDimension {\n    D1,\n    #[default]\n    D2,\n    D2Array,\n    Cube,\n    CubeArray,\n    D3,\n}\n\nenum BindingTextureSampleType {\n    Float { filterable: bool },\n    Depth,\n    Sint,\n    Uint,\n}\n\nimpl ToTokens for BindingTextureDimension {\n    fn to_tokens(&self, tokens: &mut proc_macro2::TokenStream) {\n        tokens.extend(match self {\n            BindingTextureDimension::D1 => quote! { TextureViewDimension::D1 },\n            BindingTextureDimension::D2 => quote! { TextureViewDimension::D2 },\n            BindingTextureDimension::D2Array => quote! { TextureViewDimension::D2Array },\n            BindingTextureDimension::Cube => quote! { TextureViewDimension::Cube },\n            BindingTextureDimension::CubeArray => quote! { TextureViewDimension::CubeArray },\n            BindingTextureDimension::D3 => quote! { TextureViewDimension::D3 },\n        });\n    }\n}\n\nimpl ToTokens for BindingTextureSampleType {\n    fn to_tokens(&self, tokens: &mut proc_macro2::TokenStream) {\n        tokens.extend(match self {\n            BindingTextureSampleType::Float { filterable } => {\n                quote! { TextureSampleType::Float { filterable: #filterable } }\n            }\n            BindingTextureSampleType::Depth => quote! { TextureSampleType::Depth },\n            BindingTextureSampleType::Sint => quote! { TextureSampleType::Sint },\n            BindingTextureSampleType::Uint => quote! { TextureSampleType::Uint },\n        });\n    }\n}\n\nstruct TextureAttrs {\n    dimension: BindingTextureDimension,\n    sample_type: BindingTextureSampleType,\n    multisampled: bool,\n    visibility: ShaderStageVisibility,\n}\n\nimpl Default for BindingTextureSampleType {\n    fn default() -> Self {\n        BindingTextureSampleType::Float { filterable: true }\n    }\n}\n\nimpl Default for TextureAttrs {\n    fn default() -> Self {\n        Self {\n            dimension: Default::default(),\n            sample_type: Default::default(),\n            multisampled: true,\n            visibility: Default::default(),\n        }\n    }\n}\n\nstruct StorageTextureAttrs {\n    dimension: BindingTextureDimension,\n    // Parsing of the image_format parameter is deferred to the type checker,\n    // which will error if the format is not member of the TextureFormat enum.\n    image_format: proc_macro2::TokenStream,\n    // Parsing of the access parameter is deferred to the type checker,\n    // which will error if the access is not member of the StorageTextureAccess enum.\n    access: proc_macro2::TokenStream,\n    visibility: ShaderStageVisibility,\n}\n\nimpl Default for StorageTextureAttrs {\n    fn default() -> Self {\n        Self {\n            dimension: Default::default(),\n            image_format: quote! { Rgba8Unorm },\n            access: quote! { ReadWrite },\n            visibility: ShaderStageVisibility::compute(),\n        }\n    }\n}\n\nfn get_storage_texture_binding_attr(metas: Vec<Meta>) -> Result<StorageTextureAttrs> {\n    let mut storage_texture_attrs = StorageTextureAttrs::default();\n\n    for meta in metas {\n        use syn::Meta::{List, NameValue};\n        match meta {\n            // Parse #[storage_texture(0, dimension = \"...\")].\n            NameValue(m) if m.path == DIMENSION => {\n                let value = get_lit_str(DIMENSION, &m.value)?;\n                storage_texture_attrs.dimension = get_texture_dimension_value(value)?;\n            }\n            // Parse #[storage_texture(0, format = ...))].\n            NameValue(m) if m.path == IMAGE_FORMAT => {\n                storage_texture_attrs.image_format = m.value.into_token_stream();\n            }\n            // Parse #[storage_texture(0, access = ...))].\n            NameValue(m) if m.path == ACCESS => {\n                storage_texture_attrs.access = m.value.into_token_stream();\n            }\n            // Parse #[storage_texture(0, visibility(...))].\n            List(m) if m.path == VISIBILITY => {\n                storage_texture_attrs.visibility = get_visibility_flag_value(&m)?;\n            }\n            NameValue(m) => {\n                return Err(Error::new_spanned(\n                    m.path,\n                    \"Not a valid name. Available attributes: `dimension`, `image_format`, `access`.\",\n                ));\n            }\n            _ => {\n                return Err(Error::new_spanned(\n                    meta,\n                    \"Not a name value pair: `foo = \\\"...\\\"`\",\n                ));\n            }\n        }\n    }\n\n    Ok(storage_texture_attrs)\n}\n\nconst DIMENSION: Symbol = Symbol(\"dimension\");\nconst IMAGE_FORMAT: Symbol = Symbol(\"image_format\");\nconst ACCESS: Symbol = Symbol(\"access\");\nconst SAMPLE_TYPE: Symbol = Symbol(\"sample_type\");\nconst FILTERABLE: Symbol = Symbol(\"filterable\");\nconst MULTISAMPLED: Symbol = Symbol(\"multisampled\");\n\n// Values for `dimension` attribute.\nconst DIM_1D: &str = \"1d\";\nconst DIM_2D: &str = \"2d\";\nconst DIM_3D: &str = \"3d\";\nconst DIM_2D_ARRAY: &str = \"2d_array\";\nconst DIM_CUBE: &str = \"cube\";\nconst DIM_CUBE_ARRAY: &str = \"cube_array\";\n\n// Values for sample `type` attribute.\nconst FLOAT: &str = \"float\";\nconst DEPTH: &str = \"depth\";\nconst S_INT: &str = \"s_int\";\nconst U_INT: &str = \"u_int\";\n\nfn get_texture_attrs(metas: Vec<Meta>) -> Result<TextureAttrs> {\n    let mut dimension = Default::default();\n    let mut sample_type = Default::default();\n    let mut multisampled = Default::default();\n    let mut filterable = None;\n    let mut filterable_ident = None;\n\n    let mut visibility = ShaderStageVisibility::vertex_fragment();\n\n    for meta in metas {\n        use syn::Meta::{List, NameValue};\n        match meta {\n            // Parse #[texture(0, dimension = \"...\")].\n            NameValue(m) if m.path == DIMENSION => {\n                let value = get_lit_str(DIMENSION, &m.value)?;\n                dimension = get_texture_dimension_value(value)?;\n            }\n            // Parse #[texture(0, sample_type = \"...\")].\n            NameValue(m) if m.path == SAMPLE_TYPE => {\n                let value = get_lit_str(SAMPLE_TYPE, &m.value)?;\n                sample_type = get_texture_sample_type_value(value)?;\n            }\n            // Parse #[texture(0, multisampled = \"...\")].\n            NameValue(m) if m.path == MULTISAMPLED => {\n                multisampled = get_lit_bool(MULTISAMPLED, &m.value)?;\n            }\n            // Parse #[texture(0, filterable = \"...\")].\n            NameValue(m) if m.path == FILTERABLE => {\n                filterable = get_lit_bool(FILTERABLE, &m.value)?.into();\n                filterable_ident = m.path.into();\n            }\n            // Parse #[texture(0, visibility(...))].\n            List(m) if m.path == VISIBILITY => {\n                visibility = get_visibility_flag_value(&m)?;\n            }\n            NameValue(m) => {\n                return Err(Error::new_spanned(\n                    m.path,\n                    \"Not a valid name. Available attributes: `dimension`, `sample_type`, `multisampled`, or `filterable`.\"\n                ));\n            }\n            _ => {\n                return Err(Error::new_spanned(\n                    meta,\n                    \"Not a name value pair: `foo = \\\"...\\\"`\",\n                ));\n            }\n        }\n    }\n\n    // Resolve `filterable` since the float\n    // sample type is the one that contains the value.\n    if let Some(filterable) = filterable {\n        let path = filterable_ident.unwrap();\n        match sample_type {\n            BindingTextureSampleType::Float { filterable: _ } => {\n                sample_type = BindingTextureSampleType::Float { filterable }\n            }\n            _ => {\n                return Err(Error::new_spanned(\n                    path,\n                    \"Type must be `float` to use the `filterable` attribute.\",\n                ));\n            }\n        };\n    }\n\n    Ok(TextureAttrs {\n        dimension,\n        sample_type,\n        multisampled,\n        visibility,\n    })\n}\n\nfn get_texture_dimension_value(lit_str: &LitStr) -> Result<BindingTextureDimension> {\n    match lit_str.value().as_str() {\n        DIM_1D => Ok(BindingTextureDimension::D1),\n        DIM_2D => Ok(BindingTextureDimension::D2),\n        DIM_2D_ARRAY => Ok(BindingTextureDimension::D2Array),\n        DIM_3D => Ok(BindingTextureDimension::D3),\n        DIM_CUBE => Ok(BindingTextureDimension::Cube),\n        DIM_CUBE_ARRAY => Ok(BindingTextureDimension::CubeArray),\n\n        _ => Err(Error::new_spanned(\n            lit_str,\n            \"Not a valid dimension. Must be `1d`, `2d`, `2d_array`, `3d`, `cube` or `cube_array`.\",\n        )),\n    }\n}\n\nfn get_texture_sample_type_value(lit_str: &LitStr) -> Result<BindingTextureSampleType> {\n    match lit_str.value().as_str() {\n        FLOAT => Ok(BindingTextureSampleType::Float { filterable: true }),\n        DEPTH => Ok(BindingTextureSampleType::Depth),\n        S_INT => Ok(BindingTextureSampleType::Sint),\n        U_INT => Ok(BindingTextureSampleType::Uint),\n\n        _ => Err(Error::new_spanned(\n            lit_str,\n            \"Not a valid sample type. Must be `float`, `depth`, `s_int` or `u_int`.\",\n        )),\n    }\n}\n\n#[derive(Default)]\nstruct SamplerAttrs {\n    sampler_binding_type: SamplerBindingType,\n    visibility: ShaderStageVisibility,\n}\n\n#[derive(Default)]\nenum SamplerBindingType {\n    #[default]\n    Filtering,\n    NonFiltering,\n    Comparison,\n}\n\nimpl ToTokens for SamplerBindingType {\n    fn to_tokens(&self, tokens: &mut proc_macro2::TokenStream) {\n        tokens.extend(match self {\n            SamplerBindingType::Filtering => quote! { SamplerBindingType::Filtering },\n            SamplerBindingType::NonFiltering => quote! { SamplerBindingType::NonFiltering },\n            SamplerBindingType::Comparison => quote! { SamplerBindingType::Comparison },\n        });\n    }\n}\n\nconst SAMPLER_TYPE: Symbol = Symbol(\"sampler_type\");\n\nconst FILTERING: &str = \"filtering\";\nconst NON_FILTERING: &str = \"non_filtering\";\nconst COMPARISON: &str = \"comparison\";\n\nfn get_sampler_attrs(metas: Vec<Meta>) -> Result<SamplerAttrs> {\n    let mut sampler_binding_type = Default::default();\n    let mut visibility = ShaderStageVisibility::vertex_fragment();\n\n    for meta in metas {\n        use syn::Meta::{List, NameValue};\n        match meta {\n            // Parse #[sampler(0, sampler_type = \"...\"))].\n            NameValue(m) if m.path == SAMPLER_TYPE => {\n                let value = get_lit_str(DIMENSION, &m.value)?;\n                sampler_binding_type = get_sampler_binding_type_value(value)?;\n            }\n            // Parse #[sampler(0, visibility(...))].\n            List(m) if m.path == VISIBILITY => {\n                visibility = get_visibility_flag_value(&m)?;\n            }\n            NameValue(m) => {\n                return Err(Error::new_spanned(\n                    m.path,\n                    \"Not a valid name. Available attributes: `sampler_type`.\",\n                ));\n            }\n            _ => {\n                return Err(Error::new_spanned(\n                    meta,\n                    \"Not a name value pair: `foo = \\\"...\\\"`\",\n                ));\n            }\n        }\n    }\n\n    Ok(SamplerAttrs {\n        sampler_binding_type,\n        visibility,\n    })\n}\n\nfn get_sampler_binding_type_value(lit_str: &LitStr) -> Result<SamplerBindingType> {\n    match lit_str.value().as_str() {\n        FILTERING => Ok(SamplerBindingType::Filtering),\n        NON_FILTERING => Ok(SamplerBindingType::NonFiltering),\n        COMPARISON => Ok(SamplerBindingType::Comparison),\n\n        _ => Err(Error::new_spanned(\n            lit_str,\n            \"Not a valid dimension. Must be `filtering`, `non_filtering`, or `comparison`.\",\n        )),\n    }\n}\n\n#[derive(Default)]\nstruct StorageAttrs {\n    visibility: ShaderStageVisibility,\n    read_only: bool,\n    buffer: bool,\n}\n\nconst READ_ONLY: Symbol = Symbol(\"read_only\");\nconst BUFFER: Symbol = Symbol(\"buffer\");\n\nfn get_storage_binding_attr(metas: Vec<Meta>) -> Result<StorageAttrs> {\n    let mut visibility = ShaderStageVisibility::vertex_fragment();\n    let mut read_only = false;\n    let mut buffer = false;\n\n    for meta in metas {\n        use syn::Meta::{List, Path};\n        match meta {\n            // Parse #[storage(0, visibility(...))].\n            List(m) if m.path == VISIBILITY => {\n                visibility = get_visibility_flag_value(&m)?;\n            }\n            Path(path) if path == READ_ONLY => {\n                read_only = true;\n            }\n            Path(path) if path == BUFFER => {\n                buffer = true;\n            }\n            _ => {\n                return Err(Error::new_spanned(\n                    meta,\n                    \"Not a valid attribute. Available attributes: `read_only`, `visibility`\",\n                ));\n            }\n        }\n    }\n\n    Ok(StorageAttrs {\n        visibility,\n        read_only,\n        buffer,\n    })\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "0932c8ceadf5aa4248071b68b52551f5e94689d6",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_render/src/lib.rs",
    "func": "// FIXME(15321): solve CI failures, then replace with `#![expect()]`.\n#![allow(missing_docs, reason = \"Not all docs are written yet, see #3492.\")]\n#![allow(unsafe_code)]\n// `rustdoc_internals` is needed for `#[doc(fake_variadics)]`\n#![allow(internal_features)]\n#![cfg_attr(any(docsrs, docsrs_dep), feature(doc_auto_cfg, rustdoc_internals))]\n#![doc(\n    html_logo_url = \"https://bevyengine.org/assets/icon.png\",\n    html_favicon_url = \"https://bevyengine.org/assets/icon.png\"\n)]\n\n#[cfg(target_pointer_width = \"16\")]\ncompile_error!(\"bevy_render cannot compile for a 16-bit platform.\");\n\nextern crate alloc;\nextern crate core;\n\npub mod alpha;\npub mod batching;\npub mod camera;\npub mod diagnostic;\npub mod extract_component;\npub mod extract_instances;\nmod extract_param;\npub mod extract_resource;\npub mod globals;\npub mod gpu_component_array_buffer;\npub mod gpu_readback;\npub mod mesh;\n#[cfg(not(target_arch = \"wasm32\"))]\npub mod pipelined_rendering;\npub mod primitives;\npub mod render_asset;\npub mod render_graph;\npub mod render_phase;\npub mod render_resource;\npub mod renderer;\npub mod settings;\nmod spatial_bundle;\npub mod storage;\npub mod sync_component;\npub mod sync_world;\npub mod texture;\npub mod view;\n\n/// The render prelude.\n///\n/// This includes the most common types in this crate, re-exported for your convenience.\n#[expect(deprecated)]\npub mod prelude {\n    #[doc(hidden)]\n    pub use crate::{\n        alpha::AlphaMode,\n        camera::{\n            Camera, ClearColor, ClearColorConfig, OrthographicProjection, PerspectiveProjection,\n            Projection,\n        },\n        mesh::{\n            morph::MorphWeights, primitives::MeshBuilder, primitives::Meshable, Mesh, Mesh2d,\n            Mesh3d,\n        },\n        render_resource::Shader,\n        spatial_bundle::SpatialBundle,\n        texture::ImagePlugin,\n        view::{InheritedVisibility, Msaa, ViewVisibility, Visibility, VisibilityBundle},\n        ExtractSchedule,\n    };\n}\nuse batching::gpu_preprocessing::BatchingPlugin;\nuse bevy_ecs::schedule::ScheduleBuildSettings;\nuse bevy_utils::prelude::default;\npub use extract_param::Extract;\n\nuse bevy_hierarchy::ValidParentCheckPlugin;\nuse bevy_window::{PrimaryWindow, RawHandleWrapperHolder};\nuse extract_resource::ExtractResourcePlugin;\nuse globals::GlobalsPlugin;\nuse render_asset::RenderAssetBytesPerFrame;\nuse renderer::{RenderDevice, RenderQueue};\nuse settings::RenderResources;\nuse sync_world::{\n    despawn_temporary_render_entities, entity_sync_system, SyncToRenderWorld, SyncWorldPlugin,\n};\n\nuse crate::gpu_readback::GpuReadbackPlugin;\nuse crate::{\n    camera::CameraPlugin,\n    mesh::{MeshPlugin, MorphPlugin, RenderMesh},\n    render_asset::prepare_assets,\n    render_resource::{PipelineCache, Shader, ShaderLoader},\n    renderer::{render_system, RenderInstance, WgpuWrapper},\n    settings::RenderCreation,\n    storage::StoragePlugin,\n    view::{ViewPlugin, WindowRenderPlugin},\n};\nuse alloc::sync::Arc;\nuse bevy_app::{App, AppLabel, Plugin, SubApp};\nuse bevy_asset::{load_internal_asset, AssetApp, AssetServer, Handle};\nuse bevy_ecs::{prelude::*, schedule::ScheduleLabel};\nuse bevy_utils::tracing::debug;\nuse core::ops::{Deref, DerefMut};\nuse std::sync::Mutex;\n\n/// Contains the default Bevy rendering backend based on wgpu.\n///\n/// Rendering is done in a [`SubApp`], which exchanges data with the main app\n/// between main schedule iterations.\n///\n/// Rendering can be executed between iterations of the main schedule,\n/// or it can be executed in parallel with main schedule when\n/// [`PipelinedRenderingPlugin`](pipelined_rendering::PipelinedRenderingPlugin) is enabled.\n#[derive(Default)]\npub struct RenderPlugin {\n    pub render_creation: RenderCreation,\n    /// If `true`, disables asynchronous pipeline compilation.\n    /// This has no effect on macOS, Wasm, iOS, or without the `multi_threaded` feature.\n    pub synchronous_pipeline_compilation: bool,\n}\n\n/// The systems sets of the default [`App`] rendering schedule.\n///\n/// These can be useful for ordering, but you almost never want to add your systems to these sets.\n#[derive(Debug, Hash, PartialEq, Eq, Clone, SystemSet)]\npub enum RenderSet {\n    /// This is used for applying the commands from the [`ExtractSchedule`]\n    ExtractCommands,\n    /// Prepare assets that have been created/modified/removed this frame.\n    PrepareAssets,\n    /// Create any additional views such as those used for shadow mapping.\n    ManageViews,\n    /// Queue drawable entities as phase items in render phases ready for\n    /// sorting (if necessary)\n    Queue,\n    /// A sub-set within [`Queue`](RenderSet::Queue) where mesh entity queue systems are executed. Ensures `prepare_assets::<RenderMesh>` is completed.\n    QueueMeshes,\n    // TODO: This could probably be moved in favor of a system ordering\n    // abstraction in `Render` or `Queue`\n    /// Sort the [`SortedRenderPhase`](render_phase::SortedRenderPhase)s and\n    /// [`BinKey`](render_phase::BinnedPhaseItem::BinKey)s here.\n    PhaseSort,\n    /// Prepare render resources from extracted data for the GPU based on their sorted order.\n    /// Create [`BindGroups`](render_resource::BindGroup) that depend on those data.\n    Prepare,\n    /// A sub-set within [`Prepare`](RenderSet::Prepare) for initializing buffers, textures and uniforms for use in bind groups.\n    PrepareResources,\n    /// Flush buffers after [`PrepareResources`](RenderSet::PrepareResources), but before [`PrepareBindGroups`](RenderSet::PrepareBindGroups).\n    PrepareResourcesFlush,\n    /// A sub-set within [`Prepare`](RenderSet::Prepare) for constructing bind groups, or other data that relies on render resources prepared in [`PrepareResources`](RenderSet::PrepareResources).\n    PrepareBindGroups,\n    /// Actual rendering happens here.\n    /// In most cases, only the render backend should insert resources here.\n    Render,\n    /// Cleanup render resources here.\n    Cleanup,\n    /// Final cleanup occurs: all entities will be despawned.\n    ///\n    /// Runs after [`Cleanup`](RenderSet::Cleanup).\n    PostCleanup,\n}\n\n/// The main render schedule.\n#[derive(ScheduleLabel, Debug, Hash, PartialEq, Eq, Clone)]\npub struct Render;\n\nimpl Render {\n    /// Sets up the base structure of the rendering [`Schedule`].\n    ///\n    /// The sets defined in this enum are configured to run in order.\n    pub fn base_schedule() -> Schedule {\n        use RenderSet::*;\n\n        let mut schedule = Schedule::new(Self);\n\n        schedule.configure_sets(\n            (\n                ExtractCommands,\n                ManageViews,\n                Queue,\n                PhaseSort,\n                Prepare,\n                Render,\n                Cleanup,\n                PostCleanup,\n            )\n                .chain(),\n        );\n\n        schedule.configure_sets((ExtractCommands, PrepareAssets, Prepare).chain());\n        schedule.configure_sets(\n            QueueMeshes\n                .in_set(Queue)\n                .after(prepare_assets::<RenderMesh>),\n        );\n        schedule.configure_sets(\n            (PrepareResources, PrepareResourcesFlush, PrepareBindGroups)\n                .chain()\n                .in_set(Prepare),\n        );\n\n        schedule\n    }\n}\n\n/// Schedule which extract data from the main world and inserts it into the render world.\n///\n/// This step should be kept as short as possible to increase the \"pipelining potential\" for\n/// running the next frame while rendering the current frame.\n///\n/// This schedule is run on the main world, but its buffers are not applied\n/// until it is returned to the render world.\n#[derive(ScheduleLabel, PartialEq, Eq, Debug, Clone, Hash)]\npub struct ExtractSchedule;\n\n/// The simulation [`World`] of the application, stored as a resource.\n///\n/// This resource is only available during [`ExtractSchedule`] and not\n/// during command application of that schedule.\n/// See [`Extract`] for more details.\n#[derive(Resource, Default)]\npub struct MainWorld(World);\n\nimpl Deref for MainWorld {\n    type Target = World;\n\n    fn deref(&self) -> &Self::Target {\n        &self.0\n    }\n}\n\nimpl DerefMut for MainWorld {\n    fn deref_mut(&mut self) -> &mut Self::Target {\n        &mut self.0\n    }\n}\n\npub mod graph {\n    use crate::render_graph::RenderLabel;\n\n    #[derive(Debug, Hash, PartialEq, Eq, Clone, RenderLabel)]\n    pub struct CameraDriverLabel;\n}\n\n#[derive(Resource)]\nstruct FutureRenderResources(Arc<Mutex<Option<RenderResources>>>);\n\n/// A label for the rendering sub-app.\n#[derive(Debug, Clone, Copy, Hash, PartialEq, Eq, AppLabel)]\npub struct RenderApp;\n\npub const INSTANCE_INDEX_SHADER_HANDLE: Handle<Shader> =\n    Handle::weak_from_u128(10313207077636615845);\npub const MATHS_SHADER_HANDLE: Handle<Shader> = Handle::weak_from_u128(10665356303104593376);\npub const COLOR_OPERATIONS_SHADER_HANDLE: Handle<Shader> =\n    Handle::weak_from_u128(1844674407370955161);\n\nimpl Plugin for RenderPlugin {\n    /// Initializes the renderer, sets up the [`RenderSet`] and creates the rendering sub-app.\n    fn build(&self, app: &mut App) {\n        app.init_asset::<Shader>()\n            .init_asset_loader::<ShaderLoader>();\n\n        match &self.render_creation {\n            RenderCreation::Manual(resources) => {\n                let future_render_resources_wrapper = Arc::new(Mutex::new(Some(resources.clone())));\n                app.insert_resource(FutureRenderResources(\n                    future_render_resources_wrapper.clone(),\n                ));\n                // SAFETY: Plugins should be set up on the main thread.\n                unsafe { initialize_render_app(app) };\n            }\n            RenderCreation::Automatic(render_creation) => {\n                if let Some(backends) = render_creation.backends {\n                    let future_render_resources_wrapper = Arc::new(Mutex::new(None));\n                    app.insert_resource(FutureRenderResources(\n                        future_render_resources_wrapper.clone(),\n                    ));\n\n                    let primary_window = app\n                        .world_mut()\n                        .query_filtered::<&RawHandleWrapperHolder, With<PrimaryWindow>>()\n                        .get_single(app.world())\n                        .ok()\n                        .cloned();\n                    let settings = render_creation.clone();\n                    let async_renderer = async move {\n                        let instance = wgpu::Instance::new(wgpu::InstanceDescriptor {\n                            backends,\n                            dx12_shader_compiler: settings.dx12_shader_compiler.clone(),\n                            flags: settings.instance_flags,\n                            gles_minor_version: settings.gles3_minor_version,\n                        });\n\n                        let surface = primary_window.and_then(|wrapper| {\n                            let maybe_handle = wrapper.0.lock().expect(\n                                \"Couldn't get the window handle in time for renderer initialization\",\n                            );\n                            if let Some(wrapper) = maybe_handle.as_ref() {\n                                // SAFETY: Plugins should be set up on the main thread.\n                                let handle = unsafe { wrapper.get_handle() };\n                                Some(\n                                    instance\n                                        .create_surface(handle)\n                                        .expect(\"Failed to create wgpu surface\"),\n                                )\n                            } else {\n                                None\n                            }\n                        });\n\n                        let request_adapter_options = wgpu::RequestAdapterOptions {\n                            power_preference: settings.power_preference,\n                            compatible_surface: surface.as_ref(),\n                            ..Default::default()\n                        };\n\n                        let (device, queue, adapter_info, render_adapter) =\n                            renderer::initialize_renderer(\n                                &instance,\n                                &settings,\n                                &request_adapter_options,\n                            )\n                            .await;\n                        debug!(\"Configured wgpu adapter Limits: {:#?}\", device.limits());\n                        debug!(\"Configured wgpu adapter Features: {:#?}\", device.features());\n                        let mut future_render_resources_inner =\n                            future_render_resources_wrapper.lock().unwrap();\n                        *future_render_resources_inner = Some(RenderResources(\n                            device,\n                            queue,\n                            adapter_info,\n                            render_adapter,\n                            RenderInstance(Arc::new(WgpuWrapper::new(instance))),\n                        ));\n                    };\n                    // In wasm, spawn a task and detach it for execution\n                    #[cfg(target_arch = \"wasm32\")]\n                    bevy_tasks::IoTaskPool::get()\n                        .spawn_local(async_renderer)\n                        .detach();\n                    // Otherwise, just block for it to complete\n                    #[cfg(not(target_arch = \"wasm32\"))]\n                    futures_lite::future::block_on(async_renderer);\n\n                    // SAFETY: Plugins should be set up on the main thread.\n                    unsafe { initialize_render_app(app) };\n                }\n            }\n        };\n\n        app.add_plugins((\n            ValidParentCheckPlugin::<view::InheritedVisibility>::default(),\n            WindowRenderPlugin,\n            CameraPlugin,\n            ViewPlugin,\n            MeshPlugin,\n            GlobalsPlugin,\n            MorphPlugin,\n            BatchingPlugin,\n            SyncWorldPlugin,\n            StoragePlugin,\n            GpuReadbackPlugin::default(),\n        ));\n\n        app.init_resource::<RenderAssetBytesPerFrame>()\n            .add_plugins(ExtractResourcePlugin::<RenderAssetBytesPerFrame>::default());\n\n        app.register_type::<alpha::AlphaMode>()\n            // These types cannot be registered in bevy_color, as it does not depend on the rest of Bevy\n            .register_type::<bevy_color::Color>()\n            .register_type::<primitives::Aabb>()\n            .register_type::<primitives::CascadesFrusta>()\n            .register_type::<primitives::CubemapFrusta>()\n            .register_type::<primitives::Frustum>()\n            .register_type::<SyncToRenderWorld>();\n    }\n\n    fn ready(&self, app: &App) -> bool {\n        app.world()\n            .get_resource::<FutureRenderResources>()\n            .and_then(|frr| frr.0.try_lock().map(|locked| locked.is_some()).ok())\n            .unwrap_or(true)\n    }\n\n    fn finish(&self, app: &mut App) {\n        load_internal_asset!(app, MATHS_SHADER_HANDLE, \"maths.wgsl\", Shader::from_wgsl);\n        load_internal_asset!(\n            app,\n            COLOR_OPERATIONS_SHADER_HANDLE,\n            \"color_operations.wgsl\",\n            Shader::from_wgsl\n        );\n        if let Some(future_render_resources) =\n            app.world_mut().remove_resource::<FutureRenderResources>()\n        {\n            let RenderResources(device, queue, adapter_info, render_adapter, instance) =\n                future_render_resources.0.lock().unwrap().take().unwrap();\n\n            app.insert_resource(device.clone())\n                .insert_resource(queue.clone())\n                .insert_resource(adapter_info.clone())\n                .insert_resource(render_adapter.clone());\n\n            let render_app = app.sub_app_mut(RenderApp);\n\n            render_app\n                .insert_resource(instance)\n                .insert_resource(PipelineCache::new(\n                    device.clone(),\n                    render_adapter.clone(),\n                    self.synchronous_pipeline_compilation,\n                ))\n                .insert_resource(device)\n                .insert_resource(queue)\n                .insert_resource(render_adapter)\n                .insert_resource(adapter_info)\n                .add_systems(\n                    Render,\n                    (|mut bpf: ResMut<RenderAssetBytesPerFrame>| {\n                        bpf.reset();\n                    })\n                    .in_set(RenderSet::Cleanup),\n                );\n        }\n    }\n}\n\n/// A \"scratch\" world used to avoid allocating new worlds every frame when\n/// swapping out the [`MainWorld`] for [`ExtractSchedule`].\n#[derive(Resource, Default)]\nstruct ScratchMainWorld(World);\n\n/// Executes the [`ExtractSchedule`] step of the renderer.\n/// This updates the render world with the extracted ECS data of the current frame.\nfn extract(main_world: &mut World, render_world: &mut World) {\n    // temporarily add the app world to the render world as a resource\n    let scratch_world = main_world.remove_resource::<ScratchMainWorld>().unwrap();\n    let inserted_world = core::mem::replace(main_world, scratch_world.0);\n    render_world.insert_resource(MainWorld(inserted_world));\n    render_world.run_schedule(ExtractSchedule);\n\n    // move the app world back, as if nothing happened.\n    let inserted_world = render_world.remove_resource::<MainWorld>().unwrap();\n    let scratch_world = core::mem::replace(main_world, inserted_world.0);\n    main_world.insert_resource(ScratchMainWorld(scratch_world));\n}\n\n/// # Safety\n/// This function must be called from the main thread.\nunsafe fn initialize_render_app(app: &mut App) {\n    app.init_resource::<ScratchMainWorld>();\n\n    let mut render_app = SubApp::new();\n    render_app.update_schedule = Some(Render.intern());\n\n    let mut extract_schedule = Schedule::new(ExtractSchedule);\n    // We skip applying any commands during the ExtractSchedule\n    // so commands can be applied on the render thread.\n    extract_schedule.set_build_settings(ScheduleBuildSettings {\n        auto_insert_apply_deferred: false,\n        ..default()\n    });\n    extract_schedule.set_apply_final_deferred(false);\n\n    render_app\n        .add_schedule(extract_schedule)\n        .add_schedule(Render::base_schedule())\n        .init_resource::<render_graph::RenderGraph>()\n        .insert_resource(app.world().resource::<AssetServer>().clone())\n        .add_systems(ExtractSchedule, PipelineCache::extract_shaders)\n        .add_systems(\n            Render,\n            (\n                // This set applies the commands from the extract schedule while the render schedule\n                // is running in parallel with the main app.\n                apply_extract_commands.in_set(RenderSet::ExtractCommands),\n                (\n                    PipelineCache::process_pipeline_queue_system.before(render_system),\n                    render_system,\n                )\n                    .in_set(RenderSet::Render),\n                despawn_temporary_render_entities.in_set(RenderSet::PostCleanup),\n            ),\n        );\n\n    render_app.set_extract(|main_world, render_world| {\n        {\n            #[cfg(feature = \"trace\")]\n            let _stage_span = bevy_utils::tracing::info_span!(\"entity_sync\").entered();\n            entity_sync_system(main_world, render_world);\n        }\n\n        // run extract schedule\n        extract(main_world, render_world);\n    });\n\n    let (sender, receiver) = bevy_time::create_time_channels();\n    render_app.insert_resource(sender);\n    app.insert_resource(receiver);\n    app.insert_sub_app(RenderApp, render_app);\n}\n\n/// Applies the commands from the extract schedule. This happens during\n/// the render schedule rather than during extraction to allow the commands to run in parallel with the\n/// main app when pipelined rendering is enabled.\nfn apply_extract_commands(render_world: &mut World) {\n    render_world.resource_scope(|render_world, mut schedules: Mut<Schedules>| {\n        schedules\n            .get_mut(ExtractSchedule)\n            .unwrap()\n            .apply_deferred(render_world);\n    });\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "a5e8c2605ec332f15972c2475c3bdfb5e0ca1601",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_render/src/render_phase/draw.rs",
    "func": "use crate::render_phase::{PhaseItem, TrackedRenderPass};\nuse bevy_app::{App, SubApp};\nuse bevy_ecs::{\n    entity::Entity,\n    query::{QueryEntityError, QueryState, ROQueryItem, ReadOnlyQueryData},\n    system::{ReadOnlySystemParam, Resource, SystemParam, SystemParamItem, SystemState},\n    world::World,\n};\nuse bevy_utils::TypeIdMap;\nuse core::{any::TypeId, fmt::Debug, hash::Hash};\nuse std::sync::{PoisonError, RwLock, RwLockReadGuard, RwLockWriteGuard};\nuse thiserror::Error;\nuse variadics_please::all_tuples;\n\n/// A draw function used to draw [`PhaseItem`]s.\n///\n/// The draw function can retrieve and query the required ECS data from the render world.\n///\n/// This trait can either be implemented directly or implicitly composed out of multiple modular\n/// [`RenderCommand`]s. For more details and an example see the [`RenderCommand`] documentation.\npub trait Draw<P: PhaseItem>: Send + Sync + 'static {\n    /// Prepares the draw function to be used. This is called once and only once before the phase\n    /// begins. There may be zero or more [`draw`](Draw::draw) calls following a call to this function.\n    /// Implementing this is optional.\n    #[allow(unused_variables)]\n    fn prepare(&mut self, world: &'_ World) {}\n\n    /// Draws a [`PhaseItem`] by issuing zero or more `draw` calls via the [`TrackedRenderPass`].\n    fn draw<'w>(\n        &mut self,\n        world: &'w World,\n        pass: &mut TrackedRenderPass<'w>,\n        view: Entity,\n        item: &P,\n    ) -> Result<(), DrawError>;\n}\n\n#[derive(Error, Debug, PartialEq, Eq)]\npub enum DrawError {\n    #[error(\"Failed to execute render command {0:?}\")]\n    RenderCommandFailure(&'static str),\n    #[error(\"Failed to get execute view query\")]\n    InvalidViewQuery,\n    #[error(\"View entity not found\")]\n    ViewEntityNotFound,\n}\n\n// TODO: make this generic?\n/// An identifier for a [`Draw`] function stored in [`DrawFunctions`].\n#[derive(Copy, Clone, Debug, Eq, PartialEq, PartialOrd, Ord, Hash)]\npub struct DrawFunctionId(u32);\n\n/// Stores all [`Draw`] functions for the [`PhaseItem`] type.\n///\n/// For retrieval, the [`Draw`] functions are mapped to their respective [`TypeId`]s.\npub struct DrawFunctionsInternal<P: PhaseItem> {\n    pub draw_functions: Vec<Box<dyn Draw<P>>>,\n    pub indices: TypeIdMap<DrawFunctionId>,\n}\n\nimpl<P: PhaseItem> DrawFunctionsInternal<P> {\n    /// Prepares all draw function. This is called once and only once before the phase begins.\n    pub fn prepare(&mut self, world: &World) {\n        for function in &mut self.draw_functions {\n            function.prepare(world);\n        }\n    }\n\n    /// Adds the [`Draw`] function and maps it to its own type.\n    pub fn add<T: Draw<P>>(&mut self, draw_function: T) -> DrawFunctionId {\n        self.add_with::<T, T>(draw_function)\n    }\n\n    /// Adds the [`Draw`] function and maps it to the type `T`\n    pub fn add_with<T: 'static, D: Draw<P>>(&mut self, draw_function: D) -> DrawFunctionId {\n        let id = DrawFunctionId(self.draw_functions.len().try_into().unwrap());\n        self.draw_functions.push(Box::new(draw_function));\n        self.indices.insert(TypeId::of::<T>(), id);\n        id\n    }\n\n    /// Retrieves the [`Draw`] function corresponding to the `id` mutably.\n    pub fn get_mut(&mut self, id: DrawFunctionId) -> Option<&mut dyn Draw<P>> {\n        self.draw_functions.get_mut(id.0 as usize).map(|f| &mut **f)\n    }\n\n    /// Retrieves the id of the [`Draw`] function corresponding to their associated type `T`.\n    pub fn get_id<T: 'static>(&self) -> Option<DrawFunctionId> {\n        self.indices.get(&TypeId::of::<T>()).copied()\n    }\n\n    /// Retrieves the id of the [`Draw`] function corresponding to their associated type `T`.\n    ///\n    /// Fallible wrapper for [`Self::get_id()`]\n    ///\n    /// ## Panics\n    /// If the id doesn't exist, this function will panic.\n    pub fn id<T: 'static>(&self) -> DrawFunctionId {\n        self.get_id::<T>().unwrap_or_else(|| {\n            panic!(\n                \"Draw function {} not found for {}\",\n                core::any::type_name::<T>(),\n                core::any::type_name::<P>()\n            )\n        })\n    }\n}\n\n/// Stores all draw functions for the [`PhaseItem`] type hidden behind a reader-writer lock.\n///\n/// To access them the [`DrawFunctions::read`] and [`DrawFunctions::write`] methods are used.\n#[derive(Resource)]\npub struct DrawFunctions<P: PhaseItem> {\n    internal: RwLock<DrawFunctionsInternal<P>>,\n}\n\nimpl<P: PhaseItem> Default for DrawFunctions<P> {\n    fn default() -> Self {\n        Self {\n            internal: RwLock::new(DrawFunctionsInternal {\n                draw_functions: Vec::new(),\n                indices: Default::default(),\n            }),\n        }\n    }\n}\n\nimpl<P: PhaseItem> DrawFunctions<P> {\n    /// Accesses the draw functions in read mode.\n    pub fn read(&self) -> RwLockReadGuard<'_, DrawFunctionsInternal<P>> {\n        self.internal.read().unwrap_or_else(PoisonError::into_inner)\n    }\n\n    /// Accesses the draw functions in write mode.\n    pub fn write(&self) -> RwLockWriteGuard<'_, DrawFunctionsInternal<P>> {\n        self.internal\n            .write()\n            .unwrap_or_else(PoisonError::into_inner)\n    }\n}\n\n/// [`RenderCommand`]s are modular standardized pieces of render logic that can be composed into\n/// [`Draw`] functions.\n///\n/// To turn a stateless render command into a usable draw function it has to be wrapped by a\n/// [`RenderCommandState`].\n/// This is done automatically when registering a render command as a [`Draw`] function via the\n/// [`AddRenderCommand::add_render_command`] method.\n///\n/// Compared to the draw function the required ECS data is fetched automatically\n/// (by the [`RenderCommandState`]) from the render world.\n/// Therefore the three types [`Param`](RenderCommand::Param),\n/// [`ViewQuery`](RenderCommand::ViewQuery) and\n/// [`ItemQuery`](RenderCommand::ItemQuery) are used.\n/// They specify which information is required to execute the render command.\n///\n/// Multiple render commands can be combined together by wrapping them in a tuple.\n///\n/// # Example\n///\n/// The `DrawMaterial` draw function is created from the following render command\n/// tuple. Const generics are used to set specific bind group locations:\n///\n/// ```\n/// # use bevy_render::render_phase::SetItemPipeline;\n/// # struct SetMeshViewBindGroup<const N: usize>;\n/// # struct SetMeshBindGroup<const N: usize>;\n/// # struct SetMaterialBindGroup<M, const N: usize>(std::marker::PhantomData<M>);\n/// # struct DrawMesh;\n/// pub type DrawMaterial<M> = (\n///     SetItemPipeline,\n///     SetMeshViewBindGroup<0>,\n///     SetMeshBindGroup<1>,\n///     SetMaterialBindGroup<M, 2>,\n///     DrawMesh,\n/// );\n/// ```\npub trait RenderCommand<P: PhaseItem> {\n    /// Specifies the general ECS data (e.g. resources) required by [`RenderCommand::render`].\n    ///\n    /// When fetching resources, note that, due to lifetime limitations of the `Deref` trait,\n    /// [`SRes::into_inner`] must be called on each [`SRes`] reference in the\n    /// [`RenderCommand::render`] method, instead of being automatically dereferenced as is the\n    /// case in normal `systems`.\n    ///\n    /// All parameters have to be read only.\n    ///\n    /// [`SRes`]: bevy_ecs::system::lifetimeless::SRes\n    /// [`SRes::into_inner`]: bevy_ecs::system::lifetimeless::SRes::into_inner\n    type Param: SystemParam + 'static;\n    /// Specifies the ECS data of the view entity required by [`RenderCommand::render`].\n    ///\n    /// The view entity refers to the camera, or shadow-casting light, etc. from which the phase\n    /// item will be rendered from.\n    /// All components have to be accessed read only.\n    type ViewQuery: ReadOnlyQueryData;\n    /// Specifies the ECS data of the item entity required by [`RenderCommand::render`].\n    ///\n    /// The item is the entity that will be rendered for the corresponding view.\n    /// All components have to be accessed read only.\n    ///\n    /// For efficiency reasons, Bevy doesn't always extract entities to the\n    /// render world; for instance, entities that simply consist of meshes are\n    /// often not extracted. If the entity doesn't exist in the render world,\n    /// the supplied query data will be `None`.\n    type ItemQuery: ReadOnlyQueryData;\n\n    /// Renders a [`PhaseItem`] by recording commands (e.g. setting pipelines, binding bind groups,\n    /// issuing draw calls, etc.) via the [`TrackedRenderPass`].\n    fn render<'w>(\n        item: &P,\n        view: ROQueryItem<'w, Self::ViewQuery>,\n        entity: Option<ROQueryItem<'w, Self::ItemQuery>>,\n        param: SystemParamItem<'w, '_, Self::Param>,\n        pass: &mut TrackedRenderPass<'w>,\n    ) -> RenderCommandResult;\n}\n\n/// The result of a [`RenderCommand`].\n#[derive(Debug)]\npub enum RenderCommandResult {\n    Success,\n    Skip,\n    Failure(&'static str),\n}\n\nmacro_rules! render_command_tuple_impl {\n    ($(#[$meta:meta])* $(($name: ident, $view: ident, $entity: ident)),*) => {\n        $(#[$meta])*\n        impl<P: PhaseItem, $($name: RenderCommand<P>),*> RenderCommand<P> for ($($name,)*) {\n            type Param = ($($name::Param,)*);\n            type ViewQuery = ($($name::ViewQuery,)*);\n            type ItemQuery = ($($name::ItemQuery,)*);\n\n            #[allow(non_snake_case)]\n            fn render<'w>(\n                _item: &P,\n                ($($view,)*): ROQueryItem<'w, Self::ViewQuery>,\n                maybe_entities: Option<ROQueryItem<'w, Self::ItemQuery>>,\n                ($($name,)*): SystemParamItem<'w, '_, Self::Param>,\n                _pass: &mut TrackedRenderPass<'w>,\n            ) -> RenderCommandResult {\n                match maybe_entities {\n                    None => {\n                        $(\n                            match $name::render(_item, $view, None, $name, _pass) {\n                                RenderCommandResult::Skip => return RenderCommandResult::Skip,\n                                RenderCommandResult::Failure(reason) => return RenderCommandResult::Failure(reason),\n                                _ => {},\n                            }\n                        )*\n                    }\n                    Some(($($entity,)*)) => {\n                        $(\n                            match $name::render(_item, $view, Some($entity), $name, _pass) {\n                                RenderCommandResult::Skip => return RenderCommandResult::Skip,\n                                RenderCommandResult::Failure(reason) => return RenderCommandResult::Failure(reason),\n                                _ => {},\n                            }\n                        )*\n                    }\n                }\n                RenderCommandResult::Success\n            }\n        }\n    };\n}\n\nall_tuples!(\n    #[doc(fake_variadic)]\n    render_command_tuple_impl,\n    0,\n    15,\n    C,\n    V,\n    E\n);\n\n/// Wraps a [`RenderCommand`] into a state so that it can be used as a [`Draw`] function.\n///\n/// The [`RenderCommand::Param`], [`RenderCommand::ViewQuery`] and\n/// [`RenderCommand::ItemQuery`] are fetched from the ECS and passed to the command.\npub struct RenderCommandState<P: PhaseItem + 'static, C: RenderCommand<P>> {\n    state: SystemState<C::Param>,\n    view: QueryState<C::ViewQuery>,\n    entity: QueryState<C::ItemQuery>,\n}\n\nimpl<P: PhaseItem, C: RenderCommand<P>> RenderCommandState<P, C> {\n    /// Creates a new [`RenderCommandState`] for the [`RenderCommand`].\n    pub fn new(world: &mut World) -> Self {\n        Self {\n            state: SystemState::new(world),\n            view: world.query(),\n            entity: world.query(),\n        }\n    }\n}\n\nimpl<P: PhaseItem, C: RenderCommand<P> + Send + Sync + 'static> Draw<P> for RenderCommandState<P, C>\nwhere\n    C::Param: ReadOnlySystemParam,\n{\n    /// Prepares the render command to be used. This is called once and only once before the phase\n    /// begins. There may be zero or more [`draw`](RenderCommandState::draw) calls following a call to this function.\n    fn prepare(&mut self, world: &'_ World) {\n        self.state.update_archetypes(world);\n        self.view.update_archetypes(world);\n        self.entity.update_archetypes(world);\n    }\n\n    /// Fetches the ECS parameters for the wrapped [`RenderCommand`] and then renders it.\n    fn draw<'w>(\n        &mut self,\n        world: &'w World,\n        pass: &mut TrackedRenderPass<'w>,\n        view: Entity,\n        item: &P,\n    ) -> Result<(), DrawError> {\n        let param = self.state.get_manual(world);\n        let view = match self.view.get_manual(world, view) {\n            Ok(view) => view,\n            Err(err) => match err {\n                QueryEntityError::NoSuchEntity(_) => return Err(DrawError::ViewEntityNotFound),\n                QueryEntityError::QueryDoesNotMatch(_, _)\n                | QueryEntityError::AliasedMutability(_) => {\n                    return Err(DrawError::InvalidViewQuery)\n                }\n            },\n        };\n\n        let entity = self.entity.get_manual(world, item.entity()).ok();\n        match C::render(item, view, entity, param, pass) {\n            RenderCommandResult::Success | RenderCommandResult::Skip => Ok(()),\n            RenderCommandResult::Failure(reason) => Err(DrawError::RenderCommandFailure(reason)),\n        }\n    }\n}\n\n/// Registers a [`RenderCommand`] as a [`Draw`] function.\n/// They are stored inside the [`DrawFunctions`] resource of the app.\npub trait AddRenderCommand {\n    /// Adds the [`RenderCommand`] for the specified render phase to the app.\n    fn add_render_command<P: PhaseItem, C: RenderCommand<P> + Send + Sync + 'static>(\n        &mut self,\n    ) -> &mut Self\n    where\n        C::Param: ReadOnlySystemParam;\n}\n\nimpl AddRenderCommand for SubApp {\n    fn add_render_command<P: PhaseItem, C: RenderCommand<P> + Send + Sync + 'static>(\n        &mut self,\n    ) -> &mut Self\n    where\n        C::Param: ReadOnlySystemParam,\n    {\n        let draw_function = RenderCommandState::<P, C>::new(self.world_mut());\n        let draw_functions = self\n            .world()\n            .get_resource::<DrawFunctions<P>>()\n            .unwrap_or_else(|| {\n                panic!(\n                    \"DrawFunctions<{}> must be added to the world as a resource \\\n                     before adding render commands to it\",\n                    core::any::type_name::<P>(),\n                );\n            });\n        draw_functions.write().add_with::<C, _>(draw_function);\n        self\n    }\n}\n\nimpl AddRenderCommand for App {\n    fn add_render_command<P: PhaseItem, C: RenderCommand<P> + Send + Sync + 'static>(\n        &mut self,\n    ) -> &mut Self\n    where\n        C::Param: ReadOnlySystemParam,\n    {\n        SubApp::add_render_command::<P, C>(self.main_mut());\n        self\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "c11d5b7346ac37c57be2e619044cf339637ce9e0",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_render/src/texture/fallback_image.rs",
    "func": "use crate::{\n    render_asset::RenderAssetUsages,\n    render_resource::*,\n    renderer::{RenderDevice, RenderQueue},\n    texture::{DefaultImageSampler, GpuImage},\n};\nuse bevy_derive::{Deref, DerefMut};\nuse bevy_ecs::{\n    prelude::{FromWorld, Res, ResMut},\n    system::{Resource, SystemParam},\n};\nuse bevy_image::{BevyDefault, Image, ImageSampler, TextureFormatPixelInfo};\nuse bevy_utils::HashMap;\n\n/// A [`RenderApp`](crate::RenderApp) resource that contains the default \"fallback image\",\n/// which can be used in situations where an image was not explicitly defined. The most common\n/// use case is [`AsBindGroup`] implementations (such as materials) that support optional textures.\n///\n/// Defaults to a 1x1 fully opaque white texture, (1.0, 1.0, 1.0, 1.0) which makes multiplying\n/// it with other colors a no-op.\n#[derive(Resource)]\npub struct FallbackImage {\n    /// Fallback image for [`TextureViewDimension::D1`].\n    pub d1: GpuImage,\n    /// Fallback image for [`TextureViewDimension::D2`].\n    pub d2: GpuImage,\n    /// Fallback image for [`TextureViewDimension::D2Array`].\n    pub d2_array: GpuImage,\n    /// Fallback image for [`TextureViewDimension::Cube`].\n    pub cube: GpuImage,\n    /// Fallback image for [`TextureViewDimension::CubeArray`].\n    pub cube_array: GpuImage,\n    /// Fallback image for [`TextureViewDimension::D3`].\n    pub d3: GpuImage,\n}\n\nimpl FallbackImage {\n    /// Returns the appropriate fallback image for the given texture dimension.\n    pub fn get(&self, texture_dimension: TextureViewDimension) -> &GpuImage {\n        match texture_dimension {\n            TextureViewDimension::D1 => &self.d1,\n            TextureViewDimension::D2 => &self.d2,\n            TextureViewDimension::D2Array => &self.d2_array,\n            TextureViewDimension::Cube => &self.cube,\n            TextureViewDimension::CubeArray => &self.cube_array,\n            TextureViewDimension::D3 => &self.d3,\n        }\n    }\n}\n\n/// A [`RenderApp`](crate::RenderApp) resource that contains a _zero-filled_ \"fallback image\",\n/// which can be used in place of [`FallbackImage`], when a fully transparent or black fallback\n/// is required instead of fully opaque white.\n///\n/// Defaults to a 1x1 fully transparent black texture, (0.0, 0.0, 0.0, 0.0) which makes adding\n/// or alpha-blending it to other colors a no-op.\n#[derive(Resource, Deref)]\npub struct FallbackImageZero(GpuImage);\n\n/// A [`RenderApp`](crate::RenderApp) resource that contains a \"cubemap fallback image\",\n/// which can be used in situations where an image was not explicitly defined. The most common\n/// use case is [`AsBindGroup`] implementations (such as materials) that support optional textures.\n#[derive(Resource, Deref)]\npub struct FallbackImageCubemap(GpuImage);\n\nfn fallback_image_new(\n    render_device: &RenderDevice,\n    render_queue: &RenderQueue,\n    default_sampler: &DefaultImageSampler,\n    format: TextureFormat,\n    dimension: TextureViewDimension,\n    samples: u32,\n    value: u8,\n) -> GpuImage {\n    // TODO make this configurable per channel\n\n    let extents = Extent3d {\n        width: 1,\n        height: 1,\n        depth_or_array_layers: match dimension {\n            TextureViewDimension::Cube | TextureViewDimension::CubeArray => 6,\n            _ => 1,\n        },\n    };\n\n    // We can't create textures with data when it's a depth texture or when using multiple samples\n    let create_texture_with_data = !format.is_depth_stencil_format() && samples == 1;\n\n    let image_dimension = dimension.compatible_texture_dimension();\n    let mut image = if create_texture_with_data {\n        let data = vec![value; format.pixel_size()];\n        Image::new_fill(\n            extents,\n            image_dimension,\n            &data,\n            format,\n            RenderAssetUsages::RENDER_WORLD,\n        )\n    } else {\n        let mut image = Image::default();\n        image.texture_descriptor.dimension = TextureDimension::D2;\n        image.texture_descriptor.size = extents;\n        image.texture_descriptor.format = format;\n        image\n    };\n    image.texture_descriptor.sample_count = samples;\n    if image_dimension == TextureDimension::D2 {\n        image.texture_descriptor.usage |= TextureUsages::RENDER_ATTACHMENT;\n    }\n\n    let texture = if create_texture_with_data {\n        render_device.create_texture_with_data(\n            render_queue,\n            &image.texture_descriptor,\n            TextureDataOrder::default(),\n            &image.data,\n        )\n    } else {\n        render_device.create_texture(&image.texture_descriptor)\n    };\n\n    let texture_view = texture.create_view(&TextureViewDescriptor {\n        dimension: Some(dimension),\n        array_layer_count: Some(extents.depth_or_array_layers),\n        ..TextureViewDescriptor::default()\n    });\n    let sampler = match image.sampler {\n        ImageSampler::Default => (**default_sampler).clone(),\n        ImageSampler::Descriptor(ref descriptor) => {\n            render_device.create_sampler(&descriptor.as_wgpu())\n        }\n    };\n    GpuImage {\n        texture,\n        texture_view,\n        texture_format: image.texture_descriptor.format,\n        sampler,\n        size: image.size(),\n        mip_level_count: image.texture_descriptor.mip_level_count,\n    }\n}\n\nimpl FromWorld for FallbackImage {\n    fn from_world(world: &mut bevy_ecs::prelude::World) -> Self {\n        let render_device = world.resource::<RenderDevice>();\n        let render_queue = world.resource::<RenderQueue>();\n        let default_sampler = world.resource::<DefaultImageSampler>();\n        Self {\n            d1: fallback_image_new(\n                render_device,\n                render_queue,\n                default_sampler,\n                TextureFormat::bevy_default(),\n                TextureViewDimension::D1,\n                1,\n                255,\n            ),\n            d2: fallback_image_new(\n                render_device,\n                render_queue,\n                default_sampler,\n                TextureFormat::bevy_default(),\n                TextureViewDimension::D2,\n                1,\n                255,\n            ),\n            d2_array: fallback_image_new(\n                render_device,\n                render_queue,\n                default_sampler,\n                TextureFormat::bevy_default(),\n                TextureViewDimension::D2Array,\n                1,\n                255,\n            ),\n            cube: fallback_image_new(\n                render_device,\n                render_queue,\n                default_sampler,\n                TextureFormat::bevy_default(),\n                TextureViewDimension::Cube,\n                1,\n                255,\n            ),\n            cube_array: fallback_image_new(\n                render_device,\n                render_queue,\n                default_sampler,\n                TextureFormat::bevy_default(),\n                TextureViewDimension::CubeArray,\n                1,\n                255,\n            ),\n            d3: fallback_image_new(\n                render_device,\n                render_queue,\n                default_sampler,\n                TextureFormat::bevy_default(),\n                TextureViewDimension::D3,\n                1,\n                255,\n            ),\n        }\n    }\n}\n\nimpl FromWorld for FallbackImageZero {\n    fn from_world(world: &mut bevy_ecs::prelude::World) -> Self {\n        let render_device = world.resource::<RenderDevice>();\n        let render_queue = world.resource::<RenderQueue>();\n        let default_sampler = world.resource::<DefaultImageSampler>();\n        Self(fallback_image_new(\n            render_device,\n            render_queue,\n            default_sampler,\n            TextureFormat::bevy_default(),\n            TextureViewDimension::D2,\n            1,\n            0,\n        ))\n    }\n}\n\nimpl FromWorld for FallbackImageCubemap {\n    fn from_world(world: &mut bevy_ecs::prelude::World) -> Self {\n        let render_device = world.resource::<RenderDevice>();\n        let render_queue = world.resource::<RenderQueue>();\n        let default_sampler = world.resource::<DefaultImageSampler>();\n        Self(fallback_image_new(\n            render_device,\n            render_queue,\n            default_sampler,\n            TextureFormat::bevy_default(),\n            TextureViewDimension::Cube,\n            1,\n            255,\n        ))\n    }\n}\n\n/// A Cache of fallback textures that uses the sample count and `TextureFormat` as a key\n///\n/// # WARNING\n/// Images using MSAA with sample count > 1 are not initialized with data, therefore,\n/// you shouldn't sample them before writing data to them first.\n#[derive(Resource, Deref, DerefMut, Default)]\npub struct FallbackImageFormatMsaaCache(HashMap<(u32, TextureFormat), GpuImage>);\n\n#[derive(SystemParam)]\npub struct FallbackImageMsaa<'w> {\n    cache: ResMut<'w, FallbackImageFormatMsaaCache>,\n    render_device: Res<'w, RenderDevice>,\n    render_queue: Res<'w, RenderQueue>,\n    default_sampler: Res<'w, DefaultImageSampler>,\n}\n\nimpl<'w> FallbackImageMsaa<'w> {\n    pub fn image_for_samplecount(&mut self, sample_count: u32, format: TextureFormat) -> &GpuImage {\n        self.cache.entry((sample_count, format)).or_insert_with(|| {\n            fallback_image_new(\n                &self.render_device,\n                &self.render_queue,\n                &self.default_sampler,\n                format,\n                TextureViewDimension::D2,\n                sample_count,\n                255,\n            )\n        })\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "48bfd26903a1ce1cdc53df4c9b5cb5e74910180d",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_render/src/render_resource/resource_macros.rs",
    "func": "#[macro_export]\nmacro_rules! define_atomic_id {\n    ($atomic_id_type:ident) => {\n        #[derive(Copy, Clone, Hash, Eq, PartialEq, PartialOrd, Ord, Debug)]\n        pub struct $atomic_id_type(core::num::NonZero<u32>);\n\n        // We use new instead of default to indicate that each ID created will be unique.\n        #[allow(clippy::new_without_default)]\n        impl $atomic_id_type {\n            pub fn new() -> Self {\n                use core::sync::atomic::{AtomicU32, Ordering};\n\n                static COUNTER: AtomicU32 = AtomicU32::new(1);\n\n                let counter = COUNTER.fetch_add(1, Ordering::Relaxed);\n                Self(core::num::NonZero::<u32>::new(counter).unwrap_or_else(|| {\n                    panic!(\n                        \"The system ran out of unique `{}`s.\",\n                        stringify!($atomic_id_type)\n                    );\n                }))\n            }\n        }\n\n        impl From<$atomic_id_type> for core::num::NonZero<u32> {\n            fn from(value: $atomic_id_type) -> Self {\n                value.0\n            }\n        }\n\n        impl From<core::num::NonZero<u32>> for $atomic_id_type {\n            fn from(value: core::num::NonZero<u32>) -> Self {\n                Self(value)\n            }\n        }\n    };\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "93dd3e879706243cd14d0d95b591e04b32e55175",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_render/src/render_resource/texture.rs",
    "func": "use crate::define_atomic_id;\nuse crate::renderer::WgpuWrapper;\nuse alloc::sync::Arc;\nuse bevy_derive::{Deref, DerefMut};\nuse bevy_ecs::system::Resource;\nuse core::ops::Deref;\n\ndefine_atomic_id!(TextureId);\n\n/// A GPU-accessible texture.\n///\n/// May be converted from and dereferences to a wgpu [`Texture`](wgpu::Texture).\n/// Can be created via [`RenderDevice::create_texture`](crate::renderer::RenderDevice::create_texture).\n#[derive(Clone, Debug)]\npub struct Texture {\n    id: TextureId,\n    value: Arc<WgpuWrapper<wgpu::Texture>>,\n}\n\nimpl Texture {\n    /// Returns the [`TextureId`].\n    #[inline]\n    pub fn id(&self) -> TextureId {\n        self.id\n    }\n\n    /// Creates a view of this texture.\n    pub fn create_view(&self, desc: &wgpu::TextureViewDescriptor) -> TextureView {\n        TextureView::from(self.value.create_view(desc))\n    }\n}\n\nimpl From<wgpu::Texture> for Texture {\n    fn from(value: wgpu::Texture) -> Self {\n        Texture {\n            id: TextureId::new(),\n            value: Arc::new(WgpuWrapper::new(value)),\n        }\n    }\n}\n\nimpl Deref for Texture {\n    type Target = wgpu::Texture;\n\n    #[inline]\n    fn deref(&self) -> &Self::Target {\n        &self.value\n    }\n}\n\ndefine_atomic_id!(TextureViewId);\n\n/// Describes a [`Texture`] with its associated metadata required by a pipeline or [`BindGroup`](super::BindGroup).\n#[derive(Clone, Debug)]\npub struct TextureView {\n    id: TextureViewId,\n    value: Arc<WgpuWrapper<wgpu::TextureView>>,\n}\n\npub struct SurfaceTexture {\n    value: Arc<WgpuWrapper<wgpu::SurfaceTexture>>,\n}\n\nimpl SurfaceTexture {\n    pub fn try_unwrap(self) -> Option<wgpu::SurfaceTexture> {\n        Arc::try_unwrap(self.value)\n            .map(WgpuWrapper::into_inner)\n            .ok()\n    }\n}\n\nimpl TextureView {\n    /// Returns the [`TextureViewId`].\n    #[inline]\n    pub fn id(&self) -> TextureViewId {\n        self.id\n    }\n}\n\nimpl From<wgpu::TextureView> for TextureView {\n    fn from(value: wgpu::TextureView) -> Self {\n        TextureView {\n            id: TextureViewId::new(),\n            value: Arc::new(WgpuWrapper::new(value)),\n        }\n    }\n}\n\nimpl From<wgpu::SurfaceTexture> for SurfaceTexture {\n    fn from(value: wgpu::SurfaceTexture) -> Self {\n        SurfaceTexture {\n            value: Arc::new(WgpuWrapper::new(value)),\n        }\n    }\n}\n\nimpl Deref for TextureView {\n    type Target = wgpu::TextureView;\n\n    #[inline]\n    fn deref(&self) -> &Self::Target {\n        &self.value\n    }\n}\n\nimpl Deref for SurfaceTexture {\n    type Target = wgpu::SurfaceTexture;\n\n    #[inline]\n    fn deref(&self) -> &Self::Target {\n        &self.value\n    }\n}\n\ndefine_atomic_id!(SamplerId);\n\n/// A Sampler defines how a pipeline will sample from a [`TextureView`].\n/// They define image filters (including anisotropy) and address (wrapping) modes, among other things.\n///\n/// May be converted from and dereferences to a wgpu [`Sampler`](wgpu::Sampler).\n/// Can be created via [`RenderDevice::create_sampler`](crate::renderer::RenderDevice::create_sampler).\n#[derive(Clone, Debug)]\npub struct Sampler {\n    id: SamplerId,\n    value: Arc<WgpuWrapper<wgpu::Sampler>>,\n}\n\nimpl Sampler {\n    /// Returns the [`SamplerId`].\n    #[inline]\n    pub fn id(&self) -> SamplerId {\n        self.id\n    }\n}\n\nimpl From<wgpu::Sampler> for Sampler {\n    fn from(value: wgpu::Sampler) -> Self {\n        Sampler {\n            id: SamplerId::new(),\n            value: Arc::new(WgpuWrapper::new(value)),\n        }\n    }\n}\n\nimpl Deref for Sampler {\n    type Target = wgpu::Sampler;\n\n    #[inline]\n    fn deref(&self) -> &Self::Target {\n        &self.value\n    }\n}\n\n/// A rendering resource for the default image sampler which is set during renderer\n/// initialization.\n///\n/// The [`ImagePlugin`](crate::texture::ImagePlugin) can be set during app initialization to change the default\n/// image sampler.\n#[derive(Resource, Debug, Clone, Deref, DerefMut)]\npub struct DefaultImageSampler(pub(crate) Sampler);\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "c9fcb5d1901f4d9a82db7fba68fc09bb124abebe",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_sprite/src/texture_atlas.rs",
    "func": "use bevy_asset::{Asset, AssetId, Assets, Handle};\nuse bevy_image::Image;\nuse bevy_math::{URect, UVec2};\nuse bevy_reflect::{std_traits::ReflectDefault, Reflect};\n#[cfg(feature = \"serialize\")]\nuse bevy_reflect::{ReflectDeserialize, ReflectSerialize};\nuse bevy_utils::HashMap;\n\n/// Stores a mapping from sub texture handles to the related area index.\n///\n/// Generated by [`TextureAtlasBuilder`].\n///\n/// [`TextureAtlasBuilder`]: crate::TextureAtlasBuilder\n#[derive(Debug)]\npub struct TextureAtlasSources {\n    /// Maps from a specific image handle to the index in `textures` where they can be found.\n    pub texture_ids: HashMap<AssetId<Image>, usize>,\n}\nimpl TextureAtlasSources {\n    /// Retrieves the texture *section* index of the given `texture` handle.\n    pub fn texture_index(&self, texture: impl Into<AssetId<Image>>) -> Option<usize> {\n        let id = texture.into();\n        self.texture_ids.get(&id).cloned()\n    }\n\n    /// Creates a [`TextureAtlas`] handle for the given `texture` handle.\n    pub fn handle(\n        &self,\n        layout: Handle<TextureAtlasLayout>,\n        texture: impl Into<AssetId<Image>>,\n    ) -> Option<TextureAtlas> {\n        Some(TextureAtlas {\n            layout,\n            index: self.texture_index(texture)?,\n        })\n    }\n\n    /// Retrieves the texture *section* rectangle of the given `texture` handle.\n    pub fn texture_rect(\n        &self,\n        layout: &TextureAtlasLayout,\n        texture: impl Into<AssetId<Image>>,\n    ) -> Option<URect> {\n        layout.textures.get(self.texture_index(texture)?).cloned()\n    }\n}\n\n/// Stores a map used to lookup the position of a texture in a [`TextureAtlas`].\n/// This can be used to either use and look up a specific section of a texture, or animate frame-by-frame as a sprite sheet.\n///\n/// Optionally it can store a mapping from sub texture handles to the related area index (see\n/// [`TextureAtlasBuilder`]).\n///\n/// [Example usage animating sprite.](https://github.com/bevyengine/bevy/blob/latest/examples/2d/sprite_sheet.rs)\n/// [Example usage animating sprite in response to an event.](https://github.com/bevyengine/bevy/blob/latest/examples/2d/sprite_animation.rs)\n/// [Example usage loading sprite sheet.](https://github.com/bevyengine/bevy/blob/latest/examples/2d/texture_atlas.rs)\n///\n/// [`TextureAtlasBuilder`]: crate::TextureAtlasBuilder\n#[cfg_attr(feature = \"serialize\", derive(serde::Serialize, serde::Deserialize))]\n#[derive(Asset, Reflect, PartialEq, Eq, Debug, Clone)]\n#[reflect(Debug, PartialEq)]\n#[cfg_attr(feature = \"serialize\", reflect(Serialize, Deserialize))]\npub struct TextureAtlasLayout {\n    /// Total size of texture atlas.\n    pub size: UVec2,\n    /// The specific areas of the atlas where each texture can be found\n    pub textures: Vec<URect>,\n}\n\nimpl TextureAtlasLayout {\n    /// Create a new empty layout with custom `dimensions`\n    pub fn new_empty(dimensions: UVec2) -> Self {\n        Self {\n            size: dimensions,\n            textures: Vec::new(),\n        }\n    }\n\n    /// Generate a [`TextureAtlasLayout`] as a grid where each\n    /// `tile_size` by `tile_size` grid-cell is one of the *section* in the\n    /// atlas. Grid cells are separated by some `padding`, and the grid starts\n    /// at `offset` pixels from the top left corner. Resulting layout is\n    /// indexed left to right, top to bottom.\n    ///\n    /// # Arguments\n    ///\n    /// * `tile_size` - Each layout grid cell size\n    /// * `columns` - Grid column count\n    /// * `rows` - Grid row count\n    /// * `padding` - Optional padding between cells\n    /// * `offset` - Optional global grid offset\n    pub fn from_grid(\n        tile_size: UVec2,\n        columns: u32,\n        rows: u32,\n        padding: Option<UVec2>,\n        offset: Option<UVec2>,\n    ) -> Self {\n        let padding = padding.unwrap_or_default();\n        let offset = offset.unwrap_or_default();\n        let mut sprites = Vec::new();\n        let mut current_padding = UVec2::ZERO;\n\n        for y in 0..rows {\n            if y > 0 {\n                current_padding.y = padding.y;\n            }\n            for x in 0..columns {\n                if x > 0 {\n                    current_padding.x = padding.x;\n                }\n\n                let cell = UVec2::new(x, y);\n                let rect_min = (tile_size + current_padding) * cell + offset;\n\n                sprites.push(URect {\n                    min: rect_min,\n                    max: rect_min + tile_size,\n                });\n            }\n        }\n\n        let grid_size = UVec2::new(columns, rows);\n\n        Self {\n            size: ((tile_size + current_padding) * grid_size) - current_padding,\n            textures: sprites,\n        }\n    }\n\n    /// Add a *section* to the list in the layout and returns its index\n    /// which can be used with [`TextureAtlas`]\n    ///\n    /// # Arguments\n    ///\n    /// * `rect` - The section of the texture to be added\n    ///\n    /// [`TextureAtlas`]: crate::TextureAtlas\n    pub fn add_texture(&mut self, rect: URect) -> usize {\n        self.textures.push(rect);\n        self.textures.len() - 1\n    }\n\n    /// The number of textures in the [`TextureAtlasLayout`]\n    pub fn len(&self) -> usize {\n        self.textures.len()\n    }\n\n    pub fn is_empty(&self) -> bool {\n        self.textures.is_empty()\n    }\n}\n\n/// An index into a [`TextureAtlasLayout`], which corresponds to a specific section of a texture.\n///\n/// It stores a handle to [`TextureAtlasLayout`] and the index of the current section of the atlas.\n/// The texture atlas contains various *sections* of a given texture, allowing users to have a single\n/// image file for either sprite animation or global mapping.\n/// You can change the texture [`index`](Self::index) of the atlas to animate the sprite or display only a *section* of the texture\n/// for efficient rendering of related game objects.\n///\n/// Check the following examples for usage:\n/// - [`animated sprite sheet example`](https://github.com/bevyengine/bevy/blob/latest/examples/2d/sprite_sheet.rs)\n/// - [`sprite animation event example`](https://github.com/bevyengine/bevy/blob/latest/examples/2d/sprite_animation.rs)\n/// - [`texture atlas example`](https://github.com/bevyengine/bevy/blob/latest/examples/2d/texture_atlas.rs)\n#[derive(Default, Debug, Clone, Reflect)]\n#[reflect(Default, Debug)]\npub struct TextureAtlas {\n    /// Texture atlas layout handle\n    pub layout: Handle<TextureAtlasLayout>,\n    /// Texture atlas section index\n    pub index: usize,\n}\n\nimpl TextureAtlas {\n    /// Retrieves the current texture [`URect`] of the sprite sheet according to the section `index`\n    pub fn texture_rect(&self, texture_atlases: &Assets<TextureAtlasLayout>) -> Option<URect> {\n        let atlas = texture_atlases.get(&self.layout)?;\n        atlas.textures.get(self.index).copied()\n    }\n}\n\nimpl From<Handle<TextureAtlasLayout>> for TextureAtlas {\n    fn from(texture_atlas: Handle<TextureAtlasLayout>) -> Self {\n        Self {\n            layout: texture_atlas,\n            index: 0,\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "2291425b05a738b5ddbbe7d812451b59ae44eeb3",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_diagnostic/src/system_information_diagnostics_plugin.rs",
    "func": "use crate::DiagnosticPath;\nuse bevy_app::prelude::*;\nuse bevy_ecs::system::Resource;\n\n/// Adds a System Information Diagnostic, specifically `cpu_usage` (in %) and `mem_usage` (in %)\n///\n/// Note that gathering system information is a time intensive task and therefore can't be done on every frame.\n/// Any system diagnostics gathered by this plugin may not be current when you access them.\n///\n/// Supported targets:\n/// * linux,\n/// * windows,\n/// * android,\n/// * macOS\n///\n/// NOT supported when using the `bevy/dynamic` feature even when using previously mentioned targets\n///\n/// # See also\n///\n/// [`LogDiagnosticsPlugin`](crate::LogDiagnosticsPlugin) to output diagnostics to the console.\n#[derive(Default)]\npub struct SystemInformationDiagnosticsPlugin;\nimpl Plugin for SystemInformationDiagnosticsPlugin {\n    fn build(&self, app: &mut App) {\n        internal::setup_plugin(app);\n    }\n}\n\nimpl SystemInformationDiagnosticsPlugin {\n    /// Total system cpu usage in %\n    pub const CPU_USAGE: DiagnosticPath = DiagnosticPath::const_new(\"system/cpu_usage\");\n    /// Total system memory usage in %\n    pub const MEM_USAGE: DiagnosticPath = DiagnosticPath::const_new(\"system/mem_usage\");\n}\n\n/// A resource that stores diagnostic information about the system.\n/// This information can be useful for debugging and profiling purposes.\n///\n/// # See also\n///\n/// [`SystemInformationDiagnosticsPlugin`] for more information.\n#[derive(Debug, Resource)]\npub struct SystemInfo {\n    pub os: String,\n    pub kernel: String,\n    pub cpu: String,\n    pub core_count: String,\n    pub memory: String,\n}\n\n// NOTE: sysinfo fails to compile when using bevy dynamic or on iOS and does nothing on Wasm\n#[cfg(all(\n    any(\n        target_os = \"linux\",\n        target_os = \"windows\",\n        target_os = \"android\",\n        target_os = \"macos\"\n    ),\n    not(feature = \"dynamic_linking\")\n))]\npub mod internal {\n    use alloc::sync::Arc;\n    use bevy_ecs::{prelude::ResMut, system::Local};\n    use std::{sync::Mutex, time::Instant};\n\n    use bevy_app::{App, First, Startup, Update};\n    use bevy_ecs::system::Resource;\n    use bevy_tasks::{available_parallelism, block_on, poll_once, AsyncComputeTaskPool, Task};\n    use bevy_utils::tracing::info;\n    use sysinfo::{CpuRefreshKind, MemoryRefreshKind, RefreshKind, System};\n\n    use crate::{Diagnostic, Diagnostics, DiagnosticsStore};\n\n    use super::{SystemInfo, SystemInformationDiagnosticsPlugin};\n\n    const BYTES_TO_GIB: f64 = 1.0 / 1024.0 / 1024.0 / 1024.0;\n\n    pub(super) fn setup_plugin(app: &mut App) {\n        app.add_systems(Startup, setup_system)\n            .add_systems(First, launch_diagnostic_tasks)\n            .add_systems(Update, read_diagnostic_tasks)\n            .init_resource::<SysinfoTasks>();\n    }\n\n    fn setup_system(mut diagnostics: ResMut<DiagnosticsStore>) {\n        diagnostics\n            .add(Diagnostic::new(SystemInformationDiagnosticsPlugin::CPU_USAGE).with_suffix(\"%\"));\n        diagnostics\n            .add(Diagnostic::new(SystemInformationDiagnosticsPlugin::MEM_USAGE).with_suffix(\"%\"));\n    }\n\n    struct SysinfoRefreshData {\n        current_cpu_usage: f64,\n        current_used_mem: f64,\n    }\n\n    #[derive(Resource, Default)]\n    struct SysinfoTasks {\n        tasks: Vec<Task<SysinfoRefreshData>>,\n    }\n\n    fn launch_diagnostic_tasks(\n        mut tasks: ResMut<SysinfoTasks>,\n        // TODO: Consider a fair mutex\n        mut sysinfo: Local<Option<Arc<Mutex<System>>>>,\n        // TODO: FromWorld for Instant?\n        mut last_refresh: Local<Option<Instant>>,\n    ) {\n        let sysinfo = sysinfo.get_or_insert_with(|| {\n            Arc::new(Mutex::new(System::new_with_specifics(\n                RefreshKind::new()\n                    .with_cpu(CpuRefreshKind::new().with_cpu_usage())\n                    .with_memory(MemoryRefreshKind::everything()),\n            )))\n        });\n\n        let last_refresh = last_refresh.get_or_insert_with(Instant::now);\n\n        let thread_pool = AsyncComputeTaskPool::get();\n\n        // Only queue a new system refresh task when necessary\n        // Queuing earlier than that will not give new data\n        if last_refresh.elapsed() > sysinfo::MINIMUM_CPU_UPDATE_INTERVAL\n            // These tasks don't yield and will take up all of the task pool's\n            // threads if we don't limit their amount.\n            && tasks.tasks.len() * 2 < available_parallelism()\n        {\n            let sys = Arc::clone(sysinfo);\n            let task = thread_pool.spawn(async move {\n                let mut sys = sys.lock().unwrap();\n\n                sys.refresh_cpu_specifics(CpuRefreshKind::new().with_cpu_usage());\n                sys.refresh_memory();\n                let current_cpu_usage = sys.global_cpu_usage().into();\n                // `memory()` fns return a value in bytes\n                let total_mem = sys.total_memory() as f64 / BYTES_TO_GIB;\n                let used_mem = sys.used_memory() as f64 / BYTES_TO_GIB;\n                let current_used_mem = used_mem / total_mem * 100.0;\n\n                SysinfoRefreshData {\n                    current_cpu_usage,\n                    current_used_mem,\n                }\n            });\n            tasks.tasks.push(task);\n            *last_refresh = Instant::now();\n        }\n    }\n\n    fn read_diagnostic_tasks(mut diagnostics: Diagnostics, mut tasks: ResMut<SysinfoTasks>) {\n        tasks.tasks.retain_mut(|task| {\n            let Some(data) = block_on(poll_once(task)) else {\n                return true;\n            };\n\n            diagnostics.add_measurement(&SystemInformationDiagnosticsPlugin::CPU_USAGE, || {\n                data.current_cpu_usage\n            });\n            diagnostics.add_measurement(&SystemInformationDiagnosticsPlugin::MEM_USAGE, || {\n                data.current_used_mem\n            });\n            false\n        });\n    }\n\n    impl Default for SystemInfo {\n        fn default() -> Self {\n            let sys = System::new_with_specifics(\n                RefreshKind::new()\n                    .with_cpu(CpuRefreshKind::new())\n                    .with_memory(MemoryRefreshKind::new().with_ram()),\n            );\n\n            let system_info = SystemInfo {\n                os: System::long_os_version().unwrap_or_else(|| String::from(\"not available\")),\n                kernel: System::kernel_version().unwrap_or_else(|| String::from(\"not available\")),\n                cpu: sys\n                    .cpus()\n                    .first()\n                    .map(|cpu| cpu.brand().trim().to_string())\n                    .unwrap_or_else(|| String::from(\"not available\")),\n                core_count: sys\n                    .physical_core_count()\n                    .map(|x| x.to_string())\n                    .unwrap_or_else(|| String::from(\"not available\")),\n                // Convert from Bytes to GibiBytes since it's probably what people expect most of the time\n                memory: format!(\"{:.1} GiB\", sys.total_memory() as f64 * BYTES_TO_GIB),\n            };\n\n            info!(\"{:?}\", system_info);\n            system_info\n        }\n    }\n}\n\n#[cfg(not(all(\n    any(\n        target_os = \"linux\",\n        target_os = \"windows\",\n        target_os = \"android\",\n        target_os = \"macos\"\n    ),\n    not(feature = \"dynamic_linking\")\n)))]\npub mod internal {\n    use bevy_app::{App, Startup};\n\n    pub(super) fn setup_plugin(app: &mut App) {\n        app.add_systems(Startup, setup_system);\n    }\n\n    fn setup_system() {\n        bevy_utils::tracing::warn!(\"This platform and/or configuration is not supported!\");\n    }\n\n    impl Default for super::SystemInfo {\n        fn default() -> Self {\n            let unknown = \"Unknown\".to_string();\n            Self {\n                os: unknown.clone(),\n                kernel: unknown.clone(),\n                cpu: unknown.clone(),\n                core_count: unknown.clone(),\n                memory: unknown.clone(),\n            }\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "dab211cd423b9a2d518f363a9d500ad4bd1e66ec",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_diagnostic/src/entity_count_diagnostics_plugin.rs",
    "func": "use bevy_app::prelude::*;\nuse bevy_ecs::entity::Entities;\n\nuse crate::{Diagnostic, DiagnosticPath, Diagnostics, RegisterDiagnostic};\n\n/// Adds \"entity count\" diagnostic to an App.\n///\n/// # See also\n///\n/// [`LogDiagnosticsPlugin`](crate::LogDiagnosticsPlugin) to output diagnostics to the console.\n#[derive(Default)]\npub struct EntityCountDiagnosticsPlugin;\n\nimpl Plugin for EntityCountDiagnosticsPlugin {\n    fn build(&self, app: &mut App) {\n        app.register_diagnostic(Diagnostic::new(Self::ENTITY_COUNT))\n            .add_systems(Update, Self::diagnostic_system);\n    }\n}\n\nimpl EntityCountDiagnosticsPlugin {\n    pub const ENTITY_COUNT: DiagnosticPath = DiagnosticPath::const_new(\"entity_count\");\n\n    pub fn diagnostic_system(mut diagnostics: Diagnostics, entities: &Entities) {\n        diagnostics.add_measurement(&Self::ENTITY_COUNT, || entities.len() as f64);\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "e4da1059b7bacbf479cbd799f75ce5fecdbe4576",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_winit/src/winit_monitors.rs",
    "func": "use winit::monitor::MonitorHandle;\n\nuse bevy_ecs::{entity::Entity, system::Resource};\n\n/// Stores [`winit`] monitors and their corresponding entities\n///\n/// # Known Issues\n///\n/// On some platforms, physically disconnecting a monitor might result in a\n/// panic in [`winit`]'s loop. This will lead to a crash in the bevy app. See\n/// [13669] for investigations and discussions.\n///\n/// [13669]: https://github.com/bevyengine/bevy/pull/13669\n#[derive(Resource, Debug, Default)]\npub struct WinitMonitors {\n    /// Stores [`winit`] monitors and their corresponding entities\n    // We can't use a `BtreeMap` here because clippy complains about using `MonitorHandle` as a key\n    // on some platforms. Using a `Vec` is fine because we don't expect to have a large number of\n    // monitors and avoids having to audit the code for `MonitorHandle` equality.\n    pub(crate) monitors: Vec<(MonitorHandle, Entity)>,\n}\n\nimpl WinitMonitors {\n    pub fn nth(&self, n: usize) -> Option<MonitorHandle> {\n        self.monitors.get(n).map(|(monitor, _)| monitor.clone())\n    }\n\n    pub fn find_entity(&self, entity: Entity) -> Option<MonitorHandle> {\n        self.monitors\n            .iter()\n            .find(|(_, e)| *e == entity)\n            .map(|(monitor, _)| monitor.clone())\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "14f3b0589734bf680beb4cb03040c08d5504fc07",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_pbr/src/lightmap/mod.rs",
    "func": "//! Lightmaps, baked lighting textures that can be applied at runtime to provide\n//! diffuse global illumination.\n//!\n//! Bevy doesn't currently have any way to actually bake lightmaps, but they can\n//! be baked in an external tool like [Blender](http://blender.org), for example\n//! with an addon like [The Lightmapper]. The tools in the [`bevy-baked-gi`]\n//! project support other lightmap baking methods.\n//!\n//! When a [`Lightmap`] component is added to an entity with a [`Mesh3d`] and a\n//! [`MeshMaterial3d<StandardMaterial>`], Bevy applies the lightmap when rendering. The brightness\n//! of the lightmap may be controlled with the `lightmap_exposure` field on\n//! [`StandardMaterial`].\n//!\n//! During the rendering extraction phase, we extract all lightmaps into the\n//! [`RenderLightmaps`] table, which lives in the render world. Mesh bindgroup\n//! and mesh uniform creation consults this table to determine which lightmap to\n//! supply to the shader. Essentially, the lightmap is a special type of texture\n//! that is part of the mesh instance rather than part of the material (because\n//! multiple meshes can share the same material, whereas sharing lightmaps is\n//! nonsensical).\n//!\n//! Note that meshes can't be instanced if they use different lightmap textures.\n//! If you want to instance a lightmapped mesh, combine the lightmap textures\n//! into a single atlas, and set the `uv_rect` field on [`Lightmap`]\n//! appropriately.\n//!\n//! [The Lightmapper]: https://github.com/Naxela/The_Lightmapper\n//! [`Mesh3d`]: bevy_render::mesh::Mesh3d\n//! [`MeshMaterial3d<StandardMaterial>`]: crate::StandardMaterial\n//! [`StandardMaterial`]: crate::StandardMaterial\n//! [`bevy-baked-gi`]: https://github.com/pcwalton/bevy-baked-gi\n\nuse bevy_app::{App, Plugin};\nuse bevy_asset::{load_internal_asset, AssetId, Handle};\nuse bevy_ecs::{\n    component::Component,\n    entity::Entity,\n    reflect::ReflectComponent,\n    schedule::IntoSystemConfigs,\n    system::{Query, Res, ResMut, Resource},\n};\nuse bevy_image::Image;\nuse bevy_math::{uvec2, vec4, Rect, UVec2};\nuse bevy_reflect::{std_traits::ReflectDefault, Reflect};\nuse bevy_render::sync_world::MainEntityHashMap;\nuse bevy_render::{\n    mesh::{Mesh, RenderMesh},\n    render_asset::RenderAssets,\n    render_resource::Shader,\n    texture::GpuImage,\n    view::ViewVisibility,\n    Extract, ExtractSchedule, RenderApp,\n};\nuse bevy_utils::HashSet;\n\nuse crate::{ExtractMeshesSet, RenderMeshInstances};\n\n/// The ID of the lightmap shader.\npub const LIGHTMAP_SHADER_HANDLE: Handle<Shader> =\n    Handle::weak_from_u128(285484768317531991932943596447919767152);\n\n/// A plugin that provides an implementation of lightmaps.\npub struct LightmapPlugin;\n\n/// A component that applies baked indirect diffuse global illumination from a\n/// lightmap.\n///\n/// When assigned to an entity that contains a [`Mesh3d`](bevy_render::mesh::Mesh3d) and a\n/// [`MeshMaterial3d<StandardMaterial>`](crate::StandardMaterial), if the mesh\n/// has a second UV layer ([`ATTRIBUTE_UV_1`](bevy_render::mesh::Mesh::ATTRIBUTE_UV_1)),\n/// then the lightmap will render using those UVs.\n#[derive(Component, Clone, Reflect)]\n#[reflect(Component, Default)]\npub struct Lightmap {\n    /// The lightmap texture.\n    pub image: Handle<Image>,\n\n    /// The rectangle within the lightmap texture that the UVs are relative to.\n    ///\n    /// The top left coordinate is the `min` part of the rect, and the bottom\n    /// right coordinate is the `max` part of the rect. The rect ranges from (0,\n    /// 0) to (1, 1).\n    ///\n    /// This field allows lightmaps for a variety of meshes to be packed into a\n    /// single atlas.\n    pub uv_rect: Rect,\n}\n\n/// Lightmap data stored in the render world.\n///\n/// There is one of these per visible lightmapped mesh instance.\n#[derive(Debug)]\npub(crate) struct RenderLightmap {\n    /// The ID of the lightmap texture.\n    pub(crate) image: AssetId<Image>,\n\n    /// The rectangle within the lightmap texture that the UVs are relative to.\n    ///\n    /// The top left coordinate is the `min` part of the rect, and the bottom\n    /// right coordinate is the `max` part of the rect. The rect ranges from (0,\n    /// 0) to (1, 1).\n    pub(crate) uv_rect: Rect,\n}\n\n/// Stores data for all lightmaps in the render world.\n///\n/// This is cleared and repopulated each frame during the `extract_lightmaps`\n/// system.\n#[derive(Default, Resource)]\npub struct RenderLightmaps {\n    /// The mapping from every lightmapped entity to its lightmap info.\n    ///\n    /// Entities without lightmaps, or for which the mesh or lightmap isn't\n    /// loaded, won't have entries in this table.\n    pub(crate) render_lightmaps: MainEntityHashMap<RenderLightmap>,\n\n    /// All active lightmap images in the scene.\n    ///\n    /// Gathering all lightmap images into a set makes mesh bindgroup\n    /// preparation slightly more efficient, because only one bindgroup needs to\n    /// be created per lightmap texture.\n    pub(crate) all_lightmap_images: HashSet<AssetId<Image>>,\n}\n\nimpl Plugin for LightmapPlugin {\n    fn build(&self, app: &mut App) {\n        load_internal_asset!(\n            app,\n            LIGHTMAP_SHADER_HANDLE,\n            \"lightmap.wgsl\",\n            Shader::from_wgsl\n        );\n    }\n\n    fn finish(&self, app: &mut App) {\n        let Some(render_app) = app.get_sub_app_mut(RenderApp) else {\n            return;\n        };\n\n        render_app\n            .init_resource::<RenderLightmaps>()\n            .add_systems(ExtractSchedule, extract_lightmaps.after(ExtractMeshesSet));\n    }\n}\n\n/// Extracts all lightmaps from the scene and populates the [`RenderLightmaps`]\n/// resource.\nfn extract_lightmaps(\n    mut render_lightmaps: ResMut<RenderLightmaps>,\n    lightmaps: Extract<Query<(Entity, &ViewVisibility, &Lightmap)>>,\n    render_mesh_instances: Res<RenderMeshInstances>,\n    images: Res<RenderAssets<GpuImage>>,\n    meshes: Res<RenderAssets<RenderMesh>>,\n) {\n    // Clear out the old frame's data.\n    render_lightmaps.render_lightmaps.clear();\n    render_lightmaps.all_lightmap_images.clear();\n\n    // Loop over each entity.\n    for (entity, view_visibility, lightmap) in lightmaps.iter() {\n        // Only process visible entities for which the mesh and lightmap are\n        // both loaded.\n        if !view_visibility.get()\n            || images.get(&lightmap.image).is_none()\n            || !render_mesh_instances\n                .mesh_asset_id(entity.into())\n                .and_then(|mesh_asset_id| meshes.get(mesh_asset_id))\n                .is_some_and(|mesh| mesh.layout.0.contains(Mesh::ATTRIBUTE_UV_1.id))\n        {\n            continue;\n        }\n\n        // Store information about the lightmap in the render world.\n        render_lightmaps.render_lightmaps.insert(\n            entity.into(),\n            RenderLightmap::new(lightmap.image.id(), lightmap.uv_rect),\n        );\n\n        // Make a note of the loaded lightmap image so we can efficiently\n        // process them later during mesh bindgroup creation.\n        render_lightmaps\n            .all_lightmap_images\n            .insert(lightmap.image.id());\n    }\n}\n\nimpl RenderLightmap {\n    /// Creates a new lightmap from a texture and a UV rect.\n    fn new(image: AssetId<Image>, uv_rect: Rect) -> Self {\n        Self { image, uv_rect }\n    }\n}\n\n/// Packs the lightmap UV rect into 64 bits (4 16-bit unsigned integers).\npub(crate) fn pack_lightmap_uv_rect(maybe_rect: Option<Rect>) -> UVec2 {\n    match maybe_rect {\n        Some(rect) => {\n            let rect_uvec4 = (vec4(rect.min.x, rect.min.y, rect.max.x, rect.max.y) * 65535.0)\n                .round()\n                .as_uvec4();\n            uvec2(\n                rect_uvec4.x | (rect_uvec4.y << 16),\n                rect_uvec4.z | (rect_uvec4.w << 16),\n            )\n        }\n        None => UVec2::ZERO,\n    }\n}\n\nimpl Default for Lightmap {\n    fn default() -> Self {\n        Self {\n            image: Default::default(),\n            uv_rect: Rect::new(0.0, 0.0, 1.0, 1.0),\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "50a32f9ab5838eb7744f9a47fa2fffa17d7e6c5c",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_pbr/src/meshlet/asset.rs",
    "func": "use alloc::sync::Arc;\nuse bevy_asset::{\n    io::{Reader, Writer},\n    saver::{AssetSaver, SavedAsset},\n    Asset, AssetLoader, AsyncReadExt, AsyncWriteExt, LoadContext,\n};\nuse bevy_math::{Vec2, Vec3};\nuse bevy_reflect::TypePath;\nuse bevy_tasks::block_on;\nuse bytemuck::{Pod, Zeroable};\nuse half::f16;\nuse lz4_flex::frame::{FrameDecoder, FrameEncoder};\nuse std::io::{Read, Write};\nuse thiserror::Error;\n\n/// Unique identifier for the [`MeshletMesh`] asset format.\nconst MESHLET_MESH_ASSET_MAGIC: u64 = 1717551717668;\n\n/// The current version of the [`MeshletMesh`] asset format.\npub const MESHLET_MESH_ASSET_VERSION: u64 = 1;\n\n/// A mesh that has been pre-processed into multiple small clusters of triangles called meshlets.\n///\n/// A [`bevy_render::mesh::Mesh`] can be converted to a [`MeshletMesh`] using `MeshletMesh::from_mesh` when the `meshlet_processor` cargo feature is enabled.\n/// The conversion step is very slow, and is meant to be ran once ahead of time, and not during runtime. This type of mesh is not suitable for\n/// dynamically generated geometry.\n///\n/// There are restrictions on the [`crate::Material`] functionality that can be used with this type of mesh.\n/// * Materials have no control over the vertex shader or vertex attributes.\n/// * Materials must be opaque. Transparent, alpha masked, and transmissive materials are not supported.\n/// * Do not use normal maps baked from higher-poly geometry. Use the high-poly geometry directly and skip the normal map.\n///   * If additional detail is needed, a smaller tiling normal map not baked from a mesh is ok.\n/// * Material shaders must not use builtin functions that automatically calculate derivatives <https://gpuweb.github.io/gpuweb/wgsl/#derivatives>.\n///   * Use `pbr_functions::sample_texture` to sample textures instead.\n///   * Performing manual arithmetic on texture coordinates (UVs) is forbidden. Use the chain-rule version of arithmetic functions instead (TODO: not yet implemented).\n/// * Limited control over [`bevy_render::render_resource::RenderPipelineDescriptor`] attributes.\n/// * Materials must use the [`crate::Material::meshlet_mesh_fragment_shader`] method (and similar variants for prepass/deferred shaders)\n///   which requires certain shader patterns that differ from the regular material shaders.\n///\n/// See also [`super::MeshletMesh3d`] and [`super::MeshletPlugin`].\n#[derive(Asset, TypePath, Clone)]\npub struct MeshletMesh {\n    /// Quantized and bitstream-packed vertex positions for meshlet vertices.\n    pub(crate) vertex_positions: Arc<[u32]>,\n    /// Octahedral-encoded and 2x16snorm packed normals for meshlet vertices.\n    pub(crate) vertex_normals: Arc<[u32]>,\n    /// Uncompressed vertex texture coordinates for meshlet vertices.\n    pub(crate) vertex_uvs: Arc<[Vec2]>,\n    /// Triangle indices for meshlets.\n    pub(crate) indices: Arc<[u8]>,\n    /// The list of meshlets making up this mesh.\n    pub(crate) meshlets: Arc<[Meshlet]>,\n    /// Spherical bounding volumes.\n    pub(crate) meshlet_bounding_spheres: Arc<[MeshletBoundingSpheres]>,\n    /// Meshlet group and parent group simplification errors.\n    pub(crate) meshlet_simplification_errors: Arc<[MeshletSimplificationError]>,\n}\n\n/// A single meshlet within a [`MeshletMesh`].\n#[derive(Copy, Clone, Pod, Zeroable)]\n#[repr(C)]\npub struct Meshlet {\n    /// The bit offset within the parent mesh's [`MeshletMesh::vertex_positions`] buffer where the vertex positions for this meshlet begin.\n    pub start_vertex_position_bit: u32,\n    /// The offset within the parent mesh's [`MeshletMesh::vertex_normals`] and [`MeshletMesh::vertex_uvs`] buffers\n    /// where non-position vertex attributes for this meshlet begin.\n    pub start_vertex_attribute_id: u32,\n    /// The offset within the parent mesh's [`MeshletMesh::indices`] buffer where the indices for this meshlet begin.\n    pub start_index_id: u32,\n    /// The amount of vertices in this meshlet.\n    pub vertex_count: u8,\n    /// The amount of triangles in this meshlet.\n    pub triangle_count: u8,\n    /// Unused.\n    pub padding: u16,\n    /// Number of bits used to store the X channel of vertex positions within this meshlet.\n    pub bits_per_vertex_position_channel_x: u8,\n    /// Number of bits used to store the Y channel of vertex positions within this meshlet.\n    pub bits_per_vertex_position_channel_y: u8,\n    /// Number of bits used to store the Z channel of vertex positions within this meshlet.\n    pub bits_per_vertex_position_channel_z: u8,\n    /// Power of 2 factor used to quantize vertex positions within this meshlet.\n    pub vertex_position_quantization_factor: u8,\n    /// Minimum quantized X channel value of vertex positions within this meshlet.\n    pub min_vertex_position_channel_x: f32,\n    /// Minimum quantized Y channel value of vertex positions within this meshlet.\n    pub min_vertex_position_channel_y: f32,\n    /// Minimum quantized Z channel value of vertex positions within this meshlet.\n    pub min_vertex_position_channel_z: f32,\n}\n\n/// Bounding spheres used for culling and choosing level of detail for a [`Meshlet`].\n#[derive(Copy, Clone, Pod, Zeroable)]\n#[repr(C)]\npub struct MeshletBoundingSpheres {\n    /// Bounding sphere used for frustum and occlusion culling for this meshlet.\n    pub culling_sphere: MeshletBoundingSphere,\n    /// Bounding sphere used for determining if this meshlet's group is at the correct level of detail for a given view.\n    pub lod_group_sphere: MeshletBoundingSphere,\n    /// Bounding sphere used for determining if this meshlet's parent group is at the correct level of detail for a given view.\n    pub lod_parent_group_sphere: MeshletBoundingSphere,\n}\n\n/// A spherical bounding volume used for a [`Meshlet`].\n#[derive(Copy, Clone, Pod, Zeroable)]\n#[repr(C)]\npub struct MeshletBoundingSphere {\n    pub center: Vec3,\n    pub radius: f32,\n}\n\n/// Simplification error used for choosing level of detail for a [`Meshlet`].\n#[derive(Copy, Clone, Pod, Zeroable)]\n#[repr(C)]\npub struct MeshletSimplificationError {\n    /// Simplification error used for determining if this meshlet's group is at the correct level of detail for a given view.\n    pub group_error: f16,\n    /// Simplification error used for determining if this meshlet's parent group is at the correct level of detail for a given view.\n    pub parent_group_error: f16,\n}\n\n/// An [`AssetSaver`] for `.meshlet_mesh` [`MeshletMesh`] assets.\npub struct MeshletMeshSaver;\n\nimpl AssetSaver for MeshletMeshSaver {\n    type Asset = MeshletMesh;\n    type Settings = ();\n    type OutputLoader = MeshletMeshLoader;\n    type Error = MeshletMeshSaveOrLoadError;\n\n    async fn save(\n        &self,\n        writer: &mut Writer,\n        asset: SavedAsset<'_, MeshletMesh>,\n        _settings: &(),\n    ) -> Result<(), MeshletMeshSaveOrLoadError> {\n        // Write asset magic number\n        writer\n            .write_all(&MESHLET_MESH_ASSET_MAGIC.to_le_bytes())\n            .await?;\n\n        // Write asset version\n        writer\n            .write_all(&MESHLET_MESH_ASSET_VERSION.to_le_bytes())\n            .await?;\n\n        // Compress and write asset data\n        let mut writer = FrameEncoder::new(AsyncWriteSyncAdapter(writer));\n        write_slice(&asset.vertex_positions, &mut writer)?;\n        write_slice(&asset.vertex_normals, &mut writer)?;\n        write_slice(&asset.vertex_uvs, &mut writer)?;\n        write_slice(&asset.indices, &mut writer)?;\n        write_slice(&asset.meshlets, &mut writer)?;\n        write_slice(&asset.meshlet_bounding_spheres, &mut writer)?;\n        write_slice(&asset.meshlet_simplification_errors, &mut writer)?;\n        writer.finish()?;\n\n        Ok(())\n    }\n}\n\n/// An [`AssetLoader`] for `.meshlet_mesh` [`MeshletMesh`] assets.\npub struct MeshletMeshLoader;\n\nimpl AssetLoader for MeshletMeshLoader {\n    type Asset = MeshletMesh;\n    type Settings = ();\n    type Error = MeshletMeshSaveOrLoadError;\n\n    async fn load(\n        &self,\n        reader: &mut dyn Reader,\n        _settings: &(),\n        _load_context: &mut LoadContext<'_>,\n    ) -> Result<MeshletMesh, MeshletMeshSaveOrLoadError> {\n        // Load and check magic number\n        let magic = async_read_u64(reader).await?;\n        if magic != MESHLET_MESH_ASSET_MAGIC {\n            return Err(MeshletMeshSaveOrLoadError::WrongFileType);\n        }\n\n        // Load and check asset version\n        let version = async_read_u64(reader).await?;\n        if version != MESHLET_MESH_ASSET_VERSION {\n            return Err(MeshletMeshSaveOrLoadError::WrongVersion { found: version });\n        }\n\n        // Load and decompress asset data\n        let reader = &mut FrameDecoder::new(AsyncReadSyncAdapter(reader));\n        let vertex_positions = read_slice(reader)?;\n        let vertex_normals = read_slice(reader)?;\n        let vertex_uvs = read_slice(reader)?;\n        let indices = read_slice(reader)?;\n        let meshlets = read_slice(reader)?;\n        let meshlet_bounding_spheres = read_slice(reader)?;\n        let meshlet_simplification_errors = read_slice(reader)?;\n\n        Ok(MeshletMesh {\n            vertex_positions,\n            vertex_normals,\n            vertex_uvs,\n            indices,\n            meshlets,\n            meshlet_bounding_spheres,\n            meshlet_simplification_errors,\n        })\n    }\n\n    fn extensions(&self) -> &[&str] {\n        &[\"meshlet_mesh\"]\n    }\n}\n\n#[derive(Error, Debug)]\npub enum MeshletMeshSaveOrLoadError {\n    #[error(\"file was not a MeshletMesh asset\")]\n    WrongFileType,\n    #[error(\"expected asset version {MESHLET_MESH_ASSET_VERSION} but found version {found}\")]\n    WrongVersion { found: u64 },\n    #[error(\"failed to compress or decompress asset data\")]\n    CompressionOrDecompression(#[from] lz4_flex::frame::Error),\n    #[error(\"failed to read or write asset data\")]\n    Io(#[from] std::io::Error),\n}\n\nasync fn async_read_u64(reader: &mut dyn Reader) -> Result<u64, std::io::Error> {\n    let mut bytes = [0u8; 8];\n    reader.read_exact(&mut bytes).await?;\n    Ok(u64::from_le_bytes(bytes))\n}\n\nfn read_u64(reader: &mut dyn Read) -> Result<u64, std::io::Error> {\n    let mut bytes = [0u8; 8];\n    reader.read_exact(&mut bytes)?;\n    Ok(u64::from_le_bytes(bytes))\n}\n\nfn write_slice<T: Pod>(\n    field: &[T],\n    writer: &mut dyn Write,\n) -> Result<(), MeshletMeshSaveOrLoadError> {\n    writer.write_all(&(field.len() as u64).to_le_bytes())?;\n    writer.write_all(bytemuck::cast_slice(field))?;\n    Ok(())\n}\n\nfn read_slice<T: Pod>(reader: &mut dyn Read) -> Result<Arc<[T]>, std::io::Error> {\n    let len = read_u64(reader)? as usize;\n\n    let mut data: Arc<[T]> = core::iter::repeat_with(T::zeroed).take(len).collect();\n    let slice = Arc::get_mut(&mut data).unwrap();\n    reader.read_exact(bytemuck::cast_slice_mut(slice))?;\n\n    Ok(data)\n}\n\n// TODO: Use async for everything and get rid of this adapter\nstruct AsyncWriteSyncAdapter<'a>(&'a mut Writer);\n\nimpl Write for AsyncWriteSyncAdapter<'_> {\n    fn write(&mut self, buf: &[u8]) -> std::io::Result<usize> {\n        block_on(self.0.write(buf))\n    }\n\n    fn flush(&mut self) -> std::io::Result<()> {\n        block_on(self.0.flush())\n    }\n}\n\n// TODO: Use async for everything and get rid of this adapter\nstruct AsyncReadSyncAdapter<'a>(&'a mut dyn Reader);\n\nimpl Read for AsyncReadSyncAdapter<'_> {\n    fn read(&mut self, buf: &mut [u8]) -> std::io::Result<usize> {\n        block_on(self.0.read(buf))\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "beb4337e0c6dac1c195099d382b5f8032016a38d",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_color/crates/gen_tests/src/main.rs",
    "func": "use palette::{Hsl, Hsv, Hwb, IntoColor, Lab, Lch, LinSrgb, Oklab, Oklch, Srgb, Xyz};\n\nconst TEST_COLORS: &[(f32, f32, f32, &str)] = &[\n    (0., 0., 0., \"black\"),\n    (1., 1., 1., \"white\"),\n    (1., 0., 0., \"red\"),\n    (0., 1., 0., \"green\"),\n    (0., 0., 1., \"blue\"),\n    (1., 1., 0., \"yellow\"),\n    (1., 0., 1., \"magenta\"),\n    (0., 1., 1., \"cyan\"),\n    (0.5, 0.5, 0.5, \"gray\"),\n    (0.5, 0.5, 0., \"olive\"),\n    (0.5, 0., 0.5, \"purple\"),\n    (0., 0.5, 0.5, \"teal\"),\n    (0.5, 0., 0., \"maroon\"),\n    (0., 0.5, 0., \"lime\"),\n    (0., 0., 0.5, \"navy\"),\n    (0.5, 0.5, 0., \"orange\"),\n    (0.5, 0., 0.5, \"fuchsia\"),\n    (0., 0.5, 0.5, \"aqua\"),\n];\n\nfn main() {\n    println!(\n        \"// Generated by gen_tests. Do not edit.\n#[cfg(test)]\nuse crate::{{Hsla, Hsva, Hwba, Srgba, LinearRgba, Oklaba, Oklcha, Laba, Lcha, Xyza}};\n\n#[cfg(test)]\npub struct TestColor {{\n    pub name: &'static str,\n    pub rgb: Srgba,\n    pub linear_rgb: LinearRgba,\n    pub hsl: Hsla,\n    pub hsv: Hsva,\n    pub hwb: Hwba,\n    pub lab: Laba,\n    pub lch: Lcha,\n    pub oklab: Oklaba,\n    pub oklch: Oklcha,\n    pub xyz: Xyza,\n}}\n\"\n    );\n\n    println!(\"// Table of equivalent colors in various color spaces\");\n    println!(\"#[cfg(test)]\");\n    println!(\"pub const TEST_COLORS: &[TestColor] = &[\");\n    for (r, g, b, name) in TEST_COLORS {\n        let srgb = Srgb::new(*r, *g, *b);\n        let linear_rgb: LinSrgb = srgb.into_color();\n        let hsl: Hsl = srgb.into_color();\n        let hsv: Hsv = srgb.into_color();\n        let hwb: Hwb = srgb.into_color();\n        let lab: Lab = srgb.into_color();\n        let lch: Lch = srgb.into_color();\n        let oklab: Oklab = srgb.into_color();\n        let oklch: Oklch = srgb.into_color();\n        let xyz: Xyz = srgb.into_color();\n        println!(\"    // {name}\");\n        println!(\n            \"    TestColor {{\n        name: \\\"{name}\\\",\n        rgb: Srgba::new({}, {}, {}, 1.0),\n        linear_rgb: LinearRgba::new({}, {}, {}, 1.0),\n        hsl: Hsla::new({}, {}, {}, 1.0),\n        hsv: Hsva::new({}, {}, {}, 1.0),\n        hwb: Hwba::new({}, {}, {}, 1.0),\n        lab: Laba::new({}, {}, {}, 1.0),\n        lch: Lcha::new({}, {}, {}, 1.0),\n        oklab: Oklaba::new({}, {}, {}, 1.0),\n        oklch: Oklcha::new({}, {}, {}, 1.0),\n        xyz: Xyza::new({}, {}, {}, 1.0),\n    }},\",\n            VariablePrecision(srgb.red),\n            VariablePrecision(srgb.green),\n            VariablePrecision(srgb.blue),\n            VariablePrecision(linear_rgb.red),\n            VariablePrecision(linear_rgb.green),\n            VariablePrecision(linear_rgb.blue),\n            VariablePrecision(hsl.hue.into_positive_degrees()),\n            VariablePrecision(hsl.saturation),\n            VariablePrecision(hsl.lightness),\n            VariablePrecision(hsv.hue.into_positive_degrees()),\n            VariablePrecision(hsv.saturation),\n            VariablePrecision(hsv.value),\n            VariablePrecision(hwb.hue.into_positive_degrees()),\n            VariablePrecision(hwb.whiteness),\n            VariablePrecision(hwb.blackness),\n            VariablePrecision(lab.l / 100.0),\n            VariablePrecision(lab.a / 100.0),\n            VariablePrecision(lab.b / 100.0),\n            VariablePrecision(lch.l / 100.0),\n            VariablePrecision(lch.chroma / 100.0),\n            VariablePrecision(lch.hue.into_positive_degrees()),\n            VariablePrecision(oklab.l),\n            VariablePrecision(oklab.a),\n            VariablePrecision(oklab.b),\n            VariablePrecision(oklch.l),\n            VariablePrecision(oklch.chroma),\n            VariablePrecision(oklch.hue.into_positive_degrees()),\n            VariablePrecision(xyz.x),\n            VariablePrecision(xyz.y),\n            VariablePrecision(xyz.z),\n        );\n    }\n    println!(\"];\");\n}\n\nstruct VariablePrecision(f32);\n\nimpl core::fmt::Display for VariablePrecision {\n    fn fmt(&self, f: &mut core::fmt::Formatter<'_>) -> core::fmt::Result {\n        if self.0.fract() == 0.0 {\n            return write!(f, \"{}.0\", self.0);\n        }\n        write!(f, \"{}\", self.0)\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "ffcc46be3b0c95afc6572caf10c37842f0d1cc57",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_color/src/color_gradient.rs",
    "func": "use crate::Mix;\nuse alloc::vec::Vec;\nuse bevy_math::curve::{\n    cores::{EvenCore, EvenCoreError},\n    Curve, Interval,\n};\n\n/// A curve whose samples are defined by a collection of colors.\n#[derive(Clone, Debug)]\n#[cfg_attr(feature = \"serialize\", derive(serde::Serialize, serde::Deserialize))]\n#[cfg_attr(feature = \"bevy_reflect\", derive(bevy_reflect::Reflect))]\npub struct ColorCurve<T> {\n    core: EvenCore<T>,\n}\n\nimpl<T> ColorCurve<T>\nwhere\n    T: Mix + Clone,\n{\n    /// Create a new [`ColorCurve`] from a collection of [mixable] types. The domain of this curve\n    /// will always be `[0.0, len - 1]` where `len` is the amount of mixable objects in the\n    /// collection.\n    ///\n    /// This fails if there's not at least two mixable things in the collection.\n    ///\n    /// [mixable]: `Mix`\n    ///\n    /// # Example\n    ///\n    /// ```\n    /// # use bevy_color::palettes::basic::*;\n    /// # use bevy_color::Mix;\n    /// # use bevy_color::Srgba;\n    /// # use bevy_color::ColorCurve;\n    /// # use bevy_math::curve::Interval;\n    /// # use bevy_math::curve::Curve;\n    /// let broken = ColorCurve::new([RED]);\n    /// assert!(broken.is_err());\n    /// let gradient = ColorCurve::new([RED, GREEN, BLUE]);\n    /// assert!(gradient.is_ok());\n    /// assert_eq!(gradient.unwrap().domain(), Interval::new(0.0, 2.0).unwrap());\n    /// ```\n    pub fn new(colors: impl IntoIterator<Item = T>) -> Result<Self, EvenCoreError> {\n        let colors = colors.into_iter().collect::<Vec<_>>();\n        Interval::new(0.0, colors.len().saturating_sub(1) as f32)\n            .map_err(|_| EvenCoreError::NotEnoughSamples {\n                samples: colors.len(),\n            })\n            .and_then(|domain| EvenCore::new(domain, colors))\n            .map(|core| Self { core })\n    }\n}\n\nimpl<T> Curve<T> for ColorCurve<T>\nwhere\n    T: Mix + Clone,\n{\n    #[inline]\n    fn domain(&self) -> Interval {\n        self.core.domain()\n    }\n\n    #[inline]\n    fn sample_clamped(&self, t: f32) -> T {\n        // `EvenCore::sample_with` clamps the input implicitly.\n        self.core.sample_with(t, T::mix)\n    }\n\n    #[inline]\n    fn sample_unchecked(&self, t: f32) -> T {\n        self.sample_clamped(t)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::{palettes::basic, Srgba};\n\n    #[test]\n    fn test_color_curve() {\n        let broken = ColorCurve::new([basic::RED]);\n        assert!(broken.is_err());\n\n        let gradient = [basic::RED, basic::LIME, basic::BLUE];\n        let curve = ColorCurve::new(gradient).unwrap();\n\n        assert_eq!(curve.domain(), Interval::new(0.0, 2.0).unwrap());\n\n        let brighter_curve = curve.map(|c: Srgba| c.mix(&basic::WHITE, 0.5));\n\n        [\n            (-0.1, None),\n            (0.0, Some([1.0, 0.5, 0.5, 1.0])),\n            (0.5, Some([0.75, 0.75, 0.5, 1.0])),\n            (1.0, Some([0.5, 1.0, 0.5, 1.0])),\n            (1.5, Some([0.5, 0.75, 0.75, 1.0])),\n            (2.0, Some([0.5, 0.5, 1.0, 1.0])),\n            (2.1, None),\n        ]\n        .map(|(t, maybe_rgba)| {\n            let maybe_srgba = maybe_rgba.map(|[r, g, b, a]| Srgba::new(r, g, b, a));\n            (t, maybe_srgba)\n        })\n        .into_iter()\n        .for_each(|(t, maybe_color)| {\n            assert_eq!(brighter_curve.sample(t), maybe_color);\n        });\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "b11c8f44648154f315e35228a8dfae19143270f5",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_tasks/src/wasm_task.rs",
    "func": "use core::{\n    any::Any,\n    future::{Future, IntoFuture},\n    panic::{AssertUnwindSafe, UnwindSafe},\n    pin::Pin,\n    task::{Context, Poll},\n};\n\nuse futures_channel::oneshot;\n\n/// Wraps an asynchronous task, a spawned future.\n///\n/// Tasks are also futures themselves and yield the output of the spawned future.\n#[derive(Debug)]\npub struct Task<T>(oneshot::Receiver<Result<T, Panic>>);\n\nimpl<T: 'static> Task<T> {\n    pub(crate) fn wrap_future(future: impl Future<Output = T> + 'static) -> Self {\n        let (sender, receiver) = oneshot::channel();\n        wasm_bindgen_futures::spawn_local(async move {\n            // Catch any panics that occur when polling the future so they can\n            // be propagated back to the task handle.\n            let value = CatchUnwind(AssertUnwindSafe(future)).await;\n            let _ = sender.send(value);\n        });\n        Self(receiver.into_future())\n    }\n\n    /// When building for Wasm, this method has no effect.\n    /// This is only included for feature parity with other platforms.\n    pub fn detach(self) {}\n\n    /// Requests a task to be cancelled and returns a future that suspends until it completes.\n    /// Returns the output of the future if it has already completed.\n    ///\n    /// # Implementation\n    ///\n    /// When building for Wasm, it is not possible to cancel tasks, which means this is the same\n    /// as just awaiting the task. This method is only included for feature parity with other platforms.\n    pub async fn cancel(self) -> Option<T> {\n        match self.0.await {\n            Ok(Ok(value)) => Some(value),\n            Err(_) => None,\n            Ok(Err(panic)) => {\n                // drop this to prevent the panic payload from resuming the panic on drop.\n                // this also leaks the box but I'm not sure how to avoid that\n                core::mem::forget(panic);\n                None\n            }\n        }\n    }\n}\n\nimpl<T> Future for Task<T> {\n    type Output = T;\n    fn poll(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> {\n        match Pin::new(&mut self.0).poll(cx) {\n            Poll::Ready(Ok(Ok(value))) => Poll::Ready(value),\n            // NOTE: Propagating the panic here sorta has parity with the async_executor behavior.\n            // For those tasks, polling them after a panic returns a `None` which gets `unwrap`ed, so\n            // using `resume_unwind` here is essentially keeping the same behavior while adding more information.\n            Poll::Ready(Ok(Err(panic))) => std::panic::resume_unwind(panic),\n            Poll::Ready(Err(_)) => panic!(\"Polled a task after it was cancelled\"),\n            Poll::Pending => Poll::Pending,\n        }\n    }\n}\n\ntype Panic = Box<dyn Any + Send + 'static>;\n\n#[pin_project::pin_project]\nstruct CatchUnwind<F: UnwindSafe>(#[pin] F);\n\nimpl<F: Future + UnwindSafe> Future for CatchUnwind<F> {\n    type Output = Result<F::Output, Panic>;\n    fn poll(self: Pin<&mut Self>, cx: &mut Context) -> Poll<Self::Output> {\n        std::panic::catch_unwind(AssertUnwindSafe(|| self.project().0.poll(cx)))?.map(Ok)\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "697b0841a049fc5ce2f14b940a523b0044415021",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_macro_utils/src/attrs.rs",
    "func": "use syn::{Expr, ExprLit, Lit};\n\nuse crate::symbol::Symbol;\n\n/// Get a [literal string](struct@syn::LitStr) from the provided [expression](Expr).\npub fn get_lit_str(attr_name: Symbol, value: &Expr) -> syn::Result<&syn::LitStr> {\n    if let Expr::Lit(ExprLit {\n        lit: Lit::Str(lit), ..\n    }) = &value\n    {\n        Ok(lit)\n    } else {\n        Err(syn::Error::new_spanned(\n            value,\n            format!(\"expected {attr_name} attribute to be a string: `{attr_name} = \\\"...\\\"`\"),\n        ))\n    }\n}\n\n/// Get a [literal boolean](struct@syn::LitBool) from the provided [expression](Expr) as a [`bool`].\npub fn get_lit_bool(attr_name: Symbol, value: &Expr) -> syn::Result<bool> {\n    if let Expr::Lit(ExprLit {\n        lit: Lit::Bool(lit),\n        ..\n    }) = &value\n    {\n        Ok(lit.value())\n    } else {\n        Err(syn::Error::new_spanned(\n            value,\n            format!(\"expected {attr_name} attribute to be a bool value, `true` or `false`: `{attr_name} = ...`\"),\n        ))?\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "603fad78421adfe969ab4aee36f7180ed879f7ef",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_reflect/derive/src/impls/common.rs",
    "func": "use bevy_macro_utils::fq_std::{FQAny, FQOption, FQResult};\n\nuse quote::quote;\n\nuse crate::{derive_data::ReflectMeta, where_clause_options::WhereClauseOptions};\n\npub fn impl_full_reflect(\n    meta: &ReflectMeta,\n    where_clause_options: &WhereClauseOptions,\n) -> proc_macro2::TokenStream {\n    let bevy_reflect_path = meta.bevy_reflect_path();\n    let type_path = meta.type_path();\n\n    let (impl_generics, ty_generics, where_clause) = type_path.generics().split_for_impl();\n    let where_reflect_clause = where_clause_options.extend_where_clause(where_clause);\n\n    let any_impls = if meta.is_remote_wrapper() {\n        quote! {\n            #[inline]\n            fn into_any(self: #bevy_reflect_path::__macro_exports::alloc_utils::Box<Self>) -> #bevy_reflect_path::__macro_exports::alloc_utils::Box<dyn #FQAny> {\n                #bevy_reflect_path::__macro_exports::alloc_utils::Box::new(self.0)\n            }\n\n            #[inline]\n            fn as_any(&self) -> &dyn #FQAny {\n                &self.0\n            }\n\n            #[inline]\n            fn as_any_mut(&mut self) -> &mut dyn #FQAny {\n                &mut self.0\n            }\n        }\n    } else {\n        quote! {\n            #[inline]\n            fn into_any(self: #bevy_reflect_path::__macro_exports::alloc_utils::Box<Self>) -> #bevy_reflect_path::__macro_exports::alloc_utils::Box<dyn #FQAny> {\n                self\n            }\n\n            #[inline]\n            fn as_any(&self) -> &dyn #FQAny {\n                self\n            }\n\n            #[inline]\n            fn as_any_mut(&mut self) -> &mut dyn #FQAny {\n                self\n            }\n        }\n    };\n\n    quote! {\n        impl #impl_generics #bevy_reflect_path::Reflect for #type_path #ty_generics #where_reflect_clause {\n            #any_impls\n\n            #[inline]\n            fn into_reflect(self: #bevy_reflect_path::__macro_exports::alloc_utils::Box<Self>) -> #bevy_reflect_path::__macro_exports::alloc_utils::Box<dyn #bevy_reflect_path::Reflect> {\n                self\n            }\n\n            #[inline]\n            fn as_reflect(&self) -> &dyn #bevy_reflect_path::Reflect {\n                self\n            }\n\n            #[inline]\n            fn as_reflect_mut(&mut self) -> &mut dyn #bevy_reflect_path::Reflect {\n                self\n            }\n\n            #[inline]\n            fn set(\n                &mut self,\n                value: #bevy_reflect_path::__macro_exports::alloc_utils::Box<dyn #bevy_reflect_path::Reflect>\n            ) -> #FQResult<(), #bevy_reflect_path::__macro_exports::alloc_utils::Box<dyn #bevy_reflect_path::Reflect>> {\n                *self = <dyn #bevy_reflect_path::Reflect>::take(value)?;\n                #FQResult::Ok(())\n            }\n        }\n    }\n}\n\npub fn common_partial_reflect_methods(\n    meta: &ReflectMeta,\n    default_partial_eq_delegate: impl FnOnce() -> Option<proc_macro2::TokenStream>,\n    default_hash_delegate: impl FnOnce() -> Option<proc_macro2::TokenStream>,\n) -> proc_macro2::TokenStream {\n    let bevy_reflect_path = meta.bevy_reflect_path();\n\n    let debug_fn = meta.attrs().get_debug_impl();\n    let partial_eq_fn = meta\n        .attrs()\n        .get_partial_eq_impl(bevy_reflect_path)\n        .or_else(move || {\n            let default_delegate = default_partial_eq_delegate();\n            default_delegate.map(|func| {\n                quote! {\n                    fn reflect_partial_eq(&self, value: &dyn #bevy_reflect_path::PartialReflect) -> #FQOption<bool> {\n                        (#func)(self, value)\n                    }\n                }\n            })\n        });\n    let hash_fn = meta\n        .attrs()\n        .get_hash_impl(bevy_reflect_path)\n        .or_else(move || {\n            let default_delegate = default_hash_delegate();\n            default_delegate.map(|func| {\n                quote! {\n                    fn reflect_hash(&self) -> #FQOption<u64> {\n                        (#func)(self)\n                    }\n                }\n            })\n        });\n\n    quote! {\n        #[inline]\n        fn try_into_reflect(\n            self: #bevy_reflect_path::__macro_exports::alloc_utils::Box<Self>\n        ) -> #FQResult<#bevy_reflect_path::__macro_exports::alloc_utils::Box<dyn #bevy_reflect_path::Reflect>, #bevy_reflect_path::__macro_exports::alloc_utils::Box<dyn #bevy_reflect_path::PartialReflect>> {\n            #FQResult::Ok(self)\n        }\n\n        #[inline]\n        fn try_as_reflect(&self) -> #FQOption<&dyn #bevy_reflect_path::Reflect> {\n            #FQOption::Some(self)\n        }\n\n        #[inline]\n        fn try_as_reflect_mut(&mut self) -> #FQOption<&mut dyn #bevy_reflect_path::Reflect> {\n            #FQOption::Some(self)\n        }\n\n        #[inline]\n        fn into_partial_reflect(self: #bevy_reflect_path::__macro_exports::alloc_utils::Box<Self>) -> #bevy_reflect_path::__macro_exports::alloc_utils::Box<dyn #bevy_reflect_path::PartialReflect> {\n            self\n        }\n\n        #[inline]\n        fn as_partial_reflect(&self) -> &dyn #bevy_reflect_path::PartialReflect {\n            self\n        }\n\n        #[inline]\n        fn as_partial_reflect_mut(&mut self) -> &mut dyn #bevy_reflect_path::PartialReflect {\n            self\n        }\n\n        #hash_fn\n\n        #partial_eq_fn\n\n        #debug_fn\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "22d6e4e7efb2dd4d39f94ff7ffb21c995f6c8acb",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_reflect/derive/src/impls/func/function_impls.rs",
    "func": "use crate::{\n    derive_data::ReflectMeta,\n    impls::func::{\n        from_arg::impl_from_arg, get_ownership::impl_get_ownership, into_return::impl_into_return,\n    },\n    where_clause_options::WhereClauseOptions,\n};\nuse quote::quote;\n\npub(crate) fn impl_function_traits(\n    meta: &ReflectMeta,\n    where_clause_options: &WhereClauseOptions,\n) -> proc_macro2::TokenStream {\n    let get_ownership = impl_get_ownership(meta, where_clause_options);\n    let from_arg = impl_from_arg(meta, where_clause_options);\n    let into_return = impl_into_return(meta, where_clause_options);\n\n    quote! {\n        #get_ownership\n\n        #from_arg\n\n        #into_return\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "6f7b77c925290fe84479227d1e44aa0e45f5a5bf",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_reflect/compile_fail/tests/into_function/return_fail.rs",
    "func": "#![allow(unused)]\n\nuse bevy_reflect::func::IntoFunction;\nuse bevy_reflect::Reflect;\n\nfn pass() -> i32 {\n    123\n}\n\nstruct Foo;\n\nfn return_not_reflect() -> Foo {\n    Foo\n}\n\nfn return_with_lifetime_pass<'a>(a: &'a String) -> &'a String {\n    a\n}\n\nfn return_with_invalid_lifetime<'a, 'b>(a: &'a String, b: &'b String) -> &'b String {\n    b\n}\n\nfn main() {\n    let _ = pass.into_function();\n\n    let _ = return_not_reflect.into_function();\n    //~^ E0599\n\n    let _ = return_with_lifetime_pass.into_function();\n\n    let _ = return_with_invalid_lifetime.into_function();\n    //~^ E0599\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "9332f5f4ffb6737799771d95eaaee3a790a99d0c",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_reflect/src/map.rs",
    "func": "use core::fmt::{Debug, Formatter};\n\nuse bevy_reflect_derive::impl_type_path;\nuse bevy_utils::hashbrown::HashTable;\n\nuse crate::generics::impl_generic_info_methods;\nuse crate::{\n    self as bevy_reflect, type_info::impl_type_methods, ApplyError, Generics, MaybeTyped,\n    PartialReflect, Reflect, ReflectKind, ReflectMut, ReflectOwned, ReflectRef, Type, TypeInfo,\n    TypePath,\n};\nuse alloc::{boxed::Box, format, vec::Vec};\n\n/// A trait used to power [map-like] operations via [reflection].\n///\n/// Maps contain zero or more entries of a key and its associated value,\n/// and correspond to types like [`HashMap`] and [`BTreeMap`].\n/// The order of these entries is not guaranteed by this trait.\n///\n/// # Hashing and equality\n///\n/// All keys are expected to return a valid hash value from [`PartialReflect::reflect_hash`] and be\n/// comparable using [`PartialReflect::reflect_partial_eq`].\n/// If using the [`#[derive(Reflect)]`](derive@crate::Reflect) macro, this can be done by adding\n/// `#[reflect(Hash, PartialEq)]` to the entire struct or enum.\n/// The ordering is expected to be total, that is as if the reflected type implements the [`Eq`] trait.\n/// This is true even for manual implementors who do not hash or compare values,\n/// as it is still relied on by [`DynamicMap`].\n///\n/// # Example\n///\n/// ```\n/// use bevy_reflect::{PartialReflect, Reflect, Map};\n/// use bevy_utils::HashMap;\n///\n///\n/// let foo: &mut dyn Map = &mut HashMap::<u32, bool>::new();\n/// foo.insert_boxed(Box::new(123_u32), Box::new(true));\n/// assert_eq!(foo.len(), 1);\n///\n/// let field: &dyn PartialReflect = foo.get(&123_u32).unwrap();\n/// assert_eq!(field.try_downcast_ref::<bool>(), Some(&true));\n/// ```\n///\n/// [`HashMap`]: std::collections::HashMap\n/// [`BTreeMap`]: alloc::collections::BTreeMap\n/// [map-like]: https://doc.rust-lang.org/book/ch08-03-hash-maps.html\n/// [reflection]: crate\npub trait Map: PartialReflect {\n    /// Returns a reference to the value associated with the given key.\n    ///\n    /// If no value is associated with `key`, returns `None`.\n    fn get(&self, key: &dyn PartialReflect) -> Option<&dyn PartialReflect>;\n\n    /// Returns a mutable reference to the value associated with the given key.\n    ///\n    /// If no value is associated with `key`, returns `None`.\n    fn get_mut(&mut self, key: &dyn PartialReflect) -> Option<&mut dyn PartialReflect>;\n\n    /// Returns the key-value pair at `index` by reference, or `None` if out of bounds.\n    fn get_at(&self, index: usize) -> Option<(&dyn PartialReflect, &dyn PartialReflect)>;\n\n    /// Returns the key-value pair at `index` by reference where the value is a mutable reference, or `None` if out of bounds.\n    fn get_at_mut(\n        &mut self,\n        index: usize,\n    ) -> Option<(&dyn PartialReflect, &mut dyn PartialReflect)>;\n\n    /// Returns the number of elements in the map.\n    fn len(&self) -> usize;\n\n    /// Returns `true` if the list contains no elements.\n    fn is_empty(&self) -> bool {\n        self.len() == 0\n    }\n\n    /// Returns an iterator over the key-value pairs of the map.\n    fn iter(&self) -> MapIter;\n\n    /// Drain the key-value pairs of this map to get a vector of owned values.\n    ///\n    /// After calling this function, `self` will be empty.\n    fn drain(&mut self) -> Vec<(Box<dyn PartialReflect>, Box<dyn PartialReflect>)>;\n\n    /// Clones the map, producing a [`DynamicMap`].\n    fn clone_dynamic(&self) -> DynamicMap;\n\n    /// Inserts a key-value pair into the map.\n    ///\n    /// If the map did not have this key present, `None` is returned.\n    /// If the map did have this key present, the value is updated, and the old value is returned.\n    fn insert_boxed(\n        &mut self,\n        key: Box<dyn PartialReflect>,\n        value: Box<dyn PartialReflect>,\n    ) -> Option<Box<dyn PartialReflect>>;\n\n    /// Removes an entry from the map.\n    ///\n    /// If the map did not have this key present, `None` is returned.\n    /// If the map did have this key present, the removed value is returned.\n    fn remove(&mut self, key: &dyn PartialReflect) -> Option<Box<dyn PartialReflect>>;\n\n    /// Will return `None` if [`TypeInfo`] is not available.\n    fn get_represented_map_info(&self) -> Option<&'static MapInfo> {\n        self.get_represented_type_info()?.as_map().ok()\n    }\n}\n\n/// A container for compile-time map info.\n#[derive(Clone, Debug)]\npub struct MapInfo {\n    ty: Type,\n    generics: Generics,\n    key_info: fn() -> Option<&'static TypeInfo>,\n    key_ty: Type,\n    value_info: fn() -> Option<&'static TypeInfo>,\n    value_ty: Type,\n    #[cfg(feature = \"documentation\")]\n    docs: Option<&'static str>,\n}\n\nimpl MapInfo {\n    /// Create a new [`MapInfo`].\n    pub fn new<\n        TMap: Map + TypePath,\n        TKey: Reflect + MaybeTyped + TypePath,\n        TValue: Reflect + MaybeTyped + TypePath,\n    >() -> Self {\n        Self {\n            ty: Type::of::<TMap>(),\n            generics: Generics::new(),\n            key_info: TKey::maybe_type_info,\n            key_ty: Type::of::<TKey>(),\n            value_info: TValue::maybe_type_info,\n            value_ty: Type::of::<TValue>(),\n            #[cfg(feature = \"documentation\")]\n            docs: None,\n        }\n    }\n\n    /// Sets the docstring for this map.\n    #[cfg(feature = \"documentation\")]\n    pub fn with_docs(self, docs: Option<&'static str>) -> Self {\n        Self { docs, ..self }\n    }\n\n    impl_type_methods!(ty);\n\n    /// The [`TypeInfo`] of the key type.\n    ///\n    /// Returns `None` if the key type does not contain static type information,\n    /// such as for dynamic types.\n    pub fn key_info(&self) -> Option<&'static TypeInfo> {\n        (self.key_info)()\n    }\n\n    /// The [type] of the key type.\n    ///\n    /// [type]: Type\n    pub fn key_ty(&self) -> Type {\n        self.key_ty\n    }\n\n    /// The [`TypeInfo`] of the value type.\n    ///\n    /// Returns `None` if the value type does not contain static type information,\n    /// such as for dynamic types.\n    pub fn value_info(&self) -> Option<&'static TypeInfo> {\n        (self.value_info)()\n    }\n\n    /// The [type] of the value type.\n    ///\n    /// [type]: Type\n    pub fn value_ty(&self) -> Type {\n        self.value_ty\n    }\n\n    /// The docstring of this map, if any.\n    #[cfg(feature = \"documentation\")]\n    pub fn docs(&self) -> Option<&'static str> {\n        self.docs\n    }\n\n    impl_generic_info_methods!(generics);\n}\n\n#[macro_export]\nmacro_rules! hash_error {\n    ( $key:expr ) => {{\n        let type_path = (*$key).reflect_type_path();\n        if !$key.is_dynamic() {\n            format!(\n                \"the given key of type `{}` does not support hashing\",\n                type_path\n            )\n        } else {\n            match (*$key).get_represented_type_info() {\n                // Handle dynamic types that do not represent a type (i.e a plain `DynamicStruct`):\n                None => format!(\"the dynamic type `{}` does not support hashing\", type_path),\n                // Handle dynamic types that do represent a type (i.e. a `DynamicStruct` proxying `Foo`):\n                Some(s) => format!(\n                    \"the dynamic type `{}` (representing `{}`) does not support hashing\",\n                    type_path,\n                    s.type_path()\n                ),\n            }\n        }\n        .as_str()\n    }}\n}\n\n/// An ordered mapping between reflected values.\n#[derive(Default)]\npub struct DynamicMap {\n    represented_type: Option<&'static TypeInfo>,\n    values: Vec<(Box<dyn PartialReflect>, Box<dyn PartialReflect>)>,\n    indices: HashTable<usize>,\n}\n\nimpl DynamicMap {\n    /// Sets the [type] to be represented by this `DynamicMap`.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the given [type] is not a [`TypeInfo::Map`].\n    ///\n    /// [type]: TypeInfo\n    pub fn set_represented_type(&mut self, represented_type: Option<&'static TypeInfo>) {\n        if let Some(represented_type) = represented_type {\n            assert!(\n                matches!(represented_type, TypeInfo::Map(_)),\n                \"expected TypeInfo::Map but received: {:?}\",\n                represented_type\n            );\n        }\n\n        self.represented_type = represented_type;\n    }\n\n    /// Inserts a typed key-value pair into the map.\n    pub fn insert<K: PartialReflect, V: PartialReflect>(&mut self, key: K, value: V) {\n        self.insert_boxed(Box::new(key), Box::new(value));\n    }\n\n    fn internal_hash(value: &dyn PartialReflect) -> u64 {\n        value.reflect_hash().expect(hash_error!(value))\n    }\n\n    fn internal_eq<'a>(\n        value: &'a dyn PartialReflect,\n        values: &'a [(Box<dyn PartialReflect>, Box<dyn PartialReflect>)],\n    ) -> impl FnMut(&usize) -> bool + 'a {\n        |&index| {\n            value\n            .reflect_partial_eq(&*values[index].0)\n            .expect(\"underlying type does not reflect `PartialEq` and hence doesn't support equality checks\")\n        }\n    }\n}\n\nimpl Map for DynamicMap {\n    fn get(&self, key: &dyn PartialReflect) -> Option<&dyn PartialReflect> {\n        let hash = Self::internal_hash(key);\n        let eq = Self::internal_eq(key, &self.values);\n        self.indices\n            .find(hash, eq)\n            .map(|&index| &*self.values[index].1)\n    }\n\n    fn get_mut(&mut self, key: &dyn PartialReflect) -> Option<&mut dyn PartialReflect> {\n        let hash = Self::internal_hash(key);\n        let eq = Self::internal_eq(key, &self.values);\n        self.indices\n            .find(hash, eq)\n            .map(|&index| &mut *self.values[index].1)\n    }\n\n    fn get_at(&self, index: usize) -> Option<(&dyn PartialReflect, &dyn PartialReflect)> {\n        self.values\n            .get(index)\n            .map(|(key, value)| (&**key, &**value))\n    }\n\n    fn get_at_mut(\n        &mut self,\n        index: usize,\n    ) -> Option<(&dyn PartialReflect, &mut dyn PartialReflect)> {\n        self.values\n            .get_mut(index)\n            .map(|(key, value)| (&**key, &mut **value))\n    }\n\n    fn len(&self) -> usize {\n        self.values.len()\n    }\n\n    fn iter(&self) -> MapIter {\n        MapIter::new(self)\n    }\n\n    fn drain(&mut self) -> Vec<(Box<dyn PartialReflect>, Box<dyn PartialReflect>)> {\n        self.values.drain(..).collect()\n    }\n\n    fn clone_dynamic(&self) -> DynamicMap {\n        DynamicMap {\n            represented_type: self.represented_type,\n            values: self\n                .values\n                .iter()\n                .map(|(key, value)| (key.clone_value(), value.clone_value()))\n                .collect(),\n            indices: self.indices.clone(),\n        }\n    }\n\n    fn insert_boxed(\n        &mut self,\n        key: Box<dyn PartialReflect>,\n        value: Box<dyn PartialReflect>,\n    ) -> Option<Box<dyn PartialReflect>> {\n        assert_eq!(\n            key.reflect_partial_eq(&*key),\n            Some(true),\n            \"keys inserted in `Map`-like types are expected to reflect `PartialEq`\"\n        );\n\n        let hash = Self::internal_hash(&*key);\n        let eq = Self::internal_eq(&*key, &self.values);\n        match self.indices.find(hash, eq) {\n            Some(&index) => {\n                let (key_ref, value_ref) = &mut self.values[index];\n                *key_ref = key;\n                let old_value = core::mem::replace(value_ref, value);\n                Some(old_value)\n            }\n            None => {\n                let index = self.values.len();\n                self.values.push((key, value));\n                self.indices.insert_unique(hash, index, |&index| {\n                    Self::internal_hash(&*self.values[index].0)\n                });\n                None\n            }\n        }\n    }\n\n    fn remove(&mut self, key: &dyn PartialReflect) -> Option<Box<dyn PartialReflect>> {\n        let hash = Self::internal_hash(key);\n        let eq = Self::internal_eq(key, &self.values);\n        match self.indices.find_entry(hash, eq) {\n            Ok(entry) => {\n                let (index, _) = entry.remove();\n                let (_, old_value) = self.values.swap_remove(index);\n\n                // The `swap_remove` might have moved the last element of `values`\n                // to `index`, so we might need to fix up its index in `indices`.\n                // If the removed element was also the last element there's nothing to\n                // fixup and this will return `None`, otherwise it returns the key\n                // whose index needs to be fixed up.\n                if let Some((moved_key, _)) = self.values.get(index) {\n                    let hash = Self::internal_hash(&**moved_key);\n                    let moved_index = self\n                        .indices\n                        .find_mut(hash, |&moved_index| moved_index == self.values.len())\n                        .expect(\"key inserted in a `DynamicMap` is no longer present, this means its reflected `Hash` might be incorrect\");\n                    *moved_index = index;\n                }\n\n                Some(old_value)\n            }\n            Err(_) => None,\n        }\n    }\n}\n\nimpl PartialReflect for DynamicMap {\n    #[inline]\n    fn get_represented_type_info(&self) -> Option<&'static TypeInfo> {\n        self.represented_type\n    }\n\n    #[inline]\n    fn into_partial_reflect(self: Box<Self>) -> Box<dyn PartialReflect> {\n        self\n    }\n\n    #[inline]\n    fn as_partial_reflect(&self) -> &dyn PartialReflect {\n        self\n    }\n\n    #[inline]\n    fn as_partial_reflect_mut(&mut self) -> &mut dyn PartialReflect {\n        self\n    }\n\n    fn try_into_reflect(self: Box<Self>) -> Result<Box<dyn Reflect>, Box<dyn PartialReflect>> {\n        Err(self)\n    }\n\n    fn try_as_reflect(&self) -> Option<&dyn Reflect> {\n        None\n    }\n\n    fn try_as_reflect_mut(&mut self) -> Option<&mut dyn Reflect> {\n        None\n    }\n\n    fn apply(&mut self, value: &dyn PartialReflect) {\n        map_apply(self, value);\n    }\n\n    fn try_apply(&mut self, value: &dyn PartialReflect) -> Result<(), ApplyError> {\n        map_try_apply(self, value)\n    }\n\n    fn reflect_kind(&self) -> ReflectKind {\n        ReflectKind::Map\n    }\n\n    fn reflect_ref(&self) -> ReflectRef {\n        ReflectRef::Map(self)\n    }\n\n    fn reflect_mut(&mut self) -> ReflectMut {\n        ReflectMut::Map(self)\n    }\n\n    fn reflect_owned(self: Box<Self>) -> ReflectOwned {\n        ReflectOwned::Map(self)\n    }\n\n    fn clone_value(&self) -> Box<dyn PartialReflect> {\n        Box::new(self.clone_dynamic())\n    }\n\n    fn reflect_partial_eq(&self, value: &dyn PartialReflect) -> Option<bool> {\n        map_partial_eq(self, value)\n    }\n\n    fn debug(&self, f: &mut Formatter<'_>) -> core::fmt::Result {\n        write!(f, \"DynamicMap(\")?;\n        map_debug(self, f)?;\n        write!(f, \")\")\n    }\n\n    #[inline]\n    fn is_dynamic(&self) -> bool {\n        true\n    }\n}\n\nimpl_type_path!((in bevy_reflect) DynamicMap);\n\nimpl Debug for DynamicMap {\n    fn fmt(&self, f: &mut Formatter<'_>) -> core::fmt::Result {\n        self.debug(f)\n    }\n}\n\n/// An iterator over the key-value pairs of a [`Map`].\npub struct MapIter<'a> {\n    map: &'a dyn Map,\n    index: usize,\n}\n\nimpl MapIter<'_> {\n    /// Creates a new [`MapIter`].\n    #[inline]\n    pub const fn new(map: &dyn Map) -> MapIter {\n        MapIter { map, index: 0 }\n    }\n}\n\nimpl<'a> Iterator for MapIter<'a> {\n    type Item = (&'a dyn PartialReflect, &'a dyn PartialReflect);\n\n    fn next(&mut self) -> Option<Self::Item> {\n        let value = self.map.get_at(self.index);\n        self.index += value.is_some() as usize;\n        value\n    }\n\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        let size = self.map.len();\n        (size, Some(size))\n    }\n}\n\nimpl FromIterator<(Box<dyn PartialReflect>, Box<dyn PartialReflect>)> for DynamicMap {\n    fn from_iter<I: IntoIterator<Item = (Box<dyn PartialReflect>, Box<dyn PartialReflect>)>>(\n        items: I,\n    ) -> Self {\n        let mut map = Self::default();\n        for (key, value) in items.into_iter() {\n            map.insert_boxed(key, value);\n        }\n        map\n    }\n}\n\nimpl<K: Reflect, V: Reflect> FromIterator<(K, V)> for DynamicMap {\n    fn from_iter<I: IntoIterator<Item = (K, V)>>(items: I) -> Self {\n        let mut map = Self::default();\n        for (key, value) in items.into_iter() {\n            map.insert(key, value);\n        }\n        map\n    }\n}\n\nimpl IntoIterator for DynamicMap {\n    type Item = (Box<dyn PartialReflect>, Box<dyn PartialReflect>);\n    type IntoIter = alloc::vec::IntoIter<Self::Item>;\n\n    fn into_iter(self) -> Self::IntoIter {\n        self.values.into_iter()\n    }\n}\n\nimpl<'a> IntoIterator for &'a DynamicMap {\n    type Item = (&'a dyn PartialReflect, &'a dyn PartialReflect);\n    type IntoIter = MapIter<'a>;\n\n    fn into_iter(self) -> Self::IntoIter {\n        self.iter()\n    }\n}\n\nimpl<'a> ExactSizeIterator for MapIter<'a> {}\n\n/// Compares a [`Map`] with a [`PartialReflect`] value.\n///\n/// Returns true if and only if all of the following are true:\n/// - `b` is a map;\n/// - `b` is the same length as `a`;\n/// - For each key-value pair in `a`, `b` contains a value for the given key,\n///   and [`PartialReflect::reflect_partial_eq`] returns `Some(true)` for the two values.\n///\n/// Returns [`None`] if the comparison couldn't even be performed.\n#[inline]\npub fn map_partial_eq<M: Map + ?Sized>(a: &M, b: &dyn PartialReflect) -> Option<bool> {\n    let ReflectRef::Map(map) = b.reflect_ref() else {\n        return Some(false);\n    };\n\n    if a.len() != map.len() {\n        return Some(false);\n    }\n\n    for (key, value) in a.iter() {\n        if let Some(map_value) = map.get(key) {\n            let eq_result = value.reflect_partial_eq(map_value);\n            if let failed @ (Some(false) | None) = eq_result {\n                return failed;\n            }\n        } else {\n            return Some(false);\n        }\n    }\n\n    Some(true)\n}\n\n/// The default debug formatter for [`Map`] types.\n///\n/// # Example\n/// ```\n/// # use bevy_utils::HashMap;\n/// use bevy_reflect::Reflect;\n///\n/// let mut my_map = HashMap::new();\n/// my_map.insert(123, String::from(\"Hello\"));\n/// println!(\"{:#?}\", &my_map as &dyn Reflect);\n///\n/// // Output:\n///\n/// // {\n/// //   123: \"Hello\",\n/// // }\n/// ```\n#[inline]\npub fn map_debug(dyn_map: &dyn Map, f: &mut Formatter<'_>) -> core::fmt::Result {\n    let mut debug = f.debug_map();\n    for (key, value) in dyn_map.iter() {\n        debug.entry(&key as &dyn Debug, &value as &dyn Debug);\n    }\n    debug.finish()\n}\n\n/// Applies the elements of reflected map `b` to the corresponding elements of map `a`.\n///\n/// If a key from `b` does not exist in `a`, the value is cloned and inserted.\n///\n/// # Panics\n///\n/// This function panics if `b` is not a reflected map.\n#[inline]\npub fn map_apply<M: Map>(a: &mut M, b: &dyn PartialReflect) {\n    if let Err(err) = map_try_apply(a, b) {\n        panic!(\"{err}\");\n    }\n}\n\n/// Tries to apply the elements of reflected map `b` to the corresponding elements of map `a`\n/// and returns a Result.\n///\n/// If a key from `b` does not exist in `a`, the value is cloned and inserted.\n///\n/// # Errors\n///\n/// This function returns an [`ApplyError::MismatchedKinds`] if `b` is not a reflected map or if\n/// applying elements to each other fails.\n#[inline]\npub fn map_try_apply<M: Map>(a: &mut M, b: &dyn PartialReflect) -> Result<(), ApplyError> {\n    let map_value = b.reflect_ref().as_map()?;\n\n    for (key, b_value) in map_value.iter() {\n        if let Some(a_value) = a.get_mut(key) {\n            a_value.try_apply(b_value)?;\n        } else {\n            a.insert_boxed(key.clone_value(), b_value.clone_value());\n        }\n    }\n\n    Ok(())\n}\n\n#[cfg(test)]\nmod tests {\n    use super::{DynamicMap, Map};\n\n    #[test]\n    fn test_into_iter() {\n        let expected = [\"foo\", \"bar\", \"baz\"];\n\n        let mut map = DynamicMap::default();\n        map.insert(0usize, expected[0].to_string());\n        map.insert(1usize, expected[1].to_string());\n        map.insert(2usize, expected[2].to_string());\n\n        for (index, item) in map.into_iter().enumerate() {\n            let key = item\n                .0\n                .try_take::<usize>()\n                .expect(\"couldn't downcast to usize\");\n            let value = item\n                .1\n                .try_take::<String>()\n                .expect(\"couldn't downcast to String\");\n            assert_eq!(index, key);\n            assert_eq!(expected[index], value);\n        }\n    }\n\n    #[test]\n    fn test_map_get_at() {\n        let values = [\"first\", \"second\", \"third\"];\n        let mut map = DynamicMap::default();\n        map.insert(0usize, values[0].to_string());\n        map.insert(1usize, values[1].to_string());\n        map.insert(1usize, values[2].to_string());\n\n        let (key_r, value_r) = map.get_at(1).expect(\"Item wasn't found\");\n        let value = value_r\n            .try_downcast_ref::<String>()\n            .expect(\"Couldn't downcast to String\");\n        let key = key_r\n            .try_downcast_ref::<usize>()\n            .expect(\"Couldn't downcast to usize\");\n        assert_eq!(key, &1usize);\n        assert_eq!(value, &values[2].to_owned());\n\n        assert!(map.get_at(2).is_none());\n        map.remove(&1usize);\n        assert!(map.get_at(1).is_none());\n    }\n\n    #[test]\n    fn test_map_get_at_mut() {\n        let values = [\"first\", \"second\", \"third\"];\n        let mut map = DynamicMap::default();\n        map.insert(0usize, values[0].to_string());\n        map.insert(1usize, values[1].to_string());\n        map.insert(1usize, values[2].to_string());\n\n        let (key_r, value_r) = map.get_at_mut(1).expect(\"Item wasn't found\");\n        let value = value_r\n            .try_downcast_mut::<String>()\n            .expect(\"Couldn't downcast to String\");\n        let key = key_r\n            .try_downcast_ref::<usize>()\n            .expect(\"Couldn't downcast to usize\");\n        assert_eq!(key, &1usize);\n        assert_eq!(value, &mut values[2].to_owned());\n\n        value.clone_from(&values[0].to_owned());\n\n        assert_eq!(\n            map.get(&1usize)\n                .expect(\"Item wasn't found\")\n                .try_downcast_ref::<String>()\n                .expect(\"Couldn't downcast to String\"),\n            &values[0].to_owned()\n        );\n\n        assert!(map.get_at(2).is_none());\n    }\n\n    #[test]\n    fn next_index_increment() {\n        let values = [\"first\", \"last\"];\n        let mut map = DynamicMap::default();\n        map.insert(0usize, values[0]);\n        map.insert(1usize, values[1]);\n\n        let mut iter = map.iter();\n        let size = iter.len();\n\n        for _ in 0..2 {\n            let prev_index = iter.index;\n            assert!(iter.next().is_some());\n            assert_eq!(prev_index, iter.index - 1);\n        }\n\n        // When None we should no longer increase index\n        for _ in 0..2 {\n            assert!(iter.next().is_none());\n            assert_eq!(size, iter.index);\n        }\n    }\n\n    #[test]\n    fn remove() {\n        let mut map = DynamicMap::default();\n        map.insert(0, 0);\n        map.insert(1, 1);\n\n        assert_eq!(map.remove(&0).unwrap().try_downcast_ref(), Some(&0));\n        assert!(map.get(&0).is_none());\n        assert_eq!(map.get(&1).unwrap().try_downcast_ref(), Some(&1));\n\n        assert_eq!(map.remove(&1).unwrap().try_downcast_ref(), Some(&1));\n        assert!(map.get(&1).is_none());\n\n        assert!(map.remove(&1).is_none());\n        assert!(map.get(&1).is_none());\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "d10ec9dd98b98c4d236d4a469d6cd1583ee13713",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_reflect/src/enums/helpers.rs",
    "func": "use crate::{utility::reflect_hasher, Enum, PartialReflect, ReflectRef, VariantType};\nuse core::{\n    fmt::Debug,\n    hash::{Hash, Hasher},\n};\n\n/// Returns the `u64` hash of the given [enum](Enum).\n#[inline]\npub fn enum_hash<TEnum: Enum>(value: &TEnum) -> Option<u64> {\n    let mut hasher = reflect_hasher();\n    core::any::Any::type_id(value).hash(&mut hasher);\n    value.variant_name().hash(&mut hasher);\n    value.variant_type().hash(&mut hasher);\n    for field in value.iter_fields() {\n        hasher.write_u64(field.value().reflect_hash()?);\n    }\n    Some(hasher.finish())\n}\n\n/// Compares an [`Enum`] with a [`PartialReflect`] value.\n///\n/// Returns true if and only if all of the following are true:\n/// - `b` is an enum;\n/// - `b` is the same variant as `a`;\n/// - For each field in `a`, `b` contains a field with the same name and\n///   [`PartialReflect::reflect_partial_eq`] returns `Some(true)` for the two field\n///   values.\n#[inline]\npub fn enum_partial_eq<TEnum: Enum + ?Sized>(a: &TEnum, b: &dyn PartialReflect) -> Option<bool> {\n    // Both enums?\n    let ReflectRef::Enum(b) = b.reflect_ref() else {\n        return Some(false);\n    };\n\n    // Same variant name?\n    if a.variant_name() != b.variant_name() {\n        return Some(false);\n    }\n\n    // Same variant type?\n    if !a.is_variant(b.variant_type()) {\n        return Some(false);\n    }\n\n    match a.variant_type() {\n        VariantType::Struct => {\n            // Same struct fields?\n            for field in a.iter_fields() {\n                let field_name = field.name().unwrap();\n                if let Some(field_value) = b.field(field_name) {\n                    if let Some(false) | None = field_value.reflect_partial_eq(field.value()) {\n                        // Fields failed comparison\n                        return Some(false);\n                    }\n                } else {\n                    // Field does not exist\n                    return Some(false);\n                }\n            }\n            Some(true)\n        }\n        VariantType::Tuple => {\n            // Same tuple fields?\n            for (i, field) in a.iter_fields().enumerate() {\n                if let Some(field_value) = b.field_at(i) {\n                    if let Some(false) | None = field_value.reflect_partial_eq(field.value()) {\n                        // Fields failed comparison\n                        return Some(false);\n                    }\n                } else {\n                    // Field does not exist\n                    return Some(false);\n                }\n            }\n            Some(true)\n        }\n        _ => Some(true),\n    }\n}\n\n/// The default debug formatter for [`Enum`] types.\n///\n/// # Example\n/// ```\n/// use bevy_reflect::Reflect;\n/// #[derive(Reflect)]\n/// enum MyEnum {\n///   A,\n///   B (usize),\n///   C {value: i32}\n/// }\n///\n/// let my_enum: &dyn Reflect = &MyEnum::B(123);\n/// println!(\"{:#?}\", my_enum);\n///\n/// // Output:\n///\n/// // B (\n/// //   123,\n/// // )\n/// ```\n#[inline]\npub fn enum_debug(dyn_enum: &dyn Enum, f: &mut core::fmt::Formatter<'_>) -> core::fmt::Result {\n    match dyn_enum.variant_type() {\n        VariantType::Unit => f.write_str(dyn_enum.variant_name()),\n        VariantType::Tuple => {\n            let mut debug = f.debug_tuple(dyn_enum.variant_name());\n            for field in dyn_enum.iter_fields() {\n                debug.field(&field.value() as &dyn Debug);\n            }\n            debug.finish()\n        }\n        VariantType::Struct => {\n            let mut debug = f.debug_struct(dyn_enum.variant_name());\n            for field in dyn_enum.iter_fields() {\n                debug.field(field.name().unwrap(), &field.value() as &dyn Debug);\n            }\n            debug.finish()\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "2a8de5a7757996a7acaee640ecbdf1bb2b54bebf",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_reflect/src/func/args/mod.rs",
    "func": "//! Argument types and utilities for working with [`DynamicFunction`] and [`DynamicFunctionMut`].\n//!\n//! [`DynamicFunction`]: crate::func::DynamicFunction\n//! [`DynamicFunctionMut`]: crate::func::DynamicFunctionMut\n\npub use arg::*;\npub use error::*;\npub use from_arg::*;\npub use info::*;\npub use list::*;\npub use ownership::*;\n\nmod arg;\nmod error;\nmod from_arg;\nmod info;\nmod list;\nmod ownership;\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "a63f14dd979f544949e0bc4b86aac9c86718c133",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_reflect/src/func/args/from_arg.rs",
    "func": "use crate::func::args::{Arg, ArgError};\n\n#[cfg(not(feature = \"std\"))]\nuse alloc::{boxed::Box, format, vec};\n\n/// A trait for types that can be created from an [`Arg`].\n///\n/// This trait exists so that types can be automatically converted into an [`Arg`]\n/// so they can be put into an [`ArgList`] and passed to a [`DynamicFunction`] or [`DynamicFunctionMut`].\n///\n/// This trait is used instead of a blanket [`From`] implementation due to coherence issues:\n/// we can't implement `From<T>` for both `T` and `&T`/`&mut T`.\n///\n/// This trait is automatically implemented when using the `Reflect` [derive macro].\n///\n/// [`ArgList`]: crate::func::args::ArgList\n/// [`DynamicFunction`]: crate::func::DynamicFunction\n/// [`DynamicFunctionMut`]: crate::func::DynamicFunctionMut\n/// [derive macro]: derive@crate::Reflect\npub trait FromArg {\n    /// The type to convert into.\n    ///\n    /// This should almost always be the same as `Self`, but with the lifetime `'a`.\n    ///\n    /// The reason we use a separate associated type is to allow for the lifetime\n    /// to be tied to the argument, rather than the type itself.\n    type This<'a>;\n\n    /// Creates an item from an argument.\n    ///\n    /// The argument must be of the expected type and ownership.\n    fn from_arg(arg: Arg) -> Result<Self::This<'_>, ArgError>;\n}\n\n/// Implements the [`FromArg`] trait for the given type.\n///\n/// This will implement it for `$ty`, `&$ty`, and `&mut $ty`.\n///\n/// See [`impl_function_traits`] for details on syntax.\n///\n/// [`impl_function_traits`]: crate::func::macros::impl_function_traits\nmacro_rules! impl_from_arg {\n    (\n        $ty: ty\n        $(;\n            <\n                $($T: ident $(: $T1: tt $(+ $T2: tt)*)?),*\n            >\n        )?\n        $(\n            [\n                $(const $N: ident : $size: ident),*\n            ]\n        )?\n        $(\n            where\n                $($U: ty $(: $U1: tt $(+ $U2: tt)*)?),*\n        )?\n    ) => {\n        impl <\n            $($($T $(: $T1 $(+ $T2)*)?),*)?\n            $(, $(const $N : $size),*)?\n        > $crate::func::args::FromArg for $ty\n        $(\n            where\n                $($U $(: $U1 $(+ $U2)*)?),*\n        )?\n        {\n            type This<'from_arg> = $ty;\n            fn from_arg(arg: $crate::func::args::Arg) -> Result<Self::This<'_>, $crate::func::args::ArgError> {\n                arg.take_owned()\n            }\n        }\n\n        impl <\n            $($($T $(: $T1 $(+ $T2)*)?),*)?\n            $(, $(const $N : $size),*)?\n        > $crate::func::args::FromArg for &'static $ty\n        $(\n            where\n                $($U $(: $U1 $(+ $U2)*)?),*\n        )?\n        {\n            type This<'from_arg> = &'from_arg $ty;\n            fn from_arg(arg: $crate::func::args::Arg) -> Result<Self::This<'_>, $crate::func::args::ArgError> {\n                arg.take_ref()\n            }\n        }\n\n        impl <\n            $($($T $(: $T1 $(+ $T2)*)?),*)?\n            $(, $(const $N : $size),*)?\n        > $crate::func::args::FromArg for &'static mut $ty\n        $(\n            where\n                $($U $(: $U1 $(+ $U2)*)?),*\n        )?\n        {\n            type This<'from_arg> = &'from_arg mut $ty;\n            fn from_arg(arg: $crate::func::args::Arg) -> Result<Self::This<'_>, $crate::func::args::ArgError> {\n                arg.take_mut()\n            }\n        }\n    };\n}\n\npub(crate) use impl_from_arg;\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "a85631c082a38c0d7e70b582f523a9093961f673",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_reflect/src/impls/wgpu_types.rs",
    "func": "use crate::{self as bevy_reflect, impl_reflect_opaque, ReflectDeserialize, ReflectSerialize};\n\nimpl_reflect_opaque!(::wgpu_types::TextureFormat(\n    Debug,\n    Hash,\n    PartialEq,\n    Deserialize,\n    Serialize,\n));\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "845bc393b8d0631a8371242bd7a383f316855e1c",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_reflect/src/serde/de/lists.rs",
    "func": "use crate::{\n    serde::{de::registration_utils::try_get_registration, TypedReflectDeserializer},\n    DynamicList, ListInfo, TypeRegistry,\n};\nuse core::{fmt, fmt::Formatter};\nuse serde::de::{SeqAccess, Visitor};\n\nuse super::ReflectDeserializerProcessor;\n\n/// A [`Visitor`] for deserializing [`List`] values.\n///\n/// [`List`]: crate::List\npub(super) struct ListVisitor<'a, P> {\n    pub list_info: &'static ListInfo,\n    pub registry: &'a TypeRegistry,\n    pub processor: Option<&'a mut P>,\n}\n\nimpl<'de, P: ReflectDeserializerProcessor> Visitor<'de> for ListVisitor<'_, P> {\n    type Value = DynamicList;\n\n    fn expecting(&self, formatter: &mut Formatter) -> fmt::Result {\n        formatter.write_str(\"reflected list value\")\n    }\n\n    fn visit_seq<V>(mut self, mut seq: V) -> Result<Self::Value, V::Error>\n    where\n        V: SeqAccess<'de>,\n    {\n        let mut list = DynamicList::default();\n        let registration = try_get_registration(self.list_info.item_ty(), self.registry)?;\n        while let Some(value) = seq.next_element_seed(TypedReflectDeserializer::new_internal(\n            registration,\n            self.registry,\n            self.processor.as_deref_mut(),\n        ))? {\n            list.push_box(value);\n        }\n        Ok(list)\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "6a7f01311d5394772144923cbeb1065b1509a1c2",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_reflect/src/serde/de/enums.rs",
    "func": "use crate::{\n    serde::{\n        de::{\n            error_utils::make_custom_error,\n            helpers::ExpectedValues,\n            registration_utils::try_get_registration,\n            struct_utils::{visit_struct, visit_struct_seq},\n            tuple_utils::{visit_tuple, TupleLikeInfo},\n        },\n        TypedReflectDeserializer,\n    },\n    DynamicEnum, DynamicStruct, DynamicTuple, DynamicVariant, EnumInfo, StructVariantInfo,\n    TupleVariantInfo, TypeRegistration, TypeRegistry, VariantInfo,\n};\nuse core::{fmt, fmt::Formatter};\nuse serde::de::{DeserializeSeed, EnumAccess, Error, MapAccess, SeqAccess, VariantAccess, Visitor};\n\nuse super::ReflectDeserializerProcessor;\n\n/// A [`Visitor`] for deserializing [`Enum`] values.\n///\n/// [`Enum`]: crate::Enum\npub(super) struct EnumVisitor<'a, P> {\n    pub enum_info: &'static EnumInfo,\n    pub registration: &'a TypeRegistration,\n    pub registry: &'a TypeRegistry,\n    pub processor: Option<&'a mut P>,\n}\n\nimpl<'de, P: ReflectDeserializerProcessor> Visitor<'de> for EnumVisitor<'_, P> {\n    type Value = DynamicEnum;\n\n    fn expecting(&self, formatter: &mut Formatter) -> fmt::Result {\n        formatter.write_str(\"reflected enum value\")\n    }\n\n    fn visit_enum<A>(self, data: A) -> Result<Self::Value, A::Error>\n    where\n        A: EnumAccess<'de>,\n    {\n        let mut dynamic_enum = DynamicEnum::default();\n        let (variant_info, variant) = data.variant_seed(VariantDeserializer {\n            enum_info: self.enum_info,\n        })?;\n\n        let value: DynamicVariant = match variant_info {\n            VariantInfo::Unit(..) => variant.unit_variant()?.into(),\n            VariantInfo::Struct(struct_info) => variant\n                .struct_variant(\n                    struct_info.field_names(),\n                    StructVariantVisitor {\n                        struct_info,\n                        registration: self.registration,\n                        registry: self.registry,\n                        processor: self.processor,\n                    },\n                )?\n                .into(),\n            VariantInfo::Tuple(tuple_info) if tuple_info.field_len() == 1 => {\n                let registration = try_get_registration(\n                    *TupleLikeInfo::field_at(tuple_info, 0)?.ty(),\n                    self.registry,\n                )?;\n                let value =\n                    variant.newtype_variant_seed(TypedReflectDeserializer::new_internal(\n                        registration,\n                        self.registry,\n                        self.processor,\n                    ))?;\n                let mut dynamic_tuple = DynamicTuple::default();\n                dynamic_tuple.insert_boxed(value);\n                dynamic_tuple.into()\n            }\n            VariantInfo::Tuple(tuple_info) => variant\n                .tuple_variant(\n                    tuple_info.field_len(),\n                    TupleVariantVisitor {\n                        tuple_info,\n                        registration: self.registration,\n                        registry: self.registry,\n                        processor: self.processor,\n                    },\n                )?\n                .into(),\n        };\n        let variant_name = variant_info.name();\n        let variant_index = self\n            .enum_info\n            .index_of(variant_name)\n            .expect(\"variant should exist\");\n        dynamic_enum.set_variant_with_index(variant_index, variant_name, value);\n        Ok(dynamic_enum)\n    }\n}\n\nstruct VariantDeserializer {\n    enum_info: &'static EnumInfo,\n}\n\nimpl<'de> DeserializeSeed<'de> for VariantDeserializer {\n    type Value = &'static VariantInfo;\n\n    fn deserialize<D>(self, deserializer: D) -> Result<Self::Value, D::Error>\n    where\n        D: serde::Deserializer<'de>,\n    {\n        struct VariantVisitor(&'static EnumInfo);\n\n        impl<'de> Visitor<'de> for VariantVisitor {\n            type Value = &'static VariantInfo;\n\n            fn expecting(&self, formatter: &mut Formatter) -> fmt::Result {\n                formatter.write_str(\"expected either a variant index or variant name\")\n            }\n\n            fn visit_u32<E>(self, variant_index: u32) -> Result<Self::Value, E>\n            where\n                E: Error,\n            {\n                self.0.variant_at(variant_index as usize).ok_or_else(|| {\n                    make_custom_error(format_args!(\n                        \"no variant found at index `{}` on enum `{}`\",\n                        variant_index,\n                        self.0.type_path()\n                    ))\n                })\n            }\n\n            fn visit_str<E>(self, variant_name: &str) -> Result<Self::Value, E>\n            where\n                E: Error,\n            {\n                self.0.variant(variant_name).ok_or_else(|| {\n                    let names = self.0.iter().map(VariantInfo::name);\n                    make_custom_error(format_args!(\n                        \"unknown variant `{}`, expected one of {:?}\",\n                        variant_name,\n                        ExpectedValues::from_iter(names)\n                    ))\n                })\n            }\n        }\n\n        deserializer.deserialize_identifier(VariantVisitor(self.enum_info))\n    }\n}\n\nstruct StructVariantVisitor<'a, P> {\n    struct_info: &'static StructVariantInfo,\n    registration: &'a TypeRegistration,\n    registry: &'a TypeRegistry,\n    processor: Option<&'a mut P>,\n}\n\nimpl<'de, P: ReflectDeserializerProcessor> Visitor<'de> for StructVariantVisitor<'_, P> {\n    type Value = DynamicStruct;\n\n    fn expecting(&self, formatter: &mut Formatter) -> fmt::Result {\n        formatter.write_str(\"reflected struct variant value\")\n    }\n\n    fn visit_seq<A>(self, mut seq: A) -> Result<Self::Value, A::Error>\n    where\n        A: SeqAccess<'de>,\n    {\n        visit_struct_seq(\n            &mut seq,\n            self.struct_info,\n            self.registration,\n            self.registry,\n            self.processor,\n        )\n    }\n\n    fn visit_map<V>(self, mut map: V) -> Result<Self::Value, V::Error>\n    where\n        V: MapAccess<'de>,\n    {\n        visit_struct(\n            &mut map,\n            self.struct_info,\n            self.registration,\n            self.registry,\n            self.processor,\n        )\n    }\n}\n\nstruct TupleVariantVisitor<'a, P> {\n    tuple_info: &'static TupleVariantInfo,\n    registration: &'a TypeRegistration,\n    registry: &'a TypeRegistry,\n    processor: Option<&'a mut P>,\n}\n\nimpl<'de, P: ReflectDeserializerProcessor> Visitor<'de> for TupleVariantVisitor<'_, P> {\n    type Value = DynamicTuple;\n\n    fn expecting(&self, formatter: &mut Formatter) -> fmt::Result {\n        formatter.write_str(\"reflected tuple variant value\")\n    }\n\n    fn visit_seq<V>(self, mut seq: V) -> Result<Self::Value, V::Error>\n    where\n        V: SeqAccess<'de>,\n    {\n        visit_tuple(\n            &mut seq,\n            self.tuple_info,\n            self.registration,\n            self.registry,\n            self.processor,\n        )\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "77c220b6e1cdda2569f6de42d486b56996f34c64",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_reflect/src/serde/ser/error_utils.rs",
    "func": "use core::fmt::Display;\nuse serde::ser::Error;\n\n#[cfg(feature = \"debug_stack\")]\nthread_local! {\n    /// The thread-local [`TypeInfoStack`] used for debugging.\n    ///\n    /// [`TypeInfoStack`]: crate::type_info_stack::TypeInfoStack\n    pub(super) static TYPE_INFO_STACK: core::cell::RefCell<crate::type_info_stack::TypeInfoStack> = const { core::cell::RefCell::new(\n        crate::type_info_stack::TypeInfoStack::new()\n    ) };\n}\n\n/// A helper function for generating a custom serialization error message.\n///\n/// This function should be preferred over [`Error::custom`] as it will include\n/// other useful information, such as the [type info stack].\n///\n/// [type info stack]: crate::type_info_stack::TypeInfoStack\npub(super) fn make_custom_error<E: Error>(msg: impl Display) -> E {\n    #[cfg(feature = \"debug_stack\")]\n    return TYPE_INFO_STACK\n        .with_borrow(|stack| E::custom(format_args!(\"{} (stack: {:?})\", msg, stack)));\n    #[cfg(not(feature = \"debug_stack\"))]\n    return E::custom(msg);\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "467ad5fc6befb10ebc4e9a993e53db775d46580d",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_reflect/src/serde/ser/serializer.rs",
    "func": "#[cfg(feature = \"debug_stack\")]\nuse crate::serde::ser::error_utils::TYPE_INFO_STACK;\nuse crate::{\n    serde::ser::{\n        arrays::ArraySerializer, custom_serialization::try_custom_serialize, enums::EnumSerializer,\n        error_utils::make_custom_error, lists::ListSerializer, maps::MapSerializer,\n        sets::SetSerializer, structs::StructSerializer, tuple_structs::TupleStructSerializer,\n        tuples::TupleSerializer,\n    },\n    PartialReflect, ReflectRef, TypeRegistry,\n};\nuse serde::{ser::SerializeMap, Serialize, Serializer};\n\nuse super::ReflectSerializerProcessor;\n\n/// A general purpose serializer for reflected types.\n///\n/// This is the serializer counterpart to [`ReflectDeserializer`].\n///\n/// See [`TypedReflectSerializer`] for a serializer that serializes a known type.\n///\n/// # Output\n///\n/// This serializer will output a map with a single entry,\n/// where the key is the _full_ [type path] of the reflected type\n/// and the value is the serialized data.\n///\n/// If you want to override serialization for specific values, you can pass in\n/// a reference to a [`ReflectSerializerProcessor`] which will take priority\n/// over all other serialization methods - see [`with_processor`].\n///\n/// # Example\n///\n/// ```\n/// # use bevy_reflect::prelude::*;\n/// # use bevy_reflect::{TypeRegistry, serde::ReflectSerializer};\n/// #[derive(Reflect, PartialEq, Debug)]\n/// #[type_path = \"my_crate\"]\n/// struct MyStruct {\n///   value: i32\n/// }\n///\n/// let mut registry = TypeRegistry::default();\n/// registry.register::<MyStruct>();\n///\n/// let input = MyStruct { value: 123 };\n///\n/// let reflect_serializer = ReflectSerializer::new(&input, &registry);\n/// let output = ron::to_string(&reflect_serializer).unwrap();\n///\n/// assert_eq!(output, r#\"{\"my_crate::MyStruct\":(value:123)}\"#);\n/// ```\n///\n/// [`ReflectDeserializer`]: crate::serde::ReflectDeserializer\n/// [type path]: crate::TypePath::type_path\n/// [`with_processor`]: Self::with_processor\npub struct ReflectSerializer<'a, P = ()> {\n    value: &'a dyn PartialReflect,\n    registry: &'a TypeRegistry,\n    processor: Option<&'a P>,\n}\n\nimpl<'a> ReflectSerializer<'a, ()> {\n    /// Creates a serializer with no processor.\n    ///\n    /// If you want to add custom logic for serializing certain values, use\n    /// [`with_processor`].\n    ///\n    /// [`with_processor`]: Self::with_processor\n    pub fn new(value: &'a dyn PartialReflect, registry: &'a TypeRegistry) -> Self {\n        Self {\n            value,\n            registry,\n            processor: None,\n        }\n    }\n}\n\nimpl<'a, P: ReflectSerializerProcessor> ReflectSerializer<'a, P> {\n    /// Creates a serializer with a processor.\n    ///\n    /// If you do not need any custom logic for handling certain values, use\n    /// [`new`].\n    ///\n    /// [`new`]: Self::new\n    pub fn with_processor(\n        value: &'a dyn PartialReflect,\n        registry: &'a TypeRegistry,\n        processor: &'a P,\n    ) -> Self {\n        Self {\n            value,\n            registry,\n            processor: Some(processor),\n        }\n    }\n}\n\nimpl<P: ReflectSerializerProcessor> Serialize for ReflectSerializer<'_, P> {\n    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>\n    where\n        S: Serializer,\n    {\n        let mut state = serializer.serialize_map(Some(1))?;\n        state.serialize_entry(\n            self.value\n                .get_represented_type_info()\n                .ok_or_else(|| {\n                    if self.value.is_dynamic() {\n                        make_custom_error(format_args!(\n                            \"cannot serialize dynamic value without represented type: `{}`\",\n                            self.value.reflect_type_path()\n                        ))\n                    } else {\n                        make_custom_error(format_args!(\n                            \"cannot get type info for `{}`\",\n                            self.value.reflect_type_path()\n                        ))\n                    }\n                })?\n                .type_path(),\n            &TypedReflectSerializer::new_internal(self.value, self.registry, self.processor),\n        )?;\n        state.end()\n    }\n}\n\n/// A serializer for reflected types whose type will be known during deserialization.\n///\n/// This is the serializer counterpart to [`TypedReflectDeserializer`].\n///\n/// See [`ReflectSerializer`] for a serializer that serializes an unknown type.\n///\n/// # Output\n///\n/// Since the type is expected to be known during deserialization,\n/// this serializer will not output any additional type information,\n/// such as the [type path].\n///\n/// Instead, it will output just the serialized data.\n///\n/// If you want to override serialization for specific values, you can pass in\n/// a reference to a [`ReflectSerializerProcessor`] which will take priority\n/// over all other serialization methods - see [`with_processor`].\n///\n/// # Example\n///\n/// ```\n/// # use bevy_reflect::prelude::*;\n/// # use bevy_reflect::{TypeRegistry, serde::TypedReflectSerializer};\n/// #[derive(Reflect, PartialEq, Debug)]\n/// #[type_path = \"my_crate\"]\n/// struct MyStruct {\n///   value: i32\n/// }\n///\n/// let mut registry = TypeRegistry::default();\n/// registry.register::<MyStruct>();\n///\n/// let input = MyStruct { value: 123 };\n///\n/// let reflect_serializer = TypedReflectSerializer::new(&input, &registry);\n/// let output = ron::to_string(&reflect_serializer).unwrap();\n///\n/// assert_eq!(output, r#\"(value:123)\"#);\n/// ```\n///\n/// [`TypedReflectDeserializer`]: crate::serde::TypedReflectDeserializer\n/// [type path]: crate::TypePath::type_path\n/// [`with_processor`]: Self::with_processor\npub struct TypedReflectSerializer<'a, P = ()> {\n    value: &'a dyn PartialReflect,\n    registry: &'a TypeRegistry,\n    processor: Option<&'a P>,\n}\n\nimpl<'a> TypedReflectSerializer<'a, ()> {\n    /// Creates a serializer with no processor.\n    ///\n    /// If you want to add custom logic for serializing certain values, use\n    /// [`with_processor`].\n    ///\n    /// [`with_processor`]: Self::with_processor\n    pub fn new(value: &'a dyn PartialReflect, registry: &'a TypeRegistry) -> Self {\n        #[cfg(feature = \"debug_stack\")]\n        TYPE_INFO_STACK.set(crate::type_info_stack::TypeInfoStack::new());\n\n        Self {\n            value,\n            registry,\n            processor: None,\n        }\n    }\n}\n\nimpl<'a, P> TypedReflectSerializer<'a, P> {\n    /// Creates a serializer with a processor.\n    ///\n    /// If you do not need any custom logic for handling certain values, use\n    /// [`new`].\n    ///\n    /// [`new`]: Self::new\n    pub fn with_processor(\n        value: &'a dyn PartialReflect,\n        registry: &'a TypeRegistry,\n        processor: &'a P,\n    ) -> Self {\n        #[cfg(feature = \"debug_stack\")]\n        TYPE_INFO_STACK.set(crate::type_info_stack::TypeInfoStack::new());\n\n        Self {\n            value,\n            registry,\n            processor: Some(processor),\n        }\n    }\n\n    /// An internal constructor for creating a serializer without resetting the type info stack.\n    pub(super) fn new_internal(\n        value: &'a dyn PartialReflect,\n        registry: &'a TypeRegistry,\n        processor: Option<&'a P>,\n    ) -> Self {\n        Self {\n            value,\n            registry,\n            processor,\n        }\n    }\n}\n\nimpl<P: ReflectSerializerProcessor> Serialize for TypedReflectSerializer<'_, P> {\n    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>\n    where\n        S: Serializer,\n    {\n        #[cfg(feature = \"debug_stack\")]\n        {\n            if let Some(info) = self.value.get_represented_type_info() {\n                TYPE_INFO_STACK.with_borrow_mut(|stack| stack.push(info));\n            }\n        }\n\n        // First, check if our processor wants to serialize this type\n        // This takes priority over any other serialization operations\n        let serializer = if let Some(processor) = self.processor {\n            match processor.try_serialize(self.value, self.registry, serializer) {\n                Ok(Ok(value)) => {\n                    return Ok(value);\n                }\n                Err(err) => {\n                    return Err(make_custom_error(err));\n                }\n                Ok(Err(serializer)) => serializer,\n            }\n        } else {\n            serializer\n        };\n\n        // Handle both Value case and types that have a custom `Serialize`\n        let (serializer, error) = match try_custom_serialize(self.value, self.registry, serializer)\n        {\n            Ok(result) => return result,\n            Err(value) => value,\n        };\n\n        let output = match self.value.reflect_ref() {\n            ReflectRef::Struct(struct_value) => StructSerializer {\n                struct_value,\n                registry: self.registry,\n                processor: self.processor,\n            }\n            .serialize(serializer),\n            ReflectRef::TupleStruct(tuple_struct) => TupleStructSerializer {\n                tuple_struct,\n                registry: self.registry,\n                processor: self.processor,\n            }\n            .serialize(serializer),\n            ReflectRef::Tuple(tuple) => TupleSerializer {\n                tuple,\n                registry: self.registry,\n                processor: self.processor,\n            }\n            .serialize(serializer),\n            ReflectRef::List(list) => ListSerializer {\n                list,\n                registry: self.registry,\n                processor: self.processor,\n            }\n            .serialize(serializer),\n            ReflectRef::Array(array) => ArraySerializer {\n                array,\n                registry: self.registry,\n                processor: self.processor,\n            }\n            .serialize(serializer),\n            ReflectRef::Map(map) => MapSerializer {\n                map,\n                registry: self.registry,\n                processor: self.processor,\n            }\n            .serialize(serializer),\n            ReflectRef::Set(set) => SetSerializer {\n                set,\n                registry: self.registry,\n                processor: self.processor,\n            }\n            .serialize(serializer),\n            ReflectRef::Enum(enum_value) => EnumSerializer {\n                enum_value,\n                registry: self.registry,\n                processor: self.processor,\n            }\n            .serialize(serializer),\n            #[cfg(feature = \"functions\")]\n            ReflectRef::Function(_) => Err(make_custom_error(\"functions cannot be serialized\")),\n            ReflectRef::Opaque(_) => Err(error),\n        };\n\n        #[cfg(feature = \"debug_stack\")]\n        TYPE_INFO_STACK.with_borrow_mut(crate::type_info_stack::TypeInfoStack::pop);\n\n        output\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "5433121390caeb533ff095c0c038e6164d73dabb",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_reflect/src/serde/ser/enums.rs",
    "func": "use crate::{\n    serde::{ser::error_utils::make_custom_error, TypedReflectSerializer},\n    Enum, TypeInfo, TypeRegistry, VariantInfo, VariantType,\n};\nuse serde::{\n    ser::{SerializeStructVariant, SerializeTupleVariant},\n    Serialize,\n};\n\nuse super::ReflectSerializerProcessor;\n\n/// A serializer for [`Enum`] values.\npub(super) struct EnumSerializer<'a, P> {\n    pub enum_value: &'a dyn Enum,\n    pub registry: &'a TypeRegistry,\n    pub processor: Option<&'a P>,\n}\n\nimpl<P: ReflectSerializerProcessor> Serialize for EnumSerializer<'_, P> {\n    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>\n    where\n        S: serde::Serializer,\n    {\n        let type_info = self.enum_value.get_represented_type_info().ok_or_else(|| {\n            make_custom_error(format_args!(\n                \"cannot get type info for `{}`\",\n                self.enum_value.reflect_type_path()\n            ))\n        })?;\n\n        let enum_info = match type_info {\n            TypeInfo::Enum(enum_info) => enum_info,\n            info => {\n                return Err(make_custom_error(format_args!(\n                    \"expected enum type but received {info:?}\"\n                )));\n            }\n        };\n\n        let enum_name = enum_info.type_path_table().ident().unwrap();\n        let variant_index = self.enum_value.variant_index() as u32;\n        let variant_info = enum_info\n            .variant_at(variant_index as usize)\n            .ok_or_else(|| {\n                make_custom_error(format_args!(\n                    \"variant at index `{variant_index}` does not exist\",\n                ))\n            })?;\n        let variant_name = variant_info.name();\n        let variant_type = self.enum_value.variant_type();\n        let field_len = self.enum_value.field_len();\n\n        match variant_type {\n            VariantType::Unit => {\n                if type_info.type_path_table().module_path() == Some(\"core::option\")\n                    && type_info.type_path_table().ident() == Some(\"Option\")\n                {\n                    serializer.serialize_none()\n                } else {\n                    serializer.serialize_unit_variant(enum_name, variant_index, variant_name)\n                }\n            }\n            VariantType::Struct => {\n                let struct_info = match variant_info {\n                    VariantInfo::Struct(struct_info) => struct_info,\n                    info => {\n                        return Err(make_custom_error(format_args!(\n                            \"expected struct variant type but received {info:?}\",\n                        )));\n                    }\n                };\n\n                let mut state = serializer.serialize_struct_variant(\n                    enum_name,\n                    variant_index,\n                    variant_name,\n                    field_len,\n                )?;\n                for (index, field) in self.enum_value.iter_fields().enumerate() {\n                    let field_info = struct_info.field_at(index).unwrap();\n                    state.serialize_field(\n                        field_info.name(),\n                        &TypedReflectSerializer::new_internal(\n                            field.value(),\n                            self.registry,\n                            self.processor,\n                        ),\n                    )?;\n                }\n                state.end()\n            }\n            VariantType::Tuple if field_len == 1 => {\n                let field = self.enum_value.field_at(0).unwrap();\n\n                if type_info.type_path_table().module_path() == Some(\"core::option\")\n                    && type_info.type_path_table().ident() == Some(\"Option\")\n                {\n                    serializer.serialize_some(&TypedReflectSerializer::new_internal(\n                        field,\n                        self.registry,\n                        self.processor,\n                    ))\n                } else {\n                    serializer.serialize_newtype_variant(\n                        enum_name,\n                        variant_index,\n                        variant_name,\n                        &TypedReflectSerializer::new_internal(field, self.registry, self.processor),\n                    )\n                }\n            }\n            VariantType::Tuple => {\n                let mut state = serializer.serialize_tuple_variant(\n                    enum_name,\n                    variant_index,\n                    variant_name,\n                    field_len,\n                )?;\n                for field in self.enum_value.iter_fields() {\n                    state.serialize_field(&TypedReflectSerializer::new_internal(\n                        field.value(),\n                        self.registry,\n                        self.processor,\n                    ))?;\n                }\n                state.end()\n            }\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "fe10e101af64e9620eeeaf549ce497f0b494146d",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_reflect/src/serde/ser/tuple_structs.rs",
    "func": "use crate::{\n    serde::{ser::error_utils::make_custom_error, SerializationData, TypedReflectSerializer},\n    TupleStruct, TypeInfo, TypeRegistry,\n};\nuse serde::{ser::SerializeTupleStruct, Serialize};\n\nuse super::ReflectSerializerProcessor;\n\n/// A serializer for [`TupleStruct`] values.\npub(super) struct TupleStructSerializer<'a, P> {\n    pub tuple_struct: &'a dyn TupleStruct,\n    pub registry: &'a TypeRegistry,\n    pub processor: Option<&'a P>,\n}\n\nimpl<P: ReflectSerializerProcessor> Serialize for TupleStructSerializer<'_, P> {\n    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>\n    where\n        S: serde::Serializer,\n    {\n        let type_info = self\n            .tuple_struct\n            .get_represented_type_info()\n            .ok_or_else(|| {\n                make_custom_error(format_args!(\n                    \"cannot get type info for `{}`\",\n                    self.tuple_struct.reflect_type_path()\n                ))\n            })?;\n\n        let tuple_struct_info = match type_info {\n            TypeInfo::TupleStruct(tuple_struct_info) => tuple_struct_info,\n            info => {\n                return Err(make_custom_error(format_args!(\n                    \"expected tuple struct type but received {info:?}\"\n                )));\n            }\n        };\n\n        let serialization_data = self\n            .registry\n            .get(type_info.type_id())\n            .and_then(|registration| registration.data::<SerializationData>());\n        let ignored_len = serialization_data.map(SerializationData::len).unwrap_or(0);\n\n        if self.tuple_struct.field_len() == 1 && serialization_data.is_none() {\n            let field = self.tuple_struct.field(0).unwrap();\n            return serializer.serialize_newtype_struct(\n                tuple_struct_info.type_path_table().ident().unwrap(),\n                &TypedReflectSerializer::new_internal(field, self.registry, self.processor),\n            );\n        }\n\n        let mut state = serializer.serialize_tuple_struct(\n            tuple_struct_info.type_path_table().ident().unwrap(),\n            self.tuple_struct.field_len() - ignored_len,\n        )?;\n\n        for (index, value) in self.tuple_struct.iter_fields().enumerate() {\n            if serialization_data\n                .map(|data| data.is_field_skipped(index))\n                .unwrap_or(false)\n            {\n                continue;\n            }\n            state.serialize_field(&TypedReflectSerializer::new_internal(\n                value,\n                self.registry,\n                self.processor,\n            ))?;\n        }\n        state.end()\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "658076390671fa954e6828e815625695359b8801",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_ui/src/ui_material.rs",
    "func": "use crate::Node;\nuse bevy_asset::{Asset, AssetId, Handle};\nuse bevy_derive::{Deref, DerefMut};\nuse bevy_ecs::{\n    component::{require, Component},\n    reflect::ReflectComponent,\n};\nuse bevy_reflect::{prelude::ReflectDefault, Reflect};\nuse bevy_render::{\n    extract_component::ExtractComponent,\n    render_resource::{AsBindGroup, RenderPipelineDescriptor, ShaderRef},\n};\nuse core::hash::Hash;\nuse derive_more::derive::From;\n\n/// Materials are used alongside [`UiMaterialPlugin`](crate::UiMaterialPlugin) and [`MaterialNode`]\n/// to spawn entities that are rendered with a specific [`UiMaterial`] type. They serve as an easy to use high level\n/// way to render `Node` entities with custom shader logic.\n///\n/// `UiMaterials` must implement [`AsBindGroup`] to define how data will be transferred to the GPU and bound in shaders.\n/// [`AsBindGroup`] can be derived, which makes generating bindings straightforward. See the [`AsBindGroup`] docs for details.\n///\n/// Materials must also implement [`Asset`] so they can be treated as such.\n///\n/// If you are only using the fragment shader, make sure your shader imports the `UiVertexOutput`\n/// from `bevy_ui::ui_vertex_output` and uses it as the input of your fragment shader like the\n/// example below does.\n///\n/// # Example\n///\n/// Here is a simple [`UiMaterial`] implementation. The [`AsBindGroup`] derive has many features. To see what else is available,\n/// check out the [`AsBindGroup`] documentation.\n/// ```\n/// # use bevy_ui::prelude::*;\n/// # use bevy_ecs::prelude::*;\n/// # use bevy_image::Image;\n/// # use bevy_reflect::TypePath;\n/// # use bevy_render::render_resource::{AsBindGroup, ShaderRef};\n/// # use bevy_color::LinearRgba;\n/// # use bevy_asset::{Handle, AssetServer, Assets, Asset};\n///\n/// #[derive(AsBindGroup, Asset, TypePath, Debug, Clone)]\n/// pub struct CustomMaterial {\n///     // Uniform bindings must implement `ShaderType`, which will be used to convert the value to\n///     // its shader-compatible equivalent. Most core math types already implement `ShaderType`.\n///     #[uniform(0)]\n///     color: LinearRgba,\n///     // Images can be bound as textures in shaders. If the Image's sampler is also needed, just\n///     // add the sampler attribute with a different binding index.\n///     #[texture(1)]\n///     #[sampler(2)]\n///     color_texture: Handle<Image>,\n/// }\n///\n/// // All functions on `UiMaterial` have default impls. You only need to implement the\n/// // functions that are relevant for your material.\n/// impl UiMaterial for CustomMaterial {\n///     fn fragment_shader() -> ShaderRef {\n///         \"shaders/custom_material.wgsl\".into()\n///     }\n/// }\n///\n/// // Spawn an entity using `CustomMaterial`.\n/// fn setup(mut commands: Commands, mut materials: ResMut<Assets<CustomMaterial>>, asset_server: Res<AssetServer>) {\n///     commands.spawn((\n///         MaterialNode(materials.add(CustomMaterial {\n///             color: LinearRgba::RED,\n///             color_texture: asset_server.load(\"some_image.png\"),\n///         })),\n///         Node {\n///             width: Val::Percent(100.0),\n///             ..Default::default()\n///         },\n///     ));\n/// }\n/// ```\n/// In WGSL shaders, the material's binding would look like this:\n///\n/// If you only use the fragment shader make sure to import `UiVertexOutput` from\n/// `bevy_ui::ui_vertex_output` in your wgsl shader.\n/// Also note that bind group 0 is always bound to the [`View Uniform`](bevy_render::view::ViewUniform)\n/// and the [`Globals Uniform`](bevy_render::globals::GlobalsUniform).\n///\n/// ```wgsl\n/// #import bevy_ui::ui_vertex_output UiVertexOutput\n///\n/// struct CustomMaterial {\n///     color: vec4<f32>,\n/// }\n///\n/// @group(1) @binding(0)\n/// var<uniform> material: CustomMaterial;\n/// @group(1) @binding(1)\n/// var color_texture: texture_2d<f32>;\n/// @group(1) @binding(2)\n/// var color_sampler: sampler;\n///\n/// @fragment\n/// fn fragment(in: UiVertexOutput) -> @location(0) vec4<f32> {\n///\n/// }\n/// ```\npub trait UiMaterial: AsBindGroup + Asset + Clone + Sized {\n    /// Returns this materials vertex shader. If [`ShaderRef::Default`] is returned, the default UI\n    /// vertex shader will be used.\n    fn vertex_shader() -> ShaderRef {\n        ShaderRef::Default\n    }\n\n    /// Returns this materials fragment shader. If [`ShaderRef::Default`] is returned, the default\n    /// UI fragment shader will be used.\n    fn fragment_shader() -> ShaderRef {\n        ShaderRef::Default\n    }\n\n    #[allow(unused_variables)]\n    #[inline]\n    fn specialize(descriptor: &mut RenderPipelineDescriptor, key: UiMaterialKey<Self>) {}\n}\n\npub struct UiMaterialKey<M: UiMaterial> {\n    pub hdr: bool,\n    pub bind_group_data: M::Data,\n}\n\nimpl<M: UiMaterial> Eq for UiMaterialKey<M> where M::Data: PartialEq {}\n\nimpl<M: UiMaterial> PartialEq for UiMaterialKey<M>\nwhere\n    M::Data: PartialEq,\n{\n    fn eq(&self, other: &Self) -> bool {\n        self.hdr == other.hdr && self.bind_group_data == other.bind_group_data\n    }\n}\n\nimpl<M: UiMaterial> Clone for UiMaterialKey<M>\nwhere\n    M::Data: Clone,\n{\n    fn clone(&self) -> Self {\n        Self {\n            hdr: self.hdr,\n            bind_group_data: self.bind_group_data.clone(),\n        }\n    }\n}\n\nimpl<M: UiMaterial> Hash for UiMaterialKey<M>\nwhere\n    M::Data: Hash,\n{\n    fn hash<H: core::hash::Hasher>(&self, state: &mut H) {\n        self.hdr.hash(state);\n        self.bind_group_data.hash(state);\n    }\n}\n\n#[derive(\n    Component, Clone, Debug, Deref, DerefMut, Reflect, PartialEq, Eq, ExtractComponent, From,\n)]\n#[reflect(Component, Default)]\n#[require(Node)]\npub struct MaterialNode<M: UiMaterial>(pub Handle<M>);\n\nimpl<M: UiMaterial> Default for MaterialNode<M> {\n    fn default() -> Self {\n        Self(Handle::default())\n    }\n}\n\nimpl<M: UiMaterial> From<MaterialNode<M>> for AssetId<M> {\n    fn from(material: MaterialNode<M>) -> Self {\n        material.id()\n    }\n}\n\nimpl<M: UiMaterial> From<&MaterialNode<M>> for AssetId<M> {\n    fn from(material: &MaterialNode<M>) -> Self {\n        material.id()\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "7bb8f94a72763c5310873b59f7185398a2c59813",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_ui/src/widget/label.rs",
    "func": "use bevy_ecs::{prelude::Component, reflect::ReflectComponent};\nuse bevy_reflect::{std_traits::ReflectDefault, Reflect};\n\n/// Marker struct for labels\n#[derive(Component, Debug, Default, Clone, Copy, Reflect)]\n#[reflect(Component, Default, Debug)]\npub struct Label;\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "a23b13d9a7263af6adafc9cb78589072299a475d",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/examples/shader/gpu_readback.rs",
    "func": "//! Simple example demonstrating the use of the [`Readback`] component to read back data from the GPU\n//! using both a storage buffer and texture.\n\nuse bevy::{\n    prelude::*,\n    render::{\n        extract_resource::{ExtractResource, ExtractResourcePlugin},\n        gpu_readback::{Readback, ReadbackComplete},\n        render_asset::{RenderAssetUsages, RenderAssets},\n        render_graph::{self, RenderGraph, RenderLabel},\n        render_resource::{\n            binding_types::{storage_buffer, texture_storage_2d},\n            *,\n        },\n        renderer::{RenderContext, RenderDevice},\n        storage::{GpuShaderStorageBuffer, ShaderStorageBuffer},\n        texture::GpuImage,\n        Render, RenderApp, RenderSet,\n    },\n};\n\n/// This example uses a shader source file from the assets subdirectory\nconst SHADER_ASSET_PATH: &str = \"shaders/gpu_readback.wgsl\";\n\n// The length of the buffer sent to the gpu\nconst BUFFER_LEN: usize = 16;\n\nfn main() {\n    App::new()\n        .add_plugins((\n            DefaultPlugins,\n            GpuReadbackPlugin,\n            ExtractResourcePlugin::<ReadbackBuffer>::default(),\n            ExtractResourcePlugin::<ReadbackImage>::default(),\n        ))\n        .insert_resource(ClearColor(Color::BLACK))\n        .add_systems(Startup, setup)\n        .run();\n}\n\n// We need a plugin to organize all the systems and render node required for this example\nstruct GpuReadbackPlugin;\nimpl Plugin for GpuReadbackPlugin {\n    fn build(&self, _app: &mut App) {}\n\n    fn finish(&self, app: &mut App) {\n        let render_app = app.sub_app_mut(RenderApp);\n        render_app.init_resource::<ComputePipeline>().add_systems(\n            Render,\n            prepare_bind_group\n                .in_set(RenderSet::PrepareBindGroups)\n                // We don't need to recreate the bind group every frame\n                .run_if(not(resource_exists::<GpuBufferBindGroup>)),\n        );\n\n        // Add the compute node as a top level node to the render graph\n        // This means it will only execute once per frame\n        render_app\n            .world_mut()\n            .resource_mut::<RenderGraph>()\n            .add_node(ComputeNodeLabel, ComputeNode::default());\n    }\n}\n\n#[derive(Resource, ExtractResource, Clone)]\nstruct ReadbackBuffer(Handle<ShaderStorageBuffer>);\n\n#[derive(Resource, ExtractResource, Clone)]\nstruct ReadbackImage(Handle<Image>);\n\nfn setup(\n    mut commands: Commands,\n    mut images: ResMut<Assets<Image>>,\n    mut buffers: ResMut<Assets<ShaderStorageBuffer>>,\n) {\n    // Create a storage buffer with some data\n    let buffer = vec![0u32; BUFFER_LEN];\n    let mut buffer = ShaderStorageBuffer::from(buffer);\n    // We need to enable the COPY_SRC usage so we can copy the buffer to the cpu\n    buffer.buffer_description.usage |= BufferUsages::COPY_SRC;\n    let buffer = buffers.add(buffer);\n\n    // Create a storage texture with some data\n    let size = Extent3d {\n        width: BUFFER_LEN as u32,\n        height: 1,\n        ..default()\n    };\n    let mut image = Image::new_fill(\n        size,\n        TextureDimension::D2,\n        &[0, 0, 0, 0],\n        TextureFormat::R32Uint,\n        RenderAssetUsages::RENDER_WORLD,\n    );\n    // We also need to enable the COPY_SRC, as well as STORAGE_BINDING so we can use it in the\n    // compute shader\n    image.texture_descriptor.usage |= TextureUsages::COPY_SRC | TextureUsages::STORAGE_BINDING;\n    let image = images.add(image);\n\n    // Spawn the readback components. For each frame, the data will be read back from the GPU\n    // asynchronously and trigger the `ReadbackComplete` event on this entity. Despawn the entity\n    // to stop reading back the data.\n    commands.spawn(Readback::buffer(buffer.clone())).observe(\n        |trigger: Trigger<ReadbackComplete>| {\n            // This matches the type which was used to create the `ShaderStorageBuffer` above,\n            // and is a convenient way to interpret the data.\n            let data: Vec<u32> = trigger.event().to_shader_type();\n            info!(\"Buffer {:?}\", data);\n        },\n    );\n    // This is just a simple way to pass the buffer handle to the render app for our compute node\n    commands.insert_resource(ReadbackBuffer(buffer));\n\n    // Textures can also be read back from the GPU. Pay careful attention to the format of the\n    // texture, as it will affect how the data is interpreted.\n    commands.spawn(Readback::texture(image.clone())).observe(\n        |trigger: Trigger<ReadbackComplete>| {\n            // You probably want to interpret the data as a color rather than a `ShaderType`,\n            // but in this case we know the data is a single channel storage texture, so we can\n            // interpret it as a `Vec<u32>`\n            let data: Vec<u32> = trigger.event().to_shader_type();\n            info!(\"Image {:?}\", data);\n        },\n    );\n    commands.insert_resource(ReadbackImage(image));\n}\n\n#[derive(Resource)]\nstruct GpuBufferBindGroup(BindGroup);\n\nfn prepare_bind_group(\n    mut commands: Commands,\n    pipeline: Res<ComputePipeline>,\n    render_device: Res<RenderDevice>,\n    buffer: Res<ReadbackBuffer>,\n    image: Res<ReadbackImage>,\n    buffers: Res<RenderAssets<GpuShaderStorageBuffer>>,\n    images: Res<RenderAssets<GpuImage>>,\n) {\n    let buffer = buffers.get(&buffer.0).unwrap();\n    let image = images.get(&image.0).unwrap();\n    let bind_group = render_device.create_bind_group(\n        None,\n        &pipeline.layout,\n        &BindGroupEntries::sequential((\n            buffer.buffer.as_entire_buffer_binding(),\n            image.texture_view.into_binding(),\n        )),\n    );\n    commands.insert_resource(GpuBufferBindGroup(bind_group));\n}\n\n#[derive(Resource)]\nstruct ComputePipeline {\n    layout: BindGroupLayout,\n    pipeline: CachedComputePipelineId,\n}\n\nimpl FromWorld for ComputePipeline {\n    fn from_world(world: &mut World) -> Self {\n        let render_device = world.resource::<RenderDevice>();\n        let layout = render_device.create_bind_group_layout(\n            None,\n            &BindGroupLayoutEntries::sequential(\n                ShaderStages::COMPUTE,\n                (\n                    storage_buffer::<Vec<u32>>(false),\n                    texture_storage_2d(TextureFormat::R32Uint, StorageTextureAccess::WriteOnly),\n                ),\n            ),\n        );\n        let shader = world.load_asset(SHADER_ASSET_PATH);\n        let pipeline_cache = world.resource::<PipelineCache>();\n        let pipeline = pipeline_cache.queue_compute_pipeline(ComputePipelineDescriptor {\n            label: Some(\"GPU readback compute shader\".into()),\n            layout: vec![layout.clone()],\n            push_constant_ranges: Vec::new(),\n            shader: shader.clone(),\n            shader_defs: Vec::new(),\n            entry_point: \"main\".into(),\n            zero_initialize_workgroup_memory: false,\n        });\n        ComputePipeline { layout, pipeline }\n    }\n}\n\n/// Label to identify the node in the render graph\n#[derive(Debug, Hash, PartialEq, Eq, Clone, RenderLabel)]\nstruct ComputeNodeLabel;\n\n/// The node that will execute the compute shader\n#[derive(Default)]\nstruct ComputeNode {}\nimpl render_graph::Node for ComputeNode {\n    fn run(\n        &self,\n        _graph: &mut render_graph::RenderGraphContext,\n        render_context: &mut RenderContext,\n        world: &World,\n    ) -> Result<(), render_graph::NodeRunError> {\n        let pipeline_cache = world.resource::<PipelineCache>();\n        let pipeline = world.resource::<ComputePipeline>();\n        let bind_group = world.resource::<GpuBufferBindGroup>();\n\n        if let Some(init_pipeline) = pipeline_cache.get_compute_pipeline(pipeline.pipeline) {\n            let mut pass =\n                render_context\n                    .command_encoder()\n                    .begin_compute_pass(&ComputePassDescriptor {\n                        label: Some(\"GPU readback compute pass\"),\n                        ..default()\n                    });\n\n            pass.set_bind_group(0, &bind_group.0, &[]);\n            pass.set_pipeline(init_pipeline);\n            pass.dispatch_workgroups(BUFFER_LEN as u32, 1, 1);\n        }\n        Ok(())\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "69a363c447bdfe46d3f604cdaff1994722956b0a",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/examples/3d/generate_custom_mesh.rs",
    "func": "//! This example demonstrates how to create a custom mesh,\n//! assign a custom UV mapping for a custom texture,\n//! and how to change the UV mapping at run-time.\n\nuse bevy::{\n    prelude::*,\n    render::{\n        mesh::{Indices, VertexAttributeValues},\n        render_asset::RenderAssetUsages,\n        render_resource::PrimitiveTopology,\n    },\n};\n\n// Define a \"marker\" component to mark the custom mesh. Marker components are often used in Bevy for\n// filtering entities in queries with `With`, they're usually not queried directly since they don't\n// contain information within them.\n#[derive(Component)]\nstruct CustomUV;\n\nfn main() {\n    App::new()\n        .add_plugins(DefaultPlugins)\n        .add_systems(Startup, setup)\n        .add_systems(Update, input_handler)\n        .run();\n}\n\nfn setup(\n    mut commands: Commands,\n    asset_server: Res<AssetServer>,\n    mut materials: ResMut<Assets<StandardMaterial>>,\n    mut meshes: ResMut<Assets<Mesh>>,\n) {\n    // Import the custom texture.\n    let custom_texture_handle: Handle<Image> = asset_server.load(\"textures/array_texture.png\");\n    // Create and save a handle to the mesh.\n    let cube_mesh_handle: Handle<Mesh> = meshes.add(create_cube_mesh());\n\n    // Render the mesh with the custom texture, and add the marker.\n    commands.spawn((\n        Mesh3d(cube_mesh_handle),\n        MeshMaterial3d(materials.add(StandardMaterial {\n            base_color_texture: Some(custom_texture_handle),\n            ..default()\n        })),\n        CustomUV,\n    ));\n\n    // Transform for the camera and lighting, looking at (0,0,0) (the position of the mesh).\n    let camera_and_light_transform =\n        Transform::from_xyz(1.8, 1.8, 1.8).looking_at(Vec3::ZERO, Vec3::Y);\n\n    // Camera in 3D space.\n    commands.spawn((Camera3d::default(), camera_and_light_transform));\n\n    // Light up the scene.\n    commands.spawn((PointLight::default(), camera_and_light_transform));\n\n    // Text to describe the controls.\n    commands.spawn((\n        Text::new(\"Controls:\\nSpace: Change UVs\\nX/Y/Z: Rotate\\nR: Reset orientation\"),\n        Node {\n            position_type: PositionType::Absolute,\n            top: Val::Px(12.0),\n            left: Val::Px(12.0),\n            ..default()\n        },\n    ));\n}\n\n// System to receive input from the user,\n// check out examples/input/ for more examples about user input.\nfn input_handler(\n    keyboard_input: Res<ButtonInput<KeyCode>>,\n    mesh_query: Query<&Mesh3d, With<CustomUV>>,\n    mut meshes: ResMut<Assets<Mesh>>,\n    mut query: Query<&mut Transform, With<CustomUV>>,\n    time: Res<Time>,\n) {\n    if keyboard_input.just_pressed(KeyCode::Space) {\n        let mesh_handle = mesh_query.get_single().expect(\"Query not successful\");\n        let mesh = meshes.get_mut(mesh_handle).unwrap();\n        toggle_texture(mesh);\n    }\n    if keyboard_input.pressed(KeyCode::KeyX) {\n        for mut transform in &mut query {\n            transform.rotate_x(time.delta_secs() / 1.2);\n        }\n    }\n    if keyboard_input.pressed(KeyCode::KeyY) {\n        for mut transform in &mut query {\n            transform.rotate_y(time.delta_secs() / 1.2);\n        }\n    }\n    if keyboard_input.pressed(KeyCode::KeyZ) {\n        for mut transform in &mut query {\n            transform.rotate_z(time.delta_secs() / 1.2);\n        }\n    }\n    if keyboard_input.pressed(KeyCode::KeyR) {\n        for mut transform in &mut query {\n            transform.look_to(Vec3::NEG_Z, Vec3::Y);\n        }\n    }\n}\n\n#[rustfmt::skip]\nfn create_cube_mesh() -> Mesh {\n    // Keep the mesh data accessible in future frames to be able to mutate it in toggle_texture.\n    Mesh::new(PrimitiveTopology::TriangleList, RenderAssetUsages::MAIN_WORLD | RenderAssetUsages::RENDER_WORLD)\n    .with_inserted_attribute(\n        Mesh::ATTRIBUTE_POSITION,\n        // Each array is an [x, y, z] coordinate in local space.\n        // The camera coordinate space is right-handed x-right, y-up, z-back. This means \"forward\" is -Z.\n        // Meshes always rotate around their local [0, 0, 0] when a rotation is applied to their Transform.\n        // By centering our mesh around the origin, rotating the mesh preserves its center of mass.\n        vec![\n            // top (facing towards +y)\n            [-0.5, 0.5, -0.5], // vertex with index 0\n            [0.5, 0.5, -0.5], // vertex with index 1\n            [0.5, 0.5, 0.5], // etc. until 23\n            [-0.5, 0.5, 0.5],\n            // bottom   (-y)\n            [-0.5, -0.5, -0.5],\n            [0.5, -0.5, -0.5],\n            [0.5, -0.5, 0.5],\n            [-0.5, -0.5, 0.5],\n            // right    (+x)\n            [0.5, -0.5, -0.5],\n            [0.5, -0.5, 0.5],\n            [0.5, 0.5, 0.5], // This vertex is at the same position as vertex with index 2, but they'll have different UV and normal\n            [0.5, 0.5, -0.5],\n            // left     (-x)\n            [-0.5, -0.5, -0.5],\n            [-0.5, -0.5, 0.5],\n            [-0.5, 0.5, 0.5],\n            [-0.5, 0.5, -0.5],\n            // back     (+z)\n            [-0.5, -0.5, 0.5],\n            [-0.5, 0.5, 0.5],\n            [0.5, 0.5, 0.5],\n            [0.5, -0.5, 0.5],\n            // forward  (-z)\n            [-0.5, -0.5, -0.5],\n            [-0.5, 0.5, -0.5],\n            [0.5, 0.5, -0.5],\n            [0.5, -0.5, -0.5],\n        ],\n    )\n    // Set-up UV coordinates to point to the upper (V < 0.5), \"dirt+grass\" part of the texture.\n    // Take a look at the custom image (assets/textures/array_texture.png)\n    // so the UV coords will make more sense\n    // Note: (0.0, 0.0) = Top-Left in UV mapping, (1.0, 1.0) = Bottom-Right in UV mapping\n    .with_inserted_attribute(\n        Mesh::ATTRIBUTE_UV_0,\n        vec![\n            // Assigning the UV coords for the top side.\n            [0.0, 0.2], [0.0, 0.0], [1.0, 0.0], [1.0, 0.2],\n            // Assigning the UV coords for the bottom side.\n            [0.0, 0.45], [0.0, 0.25], [1.0, 0.25], [1.0, 0.45],\n            // Assigning the UV coords for the right side.\n            [1.0, 0.45], [0.0, 0.45], [0.0, 0.2], [1.0, 0.2],\n            // Assigning the UV coords for the left side.\n            [1.0, 0.45], [0.0, 0.45], [0.0, 0.2], [1.0, 0.2],\n            // Assigning the UV coords for the back side.\n            [0.0, 0.45], [0.0, 0.2], [1.0, 0.2], [1.0, 0.45],\n            // Assigning the UV coords for the forward side.\n            [0.0, 0.45], [0.0, 0.2], [1.0, 0.2], [1.0, 0.45],\n        ],\n    )\n    // For meshes with flat shading, normals are orthogonal (pointing out) from the direction of\n    // the surface.\n    // Normals are required for correct lighting calculations.\n    // Each array represents a normalized vector, which length should be equal to 1.0.\n    .with_inserted_attribute(\n        Mesh::ATTRIBUTE_NORMAL,\n        vec![\n            // Normals for the top side (towards +y)\n            [0.0, 1.0, 0.0],\n            [0.0, 1.0, 0.0],\n            [0.0, 1.0, 0.0],\n            [0.0, 1.0, 0.0],\n            // Normals for the bottom side (towards -y)\n            [0.0, -1.0, 0.0],\n            [0.0, -1.0, 0.0],\n            [0.0, -1.0, 0.0],\n            [0.0, -1.0, 0.0],\n            // Normals for the right side (towards +x)\n            [1.0, 0.0, 0.0],\n            [1.0, 0.0, 0.0],\n            [1.0, 0.0, 0.0],\n            [1.0, 0.0, 0.0],\n            // Normals for the left side (towards -x)\n            [-1.0, 0.0, 0.0],\n            [-1.0, 0.0, 0.0],\n            [-1.0, 0.0, 0.0],\n            [-1.0, 0.0, 0.0],\n            // Normals for the back side (towards +z)\n            [0.0, 0.0, 1.0],\n            [0.0, 0.0, 1.0],\n            [0.0, 0.0, 1.0],\n            [0.0, 0.0, 1.0],\n            // Normals for the forward side (towards -z)\n            [0.0, 0.0, -1.0],\n            [0.0, 0.0, -1.0],\n            [0.0, 0.0, -1.0],\n            [0.0, 0.0, -1.0],\n        ],\n    )\n    // Create the triangles out of the 24 vertices we created.\n    // To construct a square, we need 2 triangles, therefore 12 triangles in total.\n    // To construct a triangle, we need the indices of its 3 defined vertices, adding them one\n    // by one, in a counter-clockwise order (relative to the position of the viewer, the order\n    // should appear counter-clockwise from the front of the triangle, in this case from outside the cube).\n    // Read more about how to correctly build a mesh manually in the Bevy documentation of a Mesh,\n    // further examples and the implementation of the built-in shapes.\n    //\n    // The first two defined triangles look like this (marked with the vertex indices,\n    // and the axis), when looking down at the top (+y) of the cube:\n    //   -Z\n    //   ^\n    // 0---1\n    // |  /|\n    // | / | -> +X\n    // |/  |\n    // 3---2\n    //\n    // The right face's (+x) triangles look like this, seen from the outside of the cube.\n    //   +Y\n    //   ^\n    // 10--11\n    // |  /|\n    // | / | -> -Z\n    // |/  |\n    // 9---8\n    //\n    // The back face's (+z) triangles look like this, seen from the outside of the cube.\n    //   +Y\n    //   ^\n    // 17--18\n    // |\\  |\n    // | \\ | -> +X\n    // |  \\|\n    // 16--19\n    .with_inserted_indices(Indices::U32(vec![\n        0,3,1 , 1,3,2, // triangles making up the top (+y) facing side.\n        4,5,7 , 5,6,7, // bottom (-y)\n        8,11,9 , 9,11,10, // right (+x)\n        12,13,15 , 13,14,15, // left (-x)\n        16,19,17 , 17,19,18, // back (+z)\n        20,21,23 , 21,22,23, // forward (-z)\n    ]))\n}\n\n// Function that changes the UV mapping of the mesh, to apply the other texture.\nfn toggle_texture(mesh_to_change: &mut Mesh) {\n    // Get a mutable reference to the values of the UV attribute, so we can iterate over it.\n    let uv_attribute = mesh_to_change.attribute_mut(Mesh::ATTRIBUTE_UV_0).unwrap();\n    // The format of the UV coordinates should be Float32x2.\n    let VertexAttributeValues::Float32x2(uv_attribute) = uv_attribute else {\n        panic!(\"Unexpected vertex format, expected Float32x2.\");\n    };\n\n    // Iterate over the UV coordinates, and change them as we want.\n    for uv_coord in uv_attribute.iter_mut() {\n        // If the UV coordinate points to the upper, \"dirt+grass\" part of the texture...\n        if (uv_coord[1] + 0.5) < 1.0 {\n            // ... point to the equivalent lower, \"sand+water\" part instead,\n            uv_coord[1] += 0.5;\n        } else {\n            // else, point back to the upper, \"dirt+grass\" part.\n            uv_coord[1] -= 0.5;\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "55ea93000823d21bad30e00df8db43bf45338a2c",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/examples/3d/irradiance_volumes.rs",
    "func": "//! This example shows how irradiance volumes affect the indirect lighting of\n//! objects in a scene.\n//!\n//! The controls are as follows:\n//!\n//! * Space toggles the irradiance volume on and off.\n//!\n//! * Enter toggles the camera rotation on and off.\n//!\n//! * Tab switches the object between a plain sphere and a running fox.\n//!\n//! * Backspace shows and hides the voxel cubes.\n//!\n//! * Clicking anywhere moves the object.\n\nuse bevy::{\n    color::palettes::css::*,\n    core_pipeline::Skybox,\n    math::{uvec3, vec3},\n    pbr::{\n        irradiance_volume::IrradianceVolume, ExtendedMaterial, MaterialExtension, NotShadowCaster,\n    },\n    prelude::*,\n    render::render_resource::{AsBindGroup, ShaderRef, ShaderType},\n    window::PrimaryWindow,\n};\n\n/// This example uses a shader source file from the assets subdirectory\nconst SHADER_ASSET_PATH: &str = \"shaders/irradiance_volume_voxel_visualization.wgsl\";\n\n// Rotation speed in radians per frame.\nconst ROTATION_SPEED: f32 = 0.2;\n\nconst FOX_SCALE: f32 = 0.05;\nconst SPHERE_SCALE: f32 = 2.0;\n\nconst IRRADIANCE_VOLUME_INTENSITY: f32 = 1800.0;\n\nconst AMBIENT_LIGHT_BRIGHTNESS: f32 = 0.06;\n\nconst VOXEL_CUBE_SCALE: f32 = 0.4;\n\nstatic DISABLE_IRRADIANCE_VOLUME_HELP_TEXT: &str = \"Space: Disable the irradiance volume\";\nstatic ENABLE_IRRADIANCE_VOLUME_HELP_TEXT: &str = \"Space: Enable the irradiance volume\";\n\nstatic HIDE_VOXELS_HELP_TEXT: &str = \"Backspace: Hide the voxels\";\nstatic SHOW_VOXELS_HELP_TEXT: &str = \"Backspace: Show the voxels\";\n\nstatic STOP_ROTATION_HELP_TEXT: &str = \"Enter: Stop rotation\";\nstatic START_ROTATION_HELP_TEXT: &str = \"Enter: Start rotation\";\n\nstatic SWITCH_TO_FOX_HELP_TEXT: &str = \"Tab: Switch to a skinned mesh\";\nstatic SWITCH_TO_SPHERE_HELP_TEXT: &str = \"Tab: Switch to a plain sphere mesh\";\n\nstatic CLICK_TO_MOVE_HELP_TEXT: &str = \"Left click: Move the object\";\n\nstatic GIZMO_COLOR: Color = Color::Srgba(YELLOW);\n\nstatic VOXEL_FROM_WORLD: Mat4 = Mat4::from_cols_array_2d(&[\n    [-42.317566, 0.0, 0.0, 0.0],\n    [0.0, 0.0, 44.601563, 0.0],\n    [0.0, 16.73776, 0.0, 0.0],\n    [0.0, 6.544792, 0.0, 1.0],\n]);\n\n// The mode the application is in.\n#[derive(Resource)]\nstruct AppStatus {\n    // Whether the user wants the irradiance volume to be applied.\n    irradiance_volume_present: bool,\n    // Whether the user wants the unskinned sphere mesh or the skinned fox mesh.\n    model: ExampleModel,\n    // Whether the user has requested the scene to rotate.\n    rotating: bool,\n    // Whether the user has requested the voxels to be displayed.\n    voxels_visible: bool,\n}\n\n// Which model the user wants to display.\n#[derive(Clone, Copy, PartialEq)]\nenum ExampleModel {\n    // The plain sphere.\n    Sphere,\n    // The fox, which is skinned.\n    Fox,\n}\n\n// Handles to all the assets used in this example.\n#[derive(Resource)]\nstruct ExampleAssets {\n    // The glTF scene containing the colored floor.\n    main_scene: Handle<Scene>,\n\n    // The 3D texture containing the irradiance volume.\n    irradiance_volume: Handle<Image>,\n\n    // The plain sphere mesh.\n    main_sphere: Handle<Mesh>,\n\n    // The material used for the sphere.\n    main_sphere_material: Handle<StandardMaterial>,\n\n    // The glTF scene containing the animated fox.\n    fox: Handle<Scene>,\n\n    // The graph containing the animation that the fox will play.\n    fox_animation_graph: Handle<AnimationGraph>,\n\n    // The node within the animation graph containing the animation.\n    fox_animation_node: AnimationNodeIndex,\n\n    // The voxel cube mesh.\n    voxel_cube: Handle<Mesh>,\n\n    // The skybox.\n    skybox: Handle<Image>,\n}\n\n// The sphere and fox both have this component.\n#[derive(Component)]\nstruct MainObject;\n\n// Marks each of the voxel cubes.\n#[derive(Component)]\nstruct VoxelCube;\n\n// Marks the voxel cube parent object.\n#[derive(Component)]\nstruct VoxelCubeParent;\n\ntype VoxelVisualizationMaterial = ExtendedMaterial<StandardMaterial, VoxelVisualizationExtension>;\n\n#[derive(Asset, TypePath, AsBindGroup, Debug, Clone)]\nstruct VoxelVisualizationExtension {\n    #[uniform(100)]\n    irradiance_volume_info: VoxelVisualizationIrradianceVolumeInfo,\n}\n\n#[derive(ShaderType, Debug, Clone)]\nstruct VoxelVisualizationIrradianceVolumeInfo {\n    world_from_voxel: Mat4,\n    voxel_from_world: Mat4,\n    resolution: UVec3,\n    intensity: f32,\n}\n\nfn main() {\n    // Create the example app.\n    App::new()\n        .add_plugins(DefaultPlugins.set(WindowPlugin {\n            primary_window: Some(Window {\n                title: \"Bevy Irradiance Volumes Example\".into(),\n                ..default()\n            }),\n            ..default()\n        }))\n        .add_plugins(MaterialPlugin::<VoxelVisualizationMaterial>::default())\n        .init_resource::<AppStatus>()\n        .init_resource::<ExampleAssets>()\n        .insert_resource(AmbientLight {\n            color: Color::WHITE,\n            brightness: 0.0,\n        })\n        .add_systems(Startup, setup)\n        .add_systems(PreUpdate, create_cubes)\n        .add_systems(Update, rotate_camera)\n        .add_systems(Update, play_animations)\n        .add_systems(\n            Update,\n            handle_mouse_clicks\n                .after(rotate_camera)\n                .after(play_animations),\n        )\n        .add_systems(\n            Update,\n            change_main_object\n                .after(rotate_camera)\n                .after(play_animations),\n        )\n        .add_systems(\n            Update,\n            toggle_irradiance_volumes\n                .after(rotate_camera)\n                .after(play_animations),\n        )\n        .add_systems(\n            Update,\n            toggle_voxel_visibility\n                .after(rotate_camera)\n                .after(play_animations),\n        )\n        .add_systems(\n            Update,\n            toggle_rotation.after(rotate_camera).after(play_animations),\n        )\n        .add_systems(\n            Update,\n            draw_gizmo\n                .after(handle_mouse_clicks)\n                .after(change_main_object)\n                .after(toggle_irradiance_volumes)\n                .after(toggle_voxel_visibility)\n                .after(toggle_rotation),\n        )\n        .add_systems(\n            Update,\n            update_text\n                .after(handle_mouse_clicks)\n                .after(change_main_object)\n                .after(toggle_irradiance_volumes)\n                .after(toggle_voxel_visibility)\n                .after(toggle_rotation),\n        )\n        .run();\n}\n\n// Spawns all the scene objects.\nfn setup(mut commands: Commands, assets: Res<ExampleAssets>, app_status: Res<AppStatus>) {\n    spawn_main_scene(&mut commands, &assets);\n    spawn_camera(&mut commands, &assets);\n    spawn_irradiance_volume(&mut commands, &assets);\n    spawn_light(&mut commands);\n    spawn_sphere(&mut commands, &assets);\n    spawn_voxel_cube_parent(&mut commands);\n    spawn_fox(&mut commands, &assets);\n    spawn_text(&mut commands, &app_status);\n}\n\nfn spawn_main_scene(commands: &mut Commands, assets: &ExampleAssets) {\n    commands.spawn(SceneRoot(assets.main_scene.clone()));\n}\n\nfn spawn_camera(commands: &mut Commands, assets: &ExampleAssets) {\n    commands.spawn((\n        Camera3d::default(),\n        Transform::from_xyz(-10.012, 4.8605, 13.281).looking_at(Vec3::ZERO, Vec3::Y),\n        Skybox {\n            image: assets.skybox.clone(),\n            brightness: 150.0,\n            ..default()\n        },\n    ));\n}\n\nfn spawn_irradiance_volume(commands: &mut Commands, assets: &ExampleAssets) {\n    commands.spawn((\n        Transform::from_matrix(VOXEL_FROM_WORLD),\n        IrradianceVolume {\n            voxels: assets.irradiance_volume.clone(),\n            intensity: IRRADIANCE_VOLUME_INTENSITY,\n        },\n        LightProbe,\n    ));\n}\n\nfn spawn_light(commands: &mut Commands) {\n    commands.spawn((\n        PointLight {\n            intensity: 250000.0,\n            shadows_enabled: true,\n            ..default()\n        },\n        Transform::from_xyz(4.0762, 5.9039, 1.0055),\n    ));\n}\n\nfn spawn_sphere(commands: &mut Commands, assets: &ExampleAssets) {\n    commands\n        .spawn((\n            Mesh3d(assets.main_sphere.clone()),\n            MeshMaterial3d(assets.main_sphere_material.clone()),\n            Transform::from_xyz(0.0, SPHERE_SCALE, 0.0).with_scale(Vec3::splat(SPHERE_SCALE)),\n        ))\n        .insert(MainObject);\n}\n\nfn spawn_voxel_cube_parent(commands: &mut Commands) {\n    commands.spawn((Visibility::Hidden, Transform::default(), VoxelCubeParent));\n}\n\nfn spawn_fox(commands: &mut Commands, assets: &ExampleAssets) {\n    commands.spawn((\n        SceneRoot(assets.fox.clone()),\n        Visibility::Hidden,\n        Transform::from_scale(Vec3::splat(FOX_SCALE)),\n        MainObject,\n    ));\n}\n\nfn spawn_text(commands: &mut Commands, app_status: &AppStatus) {\n    commands.spawn((\n        app_status.create_text(),\n        Node {\n            position_type: PositionType::Absolute,\n            bottom: Val::Px(12.0),\n            left: Val::Px(12.0),\n            ..default()\n        },\n    ));\n}\n\n// A system that updates the help text.\nfn update_text(mut text_query: Query<&mut Text>, app_status: Res<AppStatus>) {\n    for mut text in text_query.iter_mut() {\n        *text = app_status.create_text();\n    }\n}\n\nimpl AppStatus {\n    // Constructs the help text at the bottom of the screen based on the\n    // application status.\n    fn create_text(&self) -> Text {\n        let irradiance_volume_help_text = if self.irradiance_volume_present {\n            DISABLE_IRRADIANCE_VOLUME_HELP_TEXT\n        } else {\n            ENABLE_IRRADIANCE_VOLUME_HELP_TEXT\n        };\n\n        let voxels_help_text = if self.voxels_visible {\n            HIDE_VOXELS_HELP_TEXT\n        } else {\n            SHOW_VOXELS_HELP_TEXT\n        };\n\n        let rotation_help_text = if self.rotating {\n            STOP_ROTATION_HELP_TEXT\n        } else {\n            START_ROTATION_HELP_TEXT\n        };\n\n        let switch_mesh_help_text = match self.model {\n            ExampleModel::Sphere => SWITCH_TO_FOX_HELP_TEXT,\n            ExampleModel::Fox => SWITCH_TO_SPHERE_HELP_TEXT,\n        };\n\n        format!(\n            \"{CLICK_TO_MOVE_HELP_TEXT}\\n\\\n            {voxels_help_text}\\n\\\n            {irradiance_volume_help_text}\\n\\\n            {rotation_help_text}\\n\\\n            {switch_mesh_help_text}\"\n        )\n        .into()\n    }\n}\n\n// Rotates the camera a bit every frame.\nfn rotate_camera(\n    mut camera_query: Query<&mut Transform, With<Camera3d>>,\n    time: Res<Time>,\n    app_status: Res<AppStatus>,\n) {\n    if !app_status.rotating {\n        return;\n    }\n\n    for mut transform in camera_query.iter_mut() {\n        transform.translation = Vec2::from_angle(ROTATION_SPEED * time.delta_secs())\n            .rotate(transform.translation.xz())\n            .extend(transform.translation.y)\n            .xzy();\n        transform.look_at(Vec3::ZERO, Vec3::Y);\n    }\n}\n\n// Toggles between the unskinned sphere model and the skinned fox model if the\n// user requests it.\nfn change_main_object(\n    keyboard: Res<ButtonInput<KeyCode>>,\n    mut app_status: ResMut<AppStatus>,\n    mut sphere_query: Query<&mut Visibility, (With<MainObject>, With<Mesh3d>, Without<SceneRoot>)>,\n    mut fox_query: Query<&mut Visibility, (With<MainObject>, With<SceneRoot>)>,\n) {\n    if !keyboard.just_pressed(KeyCode::Tab) {\n        return;\n    }\n    let Some(mut sphere_visibility) = sphere_query.iter_mut().next() else {\n        return;\n    };\n    let Some(mut fox_visibility) = fox_query.iter_mut().next() else {\n        return;\n    };\n\n    match app_status.model {\n        ExampleModel::Sphere => {\n            *sphere_visibility = Visibility::Hidden;\n            *fox_visibility = Visibility::Visible;\n            app_status.model = ExampleModel::Fox;\n        }\n        ExampleModel::Fox => {\n            *sphere_visibility = Visibility::Visible;\n            *fox_visibility = Visibility::Hidden;\n            app_status.model = ExampleModel::Sphere;\n        }\n    }\n}\n\nimpl Default for AppStatus {\n    fn default() -> Self {\n        Self {\n            irradiance_volume_present: true,\n            rotating: true,\n            model: ExampleModel::Sphere,\n            voxels_visible: false,\n        }\n    }\n}\n\n// Turns on and off the irradiance volume as requested by the user.\nfn toggle_irradiance_volumes(\n    mut commands: Commands,\n    keyboard: Res<ButtonInput<KeyCode>>,\n    light_probe_query: Query<Entity, With<LightProbe>>,\n    mut app_status: ResMut<AppStatus>,\n    assets: Res<ExampleAssets>,\n    mut ambient_light: ResMut<AmbientLight>,\n) {\n    if !keyboard.just_pressed(KeyCode::Space) {\n        return;\n    };\n\n    let Some(light_probe) = light_probe_query.iter().next() else {\n        return;\n    };\n\n    if app_status.irradiance_volume_present {\n        commands.entity(light_probe).remove::<IrradianceVolume>();\n        ambient_light.brightness = AMBIENT_LIGHT_BRIGHTNESS * IRRADIANCE_VOLUME_INTENSITY;\n        app_status.irradiance_volume_present = false;\n    } else {\n        commands.entity(light_probe).insert(IrradianceVolume {\n            voxels: assets.irradiance_volume.clone(),\n            intensity: IRRADIANCE_VOLUME_INTENSITY,\n        });\n        ambient_light.brightness = 0.0;\n        app_status.irradiance_volume_present = true;\n    }\n}\n\nfn toggle_rotation(keyboard: Res<ButtonInput<KeyCode>>, mut app_status: ResMut<AppStatus>) {\n    if keyboard.just_pressed(KeyCode::Enter) {\n        app_status.rotating = !app_status.rotating;\n    }\n}\n\n// Handles clicks on the plane that reposition the object.\nfn handle_mouse_clicks(\n    buttons: Res<ButtonInput<MouseButton>>,\n    windows: Query<&Window, With<PrimaryWindow>>,\n    cameras: Query<(&Camera, &GlobalTransform)>,\n    mut main_objects: Query<&mut Transform, With<MainObject>>,\n) {\n    if !buttons.pressed(MouseButton::Left) {\n        return;\n    }\n    let Some(mouse_position) = windows.iter().next().and_then(Window::cursor_position) else {\n        return;\n    };\n    let Some((camera, camera_transform)) = cameras.iter().next() else {\n        return;\n    };\n\n    // Figure out where the user clicked on the plane.\n    let Ok(ray) = camera.viewport_to_world(camera_transform, mouse_position) else {\n        return;\n    };\n    let Some(ray_distance) = ray.intersect_plane(Vec3::ZERO, InfinitePlane3d::new(Vec3::Y)) else {\n        return;\n    };\n    let plane_intersection = ray.origin + ray.direction.normalize() * ray_distance;\n\n    // Move all the main objects.\n    for mut transform in main_objects.iter_mut() {\n        transform.translation = vec3(\n            plane_intersection.x,\n            transform.translation.y,\n            plane_intersection.z,\n        );\n    }\n}\n\nimpl FromWorld for ExampleAssets {\n    fn from_world(world: &mut World) -> Self {\n        let fox_animation =\n            world.load_asset(GltfAssetLabel::Animation(1).from_asset(\"models/animated/Fox.glb\"));\n        let (fox_animation_graph, fox_animation_node) =\n            AnimationGraph::from_clip(fox_animation.clone());\n\n        ExampleAssets {\n            main_sphere: world.add_asset(Sphere::default().mesh().uv(32, 18)),\n            fox: world.load_asset(GltfAssetLabel::Scene(0).from_asset(\"models/animated/Fox.glb\")),\n            main_sphere_material: world.add_asset(Color::from(SILVER)),\n            main_scene: world.load_asset(\n                GltfAssetLabel::Scene(0)\n                    .from_asset(\"models/IrradianceVolumeExample/IrradianceVolumeExample.glb\"),\n            ),\n            irradiance_volume: world.load_asset(\"irradiance_volumes/Example.vxgi.ktx2\"),\n            fox_animation_graph: world.add_asset(fox_animation_graph),\n            fox_animation_node,\n            voxel_cube: world.add_asset(Cuboid::default()),\n            // Just use a specular map for the skybox since it's not too blurry.\n            // In reality you wouldn't do this--you'd use a real skybox texture--but\n            // reusing the textures like this saves space in the Bevy repository.\n            skybox: world.load_asset(\"environment_maps/pisa_specular_rgb9e5_zstd.ktx2\"),\n        }\n    }\n}\n\n// Plays the animation on the fox.\nfn play_animations(\n    mut commands: Commands,\n    assets: Res<ExampleAssets>,\n    mut players: Query<(Entity, &mut AnimationPlayer), Without<AnimationGraphHandle>>,\n) {\n    for (entity, mut player) in players.iter_mut() {\n        commands\n            .entity(entity)\n            .insert(AnimationGraphHandle(assets.fox_animation_graph.clone()));\n        player.play(assets.fox_animation_node).repeat();\n    }\n}\n\nfn create_cubes(\n    image_assets: Res<Assets<Image>>,\n    mut commands: Commands,\n    irradiance_volumes: Query<(&IrradianceVolume, &GlobalTransform)>,\n    voxel_cube_parents: Query<Entity, With<VoxelCubeParent>>,\n    voxel_cubes: Query<Entity, With<VoxelCube>>,\n    example_assets: Res<ExampleAssets>,\n    mut voxel_visualization_material_assets: ResMut<Assets<VoxelVisualizationMaterial>>,\n) {\n    // If voxel cubes have already been spawned, don't do anything.\n    if !voxel_cubes.is_empty() {\n        return;\n    }\n\n    let Some(voxel_cube_parent) = voxel_cube_parents.iter().next() else {\n        return;\n    };\n\n    for (irradiance_volume, global_transform) in irradiance_volumes.iter() {\n        let Some(image) = image_assets.get(&irradiance_volume.voxels) else {\n            continue;\n        };\n\n        let resolution = image.texture_descriptor.size;\n\n        let voxel_cube_material = voxel_visualization_material_assets.add(ExtendedMaterial {\n            base: StandardMaterial::from(Color::from(RED)),\n            extension: VoxelVisualizationExtension {\n                irradiance_volume_info: VoxelVisualizationIrradianceVolumeInfo {\n                    world_from_voxel: VOXEL_FROM_WORLD.inverse(),\n                    voxel_from_world: VOXEL_FROM_WORLD,\n                    resolution: uvec3(\n                        resolution.width,\n                        resolution.height,\n                        resolution.depth_or_array_layers,\n                    ),\n                    intensity: IRRADIANCE_VOLUME_INTENSITY,\n                },\n            },\n        });\n\n        let scale = vec3(\n            1.0 / resolution.width as f32,\n            1.0 / resolution.height as f32,\n            1.0 / resolution.depth_or_array_layers as f32,\n        );\n\n        // Spawn a cube for each voxel.\n        for z in 0..resolution.depth_or_array_layers {\n            for y in 0..resolution.height {\n                for x in 0..resolution.width {\n                    let uvw = (uvec3(x, y, z).as_vec3() + 0.5) * scale - 0.5;\n                    let pos = global_transform.transform_point(uvw);\n                    let voxel_cube = commands\n                        .spawn((\n                            Mesh3d(example_assets.voxel_cube.clone()),\n                            MeshMaterial3d(voxel_cube_material.clone()),\n                            Transform::from_scale(Vec3::splat(VOXEL_CUBE_SCALE))\n                                .with_translation(pos),\n                        ))\n                        .insert(VoxelCube)\n                        .insert(NotShadowCaster)\n                        .id();\n\n                    commands.entity(voxel_cube_parent).add_child(voxel_cube);\n                }\n            }\n        }\n    }\n}\n\n// Draws a gizmo showing the bounds of the irradiance volume.\nfn draw_gizmo(\n    mut gizmos: Gizmos,\n    irradiance_volume_query: Query<&GlobalTransform, With<IrradianceVolume>>,\n    app_status: Res<AppStatus>,\n) {\n    if app_status.voxels_visible {\n        for transform in irradiance_volume_query.iter() {\n            gizmos.cuboid(*transform, GIZMO_COLOR);\n        }\n    }\n}\n\n// Handles a request from the user to toggle the voxel visibility on and off.\nfn toggle_voxel_visibility(\n    keyboard: Res<ButtonInput<KeyCode>>,\n    mut app_status: ResMut<AppStatus>,\n    mut voxel_cube_parent_query: Query<&mut Visibility, With<VoxelCubeParent>>,\n) {\n    if !keyboard.just_pressed(KeyCode::Backspace) {\n        return;\n    }\n\n    app_status.voxels_visible = !app_status.voxels_visible;\n\n    for mut visibility in voxel_cube_parent_query.iter_mut() {\n        *visibility = if app_status.voxels_visible {\n            Visibility::Visible\n        } else {\n            Visibility::Hidden\n        };\n    }\n}\n\nimpl MaterialExtension for VoxelVisualizationExtension {\n    fn fragment_shader() -> ShaderRef {\n        SHADER_ASSET_PATH.into()\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "3f679afcf3671c31ceac27121121c78e99e6b1c5",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/examples/3d/atmospheric_fog.rs",
    "func": "//! This example showcases atmospheric fog\n//!\n//! ## Controls\n//!\n//! | Key Binding        | Action                                 |\n//! |:-------------------|:---------------------------------------|\n//! | `Spacebar`         | Toggle Atmospheric Fog                 |\n//! | `S`                | Toggle Directional Light Fog Influence |\n\nuse bevy::{\n    pbr::{CascadeShadowConfigBuilder, NotShadowCaster},\n    prelude::*,\n};\n\nfn main() {\n    App::new()\n        .add_plugins(DefaultPlugins)\n        .add_systems(\n            Startup,\n            (setup_camera_fog, setup_terrain_scene, setup_instructions),\n        )\n        .add_systems(Update, toggle_system)\n        .run();\n}\n\nfn setup_camera_fog(mut commands: Commands) {\n    commands.spawn((\n        Camera3d::default(),\n        Transform::from_xyz(-1.0, 0.1, 1.0).looking_at(Vec3::new(0.0, 0.0, 0.0), Vec3::Y),\n        DistanceFog {\n            color: Color::srgba(0.35, 0.48, 0.66, 1.0),\n            directional_light_color: Color::srgba(1.0, 0.95, 0.85, 0.5),\n            directional_light_exponent: 30.0,\n            falloff: FogFalloff::from_visibility_colors(\n                15.0, // distance in world units up to which objects retain visibility (>= 5% contrast)\n                Color::srgb(0.35, 0.5, 0.66), // atmospheric extinction color (after light is lost due to absorption by atmospheric particles)\n                Color::srgb(0.8, 0.844, 1.0), // atmospheric inscattering color (light gained due to scattering from the sun)\n            ),\n        },\n    ));\n}\n\nfn setup_terrain_scene(\n    mut commands: Commands,\n    mut meshes: ResMut<Assets<Mesh>>,\n    mut materials: ResMut<Assets<StandardMaterial>>,\n    asset_server: Res<AssetServer>,\n) {\n    // Configure a properly scaled cascade shadow map for this scene (defaults are too large, mesh units are in km)\n    let cascade_shadow_config = CascadeShadowConfigBuilder {\n        first_cascade_far_bound: 0.3,\n        maximum_distance: 3.0,\n        ..default()\n    }\n    .build();\n\n    // Sun\n    commands.spawn((\n        DirectionalLight {\n            color: Color::srgb(0.98, 0.95, 0.82),\n            shadows_enabled: true,\n            ..default()\n        },\n        Transform::from_xyz(0.0, 0.0, 0.0).looking_at(Vec3::new(-0.15, -0.05, 0.25), Vec3::Y),\n        cascade_shadow_config,\n    ));\n\n    // Terrain\n    commands.spawn(SceneRoot(asset_server.load(\n        GltfAssetLabel::Scene(0).from_asset(\"models/terrain/Mountains.gltf\"),\n    )));\n\n    // Sky\n    commands.spawn((\n        Mesh3d(meshes.add(Cuboid::new(2.0, 1.0, 1.0))),\n        MeshMaterial3d(materials.add(StandardMaterial {\n            base_color: Srgba::hex(\"888888\").unwrap().into(),\n            unlit: true,\n            cull_mode: None,\n            ..default()\n        })),\n        Transform::from_scale(Vec3::splat(20.0)),\n        NotShadowCaster,\n    ));\n}\n\nfn setup_instructions(mut commands: Commands) {\n    commands.spawn((Text::new(\"Press Spacebar to Toggle Atmospheric Fog.\\nPress S to Toggle Directional Light Fog Influence.\"),\n        Node {\n            position_type: PositionType::Absolute,\n            bottom: Val::Px(12.0),\n            left: Val::Px(12.0),\n            ..default()\n        })\n    );\n}\n\nfn toggle_system(keycode: Res<ButtonInput<KeyCode>>, mut fog: Single<&mut DistanceFog>) {\n    if keycode.just_pressed(KeyCode::Space) {\n        let a = fog.color.alpha();\n        fog.color.set_alpha(1.0 - a);\n    }\n\n    if keycode.just_pressed(KeyCode::KeyS) {\n        let a = fog.directional_light_color.alpha();\n        fog.directional_light_color.set_alpha(0.5 - a);\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "f364c5ca99bca06330eab2833c0042a3ded88386",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/examples/3d/mesh_ray_cast.rs",
    "func": "//! Demonstrates how to use the [`MeshRayCast`] system parameter to chain multiple ray casts\n//! and bounce off of surfaces.\n\nuse std::f32::consts::{FRAC_PI_2, PI};\n\nuse bevy::{\n    color::palettes::css,\n    core_pipeline::{bloom::Bloom, tonemapping::Tonemapping},\n    math::vec3,\n    picking::backend::ray::RayMap,\n    prelude::*,\n};\n\nfn main() {\n    App::new()\n        .add_plugins(DefaultPlugins)\n        .add_systems(Startup, setup)\n        .add_systems(Update, bouncing_raycast)\n        .insert_resource(ClearColor(Color::BLACK))\n        .run();\n}\n\nconst MAX_BOUNCES: usize = 64;\nconst LASER_SPEED: f32 = 0.03;\n\nfn bouncing_raycast(\n    mut ray_cast: MeshRayCast,\n    mut gizmos: Gizmos,\n    time: Res<Time>,\n    // The ray map stores rays cast by the cursor\n    ray_map: Res<RayMap>,\n) {\n    // Cast an automatically moving ray and bounce it off of surfaces\n    let t = ops::cos((time.elapsed_secs() - 4.0).max(0.0) * LASER_SPEED) * PI;\n    let ray_pos = Vec3::new(ops::sin(t), ops::cos(3.0 * t) * 0.5, ops::cos(t)) * 0.5;\n    let ray_dir = Dir3::new(-ray_pos).unwrap();\n    let ray = Ray3d::new(ray_pos, ray_dir);\n    gizmos.sphere(ray_pos, 0.1, Color::WHITE);\n    bounce_ray(ray, &mut ray_cast, &mut gizmos, Color::from(css::RED));\n\n    // Cast a ray from the cursor and bounce it off of surfaces\n    for (_, ray) in ray_map.iter() {\n        bounce_ray(*ray, &mut ray_cast, &mut gizmos, Color::from(css::GREEN));\n    }\n}\n\n// Bounces a ray off of surfaces `MAX_BOUNCES` times.\nfn bounce_ray(mut ray: Ray3d, ray_cast: &mut MeshRayCast, gizmos: &mut Gizmos, color: Color) {\n    let mut intersections = Vec::with_capacity(MAX_BOUNCES + 1);\n    intersections.push((ray.origin, Color::srgb(30.0, 0.0, 0.0)));\n\n    for i in 0..MAX_BOUNCES {\n        // Cast the ray and get the first hit\n        let Some((_, hit)) = ray_cast.cast_ray(ray, &RayCastSettings::default()).first() else {\n            break;\n        };\n\n        // Draw the point of intersection and add it to the list\n        let brightness = 1.0 + 10.0 * (1.0 - i as f32 / MAX_BOUNCES as f32);\n        intersections.push((hit.point, Color::BLACK.mix(&color, brightness)));\n        gizmos.sphere(hit.point, 0.005, Color::BLACK.mix(&color, brightness * 2.0));\n\n        // Reflect the ray off of the surface\n        ray.direction = Dir3::new(ray.direction.reflect(hit.normal)).unwrap();\n        ray.origin = hit.point + ray.direction * 1e-6;\n    }\n    gizmos.linestrip_gradient(intersections);\n}\n\n// Set up a simple 3D scene\nfn setup(\n    mut commands: Commands,\n    mut meshes: ResMut<Assets<Mesh>>,\n    mut materials: ResMut<Assets<StandardMaterial>>,\n) {\n    // Make a box of planes facing inward so the laser gets trapped inside\n    let plane_mesh = meshes.add(Plane3d::default());\n    let plane_material = materials.add(Color::from(css::GRAY).with_alpha(0.01));\n    let create_plane = move |translation, rotation| {\n        (\n            Transform::from_translation(translation)\n                .with_rotation(Quat::from_scaled_axis(rotation)),\n            Mesh3d(plane_mesh.clone()),\n            MeshMaterial3d(plane_material.clone()),\n        )\n    };\n\n    commands.spawn(create_plane(vec3(0.0, 0.5, 0.0), Vec3::X * PI));\n    commands.spawn(create_plane(vec3(0.0, -0.5, 0.0), Vec3::ZERO));\n    commands.spawn(create_plane(vec3(0.5, 0.0, 0.0), Vec3::Z * FRAC_PI_2));\n    commands.spawn(create_plane(vec3(-0.5, 0.0, 0.0), Vec3::Z * -FRAC_PI_2));\n    commands.spawn(create_plane(vec3(0.0, 0.0, 0.5), Vec3::X * -FRAC_PI_2));\n    commands.spawn(create_plane(vec3(0.0, 0.0, -0.5), Vec3::X * FRAC_PI_2));\n\n    // Light\n    commands.spawn((\n        DirectionalLight::default(),\n        Transform::from_rotation(Quat::from_euler(EulerRot::XYZ, -0.1, 0.2, 0.0)),\n    ));\n\n    // Camera\n    commands.spawn((\n        Camera3d::default(),\n        Camera {\n            hdr: true,\n            ..default()\n        },\n        Transform::from_xyz(1.5, 1.5, 1.5).looking_at(Vec3::ZERO, Vec3::Y),\n        Tonemapping::TonyMcMapface,\n        Bloom::default(),\n    ));\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "aeb9c8188c6700822afb91222c1e0462d79d24c7",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/examples/3d/spherical_area_lights.rs",
    "func": "//! Demonstrates how lighting is affected by different radius of point lights.\n\nuse bevy::prelude::*;\n\nfn main() {\n    App::new()\n        .insert_resource(AmbientLight {\n            brightness: 60.0,\n            ..default()\n        })\n        .add_plugins(DefaultPlugins)\n        .add_systems(Startup, setup)\n        .run();\n}\n\nfn setup(\n    mut commands: Commands,\n    mut meshes: ResMut<Assets<Mesh>>,\n    mut materials: ResMut<Assets<StandardMaterial>>,\n) {\n    // camera\n    commands.spawn((\n        Camera3d::default(),\n        Transform::from_xyz(0.2, 1.5, 2.5).looking_at(Vec3::ZERO, Vec3::Y),\n    ));\n\n    // plane\n    commands.spawn((\n        Mesh3d(meshes.add(Plane3d::default().mesh().size(100.0, 100.0))),\n        MeshMaterial3d(materials.add(StandardMaterial {\n            base_color: Color::srgb(0.2, 0.2, 0.2),\n            perceptual_roughness: 0.08,\n            ..default()\n        })),\n    ));\n\n    const COUNT: usize = 6;\n    let position_range = -2.0..2.0;\n    let radius_range = 0.0..0.4;\n    let pos_len = position_range.end - position_range.start;\n    let radius_len = radius_range.end - radius_range.start;\n    let mesh = meshes.add(Sphere::new(1.0).mesh().uv(120, 64));\n\n    for i in 0..COUNT {\n        let percent = i as f32 / COUNT as f32;\n        let radius = radius_range.start + percent * radius_len;\n\n        // sphere light\n        commands\n            .spawn((\n                Mesh3d(mesh.clone()),\n                MeshMaterial3d(materials.add(StandardMaterial {\n                    base_color: Color::srgb(0.5, 0.5, 1.0),\n                    unlit: true,\n                    ..default()\n                })),\n                Transform::from_xyz(position_range.start + percent * pos_len, 0.3, 0.0)\n                    .with_scale(Vec3::splat(radius)),\n            ))\n            .with_child(PointLight {\n                radius,\n                color: Color::srgb(0.2, 0.2, 1.0),\n                ..default()\n            });\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "8312ed3387a27b42f5efdc5cb1cd40dc6d3d8350",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/examples/reflection/reflection_types.rs",
    "func": "#![allow(clippy::match_same_arms)]\n//! This example illustrates how reflection works for simple data structures, like\n//! structs, tuples and vectors.\n\nuse bevy::{\n    prelude::*,\n    reflect::{DynamicList, PartialReflect, ReflectRef},\n    utils::HashMap,\n};\nuse serde::{Deserialize, Serialize};\n\nfn main() {\n    App::new()\n        .add_plugins(DefaultPlugins)\n        .add_systems(Startup, setup)\n        .run();\n}\n\n/// Deriving reflect on a struct will implement the `Reflect` and `Struct` traits\n#[derive(Reflect)]\npub struct A {\n    x: usize,\n    y: Vec<u32>,\n    z: HashMap<String, f32>,\n}\n\n/// Deriving reflect on a unit struct will implement the `Reflect` and `Struct` traits\n#[derive(Reflect)]\npub struct B;\n\n/// Deriving reflect on a tuple struct will implement the `Reflect` and `TupleStruct` traits\n#[derive(Reflect)]\npub struct C(usize);\n\n/// Deriving reflect on an enum will implement the `Reflect` and `Enum` traits\n#[derive(Reflect)]\n#[allow(dead_code)]\nenum D {\n    A,\n    B(usize),\n    C { value: f32 },\n}\n\n/// Reflect has \"built in\" support for some common traits like `PartialEq`, `Hash`, and `Serialize`.\n///\n/// These are exposed via methods like `PartialReflect::reflect_hash()`,\n/// `PartialReflect::reflect_partial_eq()`, and `PartialReflect::serializable()`.\n/// You can force these implementations to use the actual trait\n/// implementations (instead of their defaults) like this:\n#[derive(Reflect, Hash, Serialize, PartialEq, Eq)]\n#[reflect(Hash, Serialize, PartialEq)]\npub struct E {\n    x: usize,\n}\n\n/// By default, deriving with Reflect assumes the type is either a \"struct\" or an \"enum\".\n///\n/// You can tell reflect to treat your type instead as an \"opaque type\" by using the `#[reflect(opaque)]`.\n/// It is generally a good idea to implement (and reflect) the `PartialEq`, `Serialize`, and `Deserialize`\n/// traits on opaque types to ensure that these values behave as expected when nested in other reflected types.\n#[derive(Reflect, Copy, Clone, PartialEq, Eq, Serialize, Deserialize)]\n#[reflect(opaque)]\n#[reflect(PartialEq, Serialize, Deserialize)]\n#[allow(dead_code)]\nenum F {\n    X,\n    Y,\n}\n\nfn setup() {\n    let mut z = HashMap::default();\n    z.insert(\"Hello\".to_string(), 1.0);\n    let value: Box<dyn Reflect> = Box::new(A {\n        x: 1,\n        y: vec![1, 2],\n        z,\n    });\n\n    // There are a number of different \"reflect traits\", which each expose different operations on\n    // the underlying type\n    match value.reflect_ref() {\n        // `Struct` is a trait automatically implemented for structs that derive Reflect. This trait\n        // allows you to interact with fields via their string names or indices\n        ReflectRef::Struct(value) => {\n            info!(\n                \"This is a 'struct' type with an 'x' value of {}\",\n                value.get_field::<usize>(\"x\").unwrap()\n            );\n        }\n        // `TupleStruct` is a trait automatically implemented for tuple structs that derive Reflect.\n        // This trait allows you to interact with fields via their indices\n        ReflectRef::TupleStruct(_) => {}\n        // `Tuple` is a special trait that can be manually implemented (instead of deriving\n        // Reflect). This exposes \"tuple\" operations on your type, allowing you to interact\n        // with fields via their indices. Tuple is automatically implemented for tuples of\n        // arity 12 or less.\n        ReflectRef::Tuple(_) => {}\n        // `Enum` is a trait automatically implemented for enums that derive Reflect. This trait allows you\n        // to interact with the current variant and its fields (if it has any)\n        ReflectRef::Enum(_) => {}\n        // `List` is a special trait that can be manually implemented (instead of deriving Reflect).\n        // This exposes \"list\" operations on your type, such as insertion. `List` is automatically\n        // implemented for relevant core types like Vec<T>.\n        ReflectRef::List(_) => {}\n        // `Array` is a special trait that can be manually implemented (instead of deriving Reflect).\n        // This exposes \"array\" operations on your type, such as indexing. `Array`\n        // is automatically implemented for relevant core types like [T; N].\n        ReflectRef::Array(_) => {}\n        // `Map` is a special trait that can be manually implemented (instead of deriving Reflect).\n        // This exposes \"map\" operations on your type, such as getting / inserting by key.\n        // Map is automatically implemented for relevant core types like HashMap<K, V>\n        ReflectRef::Map(_) => {}\n        // `Set` is a special trait that can be manually implemented (instead of deriving Reflect).\n        // This exposes \"set\" operations on your type, such as getting / inserting by value.\n        // Set is automatically implemented for relevant core types like HashSet<T>\n        ReflectRef::Set(_) => {}\n        // `Function` is a special trait that can be manually implemented (instead of deriving Reflect).\n        // This exposes \"function\" operations on your type, such as calling it with arguments.\n        // This trait is automatically implemented for types like DynamicFunction.\n        // This variant only exists if the `reflect_functions` feature is enabled.\n        #[cfg(feature = \"reflect_functions\")]\n        ReflectRef::Function(_) => {}\n        // `Opaque` types do not implement any of the other traits above. They are simply a Reflect\n        // implementation. Opaque is implemented for opaque types like String and Instant,\n        // but also include primitive types like i32, usize, and f32 (despite not technically being opaque).\n        ReflectRef::Opaque(_) => {}\n    }\n\n    let mut dynamic_list = DynamicList::default();\n    dynamic_list.push(3u32);\n    dynamic_list.push(4u32);\n    dynamic_list.push(5u32);\n\n    let mut value: A = value.take::<A>().unwrap();\n    value.y.apply(&dynamic_list);\n    assert_eq!(value.y, vec![3u32, 4u32, 5u32]);\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "e66bc3671641e2148fd9e8c83fd7ea91a22aeb1a",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/examples/ecs/system_piping.rs",
    "func": "//! Illustrates how to make a single system from multiple functions running in sequence,\n//! passing the output of the first into the input of the next.\n\nuse bevy::prelude::*;\nuse std::num::ParseIntError;\n\nuse bevy::{\n    log::LogPlugin,\n    utils::{dbg, error, info, tracing::Level, warn},\n};\n\nfn main() {\n    App::new()\n        .insert_resource(Message(\"42\".to_string()))\n        .insert_resource(OptionalWarning(Err(\"Got to rusty?\".to_string())))\n        .add_plugins(LogPlugin {\n            level: Level::TRACE,\n            filter: \"\".to_string(),\n            ..default()\n        })\n        .add_systems(\n            Update,\n            (\n                parse_message_system.pipe(handler_system),\n                data_pipe_system.map(info),\n                parse_message_system.map(dbg),\n                warning_pipe_system.map(warn),\n                parse_error_message_system.map(error),\n                parse_message_system.map(drop),\n            ),\n        )\n        .run();\n}\n\n#[derive(Resource, Deref)]\nstruct Message(String);\n\n#[derive(Resource, Deref)]\nstruct OptionalWarning(Result<(), String>);\n\n// This system produces a Result<usize> output by trying to parse the Message resource.\nfn parse_message_system(message: Res<Message>) -> Result<usize, ParseIntError> {\n    message.parse::<usize>()\n}\n\n// This system produces a Result<()> output by trying to parse the Message resource.\nfn parse_error_message_system(message: Res<Message>) -> Result<(), ParseIntError> {\n    message.parse::<usize>()?;\n    Ok(())\n}\n\n// This system takes a Result<usize> input and either prints the parsed value or the error message\n// Try changing the Message resource to something that isn't an integer. You should see the error\n// message printed.\nfn handler_system(In(result): In<Result<usize, ParseIntError>>) {\n    match result {\n        Ok(value) => println!(\"parsed message: {value}\"),\n        Err(err) => println!(\"encountered an error: {err:?}\"),\n    }\n}\n\n// This system produces a String output by trying to clone the String from the Message resource.\nfn data_pipe_system(message: Res<Message>) -> String {\n    message.0.clone()\n}\n\n// This system produces an Result<String> output by trying to extract a String from the\n// OptionalWarning resource. Try changing the OptionalWarning resource to None. You should\n// not see the warning message printed.\nfn warning_pipe_system(message: Res<OptionalWarning>) -> Result<(), String> {\n    message.0.clone()\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "ef8c39c5228b618cb56718cdfa3ecab8bb2b99e7",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/examples/animation/custom_skinned_mesh.rs",
    "func": "//! Skinned mesh example with mesh and joints data defined in code.\n//! Example taken from <https://github.com/KhronosGroup/glTF-Tutorials/blob/master/gltfTutorial/gltfTutorial_019_SimpleSkin.md>\n\nuse std::f32::consts::*;\n\nuse bevy::{\n    math::ops,\n    prelude::*,\n    render::{\n        mesh::{\n            skinning::{SkinnedMesh, SkinnedMeshInverseBindposes},\n            Indices, PrimitiveTopology, VertexAttributeValues,\n        },\n        render_asset::RenderAssetUsages,\n    },\n};\nuse rand::{Rng, SeedableRng};\nuse rand_chacha::ChaCha8Rng;\n\nfn main() {\n    App::new()\n        .add_plugins(DefaultPlugins)\n        .insert_resource(AmbientLight {\n            brightness: 3000.0,\n            ..default()\n        })\n        .add_systems(Startup, setup)\n        .add_systems(Update, joint_animation)\n        .run();\n}\n\n/// Used to mark a joint to be animated in the [`joint_animation`] system.\n#[derive(Component)]\nstruct AnimatedJoint(isize);\n\n/// Construct a mesh and a skeleton with 2 joints for that mesh,\n///   and mark the second joint to be animated.\n/// It is similar to the scene defined in `models/SimpleSkin/SimpleSkin.gltf`\nfn setup(\n    mut commands: Commands,\n    asset_server: Res<AssetServer>,\n    mut meshes: ResMut<Assets<Mesh>>,\n    mut materials: ResMut<Assets<StandardMaterial>>,\n    mut skinned_mesh_inverse_bindposes_assets: ResMut<Assets<SkinnedMeshInverseBindposes>>,\n) {\n    // Create a camera\n    commands.spawn((\n        Camera3d::default(),\n        Transform::from_xyz(2.5, 2.5, 9.0).looking_at(Vec3::ZERO, Vec3::Y),\n    ));\n\n    // Create inverse bindpose matrices for a skeleton consists of 2 joints\n    let inverse_bindposes = skinned_mesh_inverse_bindposes_assets.add(vec![\n        Mat4::from_translation(Vec3::new(-0.5, -1.0, 0.0)),\n        Mat4::from_translation(Vec3::new(-0.5, -1.0, 0.0)),\n    ]);\n\n    // Create a mesh\n    let mesh = Mesh::new(\n        PrimitiveTopology::TriangleList,\n        RenderAssetUsages::RENDER_WORLD,\n    )\n    // Set mesh vertex positions\n    .with_inserted_attribute(\n        Mesh::ATTRIBUTE_POSITION,\n        vec![\n            [0.0, 0.0, 0.0],\n            [1.0, 0.0, 0.0],\n            [0.0, 0.5, 0.0],\n            [1.0, 0.5, 0.0],\n            [0.0, 1.0, 0.0],\n            [1.0, 1.0, 0.0],\n            [0.0, 1.5, 0.0],\n            [1.0, 1.5, 0.0],\n            [0.0, 2.0, 0.0],\n            [1.0, 2.0, 0.0],\n        ],\n    )\n    // Add UV coordinates that map the left half of the texture since its a 1 x\n    // 2 rectangle.\n    .with_inserted_attribute(\n        Mesh::ATTRIBUTE_UV_0,\n        vec![\n            [0.0, 0.00],\n            [0.5, 0.00],\n            [0.0, 0.25],\n            [0.5, 0.25],\n            [0.0, 0.50],\n            [0.5, 0.50],\n            [0.0, 0.75],\n            [0.5, 0.75],\n            [0.0, 1.00],\n            [0.5, 1.00],\n        ],\n    )\n    // Set mesh vertex normals\n    .with_inserted_attribute(Mesh::ATTRIBUTE_NORMAL, vec![[0.0, 0.0, 1.0]; 10])\n    // Set mesh vertex joint indices for mesh skinning.\n    // Each vertex gets 4 indices used to address the `JointTransforms` array in the vertex shader\n    //  as well as `SkinnedMeshJoint` array in the `SkinnedMesh` component.\n    // This means that a maximum of 4 joints can affect a single vertex.\n    .with_inserted_attribute(\n        Mesh::ATTRIBUTE_JOINT_INDEX,\n        // Need to be explicit here as [u16; 4] could be either Uint16x4 or Unorm16x4.\n        VertexAttributeValues::Uint16x4(vec![\n            [0, 0, 0, 0],\n            [0, 0, 0, 0],\n            [0, 1, 0, 0],\n            [0, 1, 0, 0],\n            [0, 1, 0, 0],\n            [0, 1, 0, 0],\n            [0, 1, 0, 0],\n            [0, 1, 0, 0],\n            [0, 1, 0, 0],\n            [0, 1, 0, 0],\n        ]),\n    )\n    // Set mesh vertex joint weights for mesh skinning.\n    // Each vertex gets 4 joint weights corresponding to the 4 joint indices assigned to it.\n    // The sum of these weights should equal to 1.\n    .with_inserted_attribute(\n        Mesh::ATTRIBUTE_JOINT_WEIGHT,\n        vec![\n            [1.00, 0.00, 0.0, 0.0],\n            [1.00, 0.00, 0.0, 0.0],\n            [0.75, 0.25, 0.0, 0.0],\n            [0.75, 0.25, 0.0, 0.0],\n            [0.50, 0.50, 0.0, 0.0],\n            [0.50, 0.50, 0.0, 0.0],\n            [0.25, 0.75, 0.0, 0.0],\n            [0.25, 0.75, 0.0, 0.0],\n            [0.00, 1.00, 0.0, 0.0],\n            [0.00, 1.00, 0.0, 0.0],\n        ],\n    )\n    // Tell bevy to construct triangles from a list of vertex indices,\n    //  where each 3 vertex indices form an triangle.\n    .with_inserted_indices(Indices::U16(vec![\n        0, 1, 3, 0, 3, 2, 2, 3, 5, 2, 5, 4, 4, 5, 7, 4, 7, 6, 6, 7, 9, 6, 9, 8,\n    ]));\n\n    let mesh = meshes.add(mesh);\n\n    // We're seeding the PRNG here to make this example deterministic for testing purposes.\n    // This isn't strictly required in practical use unless you need your app to be deterministic.\n    let mut rng = ChaCha8Rng::seed_from_u64(42);\n\n    for i in -5..5 {\n        // Create joint entities\n        let joint_0 = commands\n            .spawn(Transform::from_xyz(\n                i as f32 * 1.5,\n                0.0,\n                // Move quads back a small amount to avoid Z-fighting and not\n                // obscure the transform gizmos.\n                -(i as f32 * 0.01).abs(),\n            ))\n            .id();\n        let joint_1 = commands.spawn((AnimatedJoint(i), Transform::IDENTITY)).id();\n\n        // Set joint_1 as a child of joint_0.\n        commands.entity(joint_0).add_children(&[joint_1]);\n\n        // Each joint in this vector corresponds to each inverse bindpose matrix in `SkinnedMeshInverseBindposes`.\n        let joint_entities = vec![joint_0, joint_1];\n\n        // Create skinned mesh renderer. Note that its transform doesn't affect the position of the mesh.\n        commands.spawn((\n            Mesh3d(mesh.clone()),\n            MeshMaterial3d(materials.add(StandardMaterial {\n                base_color: Color::srgb(\n                    rng.gen_range(0.0..1.0),\n                    rng.gen_range(0.0..1.0),\n                    rng.gen_range(0.0..1.0),\n                ),\n                base_color_texture: Some(asset_server.load(\"textures/uv_checker_bw.png\")),\n                ..default()\n            })),\n            SkinnedMesh {\n                inverse_bindposes: inverse_bindposes.clone(),\n                joints: joint_entities,\n            },\n        ));\n    }\n}\n\n/// Animate the joint marked with [`AnimatedJoint`] component.\nfn joint_animation(\n    time: Res<Time>,\n    mut query: Query<(&mut Transform, &AnimatedJoint)>,\n    mut gizmos: Gizmos,\n) {\n    for (mut transform, animated_joint) in &mut query {\n        match animated_joint.0 {\n            -5 => {\n                transform.rotation =\n                    Quat::from_rotation_x(FRAC_PI_2 * ops::sin(time.elapsed_secs()));\n            }\n            -4 => {\n                transform.rotation =\n                    Quat::from_rotation_y(FRAC_PI_2 * ops::sin(time.elapsed_secs()));\n            }\n            -3 => {\n                transform.rotation =\n                    Quat::from_rotation_z(FRAC_PI_2 * ops::sin(time.elapsed_secs()));\n            }\n            -2 => {\n                transform.scale.x = ops::sin(time.elapsed_secs()) + 1.0;\n            }\n            -1 => {\n                transform.scale.y = ops::sin(time.elapsed_secs()) + 1.0;\n            }\n            0 => {\n                transform.translation.x = 0.5 * ops::sin(time.elapsed_secs());\n                transform.translation.y = ops::cos(time.elapsed_secs());\n            }\n            1 => {\n                transform.translation.y = ops::sin(time.elapsed_secs());\n                transform.translation.z = ops::cos(time.elapsed_secs());\n            }\n            2 => {\n                transform.translation.x = ops::sin(time.elapsed_secs());\n            }\n            3 => {\n                transform.translation.y = ops::sin(time.elapsed_secs());\n                transform.scale.x = ops::sin(time.elapsed_secs()) + 1.0;\n            }\n            _ => (),\n        }\n        // Show transform\n        let mut axis = *transform;\n        axis.translation.x += animated_joint.0 as f32 * 1.5;\n        gizmos.axes(axis, 1.0);\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "d0e72b3d2fae07df3091a4a865977ec315d01278",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/examples/animation/eased_motion.rs",
    "func": "//! Demonstrates the application of easing curves to animate a transition.\n\nuse std::f32::consts::FRAC_PI_2;\n\nuse bevy::{\n    animation::{animated_field, AnimationTarget, AnimationTargetId},\n    color::palettes::css::{ORANGE, SILVER},\n    math::vec3,\n    prelude::*,\n};\n\nfn main() {\n    App::new()\n        .add_plugins(DefaultPlugins)\n        .add_systems(Startup, setup)\n        .run();\n}\n\nfn setup(\n    mut commands: Commands,\n    mut meshes: ResMut<Assets<Mesh>>,\n    mut materials: ResMut<Assets<StandardMaterial>>,\n    mut animation_graphs: ResMut<Assets<AnimationGraph>>,\n    mut animation_clips: ResMut<Assets<AnimationClip>>,\n) {\n    // Create the animation:\n    let AnimationInfo {\n        target_name: animation_target_name,\n        target_id: animation_target_id,\n        graph: animation_graph,\n        node_index: animation_node_index,\n    } = AnimationInfo::create(&mut animation_graphs, &mut animation_clips);\n\n    // Build an animation player that automatically plays the animation.\n    let mut animation_player = AnimationPlayer::default();\n    animation_player.play(animation_node_index).repeat();\n\n    // A cube together with the components needed to animate it\n    let cube_entity = commands\n        .spawn((\n            Mesh3d(meshes.add(Cuboid::from_length(2.0))),\n            MeshMaterial3d(materials.add(Color::from(ORANGE))),\n            Transform::from_translation(vec3(-6., 2., 0.)),\n            animation_target_name,\n            animation_player,\n            AnimationGraphHandle(animation_graph),\n        ))\n        .id();\n\n    commands.entity(cube_entity).insert(AnimationTarget {\n        id: animation_target_id,\n        player: cube_entity,\n    });\n\n    // Some light to see something\n    commands.spawn((\n        PointLight {\n            shadows_enabled: true,\n            intensity: 10_000_000.,\n            range: 100.0,\n            ..default()\n        },\n        Transform::from_xyz(8., 16., 8.),\n    ));\n\n    // Ground plane\n    commands.spawn((\n        Mesh3d(meshes.add(Plane3d::default().mesh().size(50., 50.))),\n        MeshMaterial3d(materials.add(Color::from(SILVER))),\n    ));\n\n    // The camera\n    commands.spawn((\n        Camera3d::default(),\n        Transform::from_xyz(0., 6., 12.).looking_at(Vec3::new(0., 1.5, 0.), Vec3::Y),\n    ));\n}\n\n// Holds information about the animation we programmatically create.\nstruct AnimationInfo {\n    // The name of the animation target (in this case, the text).\n    target_name: Name,\n    // The ID of the animation target, derived from the name.\n    target_id: AnimationTargetId,\n    // The animation graph asset.\n    graph: Handle<AnimationGraph>,\n    // The index of the node within that graph.\n    node_index: AnimationNodeIndex,\n}\n\nimpl AnimationInfo {\n    // Programmatically creates the UI animation.\n    fn create(\n        animation_graphs: &mut Assets<AnimationGraph>,\n        animation_clips: &mut Assets<AnimationClip>,\n    ) -> AnimationInfo {\n        // Create an ID that identifies the text node we're going to animate.\n        let animation_target_name = Name::new(\"Cube\");\n        let animation_target_id = AnimationTargetId::from_name(&animation_target_name);\n\n        // Allocate an animation clip.\n        let mut animation_clip = AnimationClip::default();\n\n        // Each leg of the translation motion should take 3 seconds.\n        let animation_domain = interval(0.0, 3.0).unwrap();\n\n        // The easing curve is parametrized over [0, 1], so we reparametrize it and\n        // then ping-pong, which makes it spend another 3 seconds on the return journey.\n        let translation_curve = EasingCurve::new(\n            vec3(-6., 2., 0.),\n            vec3(6., 2., 0.),\n            EaseFunction::CubicInOut,\n        )\n        .reparametrize_linear(animation_domain)\n        .expect(\"this curve has bounded domain, so this should never fail\")\n        .ping_pong()\n        .expect(\"this curve has bounded domain, so this should never fail\");\n\n        // Something similar for rotation. The repetition here is an illusion caused\n        // by the symmetry of the cube; it rotates on the forward journey and never\n        // rotates back.\n        let rotation_curve = EasingCurve::new(\n            Quat::IDENTITY,\n            Quat::from_rotation_y(FRAC_PI_2),\n            EaseFunction::ElasticInOut,\n        )\n        .reparametrize_linear(interval(0.0, 4.0).unwrap())\n        .expect(\"this curve has bounded domain, so this should never fail\");\n\n        animation_clip.add_curve_to_target(\n            animation_target_id,\n            AnimatableCurve::new(animated_field!(Transform::translation), translation_curve),\n        );\n        animation_clip.add_curve_to_target(\n            animation_target_id,\n            AnimatableCurve::new(animated_field!(Transform::rotation), rotation_curve),\n        );\n\n        // Save our animation clip as an asset.\n        let animation_clip_handle = animation_clips.add(animation_clip);\n\n        // Create an animation graph with that clip.\n        let (animation_graph, animation_node_index) =\n            AnimationGraph::from_clip(animation_clip_handle);\n        let animation_graph_handle = animation_graphs.add(animation_graph);\n\n        AnimationInfo {\n            target_name: animation_target_name,\n            target_id: animation_target_id,\n            graph: animation_graph_handle,\n            node_index: animation_node_index,\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "985b9bd79f88e33db01c01f854870cada45c3e8d",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/examples/2d/sprite_flipping.rs",
    "func": "//! Displays a single [`Sprite`], created from an image, but flipped on one axis.\n\nuse bevy::prelude::*;\n\nfn main() {\n    App::new()\n        .add_plugins(DefaultPlugins)\n        .add_systems(Startup, setup)\n        .run();\n}\n\nfn setup(mut commands: Commands, asset_server: Res<AssetServer>) {\n    commands.spawn(Camera2d);\n    commands.spawn(Sprite {\n        image: asset_server.load(\"branding/bevy_bird_dark.png\"),\n        // Flip the logo to the left\n        flip_x: true,\n        // And don't flip it upside-down ( the default )\n        flip_y: false,\n        ..Default::default()\n    });\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "623962f6e1ab89e8170bb2a86fff1f2b6b4459dc",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/examples/window/window_resizing.rs",
    "func": "//! This example illustrates how to resize windows, and how to respond to a window being resized.\nuse bevy::{prelude::*, window::WindowResized};\n\nfn main() {\n    App::new()\n        .insert_resource(ResolutionSettings {\n            large: Vec2::new(1920.0, 1080.0),\n            medium: Vec2::new(800.0, 600.0),\n            small: Vec2::new(640.0, 360.0),\n        })\n        .add_plugins(DefaultPlugins)\n        .add_systems(Startup, (setup_camera, setup_ui))\n        .add_systems(Update, (on_resize_system, toggle_resolution))\n        .run();\n}\n\n/// Marker component for the text that displays the current resolution.\n#[derive(Component)]\nstruct ResolutionText;\n\n/// Stores the various window-resolutions we can select between.\n#[derive(Resource)]\nstruct ResolutionSettings {\n    large: Vec2,\n    medium: Vec2,\n    small: Vec2,\n}\n\n// Spawns the camera that draws UI\nfn setup_camera(mut commands: Commands) {\n    commands.spawn(Camera2d);\n}\n\n// Spawns the UI\nfn setup_ui(mut commands: Commands) {\n    // Node that fills entire background\n    commands\n        .spawn(Node {\n            width: Val::Percent(100.),\n            ..default()\n        })\n        // Text where we display current resolution\n        .with_child((\n            Text::new(\"Resolution\"),\n            TextFont {\n                font_size: 42.0,\n                ..default()\n            },\n            ResolutionText,\n        ));\n}\n\n/// This system shows how to request the window to a new resolution\nfn toggle_resolution(\n    keys: Res<ButtonInput<KeyCode>>,\n    mut window: Single<&mut Window>,\n    resolution: Res<ResolutionSettings>,\n) {\n    if keys.just_pressed(KeyCode::Digit1) {\n        let res = resolution.small;\n        window.resolution.set(res.x, res.y);\n    }\n    if keys.just_pressed(KeyCode::Digit2) {\n        let res = resolution.medium;\n        window.resolution.set(res.x, res.y);\n    }\n    if keys.just_pressed(KeyCode::Digit3) {\n        let res = resolution.large;\n        window.resolution.set(res.x, res.y);\n    }\n}\n\n/// This system shows how to respond to a window being resized.\n/// Whenever the window is resized, the text will update with the new resolution.\nfn on_resize_system(\n    mut text: Single<&mut Text, With<ResolutionText>>,\n    mut resize_reader: EventReader<WindowResized>,\n) {\n    for e in resize_reader.read() {\n        // When resolution is being changed\n        text.0 = format!(\"{:.1} x {:.1}\", e.width, e.height);\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "bcf6ac47314aa93c5a96266c612f0483638c1aed",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/examples/asset/asset_loading.rs",
    "func": "//! This example illustrates various ways to load assets.\n\nuse bevy::{asset::LoadedFolder, prelude::*};\n\nfn main() {\n    App::new()\n        .add_plugins(DefaultPlugins)\n        .add_systems(Startup, setup)\n        .run();\n}\n\nfn setup(\n    mut commands: Commands,\n    asset_server: Res<AssetServer>,\n    meshes: Res<Assets<Mesh>>,\n    mut materials: ResMut<Assets<StandardMaterial>>,\n) {\n    // By default AssetServer will load assets from inside the \"assets\" folder.\n    // For example, the next line will load GltfAssetLabel::Primitive{mesh:0,primitive:0}.from_asset(\"ROOT/assets/models/cube/cube.gltf\"),\n    // where \"ROOT\" is the directory of the Application.\n    //\n    // This can be overridden by setting [`AssetPlugin.file_path`].\n    let cube_handle = asset_server.load(\n        GltfAssetLabel::Primitive {\n            mesh: 0,\n            primitive: 0,\n        }\n        .from_asset(\"models/cube/cube.gltf\"),\n    );\n    let sphere_handle = asset_server.load(\n        GltfAssetLabel::Primitive {\n            mesh: 0,\n            primitive: 0,\n        }\n        .from_asset(\"models/sphere/sphere.gltf\"),\n    );\n\n    // All assets end up in their Assets<T> collection once they are done loading:\n    if let Some(sphere) = meshes.get(&sphere_handle) {\n        // You might notice that this doesn't run! This is because assets load in parallel without\n        // blocking. When an asset has loaded, it will appear in relevant Assets<T>\n        // collection.\n        info!(\"{:?}\", sphere.primitive_topology());\n    } else {\n        info!(\"sphere hasn't loaded yet\");\n    }\n\n    // You can load all assets in a folder like this. They will be loaded in parallel without\n    // blocking. The LoadedFolder asset holds handles to each asset in the folder. These are all\n    // dependencies of the LoadedFolder asset, meaning you can wait for the LoadedFolder asset to\n    // fire AssetEvent::LoadedWithDependencies if you want to wait for all assets in the folder\n    // to load.\n    // If you want to keep the assets in the folder alive, make sure you store the returned handle\n    // somewhere.\n    let _loaded_folder: Handle<LoadedFolder> = asset_server.load_folder(\"models/torus\");\n\n    // If you want a handle to a specific asset in a loaded folder, the easiest way to get one is to call load.\n    // It will _not_ be loaded a second time.\n    // The LoadedFolder asset will ultimately also hold handles to the assets, but waiting for it to load\n    // and finding the right handle is more work!\n    let torus_handle = asset_server.load(\n        GltfAssetLabel::Primitive {\n            mesh: 0,\n            primitive: 0,\n        }\n        .from_asset(\"models/torus/torus.gltf\"),\n    );\n\n    // You can also add assets directly to their Assets<T> storage:\n    let material_handle = materials.add(StandardMaterial {\n        base_color: Color::srgb(0.8, 0.7, 0.6),\n        ..default()\n    });\n\n    // torus\n    commands.spawn((\n        Mesh3d(torus_handle),\n        MeshMaterial3d(material_handle.clone()),\n        Transform::from_xyz(-3.0, 0.0, 0.0),\n    ));\n    // cube\n    commands.spawn((\n        Mesh3d(cube_handle),\n        MeshMaterial3d(material_handle.clone()),\n        Transform::from_xyz(0.0, 0.0, 0.0),\n    ));\n    // sphere\n    commands.spawn((\n        Mesh3d(sphere_handle),\n        MeshMaterial3d(material_handle),\n        Transform::from_xyz(3.0, 0.0, 0.0),\n    ));\n    // light\n    commands.spawn((PointLight::default(), Transform::from_xyz(4.0, 5.0, 4.0)));\n    // camera\n    commands.spawn((\n        Camera3d::default(),\n        Transform::from_xyz(0.0, 3.0, 10.0).looking_at(Vec3::ZERO, Vec3::Y),\n    ));\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "4e4997c4a2313c289f2b9c60f39cdd89699aa09b",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/examples/ui/overflow_debug.rs",
    "func": "//! Tests how different transforms behave when clipped with `Overflow::Hidden`\n\nuse bevy::{input::common_conditions::input_just_pressed, prelude::*, ui::widget::TextUiWriter};\nuse std::f32::consts::{FRAC_PI_2, PI, TAU};\n\nconst CONTAINER_SIZE: f32 = 150.0;\nconst HALF_CONTAINER_SIZE: f32 = CONTAINER_SIZE / 2.0;\nconst LOOP_LENGTH: f32 = 4.0;\n\nfn main() {\n    App::new()\n        .add_plugins(DefaultPlugins)\n        .init_resource::<AnimationState>()\n        .add_systems(Startup, setup)\n        .add_systems(\n            Update,\n            (\n                toggle_overflow.run_if(input_just_pressed(KeyCode::KeyO)),\n                next_container_size.run_if(input_just_pressed(KeyCode::KeyS)),\n                update_transform::<Move>,\n                update_transform::<Scale>,\n                update_transform::<Rotate>,\n                update_animation,\n            ),\n        )\n        .run();\n}\n\n#[derive(Component)]\nstruct Instructions;\n\n#[derive(Resource, Default)]\nstruct AnimationState {\n    playing: bool,\n    paused_at: f32,\n    paused_total: f32,\n    t: f32,\n}\n\n#[derive(Component)]\nstruct Container(u8);\n\ntrait UpdateTransform {\n    fn update(&self, t: f32, transform: &mut Transform);\n}\n\n#[derive(Component)]\nstruct Move;\n\nimpl UpdateTransform for Move {\n    fn update(&self, t: f32, transform: &mut Transform) {\n        transform.translation.x = ops::sin(t * TAU - FRAC_PI_2) * HALF_CONTAINER_SIZE;\n        transform.translation.y = -ops::cos(t * TAU - FRAC_PI_2) * HALF_CONTAINER_SIZE;\n    }\n}\n\n#[derive(Component)]\nstruct Scale;\n\nimpl UpdateTransform for Scale {\n    fn update(&self, t: f32, transform: &mut Transform) {\n        transform.scale.x = 1.0 + 0.5 * ops::cos(t * TAU).max(0.0);\n        transform.scale.y = 1.0 + 0.5 * ops::cos(t * TAU + PI).max(0.0);\n    }\n}\n\n#[derive(Component)]\nstruct Rotate;\n\nimpl UpdateTransform for Rotate {\n    fn update(&self, t: f32, transform: &mut Transform) {\n        transform.rotation =\n            Quat::from_axis_angle(Vec3::Z, (ops::cos(t * TAU) * 45.0).to_radians());\n    }\n}\n\nfn setup(mut commands: Commands, asset_server: Res<AssetServer>) {\n    // Camera\n\n    commands.spawn(Camera2d);\n\n    // Instructions\n\n    let text_font = TextFont::default();\n\n    commands\n        .spawn((\n            Text::new(\n                \"Next Overflow Setting (O)\\nNext Container Size (S)\\nToggle Animation (space)\\n\\n\",\n            ),\n            text_font.clone(),\n            Node {\n                position_type: PositionType::Absolute,\n                top: Val::Px(12.0),\n                left: Val::Px(12.0),\n                ..default()\n            },\n            Instructions,\n        ))\n        .with_child((\n            TextSpan::new(format!(\"{:?}\", Overflow::clip())),\n            text_font.clone(),\n        ));\n\n    // Overflow Debug\n\n    commands\n        .spawn(Node {\n            width: Val::Percent(100.),\n            height: Val::Percent(100.),\n            justify_content: JustifyContent::Center,\n            align_items: AlignItems::Center,\n            ..default()\n        })\n        .with_children(|parent| {\n            parent\n                .spawn(Node {\n                    display: Display::Grid,\n                    grid_template_columns: RepeatedGridTrack::px(3, CONTAINER_SIZE),\n                    grid_template_rows: RepeatedGridTrack::px(2, CONTAINER_SIZE),\n                    row_gap: Val::Px(80.),\n                    column_gap: Val::Px(80.),\n                    ..default()\n                })\n                .with_children(|parent| {\n                    spawn_image(parent, &asset_server, Move);\n                    spawn_image(parent, &asset_server, Scale);\n                    spawn_image(parent, &asset_server, Rotate);\n\n                    spawn_text(parent, &asset_server, Move);\n                    spawn_text(parent, &asset_server, Scale);\n                    spawn_text(parent, &asset_server, Rotate);\n                });\n        });\n}\n\nfn spawn_image(\n    parent: &mut ChildBuilder,\n    asset_server: &Res<AssetServer>,\n    update_transform: impl UpdateTransform + Component,\n) {\n    spawn_container(parent, update_transform, |parent| {\n        parent.spawn((\n            ImageNode::new(asset_server.load(\"branding/bevy_logo_dark_big.png\")),\n            Node {\n                height: Val::Px(100.),\n                position_type: PositionType::Absolute,\n                top: Val::Px(-50.),\n                left: Val::Px(-200.),\n                ..default()\n            },\n        ));\n    });\n}\n\nfn spawn_text(\n    parent: &mut ChildBuilder,\n    asset_server: &Res<AssetServer>,\n    update_transform: impl UpdateTransform + Component,\n) {\n    spawn_container(parent, update_transform, |parent| {\n        parent.spawn((\n            Text::new(\"Bevy\"),\n            TextFont {\n                font: asset_server.load(\"fonts/FiraSans-Bold.ttf\"),\n                font_size: 100.0,\n                ..default()\n            },\n        ));\n    });\n}\n\nfn spawn_container(\n    parent: &mut ChildBuilder,\n    update_transform: impl UpdateTransform + Component,\n    spawn_children: impl FnOnce(&mut ChildBuilder),\n) {\n    let mut transform = Transform::default();\n\n    update_transform.update(0.0, &mut transform);\n\n    parent\n        .spawn((\n            Node {\n                width: Val::Percent(100.),\n                height: Val::Percent(100.),\n                align_items: AlignItems::Center,\n                justify_content: JustifyContent::Center,\n                overflow: Overflow::clip(),\n                ..default()\n            },\n            BackgroundColor(Color::srgb(0.25, 0.25, 0.25)),\n            Container(0),\n        ))\n        .with_children(|parent| {\n            parent\n                .spawn((\n                    Node {\n                        align_items: AlignItems::Center,\n                        justify_content: JustifyContent::Center,\n                        top: Val::Px(transform.translation.x),\n                        left: Val::Px(transform.translation.y),\n                        ..default()\n                    },\n                    transform,\n                    update_transform,\n                ))\n                .with_children(spawn_children);\n        });\n}\n\nfn update_animation(\n    mut animation: ResMut<AnimationState>,\n    time: Res<Time>,\n    keys: Res<ButtonInput<KeyCode>>,\n) {\n    let delta = time.elapsed_secs();\n\n    if keys.just_pressed(KeyCode::Space) {\n        animation.playing = !animation.playing;\n\n        if !animation.playing {\n            animation.paused_at = delta;\n        } else {\n            animation.paused_total += delta - animation.paused_at;\n        }\n    }\n\n    if animation.playing {\n        animation.t = (delta - animation.paused_total) % LOOP_LENGTH / LOOP_LENGTH;\n    }\n}\n\nfn update_transform<T: UpdateTransform + Component>(\n    animation: Res<AnimationState>,\n    mut containers: Query<(&mut Transform, &mut Node, &ComputedNode, &T)>,\n) {\n    for (mut transform, mut node, computed_node, update_transform) in &mut containers {\n        update_transform.update(animation.t, &mut transform);\n\n        node.left = Val::Px(transform.translation.x * computed_node.inverse_scale_factor());\n        node.top = Val::Px(transform.translation.y * computed_node.inverse_scale_factor());\n    }\n}\n\nfn toggle_overflow(\n    mut containers: Query<&mut Node, With<Container>>,\n    instructions: Single<Entity, With<Instructions>>,\n    mut writer: TextUiWriter,\n) {\n    for mut node in &mut containers {\n        node.overflow = match node.overflow {\n            Overflow {\n                x: OverflowAxis::Visible,\n                y: OverflowAxis::Visible,\n            } => Overflow::clip_y(),\n            Overflow {\n                x: OverflowAxis::Visible,\n                y: OverflowAxis::Clip,\n            } => Overflow::clip_x(),\n            Overflow {\n                x: OverflowAxis::Clip,\n                y: OverflowAxis::Visible,\n            } => Overflow::clip(),\n            _ => Overflow::visible(),\n        };\n\n        let entity = *instructions;\n        *writer.text(entity, 1) = format!(\"{:?}\", node.overflow);\n    }\n}\n\nfn next_container_size(mut containers: Query<(&mut Node, &mut Container)>) {\n    for (mut node, mut container) in &mut containers {\n        container.0 = (container.0 + 1) % 3;\n\n        node.width = match container.0 {\n            2 => Val::Percent(30.),\n            _ => Val::Percent(100.),\n        };\n        node.height = match container.0 {\n            1 => Val::Percent(30.),\n            _ => Val::Percent(100.),\n        };\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "05ec7199b085cdd70cf040862cc7c958774fb1cc",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/examples/diagnostics/enabling_disabling_diagnostic.rs",
    "func": "//! Shows how to disable/re-enable a Diagnostic during runtime\n\nuse std::time::Duration;\n\nuse bevy::{\n    diagnostic::{DiagnosticsStore, FrameTimeDiagnosticsPlugin, LogDiagnosticsPlugin},\n    prelude::*,\n    time::common_conditions::on_timer,\n};\n\nfn main() {\n    App::new()\n        .add_plugins((\n            DefaultPlugins,\n            FrameTimeDiagnosticsPlugin,\n            LogDiagnosticsPlugin::default(),\n        ))\n        .add_systems(\n            Update,\n            toggle.run_if(on_timer(Duration::from_secs_f32(10.0))),\n        )\n        .run();\n}\n\nfn toggle(mut store: ResMut<DiagnosticsStore>) {\n    for diag in store.iter_mut() {\n        info!(\"toggling diagnostic {}\", diag.path());\n        diag.is_enabled = !diag.is_enabled;\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "a441418a50ff70f679c1585c4cb1f616c36dc533",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/examples/app/headless.rs",
    "func": "//! This example shows how to configure the `ScheduleRunnerPlugin` to run your\n//! application without windowing. You can completely remove rendering / windowing\n//! Plugin code from bevy by making your import look like this in your Cargo.toml.\n//!\n//! ```toml\n//! [dependencies]\n//! bevy = { version = \"*\", default-features = false }\n//! # replace \"*\" with the most recent version of bevy\n//! ```\n//!\n//! And then enabling the features you need.\n//! See the full list: <https://docs.rs/bevy/latest/bevy/#cargo-features>\nuse bevy::{app::ScheduleRunnerPlugin, log::LogPlugin, prelude::*, utils::Duration};\n\nfn main() {\n    if cfg!(feature = \"bevy_window\") {\n        println!(\"This example is running with the bevy_window feature enabled and will not run headless.\");\n        println!(\"Disable the default features and rerun the example to run headless.\");\n        println!(\"To do so, run:\");\n        println!();\n        println!(\"    cargo run --example headless --no-default-features\");\n        return;\n    }\n\n    // This app runs once\n    App::new()\n        .add_plugins(DefaultPlugins.set(ScheduleRunnerPlugin::run_once()))\n        .add_systems(Update, hello_world_system)\n        .run();\n\n    // This app loops forever at 60 fps\n    App::new()\n        .add_plugins(\n            DefaultPlugins\n                .set(ScheduleRunnerPlugin::run_loop(Duration::from_secs_f64(\n                    1.0 / 60.0,\n                )))\n                // The log and ctrl+c plugin can only be registered once globally,\n                // which means we need to disable it here, because it was already registered with the\n                // app that runs once.\n                .disable::<LogPlugin>(),\n        )\n        .add_systems(Update, counter)\n        .run();\n}\n\nfn hello_world_system() {\n    println!(\"hello world\");\n}\n\nfn counter(mut state: Local<CounterState>) {\n    if state.count % 60 == 0 {\n        println!(\"{}\", state.count);\n    }\n    state.count += 1;\n}\n\n#[derive(Default)]\nstruct CounterState {\n    count: u32,\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "16107fab65bac678dbbb33c5972dfdcc3ccdd0ed",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/diesel_dynamic_schema/tests/connection_setup.rs",
    "func": "#[cfg(feature = \"postgres\")]\npub fn create_user_table(conn: &mut diesel::PgConnection) {\n    use diesel::*;\n\n    diesel::sql_query(\"CREATE TABLE IF NOT EXISTS users (id Serial PRIMARY KEY, name TEXT NOT NULL DEFAULT '', hair_color TEXT)\")\n        .execute(conn)\n        .unwrap();\n}\n\n#[cfg(feature = \"sqlite\")]\npub fn create_user_table(conn: &mut diesel::SqliteConnection) {\n    use diesel::*;\n\n    diesel::sql_query(\"CREATE TABLE IF NOT EXISTS users (id INTEGER PRIMARY KEY AUTOINCREMENT, name TEXT NOT NULL DEFAULT '', hair_color TEXT)\")\n        .execute(conn)\n        .unwrap();\n}\n\n#[cfg(feature = \"mysql\")]\npub fn create_user_table(conn: &mut diesel::MysqlConnection) {\n    use diesel::*;\n\n    diesel::sql_query(\"CREATE TEMPORARY TABLE users (id INTEGER PRIMARY KEY AUTO_INCREMENT, name TEXT NOT NULL, hair_color TEXT)\")\n        .execute(conn)\n        .unwrap();\n}\n\n#[cfg(feature = \"sqlite\")]\npub fn establish_connection() -> diesel::SqliteConnection {\n    use diesel::*;\n\n    SqliteConnection::establish(\":memory:\").unwrap()\n}\n\n#[cfg(feature = \"postgres\")]\npub fn establish_connection() -> diesel::PgConnection {\n    use diesel::*;\n\n    let mut conn = PgConnection::establish(\n        &dotenvy::var(\"DATABASE_URL\")\n            .or_else(|_| dotenvy::var(\"PG_DATABASE_URL\"))\n            .expect(\"Set either `DATABASE_URL` or `PG_DATABASE_URL`\"),\n    )\n    .unwrap();\n\n    conn.begin_test_transaction().unwrap();\n    conn\n}\n\n#[cfg(feature = \"mysql\")]\npub fn establish_connection() -> diesel::MysqlConnection {\n    use diesel::*;\n\n    let mut conn = MysqlConnection::establish(\n        &dotenvy::var(\"DATABASE_URL\")\n            .or_else(|_| dotenvy::var(\"MYSQL_DATABASE_URL\"))\n            .expect(\"Set either `DATABASE_URL` or `MYSQL_DATABASE_URL`\"),\n    )\n    .unwrap();\n\n    conn.begin_test_transaction().unwrap();\n\n    conn\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "bbecf21a619c5e857b953f4d35ab589b949af2ca",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/diesel_dynamic_schema/tests/lib.rs",
    "func": "extern crate diesel;\nextern crate diesel_dynamic_schema;\n\nuse diesel::sql_types::*;\nuse diesel::*;\nuse diesel_dynamic_schema::{schema, table};\n\nmod dynamic_values;\n\nmod connection_setup;\n\nuse connection_setup::{create_user_table, establish_connection};\n\n#[cfg(feature = \"postgres\")]\ntype Backend = diesel::pg::Pg;\n#[cfg(feature = \"mysql\")]\ntype Backend = diesel::mysql::Mysql;\n#[cfg(feature = \"sqlite\")]\ntype Backend = diesel::sqlite::Sqlite;\n\n#[test]\nfn querying_basic_schemas() {\n    let conn = &mut establish_connection();\n    create_user_table(conn);\n    sql_query(\"INSERT INTO users(name) VALUES ('Sean')\")\n        .execute(conn)\n        .unwrap();\n\n    let users = table(\"users\");\n    let name = users.column::<Text, _>(\"name\");\n    let names = users.select(name).load::<String>(conn);\n    assert_eq!(Ok(vec![\"Sean\".into()]), names);\n}\n\n#[test]\nfn querying_multiple_types() {\n    let conn = &mut establish_connection();\n    create_user_table(conn);\n    sql_query(\"INSERT INTO users (name) VALUES ('Sean'), ('Tess')\")\n        .execute(conn)\n        .unwrap();\n\n    let users = table(\"users\");\n    let hair_color = users.column::<Nullable<Text>, _>(\"hair_color\");\n    let name = users.column::<Text, _>(\"name\");\n    let users = users\n        .select((name, hair_color))\n        .load::<(String, Option<String>)>(conn);\n    assert_eq!(\n        Ok(vec![(\"Sean\".into(), None), (\"Tess\".into(), None)]),\n        users\n    );\n}\n\n#[test]\nfn columns_used_in_where_clause() {\n    let conn = &mut establish_connection();\n    create_user_table(conn);\n    sql_query(\"INSERT INTO users (name) VALUES ('Sean'), ('Tess')\")\n        .execute(conn)\n        .unwrap();\n\n    let users = table(\"users\");\n    let name = users.column::<Text, _>(\"name\");\n    let users = users\n        .select(name)\n        .filter(name.eq(\"Sean\"))\n        .load::<String>(conn);\n\n    assert_eq!(Ok(vec![\"Sean\".into()]), users);\n}\n\n#[test]\nfn providing_custom_schema_name() {\n    let table = schema(\"information_schema\").table(\"users\");\n    let sql = debug_query::<Backend, _>(&table);\n\n    #[cfg(feature = \"postgres\")]\n    assert_eq!(\n        r#\"\"information_schema\".\"users\" -- binds: []\"#,\n        sql.to_string()\n    );\n\n    #[cfg(not(feature = \"postgres\"))]\n    assert_eq!(\"`information_schema`.`users` -- binds: []\", sql.to_string());\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "fa5bb28ea093aa45761afbb5182bcf344f00559b",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/xtask/src/main.rs",
    "func": "use std::fmt::Display;\n\nuse clap::{Parser, ValueEnum};\n\nmod clippy;\nmod tests;\nmod tidy;\nmod utils;\n\n#[derive(Debug, Parser)]\nenum Commands {\n    /// Run all tests for diesel\n    ///\n    /// Requires `cargo-nextest` to be installed\n    RunTests(tests::TestArgs),\n    /// Run clippy on all crates\n    Clippy(clippy::ClippyArgs),\n    /// Perform a set of preliminary checks\n    ///\n    /// This command will execute `cargo fmt --check` to verify that\n    /// the code is formatted, `typos` to check for spelling errors\n    /// and it will execute `xtask clippy` to verify that the code\n    /// compiles without warning\n    Tidy(tidy::TidyArgs),\n}\n\nimpl Commands {\n    fn run(self) {\n        match self {\n            Commands::RunTests(test_args) => test_args.run(),\n            Commands::Clippy(clippy) => clippy.run(),\n            Commands::Tidy(tidy) => tidy.run(),\n        }\n    }\n}\n\n#[derive(Debug, Clone, Copy, ValueEnum)]\nenum Backend {\n    Postgres,\n    Sqlite,\n    Mysql,\n    All,\n}\n\nimpl Backend {\n    const ALL: &'static [Self] = &[Backend::Postgres, Backend::Sqlite, Backend::Mysql];\n}\n\nimpl Display for Backend {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            Backend::Postgres => write!(f, \"postgres\"),\n            Backend::Sqlite => write!(f, \"sqlite\"),\n            Backend::Mysql => write!(f, \"mysql\"),\n            Backend::All => write!(f, \"all\"),\n        }\n    }\n}\n\nfn main() {\n    dotenvy::dotenv().ok();\n    Commands::parse().run();\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "fefb6e2fee43ce12061fd9fcd130e50fc8d4727e",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/dsl_auto_type/src/auto_type/case.rs",
    "func": "use {heck::*, proc_macro2::Span, syn::Ident};\n\n#[derive(Clone, Copy, PartialEq, Eq)]\npub enum Case {\n    DoNotChange,\n    UpperCamel,\n    Pascal,\n    LowerCamel,\n    Snake,\n    ShoutySnake,\n}\n\nimpl Case {\n    pub(crate) fn ident_with_case(self, ident: &Ident) -> syn::Ident {\n        let s = ident.to_string();\n        let cased_s: String = match self {\n            Case::DoNotChange => s,\n            Case::UpperCamel => s.to_upper_camel_case(),\n            Case::Pascal => s.to_pascal_case(),\n            Case::LowerCamel => s.to_lower_camel_case(),\n            Case::Snake => s.to_snake_case(),\n            Case::ShoutySnake => s.to_shouty_snake_case(),\n        };\n        Ident::new(&cased_s, ident.span())\n    }\n}\n\nimpl Case {\n    pub(crate) fn from_str(s: &str, span: Span) -> Result<Self, syn::Error> {\n        Ok(match s {\n            \"dO_nOt_cHaNgE_cAsE\" => Case::DoNotChange,\n            \"UpperCamelCase\" => Case::UpperCamel,\n            \"PascalCase\" => Case::Pascal,\n            \"lowerCamelCase\" => Case::LowerCamel,\n            \"snake_case\" => Case::Snake,\n            \"SHOUTY_SNAKE_CASE\" => Case::ShoutySnake,\n            other => {\n                return Err(syn::Error::new(\n                    span,\n                    format_args!(\n                        \"Unknown case: {other}, expected one of: \\\n                            `PascalCase`, `snake_case`, `UpperCamelCase`, `lowerCamelCase`, \\\n                            `SHOUTY_SNAKE_CASE`, `dO_nOt_cHaNgE_cAsE`\"\n                    ),\n                ))\n            }\n        })\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "76400ba6ff58aee6aad73148b544b601d999b374",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/diesel_derives/tests/multiconnection.rs",
    "func": "use crate::schema::users;\nuse diesel::connection::Instrumentation;\nuse diesel::prelude::*;\n\n#[derive(diesel::MultiConnection)]\npub enum InferConnection {\n    #[cfg(feature = \"postgres\")]\n    Pg(PgConnection),\n    #[cfg(feature = \"sqlite\")]\n    Sqlite(SqliteConnection),\n    #[cfg(feature = \"mysql\")]\n    Mysql(MysqlConnection),\n}\n\n#[derive(Queryable, Selectable, Insertable, AsChangeset)]\npub struct User {\n    pub id: i32,\n    pub name: String,\n}\n\n#[test]\nfn check_queries_work() {\n    let mut conn = establish_connection();\n\n    // checks that this trait is implemented\n    conn.set_instrumentation(None::<Box<dyn Instrumentation>>);\n    let _ = conn.instrumentation();\n\n    diesel::sql_query(\n        \"CREATE TEMPORARY TABLE users(\\\n         id INTEGER NOT NULL PRIMARY KEY, \\\n         name TEXT NOT NULL)\",\n    )\n    .execute(&mut conn)\n    .unwrap();\n\n    conn.begin_test_transaction().unwrap();\n\n    // these are mostly compile pass tests\n\n    // simple query\n    let _ = users::table\n        .select((users::id, users::name))\n        .load::<User>(&mut conn)\n        .unwrap();\n\n    // with bind\n    let _ = users::table\n        .select((users::id, users::name))\n        .find(42)\n        .load::<User>(&mut conn)\n        .unwrap();\n\n    // simple boxed query\n    let _ = users::table\n        .into_boxed()\n        .select((users::id, users::name))\n        .load::<User>(&mut conn)\n        .unwrap();\n\n    // with bind\n    let _ = users::table\n        .into_boxed()\n        .select((users::id, users::name))\n        .filter(users::id.eq(42))\n        .load::<User>(&mut conn)\n        .unwrap();\n\n    // as_select\n    let _ = users::table\n        .select(User::as_select())\n        .load(&mut conn)\n        .unwrap();\n\n    // boxable expression\n    let b = Box::new(users::name.eq(\"John\"))\n        as Box<\n            dyn BoxableExpression<\n                users::table,\n                self::multi_connection_impl::MultiBackend,\n                SqlType = _,\n            >,\n        >;\n\n    let _ = users::table\n        .filter(b)\n        .select(users::id)\n        .load::<i32>(&mut conn)\n        .unwrap();\n\n    // insert\n    diesel::insert_into(users::table)\n        .values((users::id.eq(42), users::name.eq(\"John\")))\n        .execute(&mut conn)\n        .unwrap();\n    diesel::insert_into(users::table)\n        .values(User {\n            id: 43,\n            name: \"Jane\".into(),\n        })\n        .execute(&mut conn)\n        .unwrap();\n    // update\n    diesel::update(users::table)\n        .set(users::name.eq(\"John\"))\n        .execute(&mut conn)\n        .unwrap();\n    diesel::update(users::table.find(42))\n        .set(User {\n            id: 42,\n            name: \"Jane\".into(),\n        })\n        .execute(&mut conn)\n        .unwrap();\n\n    // delete\n    diesel::delete(users::table).execute(&mut conn).unwrap();\n}\n\nfn establish_connection() -> InferConnection {\n    let database_url = if cfg!(feature = \"mysql\") {\n        dotenvy::var(\"MYSQL_UNIT_TEST_DATABASE_URL\").or_else(|_| dotenvy::var(\"DATABASE_URL\"))\n    } else if cfg!(feature = \"postgres\") {\n        dotenvy::var(\"PG_DATABASE_URL\").or_else(|_| dotenvy::var(\"DATABASE_URL\"))\n    } else {\n        Ok(dotenvy::var(\"DATABASE_URL\").unwrap_or_else(|_| \":memory:\".to_owned()))\n    };\n    let database_url = database_url.expect(\"DATABASE_URL must be set in order to run tests\");\n\n    InferConnection::establish(&database_url).unwrap()\n}\n\n#[cfg(all(feature = \"chrono\", feature = \"time\"))]\nfn make_test_table(conn: &mut InferConnection) {\n    match conn {\n        #[cfg(feature = \"postgres\")]\n        InferConnection::Pg(ref mut conn) => {\n            diesel::sql_query(\n                \"CREATE TEMPORARY TABLE type_test( \\\n                     small_int SMALLINT,\\\n                     integer INTEGER,\\\n                     big_int BIGINT,\\\n                     float FLOAT4,\\\n                     double FLOAT8,\\\n                     string TEXT,\\\n                     blob BYTEA,\\\n                     timestamp1 TIMESTAMP,\\\n                     date1 DATE,\\\n                     time1 TIME,\\\n                     timestamp2 TIMESTAMP,\\\n                     date2 DATE,\\\n                     time2 TIME\n                 )\",\n            )\n            .execute(conn)\n            .unwrap();\n        }\n        #[cfg(feature = \"sqlite\")]\n        InferConnection::Sqlite(ref mut conn) => {\n            diesel::sql_query(\n                \"CREATE TEMPORARY TABLE type_test( \\\n                     small_int SMALLINT,\\\n                     integer INTEGER,\\\n                     big_int BIGINT,\\\n                     float FLOAT4,\\\n                     double FLOAT8,\\\n                     string TEXT,\\\n                     blob BLOB,\\\n                     timestamp1 TIMESTAMP,\\\n                     date1 DATE,\\\n                     time1 TIME,\\\n                     timestamp2 TIMESTAMP,\\\n                     date2 DATE,\\\n                     time2 TIME\n                 )\",\n            )\n            .execute(conn)\n            .unwrap();\n        }\n        #[cfg(feature = \"mysql\")]\n        InferConnection::Mysql(ref mut conn) => {\n            diesel::sql_query(\n                \"CREATE TEMPORARY TABLE type_test( \\\n                     `small_int` SMALLINT,\\\n                     `integer` INT,\\\n                     `big_int` BIGINT,\\\n                     `float` FLOAT,\\\n                     `double` DOUBLE,\\\n                     `string` TEXT,\\\n                     `blob` BLOB,\\\n                     `timestamp1` DATETIME,\n                     `date1` DATE,\\\n                     `time1` TIME,\\\n                     `timestamp2` DATETIME,\n                     `date2` DATE,\\\n                     `time2` TIME\n                 )\",\n            )\n            .execute(conn)\n            .unwrap();\n        }\n    }\n}\n\n#[cfg(all(feature = \"chrono\", feature = \"time\"))]\n#[test]\nfn type_checks() {\n    use diesel::internal::derives::multiconnection::{chrono, time};\n\n    table! {\n        type_test(integer) {\n            small_int -> SmallInt,\n            integer -> Integer,\n            big_int -> BigInt,\n            float -> Float,\n            double -> Double,\n            string -> Text,\n            blob -> Blob,\n            timestamp1 -> Timestamp,\n            time1 -> Time,\n            date1 -> Date,\n            timestamp2 -> Timestamp,\n            time2 -> Time,\n            date2 -> Date,\n        }\n    }\n\n    let mut conn = establish_connection();\n    make_test_table(&mut conn);\n    conn.begin_test_transaction().unwrap();\n    let small_int = 1_i16;\n    let integer = 2_i32;\n    let big_int = 3_i64;\n    let float = 4.0_f32;\n    let double = 5.0_f64;\n    let string = String::from(\"bar\");\n    let blob = vec![1_u8, 2, 3, 4];\n    let date1 = chrono::NaiveDate::from_ymd_opt(2023, 08, 17).unwrap();\n    let time1 = chrono::NaiveTime::from_hms_opt(07, 50, 12).unwrap();\n    let timestamp1 = chrono::NaiveDateTime::new(date1, time1);\n    let time2 = time::Time::from_hms(12, 22, 23).unwrap();\n    let date2 = time::Date::from_calendar_date(2023, time::Month::August, 26).unwrap();\n    let timestamp2 = time::PrimitiveDateTime::new(date2, time2);\n\n    diesel::insert_into(type_test::table)\n        .values((\n            type_test::small_int.eq(small_int),\n            type_test::integer.eq(integer),\n            type_test::big_int.eq(big_int),\n            type_test::float.eq(float),\n            type_test::double.eq(double),\n            type_test::string.eq(&string),\n            type_test::blob.eq(&blob),\n            type_test::timestamp1.eq(timestamp1),\n            type_test::time1.eq(time1),\n            type_test::date1.eq(date1),\n            type_test::timestamp2.eq(timestamp2),\n            type_test::time2.eq(time2),\n            type_test::date2.eq(date2),\n        ))\n        .execute(&mut conn)\n        .unwrap();\n\n    let result = type_test::table\n        .get_result::<(\n            i16,                     //0\n            i32,                     //1\n            i64,                     //2\n            f32,                     //3\n            f64,                     //4\n            String,                  //5\n            Vec<u8>,                 //6\n            chrono::NaiveDateTime,   //7\n            chrono::NaiveTime,       //8\n            chrono::NaiveDate,       //9\n            time::PrimitiveDateTime, //10\n            time::Time,              //11\n            time::Date,              //12\n        )>(&mut conn)\n        .unwrap();\n\n    assert_eq!(small_int, result.0);\n    assert_eq!(integer, result.1);\n    assert_eq!(big_int, result.2);\n    assert_eq!(float, result.3);\n    assert_eq!(double, result.4);\n    assert_eq!(string, result.5);\n    assert_eq!(blob, result.6);\n    assert_eq!(timestamp1, result.7);\n    assert_eq!(time1, result.8);\n    assert_eq!(date1, result.9);\n    assert_eq!(timestamp2, result.10);\n    assert_eq!(time2, result.11);\n    assert_eq!(date2, result.12);\n}\n\n#[cfg(all(feature = \"chrono\", feature = \"time\"))]\n#[test]\nfn nullable_type_checks() {\n    use diesel::internal::derives::multiconnection::{chrono, time};\n\n    table! {\n        type_test(integer) {\n            small_int -> Nullable<SmallInt>,\n            integer -> Nullable<Integer>,\n            big_int -> Nullable<BigInt>,\n            float -> Nullable<Float>,\n            double -> Nullable<Double>,\n            string -> Nullable<Text>,\n            blob -> Nullable<Blob>,\n            timestamp1 -> Nullable<Timestamp>,\n            time1 -> Nullable<Time>,\n            date1 -> Nullable<Date>,\n            timestamp2 -> Nullable<Timestamp>,\n            time2 -> Nullable<Time>,\n            date2 -> Nullable<Date>,\n        }\n    }\n\n    let mut conn = establish_connection();\n    make_test_table(&mut conn);\n    conn.begin_test_transaction().unwrap();\n\n    let small_int = Some(1_i16);\n    let integer = Some(2_i32);\n    let big_int = Some(3_i64);\n    let float = Some(4.0_f32);\n    let double = Some(5.0_f64);\n    let string = Some(String::from(\"bar\"));\n    let blob = Some(vec![1_u8, 2, 3, 4]);\n    let date1 = Some(chrono::NaiveDate::from_ymd_opt(2023, 08, 17).unwrap());\n    let time1 = Some(chrono::NaiveTime::from_hms_opt(07, 50, 12).unwrap());\n    let timestamp1 = Some(chrono::NaiveDateTime::new(date1.unwrap(), time1.unwrap()));\n    let time2 = Some(time::Time::from_hms(12, 22, 23).unwrap());\n    let date2 = Some(time::Date::from_calendar_date(2023, time::Month::August, 26).unwrap());\n    let timestamp2 = Some(time::PrimitiveDateTime::new(date2.unwrap(), time2.unwrap()));\n\n    diesel::insert_into(type_test::table)\n        .values((\n            type_test::small_int.eq(small_int),\n            type_test::integer.eq(integer),\n            type_test::big_int.eq(big_int),\n            type_test::float.eq(float),\n            type_test::double.eq(double),\n            type_test::string.eq(&string),\n            type_test::blob.eq(&blob),\n            type_test::timestamp1.eq(timestamp1),\n            type_test::time1.eq(time1),\n            type_test::date1.eq(date1),\n            type_test::timestamp2.eq(timestamp2),\n            type_test::time2.eq(time2),\n            type_test::date2.eq(date2),\n        ))\n        .execute(&mut conn)\n        .unwrap();\n\n    let result = type_test::table\n        .get_result::<(\n            Option<i16>,\n            Option<i32>,\n            Option<i64>,\n            Option<f32>,\n            Option<f64>,\n            Option<String>,\n            Option<Vec<u8>>,\n            Option<chrono::NaiveDateTime>,\n            Option<chrono::NaiveTime>,\n            Option<chrono::NaiveDate>,\n            Option<time::PrimitiveDateTime>,\n            Option<time::Time>,\n            Option<time::Date>,\n        )>(&mut conn)\n        .unwrap();\n\n    assert_eq!(small_int, result.0);\n    assert_eq!(integer, result.1);\n    assert_eq!(big_int, result.2);\n    assert_eq!(float, result.3);\n    assert_eq!(double, result.4);\n    assert_eq!(string, result.5);\n    assert_eq!(blob, result.6);\n    assert_eq!(timestamp1, result.7);\n    assert_eq!(time1, result.8);\n    assert_eq!(date1, result.9);\n    assert_eq!(timestamp2, result.10);\n    assert_eq!(time2, result.11);\n    assert_eq!(date2, result.12);\n\n    diesel::delete(type_test::table).execute(&mut conn).unwrap();\n\n    diesel::insert_into(type_test::table)\n        .values((\n            type_test::small_int.eq(None::<i16>),\n            type_test::integer.eq(None::<i32>),\n            type_test::big_int.eq(None::<i64>),\n            type_test::float.eq(None::<f32>),\n            type_test::double.eq(None::<f64>),\n            type_test::string.eq(None::<String>),\n            type_test::blob.eq(None::<Vec<u8>>),\n            type_test::timestamp1.eq(None::<chrono::NaiveDateTime>),\n            type_test::time1.eq(None::<chrono::NaiveTime>),\n            type_test::date1.eq(None::<chrono::NaiveDate>),\n            type_test::timestamp2.eq(None::<time::PrimitiveDateTime>),\n            type_test::time2.eq(None::<time::Time>),\n            type_test::date2.eq(None::<time::Date>),\n        ))\n        .execute(&mut conn)\n        .unwrap();\n    let result = type_test::table\n        .get_result::<(\n            Option<i16>,\n            Option<i32>,\n            Option<i64>,\n            Option<f32>,\n            Option<f64>,\n            Option<String>,\n            Option<Vec<u8>>,\n            Option<chrono::NaiveDateTime>,\n            Option<chrono::NaiveTime>,\n            Option<chrono::NaiveDate>,\n            Option<time::PrimitiveDateTime>,\n            Option<time::Time>,\n            Option<time::Date>,\n        )>(&mut conn)\n        .unwrap();\n    assert!(result.0.is_none());\n    assert!(result.1.is_none());\n    assert!(result.2.is_none());\n    assert!(result.3.is_none());\n    assert!(result.4.is_none());\n    assert!(result.5.is_none());\n    assert!(result.6.is_none());\n    assert!(result.7.is_none());\n    assert!(result.8.is_none());\n    assert!(result.9.is_none());\n    assert!(result.10.is_none());\n    assert!(result.11.is_none());\n    assert!(result.12.is_none());\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "49c9dd416a43b98f171706396641add477490ec5",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/diesel_derives/src/parsers/postgres_type.rs",
    "func": "use syn::parse::{Parse, ParseStream, Result};\nuse syn::punctuated::Punctuated;\nuse syn::token::Comma;\nuse syn::{Ident, LitInt, LitStr};\n\nuse crate::util::{parse_eq, unknown_attribute, POSTGRES_TYPE_NOTE, POSTGRES_TYPE_NOTE_ID};\n\nenum Attr {\n    Oid(Ident, LitInt),\n    ArrayOid(Ident, LitInt),\n    Name(Ident, LitStr),\n    Schema(Ident, LitStr),\n}\n\nimpl Parse for Attr {\n    fn parse(input: ParseStream) -> Result<Self> {\n        let name: Ident = input.parse()?;\n        let name_str = name.to_string();\n\n        match &*name_str {\n            \"oid\" => Ok(Attr::Oid(name, parse_eq(input, POSTGRES_TYPE_NOTE_ID)?)),\n            \"array_oid\" => Ok(Attr::ArrayOid(\n                name,\n                parse_eq(input, POSTGRES_TYPE_NOTE_ID)?,\n            )),\n            \"name\" => Ok(Attr::Name(name, parse_eq(input, POSTGRES_TYPE_NOTE)?)),\n            \"schema\" => Ok(Attr::Schema(name, parse_eq(input, POSTGRES_TYPE_NOTE)?)),\n\n            _ => Err(unknown_attribute(\n                &name,\n                &[\"oid\", \"array_oid\", \"name\", \"schema\"],\n            )),\n        }\n    }\n}\n\npub enum PostgresType {\n    Fixed(LitInt, LitInt),\n    Lookup(LitStr, Option<LitStr>),\n}\n\nimpl Parse for PostgresType {\n    fn parse(input: ParseStream) -> Result<Self> {\n        let mut oid = None;\n        let mut array_oid = None;\n        let mut name = None;\n        let mut schema = None;\n\n        for attr in Punctuated::<Attr, Comma>::parse_terminated(input)? {\n            match attr {\n                Attr::Oid(ident, value) => oid = Some((ident, value)),\n                Attr::ArrayOid(ident, value) => array_oid = Some((ident, value)),\n                Attr::Name(ident, value) => name = Some((ident, value)),\n                Attr::Schema(ident, value) => schema = Some((ident, value)),\n            }\n        }\n\n        Self::validate_and_build(input, oid, array_oid, name, schema)\n    }\n}\n\nimpl PostgresType {\n    pub fn validate_and_build(\n        input: ParseStream,\n        oid: Option<(Ident, LitInt)>,\n        array_oid: Option<(Ident, LitInt)>,\n        name: Option<(Ident, LitStr)>,\n        schema: Option<(Ident, LitStr)>,\n    ) -> Result<Self> {\n        let help = format!(\n            \"The correct format looks like either `#[diesel({POSTGRES_TYPE_NOTE})]` or `#[diesel({POSTGRES_TYPE_NOTE_ID})]`\"\n        );\n\n        if let Some((_, name)) = name {\n            if let Some((oid, _)) = oid {\n                Err(syn::Error::new(\n                    oid.span(),\n                    format!(\"unexpected `oid` when `name` is present\\nhelp: {help}\"),\n                ))\n            } else if let Some((array_oid, _)) = array_oid {\n                Err(syn::Error::new(\n                    array_oid.span(),\n                    format!(\"unexpected `array_oid` when `name` is present\\nhelp: {help}\"),\n                ))\n            } else {\n                Ok(PostgresType::Lookup(name, schema.map(|s| s.1)))\n            }\n        } else if let Some((schema, lit)) = schema {\n            Err(syn::Error::new(\n                schema.span(),\n                format!(\n                    \"expected `name` to be also present\\n\\\n                     help: make sure `name` is present, `#[diesel(postgres_type(name = \\\"...\\\", schema = \\\"{}\\\"))]`\", lit.value()\n                ),\n            ))\n        } else if let (Some((_, oid)), Some((_, array_oid))) = (oid, array_oid) {\n            Ok(PostgresType::Fixed(oid, array_oid))\n        } else {\n            Err(syn::Error::new(\n                input.span(),\n                format!(\n                    \"expected `oid` and `array_oid` attribute or `name` attribute\\nhelp: {help}\"\n                ),\n            ))\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "41d0bbf84849bfba626740cbd78e2fba926daad3",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/diesel_cli/tests/database_url_errors.rs",
    "func": "#[allow(unused_imports)]\nuse crate::support::{database, project};\n\n#[test]\n#[cfg(not(feature = \"sqlite\"))]\nfn missing_sqlite_panic_bare() {\n    let p = project(\"missing_sqlite_panic_bare\").build();\n    let result = p\n        .command_without_database_url(\"setup\")\n        .env(\"DATABASE_URL\", \"example.db\")\n        .run();\n    assert!(result\n        .stderr()\n        .contains(\"`example.db` is not a valid database URL. It should start with \"));\n    assert!(result\n        .stderr()\n        .contains(\"or maybe you meant to use the `sqlite` feature which is not enabled.\"));\n}\n\n#[test]\n#[cfg(not(feature = \"sqlite\"))]\nfn missing_sqlite_panic_scheme() {\n    let p = project(\"missing_sqlite_panic_scheme\").build();\n    let result = p\n        .command_without_database_url(\"setup\")\n        .env(\"DATABASE_URL\", \"sqlite://example.db\")\n        .run();\n    assert!(result.stderr().contains(\n        \"Database url `sqlite://example.db` requires the `sqlite` feature but it's not enabled.\"\n    ));\n}\n\n#[test]\n#[cfg(not(feature = \"postgres\"))]\nfn missing_postgres_panic_postgres() {\n    let p = project(\"missing_postgres_panic_postgres\").build();\n    let result = p\n        .command_without_database_url(\"setup\")\n        .env(\"DATABASE_URL\", \"postgres://localhost\")\n        .run();\n    assert!(result.stderr().contains(\n        \"Database url `postgres://localhost` requires the `postgres` feature but it's not enabled.\"\n    ));\n}\n\n#[test]\n#[cfg(not(feature = \"postgres\"))]\nfn missing_postgres_panic_postgresql() {\n    let p = project(\"missing_postgres_panic_postgresql\").build();\n    let result = p\n        .command_without_database_url(\"setup\")\n        .env(\"DATABASE_URL\", \"postgresql://localhost\")\n        .run();\n    assert!(result\n        .stderr()\n        .contains(\"Database url `postgresql://localhost` requires the `postgres` feature but it's not enabled.\"));\n}\n\n#[test]\n#[cfg(not(feature = \"mysql\"))]\nfn missing_mysql_panic() {\n    let p = project(\"missing_mysql_panic\").build();\n    let result = p\n        .command_without_database_url(\"setup\")\n        .env(\"DATABASE_URL\", \"mysql://localhost\")\n        .run();\n    assert!(result.stderr().contains(\n        \"Database url `mysql://localhost` requires the `mysql` feature but it's not enabled.\"\n    ));\n}\n\n#[test]\nfn broken_dotenv_file_results_in_error() {\n    #[cfg(feature = \"postgres\")]\n    let url = \"postgres://localhost\";\n    #[cfg(feature = \"mysql\")]\n    let url = \"mysql://localhost\";\n    #[cfg(feature = \"sqlite\")]\n    let url = \":memory:\";\n\n    let mut p = project(\"broken_dotenv_file_results_in_error\")\n        .file(\".env\", &format!(\"DATABASE_URL={url}\\n;foo\\n#bar\"))\n        .build();\n\n    p.skip_drop_db();\n\n    let result = p.command_without_database_url(\"setup\").run();\n    assert!(result\n        .stderr()\n        .contains(\"Initializing `.env` file failed: Error parsing line\"));\n    assert!(!result.is_success());\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "484ceb56f0a4e872a6368390e37cf89821c4696e",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/diesel_cli/src/query_helper.rs",
    "func": "use diesel::backend::Backend;\nuse diesel::query_builder::*;\nuse diesel::result::QueryResult;\nuse diesel::RunQueryDsl;\n\n#[derive(Debug, Clone)]\npub struct DropDatabaseStatement {\n    db_name: String,\n    if_exists: bool,\n}\n\nimpl DropDatabaseStatement {\n    pub fn new(db_name: &str) -> Self {\n        DropDatabaseStatement {\n            db_name: db_name.to_owned(),\n            if_exists: false,\n        }\n    }\n\n    pub fn if_exists(self) -> Self {\n        DropDatabaseStatement {\n            if_exists: true,\n            ..self\n        }\n    }\n}\n\nimpl<DB: Backend> QueryFragment<DB> for DropDatabaseStatement {\n    fn walk_ast<'b>(&'b self, mut out: AstPass<'_, 'b, DB>) -> QueryResult<()> {\n        out.push_sql(\"DROP DATABASE \");\n        if self.if_exists {\n            out.push_sql(\"IF EXISTS \");\n        }\n        out.push_identifier(&self.db_name)?;\n        Ok(())\n    }\n}\n\nimpl<Conn> RunQueryDsl<Conn> for DropDatabaseStatement {}\n\nimpl QueryId for DropDatabaseStatement {\n    type QueryId = ();\n\n    const HAS_STATIC_QUERY_ID: bool = false;\n}\n\n#[derive(Debug, Clone)]\npub struct CreateDatabaseStatement {\n    db_name: String,\n}\n\nimpl CreateDatabaseStatement {\n    pub fn new(db_name: &str) -> Self {\n        CreateDatabaseStatement {\n            db_name: db_name.to_owned(),\n        }\n    }\n}\n\nimpl<DB: Backend> QueryFragment<DB> for CreateDatabaseStatement {\n    fn walk_ast<'b>(&'b self, mut out: AstPass<'_, 'b, DB>) -> QueryResult<()> {\n        out.push_sql(\"CREATE DATABASE \");\n        out.push_identifier(&self.db_name)?;\n        Ok(())\n    }\n}\n\nimpl<Conn> RunQueryDsl<Conn> for CreateDatabaseStatement {}\n\nimpl QueryId for CreateDatabaseStatement {\n    type QueryId = ();\n\n    const HAS_STATIC_QUERY_ID: bool = false;\n}\n\npub fn drop_database(db_name: &str) -> DropDatabaseStatement {\n    DropDatabaseStatement::new(db_name)\n}\n\npub fn create_database(db_name: &str) -> CreateDatabaseStatement {\n    CreateDatabaseStatement::new(db_name)\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "e8db1fbda6a45a1e3869b88507a6afbbf42cabab",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/diesel_cli/src/migrations/diff_schema.rs",
    "func": "use clap::ArgMatches;\nuse diesel::backend::Backend;\nuse diesel::query_builder::QueryBuilder;\nuse diesel::QueryResult;\nuse diesel_table_macro_syntax::{ColumnDef, TableDecl};\nuse std::collections::HashMap;\nuse std::path::Path;\nuse syn::visit::Visit;\n\nuse crate::config::PrintSchema;\nuse crate::database::InferConnection;\nuse crate::infer_schema_internals::{\n    filter_table_names, load_table_names, ColumnDefinition, ColumnType, ForeignKeyConstraint,\n    TableData, TableName,\n};\nuse crate::print_schema::{ColumnSorting, DocConfig};\n\nfn compatible_type_list() -> HashMap<&'static str, Vec<&'static str>> {\n    let mut map = HashMap::new();\n    map.insert(\"integer\", vec![\"int4\"]);\n    map.insert(\"bigint\", vec![\"int8\"]);\n    map.insert(\"smallint\", vec![\"int2\"]);\n    map.insert(\"text\", vec![\"varchar\"]);\n    map\n}\n\n#[tracing::instrument]\npub fn generate_sql_based_on_diff_schema(\n    config: PrintSchema,\n    matches: &ArgMatches,\n    schema_file_path: &Path,\n) -> Result<(String, String), crate::errors::Error> {\n    let mut config = config.set_filter(matches)?;\n\n    let project_root = crate::find_project_root()?;\n\n    let schema_path = project_root.join(schema_file_path);\n    let content = std::fs::read_to_string(&schema_path)\n        .map_err(|e| crate::errors::Error::IoError(e, Some(schema_path.clone())))?;\n\n    let syn_file = syn::parse_file(&content)?;\n\n    let mut tables_from_schema = SchemaCollector::default();\n\n    tables_from_schema.visit_file(&syn_file);\n    let mut conn = InferConnection::from_matches(matches)?;\n\n    let foreign_keys =\n        crate::infer_schema_internals::load_foreign_key_constraints(&mut conn, None)?;\n    let foreign_key_map =\n        foreign_keys\n            .into_iter()\n            .fold(HashMap::<_, Vec<_>>::new(), |mut acc, t| {\n                acc.entry(t.child_table.rust_name.clone())\n                    .or_default()\n                    .push(t);\n                acc\n            });\n\n    let mut expected_fk_map = tables_from_schema.joinable.into_iter().try_fold(\n        HashMap::<_, Vec<_>>::new(),\n        |mut acc, t| {\n            t.map(|t| {\n                acc.entry(t.child_table.to_string()).or_default().push(t);\n                acc\n            })\n        },\n    )?;\n\n    let mut table_pk_key_list = HashMap::new();\n    let mut expected_schema_map = HashMap::new();\n\n    for t in tables_from_schema.table_decls {\n        let t = t?;\n        let keys = t.primary_keys.as_ref().map(|keys| {\n            keys.keys\n                .iter()\n                .map(ToString::to_string)\n                .collect::<Vec<_>>()\n        });\n        table_pk_key_list.insert(t.table_name.to_string(), keys);\n        expected_schema_map.insert(t.table_name.to_string(), t);\n    }\n    config.with_docs = DocConfig::NoDocComments;\n    config.column_sorting = ColumnSorting::OrdinalPosition;\n\n    // Parameter `sqlite_integer_primary_key_is_bigint` is only used for a SQLite connection\n    match conn {\n        #[cfg(feature = \"postgres\")]\n        InferConnection::Pg(_) => config.sqlite_integer_primary_key_is_bigint = None,\n        #[cfg(feature = \"sqlite\")]\n        InferConnection::Sqlite(_) => (),\n        #[cfg(feature = \"mysql\")]\n        InferConnection::Mysql(_) => {\n            config.sqlite_integer_primary_key_is_bigint = None;\n        }\n    }\n\n    let mut schema_diff = Vec::new();\n    let table_names = load_table_names(&mut conn, None)?;\n    let tables_from_database = filter_table_names(table_names.clone(), &config.filter);\n    for table in tables_from_database {\n        tracing::info!(?table, \"Diff for existing table\");\n        let columns =\n            crate::infer_schema_internals::load_table_data(&mut conn, table.clone(), &config)?;\n        if let Some(t) = expected_schema_map.remove(&table.sql_name.to_lowercase()) {\n            tracing::info!(table = ?t.sql_name, \"Table exists in schema.rs\");\n            let mut primary_keys_in_db =\n                crate::infer_schema_internals::get_primary_keys(&mut conn, &table)?;\n            primary_keys_in_db.sort();\n            let mut primary_keys_in_schema = t\n                .primary_keys\n                .map(|pk| pk.keys.iter().map(|k| k.to_string()).collect::<Vec<_>>())\n                .unwrap_or_else(|| vec![\"id\".into()]);\n            primary_keys_in_schema.sort();\n            if primary_keys_in_db != primary_keys_in_schema {\n                tracing::debug!(\n                    ?primary_keys_in_schema,\n                    ?primary_keys_in_db,\n                    \"Primary keys changed\"\n                );\n                return Err(crate::errors::Error::UnsupportedFeature(\n                    \"Cannot change primary keys with --diff-schema yet\".into(),\n                ));\n            }\n\n            let mut expected_column_map = t\n                .column_defs\n                .into_iter()\n                .map(|c| (c.sql_name.to_lowercase(), c))\n                .collect::<HashMap<_, _>>();\n\n            let mut added_columns = Vec::new();\n            let mut removed_columns = Vec::new();\n            let mut changed_columns = Vec::new();\n\n            for c in columns.column_data {\n                if let Some(def) = expected_column_map.remove(&c.sql_name.to_lowercase()) {\n                    let tpe = ColumnType::for_column_def(&def)?;\n                    if !is_same_type(&c.ty, tpe) {\n                        tracing::info!(old = ?c, new = ?def.sql_name, \"Column changed type\");\n                        changed_columns.push((c, def));\n                    }\n                } else {\n                    tracing::info!(column = ?c, \"Column was removed\");\n                    removed_columns.push(c);\n                }\n            }\n\n            if !expected_column_map.is_empty() {\n                let columns = expected_column_map\n                    .values()\n                    .map(|v| v.column_name.to_string())\n                    .collect::<Vec<_>>();\n                tracing::info!(added = ?columns, \"Added columns\");\n            }\n            added_columns.extend(expected_column_map.into_values());\n\n            schema_diff.push(SchemaDiff::ChangeTable {\n                table: t.sql_name,\n                added_columns,\n                removed_columns,\n                changed_columns,\n            });\n        } else {\n            tracing::info!(\"Table does not exist yet\");\n            let foreign_keys = foreign_key_map\n                .get(&table.rust_name)\n                .cloned()\n                .unwrap_or_default();\n            if foreign_keys\n                .iter()\n                .any(|fk| fk.foreign_key_columns.len() != 1 || fk.primary_key_columns.len() != 1)\n            {\n                return Err(crate::errors::Error::UnsupportedFeature(\n                    \"Tables with composite foreign keys are not supported by --diff-schema\".into(),\n                ));\n            }\n            schema_diff.push(SchemaDiff::DropTable {\n                table,\n                columns,\n                foreign_keys,\n            });\n        }\n    }\n\n    schema_diff.extend(expected_schema_map.into_values().map(|t| {\n        tracing::info!(table = ?t.sql_name, \"Tables does not exist in database\");\n        let foreign_keys = expected_fk_map\n            .remove(&t.table_name.to_string())\n            .unwrap_or_default()\n            .into_iter()\n            .filter_map(|j| {\n                let referenced_table = table_pk_key_list.get(&t.table_name.to_string())?;\n                match referenced_table {\n                    None => Some((j, \"id\".into())),\n                    Some(pks) if pks.len() == 1 => Some((j, pks.first()?.to_string())),\n                    Some(_) => None,\n                }\n            })\n            .collect();\n        SchemaDiff::CreateTable {\n            to_create: t,\n            foreign_keys,\n        }\n    }));\n\n    let mut up_sql = String::new();\n    let mut down_sql = String::new();\n\n    for diff in schema_diff {\n        let up = match conn {\n            #[cfg(feature = \"postgres\")]\n            InferConnection::Pg(_) => {\n                let mut qb = diesel::pg::PgQueryBuilder::default();\n                diff.generate_up_sql(&mut qb, &config)?;\n                qb.finish()\n            }\n            #[cfg(feature = \"sqlite\")]\n            InferConnection::Sqlite(_) => {\n                let mut qb = diesel::sqlite::SqliteQueryBuilder::default();\n                diff.generate_up_sql(&mut qb, &config)?;\n                qb.finish()\n            }\n            #[cfg(feature = \"mysql\")]\n            InferConnection::Mysql(_) => {\n                let mut qb = diesel::mysql::MysqlQueryBuilder::default();\n                diff.generate_up_sql(&mut qb, &config)?;\n                qb.finish()\n            }\n        };\n\n        let down = match conn {\n            #[cfg(feature = \"postgres\")]\n            InferConnection::Pg(_) => {\n                let mut qb = diesel::pg::PgQueryBuilder::default();\n                diff.generate_down_sql(&mut qb, &config)?;\n                qb.finish()\n            }\n            #[cfg(feature = \"sqlite\")]\n            InferConnection::Sqlite(_) => {\n                let mut qb = diesel::sqlite::SqliteQueryBuilder::default();\n                diff.generate_down_sql(&mut qb, &config)?;\n                qb.finish()\n            }\n            #[cfg(feature = \"mysql\")]\n            InferConnection::Mysql(_) => {\n                let mut qb = diesel::mysql::MysqlQueryBuilder::default();\n                diff.generate_down_sql(&mut qb, &config)?;\n                qb.finish()\n            }\n        };\n        up_sql += &up;\n        up_sql += \"\\n\";\n        down_sql += &down;\n        down_sql += \"\\n\";\n    }\n\n    Ok((up_sql, down_sql))\n}\n\nfn is_same_type(ty: &ColumnType, tpe: ColumnType) -> bool {\n    if ty.is_array != tpe.is_array\n        || ty.is_nullable != tpe.is_nullable\n        || ty.is_unsigned != tpe.is_unsigned\n        || ty.max_length != tpe.max_length\n    {\n        return false;\n    }\n\n    let mut is_same_schema = ty.schema == tpe.schema;\n    if !is_same_schema\n        && ((ty.schema.as_deref() == Some(\"pg_catalog\") && tpe.schema.is_none())\n            || (tpe.schema.as_deref() == Some(\"pg_catalog\") && ty.schema.is_none()))\n    {\n        is_same_schema = true;\n    }\n\n    if ty.sql_name.to_lowercase() == tpe.sql_name.to_lowercase() && is_same_schema {\n        return true;\n    }\n    if !is_same_schema {\n        return false;\n    }\n    let compatible_types = compatible_type_list();\n\n    if let Some(compatible) = compatible_types.get(&ty.sql_name.to_lowercase() as &str) {\n        return compatible.contains(&((&tpe.sql_name.to_lowercase()) as &str));\n    }\n    if let Some(compatible) = compatible_types.get(&tpe.sql_name.to_lowercase() as &str) {\n        return compatible.contains(&(&ty.sql_name.to_lowercase() as &str));\n    }\n    false\n}\n\n#[allow(clippy::enum_variant_names)]\nenum SchemaDiff {\n    DropTable {\n        table: TableName,\n        columns: TableData,\n        foreign_keys: Vec<ForeignKeyConstraint>,\n    },\n    CreateTable {\n        to_create: TableDecl,\n        foreign_keys: Vec<(Joinable, String)>,\n    },\n    ChangeTable {\n        table: String,\n        added_columns: Vec<ColumnDef>,\n        removed_columns: Vec<ColumnDefinition>,\n        changed_columns: Vec<(ColumnDefinition, ColumnDef)>,\n    },\n}\n\nimpl SchemaDiff {\n    fn generate_up_sql<DB>(\n        &self,\n        query_builder: &mut impl QueryBuilder<DB>,\n        config: &PrintSchema,\n    ) -> Result<(), crate::errors::Error>\n    where\n        DB: Backend,\n    {\n        match self {\n            SchemaDiff::DropTable { table, .. } => {\n                generate_drop_table(query_builder, &table.sql_name.to_lowercase())?;\n            }\n            SchemaDiff::CreateTable {\n                to_create,\n                foreign_keys,\n            } => {\n                let table = &to_create.sql_name.to_lowercase();\n                let primary_keys = to_create\n                    .primary_keys\n                    .as_ref()\n                    .map(|keys| keys.keys.iter().map(|k| k.to_string()).collect())\n                    .unwrap_or_else(|| vec![String::from(\"id\")]);\n                let column_data = to_create\n                    .column_defs\n                    .iter()\n                    .map(|c| {\n                        let ty = ColumnType::for_column_def(c)?;\n                        Ok(ColumnDefinition {\n                            sql_name: c.sql_name.to_lowercase(),\n                            rust_name: c.sql_name.clone(),\n                            ty,\n                            comment: None,\n                        })\n                    })\n                    .collect::<Result<Vec<_>, crate::errors::Error>>()?;\n                let foreign_keys = foreign_keys\n                    .iter()\n                    .map(|(f, pk)| {\n                        (\n                            f.parent_table.to_string(),\n                            f.ref_column.to_string(),\n                            pk.clone(),\n                        )\n                    })\n                    .collect::<Vec<_>>();\n\n                let sqlite_integer_primary_key_is_bigint = config\n                    .sqlite_integer_primary_key_is_bigint\n                    .unwrap_or_default();\n\n                generate_create_table(\n                    query_builder,\n                    table,\n                    &column_data,\n                    &primary_keys,\n                    &foreign_keys,\n                    sqlite_integer_primary_key_is_bigint,\n                )?;\n            }\n            SchemaDiff::ChangeTable {\n                table,\n                added_columns,\n                removed_columns,\n                changed_columns,\n            } => {\n                for c in removed_columns\n                    .iter()\n                    .chain(changed_columns.iter().map(|(a, _)| a))\n                {\n                    generate_drop_column(query_builder, &table.to_lowercase(), &c.sql_name)?;\n                    query_builder.push_sql(\"\\n\");\n                }\n                for c in added_columns\n                    .iter()\n                    .chain(changed_columns.iter().map(|(_, b)| b))\n                {\n                    generate_add_column(\n                        query_builder,\n                        &table.to_lowercase(),\n                        &c.column_name.to_string().to_lowercase(),\n                        &ColumnType::for_column_def(c)?,\n                    )?;\n                    query_builder.push_sql(\"\\n\");\n                }\n            }\n        }\n        Ok(())\n    }\n\n    fn generate_down_sql<DB>(\n        &self,\n        query_builder: &mut impl QueryBuilder<DB>,\n        config: &PrintSchema,\n    ) -> QueryResult<()>\n    where\n        DB: Backend,\n    {\n        match self {\n            SchemaDiff::DropTable {\n                table,\n                columns,\n                foreign_keys,\n            } => {\n                let fk = foreign_keys\n                    .iter()\n                    .map(|fk| {\n                        (\n                            fk.parent_table.rust_name.clone(),\n                            fk.foreign_key_columns_rust[0].clone(),\n                            fk.primary_key_columns[0].clone(),\n                        )\n                    })\n                    .collect::<Vec<_>>();\n\n                let sqlite_integer_primary_key_is_bigint = config\n                    .sqlite_integer_primary_key_is_bigint\n                    .unwrap_or_default();\n\n                generate_create_table(\n                    query_builder,\n                    &table.sql_name.to_lowercase(),\n                    &columns.column_data,\n                    &columns.primary_key,\n                    &fk,\n                    sqlite_integer_primary_key_is_bigint,\n                )?;\n            }\n            SchemaDiff::CreateTable { to_create, .. } => {\n                generate_drop_table(query_builder, &to_create.sql_name.to_lowercase())?;\n            }\n            SchemaDiff::ChangeTable {\n                table,\n                added_columns,\n                removed_columns,\n                changed_columns,\n            } => {\n                // We don't need to check the `sqlite_integer_primary_key_is_bigint` parameter here\n                // since `\u00c0LTER TABLE` queries cannot modify primary key columns in SQLite.\n                // See https://www.sqlite.org/lang_altertable.html#alter_table_add_column for more information.\n                for c in added_columns\n                    .iter()\n                    .chain(changed_columns.iter().map(|(_, b)| b))\n                {\n                    generate_drop_column(\n                        query_builder,\n                        &table.to_lowercase(),\n                        &c.column_name.to_string().to_lowercase(),\n                    )?;\n                    query_builder.push_sql(\"\\n\");\n                }\n                for c in removed_columns\n                    .iter()\n                    .chain(changed_columns.iter().map(|(a, _)| a))\n                {\n                    generate_add_column(\n                        query_builder,\n                        &table.to_lowercase(),\n                        &c.sql_name.to_lowercase(),\n                        &c.ty,\n                    )?;\n                    query_builder.push_sql(\"\\n\");\n                }\n            }\n        }\n        Ok(())\n    }\n}\n\nfn generate_add_column<DB>(\n    query_builder: &mut impl QueryBuilder<DB>,\n    table: &str,\n    column: &str,\n    ty: &ColumnType,\n) -> QueryResult<()>\nwhere\n    DB: Backend,\n{\n    query_builder.push_sql(\"ALTER TABLE \");\n    query_builder.push_identifier(table)?;\n    query_builder.push_sql(\" ADD COLUMN \");\n    query_builder.push_identifier(column)?;\n    generate_column_type_name(query_builder, ty);\n    query_builder.push_sql(\";\");\n    Ok(())\n}\n\nfn generate_drop_column<DB>(\n    query_builder: &mut impl QueryBuilder<DB>,\n    table: &str,\n    column: &str,\n) -> QueryResult<()>\nwhere\n    DB: Backend,\n{\n    query_builder.push_sql(\"ALTER TABLE \");\n    query_builder.push_identifier(table)?;\n    query_builder.push_sql(\" DROP COLUMN \");\n    query_builder.push_identifier(column)?;\n    query_builder.push_sql(\";\");\n\n    Ok(())\n}\n\nfn generate_create_table<DB>(\n    query_builder: &mut impl QueryBuilder<DB>,\n    table: &str,\n    column_data: &[ColumnDefinition],\n    primary_keys: &[String],\n    foreign_keys: &[(String, String, String)],\n    sqlite_integer_primary_key_is_bigint: bool,\n) -> QueryResult<()>\nwhere\n    DB: Backend,\n{\n    query_builder.push_sql(\"CREATE TABLE \");\n    query_builder.push_identifier(table)?;\n    query_builder.push_sql(\"(\\n\");\n    let mut first = true;\n    let mut foreign_key_list = Vec::with_capacity(foreign_keys.len());\n    for column in column_data {\n        if first {\n            first = false;\n        } else {\n            query_builder.push_sql(\",\\n\");\n        }\n        query_builder.push_sql(\"\\t\");\n\n        let is_only_primary_key =\n            primary_keys.contains(&column.rust_name) && primary_keys.len() == 1;\n\n        query_builder.push_identifier(&column.sql_name)?;\n\n        // When the `sqlite_integer_primary_key_is_bigint` config parameter is used,\n        // if a column is the only primary key and its type is `BigInt`,\n        // we consider it equivalent to the `rowid` column in order to be compatible\n        // with the `print-schema` command using the same config parameter.\n        // See https://www.sqlite.org/lang_createtable.html#rowid for more information.\n        if sqlite_integer_primary_key_is_bigint\n            && is_only_primary_key\n            && column.ty.sql_name.eq_ignore_ascii_case(\"BigInt\")\n        {\n            let ty = ColumnType {\n                rust_name: \"Integer\".into(),\n                sql_name: \"Integer\".into(),\n                ..column.ty.clone()\n            };\n            generate_column_type_name(query_builder, &ty);\n        } else {\n            generate_column_type_name(query_builder, &column.ty);\n        }\n\n        if is_only_primary_key {\n            query_builder.push_sql(\" PRIMARY KEY\");\n        }\n\n        if let Some((table, _, pk)) = foreign_keys.iter().find(|(_, k, _)| k == &column.rust_name) {\n            foreign_key_list.push((column, table, pk));\n        }\n    }\n    if primary_keys.len() > 1 {\n        query_builder.push_sql(\",\\n\");\n        query_builder.push_sql(\"\\tPRIMARY KEY(\");\n        for (idx, key) in primary_keys.iter().enumerate() {\n            query_builder.push_identifier(key)?;\n            if idx != primary_keys.len() - 1 {\n                query_builder.push_sql(\", \");\n            }\n        }\n        query_builder.push_sql(\")\");\n    }\n    // MySQL parses but ignores \u201cinline REFERENCES specifications\u201d\n    // (as defined in the SQL standard)\n    // where the references are defined as part of the column specification.\n    // MySQL accepts REFERENCES clauses only when specified as\n    // part of a separate FOREIGN KEY specification.\n    //\n    // https://dev.mysql.com/doc/refman/8.0/en/ansi-diff-foreign-keys.html\n\n    for (column, table, pk) in foreign_key_list {\n        query_builder.push_sql(\",\\n\\t\");\n        query_builder.push_sql(\"FOREIGN KEY (\");\n        query_builder.push_identifier(&column.sql_name)?;\n        query_builder.push_sql(\") REFERENCES \");\n        query_builder.push_identifier(table)?;\n        query_builder.push_sql(\"(\");\n        query_builder.push_identifier(pk)?;\n        query_builder.push_sql(\")\");\n    }\n    query_builder.push_sql(\"\\n);\");\n\n    query_builder.push_sql(\"\\n\");\n\n    Ok(())\n}\n\nfn generate_column_type_name<DB>(query_builder: &mut impl QueryBuilder<DB>, ty: &ColumnType)\nwhere\n    DB: Backend,\n{\n    // TODO: handle schema\n    query_builder.push_sql(&format!(\" {}\", ty.sql_name.to_uppercase()));\n    if let Some(max_length) = ty.max_length {\n        query_builder.push_sql(&format!(\"({max_length})\"));\n    }\n    if !ty.is_nullable {\n        query_builder.push_sql(\" NOT NULL\");\n    }\n    if ty.is_unsigned {\n        query_builder.push_sql(\" UNSIGNED\");\n    }\n    if ty.is_array {\n        query_builder.push_sql(\"[]\");\n    }\n}\n\nfn generate_drop_table<DB>(\n    query_builder: &mut impl QueryBuilder<DB>,\n    table: &str,\n) -> QueryResult<()>\nwhere\n    DB: Backend,\n{\n    // TODO: handle schema?\n    query_builder.push_sql(\"DROP TABLE IF EXISTS \");\n    query_builder.push_identifier(table)?;\n    query_builder.push_sql(\";\");\n    Ok(())\n}\n\nstruct Joinable {\n    parent_table: syn::Ident,\n    child_table: syn::Ident,\n    ref_column: syn::Ident,\n}\n\nimpl syn::parse::Parse for Joinable {\n    fn parse(input: syn::parse::ParseStream) -> syn::Result<Self> {\n        let child_table = input.parse()?;\n        let _arrow: syn::Token![->] = input.parse()?;\n        let parent_table = input.parse()?;\n        let content;\n        syn::parenthesized!(content in input);\n        let ref_column = content.parse()?;\n        Ok(Self {\n            child_table,\n            parent_table,\n            ref_column,\n        })\n    }\n}\n\n#[derive(Default)]\nstruct SchemaCollector {\n    table_decls: Vec<Result<TableDecl, syn::Error>>,\n    joinable: Vec<Result<Joinable, syn::Error>>,\n}\n\nimpl<'ast> syn::visit::Visit<'ast> for SchemaCollector {\n    fn visit_macro(&mut self, i: &'ast syn::Macro) {\n        let last_segment = i.path.segments.last();\n        if last_segment.map(|s| s.ident == \"table\").unwrap_or(false) {\n            self.table_decls.push(i.parse_body());\n        } else if last_segment.map(|s| s.ident == \"joinable\").unwrap_or(false) {\n            self.joinable.push(i.parse_body());\n        }\n        syn::visit::visit_macro(self, i)\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "4ad500b6131bca76dbf29994f4a0a9904fef5c75",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/diesel_cli/src/infer_schema_internals/mod.rs",
    "func": "mod data_structures;\nmod foreign_keys;\nmod inference;\nmod table_data;\n\n#[cfg(feature = \"uses_information_schema\")]\nmod information_schema;\n#[cfg(feature = \"mysql\")]\nmod mysql;\n#[cfg(feature = \"postgres\")]\nmod pg;\n#[cfg(feature = \"sqlite\")]\nmod sqlite;\n\npub use self::data_structures::*;\npub use self::foreign_keys::*;\npub use self::inference::*;\npub use self::table_data::*;\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "882477980343a3ee42070f4e7ffafb75cd390f6c",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/diesel_compile_tests/tests/fail/and_or_functions_must_take_boolean_expr_as_attributes.rs",
    "func": "extern crate diesel;\n\nuse diesel::prelude::*;\n\ntable! {\n    users {\n        id -> Integer,\n        name -> VarChar,\n    }\n}\n\nfn main() {\n    let conn = &mut PgConnection::establish(\"\u2026\").unwrap();\n    users::table\n        .filter(users::id.eq(1).and(users::id).or(users::id))\n        .select(users::id)\n        .execute(conn)\n        .unwrap();\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "d5ca16c099716c287a3b7bd3352b6450974f5338",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/diesel_compile_tests/tests/fail/combinations_require_same_sql_types.rs",
    "func": "extern crate diesel;\n\nuse diesel::*;\n\ntable! {\n    users {\n        id -> Integer,\n        name -> VarChar,\n    }\n}\n\ntable! {\n    posts {\n        id -> Integer,\n        title -> VarChar,\n    }\n}\n\ntable! {\n    comments {\n        id -> Integer,\n        post_id -> Integer,\n    }\n}\n\njoinable!(comments -> posts (post_id));\nallow_tables_to_appear_in_same_query!(comments, posts, users);\n\nfn main() {\n    let _ = users::table.union(comments::table);\n\n    // Sanity check to make sure the error is when comments\n    // become involved\n    let union = users::table.union(posts::table);\n    let _ = union.union(comments::table);\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "0f7befde29c6c30d6196516414fe392429ca1065",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/diesel_compile_tests/tests/fail/array_expressions_must_be_correct_type.rs",
    "func": "extern crate diesel;\n\nuse diesel::dsl::*;\nuse diesel::*;\n\nfn main() {\n    let mut connection = PgConnection::establish(\"\").unwrap();\n    select(array((1, 3))).get_result::<Vec<i32>>(&mut connection);\n    select(array((1f64, 3f64))).get_result::<Vec<i32>>(&mut connection);\n    select(array((1f64, 3f64))).get_result::<Vec<f64>>(&mut connection);\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "39c3209859118ef7015407a2c368cac23e45985d",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/diesel_compile_tests/tests/fail/must_use_query_methods.rs",
    "func": "#![deny(unused_must_use)]\n\nextern crate diesel;\n\nuse diesel::*;\n\ntable! {\n    stuff (b) {\n        b -> Bool,\n    }\n}\n\nfn main() {\n    use stuff::b;\n    use stuff::table as st;\n\n    st.select(b);\n    st.select(b).distinct();\n    st.count();\n    st.order(b);\n    st.limit(1);\n    st.offset(1);\n\n    st.filter(b.eq(true));\n    st.filter(b.eq(true)).limit(1);\n\n    insert_into(st);\n    insert_into(st).values(&vec![b.eq(true), b.eq(false)]);\n\n    update(st).set(b.eq(true));\n\n    delete(st);\n\n    let _thingies = st.filter(b.eq(true)); // No ERROR\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "6be8399a8e8ce95c55067fa81f2502f9c1e7edbd",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/diesel_compile_tests/tests/fail/selecting_multiple_columns_requires_all_must_be_from_selectable_table.rs",
    "func": "extern crate diesel;\n\nuse diesel::*;\n\ntable! {\n    users {\n        id -> Integer,\n        name -> VarChar,\n    }\n}\n\ntable! {\n    posts {\n        id -> Integer,\n        title -> VarChar,\n        user_id -> Integer,\n    }\n}\n\nallow_tables_to_appear_in_same_query!(users, posts);\n\nfn main() {\n    let stuff = users::table.select((posts::id, posts::user_id));\n    let stuff = users::table.select((posts::id, users::name));\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "af2282011747731ad94fc3b45f63e2a5fb3004da",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/diesel_compile_tests/tests/fail/derive/as_expression_without_sql_type.rs",
    "func": "extern crate diesel;\nuse diesel::expression::AsExpression;\n\n#[derive(AsExpression)]\nstruct Lol;\n\nfn main() {}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "e8ff8981b45105eb4821adeaf07594e63593ea61",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/diesel/src/test_helpers.rs",
    "func": "#![allow(missing_docs)] // test only module\nextern crate dotenvy;\n\nuse crate::prelude::*;\n\ncfg_if! {\n    if #[cfg(feature = \"sqlite\")] {\n        pub type TestConnection = SqliteConnection;\n\n        pub fn connection() -> TestConnection {\n            SqliteConnection::establish(\":memory:\").unwrap()\n        }\n\n        pub fn database_url() -> String {\n            String::from(\":memory:\")\n        }\n    } else if #[cfg(feature = \"postgres\")] {\n        pub type TestConnection = PgConnection;\n\n        pub fn connection() -> TestConnection {\n            pg_connection()\n        }\n\n        pub fn database_url() -> String {\n            pg_database_url()\n        }\n    } else if #[cfg(feature = \"mysql\")] {\n        pub type TestConnection = MysqlConnection;\n\n        pub fn connection() -> TestConnection {\n            let mut conn = connection_no_transaction();\n            conn.begin_test_transaction().unwrap();\n            conn\n        }\n\n        pub fn connection_no_transaction() -> TestConnection {\n            MysqlConnection::establish(&database_url()).unwrap()\n        }\n\n        pub fn database_url() -> String {\n            dotenvy::var(\"MYSQL_UNIT_TEST_DATABASE_URL\")\n                .or_else(|_| dotenvy::var(\"DATABASE_URL\"))\n                .expect(\"DATABASE_URL must be set in order to run tests\")\n        }\n    } else {\n        compile_error!(\n            \"At least one backend must be used to test this crate.\\n \\\n            Pass argument `--features \\\"<backend>\\\"` with one or more of the following backends, \\\n            'mysql', 'postgres', or 'sqlite'. \\n\\n \\\n            ex. cargo test --features \\\"mysql postgres sqlite\\\"\\n\"\n        );\n    }\n}\n\n#[cfg(feature = \"postgres\")]\npub fn pg_connection() -> PgConnection {\n    let mut conn = pg_connection_no_transaction();\n    conn.begin_test_transaction().unwrap();\n    conn\n}\n\n#[cfg(feature = \"postgres\")]\npub fn pg_connection_no_transaction() -> PgConnection {\n    PgConnection::establish(&pg_database_url()).unwrap()\n}\n\n#[cfg(feature = \"postgres\")]\npub fn pg_database_url() -> String {\n    dotenvy::var(\"PG_DATABASE_URL\")\n        .or_else(|_| dotenvy::var(\"DATABASE_URL\"))\n        .expect(\"DATABASE_URL must be set in order to run tests\")\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "f6a3a7755268083ec196443ef496fe02cb0c052f",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/diesel/src/sqlite/query_builder/query_fragment_impls.rs",
    "func": "use crate::query_builder::select_statement::boxed::BoxedQueryHelper;\nuse crate::query_builder::upsert::into_conflict_clause::OnConflictSelectWrapper;\nuse crate::query_builder::where_clause::BoxedWhereClause;\nuse crate::query_builder::where_clause::WhereClause;\nuse crate::query_builder::AstPass;\nuse crate::query_builder::BoxedSelectStatement;\nuse crate::query_builder::QueryFragment;\nuse crate::query_builder::SelectStatement;\nuse crate::QueryResult;\n\n// The corresponding impl for`NoWhereClause` is missing because of\n// https://www.sqlite.org/lang_UPSERT.html (Parsing Ambiguity)\n#[cfg(feature = \"sqlite\")]\nimpl<F, S, D, W, O, LOf, G, H, LC> QueryFragment<crate::sqlite::Sqlite>\n    for OnConflictSelectWrapper<SelectStatement<F, S, D, WhereClause<W>, O, LOf, G, H, LC>>\nwhere\n    SelectStatement<F, S, D, WhereClause<W>, O, LOf, G, H, LC>:\n        QueryFragment<crate::sqlite::Sqlite>,\n{\n    fn walk_ast<'b>(&'b self, out: AstPass<'_, 'b, crate::sqlite::Sqlite>) -> QueryResult<()> {\n        self.0.walk_ast(out)\n    }\n}\n\n#[cfg(feature = \"sqlite\")]\nimpl<'a, ST, QS, GB> QueryFragment<crate::sqlite::Sqlite>\n    for OnConflictSelectWrapper<BoxedSelectStatement<'a, ST, QS, crate::sqlite::Sqlite, GB>>\nwhere\n    BoxedSelectStatement<'a, ST, QS, crate::sqlite::Sqlite, GB>:\n        QueryFragment<crate::sqlite::Sqlite>,\n    QS: QueryFragment<crate::sqlite::Sqlite>,\n{\n    fn walk_ast<'b>(&'b self, pass: AstPass<'_, 'b, crate::sqlite::Sqlite>) -> QueryResult<()> {\n        // https://www.sqlite.org/lang_UPSERT.html (Parsing Ambiguity)\n        self.0.build_query(pass, |where_clause, mut pass| {\n            match where_clause {\n                BoxedWhereClause::None => pass.push_sql(\" WHERE 1=1 \"),\n                w => w.walk_ast(pass.reborrow())?,\n            }\n            Ok(())\n        })\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "7b54ac05fe106d5485a4fca252f9c4c8773cfb1c",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/diesel/src/sqlite/query_builder/limit_offset.rs",
    "func": "use crate::query_builder::limit_clause::{LimitClause, NoLimitClause};\nuse crate::query_builder::limit_offset_clause::{BoxedLimitOffsetClause, LimitOffsetClause};\nuse crate::query_builder::offset_clause::{NoOffsetClause, OffsetClause};\nuse crate::query_builder::{AstPass, IntoBoxedClause, QueryFragment};\nuse crate::result::QueryResult;\nuse crate::sqlite::Sqlite;\n\nimpl QueryFragment<Sqlite> for LimitOffsetClause<NoLimitClause, NoOffsetClause> {\n    fn walk_ast<'b>(&'b self, _out: AstPass<'_, 'b, Sqlite>) -> QueryResult<()> {\n        Ok(())\n    }\n}\n\nimpl<L> QueryFragment<Sqlite> for LimitOffsetClause<LimitClause<L>, NoOffsetClause>\nwhere\n    LimitClause<L>: QueryFragment<Sqlite>,\n{\n    fn walk_ast<'b>(&'b self, out: AstPass<'_, 'b, Sqlite>) -> QueryResult<()> {\n        self.limit_clause.walk_ast(out)?;\n        Ok(())\n    }\n}\n\nimpl<O> QueryFragment<Sqlite> for LimitOffsetClause<NoLimitClause, OffsetClause<O>>\nwhere\n    OffsetClause<O>: QueryFragment<Sqlite>,\n{\n    fn walk_ast<'b>(&'b self, mut out: AstPass<'_, 'b, Sqlite>) -> QueryResult<()> {\n        // Sqlite requires a limit clause in front of any offset clause\n        // using `LIMIT -1` is the same as not having any limit clause\n        // https://sqlite.org/lang_select.html\n        out.push_sql(\" LIMIT -1 \");\n        self.offset_clause.walk_ast(out)?;\n        Ok(())\n    }\n}\n\nimpl<L, O> QueryFragment<Sqlite> for LimitOffsetClause<LimitClause<L>, OffsetClause<O>>\nwhere\n    LimitClause<L>: QueryFragment<Sqlite>,\n    OffsetClause<O>: QueryFragment<Sqlite>,\n{\n    fn walk_ast<'b>(&'b self, mut out: AstPass<'_, 'b, Sqlite>) -> QueryResult<()> {\n        self.limit_clause.walk_ast(out.reborrow())?;\n        self.offset_clause.walk_ast(out.reborrow())?;\n        Ok(())\n    }\n}\n\nimpl QueryFragment<Sqlite> for BoxedLimitOffsetClause<'_, Sqlite> {\n    fn walk_ast<'b>(&'b self, mut out: AstPass<'_, 'b, Sqlite>) -> QueryResult<()> {\n        match (self.limit.as_ref(), self.offset.as_ref()) {\n            (Some(limit), Some(offset)) => {\n                limit.walk_ast(out.reborrow())?;\n                offset.walk_ast(out.reborrow())?;\n            }\n            (Some(limit), None) => {\n                limit.walk_ast(out.reborrow())?;\n            }\n            (None, Some(offset)) => {\n                // See the `QueryFragment` implementation for `LimitOffsetClause` for details.\n                out.push_sql(\" LIMIT -1 \");\n                offset.walk_ast(out.reborrow())?;\n            }\n            (None, None) => {}\n        }\n        Ok(())\n    }\n}\n\n// Have explicit impls here because we need to set `Some`/`None` for the clauses\n// correspondingly, otherwise we cannot match on it in the `QueryFragment` impl\n// above\nimpl<'a> IntoBoxedClause<'a, Sqlite> for LimitOffsetClause<NoLimitClause, NoOffsetClause> {\n    type BoxedClause = BoxedLimitOffsetClause<'a, Sqlite>;\n\n    fn into_boxed(self) -> Self::BoxedClause {\n        BoxedLimitOffsetClause {\n            limit: None,\n            offset: None,\n        }\n    }\n}\n\nimpl<'a, L> IntoBoxedClause<'a, Sqlite> for LimitOffsetClause<LimitClause<L>, NoOffsetClause>\nwhere\n    L: QueryFragment<Sqlite> + Send + 'a,\n{\n    type BoxedClause = BoxedLimitOffsetClause<'a, Sqlite>;\n\n    fn into_boxed(self) -> Self::BoxedClause {\n        BoxedLimitOffsetClause {\n            limit: Some(Box::new(self.limit_clause)),\n            offset: None,\n        }\n    }\n}\n\nimpl<'a, O> IntoBoxedClause<'a, Sqlite> for LimitOffsetClause<NoLimitClause, OffsetClause<O>>\nwhere\n    O: QueryFragment<Sqlite> + Send + 'a,\n{\n    type BoxedClause = BoxedLimitOffsetClause<'a, Sqlite>;\n\n    fn into_boxed(self) -> Self::BoxedClause {\n        BoxedLimitOffsetClause {\n            limit: None,\n            offset: Some(Box::new(self.offset_clause)),\n        }\n    }\n}\n\nimpl<'a, L, O> IntoBoxedClause<'a, Sqlite> for LimitOffsetClause<LimitClause<L>, OffsetClause<O>>\nwhere\n    L: QueryFragment<Sqlite> + Send + 'a,\n    O: QueryFragment<Sqlite> + Send + 'a,\n{\n    type BoxedClause = BoxedLimitOffsetClause<'a, Sqlite>;\n\n    fn into_boxed(self) -> Self::BoxedClause {\n        BoxedLimitOffsetClause {\n            limit: Some(Box::new(self.limit_clause)),\n            offset: Some(Box::new(self.offset_clause)),\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "9cc5951ac0a5d9e72c8f7783ba1198efe83c4cbd",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/diesel/src/expression_methods/bool_expression_methods.rs",
    "func": "use crate::dsl;\nuse crate::expression::grouped::Grouped;\nuse crate::expression::operators::{And, Or};\nuse crate::expression::{AsExpression, Expression, TypedExpressionType};\nuse crate::sql_types::{self, BoolOrNullableBool, SqlType};\n\n/// Methods present on boolean expressions\npub trait BoolExpressionMethods: Expression + Sized {\n    /// Creates a SQL `AND` expression\n    ///\n    /// # Example\n    ///\n    /// ```\n    /// # include!(\"../doctest_setup.rs\");\n    /// #\n    /// # fn main() {\n    /// #     run_test().unwrap();\n    /// # }\n    /// #\n    /// # fn run_test() -> QueryResult<()> {\n    /// #     use schema::animals::dsl::*;\n    /// #     let connection = &mut establish_connection();\n    /// #\n    /// diesel::insert_into(animals)\n    ///     .values(&vec![\n    ///         (species.eq(\"ferret\"), legs.eq(4), name.eq(\"Freddy\")),\n    ///         (species.eq(\"ferret\"), legs.eq(4), name.eq(\"Jack\")),\n    ///     ])\n    ///     .execute(connection)?;\n    ///\n    /// let data = animals.select((species, name))\n    ///     .filter(species.eq(\"ferret\").and(name.eq(\"Jack\")))\n    ///     .load(connection)?;\n    /// let expected = vec![\n    ///     (String::from(\"ferret\"), Some(String::from(\"Jack\"))),\n    /// ];\n    /// assert_eq!(expected, data);\n    /// #     Ok(())\n    /// # }\n    /// ```\n    fn and<T, ST>(self, other: T) -> dsl::And<Self, T, ST>\n    where\n        Self::SqlType: SqlType,\n        ST: SqlType + TypedExpressionType + BoolOrNullableBool,\n        T: AsExpression<ST>,\n        And<Self, T::Expression>: Expression,\n    {\n        Grouped(And::new(self, other.as_expression()))\n    }\n\n    /// Creates a SQL `OR` expression\n    ///\n    /// The result will be wrapped in parenthesis, so that precedence matches\n    /// that of your function calls. For example, `false.and(false.or(true))`\n    /// will generate the SQL `FALSE AND (FALSE OR TRUE)`, which returns `false`\n    ///\n    /// # Example\n    ///\n    /// ```\n    /// # include!(\"../doctest_setup.rs\");\n    /// #\n    /// # fn main() {\n    /// #     run_test().unwrap();\n    /// # }\n    /// #\n    /// # fn run_test() -> QueryResult<()> {\n    /// #     use schema::animals::dsl::*;\n    /// #     let connection = &mut establish_connection();\n    /// #\n    /// diesel::insert_into(animals)\n    ///     .values(&vec![\n    ///         (species.eq(\"ferret\"), legs.eq(4), name.eq(\"Freddy\")),\n    ///         (species.eq(\"ferret\"), legs.eq(4), name.eq(\"Jack\")),\n    ///     ])\n    ///     .execute(connection)?;\n    ///\n    /// let data = animals.select((species, name))\n    ///     .filter(species.eq(\"ferret\").or(name.eq(\"Jack\")))\n    ///     .load(connection)?;\n    /// let expected = vec![\n    ///     (String::from(\"dog\"), Some(String::from(\"Jack\"))),\n    ///     (String::from(\"ferret\"), Some(String::from(\"Freddy\"))),\n    ///     (String::from(\"ferret\"), Some(String::from(\"Jack\"))),\n    /// ];\n    /// assert_eq!(expected, data);\n    /// #     Ok(())\n    /// # }\n    /// ```\n    fn or<T, ST>(self, other: T) -> dsl::Or<Self, T, ST>\n    where\n        Self::SqlType: SqlType,\n        ST: SqlType + TypedExpressionType + BoolOrNullableBool,\n        T: AsExpression<ST>,\n        Or<Self, T::Expression>: Expression,\n    {\n        Grouped(Or::new(self, other.as_expression()))\n    }\n}\n\nimpl<T> BoolExpressionMethods for T\nwhere\n    T: Expression,\n    T::SqlType: BoolOrNullableBool,\n{\n}\n\n/// Allow ~type inference on [And](crate::helper_types::And) and [Or](crate::helper_types::Or)\n/// helper types\n///\n/// This is used to be statistically correct as last generic parameter of `dsl::And` and `dsl::Or`\n/// without having to specify an additional type parameter.\n///\n/// It works with types that are [Expression]s and have a [`SqlType`](Expression::SqlType) that is\n/// either [`Bool`](sql_types::Bool) or [`Nullable<Bool>`](sql_types::Nullable), and with [`bool`]\n/// (and `Option<bool>` and references to those).\n///\n/// Cases where an additional type parameter would still have to be specified in the helper type\n/// generic parameters are:\n/// - If this trait isn't implemented for the `other` parameter of the expression\n///   (in that case the user (you?) probably wants to implement it)\n/// - If the user actually was using the not-preferred implementation of `AsExpression`\n///   (e.g. towards `Nullable<Bool>` instead of `Bool`)\npub trait PreferredBoolSqlType {\n    /// The preferred `Bool` SQL type for this AsExpression implementation.\n    ///\n    /// That should be either `Bool` or `Nullable<Bool>`.\n    type PreferredSqlType;\n}\n\nimpl<E: Expression> PreferredBoolSqlType for E\nwhere\n    E::SqlType: BoolOrNullableBool,\n{\n    type PreferredSqlType = <E as Expression>::SqlType;\n}\n\n/// This impl has to live in Diesel because otherwise it would conflict with the blanket impl above\n/// because \"diesel might add an implementation of Expression for bool\"\nimpl PreferredBoolSqlType for bool {\n    type PreferredSqlType = sql_types::Bool;\n}\n\nimpl PreferredBoolSqlType for &bool {\n    type PreferredSqlType = sql_types::Bool;\n}\n\nimpl PreferredBoolSqlType for &&bool {\n    type PreferredSqlType = sql_types::Bool;\n}\n\nimpl PreferredBoolSqlType for Option<bool> {\n    type PreferredSqlType = sql_types::Nullable<sql_types::Bool>;\n}\n\nimpl PreferredBoolSqlType for &Option<bool> {\n    type PreferredSqlType = sql_types::Nullable<sql_types::Bool>;\n}\n\nimpl PreferredBoolSqlType for &&Option<bool> {\n    type PreferredSqlType = sql_types::Nullable<sql_types::Bool>;\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "eed529c677beeb3d047a00a7405bd009236d83e4",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/diesel/src/expression/functions/date_and_time.rs",
    "func": "use crate::backend::Backend;\nuse crate::expression::coerce::Coerce;\nuse crate::expression::functions::define_sql_function;\nuse crate::expression::{AsExpression, Expression, ValidGrouping};\nuse crate::query_builder::*;\nuse crate::result::QueryResult;\nuse crate::sql_types::*;\n\n/// Represents the SQL `CURRENT_TIMESTAMP` constant. This is equivalent to the\n/// `NOW()` function on backends that support it.\n#[allow(non_camel_case_types)]\n#[derive(Debug, Copy, Clone, QueryId, ValidGrouping)]\npub struct now;\n\nimpl Expression for now {\n    type SqlType = Timestamp;\n}\n\nimpl<DB: Backend> QueryFragment<DB> for now {\n    fn walk_ast<'b>(&'b self, mut out: AstPass<'_, 'b, DB>) -> QueryResult<()> {\n        out.push_sql(\"CURRENT_TIMESTAMP\");\n        Ok(())\n    }\n}\n\nimpl_selectable_expression!(now);\n\noperator_allowed!(now, Add, add);\noperator_allowed!(now, Sub, sub);\ndefine_sql_function! {\n    /// Represents the SQL `DATE` function. The argument should be a Timestamp\n    /// expression, and the return value will be an expression of type Date.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # include!(\"../../doctest_setup.rs\");\n    /// # use diesel::dsl::{now, date};\n    /// # use diesel::deserialize::Queryable;\n    /// #\n    /// # fn test<R: Queryable<diesel::sql_types::Date, DB> + 'static>() -> QueryResult<R> {\n    /// #     let connection = &mut establish_connection();\n    /// let today = diesel::select(date(now)).first(connection)?;\n    /// #     Ok(today)\n    /// # }\n    /// # fn main() {\n    /// #\n    /// # }\n    /// ```\n    fn date(expr: Timestamp) -> Date;\n}\n\nimpl AsExpression<Nullable<Timestamp>> for now {\n    type Expression = Coerce<now, Nullable<Timestamp>>;\n\n    fn as_expression(self) -> Self::Expression {\n        Coerce::new(self)\n    }\n}\n\n#[cfg(feature = \"postgres_backend\")]\nimpl AsExpression<Timestamptz> for now {\n    type Expression = Coerce<now, Timestamptz>;\n\n    fn as_expression(self) -> Self::Expression {\n        Coerce::new(self)\n    }\n}\n\n#[cfg(feature = \"postgres_backend\")]\nimpl AsExpression<Nullable<Timestamptz>> for now {\n    type Expression = Coerce<now, Nullable<Timestamptz>>;\n\n    fn as_expression(self) -> Self::Expression {\n        Coerce::new(self)\n    }\n}\n\n#[cfg(feature = \"sqlite\")]\nimpl AsExpression<TimestamptzSqlite> for now {\n    type Expression = Coerce<now, TimestamptzSqlite>;\n\n    fn as_expression(self) -> Self::Expression {\n        Coerce::new(self)\n    }\n}\n\n#[cfg(feature = \"sqlite\")]\nimpl AsExpression<Nullable<TimestamptzSqlite>> for now {\n    type Expression = Coerce<now, Nullable<TimestamptzSqlite>>;\n\n    fn as_expression(self) -> Self::Expression {\n        Coerce::new(self)\n    }\n}\n\n/// Represents the SQL `CURRENT_DATE` constant.\n#[allow(non_camel_case_types)]\n#[derive(Debug, Copy, Clone, QueryId, ValidGrouping)]\npub struct today;\n\nimpl Expression for today {\n    type SqlType = Date;\n}\n\nimpl<DB: Backend> QueryFragment<DB> for today {\n    fn walk_ast<'b>(&'b self, mut out: AstPass<'_, 'b, DB>) -> QueryResult<()> {\n        out.push_sql(\"CURRENT_DATE\");\n        Ok(())\n    }\n}\n\nimpl_selectable_expression!(today);\n\noperator_allowed!(today, Add, add);\noperator_allowed!(today, Sub, sub);\n\nimpl AsExpression<Nullable<Date>> for today {\n    type Expression = Coerce<today, Nullable<Date>>;\n\n    fn as_expression(self) -> Self::Expression {\n        Coerce::new(self)\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "fa09e0ef466a1391b40aba7a2f007e2336a739af",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/diesel/src/expression/functions/helper_types.rs",
    "func": "#![allow(non_camel_case_types)]\n\nuse crate::dsl::SqlTypeOf;\nuse crate::expression::grouped::Grouped;\nuse crate::expression::operators;\n\n/// The return type of [`not(expr)`](crate::dsl::not())\npub type not<Expr> = operators::Not<Grouped<Expr>>;\n\n/// The return type of [`max(expr)`](crate::dsl::max())\npub type max<Expr> = super::aggregate_ordering::max<SqlTypeOf<Expr>, Expr>;\n\n/// The return type of [`min(expr)`](crate::dsl::min())\npub type min<Expr> = super::aggregate_ordering::min<SqlTypeOf<Expr>, Expr>;\n\n/// The return type of [`sum(expr)`](crate::dsl::sum())\npub type sum<Expr> = super::aggregate_folding::sum<SqlTypeOf<Expr>, Expr>;\n\n/// The return type of [`avg(expr)`](crate::dsl::avg())\npub type avg<Expr> = super::aggregate_folding::avg<SqlTypeOf<Expr>, Expr>;\n\n/// The return type of [`exists(expr)`](crate::dsl::exists())\npub type exists<Expr> = crate::expression::exists::Exists<Expr>;\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "f4aaad235f3fae9d4550fad3b285f52117a3b913",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/diesel/src/pg/metadata_lookup.rs",
    "func": "// FIXME: Remove this attribute once false positive is resolved.\n#![allow(unused_parens)]\n// conditionally allow deprecated items to allow using the\n// \"deprecated\" table! macro\n#![cfg_attr(\n    any(feature = \"huge-tables\", feature = \"large-tables\"),\n    allow(deprecated)\n)]\n\nuse super::backend::{FailedToLookupTypeError, InnerPgTypeMetadata};\nuse super::{Pg, PgTypeMetadata};\nuse crate::connection::{DefaultLoadingMode, LoadConnection};\nuse crate::prelude::*;\n\nuse std::borrow::Cow;\nuse std::collections::HashMap;\n\n/// Determines the OID of types at runtime\n///\n/// Custom implementations of `Connection<Backend = Pg>` should not implement this trait directly.\n/// Instead `GetPgMetadataCache` should be implemented, afterwards the generic implementation will provide\n/// the necessary functions to perform the type lookup.\n#[cfg(feature = \"postgres_backend\")]\npub trait PgMetadataLookup {\n    /// Determine the type metadata for the given `type_name`\n    ///\n    /// This function should only be used for user defined types, or types which\n    /// come from an extension. This function may perform a SQL query to look\n    /// up the type. For built-in types, a static OID should be preferred.\n    fn lookup_type(&mut self, type_name: &str, schema: Option<&str>) -> PgTypeMetadata;\n\n    /// Convert this lookup instance to a `std::any::Any` pointer\n    ///\n    /// Implementing this method is required to support `#[derive(MultiConnection)]`\n    // We provide a default implementation here, so that adding this method is no breaking\n    // change\n    #[diesel_derives::__diesel_public_if(\n        feature = \"i-implement-a-third-party-backend-and-opt-into-breaking-changes\"\n    )]\n    fn as_any<'a>(&mut self) -> &mut (dyn std::any::Any + 'a)\n    where\n        Self: 'a,\n    {\n        unimplemented!()\n    }\n}\n\nimpl<T> PgMetadataLookup for T\nwhere\n    T: Connection<Backend = Pg> + GetPgMetadataCache + LoadConnection<DefaultLoadingMode>,\n{\n    fn lookup_type(&mut self, type_name: &str, schema: Option<&str>) -> PgTypeMetadata {\n        let cache_key = PgMetadataCacheKey {\n            schema: schema.map(Cow::Borrowed),\n            type_name: Cow::Borrowed(type_name),\n        };\n\n        {\n            let metadata_cache = self.get_metadata_cache();\n\n            if let Some(metadata) = metadata_cache.lookup_type(&cache_key) {\n                return metadata;\n            }\n        }\n\n        let r = lookup_type(&cache_key, self);\n\n        match r {\n            Ok(type_metadata) => {\n                self.get_metadata_cache()\n                    .store_type(cache_key, type_metadata);\n                PgTypeMetadata(Ok(type_metadata))\n            }\n            Err(_e) => PgTypeMetadata(Err(FailedToLookupTypeError::new_internal(\n                cache_key.into_owned(),\n            ))),\n        }\n    }\n\n    fn as_any<'a>(&mut self) -> &mut (dyn std::any::Any + 'a)\n    where\n        Self: 'a,\n    {\n        self\n    }\n}\n\n/// Gets the `PgMetadataCache` for a `Connection<Backend=Pg>`\n/// so that the lookup of user defined types, or types which come from an extension can be cached.\n///\n/// Implementing this trait for a `Connection<Backend=Pg>` will cause `PgMetadataLookup` to be auto implemented.\n#[cfg_attr(\n    feature = \"i-implement-a-third-party-backend-and-opt-into-breaking-changes\",\n    cfg(feature = \"i-implement-a-third-party-backend-and-opt-into-breaking-changes\")\n)]\npub trait GetPgMetadataCache {\n    /// Get the `PgMetadataCache`\n    fn get_metadata_cache(&mut self) -> &mut PgMetadataCache;\n}\n\nfn lookup_type<T: Connection<Backend = Pg> + LoadConnection<DefaultLoadingMode>>(\n    cache_key: &PgMetadataCacheKey<'_>,\n    conn: &mut T,\n) -> QueryResult<InnerPgTypeMetadata> {\n    let metadata_query = pg_type::table.select((pg_type::oid, pg_type::typarray));\n\n    let metadata = if let Some(schema) = cache_key.schema.as_deref() {\n        // We have an explicit type name and schema given here\n        // that should resolve to an unique type\n        metadata_query\n            .inner_join(pg_namespace::table)\n            .filter(pg_type::typname.eq(&cache_key.type_name))\n            .filter(pg_namespace::nspname.eq(schema))\n            .first(conn)?\n    } else {\n        // We don't have a schema here. A type with the same name could exists\n        // in more than one schema at once, even in more than one schema that\n        // is in the current search path. As we don't want to reimplement\n        // postgres name resolution here we just cast the time name to a concrete type\n        // and let postgres figure out the name resolution on it's own.\n        metadata_query\n            .filter(\n                pg_type::oid.eq(crate::dsl::sql(\"quote_ident(\")\n                    .bind::<crate::sql_types::Text, _>(&cache_key.type_name)\n                    .sql(\")::regtype::oid\")),\n            )\n            .first(conn)?\n    };\n\n    Ok(metadata)\n}\n\n/// The key used to lookup cached type oid's inside of\n/// a [PgMetadataCache].\n#[derive(Hash, PartialEq, Eq, Debug, Clone)]\n#[cfg_attr(\n    feature = \"i-implement-a-third-party-backend-and-opt-into-breaking-changes\",\n    cfg(feature = \"i-implement-a-third-party-backend-and-opt-into-breaking-changes\")\n)]\npub struct PgMetadataCacheKey<'a> {\n    pub(in crate::pg) schema: Option<Cow<'a, str>>,\n    pub(in crate::pg) type_name: Cow<'a, str>,\n}\n\nimpl<'a> PgMetadataCacheKey<'a> {\n    /// Construct a new cache key from an optional schema name and\n    /// a type name\n    pub fn new(schema: Option<Cow<'a, str>>, type_name: Cow<'a, str>) -> Self {\n        Self { schema, type_name }\n    }\n\n    /// Convert the possibly borrowed version of this metadata cache key\n    /// into a lifetime independent owned version\n    pub fn into_owned(self) -> PgMetadataCacheKey<'static> {\n        let PgMetadataCacheKey { schema, type_name } = self;\n        PgMetadataCacheKey {\n            schema: schema.map(|s| Cow::Owned(s.into_owned())),\n            type_name: Cow::Owned(type_name.into_owned()),\n        }\n    }\n}\n\n/// Cache for the [OIDs] of custom Postgres types\n///\n/// [OIDs]: https://www.postgresql.org/docs/current/static/datatype-oid.html\n#[allow(missing_debug_implementations)]\n#[derive(Default)]\n#[cfg_attr(\n    feature = \"i-implement-a-third-party-backend-and-opt-into-breaking-changes\",\n    cfg(feature = \"i-implement-a-third-party-backend-and-opt-into-breaking-changes\")\n)]\npub struct PgMetadataCache {\n    cache: HashMap<PgMetadataCacheKey<'static>, InnerPgTypeMetadata>,\n}\n\nimpl PgMetadataCache {\n    /// Construct a new `PgMetadataCache`\n    pub fn new() -> Self {\n        Default::default()\n    }\n\n    /// Lookup the OID of a custom type\n    pub fn lookup_type(&self, type_name: &PgMetadataCacheKey<'_>) -> Option<PgTypeMetadata> {\n        Some(PgTypeMetadata(Ok(*self.cache.get(type_name)?)))\n    }\n\n    /// Store the OID of a custom type\n    pub fn store_type(\n        &mut self,\n        type_name: PgMetadataCacheKey<'_>,\n        type_metadata: impl Into<InnerPgTypeMetadata>,\n    ) {\n        self.cache\n            .insert(type_name.into_owned(), type_metadata.into());\n    }\n}\n\ntable! {\n    pg_type (oid) {\n        oid -> Oid,\n        typname -> Text,\n        typarray -> Oid,\n        typnamespace -> Oid,\n    }\n}\n\ntable! {\n    pg_namespace (oid) {\n        oid -> Oid,\n        nspname -> Text,\n    }\n}\n\njoinable!(pg_type -> pg_namespace(typnamespace));\nallow_tables_to_appear_in_same_query!(pg_type, pg_namespace);\n\ndefine_sql_function! { fn pg_my_temp_schema() -> Oid; }\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "35e6fa89fca464785e3f58a40e9ef5b8101973ee",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/diesel/src/pg/expression/date_and_time.rs",
    "func": "use crate::expression::{Expression, ValidGrouping};\nuse crate::pg::Pg;\nuse crate::query_builder::*;\nuse crate::result::QueryResult;\nuse crate::sql_types::{is_nullable, Date, Nullable, SqlType, Timestamp, Timestamptz, VarChar};\n\n/// Marker trait for types which are valid in `AT TIME ZONE` expressions\npub trait DateTimeLike {}\nimpl DateTimeLike for Date {}\nimpl DateTimeLike for Timestamp {}\nimpl DateTimeLike for Timestamptz {}\nimpl<T> DateTimeLike for Nullable<T> where T: SqlType<IsNull = is_nullable::NotNull> + DateTimeLike {}\n#[derive(Debug, Copy, Clone, QueryId, ValidGrouping)]\npub struct AtTimeZone<Ts, Tz> {\n    timestamp: Ts,\n    timezone: Tz,\n}\n\nimpl<Ts, Tz> AtTimeZone<Ts, Tz> {\n    pub fn new(timestamp: Ts, timezone: Tz) -> Self {\n        AtTimeZone {\n            timestamp: timestamp,\n            timezone: timezone,\n        }\n    }\n}\n\nimpl<Ts, Tz> Expression for AtTimeZone<Ts, Tz>\nwhere\n    Ts: Expression,\n    Ts::SqlType: DateTimeLike,\n    Tz: Expression<SqlType = VarChar>,\n{\n    type SqlType = Timestamp;\n}\n\nimpl<Ts, Tz> QueryFragment<Pg> for AtTimeZone<Ts, Tz>\nwhere\n    Ts: QueryFragment<Pg>,\n    Tz: QueryFragment<Pg>,\n{\n    fn walk_ast<'b>(&'b self, mut out: AstPass<'_, 'b, Pg>) -> QueryResult<()> {\n        self.timestamp.walk_ast(out.reborrow())?;\n        out.push_sql(\" AT TIME ZONE \");\n        self.timezone.walk_ast(out.reborrow())?;\n        Ok(())\n    }\n}\n\nimpl_selectable_expression!(AtTimeZone<Ts, Tz>);\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "dc555bc51db1fd879d53dac1c8418a7fd21a4da4",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/diesel/src/pg/types/mac_addr.rs",
    "func": "use std::io::prelude::*;\n\nuse crate::deserialize::{self, FromSql};\nuse crate::pg::{Pg, PgValue};\nuse crate::serialize::{self, IsNull, Output, ToSql};\nuse crate::sql_types::MacAddr;\n\n#[allow(dead_code)]\nmod foreign_derives {\n    use super::*;\n    use crate::deserialize::FromSqlRow;\n    use crate::expression::AsExpression;\n\n    #[derive(AsExpression, FromSqlRow)]\n    #[diesel(foreign_derive)]\n    #[diesel(sql_type = MacAddr)]\n    struct ByteArrayProxy([u8; 6]);\n}\n\n#[cfg(feature = \"postgres_backend\")]\nimpl FromSql<MacAddr, Pg> for [u8; 6] {\n    fn from_sql(value: PgValue<'_>) -> deserialize::Result<Self> {\n        value\n            .as_bytes()\n            .try_into()\n            .map_err(|_| \"invalid network address format: input isn't 6 bytes.\".into())\n    }\n}\n\n#[cfg(feature = \"postgres_backend\")]\nimpl ToSql<MacAddr, Pg> for [u8; 6] {\n    fn to_sql<'b>(&'b self, out: &mut Output<'b, '_, Pg>) -> serialize::Result {\n        out.write_all(&self[..])\n            .map(|_| IsNull::No)\n            .map_err(Into::into)\n    }\n}\n\n#[test]\nfn macaddr_roundtrip() {\n    use crate::query_builder::bind_collector::ByteWrapper;\n\n    let mut buffer = Vec::new();\n    let mut bytes = Output::test(ByteWrapper(&mut buffer));\n    let input_address = [0x52, 0x54, 0x00, 0xfb, 0xc6, 0x16];\n    ToSql::<MacAddr, Pg>::to_sql(&input_address, &mut bytes).unwrap();\n    let output_address: [u8; 6] = FromSql::from_sql(PgValue::for_test(&buffer)).unwrap();\n    assert_eq!(input_address, output_address);\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "7f0e4a618d44c2267b7d87f3358b519431d92bb6",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/diesel/src/pg/query_builder/limit_offset.rs",
    "func": "use crate::pg::Pg;\nuse crate::query_builder::limit_offset_clause::{BoxedLimitOffsetClause, LimitOffsetClause};\nuse crate::query_builder::{AstPass, IntoBoxedClause, QueryFragment};\nuse crate::result::QueryResult;\n\nimpl<'a, L, O> IntoBoxedClause<'a, Pg> for LimitOffsetClause<L, O>\nwhere\n    L: QueryFragment<Pg> + Send + 'a,\n    O: QueryFragment<Pg> + Send + 'a,\n{\n    type BoxedClause = BoxedLimitOffsetClause<'a, Pg>;\n\n    fn into_boxed(self) -> Self::BoxedClause {\n        BoxedLimitOffsetClause {\n            limit: Some(Box::new(self.limit_clause)),\n            offset: Some(Box::new(self.offset_clause)),\n        }\n    }\n}\n\nimpl QueryFragment<Pg> for BoxedLimitOffsetClause<'_, Pg> {\n    fn walk_ast<'b>(&'b self, mut out: AstPass<'_, 'b, Pg>) -> QueryResult<()> {\n        if let Some(ref limit) = self.limit {\n            limit.walk_ast(out.reborrow())?;\n        }\n        if let Some(ref offset) = self.offset {\n            offset.walk_ast(out.reborrow())?;\n        }\n        Ok(())\n    }\n}\n\nimpl<L, O> QueryFragment<Pg> for LimitOffsetClause<L, O>\nwhere\n    L: QueryFragment<Pg>,\n    O: QueryFragment<Pg>,\n{\n    fn walk_ast<'b>(&'b self, mut out: AstPass<'_, 'b, Pg>) -> QueryResult<()> {\n        self.limit_clause.walk_ast(out.reborrow())?;\n        self.offset_clause.walk_ast(out.reborrow())?;\n        Ok(())\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "ca72e4ac31e8ef6cb9f60b0681cee650f33433e1",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/diesel/src/pg/query_builder/copy/copy_from.rs",
    "func": "use std::borrow::Cow;\nuse std::marker::PhantomData;\n\nuse byteorder::NetworkEndian;\nuse byteorder::WriteBytesExt;\n\nuse super::CommonOptions;\nuse super::CopyFormat;\nuse super::CopyTarget;\nuse crate::expression::bound::Bound;\nuse crate::insertable::ColumnInsertValue;\nuse crate::pg::backend::FailedToLookupTypeError;\nuse crate::pg::metadata_lookup::PgMetadataCacheKey;\nuse crate::pg::Pg;\nuse crate::pg::PgMetadataLookup;\nuse crate::query_builder::BatchInsert;\nuse crate::query_builder::QueryFragment;\nuse crate::query_builder::QueryId;\nuse crate::query_builder::ValuesClause;\nuse crate::serialize::IsNull;\nuse crate::serialize::ToSql;\nuse crate::Connection;\nuse crate::Insertable;\nuse crate::QueryResult;\nuse crate::{Column, Table};\n\n/// Describes the different possible settings for the `HEADER` option\n/// for `COPY FROM` statements\n#[derive(Debug, Copy, Clone)]\npub enum CopyHeader {\n    /// Is the header set?\n    Set(bool),\n    /// Match the header with the targeted table names\n    /// and fail in the case of a mismatch\n    Match,\n}\n\n#[derive(Debug, Default)]\npub struct CopyFromOptions {\n    common: CommonOptions,\n    default: Option<String>,\n    header: Option<CopyHeader>,\n}\n\nimpl QueryFragment<Pg> for CopyFromOptions {\n    fn walk_ast<'b>(\n        &'b self,\n        mut pass: crate::query_builder::AstPass<'_, 'b, Pg>,\n    ) -> crate::QueryResult<()> {\n        if self.any_set() {\n            let mut comma = \"\";\n            pass.push_sql(\" WITH (\");\n            self.common.walk_ast(pass.reborrow(), &mut comma);\n            if let Some(ref default) = self.default {\n                pass.push_sql(comma);\n                comma = \", \";\n                pass.push_sql(\"DEFAULT '\");\n                // cannot use binds here :(\n                pass.push_sql(default);\n                pass.push_sql(\"'\");\n            }\n            if let Some(ref header) = self.header {\n                pass.push_sql(comma);\n                // commented out because rustc complains otherwise\n                //comma = \", \";\n                pass.push_sql(\"HEADER \");\n                match header {\n                    CopyHeader::Set(true) => pass.push_sql(\"1\"),\n                    CopyHeader::Set(false) => pass.push_sql(\"0\"),\n                    CopyHeader::Match => pass.push_sql(\"MATCH\"),\n                }\n            }\n\n            pass.push_sql(\")\");\n        }\n        Ok(())\n    }\n}\n\nimpl CopyFromOptions {\n    fn any_set(&self) -> bool {\n        self.common.any_set() || self.default.is_some() || self.header.is_some()\n    }\n}\n\n#[derive(Debug)]\npub struct CopyFrom<S, F> {\n    options: CopyFromOptions,\n    copy_callback: F,\n    p: PhantomData<S>,\n}\n\npub(crate) struct InternalCopyFromQuery<S, T> {\n    pub(crate) target: S,\n    p: PhantomData<T>,\n}\n\n#[cfg(feature = \"postgres\")]\nimpl<S, T> InternalCopyFromQuery<S, T> {\n    pub(crate) fn new(target: S) -> Self {\n        Self {\n            target,\n            p: PhantomData,\n        }\n    }\n}\n\nimpl<S, T> QueryId for InternalCopyFromQuery<S, T>\nwhere\n    S: CopyFromExpression<T>,\n{\n    const HAS_STATIC_QUERY_ID: bool = false;\n    type QueryId = ();\n}\n\nimpl<S, T> QueryFragment<Pg> for InternalCopyFromQuery<S, T>\nwhere\n    S: CopyFromExpression<T>,\n{\n    fn walk_ast<'b>(\n        &'b self,\n        mut pass: crate::query_builder::AstPass<'_, 'b, Pg>,\n    ) -> crate::QueryResult<()> {\n        pass.unsafe_to_cache_prepared();\n        pass.push_sql(\"COPY \");\n        self.target.walk_target(pass.reborrow())?;\n        pass.push_sql(\" FROM STDIN\");\n        self.target.options().walk_ast(pass.reborrow())?;\n        Ok(())\n    }\n}\n\npub trait CopyFromExpression<T> {\n    type Error: From<crate::result::Error> + std::error::Error;\n\n    fn callback(&mut self, copy: &mut impl std::io::Write) -> Result<(), Self::Error>;\n\n    fn walk_target<'b>(\n        &'b self,\n        pass: crate::query_builder::AstPass<'_, 'b, Pg>,\n    ) -> crate::QueryResult<()>;\n\n    fn options(&self) -> &CopyFromOptions;\n}\n\nimpl<S, F, E> CopyFromExpression<S::Table> for CopyFrom<S, F>\nwhere\n    E: From<crate::result::Error> + std::error::Error,\n    S: CopyTarget,\n    F: Fn(&mut dyn std::io::Write) -> Result<(), E>,\n{\n    type Error = E;\n\n    fn callback(&mut self, copy: &mut impl std::io::Write) -> Result<(), Self::Error> {\n        (self.copy_callback)(copy)\n    }\n\n    fn options(&self) -> &CopyFromOptions {\n        &self.options\n    }\n\n    fn walk_target<'b>(\n        &'b self,\n        pass: crate::query_builder::AstPass<'_, 'b, Pg>,\n    ) -> crate::QueryResult<()> {\n        S::walk_target(pass)\n    }\n}\n\nstruct Dummy;\n\nimpl PgMetadataLookup for Dummy {\n    fn lookup_type(&mut self, type_name: &str, schema: Option<&str>) -> crate::pg::PgTypeMetadata {\n        let cache_key = PgMetadataCacheKey::new(\n            schema.map(Into::into).map(Cow::Owned),\n            Cow::Owned(type_name.into()),\n        );\n        crate::pg::PgTypeMetadata(Err(FailedToLookupTypeError::new_internal(cache_key)))\n    }\n}\n\ntrait CopyFromInsertableHelper {\n    type Target: CopyTarget;\n    const COLUMN_COUNT: i16;\n\n    fn write_to_buffer(&self, idx: i16, out: &mut Vec<u8>) -> QueryResult<IsNull>;\n}\n\nmacro_rules! impl_copy_from_insertable_helper_for_values_clause {\n    ($(\n        $Tuple:tt {\n            $(($idx:tt) -> $T:ident, $ST:ident, $TT:ident,)+\n        }\n    )+) => {\n        $(\n            impl<T, $($ST,)* $($T,)* $($TT,)*> CopyFromInsertableHelper for ValuesClause<\n                ($(ColumnInsertValue<$ST, Bound<$T, $TT>>,)*),\n            T>\n                where\n                T: Table,\n                $($ST: Column<Table = T>,)*\n                ($($ST,)*): CopyTarget,\n                $($TT: ToSql<$T, Pg>,)*\n            {\n                type Target = ($($ST,)*);\n\n                // statically known to always fit\n                // as we don't support more than 128 columns\n                #[allow(clippy::cast_possible_truncation)]\n                const COLUMN_COUNT: i16 = $Tuple as i16;\n\n                fn write_to_buffer(&self, idx: i16, out: &mut Vec<u8>) -> QueryResult<IsNull> {\n                    use crate::query_builder::ByteWrapper;\n                    use crate::serialize::Output;\n\n                    let values = &self.values;\n                    match idx {\n                        $($idx =>{\n                            let item = &values.$idx.expr.item;\n                            let is_null = ToSql::<$T, Pg>::to_sql(\n                                item,\n                                &mut Output::new( ByteWrapper(out), &mut Dummy as _)\n                            ).map_err(crate::result::Error::SerializationError)?;\n                            return Ok(is_null);\n                        })*\n                        _ => unreachable!(),\n                    }\n                }\n            }\n\n            impl<'a, T, $($ST,)* $($T,)* $($TT,)*> CopyFromInsertableHelper for ValuesClause<\n                ($(ColumnInsertValue<$ST, &'a Bound<$T, $TT>>,)*),\n            T>\n                where\n                T: Table,\n                $($ST: Column<Table = T>,)*\n                ($($ST,)*): CopyTarget,\n                $($TT: ToSql<$T, Pg>,)*\n            {\n                type Target = ($($ST,)*);\n\n                // statically known to always fit\n                // as we don't support more than 128 columns\n                #[allow(clippy::cast_possible_truncation)]\n                const COLUMN_COUNT: i16 = $Tuple as i16;\n\n                fn write_to_buffer(&self, idx: i16, out: &mut Vec<u8>) -> QueryResult<IsNull> {\n                    use crate::query_builder::ByteWrapper;\n                    use crate::serialize::Output;\n\n                    let values = &self.values;\n                    match idx {\n                        $($idx =>{\n                            let item = &values.$idx.expr.item;\n                            let is_null = ToSql::<$T, Pg>::to_sql(\n                                item,\n                                &mut Output::new( ByteWrapper(out), &mut Dummy as _)\n                            ).map_err(crate::result::Error::SerializationError)?;\n                            return Ok(is_null);\n                        })*\n                        _ => unreachable!(),\n                    }\n                }\n            }\n        )*\n    }\n}\n\ndiesel_derives::__diesel_for_each_tuple!(impl_copy_from_insertable_helper_for_values_clause);\n\n#[derive(Debug)]\npub struct InsertableWrapper<I>(Option<I>);\n\nimpl<I, T, V, QId, const STATIC_QUERY_ID: bool> CopyFromExpression<T> for InsertableWrapper<I>\nwhere\n    I: Insertable<T, Values = BatchInsert<Vec<V>, T, QId, STATIC_QUERY_ID>>,\n    V: CopyFromInsertableHelper,\n{\n    type Error = crate::result::Error;\n\n    fn callback(&mut self, copy: &mut impl std::io::Write) -> Result<(), Self::Error> {\n        let io_result_mapper = |e| crate::result::Error::DeserializationError(Box::new(e));\n        // see https://www.postgresql.org/docs/current/sql-copy.html for\n        // a description of the binary format\n        //\n        // We don't write oids\n\n        // write the header\n        copy.write_all(&super::COPY_MAGIC_HEADER)\n            .map_err(io_result_mapper)?;\n        copy.write_i32::<NetworkEndian>(0)\n            .map_err(io_result_mapper)?;\n        copy.write_i32::<NetworkEndian>(0)\n            .map_err(io_result_mapper)?;\n        // write the data\n        // we reuse the same buffer here again and again\n        // as we expect the data to be \"similar\"\n        // this skips reallocating\n        let mut buffer = Vec::<u8>::new();\n        let values = self\n            .0\n            .take()\n            .expect(\"We only call this callback once\")\n            .values();\n        for i in values.values {\n            // column count\n            buffer\n                .write_i16::<NetworkEndian>(V::COLUMN_COUNT)\n                .map_err(io_result_mapper)?;\n            for idx in 0..V::COLUMN_COUNT {\n                // first write the null indicator as dummy value\n                buffer\n                    .write_i32::<NetworkEndian>(-1)\n                    .map_err(io_result_mapper)?;\n                let len_before = buffer.len();\n                let is_null = i.write_to_buffer(idx, &mut buffer)?;\n                if is_null == IsNull::No {\n                    // fill in the length afterwards\n                    let len_after = buffer.len();\n                    let diff = (len_after - len_before)\n                        .try_into()\n                        .map_err(|e| crate::result::Error::SerializationError(Box::new(e)))?;\n                    let bytes = i32::to_be_bytes(diff);\n                    for (b, t) in bytes.into_iter().zip(&mut buffer[len_before - 4..]) {\n                        *t = b;\n                    }\n                }\n            }\n            copy.write_all(&buffer).map_err(io_result_mapper)?;\n            buffer.clear();\n        }\n        // write the trailer\n        copy.write_i16::<NetworkEndian>(-1)\n            .map_err(io_result_mapper)?;\n        Ok(())\n    }\n\n    fn options(&self) -> &CopyFromOptions {\n        &CopyFromOptions {\n            common: CommonOptions {\n                format: Some(CopyFormat::Binary),\n                freeze: None,\n                delimiter: None,\n                null: None,\n                quote: None,\n                escape: None,\n            },\n            default: None,\n            header: None,\n        }\n    }\n\n    fn walk_target<'b>(\n        &'b self,\n        pass: crate::query_builder::AstPass<'_, 'b, Pg>,\n    ) -> crate::QueryResult<()> {\n        <V as CopyFromInsertableHelper>::Target::walk_target(pass)\n    }\n}\n\n/// The structure returned by [`copy_from`]\n///\n/// The [`from_raw_data`] and the [`from_insertable`] methods allow\n/// to configure the data copied into the database\n///\n/// The `with_*` methods allow to configure the settings used for the\n/// copy statement.\n///\n/// [`from_raw_data`]: CopyFromQuery::from_raw_data\n/// [`from_insertable`]: CopyFromQuery::from_insertable\n#[derive(Debug)]\n#[must_use = \"`COPY FROM` statements are only executed when calling `.execute()`.\"]\n#[cfg(feature = \"postgres_backend\")]\npub struct CopyFromQuery<T, Action> {\n    table: T,\n    action: Action,\n}\n\nimpl<T> CopyFromQuery<T, NotSet>\nwhere\n    T: Table,\n{\n    /// Copy data into the database by directly providing the data in the corresponding format\n    ///\n    /// `target` specifies the column selection that is the target of the `COPY FROM` statement\n    /// `action` expects a callback which accepts a [`std::io::Write`] argument. The necessary format\n    /// accepted by this writer sink depends on the options provided via the `with_*` methods\n    #[allow(clippy::wrong_self_convention)] // the sql struct is named that way\n    pub fn from_raw_data<F, C, E>(self, _target: C, action: F) -> CopyFromQuery<T, CopyFrom<C, F>>\n    where\n        C: CopyTarget<Table = T>,\n        F: Fn(&mut dyn std::io::Write) -> Result<(), E>,\n    {\n        CopyFromQuery {\n            table: self.table,\n            action: CopyFrom {\n                p: PhantomData,\n                options: Default::default(),\n                copy_callback: action,\n            },\n        }\n    }\n\n    /// Copy a set of insertable values into the database.\n    ///\n    /// The `insertable` argument is expected to be a `Vec<I>`, `&[I]` or similar, where `I`\n    /// needs to implement `Insertable<T>`. If you use the [`#[derive(Insertable)]`](derive@crate::prelude::Insertable)\n    /// derive macro make sure to also set the `#[diesel(treat_none_as_default_value = false)]` option\n    /// to disable the default value handling otherwise implemented by `#[derive(Insertable)]`.\n    ///\n    /// This uses the binary format. It internally configures the correct\n    /// set of settings and does not allow to set other options\n    #[allow(clippy::wrong_self_convention)] // the sql struct is named that way\n    pub fn from_insertable<I>(self, insertable: I) -> CopyFromQuery<T, InsertableWrapper<I>>\n    where\n        InsertableWrapper<I>: CopyFromExpression<T>,\n    {\n        CopyFromQuery {\n            table: self.table,\n            action: InsertableWrapper(Some(insertable)),\n        }\n    }\n}\n\nimpl<T, C, F> CopyFromQuery<T, CopyFrom<C, F>> {\n    /// The format used for the copy statement\n    ///\n    /// See the [PostgreSQL documentation](https://www.postgresql.org/docs/current/sql-copy.html)\n    /// for more details.\n    pub fn with_format(mut self, format: CopyFormat) -> Self {\n        self.action.options.common.format = Some(format);\n        self\n    }\n\n    /// Whether or not the `freeze` option is set\n    ///\n    /// See the [PostgreSQL documentation](https://www.postgresql.org/docs/current/sql-copy.html)\n    /// for more details.\n    pub fn with_freeze(mut self, freeze: bool) -> Self {\n        self.action.options.common.freeze = Some(freeze);\n        self\n    }\n\n    /// Which delimiter should be used for textual input formats\n    ///\n    /// See the [PostgreSQL documentation](https://www.postgresql.org/docs/current/sql-copy.html)\n    /// for more details.\n    pub fn with_delimiter(mut self, delimiter: char) -> Self {\n        self.action.options.common.delimiter = Some(delimiter);\n        self\n    }\n\n    /// Which string should be used in place of a `NULL` value\n    /// for textual input formats\n    ///\n    /// See the [PostgreSQL documentation](https://www.postgresql.org/docs/current/sql-copy.html)\n    /// for more details.\n    pub fn with_null(mut self, null: impl Into<String>) -> Self {\n        self.action.options.common.null = Some(null.into());\n        self\n    }\n\n    /// Which quote character should be used for textual input formats\n    ///\n    /// See the [PostgreSQL documentation](https://www.postgresql.org/docs/current/sql-copy.html)\n    /// for more details.\n    pub fn with_quote(mut self, quote: char) -> Self {\n        self.action.options.common.quote = Some(quote);\n        self\n    }\n\n    /// Which escape character should be used for textual input formats\n    ///\n    /// See the [PostgreSQL documentation](https://www.postgresql.org/docs/current/sql-copy.html)\n    /// for more details.\n    pub fn with_escape(mut self, escape: char) -> Self {\n        self.action.options.common.escape = Some(escape);\n        self\n    }\n\n    /// Which string should be used to indicate that\n    /// the `default` value should be used in place of that string\n    /// for textual formats\n    ///\n    /// See the [PostgreSQL documentation](https://www.postgresql.org/docs/current/sql-copy.html)\n    /// for more details.\n    ///\n    /// (This parameter was added with PostgreSQL 16)\n    pub fn with_default(mut self, default: impl Into<String>) -> Self {\n        self.action.options.default = Some(default.into());\n        self\n    }\n\n    /// Is a header provided as part of the textual input or not\n    ///\n    /// See the [PostgreSQL documentation](https://www.postgresql.org/docs/current/sql-copy.html)\n    /// for more details.\n    pub fn with_header(mut self, header: CopyHeader) -> Self {\n        self.action.options.header = Some(header);\n        self\n    }\n}\n\n/// A custom execute function tailored for `COPY FROM` statements\n///\n/// This trait can be used to execute `COPY FROM` queries constructed\n/// via [`copy_from]`\npub trait ExecuteCopyFromDsl<C>\nwhere\n    C: Connection<Backend = Pg>,\n{\n    /// The error type returned by the execute function\n    type Error: std::error::Error;\n\n    /// See the trait documentation for details\n    fn execute(self, conn: &mut C) -> Result<usize, Self::Error>;\n}\n\n#[cfg(feature = \"postgres\")]\nimpl<T, A> ExecuteCopyFromDsl<crate::PgConnection> for CopyFromQuery<T, A>\nwhere\n    A: CopyFromExpression<T>,\n{\n    type Error = A::Error;\n\n    fn execute(self, conn: &mut crate::PgConnection) -> Result<usize, A::Error> {\n        conn.copy_from::<A, T>(self.action)\n    }\n}\n\n#[cfg(feature = \"r2d2\")]\nimpl<T, A, C> ExecuteCopyFromDsl<crate::r2d2::PooledConnection<crate::r2d2::ConnectionManager<C>>>\n    for CopyFromQuery<T, A>\nwhere\n    A: CopyFromExpression<T>,\n    C: crate::r2d2::R2D2Connection<Backend = Pg> + 'static,\n    Self: ExecuteCopyFromDsl<C>,\n{\n    type Error = <Self as ExecuteCopyFromDsl<C>>::Error;\n\n    fn execute(\n        self,\n        conn: &mut crate::r2d2::PooledConnection<crate::r2d2::ConnectionManager<C>>,\n    ) -> Result<usize, Self::Error> {\n        self.execute(&mut **conn)\n    }\n}\n\n#[derive(Debug, Clone, Copy)]\npub struct NotSet;\n\n/// Creates a `COPY FROM` statement\n///\n/// This function constructs `COPY FROM` statement which copies data\n/// *from* a source into the database. It's designed to move larger\n/// amounts of data into the database.\n///\n/// This function accepts a target table as argument.\n///\n/// There are two ways to construct a `COPY FROM` statement with\n/// diesel:\n///\n/// * By providing a `Vec<I>` where `I` implements `Insertable` for the\n///   given table\n/// * By providing a target selection (column list or table name)\n///   and a callback that provides the data\n///\n/// The first variant uses the `BINARY` format internally to send\n/// the provided data efficiently to the database. It automatically\n/// sets the right options and does not allow changing them.\n/// Use [`CopyFromQuery::from_insertable`] for this.\n///\n/// The second variant allows you to control the behaviour\n/// of the generated `COPY FROM` statement in detail. It can\n/// be setup via the [`CopyFromQuery::from_raw_data`] function.\n/// The callback accepts an opaque object as argument that allows\n/// to write the corresponding data to the database. The exact\n/// format depends on the settings chosen by the various\n/// `CopyFromQuery::with_*` methods. See\n/// [the postgresql documentation](https://www.postgresql.org/docs/current/sql-copy.html)\n/// for more details about the expected formats.\n///\n/// If you don't have any specific needs you should prefer\n/// using the more convenient first variant.\n///\n/// This functionality is postgresql specific.\n///\n/// # Examples\n///\n/// ## Via [`CopyFromQuery::from_insertable`]\n///\n/// ```rust\n/// # include!(\"../../../doctest_setup.rs\");\n/// # use crate::schema::users;\n///\n/// #[derive(Insertable)]\n/// #[diesel(table_name = users)]\n/// #[diesel(treat_none_as_default_value = false)]\n/// struct NewUser {\n///     name: &'static str,\n/// }\n///\n/// # fn run_test() -> QueryResult<()> {\n/// # let connection = &mut establish_connection();\n///\n/// let data = vec![\n///     NewUser { name: \"Diva Plavalaguna\" },\n///     NewUser { name: \"Father Vito Cornelius\" },\n/// ];\n///\n/// let count = diesel::copy_from(users::table)\n///     .from_insertable(&data)\n///     .execute(connection)?;\n///\n/// assert_eq!(count, 2);\n/// # Ok(())\n/// # }\n/// # fn main() {\n/// #    run_test().unwrap();\n/// # }\n/// ```\n///\n/// ## Via [`CopyFromQuery::from_raw_data`]\n///\n/// ```rust\n/// # include!(\"../../../doctest_setup.rs\");\n/// # fn run_test() -> QueryResult<()> {\n/// # use crate::schema::users;\n/// use diesel::pg::CopyFormat;\n/// # let connection = &mut establish_connection();\n/// let count = diesel::copy_from(users::table)\n///     .from_raw_data(users::table, |copy| {\n///         writeln!(copy, \"3,Diva Plavalaguna\").unwrap();\n///         writeln!(copy, \"4,Father Vito Cornelius\").unwrap();\n///         diesel::QueryResult::Ok(())\n///     })\n///     .with_format(CopyFormat::Csv)\n///     .execute(connection)?;\n///\n/// assert_eq!(count, 2);\n/// # Ok(())\n/// # }\n/// # fn main() {\n/// #    run_test().unwrap();\n/// # }\n/// ```\n#[cfg(feature = \"postgres_backend\")]\npub fn copy_from<T>(table: T) -> CopyFromQuery<T, NotSet>\nwhere\n    T: Table,\n{\n    CopyFromQuery {\n        table,\n        action: NotSet,\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "664889df555e241e9a0556ae49302e10c3bd7b21",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/diesel/src/query_source/mod.rs",
    "func": "//! Types related to describing schema, and interactions between tables.\n//!\n//! Most traits in this module are derived or generated by [`table!`].\n//!\n//! [`table!`]: crate::table!\n\npub(crate) mod aliasing;\npub(crate) mod joins;\nmod peano_numbers;\n\nuse crate::expression::{Expression, SelectableExpression, ValidGrouping};\nuse crate::query_builder::*;\n\npub use self::aliasing::{Alias, AliasSource, AliasedField};\npub use self::joins::JoinTo;\npub use self::peano_numbers::*;\npub(crate) use self::private::Pick;\n\n/// Represents a type which can appear in the `FROM` clause. Apps should not\n/// need to concern themselves with this trait.\n///\n/// Types which implement this trait include:\n/// - Tables generated by the `table!` macro\n/// - Internal structs which represent joins\n/// - A select statement which has had no query builder methods called on it,\n///   other than those which can affect the from clause.\npub trait QuerySource {\n    /// The type returned by `from_clause`\n    type FromClause;\n    /// The type returned by `default_selection`\n    type DefaultSelection: SelectableExpression<Self>;\n\n    /// The actual `FROM` clause of this type. This is typically only called in\n    /// `QueryFragment` implementations.\n    // from here is something different than from in rust\n    // as this literally refers to SQL from.\n    #[allow(clippy::wrong_self_convention)]\n    fn from_clause(&self) -> Self::FromClause;\n    /// The default select clause of this type, which should be used if no\n    /// select clause was explicitly specified. This should always be a tuple of\n    /// all the desired columns, not `star`\n    fn default_selection(&self) -> Self::DefaultSelection;\n}\n\n/// A column on a database table. Types which implement this trait should have\n/// been generated by the [`table!` macro](crate::table!).\npub trait Column: Expression {\n    /// The table which this column belongs to\n    type Table: Table;\n\n    /// The name of this column\n    const NAME: &'static str;\n}\n\n/// A SQL database table. Types which implement this trait should have been\n/// generated by the [`table!` macro](crate::table!).\npub trait Table: QuerySource + AsQuery + Sized {\n    /// The type returned by `primary_key`\n    type PrimaryKey: SelectableExpression<Self> + ValidGrouping<()>;\n    /// The type returned by `all_columns`\n    type AllColumns: SelectableExpression<Self> + ValidGrouping<()>;\n\n    /// Returns the primary key of this table.\n    ///\n    /// If the table has a composite primary key, this will be a tuple.\n    fn primary_key(&self) -> Self::PrimaryKey;\n    /// Returns a tuple of all columns belonging to this table.\n    fn all_columns() -> Self::AllColumns;\n}\n\n/// Determines how many times `Self` appears in `QS`\n///\n/// This trait is primarily used to determine whether or not a column is\n/// selectable from a given from clause. A column can be selected if its table\n/// appears in the from clause *exactly once*.\n///\n/// We do not allow the same table to appear in a query multiple times in any\n/// context where referencing that table would be ambiguous (depending on the\n/// context and backend being used, this may or may not be something that would\n/// otherwise result in a runtime error).\n#[diagnostic::on_unimplemented(\n    note = \"double check that `{QS}` and `{Self}` appear in the same `allow_tables_to_appear_in_same_query!` \\ncall if both are tables\",\n    note = \"double check that any two aliases to the same table in `{QS}` and `{Self}` appear in the same `alias!` call\"\n)]\npub trait AppearsInFromClause<QS> {\n    /// How many times does `Self` appear in `QS`?\n    type Count;\n}\n\n/// Allows Diesel to implement some internal traits for two tables that are distinct.\n///\n/// (Notably, a bunch of [`AppearsInFromClause`] for the tables and their aliases.)\n///\n/// This trait is implemented by the [`allow_tables_to_appear_in_same_query!`] macro.\n///\n/// Troubleshooting\n/// ---------------\n/// If you encounter an error mentioning this trait, it could mean that either:\n/// - You are attempting to use tables that don't belong to the same database together\n///   (no call to [`allow_tables_to_appear_in_same_query!`] was made)\n/// - You are attempting to use two aliases to the same table in the same query, but they\n///   were declared through different calls to [`alias!`](crate::alias)\n#[diagnostic::on_unimplemented(\n    note = \"double check that `{T}` and `{Self}` appear in the same `allow_tables_to_appear_in_same_query!` \\ncall if both are tables\"\n)]\npub trait TableNotEqual<T: Table>: Table {}\n\nimpl<T1, T2> AppearsInFromClause<T2> for T1\nwhere\n    T1: TableNotEqual<T2> + Table,\n    T2: Table,\n{\n    type Count = Never;\n}\n\npub(crate) mod private {\n    use super::{Never, Once};\n\n    /// Used to determine which of two from clauses contains a given table.\n    ///\n    /// This trait can be used to emulate \"or\" conditions in where clauses when\n    /// we want a trait to be implemented with one of two type parameters.\n    ///\n    /// For example, if we wanted to write:\n    ///\n    /// ```rust,ignore\n    /// where\n    ///     T: SelectableExpression<Left> | SelectableExpression<Right>,\n    /// ```\n    ///\n    /// we can emulate this by writing:\n    ///\n    /// ```rust,ignore\n    /// where\n    ///     Left: AppearsInFromClause<T::Table>,\n    ///     Right: AppearsInFromClause<T::Table>,\n    ///     (Left::Count, Right::Count): Pick<Left, Right>,\n    ///     T: SelectableExpression<\n    ///         <(Left::Count, Right::Count) as Pick<Left, Right>>::Selection,\n    ///     >,\n    /// ```\n    ///\n    /// In order to acquire the counts in the first place, we must already know\n    /// the table we're searching for.\n    #[doc(hidden)] // This is used as part of the `table!` implementation\n    pub trait Pick<Left, Right> {\n        /// The selected type.\n        ///\n        /// For `(Once, Never)` this type will be `Left`. For `(Never, Once)`, this type will be\n        /// `Right`\n        type Selection;\n    }\n\n    impl<Left, Right> Pick<Left, Right> for (Once, Never) {\n        type Selection = Left;\n    }\n\n    impl<Left, Right> Pick<Left, Right> for (Never, Once) {\n        type Selection = Right;\n    }\n}\n\n#[doc(hidden)]\n#[allow(\n    non_camel_case_types,\n    missing_debug_implementations,\n    missing_copy_implementations\n)]\n/// Everything in this module is here to give something more helpful than:\n///\n/// > (Never, Never): Pick<table1, table2> is not satisfied\n///\n/// Any of these impls can be deleted if they are getting in the way of\n/// other functionality. Any code which is using these impls is already\n/// failing to compile.\nmod impls_which_are_only_here_to_improve_error_messages {\n    use super::*;\n\n    pub struct this_table_doesnt_appear_in_the_from_clause_of_your_query;\n\n    impl<Left, Right> Pick<Left, Right> for (Never, Never) {\n        type Selection = this_table_doesnt_appear_in_the_from_clause_of_your_query;\n    }\n\n    pub struct this_table_appears_in_your_query_more_than_once_and_must_be_aliased;\n\n    impl<Left, Right, OtherCount> Pick<Left, Right> for (MoreThanOnce, OtherCount) {\n        type Selection = this_table_appears_in_your_query_more_than_once_and_must_be_aliased;\n    }\n\n    impl<Left, Right> Pick<Left, Right> for (Never, MoreThanOnce) {\n        type Selection = this_table_appears_in_your_query_more_than_once_and_must_be_aliased;\n    }\n\n    impl<Left, Right> Pick<Left, Right> for (Once, MoreThanOnce) {\n        type Selection = this_table_appears_in_your_query_more_than_once_and_must_be_aliased;\n    }\n}\n\n/// Max length for columns of type Char/Varchar...\n///\n/// If a given column has a such constraint, this trait will be implemented and specify that\n/// length.\npub trait SizeRestrictedColumn: Column {\n    /// Max length of that column\n    const MAX_LENGTH: usize;\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "6a76d4bd8893ca9be0dc8e9141986e65fa0e0729",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/diesel/src/query_source/aliasing/macros.rs",
    "func": "/// Declare a new alias for a table\n///\n/// This macro creates a value of the type [`Alias`](super::Alias)\n///\n/// Example usage\n/// -------------\n/// ```rust\n/// # include!(\"../../doctest_setup.rs\");\n/// fn main() {\n///     use schema::users;\n///     let connection = &mut establish_connection();\n///     let (users1, users2) = diesel::alias!(schema::users as user1, schema::users as user2);\n/// # #[cfg(not(feature = \"mysql\"))] // self joins are not supported with mysql temporary tables\n///     let res = users1\n///         .inner_join(users2.on(users1.field(users::id).eq(users2.field(users::id))))\n///         .select((users1.fields((users::id, users::name)), users2.field(users::name)))\n///         .order_by(users2.field(users::id))\n///         .load::<((i32, String), String)>(connection);\n/// # #[cfg(not(feature = \"mysql\"))] // self joins are not supported with mysql temporary tables\n///     assert_eq!(\n///         res,\n///         Ok(vec![\n///             ((1, \"Sean\".to_owned()), \"Sean\".to_owned()),\n///             ((2, \"Tess\".to_owned()), \"Tess\".to_owned()),\n///         ]),\n///     );\n/// }\n/// ```\n///\n///\n/// Make type expressible\n/// ---------------------\n/// It may sometimes be useful to declare an alias at the module level, in such a way that the type\n/// of a query using it can be expressed (to not declare it anonymously).\n///\n/// This can be achieved in the following way\n/// ```rust\n/// # include!(\"../../doctest_setup.rs\");\n/// use diesel::{query_source::Alias, dsl};\n///\n/// diesel::alias!(schema::users as users_alias: UsersAlias);\n/// // or\n/// diesel::alias!{\n///     pub const USERS_ALIAS_2: Alias<UsersAlias2> = schema::users as users_alias_2;\n/// }\n///\n/// fn some_function_that_returns_a_query_fragment(\n/// ) -> dsl::InnerJoin<schema::posts::table, Alias<UsersAlias>>\n/// {\n///     schema::posts::table.inner_join(users_alias)\n/// }\n/// # fn main() {\n/// #     some_function_that_returns_a_query_fragment();\n/// #     schema::posts::table.inner_join(USERS_ALIAS_2);\n/// # }\n/// ```\n///\n/// Note that you may also use this form within a function, in the following way:\n/// ```rust\n/// # include!(\"../../doctest_setup.rs\");\n/// fn main() {\n///     diesel::alias!(schema::users as users_alias: UsersAlias);\n///     users_alias.inner_join(schema::posts::table);\n/// }\n/// ```\n///\n/// Troubleshooting and limitations\n/// -------------------------------\n/// If you encounter a **compilation error** where \"the trait\n/// `AppearsInFromClause<Alias<your_alias>>` is not implemented\", when trying to use two aliases to\n/// the same table within a single query note the following two limitations:\n///  - You will need to declare these in a single `alias!` call.\n///  - The path to the table module will have to be expressed in the exact same\n///    manner. (That is, you can do `alias!(schema::users as user1, schema::users as user2)`\n///    or `alias!(users as user1, users as user2)`, but not\n///    `alias!(schema::users as user1, users as user2)`)\n#[macro_export]\nmacro_rules! alias {\n    ($($($table: ident)::+ as $alias: ident),* $(,)?) => {{\n        $crate::alias!(NoConst $($($table)::+ as $alias: $alias,)*);\n        ($($crate::query_source::Alias::<$alias>::default()),*)\n    }};\n    ($($($table: ident)::+ as $alias_name: ident: $alias_ty: ident),* $(,)?) => {\n        $crate::alias! {\n            $(\n                pub const $alias_name: Alias<$alias_ty> = $($table)::+ as $alias_name;\n            )*\n        }\n    };\n    ($($vis: vis const $const_name: ident: Alias<$alias_ty: ident> = $($table: ident)::+ as $alias_sql_name: ident);* $(;)?) => {\n        $crate::alias!(NoConst $($($table)::+ as $alias_sql_name: $vis $alias_ty,)*);\n        $(\n            #[allow(non_upper_case_globals)]\n            $vis const $const_name: $crate::query_source::Alias::<$alias_ty> =\n                $crate::query_source::Alias::new($alias_ty { table: $($table)::+::table });\n\n            #[allow(non_camel_case_types)]\n            $vis type $const_name = $crate::query_source::Alias::<$alias_ty>;\n        )*\n    };\n    (NoConst $($($table: ident)::+ as $alias_sql_name: ident: $vis: vis $alias_ty: ident),* $(,)?) => {\n        $(\n            #[allow(non_camel_case_types)]\n            #[derive(Debug, Clone, Copy)]\n            $vis struct $alias_ty {\n                table: $($table)::+::table,\n            }\n\n            impl $crate::query_source::AliasSource for $alias_ty {\n                const NAME: &'static str = stringify!($alias_sql_name);\n                type Target = $($table)::+::table;\n                fn target(&self) -> &Self::Target { &self.table }\n            }\n\n            impl ::std::default::Default for $alias_ty {\n                fn default() -> Self {\n                    Self { table: $($table)::+::table }\n                }\n            }\n\n            // impl AppearsInFromClause<Alias<$alias>> for Alias<$alias>\n            impl $crate::internal::alias_macro::AliasAliasAppearsInFromClauseSameTable<$alias_ty, $($table)::+::table> for $alias_ty {\n                type Count = $crate::query_source::Once;\n            }\n        )*\n        $crate::__internal_alias_helper!($(table_ty = $($table)::+::table, table_tt = ($($table)::+), alias_ty = $alias_ty, alias_sql_name = $alias_sql_name;)*);\n    };\n}\n\n#[macro_export]\n#[doc(hidden)]\n/// This only exists to hide internals from the doc\n// The `($left_sql_name) != ($right_sql_name)` condition is not perfect because a user could still\n// cause runtime errors by declaring two aliases to different tables with the same name then use\n// them in the same query, but that would almost have to be voluntary, so this alone should prevent\n// most mistakes.\nmacro_rules! __internal_alias_helper {\n    (\n        table_ty = $left_table_ty: ty, table_tt = $left_table_tt: tt, alias_ty = $left_alias: ident, alias_sql_name = $left_sql_name: ident;\n        $(table_ty = $right_table_ty: ty, table_tt = $right_table_tt: tt, alias_ty = $right_alias: ident, alias_sql_name = $right_sql_name: ident;)+\n    ) => {\n        $(\n            $crate::static_cond!{if ($left_table_tt) == ($right_table_tt) {\n                $crate::static_cond!{if ($left_sql_name) != ($right_sql_name) {\n                    impl $crate::internal::alias_macro::AliasAliasAppearsInFromClauseSameTable<$left_alias, $left_table_ty>\n                        for $right_alias\n                    {\n                        type Count = $crate::query_source::Never;\n                    }\n                    impl $crate::internal::alias_macro::AliasAliasAppearsInFromClauseSameTable<$right_alias, $left_table_ty>\n                        for $left_alias\n                    {\n                        type Count = $crate::query_source::Never;\n                    }\n                }}\n            }}\n        )*\n        $crate::__internal_alias_helper!($(table_ty = $right_table_ty, table_tt = $right_table_tt, alias_ty = $right_alias, alias_sql_name = $right_sql_name;)+);\n    };\n\n    (table_ty = $left_table_ty: ty, table_tt = $left_table_tt: tt, alias_ty = $left_alias: ident, alias_sql_name = $left_sql_name: ident;) => {};\n    () => {};\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "35bbd2f9895750faaced85352221c31c917d663f",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/diesel/src/mysql/mod.rs",
    "func": "//! Provides types and functions related to working with MySQL\n//!\n//! Much of this module is re-exported from database agnostic locations.\n//! However, if you are writing code specifically to extend Diesel on\n//! MySQL, you may need to work with this module directly.\n\npub(crate) mod backend;\n#[cfg(feature = \"mysql\")]\nmod connection;\nmod value;\n\npub(crate) mod query_builder;\nmod types;\n\npub use self::backend::{Mysql, MysqlType};\n#[cfg(feature = \"mysql\")]\npub use self::connection::MysqlConnection;\npub use self::query_builder::MysqlQueryBuilder;\npub use self::value::{MysqlValue, NumericRepresentation};\n\n/// Data structures for MySQL types which have no corresponding Rust type\n///\n/// Most of these types are used to implement `ToSql` and `FromSql` for higher\n/// level types.\npub mod data_types {\n    #[doc(inline)]\n    pub use super::types::date_and_time::{MysqlTime, MysqlTimestampType};\n}\n\n/// MySQL specific sql types\npub mod sql_types {\n    #[doc(inline)]\n    pub use super::types::{Datetime, Unsigned};\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "da1deeac14981565f8656dd866ef5f7a8b586bf1",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/diesel/src/mysql/types/json.rs",
    "func": "use crate::deserialize::{self, FromSql};\nuse crate::mysql::{Mysql, MysqlValue};\nuse crate::serialize::{self, IsNull, Output, ToSql};\nuse crate::sql_types;\n\n#[cfg(all(feature = \"mysql_backend\", feature = \"serde_json\"))]\nimpl FromSql<sql_types::Json, Mysql> for serde_json::Value {\n    fn from_sql(value: MysqlValue<'_>) -> deserialize::Result<Self> {\n        serde_json::from_slice(value.as_bytes()).map_err(|_| \"Invalid Json\".into())\n    }\n}\n\n#[cfg(all(feature = \"mysql_backend\", feature = \"serde_json\"))]\nimpl ToSql<sql_types::Json, Mysql> for serde_json::Value {\n    fn to_sql<'b>(&'b self, out: &mut Output<'b, '_, Mysql>) -> serialize::Result {\n        serde_json::to_writer(out, self)\n            .map(|_| IsNull::No)\n            .map_err(Into::into)\n    }\n}\n\n#[test]\nfn json_to_sql() {\n    use crate::query_builder::bind_collector::ByteWrapper;\n\n    let mut buffer = Vec::new();\n    let mut bytes = Output::test(ByteWrapper(&mut buffer));\n    let test_json = serde_json::Value::Bool(true);\n    ToSql::<sql_types::Json, Mysql>::to_sql(&test_json, &mut bytes).unwrap();\n    assert_eq!(buffer, b\"true\");\n}\n\n#[test]\nfn some_json_from_sql() {\n    use crate::mysql::MysqlType;\n    let input_json = b\"true\";\n    let output_json: serde_json::Value = FromSql::<sql_types::Json, Mysql>::from_sql(\n        MysqlValue::new_internal(input_json, MysqlType::String),\n    )\n    .unwrap();\n    assert_eq!(output_json, serde_json::Value::Bool(true));\n}\n\n#[test]\nfn bad_json_from_sql() {\n    use crate::mysql::MysqlType;\n    let uuid: Result<serde_json::Value, _> = FromSql::<sql_types::Json, Mysql>::from_sql(\n        MysqlValue::new_internal(b\"boom\", MysqlType::String),\n    );\n    assert_eq!(uuid.unwrap_err().to_string(), \"Invalid Json\");\n}\n\n#[test]\nfn no_json_from_sql() {\n    let uuid: Result<serde_json::Value, _> =\n        FromSql::<sql_types::Json, Mysql>::from_nullable_sql(None);\n    assert_eq!(\n        uuid.unwrap_err().to_string(),\n        \"Unexpected null for non-null column\"\n    );\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "edfdcbfb8a677ad0a793ae4a6d47bb384016fb86",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/diesel/src/mysql/types/date_and_time/time.rs",
    "func": "use std::os::raw as libc;\nuse time::{\n    Date as NaiveDate, Month, OffsetDateTime, PrimitiveDateTime, Time as NaiveTime, UtcOffset,\n};\n\nuse crate::deserialize::{self, FromSql};\nuse crate::mysql::{Mysql, MysqlValue};\nuse crate::serialize::{self, Output, ToSql};\nuse crate::sql_types::{Date, Datetime, Time, Timestamp};\n\nuse super::{MysqlTime, MysqlTimestampType};\n\nfn to_time(dt: MysqlTime) -> Result<NaiveTime, Box<dyn std::error::Error>> {\n    for (name, field) in [\n        (\"year\", dt.year),\n        (\"month\", dt.month),\n        (\"day\", dt.day),\n        (\"offset\", dt.time_zone_displacement.try_into()?),\n    ] {\n        if field != 0 {\n            return Err(format!(\"Unable to convert {dt:?} to time: {name} must be 0\").into());\n        }\n    }\n\n    let hour: u8 = dt.hour.try_into()?;\n    let minute: u8 = dt.minute.try_into()?;\n    let second: u8 = dt.second.try_into()?;\n    let microsecond: u32 = dt.second_part.try_into()?;\n\n    Ok(NaiveTime::from_hms_micro(\n        hour,\n        minute,\n        second,\n        microsecond,\n    )?)\n}\n\nfn to_datetime(dt: MysqlTime) -> Result<OffsetDateTime, Box<dyn std::error::Error>> {\n    let year: i32 = dt.year.try_into()?;\n    let month: u8 = dt.month.try_into()?;\n    let month: Month = month.try_into()?;\n    let day: u8 = dt.day.try_into()?;\n    let hour: u8 = dt.hour.try_into()?;\n    let minute: u8 = dt.minute.try_into()?;\n    let second: u8 = dt.second.try_into()?;\n    let microsecond: u32 = dt.second_part.try_into()?;\n    let offset = UtcOffset::from_whole_seconds(dt.time_zone_displacement)?;\n\n    Ok(PrimitiveDateTime::new(\n        NaiveDate::from_calendar_date(year, month, day)?,\n        NaiveTime::from_hms_micro(hour, minute, second, microsecond)?,\n    )\n    .assume_offset(offset))\n}\n\nfn to_primitive_datetime(dt: OffsetDateTime) -> PrimitiveDateTime {\n    let dt = dt.to_offset(UtcOffset::UTC);\n    PrimitiveDateTime::new(dt.date(), dt.time())\n}\n\n// Mysql datetime column has a wider range than timestamp column, so let's implement the fundamental operations in terms of datetime.\n#[cfg(all(feature = \"time\", feature = \"mysql_backend\"))]\nimpl ToSql<Datetime, Mysql> for PrimitiveDateTime {\n    fn to_sql<'b>(&'b self, out: &mut Output<'b, '_, Mysql>) -> serialize::Result {\n        let mysql_time = MysqlTime {\n            year: self.year().try_into()?,\n            month: self.month() as libc::c_uint,\n            day: self.day() as libc::c_uint,\n            hour: self.hour() as libc::c_uint,\n            minute: self.minute() as libc::c_uint,\n            second: self.second() as libc::c_uint,\n            second_part: libc::c_ulong::from(self.microsecond()),\n            neg: false,\n            time_type: MysqlTimestampType::MYSQL_TIMESTAMP_DATETIME,\n            time_zone_displacement: 0,\n        };\n\n        <MysqlTime as ToSql<Timestamp, Mysql>>::to_sql(&mysql_time, &mut out.reborrow())\n    }\n}\n\n#[cfg(all(feature = \"time\", feature = \"mysql_backend\"))]\nimpl FromSql<Datetime, Mysql> for PrimitiveDateTime {\n    fn from_sql(bytes: MysqlValue<'_>) -> deserialize::Result<Self> {\n        let mysql_time = <MysqlTime as FromSql<Timestamp, Mysql>>::from_sql(bytes)?;\n\n        to_datetime(mysql_time)\n            .map(to_primitive_datetime)\n            .map_err(|err| format!(\"Cannot parse this date: {mysql_time:?}: {err}\").into())\n    }\n}\n\n// We can implement timestamps in terms of datetimes\n#[cfg(all(feature = \"time\", feature = \"mysql_backend\"))]\nimpl ToSql<Timestamp, Mysql> for PrimitiveDateTime {\n    fn to_sql<'b>(&'b self, out: &mut Output<'b, '_, Mysql>) -> serialize::Result {\n        <PrimitiveDateTime as ToSql<Datetime, Mysql>>::to_sql(self, out)\n    }\n}\n\n#[cfg(all(feature = \"time\", feature = \"mysql_backend\"))]\nimpl FromSql<Timestamp, Mysql> for PrimitiveDateTime {\n    fn from_sql(bytes: MysqlValue<'_>) -> deserialize::Result<Self> {\n        <PrimitiveDateTime as FromSql<Datetime, Mysql>>::from_sql(bytes)\n    }\n}\n\n// Delegate offset datetimes in terms of UTC primitive datetimes; this stores everything in the DB as UTC\n#[cfg(all(feature = \"time\", feature = \"mysql_backend\"))]\nimpl ToSql<Datetime, Mysql> for OffsetDateTime {\n    fn to_sql<'b>(&'b self, out: &mut Output<'b, '_, Mysql>) -> serialize::Result {\n        let prim = to_primitive_datetime(*self);\n        <PrimitiveDateTime as ToSql<Datetime, Mysql>>::to_sql(&prim, &mut out.reborrow())\n    }\n}\n\n#[cfg(all(feature = \"time\", feature = \"mysql_backend\"))]\nimpl FromSql<Datetime, Mysql> for OffsetDateTime {\n    fn from_sql(bytes: MysqlValue<'_>) -> deserialize::Result<Self> {\n        let prim = <PrimitiveDateTime as FromSql<Datetime, Mysql>>::from_sql(bytes)?;\n        Ok(prim.assume_offset(UtcOffset::UTC))\n    }\n}\n\n// delegate timestamp column to datetime column for offset datetimes\n#[cfg(all(feature = \"time\", feature = \"mysql_backend\"))]\nimpl ToSql<Timestamp, Mysql> for OffsetDateTime {\n    fn to_sql<'b>(&'b self, out: &mut Output<'b, '_, Mysql>) -> serialize::Result {\n        <OffsetDateTime as ToSql<Datetime, Mysql>>::to_sql(self, out)\n    }\n}\n\n#[cfg(all(feature = \"time\", feature = \"mysql_backend\"))]\nimpl FromSql<Timestamp, Mysql> for OffsetDateTime {\n    fn from_sql(bytes: MysqlValue<'_>) -> deserialize::Result<Self> {\n        <OffsetDateTime as FromSql<Datetime, Mysql>>::from_sql(bytes)\n    }\n}\n\n#[cfg(all(feature = \"time\", feature = \"mysql_backend\"))]\nimpl ToSql<Time, Mysql> for NaiveTime {\n    fn to_sql<'b>(&'b self, out: &mut serialize::Output<'b, '_, Mysql>) -> serialize::Result {\n        let mysql_time = MysqlTime {\n            hour: self.hour() as libc::c_uint,\n            minute: self.minute() as libc::c_uint,\n            second: self.second() as libc::c_uint,\n            day: 0,\n            month: 0,\n            second_part: 0,\n            year: 0,\n            neg: false,\n            time_type: MysqlTimestampType::MYSQL_TIMESTAMP_TIME,\n            time_zone_displacement: 0,\n        };\n\n        <MysqlTime as ToSql<Time, Mysql>>::to_sql(&mysql_time, &mut out.reborrow())\n    }\n}\n\n#[cfg(all(feature = \"time\", feature = \"mysql_backend\"))]\nimpl FromSql<Time, Mysql> for NaiveTime {\n    fn from_sql(bytes: MysqlValue<'_>) -> deserialize::Result<Self> {\n        let mysql_time = <MysqlTime as FromSql<Time, Mysql>>::from_sql(bytes)?;\n\n        to_time(mysql_time)\n            .map_err(|err| format!(\"Unable to convert {mysql_time:?} to time: {err}\").into())\n    }\n}\n\n#[cfg(all(feature = \"time\", feature = \"mysql_backend\"))]\nimpl ToSql<Date, Mysql> for NaiveDate {\n    fn to_sql<'b>(&'b self, out: &mut Output<'b, '_, Mysql>) -> serialize::Result {\n        let mysql_time = MysqlTime {\n            year: self.year().try_into()?,\n            month: self.month() as libc::c_uint,\n            day: self.day() as libc::c_uint,\n            hour: 0,\n            minute: 0,\n            second: 0,\n            second_part: 0,\n            neg: false,\n            time_type: MysqlTimestampType::MYSQL_TIMESTAMP_DATE,\n            time_zone_displacement: 0,\n        };\n\n        <MysqlTime as ToSql<Date, Mysql>>::to_sql(&mysql_time, &mut out.reborrow())\n    }\n}\n\n#[cfg(all(feature = \"time\", feature = \"mysql_backend\"))]\nimpl FromSql<Date, Mysql> for NaiveDate {\n    fn from_sql(bytes: MysqlValue<'_>) -> deserialize::Result<Self> {\n        let mysql_time = <MysqlTime as FromSql<Date, Mysql>>::from_sql(bytes)?;\n\n        to_datetime(mysql_time)\n            .map_err(|err| format!(\"Unable to convert {mysql_time:?} to time: {err}\").into())\n            .and_then(|dt| {\n                let prim = to_primitive_datetime(dt);\n                if prim.time() == NaiveTime::MIDNIGHT {\n                    Ok(prim.date())\n                } else {\n                    Err(format!(\"Unable to convert {prim:?} to date: non-0 time part\").into())\n                }\n            })\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    extern crate dotenvy;\n    extern crate time;\n\n    use time::{\n        macros::{date, datetime, time},\n        Date as NaiveDate, Duration, OffsetDateTime, Time as NaiveTime,\n    };\n\n    use super::to_primitive_datetime;\n\n    use crate::dsl::{now, sql};\n    use crate::prelude::*;\n    use crate::select;\n    use crate::sql_types::{Date, Datetime, Time, Timestamp};\n    use crate::test_helpers::connection;\n\n    #[test]\n    fn unix_epoch_encodes_correctly() {\n        let connection = &mut connection();\n        let time = datetime!(1970-1-1 0:0:0);\n        let query = select(sql::<Timestamp>(\"CAST('1970-01-01' AS DATETIME)\").eq(time));\n        assert!(query.get_result::<bool>(connection).unwrap());\n        let query = select(sql::<Datetime>(\"CAST('1970-01-01' AS DATETIME)\").eq(time));\n        assert!(query.get_result::<bool>(connection).unwrap());\n    }\n\n    #[test]\n    fn unix_epoch_decodes_correctly() {\n        let connection = &mut connection();\n        let time = datetime!(1970-1-1 0:0:0);\n        let epoch_from_sql =\n            select(sql::<Timestamp>(\"CAST('1970-01-01' AS DATETIME)\")).get_result(connection);\n        assert_eq!(Ok(time), epoch_from_sql);\n        let epoch_from_sql =\n            select(sql::<Datetime>(\"CAST('1970-01-01' AS DATETIME)\")).get_result(connection);\n        assert_eq!(Ok(time), epoch_from_sql);\n    }\n\n    #[test]\n    fn times_relative_to_now_encode_correctly() {\n        let connection = &mut connection();\n        let time = to_primitive_datetime(OffsetDateTime::now_utc()) + Duration::days(1);\n        let query = select(now.lt(time));\n        assert!(query.get_result::<bool>(connection).unwrap());\n\n        let time = to_primitive_datetime(OffsetDateTime::now_utc()) - Duration::days(1);\n        let query = select(now.gt(time));\n        assert!(query.get_result::<bool>(connection).unwrap());\n    }\n\n    #[test]\n    fn times_of_day_encode_correctly() {\n        let connection = &mut connection();\n\n        let midnight = time!(0:0:0);\n        let query = select(sql::<Time>(\"CAST('00:00:00' AS TIME)\").eq(midnight));\n        assert!(query.get_result::<bool>(connection).unwrap());\n\n        let noon = time!(12:0:0);\n        let query = select(sql::<Time>(\"CAST('12:00:00' AS TIME)\").eq(noon));\n        assert!(query.get_result::<bool>(connection).unwrap());\n\n        let roughly_half_past_eleven = time!(23:37:4);\n        let query = select(sql::<Time>(\"CAST('23:37:04' AS TIME)\").eq(roughly_half_past_eleven));\n        assert!(query.get_result::<bool>(connection).unwrap());\n    }\n\n    #[test]\n    fn times_of_day_decode_correctly() {\n        let connection = &mut connection();\n        let midnight = time!(0:0:0);\n        let query = select(sql::<Time>(\"CAST('00:00:00' AS TIME)\"));\n        assert_eq!(Ok(midnight), query.get_result::<NaiveTime>(connection));\n\n        let noon = time!(12:0:0);\n        let query = select(sql::<Time>(\"CAST('12:00:00' AS TIME)\"));\n        assert_eq!(Ok(noon), query.get_result::<NaiveTime>(connection));\n\n        let roughly_half_past_eleven = time!(23:37:4);\n        let query = select(sql::<Time>(\"CAST('23:37:04' AS TIME)\"));\n        assert_eq!(\n            Ok(roughly_half_past_eleven),\n            query.get_result::<NaiveTime>(connection)\n        );\n    }\n\n    #[test]\n    fn dates_encode_correctly() {\n        let connection = &mut connection();\n        let january_first_2000 = date!(2000 - 1 - 1);\n        let query = select(sql::<Date>(\"CAST('2000-1-1' AS DATE)\").eq(january_first_2000));\n        assert!(query.get_result::<bool>(connection).unwrap());\n\n        let january_first_2018 = date!(2018 - 1 - 1);\n        let query = select(sql::<Date>(\"CAST('2018-1-1' AS DATE)\").eq(january_first_2018));\n        assert!(query.get_result::<bool>(connection).unwrap());\n    }\n\n    #[test]\n    fn dates_decode_correctly() {\n        let connection = &mut connection();\n        let january_first_2000 = date!(2000 - 1 - 1);\n        let query = select(sql::<Date>(\"CAST('2000-1-1' AS DATE)\"));\n        assert_eq!(\n            Ok(january_first_2000),\n            query.get_result::<NaiveDate>(connection)\n        );\n\n        let january_first_2018 = date!(2018 - 1 - 1);\n        let query = select(sql::<Date>(\"CAST('2018-1-1' AS DATE)\"));\n        assert_eq!(\n            Ok(january_first_2018),\n            query.get_result::<NaiveDate>(connection)\n        );\n\n        crate::sql_query(\"SET sql_mode = (SELECT REPLACE(@@sql_mode, 'NO_ZERO_DATE,', ''))\")\n            .execute(connection)\n            .unwrap();\n        let query = select(sql::<Date>(\"CAST('0000-00-00' AS DATE)\"));\n        assert!(query.get_result::<NaiveDate>(connection).is_err());\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "978e65e5b11d9f7ec639acde67a3928f86124912",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/diesel/src/mysql/query_builder/limit_offset.rs",
    "func": "use crate::mysql::Mysql;\nuse crate::query_builder::limit_clause::{LimitClause, NoLimitClause};\nuse crate::query_builder::limit_offset_clause::{BoxedLimitOffsetClause, LimitOffsetClause};\nuse crate::query_builder::offset_clause::{NoOffsetClause, OffsetClause};\nuse crate::query_builder::{AstPass, IntoBoxedClause, QueryFragment};\nuse crate::result::QueryResult;\n\nimpl QueryFragment<Mysql> for LimitOffsetClause<NoLimitClause, NoOffsetClause> {\n    fn walk_ast<'b>(&'b self, _out: AstPass<'_, 'b, Mysql>) -> QueryResult<()> {\n        Ok(())\n    }\n}\n\nimpl<L> QueryFragment<Mysql> for LimitOffsetClause<LimitClause<L>, NoOffsetClause>\nwhere\n    LimitClause<L>: QueryFragment<Mysql>,\n{\n    fn walk_ast<'b>(&'b self, out: AstPass<'_, 'b, Mysql>) -> QueryResult<()> {\n        self.limit_clause.walk_ast(out)?;\n        Ok(())\n    }\n}\n\nimpl<L, O> QueryFragment<Mysql> for LimitOffsetClause<LimitClause<L>, OffsetClause<O>>\nwhere\n    LimitClause<L>: QueryFragment<Mysql>,\n    OffsetClause<O>: QueryFragment<Mysql>,\n{\n    fn walk_ast<'b>(&'b self, mut out: AstPass<'_, 'b, Mysql>) -> QueryResult<()> {\n        self.limit_clause.walk_ast(out.reborrow())?;\n        self.offset_clause.walk_ast(out.reborrow())?;\n        Ok(())\n    }\n}\n\nimpl QueryFragment<Mysql> for BoxedLimitOffsetClause<'_, Mysql> {\n    fn walk_ast<'b>(&'b self, mut out: AstPass<'_, 'b, Mysql>) -> QueryResult<()> {\n        match (self.limit.as_ref(), self.offset.as_ref()) {\n            (Some(limit), Some(offset)) => {\n                limit.walk_ast(out.reborrow())?;\n                offset.walk_ast(out.reborrow())?;\n            }\n            (Some(limit), None) => {\n                limit.walk_ast(out.reborrow())?;\n            }\n            (None, Some(offset)) => {\n                // Mysql requires a limit clause in front of any offset clause\n                // The documentation proposes the following:\n                // > To retrieve all rows from a certain offset up to the end of the\n                // > result set, you can use some large number for the second parameter.\n                // https://dev.mysql.com/doc/refman/8.0/en/select.html\n                // Therefore we just use u64::MAX as limit here\n                // That does not result in any limitations because mysql only supports\n                // up to 64TB of data per table. Assuming 1 bit per row this means\n                // 1024 * 1024 * 1024 * 1024 * 8 = 562.949.953.421.312 rows which is smaller\n                // than 2^64 = 18.446.744.073.709.551.615\n                out.push_sql(\" LIMIT 18446744073709551615 \");\n                offset.walk_ast(out.reborrow())?;\n            }\n            (None, None) => {}\n        }\n        Ok(())\n    }\n}\n\nimpl<'a> IntoBoxedClause<'a, Mysql> for LimitOffsetClause<NoLimitClause, NoOffsetClause> {\n    type BoxedClause = BoxedLimitOffsetClause<'a, Mysql>;\n\n    fn into_boxed(self) -> Self::BoxedClause {\n        BoxedLimitOffsetClause {\n            limit: None,\n            offset: None,\n        }\n    }\n}\n\nimpl<'a, L> IntoBoxedClause<'a, Mysql> for LimitOffsetClause<LimitClause<L>, NoOffsetClause>\nwhere\n    L: QueryFragment<Mysql> + Send + 'a,\n{\n    type BoxedClause = BoxedLimitOffsetClause<'a, Mysql>;\n\n    fn into_boxed(self) -> Self::BoxedClause {\n        BoxedLimitOffsetClause {\n            limit: Some(Box::new(self.limit_clause)),\n            offset: None,\n        }\n    }\n}\n\nimpl<'a, L, O> IntoBoxedClause<'a, Mysql> for LimitOffsetClause<LimitClause<L>, OffsetClause<O>>\nwhere\n    L: QueryFragment<Mysql> + Send + 'a,\n    O: QueryFragment<Mysql> + Send + 'a,\n{\n    type BoxedClause = BoxedLimitOffsetClause<'a, Mysql>;\n\n    fn into_boxed(self) -> Self::BoxedClause {\n        BoxedLimitOffsetClause {\n            limit: Some(Box::new(self.limit_clause)),\n            offset: Some(Box::new(self.offset_clause)),\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "b022aaafb3db3ddb33d2794adf180603ec116e54",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/diesel/src/query_builder/insert_statement/insert_with_default_for_sqlite.rs",
    "func": "use super::{BatchInsert, InsertStatement};\nuse crate::insertable::InsertValues;\nuse crate::insertable::{CanInsertInSingleQuery, ColumnInsertValue, DefaultableColumnInsertValue};\nuse crate::prelude::*;\nuse crate::query_builder::{AstPass, QueryId, ValuesClause};\nuse crate::query_builder::{DebugQuery, QueryFragment};\nuse crate::query_dsl::methods::ExecuteDsl;\nuse crate::sqlite::Sqlite;\nuse std::fmt::{self, Debug, Display};\n\npub trait DebugQueryHelper<ContainsDefaultableValue> {\n    fn fmt_debug(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result;\n    fn fmt_display(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result;\n}\n\nimpl<T, V, QId, Op, Ret, const STATIC_QUERY_ID: bool> DebugQueryHelper<Yes>\n    for DebugQuery<\n        '_,\n        InsertStatement<T, BatchInsert<Vec<ValuesClause<V, T>>, T, QId, STATIC_QUERY_ID>, Op, Ret>,\n        Sqlite,\n    >\nwhere\n    V: QueryFragment<Sqlite>,\n    T: Copy + QuerySource,\n    Op: Copy,\n    Ret: Copy,\n    for<'b> InsertStatement<T, &'b ValuesClause<V, T>, Op, Ret>: QueryFragment<Sqlite>,\n{\n    fn fmt_debug(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        let mut statements = vec![String::from(\"BEGIN\")];\n        for record in self.query.records.values.iter() {\n            let stmt = InsertStatement::new(\n                self.query.target,\n                record,\n                self.query.operator,\n                self.query.returning,\n            );\n            statements.push(crate::debug_query(&stmt).to_string());\n        }\n        statements.push(\"COMMIT\".into());\n\n        f.debug_struct(\"Query\")\n            .field(\"sql\", &statements)\n            .field(\"binds\", &[] as &[i32; 0])\n            .finish()\n    }\n\n    fn fmt_display(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        writeln!(f, \"BEGIN;\")?;\n        for record in self.query.records.values.iter() {\n            let stmt = InsertStatement::new(\n                self.query.target,\n                record,\n                self.query.operator,\n                self.query.returning,\n            );\n            writeln!(f, \"{}\", crate::debug_query(&stmt))?;\n        }\n        writeln!(f, \"COMMIT;\")?;\n        Ok(())\n    }\n}\n\n#[allow(unsafe_code)] // cast to transparent wrapper type\nimpl<'a, T, V, QId, Op, const STATIC_QUERY_ID: bool> DebugQueryHelper<No>\n    for DebugQuery<'a, InsertStatement<T, BatchInsert<V, T, QId, STATIC_QUERY_ID>, Op>, Sqlite>\nwhere\n    T: Copy + QuerySource,\n    Op: Copy,\n    DebugQuery<\n        'a,\n        InsertStatement<T, SqliteBatchInsertWrapper<V, T, QId, STATIC_QUERY_ID>, Op>,\n        Sqlite,\n    >: Debug + Display,\n{\n    fn fmt_debug(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        let value = unsafe {\n            // This cast is safe as `SqliteBatchInsertWrapper` is #[repr(transparent)]\n            &*(self as *const DebugQuery<\n                'a,\n                InsertStatement<T, BatchInsert<V, T, QId, STATIC_QUERY_ID>, Op>,\n                Sqlite,\n            >\n                as *const DebugQuery<\n                    'a,\n                    InsertStatement<T, SqliteBatchInsertWrapper<V, T, QId, STATIC_QUERY_ID>, Op>,\n                    Sqlite,\n                >)\n        };\n        <_ as Debug>::fmt(value, f)\n    }\n\n    fn fmt_display(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        let value = unsafe {\n            // This cast is safe as `SqliteBatchInsertWrapper` is #[repr(transparent)]\n            &*(self as *const DebugQuery<\n                'a,\n                InsertStatement<T, BatchInsert<V, T, QId, STATIC_QUERY_ID>, Op>,\n                Sqlite,\n            >\n                as *const DebugQuery<\n                    'a,\n                    InsertStatement<T, SqliteBatchInsertWrapper<V, T, QId, STATIC_QUERY_ID>, Op>,\n                    Sqlite,\n                >)\n        };\n        <_ as Display>::fmt(value, f)\n    }\n}\n\nimpl<T, V, QId, Op, O, const STATIC_QUERY_ID: bool> Display\n    for DebugQuery<\n        '_,\n        InsertStatement<T, BatchInsert<Vec<ValuesClause<V, T>>, T, QId, STATIC_QUERY_ID>, Op>,\n        Sqlite,\n    >\nwhere\n    T: QuerySource,\n    V: ContainsDefaultableValue<Out = O>,\n    Self: DebugQueryHelper<O>,\n{\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        self.fmt_display(f)\n    }\n}\n\nimpl<T, V, QId, Op, O, const STATIC_QUERY_ID: bool> Debug\n    for DebugQuery<\n        '_,\n        InsertStatement<T, BatchInsert<Vec<ValuesClause<V, T>>, T, QId, STATIC_QUERY_ID>, Op>,\n        Sqlite,\n    >\nwhere\n    T: QuerySource,\n    V: ContainsDefaultableValue<Out = O>,\n    Self: DebugQueryHelper<O>,\n{\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        self.fmt_debug(f)\n    }\n}\n\n#[allow(missing_debug_implementations, missing_copy_implementations)]\npub struct Yes;\n\nimpl Default for Yes {\n    fn default() -> Self {\n        Yes\n    }\n}\n\n#[allow(missing_debug_implementations, missing_copy_implementations)]\npub struct No;\n\nimpl Default for No {\n    fn default() -> Self {\n        No\n    }\n}\n\npub trait Any<Rhs> {\n    type Out: Any<Yes> + Any<No>;\n}\n\nimpl Any<No> for No {\n    type Out = No;\n}\n\nimpl Any<Yes> for No {\n    type Out = Yes;\n}\n\nimpl Any<No> for Yes {\n    type Out = Yes;\n}\n\nimpl Any<Yes> for Yes {\n    type Out = Yes;\n}\n\npub trait ContainsDefaultableValue {\n    type Out: Any<Yes> + Any<No>;\n}\n\nimpl<C, B> ContainsDefaultableValue for ColumnInsertValue<C, B> {\n    type Out = No;\n}\n\nimpl<I> ContainsDefaultableValue for DefaultableColumnInsertValue<I> {\n    type Out = Yes;\n}\n\nimpl<I, const SIZE: usize> ContainsDefaultableValue for [I; SIZE]\nwhere\n    I: ContainsDefaultableValue,\n{\n    type Out = I::Out;\n}\n\nimpl<I, T> ContainsDefaultableValue for ValuesClause<I, T>\nwhere\n    I: ContainsDefaultableValue,\n{\n    type Out = I::Out;\n}\n\nimpl<T> ContainsDefaultableValue for &T\nwhere\n    T: ContainsDefaultableValue,\n{\n    type Out = T::Out;\n}\n\nimpl<V, T, QId, C, Op, O, const STATIC_QUERY_ID: bool> ExecuteDsl<C, Sqlite>\n    for InsertStatement<T, BatchInsert<Vec<ValuesClause<V, T>>, T, QId, STATIC_QUERY_ID>, Op>\nwhere\n    T: QuerySource,\n    C: Connection<Backend = Sqlite>,\n    V: ContainsDefaultableValue<Out = O>,\n    O: Default,\n    (O, Self): ExecuteDsl<C, Sqlite>,\n{\n    fn execute(query: Self, conn: &mut C) -> QueryResult<usize> {\n        <(O, Self) as ExecuteDsl<C, Sqlite>>::execute((O::default(), query), conn)\n    }\n}\n\nimpl<V, T, QId, C, Op, const STATIC_QUERY_ID: bool> ExecuteDsl<C, Sqlite>\n    for (\n        Yes,\n        InsertStatement<T, BatchInsert<Vec<ValuesClause<V, T>>, T, QId, STATIC_QUERY_ID>, Op>,\n    )\nwhere\n    C: Connection<Backend = Sqlite>,\n    T: Table + Copy + QueryId + 'static,\n    T::FromClause: QueryFragment<Sqlite>,\n    Op: Copy + QueryId + QueryFragment<Sqlite>,\n    V: InsertValues<Sqlite, T> + CanInsertInSingleQuery<Sqlite> + QueryId,\n{\n    fn execute((Yes, query): Self, conn: &mut C) -> QueryResult<usize> {\n        conn.transaction(|conn| {\n            let mut result = 0;\n            for record in &query.records.values {\n                let stmt =\n                    InsertStatement::new(query.target, record, query.operator, query.returning);\n                result += stmt.execute(conn)?;\n            }\n            Ok(result)\n        })\n    }\n}\n\n#[allow(missing_debug_implementations, missing_copy_implementations)]\n#[repr(transparent)]\npub struct SqliteBatchInsertWrapper<V, T, QId, const STATIC_QUERY_ID: bool>(\n    BatchInsert<V, T, QId, STATIC_QUERY_ID>,\n);\n\nimpl<V, Tab, QId, const STATIC_QUERY_ID: bool> QueryFragment<Sqlite>\n    for SqliteBatchInsertWrapper<Vec<ValuesClause<V, Tab>>, Tab, QId, STATIC_QUERY_ID>\nwhere\n    ValuesClause<V, Tab>: QueryFragment<Sqlite>,\n    V: QueryFragment<Sqlite>,\n{\n    fn walk_ast<'b>(&'b self, mut out: AstPass<'_, 'b, Sqlite>) -> QueryResult<()> {\n        if !STATIC_QUERY_ID {\n            out.unsafe_to_cache_prepared();\n        }\n\n        let mut values = self.0.values.iter();\n        if let Some(value) = values.next() {\n            value.walk_ast(out.reborrow())?;\n        }\n        for value in values {\n            out.push_sql(\", (\");\n            value.values.walk_ast(out.reborrow())?;\n            out.push_sql(\")\");\n        }\n        Ok(())\n    }\n}\n\n#[allow(missing_copy_implementations, missing_debug_implementations)]\n#[repr(transparent)]\npub struct SqliteCanInsertInSingleQueryHelper<T: ?Sized>(T);\n\nimpl<V, T, QId, const STATIC_QUERY_ID: bool> CanInsertInSingleQuery<Sqlite>\n    for SqliteBatchInsertWrapper<Vec<ValuesClause<V, T>>, T, QId, STATIC_QUERY_ID>\nwhere\n    // We constrain that here on an internal helper type\n    // to make sure that this does not accidentally leak\n    // so that none does really implement normal batch\n    // insert for inserts with default values here\n    SqliteCanInsertInSingleQueryHelper<V>: CanInsertInSingleQuery<Sqlite>,\n{\n    fn rows_to_insert(&self) -> Option<usize> {\n        Some(self.0.values.len())\n    }\n}\n\nimpl<T> CanInsertInSingleQuery<Sqlite> for SqliteCanInsertInSingleQueryHelper<T>\nwhere\n    T: CanInsertInSingleQuery<Sqlite>,\n{\n    fn rows_to_insert(&self) -> Option<usize> {\n        self.0.rows_to_insert()\n    }\n}\n\nimpl<V, T, QId, const STATIC_QUERY_ID: bool> QueryId\n    for SqliteBatchInsertWrapper<V, T, QId, STATIC_QUERY_ID>\nwhere\n    BatchInsert<V, T, QId, STATIC_QUERY_ID>: QueryId,\n{\n    type QueryId = <BatchInsert<V, T, QId, STATIC_QUERY_ID> as QueryId>::QueryId;\n\n    const HAS_STATIC_QUERY_ID: bool =\n        <BatchInsert<V, T, QId, STATIC_QUERY_ID> as QueryId>::HAS_STATIC_QUERY_ID;\n}\n\nimpl<V, T, QId, C, Op, const STATIC_QUERY_ID: bool> ExecuteDsl<C, Sqlite>\n    for (\n        No,\n        InsertStatement<T, BatchInsert<V, T, QId, STATIC_QUERY_ID>, Op>,\n    )\nwhere\n    C: Connection<Backend = Sqlite>,\n    T: Table + QueryId + 'static,\n    T::FromClause: QueryFragment<Sqlite>,\n    Op: QueryFragment<Sqlite> + QueryId,\n    SqliteBatchInsertWrapper<V, T, QId, STATIC_QUERY_ID>:\n        QueryFragment<Sqlite> + QueryId + CanInsertInSingleQuery<Sqlite>,\n{\n    fn execute((No, query): Self, conn: &mut C) -> QueryResult<usize> {\n        let query = InsertStatement {\n            records: SqliteBatchInsertWrapper(query.records),\n            operator: query.operator,\n            target: query.target,\n            returning: query.returning,\n            into_clause: query.into_clause,\n        };\n        query.execute(conn)\n    }\n}\n\nmacro_rules! tuple_impls {\n        ($(\n            $Tuple:tt {\n                $(($idx:tt) -> $T:ident, $ST:ident, $TT:ident,)+\n            }\n        )+) => {\n            $(\n                impl_contains_defaultable_value!($($T,)*);\n            )*\n        }\n    }\n\nmacro_rules! impl_contains_defaultable_value {\n      (\n        @build\n        start_ts = [$($ST: ident,)*],\n        ts = [$T1: ident,],\n        bounds = [$($bounds: tt)*],\n        out = [$($out: tt)*],\n    )=> {\n        impl<$($ST,)*> ContainsDefaultableValue for ($($ST,)*)\n        where\n            $($ST: ContainsDefaultableValue,)*\n            $($bounds)*\n            $T1::Out: Any<$($out)*>,\n        {\n            type Out = <$T1::Out as Any<$($out)*>>::Out;\n        }\n\n    };\n    (\n        @build\n        start_ts = [$($ST: ident,)*],\n        ts = [$T1: ident, $($T: ident,)+],\n        bounds = [$($bounds: tt)*],\n        out = [$($out: tt)*],\n    )=> {\n        impl_contains_defaultable_value! {\n            @build\n            start_ts = [$($ST,)*],\n            ts = [$($T,)*],\n            bounds = [$($bounds)* $T1::Out: Any<$($out)*>,],\n            out = [<$T1::Out as Any<$($out)*>>::Out],\n        }\n    };\n    ($T1: ident, $($T: ident,)+) => {\n        impl_contains_defaultable_value! {\n            @build\n            start_ts = [$T1, $($T,)*],\n            ts = [$($T,)*],\n            bounds = [],\n            out = [$T1::Out],\n        }\n    };\n    ($T1: ident,) => {\n        impl<$T1> ContainsDefaultableValue for ($T1,)\n        where $T1: ContainsDefaultableValue,\n        {\n            type Out = <$T1 as ContainsDefaultableValue>::Out;\n        }\n    }\n}\n\ndiesel_derives::__diesel_for_each_tuple!(tuple_impls);\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "a09086b0f2751bbca2d2c563a4b62df5b906d378",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/diesel/src/query_builder/update_statement/target.rs",
    "func": "use crate::associations::{HasTable, Identifiable};\nuse crate::dsl::Find;\nuse crate::query_dsl::methods::FindDsl;\nuse crate::query_source::Table;\n\n#[doc(hidden)]\n#[derive(Debug)]\npub struct UpdateTarget<Table, WhereClause> {\n    pub table: Table,\n    pub where_clause: WhereClause,\n}\n\n/// A type which can be passed to [`update`] or [`delete`].\n///\n/// Apps will never need to implement this type directly. There are three kinds\n/// which implement this trait. Tables, queries which have only had `filter`\n/// called on them, and types which implement `Identifiable`.\n///\n/// When a table is passed to `update`, every row in the table will be updated.\n/// You can scope this down by calling [`filter`] which will\n/// result in `UPDATE your_table SET ... WHERE args_to_filter`. Passing a type\n/// which implements `Identifiable` is the same as passing\n/// `SomeStruct::table().find(some_struct)`.\n///\n/// [`update`]: crate::update()\n/// [`delete`]: crate::delete()\n/// [`filter`]: crate::query_builder::UpdateStatement::filter()\npub trait IntoUpdateTarget: HasTable {\n    /// What is the `WHERE` clause of this target?\n    type WhereClause;\n\n    /// Decomposes `self` into the table and where clause.\n    fn into_update_target(self) -> UpdateTarget<Self::Table, Self::WhereClause>;\n}\n\nimpl<T, Tab, V> IntoUpdateTarget for T\nwhere\n    T: Identifiable<Table = Tab>,\n    Tab: Table + FindDsl<T::Id>,\n    Find<Tab, T::Id>: IntoUpdateTarget<Table = Tab, WhereClause = V>,\n{\n    type WhereClause = V;\n\n    fn into_update_target(self) -> UpdateTarget<Self::Table, Self::WhereClause> {\n        T::table().find(self.id()).into_update_target()\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "2f90eb2dec11fcfd6a98d7fe80e30688b4170b60",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/diesel_tests/tests/filter.rs",
    "func": "use crate::schema::*;\nuse diesel::*;\n\nmacro_rules! assert_sets_eq {\n    ($set1:expr, $set2:expr) => {\n        let set1 = { $set1 };\n        let set2 = { $set2 };\n        let s1r: Vec<_> = set1.iter().filter(|&si| !set2.contains(si)).collect();\n        assert!(\n            s1r.len() == 0,\n            \"left set contains items not found in right set: {:?}\",\n            s1r\n        );\n        let s2r: Vec<_> = set2.iter().filter(|&si| !set1.contains(si)).collect();\n        assert!(\n            s2r.len() == 0,\n            \"right set contains items not found in left set: {:?}\",\n            s2r\n        );\n    };\n}\n\n#[test]\nfn filter_by_int_equality() {\n    use crate::schema::users::dsl::*;\n\n    let connection = &mut connection_with_sean_and_tess_in_users_table();\n    let sean_id = find_user_by_name(\"Sean\", connection).id;\n    let tess_id = find_user_by_name(\"Tess\", connection).id;\n    let unused_id = sean_id + tess_id;\n\n    let sean = User::new(sean_id, \"Sean\");\n    let tess = User::new(tess_id, \"Tess\");\n    assert_eq!(Ok(sean), users.filter(id.eq(sean_id)).first(connection));\n    assert_eq!(Ok(tess), users.filter(id.eq(tess_id)).first(connection));\n    assert_eq!(\n        Err(NotFound),\n        users.filter(id.eq(unused_id)).first::<User>(connection)\n    );\n}\n\n#[test]\nfn filter_by_string_equality() {\n    use crate::schema::users::dsl::*;\n\n    let connection = &mut connection_with_sean_and_tess_in_users_table();\n\n    let sean = User::new(1, \"Sean\");\n    let tess = User::new(2, \"Tess\");\n    assert_eq!(Ok(sean), users.filter(name.eq(\"Sean\")).first(connection));\n    assert_eq!(Ok(tess), users.filter(name.eq(\"Tess\")).first(connection));\n    assert_eq!(\n        Err(NotFound),\n        users.filter(name.eq(\"Jim\")).first::<User>(connection)\n    );\n}\n\n#[test]\nfn filter_by_equality_on_nullable_columns() {\n    use crate::schema::users::dsl::*;\n\n    let connection = &mut connection();\n    let data = vec![\n        NewUser::new(\"Sean\", Some(\"black\")),\n        NewUser::new(\"Tess\", Some(\"brown\")),\n        NewUser::new(\"Jim\", Some(\"black\")),\n    ];\n    insert_into(users)\n        .values(&data)\n        .execute(connection)\n        .unwrap();\n\n    let data = users.order(id).load::<User>(connection).unwrap();\n    let sean = data[0].clone();\n    let tess = data[1].clone();\n    let jim = data[2].clone();\n\n    let source = users.filter(hair_color.eq(\"black\"));\n    assert_sets_eq!(vec![sean, jim], source.load(connection).unwrap());\n\n    let source = users.filter(hair_color.eq(\"brown\"));\n    assert_eq!(vec![tess], source.load(connection).unwrap());\n}\n\n#[test]\nfn filter_by_is_not_null_on_nullable_columns() {\n    use crate::schema::users::dsl::*;\n\n    let connection = &mut connection();\n    let data = vec![\n        NewUser::new(\"Derek\", Some(\"red\")),\n        NewUser::new(\"Gordon\", None),\n    ];\n    insert_into(users)\n        .values(&data)\n        .execute(connection)\n        .unwrap();\n    let data = users.order(id).load::<User>(connection).unwrap();\n    let derek = data[0].clone();\n\n    let source = users.filter(hair_color.is_not_null());\n    assert_eq!(vec![derek], source.load(connection).unwrap());\n}\n\n#[test]\nfn filter_by_is_null_on_nullable_columns() {\n    use crate::schema::users::dsl::*;\n\n    let connection = &mut connection();\n    let data = vec![\n        NewUser::new(\"Derek\", Some(\"red\")),\n        NewUser::new(\"Gordon\", None),\n    ];\n    insert_into(users)\n        .values(&data)\n        .execute(connection)\n        .unwrap();\n    let data = users.order(id).load::<User>(connection).unwrap();\n    let gordon = data[1].clone();\n\n    let source = users.filter(hair_color.is_null());\n    assert_eq!(vec![gordon], source.load(connection).unwrap());\n}\n\n#[test]\nfn filter_after_joining() {\n    use crate::schema::users::name;\n\n    let connection = &mut connection_with_sean_and_tess_in_users_table();\n    diesel::sql_query(\n        \"INSERT INTO posts (id, title, user_id) VALUES\n                       (1, 'Hello', 1), (2, 'World', 2)\",\n    )\n    .execute(connection)\n    .unwrap();\n\n    let sean = User::new(1, \"Sean\");\n    let tess = User::new(2, \"Tess\");\n    let seans_post = Post::new(1, 1, \"Hello\", None);\n    let tess_post = Post::new(2, 2, \"World\", None);\n    let source = users::table.inner_join(posts::table);\n    assert_eq!(\n        Ok((sean, seans_post)),\n        source.filter(name.eq(\"Sean\")).first(connection)\n    );\n    assert_eq!(\n        Ok((tess, tess_post)),\n        source.filter(name.eq(\"Tess\")).first(connection)\n    );\n    assert_eq!(\n        Err(NotFound),\n        source\n            .filter(name.eq(\"Jim\"))\n            .first::<(User, Post)>(connection)\n    );\n}\n\n#[test]\nfn select_then_filter() {\n    use crate::schema::users::dsl::*;\n\n    let connection = &mut connection_with_sean_and_tess_in_users_table();\n\n    let source = users.select(name);\n    assert_eq!(\n        Ok(\"Sean\".to_string()),\n        source.filter(name.eq(\"Sean\")).first(connection)\n    );\n    assert_eq!(\n        Ok(\"Tess\".to_string()),\n        source.filter(name.eq(\"Tess\")).first(connection)\n    );\n    assert_eq!(\n        Err(NotFound),\n        source.filter(name.eq(\"Jim\")).first::<String>(connection)\n    );\n}\n\n#[test]\nfn filter_then_select() {\n    use crate::schema::users::dsl::*;\n\n    let connection = &mut connection();\n    let data = vec![NewUser::new(\"Sean\", None), NewUser::new(\"Tess\", None)];\n    insert_into(users)\n        .values(&data)\n        .execute(connection)\n        .unwrap();\n\n    assert_eq!(\n        Ok(\"Sean\".to_string()),\n        users.filter(name.eq(\"Sean\")).select(name).first(connection)\n    );\n    assert_eq!(\n        Ok(\"Tess\".to_string()),\n        users.filter(name.eq(\"Tess\")).select(name).first(connection)\n    );\n    assert_eq!(\n        Err(NotFound),\n        users\n            .filter(name.eq(\"Jim\"))\n            .select(name)\n            .first::<String>(connection)\n    );\n}\n\n#[test]\nfn select_by_then_filter() {\n    use crate::schema::users::dsl::*;\n\n    let connection = &mut connection_with_sean_and_tess_in_users_table();\n\n    let source = users.select(UserName::as_select());\n    assert_eq!(\n        Ok(UserName::new(\"Sean\")),\n        source.filter(name.eq(\"Sean\")).first(connection)\n    );\n    assert_eq!(\n        Ok(UserName::new(\"Tess\")),\n        source.filter(name.eq(\"Tess\")).first(connection)\n    );\n    assert_eq!(\n        Err(NotFound),\n        source.filter(name.eq(\"Jim\")).first::<UserName>(connection)\n    );\n}\n\n#[test]\nfn filter_then_select_by() {\n    use crate::schema::users::dsl::*;\n\n    let connection = &mut connection_with_sean_and_tess_in_users_table();\n\n    assert_eq!(\n        Ok(UserName::new(\"Sean\")),\n        users\n            .filter(name.eq(\"Sean\"))\n            .select(UserName::as_select())\n            .first(connection)\n    );\n    assert_eq!(\n        Ok(UserName::new(\"Tess\")),\n        users\n            .filter(name.eq(\"Tess\"))\n            .select(UserName::as_select())\n            .first(connection)\n    );\n    assert_eq!(\n        Err(NotFound),\n        users\n            .filter(name.eq(\"Jim\"))\n            .select(UserName::as_select())\n            .first::<UserName>(connection)\n    );\n}\n\n#[test]\nfn filter_on_multiple_columns() {\n    use crate::schema::users::dsl::*;\n\n    let connection = &mut connection();\n    let data: &[_] = &[\n        NewUser::new(\"Sean\", Some(\"black\")),\n        NewUser::new(\"Sean\", Some(\"brown\")),\n        NewUser::new(\"Sean\", None),\n        NewUser::new(\"Tess\", Some(\"black\")),\n        NewUser::new(\"Tess\", Some(\"brown\")),\n    ];\n    insert_into(users).values(data).execute(connection).unwrap();\n    let data = users.order(id).load::<User>(connection).unwrap();\n    let black_haired_sean = data[0].clone();\n    let brown_haired_sean = data[1].clone();\n    let black_haired_tess = data[3].clone();\n    let brown_haired_tess = data[4].clone();\n\n    let source = users.filter(name.eq(\"Sean\").and(hair_color.eq(\"black\")));\n    assert_eq!(vec![black_haired_sean], source.load(connection).unwrap());\n\n    let source = users.filter(name.eq(\"Sean\").and(hair_color.eq(\"brown\")));\n    assert_eq!(vec![brown_haired_sean], source.load(connection).unwrap());\n\n    let source = users.filter(name.eq(\"Tess\").and(hair_color.eq(\"black\")));\n    assert_eq!(vec![black_haired_tess], source.load(connection).unwrap());\n\n    let source = users.filter(name.eq(\"Tess\").and(hair_color.eq(\"brown\")));\n    assert_eq!(vec![brown_haired_tess], source.load(connection).unwrap());\n}\n\n#[test]\nfn filter_called_twice_means_same_thing_as_and() {\n    use crate::schema::users::dsl::*;\n\n    let connection = &mut connection();\n    let data: &[_] = &[\n        NewUser::new(\"Sean\", Some(\"black\")),\n        NewUser::new(\"Sean\", Some(\"brown\")),\n        NewUser::new(\"Sean\", None),\n        NewUser::new(\"Tess\", Some(\"black\")),\n        NewUser::new(\"Tess\", Some(\"brown\")),\n    ];\n    insert_into(users).values(data).execute(connection).unwrap();\n    let data = users.order(id).load::<User>(connection).unwrap();\n    let black_haired_sean = data[0].clone();\n    let brown_haired_sean = data[1].clone();\n    let black_haired_tess = data[3].clone();\n    let brown_haired_tess = data[4].clone();\n\n    let source = users.filter(name.eq(\"Sean\")).filter(hair_color.eq(\"black\"));\n    assert_eq!(vec![black_haired_sean], source.load(connection).unwrap());\n\n    let source = users.filter(name.eq(\"Sean\")).filter(hair_color.eq(\"brown\"));\n    assert_eq!(vec![brown_haired_sean], source.load(connection).unwrap());\n\n    let source = users.filter(name.eq(\"Tess\")).filter(hair_color.eq(\"black\"));\n    assert_eq!(vec![black_haired_tess], source.load(connection).unwrap());\n\n    let source = users.filter(name.eq(\"Tess\")).filter(hair_color.eq(\"brown\"));\n    assert_eq!(vec![brown_haired_tess], source.load(connection).unwrap());\n}\n\ntable! {\n    points (x) {\n        x -> Integer,\n        y -> Integer,\n    }\n}\n\n#[test]\nfn filter_on_column_equality() {\n    use self::points::dsl::*;\n\n    let connection = &mut connection();\n    diesel::sql_query(\"INSERT INTO points (x, y) VALUES (1, 1), (1, 2), (2, 2)\")\n        .execute(connection)\n        .unwrap();\n\n    let expected_data = vec![(1, 1), (2, 2)];\n    let query = points.order(x).filter(x.eq(y));\n    let data: Vec<_> = query.load(connection).unwrap();\n    assert_sets_eq!(expected_data, data);\n}\n\n#[test]\nfn filter_with_or() {\n    use crate::schema::users::dsl::*;\n\n    let connection = &mut connection_with_sean_and_tess_in_users_table();\n    insert_into(users)\n        .values(&NewUser::new(\"Jim\", None))\n        .execute(connection)\n        .unwrap();\n\n    let expected_users = vec![User::new(1, \"Sean\"), User::new(2, \"Tess\")];\n    let data: Vec<_> = users\n        .order(id)\n        .filter(name.eq(\"Sean\").or(name.eq(\"Tess\")))\n        .load(connection)\n        .unwrap();\n\n    assert_sets_eq!(expected_users, data);\n}\n\n#[test]\nfn or_doesnt_mess_with_precedence_of_previous_statements() {\n    use crate::schema::users::dsl::*;\n\n    let connection = &mut connection_with_sean_and_tess_in_users_table();\n    let f = false.into_sql::<sql_types::Bool>();\n    let count = users\n        .filter(f)\n        .filter(f.or(true.into_sql::<sql_types::Bool>()))\n        .count()\n        .first(connection);\n\n    assert_eq!(Ok(0), count);\n\n    let count = users\n        .filter(f.or(f).and(f.or(true.into_sql::<sql_types::Bool>())))\n        .count()\n        .first(connection);\n\n    assert_eq!(Ok(0), count);\n}\n\n#[test]\nfn not_does_not_affect_expressions_other_than_those_passed_to_it() {\n    use crate::schema::users::dsl::*;\n    use diesel::dsl::not;\n\n    let connection = &mut connection_with_sean_and_tess_in_users_table();\n    let count = users\n        .filter(not(name.eq(\"Tess\")))\n        .filter(id.eq(1))\n        .count()\n        .get_result(connection);\n\n    assert_eq!(Ok(1), count);\n}\n\n#[test]\nfn not_affects_arguments_passed_when_they_contain_higher_operator_precedence() {\n    use crate::schema::users::dsl::*;\n    use diesel::dsl::not;\n\n    let connection = &mut connection_with_sean_and_tess_in_users_table();\n    let count = users\n        .filter(not(name.eq(\"Tess\").and(id.eq(1))))\n        .count()\n        .get_result(connection);\n\n    assert_eq!(Ok(2), count);\n}\n\nuse diesel::sql_types::VarChar;\ndefine_sql_function!(fn lower(x: VarChar) -> VarChar);\n\n#[test]\nfn filter_by_boxed_predicate() {\n    fn by_name(\n        name: &str,\n    ) -> Box<dyn BoxableExpression<users::table, TestBackend, SqlType = sql_types::Bool>> {\n        Box::new(lower(users::name).eq(name.to_string()))\n    }\n\n    let connection = &mut connection_with_sean_and_tess_in_users_table();\n    let sean = User::new(1, \"Sean\");\n    let tess = User::new(2, \"Tess\");\n    let queried_sean = users::table.filter(by_name(\"sean\")).first(connection);\n    let queried_tess = users::table.filter(by_name(\"tess\")).first(connection);\n\n    assert_eq!(Ok(sean), queried_sean);\n    assert_eq!(Ok(tess), queried_tess);\n}\n\n#[test]\nfn filter_like_nullable_column() {\n    use crate::schema::users::dsl::*;\n\n    let conn = &mut connection_with_gilbert_and_jonathan_in_users_table();\n    let jonathan = find_user_by_name(\"Jonathan\", conn);\n\n    let data = users.filter(hair_color.like(\"%blue%\")).load(conn);\n\n    let expected = Ok(vec![jonathan]);\n    assert_eq!(expected, data);\n}\n\n#[test]\nfn filter_subselect_referencing_outer_table() {\n    use diesel::dsl::exists;\n\n    let conn = &mut connection_with_sean_and_tess_in_users_table();\n    let sean = find_user_by_name(\"Sean\", conn);\n\n    insert_into(posts::table)\n        .values(&vec![\n            sean.new_post(\"Hello\", None),\n            sean.new_post(\"Hello 2\", None),\n        ])\n        .execute(conn)\n        .unwrap();\n\n    let expected = Ok(vec![sean]);\n    let users_with_published_posts = users::table\n        .filter(exists(posts::table.filter(posts::user_id.eq(users::id))))\n        .load(conn);\n    assert_eq!(expected, users_with_published_posts);\n\n    let users_with_published_posts = users::table\n        .filter(\n            users::id.eq_any(\n                posts::table\n                    .select(posts::user_id)\n                    .filter(posts::user_id.eq(users::id)),\n            ),\n        )\n        .load(conn);\n    assert_eq!(expected, users_with_published_posts);\n}\n\n#[test]\nfn filter_subselect_with_boxed_query() {\n    use crate::schema::users::dsl::*;\n\n    let conn = &mut connection_with_sean_and_tess_in_users_table();\n    let sean = find_user_by_name(\"Sean\", conn);\n\n    let subselect = users.filter(name.eq(\"Sean\")).select(id).into_boxed();\n\n    let expected = Ok(vec![sean]);\n    let data = users.filter(id.eq_any(subselect)).load(conn);\n    assert_eq!(expected, data);\n}\n\n#[test]\n// FIXME: this test shouldn't need to modify schema each run\n#[cfg(not(feature = \"mysql\"))]\n// https://github.com/rust-lang/rust/issues/124396\n#[allow(unknown_lints, non_local_definitions)]\nfn filter_subselect_with_nullable_column() {\n    use crate::schema_dsl::*;\n    table! {\n        heroes {\n            id -> Integer,\n            name -> Text,\n            home_world -> Nullable<Integer>,\n        }\n    }\n    table! {\n        home_worlds {\n            id -> Integer,\n            name -> Text,\n        }\n    }\n\n    allow_tables_to_appear_in_same_query!(heroes, home_worlds);\n\n    #[derive(Debug, Queryable, PartialEq)]\n    struct Hero {\n        id: i32,\n        name: String,\n        home_world: Option<i32>,\n    }\n    let connection = &mut connection();\n\n    create_table(\n        \"home_worlds\",\n        (\n            integer(\"id\").primary_key().auto_increment(),\n            string(\"name\").not_null(),\n        ),\n    )\n    .execute(connection)\n    .unwrap();\n\n    create_table(\n        \"heroes\",\n        (\n            integer(\"id\").primary_key().auto_increment(),\n            string(\"name\").not_null(),\n            integer(\"home_world\"),\n        ),\n    )\n    .execute(connection)\n    .unwrap();\n\n    ::diesel::insert_into(home_worlds::table)\n        .values(home_worlds::name.eq(\"Tatooine\"))\n        .execute(connection)\n        .unwrap();\n    ::diesel::insert_into(heroes::table)\n        .values((\n            heroes::name.eq(\"Luke Skywalker\"),\n            heroes::home_world.eq(Some(1)),\n        ))\n        .execute(connection)\n        .unwrap();\n    ::diesel::insert_into(heroes::table)\n        .values((\n            heroes::name.eq(\"R2D2\"),\n            heroes::home_world.eq::<Option<i32>>(None),\n        ))\n        .execute(connection)\n        .unwrap();\n\n    let expected = vec![Hero {\n        id: 1,\n        name: String::from(\"Luke Skywalker\"),\n        home_world: Some(1),\n    }];\n\n    let query = heroes::table\n        .filter(heroes::home_world.eq_any(home_worlds::table.select(home_worlds::id).nullable()))\n        .load::<Hero>(connection)\n        .unwrap();\n\n    assert_eq!(query, expected);\n\n    let query = heroes::table\n        .filter(\n            heroes::home_world.eq_any(\n                home_worlds::table\n                    .select(home_worlds::id)\n                    .into_boxed()\n                    .nullable(),\n            ),\n        )\n        .load::<Hero>(connection)\n        .unwrap();\n\n    assert_eq!(query, expected);\n\n    let query = heroes::table\n        .filter(\n            heroes::home_world.eq_any(\n                home_worlds::table\n                    .select(home_worlds::id)\n                    .nullable()\n                    .into_boxed(),\n            ),\n        )\n        .load::<Hero>(connection)\n        .unwrap();\n\n    assert_eq!(query, expected);\n}\n\n#[test]\n#[cfg(feature = \"postgres\")]\nfn filter_subselect_with_pg_any() {\n    let conn = &mut connection_with_sean_and_tess_in_users_table();\n    let sean = find_user_by_name(\"Sean\", conn);\n\n    insert_into(posts::table)\n        .values(&vec![\n            sean.new_post(\"Hello\", None),\n            sean.new_post(\"Hello 2\", None),\n        ])\n        .execute(conn)\n        .unwrap();\n\n    let users_with_published_posts = users::table\n        .filter(\n            users::id.eq_any(\n                posts::table\n                    .select(posts::user_id)\n                    .filter(posts::user_id.eq(users::id)),\n            ),\n        )\n        .load(conn);\n    assert_eq!(Ok(vec![sean]), users_with_published_posts);\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "2a050220e9e3b62ad69ab4e10bced1659a4ebdcc",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/diesel_tests/tests/combination.rs",
    "func": "use crate::schema::*;\nuse diesel::query_dsl::positional_order_dsl::{OrderColumn, PositionalOrderDsl};\nuse diesel::*;\n\n#[test]\nfn union() {\n    use crate::schema::users::dsl::*;\n\n    let conn = &mut connection();\n    let data = vec![\n        NewUser::new(\"Sean\", None),\n        NewUser::new(\"Tess\", None),\n        NewUser::new(\"Jim\", None),\n    ];\n    insert_into(users).values(&data).execute(conn).unwrap();\n    let data = users.order(id).load::<User>(conn).unwrap();\n    let sean = &data[0];\n    let tess = &data[1];\n    let jim = &data[2];\n\n    let expected_data = vec![\n        User::new(jim.id, \"Jim\"),\n        User::new(sean.id, \"Sean\"),\n        User::new(tess.id, \"Tess\"),\n    ];\n    let data: Vec<_> = users\n        .filter(id.le(tess.id))\n        .union(users.filter(id.ge(tess.id)))\n        .positional_order_by(2) // name is the second column\n        .load(conn)\n        .unwrap();\n    assert_eq!(expected_data, data);\n}\n\n#[test]\nfn union_all() {\n    use crate::schema::users::dsl::*;\n\n    let conn = &mut connection();\n    let data = vec![\n        NewUser::new(\"Sean\", None),\n        NewUser::new(\"Tess\", None),\n        NewUser::new(\"Jim\", None),\n    ];\n    insert_into(users).values(&data).execute(conn).unwrap();\n    let data = users.order(id).load::<User>(conn).unwrap();\n    let sean = &data[0];\n    let tess = &data[1];\n    let jim = &data[2];\n\n    let expected_data = vec![\n        User::new(jim.id, \"Jim\"),\n        User::new(sean.id, \"Sean\"),\n        User::new(tess.id, \"Tess\"),\n        User::new(tess.id, \"Tess\"),\n    ];\n    let data: Vec<_> = users\n        .filter(id.le(tess.id))\n        .union_all(users.filter(id.ge(tess.id)))\n        .positional_order_by(2) // name is the second column\n        .load(conn)\n        .unwrap();\n    assert_eq!(expected_data, data);\n}\n\n#[test]\n#[cfg(any(feature = \"postgres\", feature = \"sqlite\"))]\nfn intersect() {\n    use crate::schema::users::dsl::*;\n\n    let conn = &mut connection();\n    let data = vec![\n        NewUser::new(\"Sean\", None),\n        NewUser::new(\"Tess\", None),\n        NewUser::new(\"Jim\", None),\n    ];\n    insert_into(users).values(&data).execute(conn).unwrap();\n    let data = users.order(name).load::<User>(conn).unwrap();\n    let _sean = &data[1];\n    let tess = &data[2];\n    let _jim = &data[0];\n\n    let expected_data = vec![User::new(tess.id, \"Tess\")];\n    let data: Vec<_> = users\n        .filter(id.le(tess.id))\n        .intersect(users.filter(id.ge(tess.id)))\n        .positional_order_by(2) // name is the second column\n        .load(conn)\n        .unwrap();\n    assert_eq!(expected_data, data);\n}\n\n#[test]\n#[cfg(any(feature = \"postgres\", feature = \"sqlite\"))]\nfn except() {\n    use crate::schema::users::dsl::*;\n\n    let conn = &mut connection();\n    let data = vec![\n        NewUser::new(\"Sean\", None),\n        NewUser::new(\"Tess\", None),\n        NewUser::new(\"Jim\", None),\n    ];\n    insert_into(users).values(&data).execute(conn).unwrap();\n    let data = users.load::<User>(conn).unwrap();\n    let sean = &data[0];\n    let tess = &data[1];\n    let _jim = &data[2];\n\n    let expected_data = vec![User::new(sean.id, \"Sean\")];\n    let data: Vec<_> = users\n        .filter(id.le(tess.id))\n        .except(users.filter(id.ge(tess.id)))\n        .positional_order_by(2) // name is the second column\n        .load(conn)\n        .unwrap();\n    assert_eq!(expected_data, data);\n}\n\n#[test]\nfn union_with_limit() {\n    use crate::schema::users::dsl::*;\n\n    let conn = &mut connection();\n    let data = vec![\n        NewUser::new(\"Sean\", None),\n        NewUser::new(\"Tess\", None),\n        NewUser::new(\"Jim\", None),\n    ];\n    insert_into(users).values(&data).execute(conn).unwrap();\n    let data = users.order(id).load::<User>(conn).unwrap();\n    let sean = &data[0];\n    let tess = &data[1];\n    let _jim = &data[2];\n\n    let data: Vec<User> = users\n        .filter(id.le(tess.id))\n        .union(users.filter(id.ge(tess.id)))\n        .limit(2)\n        .positional_order_by(1) // id is the first column\n        .load(conn)\n        .unwrap();\n\n    let expected_data = vec![User::new(sean.id, \"Sean\"), User::new(tess.id, \"Tess\")];\n    assert_eq!(expected_data, data);\n}\n\n#[test]\nfn union_with_offset() {\n    use crate::schema::users::dsl::*;\n\n    let conn = &mut connection();\n    let data = vec![\n        NewUser::new(\"Sean\", None),\n        NewUser::new(\"Tess\", None),\n        NewUser::new(\"Jim\", None),\n    ];\n    insert_into(users).values(&data).execute(conn).unwrap();\n    let data = users.order(id).load::<User>(conn).unwrap();\n    let sean = &data[0];\n    let tess = &data[1];\n    let _jim = &data[2];\n\n    let data: Vec<User> = users\n        .filter(id.le(tess.id))\n        .union(users.filter(id.ge(tess.id)))\n        .positional_order_by(2) // name is the second column\n        .limit(3)\n        .offset(1)\n        .load(conn)\n        .unwrap();\n\n    let expected_data = vec![User::new(sean.id, \"Sean\"), User::new(tess.id, \"Tess\")];\n    assert_eq!(expected_data, data);\n}\n\n#[test]\nfn union_with_order() {\n    let conn = &mut connection();\n    let data = vec![\n        NewUser::new(\"Sean\", None),\n        NewUser::new(\"Tess\", None),\n        NewUser::new(\"Jim\", None),\n    ];\n    insert_into(users::table)\n        .values(&data)\n        .execute(conn)\n        .unwrap();\n\n    let users = users::table\n        .select(users::name)\n        .order_by(users::id.asc())\n        .limit(1)\n        .union(\n            users::table\n                .order_by(users::id.desc())\n                .select(users::name)\n                .limit(1),\n        )\n        .positional_order_by(OrderColumn::from(1).asc())\n        .load::<String>(conn)\n        .unwrap();\n\n    assert_eq!(vec![String::from(\"Jim\"), \"Sean\".into()], users);\n}\n\n#[test]\nfn as_subquery_for_eq_in() {\n    let conn = &mut connection_with_sean_and_tess_in_users_table();\n\n    insert_into(posts::table)\n        .values(&[\n            (posts::user_id.eq(1), posts::title.eq(\"First post\")),\n            (posts::user_id.eq(2), posts::title.eq(\"Second post\")),\n        ])\n        .execute(conn)\n        .unwrap();\n\n    let subquery = users::table\n        .select(users::id)\n        .filter(users::name.eq(\"Sean\"))\n        .union(\n            users::table\n                .select(users::id)\n                .filter(users::name.ne(\"Sean\")),\n        );\n\n    let out = posts::table\n        .filter(posts::user_id.eq_any(subquery))\n        .select(posts::title)\n        .order_by(posts::title)\n        .load::<String>(conn)\n        .unwrap();\n\n    assert_eq!(out, vec![\"First post\", \"Second post\"]);\n}\n\n#[test]\nfn positional_order_by() {\n    use crate::schema::users::dsl::*;\n\n    let conn = &mut connection();\n    let data = vec![\n        NewUser::new(\"Sean\", None),\n        NewUser::new(\"Tess\", Some(\"green\")),\n        NewUser::new(\"Jim\", None),\n        NewUser::new(\"Tess\", Some(\"blue\")),\n        NewUser::new(\"Arnold\", Some(\"red\")),\n    ];\n    insert_into(users).values(&data).execute(conn).unwrap();\n    let data = users.order(id).load::<User>(conn).unwrap();\n    let sean = &data[0];\n    let tess_green = &data[1];\n    let jim = &data[2];\n    let tess_blue = &data[3];\n    let arnold = &data[4];\n\n    let expected_data = vec![\n        User::new(sean.id, \"Sean\"),\n        User::new(jim.id, \"Jim\"),\n        User::with_hair_color(tess_blue.id, \"Tess\", \"blue\"),\n        User::with_hair_color(tess_green.id, \"Tess\", \"green\"),\n        User::with_hair_color(arnold.id, \"Arnold\", \"red\"),\n    ];\n    let data: Vec<_> = users\n        .filter(id.le(jim.id))\n        .union(users.filter(id.ge(jim.id)))\n        .positional_order_by((\n            // hair color is the third column\n            // Also, we don't need OrderColumn here because .asc() is the default direction\n            #[cfg(not(feature = \"postgres\"))]\n            3,\n            // postgres doesn't sort nulls first by default, so we need to call nulls_first().\n            // This also tests whether or not NullsFirst implements PositionalOrderExpr\n            #[cfg(feature = \"postgres\")]\n            OrderColumn::from(3).asc().nulls_first(), // hair color is the third column\n            OrderColumn::from(2).desc(), // name is the second column\n        ))\n        .load(conn)\n        .unwrap();\n    assert_eq!(expected_data, data);\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "3fcb6c14a7ca53e0a60de100c74e1357582f2575",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/diesel_tests/tests/schema_inference.rs",
    "func": "#[cfg(feature = \"sqlite\")]\nmod sqlite {\n    use crate::schema::*;\n    use chrono::*;\n    use diesel::*;\n\n    #[derive(Queryable, PartialEq, Debug, Insertable)]\n    #[diesel(table_name = infer_all_the_ints)]\n    struct InferredInts {\n        col1: i32,\n        col2: i32,\n        col3: i32,\n        col4: i32,\n        col5: i16,\n        col6: i16,\n        col7: i16,\n        col8: i64,\n        col9: i64,\n        col10: i64,\n        col11: i16,\n        col12: i32,\n        col13: i64,\n    }\n\n    #[test]\n    fn integers_infer_to_semantically_correct_types() {\n        let conn = &mut connection();\n        let inferred_ints = InferredInts {\n            col1: 1,\n            col2: 2,\n            col3: 3,\n            col4: 4,\n            col5: 5,\n            col6: 6,\n            col7: 7,\n            col8: 8,\n            col9: 9,\n            col10: 10,\n            col11: 11,\n            col12: 12,\n            col13: 13,\n        };\n        insert_into(infer_all_the_ints::table)\n            .values(&inferred_ints)\n            .execute(conn)\n            .unwrap();\n\n        assert_eq!(\n            Ok(vec![inferred_ints]),\n            infer_all_the_ints::table.load(conn)\n        );\n    }\n\n    #[derive(Queryable, PartialEq, Debug, Insertable)]\n    #[diesel(table_name = infer_all_the_bools)]\n    struct InferredBools {\n        col1: bool,\n        col2: bool,\n        col3: bool,\n        col4: bool,\n    }\n\n    #[test]\n    fn bool_types_infer_to_bool() {\n        let conn = &mut connection();\n        let inferred_bools = InferredBools {\n            col1: true,\n            col2: true,\n            col3: false,\n            col4: false,\n        };\n        insert_into(infer_all_the_bools::table)\n            .values(&inferred_bools)\n            .execute(conn)\n            .unwrap();\n\n        assert_eq!(\n            Ok(vec![inferred_bools]),\n            infer_all_the_bools::table.load(conn)\n        );\n    }\n\n    #[derive(Queryable, PartialEq, Debug, Insertable)]\n    #[diesel(table_name = infer_all_the_strings)]\n    struct InferredStrings {\n        col1: String,\n        col2: String,\n        col3: String,\n        col4: String,\n        col5: String,\n        col6: String,\n        col7: String,\n        col8: String,\n        col9: Vec<u8>,\n        col10: Vec<u8>,\n    }\n\n    #[test]\n    fn strings_infer_to_semantically_correct_types() {\n        let conn = &mut connection();\n        let inferred_strings = InferredStrings {\n            col1: \"Hello\".into(),\n            col2: \"Hello\".into(),\n            col3: \"Hello\".into(),\n            col4: \"Hello\".into(),\n            col5: \"Hello\".into(),\n            col6: \"Hello\".into(),\n            col7: \"Hello\".into(),\n            col8: \"Hello\".into(),\n            col9: vec![1, 2, 3],\n            col10: vec![1, 2, 3],\n        };\n        insert_into(infer_all_the_strings::table)\n            .values(&inferred_strings)\n            .execute(conn)\n            .unwrap();\n\n        assert_eq!(\n            Ok(vec![inferred_strings]),\n            infer_all_the_strings::table.load(conn)\n        );\n    }\n\n    #[derive(Queryable, PartialEq, Debug, Insertable)]\n    #[diesel(table_name = infer_all_the_floats)]\n    struct InferredFloats {\n        col1: f32,\n        col2: f32,\n        col3: f64,\n        col4: f64,\n        col5: f64,\n        col6: f64,\n    }\n\n    #[test]\n    fn floats_infer_to_semantically_correct_types() {\n        let conn = &mut connection();\n        let inferred_floats = InferredFloats {\n            col1: 1.0,\n            col2: 2.0,\n            col3: 3.0,\n            col4: 4.0,\n            col5: 5.0,\n            col6: 6.0,\n        };\n        insert_into(infer_all_the_floats::table)\n            .values(&inferred_floats)\n            .execute(conn)\n            .unwrap();\n\n        assert_eq!(\n            Ok(vec![inferred_floats]),\n            infer_all_the_floats::table.load(conn)\n        );\n    }\n\n    #[derive(Queryable, PartialEq, Debug, Insertable)]\n    #[diesel(table_name = infer_all_the_datetime_types)]\n    struct InferredDatetimeTypes {\n        dt: NaiveDateTime,\n        date: NaiveDate,\n        time: NaiveTime,\n        timestamp: NaiveDateTime,\n    }\n\n    #[test]\n    fn datetime_types_are_correctly_inferred() {\n        let conn = &mut connection();\n\n        let dt = NaiveDate::from_ymd_opt(2016, 7, 8)\n            .unwrap()\n            .and_hms_opt(9, 10, 11)\n            .unwrap();\n        let inferred_datetime_types = InferredDatetimeTypes {\n            dt,\n            date: dt.date(),\n            time: dt.time(),\n            timestamp: dt,\n        };\n\n        insert_into(infer_all_the_datetime_types::table)\n            .values(&inferred_datetime_types)\n            .execute(conn)\n            .unwrap();\n\n        assert_eq!(\n            Ok(vec![inferred_datetime_types]),\n            infer_all_the_datetime_types::table.load(conn)\n        );\n    }\n}\n\n#[cfg(feature = \"postgres\")]\nmod postgres {\n    use crate::schema::*;\n    use chrono::*;\n    use diesel::data_types::PgNumeric;\n    use diesel::*;\n    use std::collections::Bound;\n\n    #[derive(Queryable, PartialEq, Debug, Insertable)]\n    #[diesel(table_name = all_the_ranges)]\n    struct InferredRanges {\n        int4: (Bound<i32>, Bound<i32>),\n        int8: (Bound<i64>, Bound<i64>),\n        num: (Bound<PgNumeric>, Bound<PgNumeric>),\n        ts: (Bound<NaiveDateTime>, Bound<NaiveDateTime>),\n        tstz: (Bound<DateTime<Utc>>, Bound<DateTime<Utc>>),\n        date: (Bound<NaiveDate>, Bound<NaiveDate>),\n        int4multi: Vec<(Bound<i32>, Bound<i32>)>,\n        int8multi: Vec<(Bound<i64>, Bound<i64>)>,\n        nummulti: Vec<(Bound<PgNumeric>, Bound<PgNumeric>)>,\n        tsmulti: Vec<(Bound<NaiveDateTime>, Bound<NaiveDateTime>)>,\n        #[allow(clippy::type_complexity)]\n        tstzmulti: Vec<(Bound<DateTime<Utc>>, Bound<DateTime<Utc>>)>,\n        datemulti: Vec<(Bound<NaiveDate>, Bound<NaiveDate>)>,\n    }\n\n    #[test]\n    fn ranges_are_correctly_inferred() {\n        let conn = &mut connection();\n        let numeric = PgNumeric::Positive {\n            weight: 1,\n            scale: 1,\n            digits: vec![1],\n        };\n        let dt = NaiveDate::from_ymd_opt(2016, 7, 8)\n            .unwrap()\n            .and_hms_opt(9, 10, 11)\n            .unwrap();\n\n        let inferred_ranges = InferredRanges {\n            int4: (Bound::Included(5), Bound::Excluded(12)),\n            int8: (Bound::Included(5), Bound::Excluded(13)),\n            num: (Bound::Included(numeric.clone()), Bound::Unbounded),\n            ts: (Bound::Included(dt), Bound::Unbounded),\n            tstz: (\n                Bound::Unbounded,\n                Bound::Excluded(Utc.from_utc_datetime(&dt)),\n            ),\n            date: (Bound::Included(dt.date()), Bound::Unbounded),\n            int4multi: vec![(Bound::Included(5), Bound::Excluded(12))],\n            int8multi: vec![(Bound::Included(5), Bound::Excluded(13))],\n            nummulti: vec![(Bound::Included(numeric), Bound::Unbounded)],\n            tsmulti: vec![(Bound::Included(dt), Bound::Unbounded)],\n            tstzmulti: vec![(\n                Bound::Unbounded,\n                Bound::Excluded(Utc.from_utc_datetime(&dt)),\n            )],\n            datemulti: vec![(Bound::Included(dt.date()), Bound::Unbounded)],\n        };\n\n        insert_into(all_the_ranges::table)\n            .values(&inferred_ranges)\n            .execute(conn)\n            .unwrap();\n\n        assert_eq!(Ok(vec![inferred_ranges]), all_the_ranges::table.load(conn));\n    }\n}\n\n#[cfg(feature = \"mysql\")]\nmod mysql {\n    use crate::schema::*;\n    use diesel::*;\n\n    #[derive(Insertable)]\n    #[diesel(table_name = all_the_blobs)]\n    struct InferredBlobs<'a> {\n        id: i32,\n        tiny: &'a [u8],\n        normal: &'a [u8],\n        medium: &'a [u8],\n        big: &'a [u8],\n    }\n\n    #[derive(Queryable, Debug, PartialEq)]\n    struct Blobs {\n        id: i32,\n        tiny: Vec<u8>,\n        normal: Vec<u8>,\n        medium: Vec<u8>,\n        big: Vec<u8>,\n    }\n\n    #[test]\n    fn blobs_are_correctly_inferred() {\n        let conn = &mut connection();\n        let inferred_blobs = InferredBlobs {\n            id: 0,\n            tiny: &[0x01],\n            normal: &[0x02],\n            medium: &[0x03],\n            big: &[0x04],\n        };\n\n        let blobs = Blobs {\n            id: 0,\n            tiny: vec![0x01],\n            normal: vec![0x02],\n            medium: vec![0x03],\n            big: vec![0x04],\n        };\n\n        insert_into(all_the_blobs::table)\n            .values(&inferred_blobs)\n            .execute(conn)\n            .unwrap();\n        assert_eq!(Ok(vec![blobs]), all_the_blobs::table.load(conn));\n    }\n}\n\n#[test]\nfn columns_named_as_reserved_keywords_are_renamed() {\n    use crate::schema::*;\n    use diesel::*;\n\n    #[derive(Queryable, Insertable, Debug, PartialEq)]\n    #[diesel(table_name = with_keywords)]\n    struct WithKeywords {\n        fn_: i32,\n        let_: i32,\n        extern_: i32,\n    }\n\n    let value = WithKeywords {\n        fn_: 1,\n        let_: 42,\n        extern_: 51,\n    };\n\n    let conn = &mut connection();\n    insert_into(with_keywords::table)\n        .values(&value)\n        .execute(conn)\n        .unwrap();\n    assert_eq!(Ok(vec![value]), with_keywords::table.load(conn));\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "77ae5d1aed3094f1e7769e3e4c5ffed935613648",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/examples/postgres/composite_types/examples/composite2rust_coordinates.rs",
    "func": "// Function to connect to database.\nuse composite_types::establish_connection;\n\n// Bring column names of the table into scope\nuse composite_types::schema::coordinates::{coord_id, dsl::coordinates, xcoord, ycoord};\n\n// Define the signature of the SQL function we want to call:\nuse diesel::define_sql_function;\nuse diesel::sql_types::Integer;\ndefine_sql_function!(fn distance_from_origin(re: Integer,im: Integer) -> Float);\ndefine_sql_function!(fn shortest_distance() -> Record<(Integer,Float)>);\ndefine_sql_function!(fn longest_distance() -> Record<(Integer,Float)>);\n\n// Needed to select, construct the query and submit it.\nuse diesel::select;\nuse diesel::{QueryDsl, RunQueryDsl};\n\nfn main() {\n    let connection = &mut establish_connection();\n    // Experiment 1: Read tuple directly from processed table\n    let results: Vec<(i32, f32)> = coordinates\n        .select((coord_id, distance_from_origin(xcoord, ycoord)))\n        .load(connection)\n        .expect(\"Error loading numbers\");\n    for r in results {\n        println!(\"index {:?}, length {:?}\", r.0, r.1);\n    }\n    // Experiment 2: Define a type for clearer re-use\n    type Distance = (i32, f32);\n    let results: Vec<Distance> = coordinates\n        .select((coord_id, distance_from_origin(xcoord, ycoord)))\n        .load(connection)\n        .expect(\"Error loading numbers\");\n    for r in results {\n        println!(\"index {:?}, length {:?}\", r.0, r.1);\n    }\n    // Experiment 3: use tuple for single result and do some math in SQL\n    // Notice that we only expect one result, not an vector\n    // of results, so use get_result() instead of load())\n    let result: Distance = select(shortest_distance())\n        .get_result(connection)\n        .expect(\"Error loading longest distance\");\n    println!(\n        \"Coordinate {:?} has shortest distance of {:?}\",\n        result.0, result.1\n    );\n    // Unfortunately, the members of our Distance struct, a tuple, are anonymous.\n    // Will be unhandy for longer tuples.\n\n    // Experiment 4: use composite type in SQL, read as Record in Rust\n    // Notice that we only expect one result, not an vector\n    // of results, so use get_result() instead of load())\n    let result: Distance = select(longest_distance())\n        .get_result(connection)\n        .expect(\"Error loading longest distance\");\n    println!(\n        \"Coordinate {:?} has longest distance of {:?}\",\n        result.0, result.1\n    );\n    // TODO: also show an example with a recursively interpreted Record<Integer,Record<Integer,Integer>>\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "a542130015b46e6537bc04fee085954b430c01fd",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/examples/postgres/composite_types/examples/composite2rust_colors.rs",
    "func": "// Function to connect to database.\nuse composite_types::establish_connection;\n\n// Bring column names of the table into scope\nuse composite_types::schema::colors::{blue, color_id, color_name, dsl::colors, green, red};\n\n// Define the signature of the SQL function we want to call:\nuse diesel::define_sql_function;\nuse diesel::pg::Pg;\nuse diesel::pg::PgValue;\nuse diesel::sql_types::{Float, Integer, Record, Text};\ndefine_sql_function!(fn color2grey(r: Integer, g: Integer,b: Integer) -> Record<(Float,Text)>);\ndefine_sql_function!(fn color2gray(r: Integer, g: Integer,b: Integer) -> PgGrayType);\n\n// Needed to select, construct the query and submit it.\nuse diesel::deserialize::{self, FromSql, FromSqlRow};\nuse diesel::{QueryDsl, RunQueryDsl};\n\n#[derive(Debug, FromSqlRow)]\npub struct GrayType {\n    pub intensity: f32,\n    pub suggestion: String,\n}\n\n// Define how a record of this can be converted to a Postgres type.\ntype PgGrayType = Record<(Float, Text)>;\n\n// Explain how this Postgres type can be converted to a Rust type.\nimpl FromSql<PgGrayType, Pg> for GrayType {\n    fn from_sql(bytes: PgValue) -> deserialize::Result<Self> {\n        let (intensity, suggestion) = FromSql::<PgGrayType, Pg>::from_sql(bytes)?;\n        Ok(GrayType {\n            intensity,\n            suggestion,\n        })\n    }\n}\n\nfn main() {\n    let connection = &mut establish_connection();\n    // Experiment 1: Define a type for clearer re-use,\n    // similar as in the coordinates example.\n    type Color = (i32, i32, i32, i32, Option<String>);\n    let results: Vec<Color> = colors\n        .select((color_id, red, green, blue, color_name))\n        .load(connection)\n        .expect(\"Error loading colors\");\n    for r in results {\n        println!(\n            \"index {:?}, red {:?}, green {:?}, blue {:?}, name: {:?}\",\n            r.0, r.1, r.2, r.3, r.4\n        );\n    }\n    // Experiment 2: When recognizing the new type with named fields,\n    // the code is more readable.\n    let results: Vec<(i32, GrayType)> = colors\n        .select((color_id, color2grey(red, green, blue)))\n        .load(connection)\n        .expect(\"Error loading gray conversions\");\n    for (i, g) in results {\n        println!(\n            \"Color {:?} has intensity level {:?} with suggested name {:?}\",\n            i, g.intensity, g.suggestion\n        );\n    }\n    // Experiment 3: Similar, using the type also in the above listed\n    // define_sql_function!(...) definition.\n    let results: Vec<(i32, GrayType)> = colors\n        .select((color_id, color2gray(red, green, blue)))\n        .load(connection)\n        .expect(\"Error loading gray conversions\");\n    for (i, g) in results {\n        println!(\n            \"Color {:?} has intensity level {:?} with suggested name {:?}\",\n            i, g.intensity, g.suggestion\n        );\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "969cc1e49e67f1c3d68373f325058a842dc99fbc",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/examples/postgres/getting_started_step_3/src/lib.rs",
    "func": "pub mod models;\npub mod schema;\n\nuse diesel::prelude::*;\nuse dotenvy::dotenv;\nuse std::env;\n\nuse self::models::{NewPost, Post};\n\npub fn establish_connection() -> PgConnection {\n    dotenv().ok();\n\n    let database_url = env::var(\"PG_DATABASE_URL\")\n        .or_else(|_| env::var(\"DATABASE_URL\"))\n        .expect(\"DATABASE_URL must be set\");\n    PgConnection::establish(&database_url)\n        .unwrap_or_else(|_| panic!(\"Error connecting to {}\", database_url))\n}\n\npub fn create_post(conn: &mut PgConnection, title: &str, body: &str) -> Post {\n    use crate::schema::posts;\n\n    let new_post = NewPost { title, body };\n\n    diesel::insert_into(posts::table)\n        .values(&new_post)\n        .returning(Post::as_returning())\n        .get_result(conn)\n        .expect(\"Error saving new post\")\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "d7c3f6e32ac871424b6fdf470602e3a4837700cb",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/examples/postgres/getting_started_step_3/src/bin/write_post.rs",
    "func": "use getting_started_step_3_pg::*;\nuse std::io::{stdin, Read};\n\nfn main() {\n    let connection = &mut establish_connection();\n\n    let mut title = String::new();\n    let mut body = String::new();\n\n    println!(\"What would you like your title to be?\");\n    stdin().read_line(&mut title).unwrap();\n    let title = title.trim_end(); // Remove the trailing newline\n\n    println!(\"\\nOk! Let's write {title} (Press {EOF} when finished)\\n\",);\n    stdin().read_to_string(&mut body).unwrap();\n\n    let post = create_post(connection, title, &body);\n    println!(\"\\nSaved draft {title} with id {}\", post.id);\n}\n\n#[cfg(not(windows))]\nconst EOF: &str = \"CTRL+D\";\n\n#[cfg(windows)]\nconst EOF: &str = \"CTRL+Z\";\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "c9008d86ee8af9842cc89447d7ecd9ee0969a94f",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/examples/postgres/getting_started_step_3/src/bin/delete_post.rs",
    "func": "use diesel::prelude::*;\nuse getting_started_step_3_pg::*;\nuse std::env::args;\n\nfn main() {\n    use self::schema::posts::dsl::*;\n\n    let target = args().nth(1).expect(\"Expected a target to match against\");\n    let pattern = format!(\"%{target}%\");\n\n    let connection = &mut establish_connection();\n    let num_deleted = diesel::delete(posts.filter(title.like(pattern)))\n        .execute(connection)\n        .expect(\"Error deleting posts\");\n\n    println!(\"Deleted {num_deleted} posts\");\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "0b5ea37f19f4dec1e82d760f3906d0d01a78a3c2",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/examples/postgres/getting_started_step_2/src/bin/write_post.rs",
    "func": "use getting_started_step_2_pg::*;\nuse std::io::{stdin, Read};\n\nfn main() {\n    let connection = &mut establish_connection();\n\n    let mut title = String::new();\n    let mut body = String::new();\n\n    println!(\"What would you like your title to be?\");\n    stdin().read_line(&mut title).unwrap();\n    let title = title.trim_end(); // Remove the trailing newline\n\n    println!(\"\\nOk! Let's write {title} (Press {EOF} when finished)\\n\",);\n    stdin().read_to_string(&mut body).unwrap();\n\n    let post = create_post(connection, title, &body);\n    println!(\"\\nSaved draft {title} with id {}\", post.id);\n}\n\n#[cfg(not(windows))]\nconst EOF: &str = \"CTRL+D\";\n\n#[cfg(windows)]\nconst EOF: &str = \"CTRL+Z\";\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "6fd85adae1c23d2eba097904e40f86782bc29cfa",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/examples/postgres/advanced-blog-cli/src/comment.rs",
    "func": "use chrono::NaiveDateTime;\nuse diesel::prelude::*;\n\nuse crate::auth::User;\nuse crate::post::Post;\nuse crate::schema::comments;\n\n#[derive(Queryable, Identifiable, Associations)]\n#[diesel(belongs_to(User))]\n#[diesel(belongs_to(Post))]\npub struct Comment {\n    pub id: i32,\n    pub user_id: i32,\n    pub post_id: i32,\n    pub body: String,\n    pub created_at: NaiveDateTime,\n    pub updated_at: NaiveDateTime,\n}\n\npub fn render(comments_and_post_title: &[(Comment, String)]) {\n    for (comment, post_title) in comments_and_post_title {\n        println!(\"On post {post_title}\");\n        println!(\n            \"At {} (id: {})\",\n            comment.updated_at.format(\"%F %T\"),\n            comment.id\n        );\n        println!(\"{}\", comment.body);\n        println!(\"===============\\n\");\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "ec1af516d543ba8ca5c5b087f8f2513d4ae456ba",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/examples/mysql/getting_started_step_3/tests/step_3.rs",
    "func": "use assert_cmd::Command;\nuse diesel::connection::SimpleConnection;\nuse diesel::{Connection, MysqlConnection};\nuse diesel_migrations::MigrationHarness;\nuse std::env;\n\nstruct DropGuard {\n    conn: MysqlConnection,\n}\n\nimpl Drop for DropGuard {\n    fn drop(&mut self) {\n        self.conn\n            .batch_execute(\"DROP DATABASE getting_started_step_3\")\n            .unwrap();\n    }\n}\n\n#[test]\nfn publish_post() {\n    let url = env::var(\"MYSQL_DATABASE_URL\")\n        .or_else(|_| env::var(\"DATABASE_URL\"))\n        .expect(\"DATABASE_URL is set for tests\");\n    let mut db_url = url::Url::parse(&url).unwrap();\n\n    db_url.set_path(\"getting_started_step_3\");\n\n    let mut conn = MysqlConnection::establish(&url).unwrap();\n    conn.batch_execute(\"CREATE DATABASE getting_started_step_3\")\n        .unwrap();\n    let _guard = DropGuard { conn };\n\n    let mut conn = MysqlConnection::establish(db_url.as_ref()).unwrap();\n    let migrations = diesel_migrations::FileBasedMigrations::find_migrations_directory().unwrap();\n    conn.run_pending_migrations(migrations).unwrap();\n\n    let _ = Command::cargo_bin(\"show_posts\")\n        .unwrap()\n        .env(\"MYSQL_DATABASE_URL\", db_url.to_string())\n        .assert()\n        .append_context(\"show_posts\", \"\")\n        .stdout(\"Displaying 0 posts\\n\");\n\n    let _ = Command::cargo_bin(\"write_post\")\n        .unwrap()\n        .env(\"MYSQL_DATABASE_URL\", db_url.to_string())\n        .write_stdin(\"Test Title\\ntest text\\n1 2 3\")\n        .assert()\n        .append_context(\"write_post\", \"\")\n        .stdout(\n            \"What would you like your title to be?\\n\\nOk! Let's write Test Title (Press \"\n                .to_owned()\n                + EOF\n                + \" when finished)\\n\\n\\nSaved draft Test Title with id 1\\n\",\n        );\n\n    let _ = Command::cargo_bin(\"publish_post\")\n        .unwrap()\n        .env(\"MYSQL_DATABASE_URL\", db_url.to_string())\n        .arg(\"1\")\n        .assert()\n        .append_context(\"publish_post\", \"\")\n        .stdout(\"Published post Test Title\\n\");\n\n    let _ = Command::cargo_bin(\"show_posts\")\n        .unwrap()\n        .env(\"MYSQL_DATABASE_URL\", db_url.to_string())\n        .assert()\n        .append_context(\"show_posts\", \"\")\n        .stdout(\"Displaying 1 posts\\nTest Title\\n-----------\\n\\ntest text\\n1 2 3\\n\");\n\n    let _ = Command::cargo_bin(\"delete_post\")\n        .unwrap()\n        .env(\"MYSQL_DATABASE_URL\", db_url.to_string())\n        .arg(\"Test Title\")\n        .assert()\n        .append_context(\"delete_post\", \"\")\n        .stdout(\"Deleted 1 posts\\n\");\n\n    let _ = Command::cargo_bin(\"show_posts\")\n        .unwrap()\n        .env(\"MYSQL_DATABASE_URL\", db_url.to_string())\n        .assert()\n        .append_context(\"show_posts\", \"\")\n        .stdout(\"Displaying 0 posts\\n\");\n}\n\n#[cfg(not(windows))]\nconst EOF: &str = \"CTRL+D\";\n\n#[cfg(windows)]\nconst EOF: &str = \"CTRL+Z\";\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "f1ea81139ec3c895c443f947bbcdfd5b2928b971",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/examples/mysql/getting_started_step_3/src/schema.rs",
    "func": "// @generated automatically by Diesel CLI.\n\ndiesel::table! {\n    posts (id) {\n        id -> Integer,\n        #[max_length = 255]\n        title -> Varchar,\n        body -> Text,\n        published -> Bool,\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "98fd1c688bc51f455d78d61f2d3d272af229a14c",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tokio/tokio-util/tests/poll_semaphore.rs",
    "func": "use std::future::Future;\nuse std::sync::Arc;\nuse std::task::Poll;\nuse tokio::sync::{OwnedSemaphorePermit, Semaphore};\nuse tokio_util::sync::PollSemaphore;\n\ntype SemRet = Option<OwnedSemaphorePermit>;\n\nfn semaphore_poll(\n    sem: &mut PollSemaphore,\n) -> tokio_test::task::Spawn<impl Future<Output = SemRet> + '_> {\n    let fut = std::future::poll_fn(move |cx| sem.poll_acquire(cx));\n    tokio_test::task::spawn(fut)\n}\n\nfn semaphore_poll_many(\n    sem: &mut PollSemaphore,\n    permits: u32,\n) -> tokio_test::task::Spawn<impl Future<Output = SemRet> + '_> {\n    let fut = std::future::poll_fn(move |cx| sem.poll_acquire_many(cx, permits));\n    tokio_test::task::spawn(fut)\n}\n\n#[tokio::test]\nasync fn it_works() {\n    let sem = Arc::new(Semaphore::new(1));\n    let mut poll_sem = PollSemaphore::new(sem.clone());\n\n    let permit = sem.acquire().await.unwrap();\n    let mut poll = semaphore_poll(&mut poll_sem);\n    assert!(poll.poll().is_pending());\n    drop(permit);\n\n    assert!(matches!(poll.poll(), Poll::Ready(Some(_))));\n    drop(poll);\n\n    sem.close();\n\n    assert!(semaphore_poll(&mut poll_sem).await.is_none());\n\n    // Check that it is fused.\n    assert!(semaphore_poll(&mut poll_sem).await.is_none());\n    assert!(semaphore_poll(&mut poll_sem).await.is_none());\n}\n\n#[tokio::test]\nasync fn can_acquire_many_permits() {\n    let sem = Arc::new(Semaphore::new(4));\n    let mut poll_sem = PollSemaphore::new(sem.clone());\n\n    let permit1 = semaphore_poll(&mut poll_sem).poll();\n    assert!(matches!(permit1, Poll::Ready(Some(_))));\n\n    let permit2 = semaphore_poll_many(&mut poll_sem, 2).poll();\n    assert!(matches!(permit2, Poll::Ready(Some(_))));\n\n    assert_eq!(sem.available_permits(), 1);\n\n    drop(permit2);\n\n    let mut permit4 = semaphore_poll_many(&mut poll_sem, 4);\n    assert!(permit4.poll().is_pending());\n\n    drop(permit1);\n\n    let permit4 = permit4.poll();\n    assert!(matches!(permit4, Poll::Ready(Some(_))));\n    assert_eq!(sem.available_permits(), 0);\n}\n\n#[tokio::test]\nasync fn can_poll_different_amounts_of_permits() {\n    let sem = Arc::new(Semaphore::new(4));\n    let mut poll_sem = PollSemaphore::new(sem.clone());\n    assert!(semaphore_poll_many(&mut poll_sem, 5).poll().is_pending());\n    assert!(semaphore_poll_many(&mut poll_sem, 4).poll().is_ready());\n\n    let permit = sem.acquire_many(4).await.unwrap();\n    assert!(semaphore_poll_many(&mut poll_sem, 5).poll().is_pending());\n    assert!(semaphore_poll_many(&mut poll_sem, 4).poll().is_pending());\n    drop(permit);\n    assert!(semaphore_poll_many(&mut poll_sem, 5).poll().is_pending());\n    assert!(semaphore_poll_many(&mut poll_sem, 4).poll().is_ready());\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "3c5f2d8a97120e45ee472d53e79e7367d8c561cd",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tokio/tokio-util/tests/abort_on_drop.rs",
    "func": "use tokio::sync::oneshot;\nuse tokio_util::task::AbortOnDropHandle;\n\n#[tokio::test]\nasync fn aborts_task_on_drop() {\n    let (mut tx, rx) = oneshot::channel::<bool>();\n    let handle = tokio::spawn(async move {\n        let _ = rx.await;\n    });\n    let handle = AbortOnDropHandle::new(handle);\n    drop(handle);\n    tx.closed().await;\n    assert!(tx.is_closed());\n}\n\n#[tokio::test]\nasync fn aborts_task_directly() {\n    let (mut tx, rx) = oneshot::channel::<bool>();\n    let handle = tokio::spawn(async move {\n        let _ = rx.await;\n    });\n    let handle = AbortOnDropHandle::new(handle);\n    handle.abort();\n    tx.closed().await;\n    assert!(tx.is_closed());\n    assert!(handle.is_finished());\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "4fa9f7e923060d0c21efdcae5c2b0cc68d6b4ee5",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tokio/tokio-util/src/udp/frame.rs",
    "func": "use crate::codec::{Decoder, Encoder};\n\nuse futures_core::Stream;\nuse tokio::{io::ReadBuf, net::UdpSocket};\n\nuse bytes::{BufMut, BytesMut};\nuse futures_sink::Sink;\nuse std::pin::Pin;\nuse std::task::{ready, Context, Poll};\nuse std::{\n    borrow::Borrow,\n    net::{Ipv4Addr, SocketAddr, SocketAddrV4},\n};\nuse std::{io, mem::MaybeUninit};\n\n/// A unified [`Stream`] and [`Sink`] interface to an underlying `UdpSocket`, using\n/// the `Encoder` and `Decoder` traits to encode and decode frames.\n///\n/// Raw UDP sockets work with datagrams, but higher-level code usually wants to\n/// batch these into meaningful chunks, called \"frames\". This method layers\n/// framing on top of this socket by using the `Encoder` and `Decoder` traits to\n/// handle encoding and decoding of messages frames. Note that the incoming and\n/// outgoing frame types may be distinct.\n///\n/// This function returns a *single* object that is both [`Stream`] and [`Sink`];\n/// grouping this into a single object is often useful for layering things which\n/// require both read and write access to the underlying object.\n///\n/// If you want to work more directly with the streams and sink, consider\n/// calling [`split`] on the `UdpFramed` returned by this method, which will break\n/// them into separate objects, allowing them to interact more easily.\n///\n/// [`Stream`]: futures_core::Stream\n/// [`Sink`]: futures_sink::Sink\n/// [`split`]: https://docs.rs/futures/0.3/futures/stream/trait.StreamExt.html#method.split\n#[must_use = \"sinks do nothing unless polled\"]\n#[derive(Debug)]\npub struct UdpFramed<C, T = UdpSocket> {\n    socket: T,\n    codec: C,\n    rd: BytesMut,\n    wr: BytesMut,\n    out_addr: SocketAddr,\n    flushed: bool,\n    is_readable: bool,\n    current_addr: Option<SocketAddr>,\n}\n\nconst INITIAL_RD_CAPACITY: usize = 64 * 1024;\nconst INITIAL_WR_CAPACITY: usize = 8 * 1024;\n\nimpl<C, T> Unpin for UdpFramed<C, T> {}\n\nimpl<C, T> Stream for UdpFramed<C, T>\nwhere\n    T: Borrow<UdpSocket>,\n    C: Decoder,\n{\n    type Item = Result<(C::Item, SocketAddr), C::Error>;\n\n    fn poll_next(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Option<Self::Item>> {\n        let pin = self.get_mut();\n\n        pin.rd.reserve(INITIAL_RD_CAPACITY);\n\n        loop {\n            // Are there still bytes left in the read buffer to decode?\n            if pin.is_readable {\n                if let Some(frame) = pin.codec.decode_eof(&mut pin.rd)? {\n                    let current_addr = pin\n                        .current_addr\n                        .expect(\"will always be set before this line is called\");\n\n                    return Poll::Ready(Some(Ok((frame, current_addr))));\n                }\n\n                // if this line has been reached then decode has returned `None`.\n                pin.is_readable = false;\n                pin.rd.clear();\n            }\n\n            // We're out of data. Try and fetch more data to decode\n            let addr = {\n                // Safety: `chunk_mut()` returns a `&mut UninitSlice`, and `UninitSlice` is a\n                // transparent wrapper around `[MaybeUninit<u8>]`.\n                let buf = unsafe { &mut *(pin.rd.chunk_mut() as *mut _ as *mut [MaybeUninit<u8>]) };\n                let mut read = ReadBuf::uninit(buf);\n                let ptr = read.filled().as_ptr();\n                let res = ready!(pin.socket.borrow().poll_recv_from(cx, &mut read));\n\n                assert_eq!(ptr, read.filled().as_ptr());\n                let addr = res?;\n\n                // Safety: This is guaranteed to be the number of initialized (and read) bytes due\n                // to the invariants provided by `ReadBuf::filled`.\n                unsafe { pin.rd.advance_mut(read.filled().len()) };\n\n                addr\n            };\n\n            pin.current_addr = Some(addr);\n            pin.is_readable = true;\n        }\n    }\n}\n\nimpl<I, C, T> Sink<(I, SocketAddr)> for UdpFramed<C, T>\nwhere\n    T: Borrow<UdpSocket>,\n    C: Encoder<I>,\n{\n    type Error = C::Error;\n\n    fn poll_ready(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Result<(), Self::Error>> {\n        if !self.flushed {\n            match self.poll_flush(cx)? {\n                Poll::Ready(()) => {}\n                Poll::Pending => return Poll::Pending,\n            }\n        }\n\n        Poll::Ready(Ok(()))\n    }\n\n    fn start_send(self: Pin<&mut Self>, item: (I, SocketAddr)) -> Result<(), Self::Error> {\n        let (frame, out_addr) = item;\n\n        let pin = self.get_mut();\n\n        pin.codec.encode(frame, &mut pin.wr)?;\n        pin.out_addr = out_addr;\n        pin.flushed = false;\n\n        Ok(())\n    }\n\n    fn poll_flush(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Result<(), Self::Error>> {\n        if self.flushed {\n            return Poll::Ready(Ok(()));\n        }\n\n        let Self {\n            ref socket,\n            ref mut out_addr,\n            ref mut wr,\n            ..\n        } = *self;\n\n        let n = ready!(socket.borrow().poll_send_to(cx, wr, *out_addr))?;\n\n        let wrote_all = n == self.wr.len();\n        self.wr.clear();\n        self.flushed = true;\n\n        let res = if wrote_all {\n            Ok(())\n        } else {\n            Err(io::Error::new(\n                io::ErrorKind::Other,\n                \"failed to write entire datagram to socket\",\n            )\n            .into())\n        };\n\n        Poll::Ready(res)\n    }\n\n    fn poll_close(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Result<(), Self::Error>> {\n        ready!(self.poll_flush(cx))?;\n        Poll::Ready(Ok(()))\n    }\n}\n\nimpl<C, T> UdpFramed<C, T>\nwhere\n    T: Borrow<UdpSocket>,\n{\n    /// Create a new `UdpFramed` backed by the given socket and codec.\n    ///\n    /// See struct level documentation for more details.\n    pub fn new(socket: T, codec: C) -> UdpFramed<C, T> {\n        Self {\n            socket,\n            codec,\n            out_addr: SocketAddr::V4(SocketAddrV4::new(Ipv4Addr::new(0, 0, 0, 0), 0)),\n            rd: BytesMut::with_capacity(INITIAL_RD_CAPACITY),\n            wr: BytesMut::with_capacity(INITIAL_WR_CAPACITY),\n            flushed: true,\n            is_readable: false,\n            current_addr: None,\n        }\n    }\n\n    /// Returns a reference to the underlying I/O stream wrapped by `Framed`.\n    ///\n    /// # Note\n    ///\n    /// Care should be taken to not tamper with the underlying stream of data\n    /// coming in as it may corrupt the stream of frames otherwise being worked\n    /// with.\n    pub fn get_ref(&self) -> &T {\n        &self.socket\n    }\n\n    /// Returns a mutable reference to the underlying I/O stream wrapped by `Framed`.\n    ///\n    /// # Note\n    ///\n    /// Care should be taken to not tamper with the underlying stream of data\n    /// coming in as it may corrupt the stream of frames otherwise being worked\n    /// with.\n    pub fn get_mut(&mut self) -> &mut T {\n        &mut self.socket\n    }\n\n    /// Returns a reference to the underlying codec wrapped by\n    /// `Framed`.\n    ///\n    /// Note that care should be taken to not tamper with the underlying codec\n    /// as it may corrupt the stream of frames otherwise being worked with.\n    pub fn codec(&self) -> &C {\n        &self.codec\n    }\n\n    /// Returns a mutable reference to the underlying codec wrapped by\n    /// `UdpFramed`.\n    ///\n    /// Note that care should be taken to not tamper with the underlying codec\n    /// as it may corrupt the stream of frames otherwise being worked with.\n    pub fn codec_mut(&mut self) -> &mut C {\n        &mut self.codec\n    }\n\n    /// Returns a reference to the read buffer.\n    pub fn read_buffer(&self) -> &BytesMut {\n        &self.rd\n    }\n\n    /// Returns a mutable reference to the read buffer.\n    pub fn read_buffer_mut(&mut self) -> &mut BytesMut {\n        &mut self.rd\n    }\n\n    /// Consumes the `Framed`, returning its underlying I/O stream.\n    pub fn into_inner(self) -> T {\n        self.socket\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "99186993b1cec2f9d0c7ed58c8eaa66740c5825e",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tokio/tokio-util/src/time/wheel/level.rs",
    "func": "use crate::time::wheel::Stack;\n\nuse std::fmt;\n\n/// Wheel for a single level in the timer. This wheel contains 64 slots.\npub(crate) struct Level<T> {\n    level: usize,\n\n    /// Bit field tracking which slots currently contain entries.\n    ///\n    /// Using a bit field to track slots that contain entries allows avoiding a\n    /// scan to find entries. This field is updated when entries are added or\n    /// removed from a slot.\n    ///\n    /// The least-significant bit represents slot zero.\n    occupied: u64,\n\n    /// Slots\n    slot: [T; LEVEL_MULT],\n}\n\n/// Indicates when a slot must be processed next.\n#[derive(Debug)]\npub(crate) struct Expiration {\n    /// The level containing the slot.\n    pub(crate) level: usize,\n\n    /// The slot index.\n    pub(crate) slot: usize,\n\n    /// The instant at which the slot needs to be processed.\n    pub(crate) deadline: u64,\n}\n\n/// Level multiplier.\n///\n/// Being a power of 2 is very important.\nconst LEVEL_MULT: usize = 64;\n\nimpl<T: Stack> Level<T> {\n    pub(crate) fn new(level: usize) -> Level<T> {\n        Level {\n            level,\n            occupied: 0,\n            slot: std::array::from_fn(|_| T::default()),\n        }\n    }\n\n    /// Finds the slot that needs to be processed next and returns the slot and\n    /// `Instant` at which this slot must be processed.\n    pub(crate) fn next_expiration(&self, now: u64) -> Option<Expiration> {\n        // Use the `occupied` bit field to get the index of the next slot that\n        // needs to be processed.\n        let slot = match self.next_occupied_slot(now) {\n            Some(slot) => slot,\n            None => return None,\n        };\n\n        // From the slot index, calculate the `Instant` at which it needs to be\n        // processed. This value *must* be in the future with respect to `now`.\n\n        let level_range = level_range(self.level);\n        let slot_range = slot_range(self.level);\n\n        // TODO: This can probably be simplified w/ power of 2 math\n        let level_start = now - (now % level_range);\n        let mut deadline = level_start + slot as u64 * slot_range;\n        if deadline < now {\n            // A timer is in a slot \"prior\" to the current time. This can occur\n            // because we do not have an infinite hierarchy of timer levels, and\n            // eventually a timer scheduled for a very distant time might end up\n            // being placed in a slot that is beyond the end of all of the\n            // arrays.\n            //\n            // To deal with this, we first limit timers to being scheduled no\n            // more than MAX_DURATION ticks in the future; that is, they're at\n            // most one rotation of the top level away. Then, we force timers\n            // that logically would go into the top+1 level, to instead go into\n            // the top level's slots.\n            //\n            // What this means is that the top level's slots act as a\n            // pseudo-ring buffer, and we rotate around them indefinitely. If we\n            // compute a deadline before now, and it's the top level, it\n            // therefore means we're actually looking at a slot in the future.\n            debug_assert_eq!(self.level, super::NUM_LEVELS - 1);\n\n            deadline += level_range;\n        }\n        debug_assert!(\n            deadline >= now,\n            \"deadline={:016X}; now={:016X}; level={}; slot={}; occupied={:b}\",\n            deadline,\n            now,\n            self.level,\n            slot,\n            self.occupied\n        );\n\n        Some(Expiration {\n            level: self.level,\n            slot,\n            deadline,\n        })\n    }\n\n    fn next_occupied_slot(&self, now: u64) -> Option<usize> {\n        if self.occupied == 0 {\n            return None;\n        }\n\n        // Get the slot for now using Maths\n        let now_slot = (now / slot_range(self.level)) as usize;\n        let occupied = self.occupied.rotate_right(now_slot as u32);\n        let zeros = occupied.trailing_zeros() as usize;\n        let slot = (zeros + now_slot) % 64;\n\n        Some(slot)\n    }\n\n    pub(crate) fn add_entry(&mut self, when: u64, item: T::Owned, store: &mut T::Store) {\n        let slot = slot_for(when, self.level);\n\n        self.slot[slot].push(item, store);\n        self.occupied |= occupied_bit(slot);\n    }\n\n    pub(crate) fn remove_entry(&mut self, when: u64, item: &T::Borrowed, store: &mut T::Store) {\n        let slot = slot_for(when, self.level);\n\n        self.slot[slot].remove(item, store);\n\n        if self.slot[slot].is_empty() {\n            // The bit is currently set\n            debug_assert!(self.occupied & occupied_bit(slot) != 0);\n\n            // Unset the bit\n            self.occupied ^= occupied_bit(slot);\n        }\n    }\n\n    pub(crate) fn pop_entry_slot(&mut self, slot: usize, store: &mut T::Store) -> Option<T::Owned> {\n        let ret = self.slot[slot].pop(store);\n\n        if ret.is_some() && self.slot[slot].is_empty() {\n            // The bit is currently set\n            debug_assert!(self.occupied & occupied_bit(slot) != 0);\n\n            self.occupied ^= occupied_bit(slot);\n        }\n\n        ret\n    }\n\n    pub(crate) fn peek_entry_slot(&self, slot: usize) -> Option<T::Owned> {\n        self.slot[slot].peek()\n    }\n}\n\nimpl<T> fmt::Debug for Level<T> {\n    fn fmt(&self, fmt: &mut fmt::Formatter<'_>) -> fmt::Result {\n        fmt.debug_struct(\"Level\")\n            .field(\"occupied\", &self.occupied)\n            .finish()\n    }\n}\n\nfn occupied_bit(slot: usize) -> u64 {\n    1 << slot\n}\n\nfn slot_range(level: usize) -> u64 {\n    LEVEL_MULT.pow(level as u32) as u64\n}\n\nfn level_range(level: usize) -> u64 {\n    LEVEL_MULT as u64 * slot_range(level)\n}\n\n/// Convert a duration (milliseconds) and a level to a slot position\nfn slot_for(duration: u64, level: usize) -> usize {\n    ((duration >> (level * 6)) % LEVEL_MULT as u64) as usize\n}\n\n#[cfg(all(test, not(loom)))]\nmod test {\n    use super::*;\n\n    #[test]\n    fn test_slot_for() {\n        for pos in 0..64 {\n            assert_eq!(pos as usize, slot_for(pos, 0));\n        }\n\n        for level in 1..5 {\n            for pos in level..64 {\n                let a = pos * 64_usize.pow(level as u32);\n                assert_eq!(pos, slot_for(a as u64, level));\n            }\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "b2093e054fa2deab2659bd9c3a7c814e11370048",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tokio/tokio/tests/coop_budget.rs",
    "func": "#![warn(rust_2018_idioms)]\n#![cfg(all(feature = \"full\", target_os = \"linux\"))]\n\nuse std::sync::atomic::{AtomicUsize, Ordering};\nuse std::sync::Arc;\nuse tokio::net::UdpSocket;\n\n/// Ensure that UDP sockets have functional budgeting\n///\n/// # Design\n/// Two sockets communicate by spamming packets from one to the other.\n///\n/// In Linux, this packet will be slammed through the entire network stack and into the receiver's buffer during the\n/// send system call because we are using the loopback interface.\n/// This happens because the softirq chain invoked on send when using the loopback interface covers virtually the\n/// entirety of the lifecycle of a packet within the kernel network stack.\n///\n/// As a result, neither socket will ever encounter an EWOULDBLOCK, and the only way for these to yield during the loop\n/// is through budgeting.\n///\n/// A second task runs in the background and increments a counter before yielding, allowing us to know how many times sockets yielded.\n/// Since we are both sending and receiving, that should happen once per 64 packets, because budgets are of size 128\n/// and there are two budget events per packet, a send and a recv.\n#[tokio::test]\n#[cfg_attr(miri, ignore)] // No `socket` on miri.\nasync fn coop_budget_udp_send_recv() {\n    const BUDGET: usize = 128;\n    const N_ITERATIONS: usize = 1024;\n\n    const PACKET: &[u8] = b\"Hello, world\";\n    const PACKET_LEN: usize = 12;\n\n    assert_eq!(\n        PACKET_LEN,\n        PACKET.len(),\n        \"Defect in test, programmer can't do math\"\n    );\n\n    // bind each socket to a dynamic port, forcing IPv4 addressing on the localhost interface\n    let tx = UdpSocket::bind(\"127.0.0.1:0\").await.unwrap();\n    let rx = UdpSocket::bind(\"127.0.0.1:0\").await.unwrap();\n\n    tx.connect(rx.local_addr().unwrap()).await.unwrap();\n    rx.connect(tx.local_addr().unwrap()).await.unwrap();\n\n    let tracker = Arc::new(AtomicUsize::default());\n\n    let tracker_clone = Arc::clone(&tracker);\n\n    tokio::task::yield_now().await;\n\n    tokio::spawn(async move {\n        loop {\n            tracker_clone.fetch_add(1, Ordering::SeqCst);\n\n            tokio::task::yield_now().await;\n        }\n    });\n\n    for _ in 0..N_ITERATIONS {\n        tx.send(PACKET).await.unwrap();\n\n        let mut tmp = [0; PACKET_LEN];\n\n        // ensure that we aren't somehow accumulating other\n        assert_eq!(\n            PACKET_LEN,\n            rx.recv(&mut tmp).await.unwrap(),\n            \"Defect in test case, received unexpected result from socket\"\n        );\n        assert_eq!(\n            PACKET, &tmp,\n            \"Defect in test case, received unexpected result from socket\"\n        );\n    }\n\n    assert_eq!(N_ITERATIONS / (BUDGET / 2), tracker.load(Ordering::SeqCst));\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "33d3360d29f7ae4698df60620a9efa5bd5040d4b",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tokio/tokio/tests/time_rt.rs",
    "func": "#![warn(rust_2018_idioms)]\n#![cfg(feature = \"full\")]\n\nuse tokio::time::*;\n\nuse std::sync::mpsc;\n\n#[cfg(all(feature = \"rt-multi-thread\", not(target_os = \"wasi\")))] // Wasi doesn't support threads\n#[test]\nfn timer_with_threaded_runtime() {\n    use tokio::runtime::Runtime;\n\n    let rt = Runtime::new().unwrap();\n    let (tx, rx) = mpsc::channel();\n\n    rt.spawn(async move {\n        let when = Instant::now() + Duration::from_millis(10);\n\n        sleep_until(when).await;\n        assert!(Instant::now() >= when);\n\n        tx.send(()).unwrap();\n    });\n\n    rx.recv().unwrap();\n}\n\n#[test]\nfn timer_with_current_thread_scheduler() {\n    use tokio::runtime::Builder;\n\n    let rt = Builder::new_current_thread().enable_all().build().unwrap();\n    let (tx, rx) = mpsc::channel();\n\n    rt.block_on(async move {\n        let when = Instant::now() + Duration::from_millis(10);\n\n        sleep_until(when).await;\n        assert!(Instant::now() >= when);\n\n        tx.send(()).unwrap();\n    });\n\n    rx.recv().unwrap();\n}\n\n#[tokio::test]\nasync fn starving() {\n    use std::future::Future;\n    use std::pin::Pin;\n    use std::task::{Context, Poll};\n\n    struct Starve<T: Future<Output = ()> + Unpin>(T, u64);\n\n    impl<T: Future<Output = ()> + Unpin> Future for Starve<T> {\n        type Output = u64;\n\n        fn poll(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<u64> {\n            if Pin::new(&mut self.0).poll(cx).is_ready() {\n                return Poll::Ready(self.1);\n            }\n\n            self.1 += 1;\n\n            cx.waker().wake_by_ref();\n\n            Poll::Pending\n        }\n    }\n\n    let when = Instant::now() + Duration::from_millis(10);\n    let starve = Starve(Box::pin(sleep_until(when)), 0);\n\n    starve.await;\n    assert!(Instant::now() >= when);\n}\n\n#[tokio::test]\nasync fn timeout_value() {\n    use tokio::sync::oneshot;\n\n    let (_tx, rx) = oneshot::channel::<()>();\n\n    let now = Instant::now();\n    let dur = Duration::from_millis(10);\n\n    let res = timeout(dur, rx).await;\n    assert!(res.is_err());\n    assert!(Instant::now() >= now + dur);\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "106565fa92fa365de61932ad61e7113967cb2168",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tokio/tokio/tests/rt_handle.rs",
    "func": "#![allow(unknown_lints, unexpected_cfgs)]\n#![warn(rust_2018_idioms)]\n#![cfg(feature = \"full\")]\n\nuse tokio::runtime::Runtime;\n\n#[test]\n#[cfg_attr(panic = \"abort\", ignore)]\nfn basic_enter() {\n    let rt1 = rt();\n    let rt2 = rt();\n\n    let enter1 = rt1.enter();\n    let enter2 = rt2.enter();\n\n    drop(enter2);\n    drop(enter1);\n}\n\n#[test]\n#[should_panic]\n#[cfg_attr(panic = \"abort\", ignore)]\nfn interleave_enter_different_rt() {\n    let rt1 = rt();\n    let rt2 = rt();\n\n    let enter1 = rt1.enter();\n    let enter2 = rt2.enter();\n\n    drop(enter1);\n    drop(enter2);\n}\n\n#[test]\n#[should_panic]\n#[cfg_attr(panic = \"abort\", ignore)]\nfn interleave_enter_same_rt() {\n    let rt1 = rt();\n\n    let _enter1 = rt1.enter();\n    let enter2 = rt1.enter();\n    let enter3 = rt1.enter();\n\n    drop(enter2);\n    drop(enter3);\n}\n\n#[test]\n#[cfg(not(target_os = \"wasi\"))]\n#[cfg_attr(panic = \"abort\", ignore)]\nfn interleave_then_enter() {\n    let _ = std::panic::catch_unwind(|| {\n        let rt1 = rt();\n        let rt2 = rt();\n\n        let enter1 = rt1.enter();\n        let enter2 = rt2.enter();\n\n        drop(enter1);\n        drop(enter2);\n    });\n\n    // Can still enter\n    let rt3 = rt();\n    let _enter = rt3.enter();\n}\n\n#[cfg(tokio_unstable)]\nmod unstable {\n    use super::*;\n\n    #[test]\n    fn runtime_id_is_same() {\n        let rt = rt();\n\n        let handle1 = rt.handle();\n        let handle2 = rt.handle();\n\n        assert_eq!(handle1.id(), handle2.id());\n    }\n\n    #[test]\n    fn runtime_ids_different() {\n        let rt1 = rt();\n        let rt2 = rt();\n\n        assert_ne!(rt1.handle().id(), rt2.handle().id());\n    }\n}\n\nfn rt() -> Runtime {\n    tokio::runtime::Builder::new_current_thread()\n        .build()\n        .unwrap()\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "41f017e4be1954c890abe83127200f321521d609",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tokio/tokio/tests/process_issue_2174.rs",
    "func": "#![cfg(feature = \"process\")]\n#![warn(rust_2018_idioms)]\n// This test reveals a difference in behavior of kqueue on FreeBSD. When the\n// reader disconnects, there does not seem to be an `EVFILT_WRITE` filter that\n// is returned.\n//\n// It is expected that `EVFILT_WRITE` would be returned with either the\n// `EV_EOF` or `EV_ERROR` flag set. If either flag is set a write would be\n// attempted, but that does not seem to occur.\n#![cfg(all(unix, not(target_os = \"freebsd\"), not(miri)))]\n\nuse std::process::Stdio;\nuse std::time::Duration;\nuse tokio::io::AsyncWriteExt;\nuse tokio::process::Command;\nuse tokio::time;\nuse tokio_test::assert_err;\n\n#[tokio::test]\n#[cfg_attr(panic = \"abort\", ignore)]\nasync fn issue_2174() {\n    let mut child = Command::new(\"sleep\")\n        .arg(\"2\")\n        .stdin(Stdio::piped())\n        .stdout(Stdio::null())\n        .spawn()\n        .unwrap();\n    let mut input = child.stdin.take().unwrap();\n\n    // Writes will buffer up to 65_636. This *should* loop at least 8 times\n    // and then register interest.\n    let handle = tokio::spawn(async move {\n        let data = [0u8; 8192];\n        loop {\n            input.write_all(&data).await.unwrap();\n        }\n    });\n\n    // Sleep enough time so that the child process's stdin's buffer fills.\n    time::sleep(Duration::from_secs(1)).await;\n\n    // Kill the child process.\n    child.kill().await.unwrap();\n\n    assert_err!(handle.await);\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "a3694cd6b4e922e79dc03597f7a20a70a1b40228",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tokio/tokio/tests/time_interval.rs",
    "func": "#![warn(rust_2018_idioms)]\n#![cfg(feature = \"full\")]\n\nuse std::pin::Pin;\nuse std::task::{Context, Poll};\n\nuse futures::{Stream, StreamExt};\nuse tokio::time::{self, Duration, Instant, Interval, MissedTickBehavior};\nuse tokio_test::{assert_pending, assert_ready, assert_ready_eq, task};\n\n// Takes the `Interval` task, `start` variable, and optional time deltas\n// For each time delta, it polls the `Interval` and asserts that the result is\n// equal to `start` + the specific time delta. Then it asserts that the\n// `Interval` is pending.\nmacro_rules! check_interval_poll {\n    ($i:ident, $start:ident, $($delta:expr),*$(,)?) => {\n        $(\n            assert_ready_eq!(poll_next(&mut $i), $start + ms($delta));\n        )*\n        assert_pending!(poll_next(&mut $i));\n    };\n    ($i:ident, $start:ident) => {\n        check_interval_poll!($i, $start,);\n    };\n}\n\n#[tokio::test]\n#[should_panic]\nasync fn interval_zero_duration() {\n    let _ = time::interval_at(Instant::now(), ms(0));\n}\n\n// Expected ticks: |     1     |     2     |     3     |     4     |     5     |     6     |\n// Actual ticks:   | work -----|          delay          | work | work | work -| work -----|\n// Poll behavior:  |   |       |                         |      |      |       |           |\n//                 |   |       |                         |      |      |       |           |\n//          Ready(s)   |       |             Ready(s + 2p)      |      |       |           |\n//               Pending       |                    Ready(s + 3p)      |       |           |\n//                  Ready(s + p)                           Ready(s + 4p)       |           |\n//                                                                 Ready(s + 5p)           |\n//                                                                             Ready(s + 6p)\n#[tokio::test(start_paused = true)]\nasync fn burst() {\n    let start = Instant::now();\n\n    // This is necessary because the timer is only so granular, and in order for\n    // all our ticks to resolve, the time needs to be 1ms ahead of what we\n    // expect, so that the runtime will see that it is time to resolve the timer\n    time::advance(ms(1)).await;\n\n    let mut i = task::spawn(time::interval_at(start, ms(300)));\n\n    check_interval_poll!(i, start, 0);\n\n    time::advance(ms(100)).await;\n    check_interval_poll!(i, start);\n\n    time::advance(ms(200)).await;\n    check_interval_poll!(i, start, 300);\n\n    time::advance(ms(650)).await;\n    check_interval_poll!(i, start, 600, 900);\n\n    time::advance(ms(200)).await;\n    check_interval_poll!(i, start);\n\n    time::advance(ms(100)).await;\n    check_interval_poll!(i, start, 1200);\n\n    time::advance(ms(250)).await;\n    check_interval_poll!(i, start, 1500);\n\n    time::advance(ms(300)).await;\n    check_interval_poll!(i, start, 1800);\n}\n\n// Expected ticks: |     1     |     2     |     3     |     4     |     5     |     6     |\n// Actual ticks:   | work -----|          delay          | work -----| work -----| work -----|\n// Poll behavior:  |   |       |                         |   |       |           |           |\n//                 |   |       |                         |   |       |           |           |\n//          Ready(s)   |       |             Ready(s + 2p)   |       |           |           |\n//               Pending       |                       Pending       |           |           |\n//                  Ready(s + p)                     Ready(s + 2p + d)           |           |\n//                                                               Ready(s + 3p + d)           |\n//                                                                           Ready(s + 4p + d)\n#[tokio::test(start_paused = true)]\nasync fn delay() {\n    let start = Instant::now();\n\n    // This is necessary because the timer is only so granular, and in order for\n    // all our ticks to resolve, the time needs to be 1ms ahead of what we\n    // expect, so that the runtime will see that it is time to resolve the timer\n    time::advance(ms(1)).await;\n\n    let mut i = task::spawn(time::interval_at(start, ms(300)));\n    i.set_missed_tick_behavior(MissedTickBehavior::Delay);\n\n    check_interval_poll!(i, start, 0);\n\n    time::advance(ms(100)).await;\n    check_interval_poll!(i, start);\n\n    time::advance(ms(200)).await;\n    check_interval_poll!(i, start, 300);\n\n    time::advance(ms(650)).await;\n    check_interval_poll!(i, start, 600);\n\n    time::advance(ms(100)).await;\n    check_interval_poll!(i, start);\n\n    // We have to add one here for the same reason as is above.\n    // Because `Interval` has reset its timer according to `Instant::now()`,\n    // we have to go forward 1 more millisecond than is expected so that the\n    // runtime realizes that it's time to resolve the timer.\n    time::advance(ms(201)).await;\n    // We add one because when using the `Delay` behavior, `Interval`\n    // adds the `period` from `Instant::now()`, which will always be off by one\n    // because we have to advance time by 1 (see above).\n    check_interval_poll!(i, start, 1251);\n\n    time::advance(ms(300)).await;\n    // Again, we add one.\n    check_interval_poll!(i, start, 1551);\n\n    time::advance(ms(300)).await;\n    check_interval_poll!(i, start, 1851);\n}\n\n// Expected ticks: |     1     |     2     |     3     |     4     |     5     |     6     |\n// Actual ticks:   | work -----|          delay          | work ---| work -----| work -----|\n// Poll behavior:  |   |       |                         |         |           |           |\n//                 |   |       |                         |         |           |           |\n//          Ready(s)   |       |             Ready(s + 2p)         |           |           |\n//               Pending       |                       Ready(s + 4p)           |           |\n//                  Ready(s + p)                                   Ready(s + 5p)           |\n//                                                                             Ready(s + 6p)\n#[tokio::test(start_paused = true)]\nasync fn skip() {\n    let start = Instant::now();\n\n    // This is necessary because the timer is only so granular, and in order for\n    // all our ticks to resolve, the time needs to be 1ms ahead of what we\n    // expect, so that the runtime will see that it is time to resolve the timer\n    time::advance(ms(1)).await;\n\n    let mut i = task::spawn(time::interval_at(start, ms(300)));\n    i.set_missed_tick_behavior(MissedTickBehavior::Skip);\n\n    check_interval_poll!(i, start, 0);\n\n    time::advance(ms(100)).await;\n    check_interval_poll!(i, start);\n\n    time::advance(ms(200)).await;\n    check_interval_poll!(i, start, 300);\n\n    time::advance(ms(650)).await;\n    check_interval_poll!(i, start, 600);\n\n    time::advance(ms(250)).await;\n    check_interval_poll!(i, start, 1200);\n\n    time::advance(ms(300)).await;\n    check_interval_poll!(i, start, 1500);\n\n    time::advance(ms(300)).await;\n    check_interval_poll!(i, start, 1800);\n}\n\n#[tokio::test(start_paused = true)]\nasync fn reset() {\n    let start = Instant::now();\n\n    // This is necessary because the timer is only so granular, and in order for\n    // all our ticks to resolve, the time needs to be 1ms ahead of what we\n    // expect, so that the runtime will see that it is time to resolve the timer\n    time::advance(ms(1)).await;\n\n    let mut i = task::spawn(time::interval_at(start, ms(300)));\n\n    check_interval_poll!(i, start, 0);\n\n    time::advance(ms(100)).await;\n    check_interval_poll!(i, start);\n\n    time::advance(ms(200)).await;\n    check_interval_poll!(i, start, 300);\n\n    time::advance(ms(100)).await;\n    check_interval_poll!(i, start);\n\n    i.reset();\n\n    time::advance(ms(250)).await;\n    check_interval_poll!(i, start);\n\n    time::advance(ms(50)).await;\n    // We add one because when using `reset` method, `Interval` adds the\n    // `period` from `Instant::now()`, which will always be off by one\n    check_interval_poll!(i, start, 701);\n\n    time::advance(ms(300)).await;\n    check_interval_poll!(i, start, 1001);\n}\n\n#[tokio::test(start_paused = true)]\nasync fn reset_immediately() {\n    let start = Instant::now();\n\n    // This is necessary because the timer is only so granular, and in order for\n    // all our ticks to resolve, the time needs to be 1ms ahead of what we\n    // expect, so that the runtime will see that it is time to resolve the timer\n    time::advance(ms(1)).await;\n\n    let mut i = task::spawn(time::interval_at(start, ms(300)));\n\n    check_interval_poll!(i, start, 0);\n\n    time::advance(ms(100)).await;\n    check_interval_poll!(i, start);\n\n    time::advance(ms(200)).await;\n    check_interval_poll!(i, start, 300);\n\n    time::advance(ms(100)).await;\n    check_interval_poll!(i, start);\n\n    i.reset_immediately();\n\n    // We add one because when using `reset` method, `Interval` adds the\n    // `period` from `Instant::now()`, which will always be off by one\n    check_interval_poll!(i, start, 401);\n\n    time::advance(ms(100)).await;\n    check_interval_poll!(i, start);\n\n    time::advance(ms(200)).await;\n    check_interval_poll!(i, start, 701);\n}\n\n#[tokio::test(start_paused = true)]\nasync fn reset_after() {\n    let start = Instant::now();\n\n    // This is necessary because the timer is only so granular, and in order for\n    // all our ticks to resolve, the time needs to be 1ms ahead of what we\n    // expect, so that the runtime will see that it is time to resolve the timer\n    time::advance(ms(1)).await;\n\n    let mut i = task::spawn(time::interval_at(start, ms(300)));\n\n    check_interval_poll!(i, start, 0);\n\n    time::advance(ms(100)).await;\n    check_interval_poll!(i, start);\n\n    time::advance(ms(200)).await;\n    check_interval_poll!(i, start, 300);\n\n    time::advance(ms(100)).await;\n    check_interval_poll!(i, start);\n\n    i.reset_after(Duration::from_millis(20));\n\n    // We add one because when using `reset` method, `Interval` adds the\n    // `period` from `Instant::now()`, which will always be off by one\n    time::advance(ms(20)).await;\n    check_interval_poll!(i, start, 421);\n\n    time::advance(ms(100)).await;\n    check_interval_poll!(i, start);\n\n    time::advance(ms(200)).await;\n    check_interval_poll!(i, start, 721);\n}\n\n#[tokio::test(start_paused = true)]\nasync fn reset_at() {\n    let start = Instant::now();\n\n    // This is necessary because the timer is only so granular, and in order for\n    // all our ticks to resolve, the time needs to be 1ms ahead of what we\n    // expect, so that the runtime will see that it is time to resolve the timer\n    time::advance(ms(1)).await;\n\n    let mut i = task::spawn(time::interval_at(start, ms(300)));\n\n    check_interval_poll!(i, start, 0);\n\n    time::advance(ms(100)).await;\n    check_interval_poll!(i, start);\n\n    time::advance(ms(200)).await;\n    check_interval_poll!(i, start, 300);\n\n    time::advance(ms(100)).await;\n    check_interval_poll!(i, start);\n\n    i.reset_at(Instant::now() + Duration::from_millis(40));\n\n    // We add one because when using `reset` method, `Interval` adds the\n    // `period` from `Instant::now()`, which will always be off by one\n    time::advance(ms(40)).await;\n    check_interval_poll!(i, start, 441);\n\n    time::advance(ms(100)).await;\n    check_interval_poll!(i, start);\n\n    time::advance(ms(200)).await;\n    check_interval_poll!(i, start, 741);\n}\n\n#[tokio::test(start_paused = true)]\nasync fn reset_at_bigger_than_interval() {\n    let start = Instant::now();\n\n    // This is necessary because the timer is only so granular, and in order for\n    // all our ticks to resolve, the time needs to be 1ms ahead of what we\n    // expect, so that the runtime will see that it is time to resolve the timer\n    time::advance(ms(1)).await;\n\n    let mut i = task::spawn(time::interval_at(start, ms(300)));\n\n    check_interval_poll!(i, start, 0);\n\n    time::advance(ms(100)).await;\n    check_interval_poll!(i, start);\n\n    time::advance(ms(200)).await;\n    check_interval_poll!(i, start, 300);\n\n    time::advance(ms(100)).await;\n    check_interval_poll!(i, start);\n\n    i.reset_at(Instant::now() + Duration::from_millis(1000));\n\n    // Validate the interval does not tick until 1000ms have passed\n    time::advance(ms(300)).await;\n    check_interval_poll!(i, start);\n    time::advance(ms(300)).await;\n    check_interval_poll!(i, start);\n    time::advance(ms(300)).await;\n    check_interval_poll!(i, start);\n\n    // We add one because when using `reset` method, `Interval` adds the\n    // `period` from `Instant::now()`, which will always be off by one\n    time::advance(ms(100)).await;\n    check_interval_poll!(i, start, 1401);\n\n    time::advance(ms(300)).await;\n    check_interval_poll!(i, start, 1701);\n}\n\nfn poll_next(interval: &mut task::Spawn<time::Interval>) -> Poll<Instant> {\n    interval.enter(|cx, mut interval| interval.poll_tick(cx))\n}\n\nfn ms(n: u64) -> Duration {\n    Duration::from_millis(n)\n}\n\n/// Helper struct to test the [tokio::time::Interval::poll_tick()] method.\n///\n/// `poll_tick()` should register the waker in the context only if it returns\n/// `Poll::Pending`, not when returning `Poll::Ready`. This struct contains an\n/// interval timer and counts up on every tick when used as stream. When the\n/// counter is a multiple of four, it yields the current counter value.\n/// Depending on the value for `wake_on_pending`, it will reschedule itself when\n/// it returns `Poll::Pending` or not. When used with `wake_on_pending=false`,\n/// we expect that the stream stalls because the timer will **not** reschedule\n/// the next wake-up itself once it returned `Poll::Ready`.\nstruct IntervalStreamer {\n    counter: u32,\n    timer: Interval,\n    wake_on_pending: bool,\n}\n\nimpl Stream for IntervalStreamer {\n    type Item = u32;\n\n    fn poll_next(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Option<Self::Item>> {\n        let this = Pin::into_inner(self);\n\n        if this.counter > 12 {\n            return Poll::Ready(None);\n        }\n\n        match this.timer.poll_tick(cx) {\n            Poll::Pending => Poll::Pending,\n            Poll::Ready(_) => {\n                this.counter += 1;\n                if this.counter % 4 == 0 {\n                    Poll::Ready(Some(this.counter))\n                } else {\n                    if this.wake_on_pending {\n                        // Schedule this task for wake-up\n                        cx.waker().wake_by_ref();\n                    }\n                    Poll::Pending\n                }\n            }\n        }\n    }\n}\n\n#[tokio::test(start_paused = true)]\nasync fn stream_with_interval_poll_tick_self_waking() {\n    let stream = IntervalStreamer {\n        counter: 0,\n        timer: tokio::time::interval(tokio::time::Duration::from_millis(10)),\n        wake_on_pending: true,\n    };\n\n    let (res_tx, mut res_rx) = tokio::sync::mpsc::channel(12);\n\n    // Wrap task in timeout so that it will finish eventually even if the stream\n    // stalls.\n    tokio::spawn(tokio::time::timeout(\n        tokio::time::Duration::from_millis(150),\n        async move {\n            tokio::pin!(stream);\n\n            while let Some(item) = stream.next().await {\n                res_tx.send(item).await.ok();\n            }\n        },\n    ));\n\n    let mut items = Vec::with_capacity(3);\n    while let Some(result) = res_rx.recv().await {\n        items.push(result);\n    }\n\n    // We expect the stream to yield normally and thus three items.\n    assert_eq!(items, vec![4, 8, 12]);\n}\n\n#[tokio::test(start_paused = true)]\nasync fn stream_with_interval_poll_tick_no_waking() {\n    let stream = IntervalStreamer {\n        counter: 0,\n        timer: tokio::time::interval(tokio::time::Duration::from_millis(10)),\n        wake_on_pending: false,\n    };\n\n    let (res_tx, mut res_rx) = tokio::sync::mpsc::channel(12);\n\n    // Wrap task in timeout so that it will finish eventually even if the stream\n    // stalls.\n    tokio::spawn(tokio::time::timeout(\n        tokio::time::Duration::from_millis(150),\n        async move {\n            tokio::pin!(stream);\n\n            while let Some(item) = stream.next().await {\n                res_tx.send(item).await.ok();\n            }\n        },\n    ));\n\n    let mut items = Vec::with_capacity(0);\n    while let Some(result) = res_rx.recv().await {\n        items.push(result);\n    }\n\n    // We expect the stream to stall because it does not reschedule itself on\n    // `Poll::Pending` and neither does [tokio::time::Interval] reschedule the\n    // task when returning `Poll::Ready`.\n    assert_eq!(items, vec![]);\n}\n\n#[tokio::test(start_paused = true)]\nasync fn interval_doesnt_panic_max_duration_when_polling() {\n    let mut timer = task::spawn(time::interval(Duration::MAX));\n    assert_ready!(timer.enter(|cx, mut timer| timer.poll_tick(cx)));\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "19d6d2fd843bac8532704be7a4f1937cba7e6ebe",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tokio/tokio/src/runtime/task/core.rs",
    "func": "//! Core task module.\n//!\n//! # Safety\n//!\n//! The functions in this module are private to the `task` module. All of them\n//! should be considered `unsafe` to use, but are not marked as such since it\n//! would be too noisy.\n//!\n//! Make sure to consult the relevant safety section of each function before\n//! use.\n\nuse crate::future::Future;\nuse crate::loom::cell::UnsafeCell;\nuse crate::runtime::context;\nuse crate::runtime::task::raw::{self, Vtable};\nuse crate::runtime::task::state::State;\nuse crate::runtime::task::{Id, Schedule, TaskHarnessScheduleHooks};\nuse crate::util::linked_list;\n\nuse std::num::NonZeroU64;\nuse std::pin::Pin;\nuse std::ptr::NonNull;\nuse std::task::{Context, Poll, Waker};\n\n/// The task cell. Contains the components of the task.\n///\n/// It is critical for `Header` to be the first field as the task structure will\n/// be referenced by both *mut Cell and *mut Header.\n///\n/// Any changes to the layout of this struct _must_ also be reflected in the\n/// `const` fns in raw.rs.\n///\n// # This struct should be cache padded to avoid false sharing. The cache padding rules are copied\n// from crossbeam-utils/src/cache_padded.rs\n//\n// Starting from Intel's Sandy Bridge, spatial prefetcher is now pulling pairs of 64-byte cache\n// lines at a time, so we have to align to 128 bytes rather than 64.\n//\n// Sources:\n// - https://www.intel.com/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-optimization-manual.pdf\n// - https://github.com/facebook/folly/blob/1b5288e6eea6df074758f877c849b6e73bbb9fbb/folly/lang/Align.h#L107\n//\n// ARM's big.LITTLE architecture has asymmetric cores and \"big\" cores have 128-byte cache line size.\n//\n// Sources:\n// - https://www.mono-project.com/news/2016/09/12/arm64-icache/\n//\n// powerpc64 has 128-byte cache line size.\n//\n// Sources:\n// - https://github.com/golang/go/blob/3dd58676054223962cd915bb0934d1f9f489d4d2/src/internal/cpu/cpu_ppc64x.go#L9\n#[cfg_attr(\n    any(\n        target_arch = \"x86_64\",\n        target_arch = \"aarch64\",\n        target_arch = \"powerpc64\",\n    ),\n    repr(align(128))\n)]\n// arm, mips, mips64, sparc, and hexagon have 32-byte cache line size.\n//\n// Sources:\n// - https://github.com/golang/go/blob/3dd58676054223962cd915bb0934d1f9f489d4d2/src/internal/cpu/cpu_arm.go#L7\n// - https://github.com/golang/go/blob/3dd58676054223962cd915bb0934d1f9f489d4d2/src/internal/cpu/cpu_mips.go#L7\n// - https://github.com/golang/go/blob/3dd58676054223962cd915bb0934d1f9f489d4d2/src/internal/cpu/cpu_mipsle.go#L7\n// - https://github.com/golang/go/blob/3dd58676054223962cd915bb0934d1f9f489d4d2/src/internal/cpu/cpu_mips64x.go#L9\n// - https://github.com/torvalds/linux/blob/3516bd729358a2a9b090c1905bd2a3fa926e24c6/arch/sparc/include/asm/cache.h#L17\n// - https://github.com/torvalds/linux/blob/3516bd729358a2a9b090c1905bd2a3fa926e24c6/arch/hexagon/include/asm/cache.h#L12\n#[cfg_attr(\n    any(\n        target_arch = \"arm\",\n        target_arch = \"mips\",\n        target_arch = \"mips64\",\n        target_arch = \"sparc\",\n        target_arch = \"hexagon\",\n    ),\n    repr(align(32))\n)]\n// m68k has 16-byte cache line size.\n//\n// Sources:\n// - https://github.com/torvalds/linux/blob/3516bd729358a2a9b090c1905bd2a3fa926e24c6/arch/m68k/include/asm/cache.h#L9\n#[cfg_attr(target_arch = \"m68k\", repr(align(16)))]\n// s390x has 256-byte cache line size.\n//\n// Sources:\n// - https://github.com/golang/go/blob/3dd58676054223962cd915bb0934d1f9f489d4d2/src/internal/cpu/cpu_s390x.go#L7\n// - https://github.com/torvalds/linux/blob/3516bd729358a2a9b090c1905bd2a3fa926e24c6/arch/s390/include/asm/cache.h#L13\n#[cfg_attr(target_arch = \"s390x\", repr(align(256)))]\n// x86, riscv, wasm, and sparc64 have 64-byte cache line size.\n//\n// Sources:\n// - https://github.com/golang/go/blob/dda2991c2ea0c5914714469c4defc2562a907230/src/internal/cpu/cpu_x86.go#L9\n// - https://github.com/golang/go/blob/3dd58676054223962cd915bb0934d1f9f489d4d2/src/internal/cpu/cpu_wasm.go#L7\n// - https://github.com/torvalds/linux/blob/3516bd729358a2a9b090c1905bd2a3fa926e24c6/arch/sparc/include/asm/cache.h#L19\n// - https://github.com/torvalds/linux/blob/3516bd729358a2a9b090c1905bd2a3fa926e24c6/arch/riscv/include/asm/cache.h#L10\n//\n// All others are assumed to have 64-byte cache line size.\n#[cfg_attr(\n    not(any(\n        target_arch = \"x86_64\",\n        target_arch = \"aarch64\",\n        target_arch = \"powerpc64\",\n        target_arch = \"arm\",\n        target_arch = \"mips\",\n        target_arch = \"mips64\",\n        target_arch = \"sparc\",\n        target_arch = \"hexagon\",\n        target_arch = \"m68k\",\n        target_arch = \"s390x\",\n    )),\n    repr(align(64))\n)]\n#[repr(C)]\npub(super) struct Cell<T: Future, S> {\n    /// Hot task state data\n    pub(super) header: Header,\n\n    /// Either the future or output, depending on the execution stage.\n    pub(super) core: Core<T, S>,\n\n    /// Cold data\n    pub(super) trailer: Trailer,\n}\n\npub(super) struct CoreStage<T: Future> {\n    stage: UnsafeCell<Stage<T>>,\n}\n\n/// The core of the task.\n///\n/// Holds the future or output, depending on the stage of execution.\n///\n/// Any changes to the layout of this struct _must_ also be reflected in the\n/// `const` fns in raw.rs.\n#[repr(C)]\npub(super) struct Core<T: Future, S> {\n    /// Scheduler used to drive this future.\n    pub(super) scheduler: S,\n\n    /// The task's ID, used for populating `JoinError`s.\n    pub(super) task_id: Id,\n\n    /// Either the future or the output.\n    pub(super) stage: CoreStage<T>,\n}\n\n/// Crate public as this is also needed by the pool.\n#[repr(C)]\npub(crate) struct Header {\n    /// Task state.\n    pub(super) state: State,\n\n    /// Pointer to next task, used with the injection queue.\n    pub(super) queue_next: UnsafeCell<Option<NonNull<Header>>>,\n\n    /// Table of function pointers for executing actions on the task.\n    pub(super) vtable: &'static Vtable,\n\n    /// This integer contains the id of the `OwnedTasks` or `LocalOwnedTasks`\n    /// that this task is stored in. If the task is not in any list, should be\n    /// the id of the list that it was previously in, or `None` if it has never\n    /// been in any list.\n    ///\n    /// Once a task has been bound to a list, it can never be bound to another\n    /// list, even if removed from the first list.\n    ///\n    /// The id is not unset when removed from a list because we want to be able\n    /// to read the id without synchronization, even if it is concurrently being\n    /// removed from the list.\n    pub(super) owner_id: UnsafeCell<Option<NonZeroU64>>,\n\n    /// The tracing ID for this instrumented task.\n    #[cfg(all(tokio_unstable, feature = \"tracing\"))]\n    pub(super) tracing_id: Option<tracing::Id>,\n}\n\nunsafe impl Send for Header {}\nunsafe impl Sync for Header {}\n\n/// Cold data is stored after the future. Data is considered cold if it is only\n/// used during creation or shutdown of the task.\npub(super) struct Trailer {\n    /// Pointers for the linked list in the `OwnedTasks` that owns this task.\n    pub(super) owned: linked_list::Pointers<Header>,\n    /// Consumer task waiting on completion of this task.\n    pub(super) waker: UnsafeCell<Option<Waker>>,\n    /// Optional hooks needed in the harness.\n    pub(super) hooks: TaskHarnessScheduleHooks,\n}\n\ngenerate_addr_of_methods! {\n    impl<> Trailer {\n        pub(super) unsafe fn addr_of_owned(self: NonNull<Self>) -> NonNull<linked_list::Pointers<Header>> {\n            &self.owned\n        }\n    }\n}\n\n/// Either the future or the output.\n#[repr(C)] // https://github.com/rust-lang/miri/issues/3780\npub(super) enum Stage<T: Future> {\n    Running(T),\n    Finished(super::Result<T::Output>),\n    Consumed,\n}\n\nimpl<T: Future, S: Schedule> Cell<T, S> {\n    /// Allocates a new task cell, containing the header, trailer, and core\n    /// structures.\n    pub(super) fn new(future: T, scheduler: S, state: State, task_id: Id) -> Box<Cell<T, S>> {\n        // Separated into a non-generic function to reduce LLVM codegen\n        fn new_header(\n            state: State,\n            vtable: &'static Vtable,\n            #[cfg(all(tokio_unstable, feature = \"tracing\"))] tracing_id: Option<tracing::Id>,\n        ) -> Header {\n            Header {\n                state,\n                queue_next: UnsafeCell::new(None),\n                vtable,\n                owner_id: UnsafeCell::new(None),\n                #[cfg(all(tokio_unstable, feature = \"tracing\"))]\n                tracing_id,\n            }\n        }\n\n        #[cfg(all(tokio_unstable, feature = \"tracing\"))]\n        let tracing_id = future.id();\n        let vtable = raw::vtable::<T, S>();\n        let result = Box::new(Cell {\n            trailer: Trailer::new(scheduler.hooks()),\n            header: new_header(\n                state,\n                vtable,\n                #[cfg(all(tokio_unstable, feature = \"tracing\"))]\n                tracing_id,\n            ),\n            core: Core {\n                scheduler,\n                stage: CoreStage {\n                    stage: UnsafeCell::new(Stage::Running(future)),\n                },\n                task_id,\n            },\n        });\n\n        #[cfg(debug_assertions)]\n        {\n            // Using a separate function for this code avoids instantiating it separately for every `T`.\n            unsafe fn check<S>(header: &Header, trailer: &Trailer, scheduler: &S, task_id: &Id) {\n                let trailer_addr = trailer as *const Trailer as usize;\n                let trailer_ptr = unsafe { Header::get_trailer(NonNull::from(header)) };\n                assert_eq!(trailer_addr, trailer_ptr.as_ptr() as usize);\n\n                let scheduler_addr = scheduler as *const S as usize;\n                let scheduler_ptr = unsafe { Header::get_scheduler::<S>(NonNull::from(header)) };\n                assert_eq!(scheduler_addr, scheduler_ptr.as_ptr() as usize);\n\n                let id_addr = task_id as *const Id as usize;\n                let id_ptr = unsafe { Header::get_id_ptr(NonNull::from(header)) };\n                assert_eq!(id_addr, id_ptr.as_ptr() as usize);\n            }\n            unsafe {\n                check(\n                    &result.header,\n                    &result.trailer,\n                    &result.core.scheduler,\n                    &result.core.task_id,\n                );\n            }\n        }\n\n        result\n    }\n}\n\nimpl<T: Future> CoreStage<T> {\n    pub(super) fn with_mut<R>(&self, f: impl FnOnce(*mut Stage<T>) -> R) -> R {\n        self.stage.with_mut(f)\n    }\n}\n\n/// Set and clear the task id in the context when the future is executed or\n/// dropped, or when the output produced by the future is dropped.\npub(crate) struct TaskIdGuard {\n    parent_task_id: Option<Id>,\n}\n\nimpl TaskIdGuard {\n    fn enter(id: Id) -> Self {\n        TaskIdGuard {\n            parent_task_id: context::set_current_task_id(Some(id)),\n        }\n    }\n}\n\nimpl Drop for TaskIdGuard {\n    fn drop(&mut self) {\n        context::set_current_task_id(self.parent_task_id);\n    }\n}\n\nimpl<T: Future, S: Schedule> Core<T, S> {\n    /// Polls the future.\n    ///\n    /// # Safety\n    ///\n    /// The caller must ensure it is safe to mutate the `state` field. This\n    /// requires ensuring mutual exclusion between any concurrent thread that\n    /// might modify the future or output field.\n    ///\n    /// The mutual exclusion is implemented by `Harness` and the `Lifecycle`\n    /// component of the task state.\n    ///\n    /// `self` must also be pinned. This is handled by storing the task on the\n    /// heap.\n    pub(super) fn poll(&self, mut cx: Context<'_>) -> Poll<T::Output> {\n        let res = {\n            self.stage.stage.with_mut(|ptr| {\n                // Safety: The caller ensures mutual exclusion to the field.\n                let future = match unsafe { &mut *ptr } {\n                    Stage::Running(future) => future,\n                    _ => unreachable!(\"unexpected stage\"),\n                };\n\n                // Safety: The caller ensures the future is pinned.\n                let future = unsafe { Pin::new_unchecked(future) };\n\n                let _guard = TaskIdGuard::enter(self.task_id);\n                future.poll(&mut cx)\n            })\n        };\n\n        if res.is_ready() {\n            self.drop_future_or_output();\n        }\n\n        res\n    }\n\n    /// Drops the future.\n    ///\n    /// # Safety\n    ///\n    /// The caller must ensure it is safe to mutate the `stage` field.\n    pub(super) fn drop_future_or_output(&self) {\n        // Safety: the caller ensures mutual exclusion to the field.\n        unsafe {\n            self.set_stage(Stage::Consumed);\n        }\n    }\n\n    /// Stores the task output.\n    ///\n    /// # Safety\n    ///\n    /// The caller must ensure it is safe to mutate the `stage` field.\n    pub(super) fn store_output(&self, output: super::Result<T::Output>) {\n        // Safety: the caller ensures mutual exclusion to the field.\n        unsafe {\n            self.set_stage(Stage::Finished(output));\n        }\n    }\n\n    /// Takes the task output.\n    ///\n    /// # Safety\n    ///\n    /// The caller must ensure it is safe to mutate the `stage` field.\n    pub(super) fn take_output(&self) -> super::Result<T::Output> {\n        use std::mem;\n\n        self.stage.stage.with_mut(|ptr| {\n            // Safety:: the caller ensures mutual exclusion to the field.\n            match mem::replace(unsafe { &mut *ptr }, Stage::Consumed) {\n                Stage::Finished(output) => output,\n                _ => panic!(\"JoinHandle polled after completion\"),\n            }\n        })\n    }\n\n    unsafe fn set_stage(&self, stage: Stage<T>) {\n        let _guard = TaskIdGuard::enter(self.task_id);\n        self.stage.stage.with_mut(|ptr| *ptr = stage);\n    }\n}\n\nimpl Header {\n    pub(super) unsafe fn set_next(&self, next: Option<NonNull<Header>>) {\n        self.queue_next.with_mut(|ptr| *ptr = next);\n    }\n\n    // safety: The caller must guarantee exclusive access to this field, and\n    // must ensure that the id is either `None` or the id of the OwnedTasks\n    // containing this task.\n    pub(super) unsafe fn set_owner_id(&self, owner: NonZeroU64) {\n        self.owner_id.with_mut(|ptr| *ptr = Some(owner));\n    }\n\n    pub(super) fn get_owner_id(&self) -> Option<NonZeroU64> {\n        // safety: If there are concurrent writes, then that write has violated\n        // the safety requirements on `set_owner_id`.\n        unsafe { self.owner_id.with(|ptr| *ptr) }\n    }\n\n    /// Gets a pointer to the `Trailer` of the task containing this `Header`.\n    ///\n    /// # Safety\n    ///\n    /// The provided raw pointer must point at the header of a task.\n    pub(super) unsafe fn get_trailer(me: NonNull<Header>) -> NonNull<Trailer> {\n        let offset = me.as_ref().vtable.trailer_offset;\n        let trailer = me.as_ptr().cast::<u8>().add(offset).cast::<Trailer>();\n        NonNull::new_unchecked(trailer)\n    }\n\n    /// Gets a pointer to the scheduler of the task containing this `Header`.\n    ///\n    /// # Safety\n    ///\n    /// The provided raw pointer must point at the header of a task.\n    ///\n    /// The generic type S must be set to the correct scheduler type for this\n    /// task.\n    pub(super) unsafe fn get_scheduler<S>(me: NonNull<Header>) -> NonNull<S> {\n        let offset = me.as_ref().vtable.scheduler_offset;\n        let scheduler = me.as_ptr().cast::<u8>().add(offset).cast::<S>();\n        NonNull::new_unchecked(scheduler)\n    }\n\n    /// Gets a pointer to the id of the task containing this `Header`.\n    ///\n    /// # Safety\n    ///\n    /// The provided raw pointer must point at the header of a task.\n    pub(super) unsafe fn get_id_ptr(me: NonNull<Header>) -> NonNull<Id> {\n        let offset = me.as_ref().vtable.id_offset;\n        let id = me.as_ptr().cast::<u8>().add(offset).cast::<Id>();\n        NonNull::new_unchecked(id)\n    }\n\n    /// Gets the id of the task containing this `Header`.\n    ///\n    /// # Safety\n    ///\n    /// The provided raw pointer must point at the header of a task.\n    pub(super) unsafe fn get_id(me: NonNull<Header>) -> Id {\n        let ptr = Header::get_id_ptr(me).as_ptr();\n        *ptr\n    }\n\n    /// Gets the tracing id of the task containing this `Header`.\n    ///\n    /// # Safety\n    ///\n    /// The provided raw pointer must point at the header of a task.\n    #[cfg(all(tokio_unstable, feature = \"tracing\"))]\n    pub(super) unsafe fn get_tracing_id(me: &NonNull<Header>) -> Option<&tracing::Id> {\n        me.as_ref().tracing_id.as_ref()\n    }\n}\n\nimpl Trailer {\n    fn new(hooks: TaskHarnessScheduleHooks) -> Self {\n        Trailer {\n            waker: UnsafeCell::new(None),\n            owned: linked_list::Pointers::new(),\n            hooks,\n        }\n    }\n\n    pub(super) unsafe fn set_waker(&self, waker: Option<Waker>) {\n        self.waker.with_mut(|ptr| {\n            *ptr = waker;\n        });\n    }\n\n    pub(super) unsafe fn will_wake(&self, waker: &Waker) -> bool {\n        self.waker\n            .with(|ptr| (*ptr).as_ref().unwrap().will_wake(waker))\n    }\n\n    pub(super) fn wake_join(&self) {\n        self.waker.with(|ptr| match unsafe { &*ptr } {\n            Some(waker) => waker.wake_by_ref(),\n            None => panic!(\"waker missing\"),\n        });\n    }\n}\n\n#[test]\n#[cfg(not(loom))]\nfn header_lte_cache_line() {\n    assert!(std::mem::size_of::<Header>() <= 8 * std::mem::size_of::<*const ()>());\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "948ddb89a94c67855ede1d608d76abebca7f2dd8",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tokio/tokio/src/runtime/tests/inject.rs",
    "func": "use crate::runtime::scheduler::inject;\n\n#[test]\nfn push_and_pop() {\n    const N: usize = 2;\n\n    let (inject, mut synced) = inject::Shared::new();\n\n    for i in 0..N {\n        assert_eq!(inject.len(), i);\n        let (task, _) = super::unowned(async {});\n        unsafe { inject.push(&mut synced, task) };\n    }\n\n    for i in 0..N {\n        assert_eq!(inject.len(), N - i);\n        assert!(unsafe { inject.pop(&mut synced) }.is_some());\n    }\n\n    println!(\"--------------\");\n\n    assert!(unsafe { inject.pop(&mut synced) }.is_none());\n}\n\n#[test]\nfn push_batch_and_pop() {\n    let (inject, mut inject_synced) = inject::Shared::new();\n\n    unsafe {\n        inject.push_batch(\n            &mut inject_synced,\n            (0..10).map(|_| super::unowned(async {}).0),\n        );\n\n        assert_eq!(5, inject.pop_n(&mut inject_synced, 5).count());\n        assert_eq!(5, inject.pop_n(&mut inject_synced, 5).count());\n        assert_eq!(0, inject.pop_n(&mut inject_synced, 5).count());\n    }\n}\n\n#[test]\nfn pop_n_drains_on_drop() {\n    let (inject, mut inject_synced) = inject::Shared::new();\n\n    unsafe {\n        inject.push_batch(\n            &mut inject_synced,\n            (0..10).map(|_| super::unowned(async {}).0),\n        );\n        let _ = inject.pop_n(&mut inject_synced, 10);\n\n        assert_eq!(inject.len(), 0);\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "da8df29eaa4c091905d7d676d3e05c9d88fecceb",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tokio/tokio/src/runtime/tests/loom_join_set.rs",
    "func": "use crate::runtime::Builder;\nuse crate::task::JoinSet;\n\n#[test]\nfn test_join_set() {\n    loom::model(|| {\n        let rt = Builder::new_multi_thread()\n            .worker_threads(1)\n            .build()\n            .unwrap();\n        let mut set = JoinSet::new();\n\n        rt.block_on(async {\n            assert_eq!(set.len(), 0);\n            set.spawn(async { () });\n            assert_eq!(set.len(), 1);\n            set.spawn(async { () });\n            assert_eq!(set.len(), 2);\n            let () = set.join_next().await.unwrap().unwrap();\n            assert_eq!(set.len(), 1);\n            set.spawn(async { () });\n            assert_eq!(set.len(), 2);\n            let () = set.join_next().await.unwrap().unwrap();\n            assert_eq!(set.len(), 1);\n            let () = set.join_next().await.unwrap().unwrap();\n            assert_eq!(set.len(), 0);\n            set.spawn(async { () });\n            assert_eq!(set.len(), 1);\n        });\n\n        drop(set);\n        drop(rt);\n    });\n}\n\n#[test]\nfn abort_all_during_completion() {\n    use std::sync::{\n        atomic::{AtomicBool, Ordering::SeqCst},\n        Arc,\n    };\n\n    // These booleans assert that at least one execution had the task complete first, and that at\n    // least one execution had the task be cancelled before it completed.\n    let complete_happened = Arc::new(AtomicBool::new(false));\n    let cancel_happened = Arc::new(AtomicBool::new(false));\n\n    {\n        let complete_happened = complete_happened.clone();\n        let cancel_happened = cancel_happened.clone();\n        loom::model(move || {\n            let rt = Builder::new_multi_thread()\n                .worker_threads(1)\n                .build()\n                .unwrap();\n\n            let mut set = JoinSet::new();\n\n            rt.block_on(async {\n                set.spawn(async { () });\n                set.abort_all();\n\n                match set.join_next().await {\n                    Some(Ok(())) => complete_happened.store(true, SeqCst),\n                    Some(Err(err)) if err.is_cancelled() => cancel_happened.store(true, SeqCst),\n                    Some(Err(err)) => panic!(\"fail: {}\", err),\n                    None => {\n                        unreachable!(\"Aborting the task does not remove it from the JoinSet.\")\n                    }\n                }\n\n                assert!(matches!(set.join_next().await, None));\n            });\n\n            drop(set);\n            drop(rt);\n        });\n    }\n\n    assert!(complete_happened.load(SeqCst));\n    assert!(cancel_happened.load(SeqCst));\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "1df477a342ad49bf79742bc9e4490ec5d083a434",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tokio/tokio/src/runtime/io/scheduled_io.rs",
    "func": "use crate::io::interest::Interest;\nuse crate::io::ready::Ready;\nuse crate::loom::sync::atomic::AtomicUsize;\nuse crate::loom::sync::Mutex;\nuse crate::runtime::io::{Direction, ReadyEvent, Tick};\nuse crate::util::bit;\nuse crate::util::linked_list::{self, LinkedList};\nuse crate::util::WakeList;\n\nuse std::cell::UnsafeCell;\nuse std::future::Future;\nuse std::marker::PhantomPinned;\nuse std::pin::Pin;\nuse std::ptr::NonNull;\nuse std::sync::atomic::Ordering::{AcqRel, Acquire};\nuse std::task::{Context, Poll, Waker};\n\n/// Stored in the I/O driver resource slab.\n#[derive(Debug)]\n// # This struct should be cache padded to avoid false sharing. The cache padding rules are copied\n// from crossbeam-utils/src/cache_padded.rs\n//\n// Starting from Intel's Sandy Bridge, spatial prefetcher is now pulling pairs of 64-byte cache\n// lines at a time, so we have to align to 128 bytes rather than 64.\n//\n// Sources:\n// - https://www.intel.com/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-optimization-manual.pdf\n// - https://github.com/facebook/folly/blob/1b5288e6eea6df074758f877c849b6e73bbb9fbb/folly/lang/Align.h#L107\n//\n// ARM's big.LITTLE architecture has asymmetric cores and \"big\" cores have 128-byte cache line size.\n//\n// Sources:\n// - https://www.mono-project.com/news/2016/09/12/arm64-icache/\n//\n// powerpc64 has 128-byte cache line size.\n//\n// Sources:\n// - https://github.com/golang/go/blob/3dd58676054223962cd915bb0934d1f9f489d4d2/src/internal/cpu/cpu_ppc64x.go#L9\n#[cfg_attr(\n    any(\n        target_arch = \"x86_64\",\n        target_arch = \"aarch64\",\n        target_arch = \"powerpc64\",\n    ),\n    repr(align(128))\n)]\n// arm, mips, mips64, sparc, and hexagon have 32-byte cache line size.\n//\n// Sources:\n// - https://github.com/golang/go/blob/3dd58676054223962cd915bb0934d1f9f489d4d2/src/internal/cpu/cpu_arm.go#L7\n// - https://github.com/golang/go/blob/3dd58676054223962cd915bb0934d1f9f489d4d2/src/internal/cpu/cpu_mips.go#L7\n// - https://github.com/golang/go/blob/3dd58676054223962cd915bb0934d1f9f489d4d2/src/internal/cpu/cpu_mipsle.go#L7\n// - https://github.com/golang/go/blob/3dd58676054223962cd915bb0934d1f9f489d4d2/src/internal/cpu/cpu_mips64x.go#L9\n// - https://github.com/torvalds/linux/blob/3516bd729358a2a9b090c1905bd2a3fa926e24c6/arch/sparc/include/asm/cache.h#L17\n// - https://github.com/torvalds/linux/blob/3516bd729358a2a9b090c1905bd2a3fa926e24c6/arch/hexagon/include/asm/cache.h#L12\n#[cfg_attr(\n    any(\n        target_arch = \"arm\",\n        target_arch = \"mips\",\n        target_arch = \"mips64\",\n        target_arch = \"sparc\",\n        target_arch = \"hexagon\",\n    ),\n    repr(align(32))\n)]\n// m68k has 16-byte cache line size.\n//\n// Sources:\n// - https://github.com/torvalds/linux/blob/3516bd729358a2a9b090c1905bd2a3fa926e24c6/arch/m68k/include/asm/cache.h#L9\n#[cfg_attr(target_arch = \"m68k\", repr(align(16)))]\n// s390x has 256-byte cache line size.\n//\n// Sources:\n// - https://github.com/golang/go/blob/3dd58676054223962cd915bb0934d1f9f489d4d2/src/internal/cpu/cpu_s390x.go#L7\n// - https://github.com/torvalds/linux/blob/3516bd729358a2a9b090c1905bd2a3fa926e24c6/arch/s390/include/asm/cache.h#L13\n#[cfg_attr(target_arch = \"s390x\", repr(align(256)))]\n// x86, riscv, wasm, and sparc64 have 64-byte cache line size.\n//\n// Sources:\n// - https://github.com/golang/go/blob/dda2991c2ea0c5914714469c4defc2562a907230/src/internal/cpu/cpu_x86.go#L9\n// - https://github.com/golang/go/blob/3dd58676054223962cd915bb0934d1f9f489d4d2/src/internal/cpu/cpu_wasm.go#L7\n// - https://github.com/torvalds/linux/blob/3516bd729358a2a9b090c1905bd2a3fa926e24c6/arch/sparc/include/asm/cache.h#L19\n// - https://github.com/torvalds/linux/blob/3516bd729358a2a9b090c1905bd2a3fa926e24c6/arch/riscv/include/asm/cache.h#L10\n//\n// All others are assumed to have 64-byte cache line size.\n#[cfg_attr(\n    not(any(\n        target_arch = \"x86_64\",\n        target_arch = \"aarch64\",\n        target_arch = \"powerpc64\",\n        target_arch = \"arm\",\n        target_arch = \"mips\",\n        target_arch = \"mips64\",\n        target_arch = \"sparc\",\n        target_arch = \"hexagon\",\n        target_arch = \"m68k\",\n        target_arch = \"s390x\",\n    )),\n    repr(align(64))\n)]\npub(crate) struct ScheduledIo {\n    pub(super) linked_list_pointers: UnsafeCell<linked_list::Pointers<Self>>,\n\n    /// Packs the resource's readiness and I/O driver latest tick.\n    readiness: AtomicUsize,\n\n    waiters: Mutex<Waiters>,\n}\n\ntype WaitList = LinkedList<Waiter, <Waiter as linked_list::Link>::Target>;\n\n#[derive(Debug, Default)]\nstruct Waiters {\n    /// List of all current waiters.\n    list: WaitList,\n\n    /// Waker used for `AsyncRead`.\n    reader: Option<Waker>,\n\n    /// Waker used for `AsyncWrite`.\n    writer: Option<Waker>,\n}\n\n#[derive(Debug)]\nstruct Waiter {\n    pointers: linked_list::Pointers<Waiter>,\n\n    /// The waker for this task.\n    waker: Option<Waker>,\n\n    /// The interest this waiter is waiting on.\n    interest: Interest,\n\n    is_ready: bool,\n\n    /// Should never be `!Unpin`.\n    _p: PhantomPinned,\n}\n\ngenerate_addr_of_methods! {\n    impl<> Waiter {\n        unsafe fn addr_of_pointers(self: NonNull<Self>) -> NonNull<linked_list::Pointers<Waiter>> {\n            &self.pointers\n        }\n    }\n}\n\n/// Future returned by `readiness()`.\nstruct Readiness<'a> {\n    scheduled_io: &'a ScheduledIo,\n\n    state: State,\n\n    /// Entry in the waiter `LinkedList`.\n    waiter: UnsafeCell<Waiter>,\n}\n\nenum State {\n    Init,\n    Waiting,\n    Done,\n}\n\n// The `ScheduledIo::readiness` (`AtomicUsize`) is packed full of goodness.\n//\n// | shutdown | driver tick | readiness |\n// |----------+-------------+-----------|\n// |   1 bit  |  15 bits    +   16 bits |\n\nconst READINESS: bit::Pack = bit::Pack::least_significant(16);\n\nconst TICK: bit::Pack = READINESS.then(15);\n\nconst SHUTDOWN: bit::Pack = TICK.then(1);\n\n// ===== impl ScheduledIo =====\n\nimpl Default for ScheduledIo {\n    fn default() -> ScheduledIo {\n        ScheduledIo {\n            linked_list_pointers: UnsafeCell::new(linked_list::Pointers::new()),\n            readiness: AtomicUsize::new(0),\n            waiters: Mutex::new(Waiters::default()),\n        }\n    }\n}\n\nimpl ScheduledIo {\n    pub(crate) fn token(&self) -> mio::Token {\n        mio::Token(super::EXPOSE_IO.expose_provenance(self))\n    }\n\n    /// Invoked when the IO driver is shut down; forces this `ScheduledIo` into a\n    /// permanently shutdown state.\n    pub(super) fn shutdown(&self) {\n        let mask = SHUTDOWN.pack(1, 0);\n        self.readiness.fetch_or(mask, AcqRel);\n        self.wake(Ready::ALL);\n    }\n\n    /// Sets the readiness on this `ScheduledIo` by invoking the given closure on\n    /// the current value, returning the previous readiness value.\n    ///\n    /// # Arguments\n    /// - `tick`: whether setting the tick or trying to clear readiness for a\n    ///    specific tick.\n    /// - `f`: a closure returning a new readiness value given the previous\n    ///   readiness.\n    pub(super) fn set_readiness(&self, tick_op: Tick, f: impl Fn(Ready) -> Ready) {\n        let _ = self.readiness.fetch_update(AcqRel, Acquire, |curr| {\n            // If the io driver is shut down, then you are only allowed to clear readiness.\n            debug_assert!(SHUTDOWN.unpack(curr) == 0 || matches!(tick_op, Tick::Clear(_)));\n\n            const MAX_TICK: usize = TICK.max_value() + 1;\n            let tick = TICK.unpack(curr);\n\n            let new_tick = match tick_op {\n                // Trying to clear readiness with an old event!\n                Tick::Clear(t) if tick as u8 != t => return None,\n                Tick::Clear(t) => t as usize,\n                Tick::Set => tick.wrapping_add(1) % MAX_TICK,\n            };\n            let ready = Ready::from_usize(READINESS.unpack(curr));\n            Some(TICK.pack(new_tick, f(ready).as_usize()))\n        });\n    }\n\n    /// Notifies all pending waiters that have registered interest in `ready`.\n    ///\n    /// There may be many waiters to notify. Waking the pending task **must** be\n    /// done from outside of the lock otherwise there is a potential for a\n    /// deadlock.\n    ///\n    /// A stack array of wakers is created and filled with wakers to notify, the\n    /// lock is released, and the wakers are notified. Because there may be more\n    /// than 32 wakers to notify, if the stack array fills up, the lock is\n    /// released, the array is cleared, and the iteration continues.\n    pub(super) fn wake(&self, ready: Ready) {\n        let mut wakers = WakeList::new();\n\n        let mut waiters = self.waiters.lock();\n\n        // check for AsyncRead slot\n        if ready.is_readable() {\n            if let Some(waker) = waiters.reader.take() {\n                wakers.push(waker);\n            }\n        }\n\n        // check for AsyncWrite slot\n        if ready.is_writable() {\n            if let Some(waker) = waiters.writer.take() {\n                wakers.push(waker);\n            }\n        }\n\n        'outer: loop {\n            let mut iter = waiters.list.drain_filter(|w| ready.satisfies(w.interest));\n\n            while wakers.can_push() {\n                match iter.next() {\n                    Some(waiter) => {\n                        let waiter = unsafe { &mut *waiter.as_ptr() };\n\n                        if let Some(waker) = waiter.waker.take() {\n                            waiter.is_ready = true;\n                            wakers.push(waker);\n                        }\n                    }\n                    None => {\n                        break 'outer;\n                    }\n                }\n            }\n\n            drop(waiters);\n\n            wakers.wake_all();\n\n            // Acquire the lock again.\n            waiters = self.waiters.lock();\n        }\n\n        // Release the lock before notifying\n        drop(waiters);\n\n        wakers.wake_all();\n    }\n\n    pub(super) fn ready_event(&self, interest: Interest) -> ReadyEvent {\n        let curr = self.readiness.load(Acquire);\n\n        ReadyEvent {\n            tick: TICK.unpack(curr) as u8,\n            ready: interest.mask() & Ready::from_usize(READINESS.unpack(curr)),\n            is_shutdown: SHUTDOWN.unpack(curr) != 0,\n        }\n    }\n\n    /// Polls for readiness events in a given direction.\n    ///\n    /// These are to support `AsyncRead` and `AsyncWrite` polling methods,\n    /// which cannot use the `async fn` version. This uses reserved reader\n    /// and writer slots.\n    pub(super) fn poll_readiness(\n        &self,\n        cx: &mut Context<'_>,\n        direction: Direction,\n    ) -> Poll<ReadyEvent> {\n        let curr = self.readiness.load(Acquire);\n\n        let ready = direction.mask() & Ready::from_usize(READINESS.unpack(curr));\n        let is_shutdown = SHUTDOWN.unpack(curr) != 0;\n\n        if ready.is_empty() && !is_shutdown {\n            // Update the task info\n            let mut waiters = self.waiters.lock();\n            let waker = match direction {\n                Direction::Read => &mut waiters.reader,\n                Direction::Write => &mut waiters.writer,\n            };\n\n            // Avoid cloning the waker if one is already stored that matches the\n            // current task.\n            match waker {\n                Some(waker) => waker.clone_from(cx.waker()),\n                None => *waker = Some(cx.waker().clone()),\n            }\n\n            // Try again, in case the readiness was changed while we were\n            // taking the waiters lock\n            let curr = self.readiness.load(Acquire);\n            let ready = direction.mask() & Ready::from_usize(READINESS.unpack(curr));\n            let is_shutdown = SHUTDOWN.unpack(curr) != 0;\n            if is_shutdown {\n                Poll::Ready(ReadyEvent {\n                    tick: TICK.unpack(curr) as u8,\n                    ready: direction.mask(),\n                    is_shutdown,\n                })\n            } else if ready.is_empty() {\n                Poll::Pending\n            } else {\n                Poll::Ready(ReadyEvent {\n                    tick: TICK.unpack(curr) as u8,\n                    ready,\n                    is_shutdown,\n                })\n            }\n        } else {\n            Poll::Ready(ReadyEvent {\n                tick: TICK.unpack(curr) as u8,\n                ready,\n                is_shutdown,\n            })\n        }\n    }\n\n    pub(crate) fn clear_readiness(&self, event: ReadyEvent) {\n        // This consumes the current readiness state **except** for closed\n        // states. Closed states are excluded because they are final states.\n        let mask_no_closed = event.ready - Ready::READ_CLOSED - Ready::WRITE_CLOSED;\n        self.set_readiness(Tick::Clear(event.tick), |curr| curr - mask_no_closed);\n    }\n\n    pub(crate) fn clear_wakers(&self) {\n        let mut waiters = self.waiters.lock();\n        waiters.reader.take();\n        waiters.writer.take();\n    }\n}\n\nimpl Drop for ScheduledIo {\n    fn drop(&mut self) {\n        self.wake(Ready::ALL);\n    }\n}\n\nunsafe impl Send for ScheduledIo {}\nunsafe impl Sync for ScheduledIo {}\n\nimpl ScheduledIo {\n    /// An async version of `poll_readiness` which uses a linked list of wakers.\n    pub(crate) async fn readiness(&self, interest: Interest) -> ReadyEvent {\n        self.readiness_fut(interest).await\n    }\n\n    // This is in a separate function so that the borrow checker doesn't think\n    // we are borrowing the `UnsafeCell` possibly over await boundaries.\n    //\n    // Go figure.\n    fn readiness_fut(&self, interest: Interest) -> Readiness<'_> {\n        Readiness {\n            scheduled_io: self,\n            state: State::Init,\n            waiter: UnsafeCell::new(Waiter {\n                pointers: linked_list::Pointers::new(),\n                waker: None,\n                is_ready: false,\n                interest,\n                _p: PhantomPinned,\n            }),\n        }\n    }\n}\n\nunsafe impl linked_list::Link for Waiter {\n    type Handle = NonNull<Waiter>;\n    type Target = Waiter;\n\n    fn as_raw(handle: &NonNull<Waiter>) -> NonNull<Waiter> {\n        *handle\n    }\n\n    unsafe fn from_raw(ptr: NonNull<Waiter>) -> NonNull<Waiter> {\n        ptr\n    }\n\n    unsafe fn pointers(target: NonNull<Waiter>) -> NonNull<linked_list::Pointers<Waiter>> {\n        Waiter::addr_of_pointers(target)\n    }\n}\n\n// ===== impl Readiness =====\n\nimpl Future for Readiness<'_> {\n    type Output = ReadyEvent;\n\n    fn poll(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> {\n        use std::sync::atomic::Ordering::SeqCst;\n\n        let (scheduled_io, state, waiter) = unsafe {\n            let me = self.get_unchecked_mut();\n            (&me.scheduled_io, &mut me.state, &me.waiter)\n        };\n\n        loop {\n            match *state {\n                State::Init => {\n                    // Optimistically check existing readiness\n                    let curr = scheduled_io.readiness.load(SeqCst);\n                    let is_shutdown = SHUTDOWN.unpack(curr) != 0;\n\n                    // Safety: `waiter.interest` never changes\n                    let interest = unsafe { (*waiter.get()).interest };\n                    let ready = Ready::from_usize(READINESS.unpack(curr)).intersection(interest);\n\n                    if !ready.is_empty() || is_shutdown {\n                        // Currently ready!\n                        let tick = TICK.unpack(curr) as u8;\n                        *state = State::Done;\n                        return Poll::Ready(ReadyEvent {\n                            tick,\n                            ready,\n                            is_shutdown,\n                        });\n                    }\n\n                    // Wasn't ready, take the lock (and check again while locked).\n                    let mut waiters = scheduled_io.waiters.lock();\n\n                    let curr = scheduled_io.readiness.load(SeqCst);\n                    let mut ready = Ready::from_usize(READINESS.unpack(curr));\n                    let is_shutdown = SHUTDOWN.unpack(curr) != 0;\n\n                    if is_shutdown {\n                        ready = Ready::ALL;\n                    }\n\n                    let ready = ready.intersection(interest);\n\n                    if !ready.is_empty() || is_shutdown {\n                        // Currently ready!\n                        let tick = TICK.unpack(curr) as u8;\n                        *state = State::Done;\n                        return Poll::Ready(ReadyEvent {\n                            tick,\n                            ready,\n                            is_shutdown,\n                        });\n                    }\n\n                    // Not ready even after locked, insert into list...\n\n                    // Safety: called while locked\n                    unsafe {\n                        (*waiter.get()).waker = Some(cx.waker().clone());\n                    }\n\n                    // Insert the waiter into the linked list\n                    //\n                    // safety: pointers from `UnsafeCell` are never null.\n                    waiters\n                        .list\n                        .push_front(unsafe { NonNull::new_unchecked(waiter.get()) });\n                    *state = State::Waiting;\n                }\n                State::Waiting => {\n                    // Currently in the \"Waiting\" state, implying the caller has\n                    // a waiter stored in the waiter list (guarded by\n                    // `notify.waiters`). In order to access the waker fields,\n                    // we must hold the lock.\n\n                    let waiters = scheduled_io.waiters.lock();\n\n                    // Safety: called while locked\n                    let w = unsafe { &mut *waiter.get() };\n\n                    if w.is_ready {\n                        // Our waker has been notified.\n                        *state = State::Done;\n                    } else {\n                        // Update the waker, if necessary.\n                        w.waker.as_mut().unwrap().clone_from(cx.waker());\n                        return Poll::Pending;\n                    }\n\n                    // Explicit drop of the lock to indicate the scope that the\n                    // lock is held. Because holding the lock is required to\n                    // ensure safe access to fields not held within the lock, it\n                    // is helpful to visualize the scope of the critical\n                    // section.\n                    drop(waiters);\n                }\n                State::Done => {\n                    // Safety: State::Done means it is no longer shared\n                    let w = unsafe { &mut *waiter.get() };\n\n                    let curr = scheduled_io.readiness.load(Acquire);\n                    let is_shutdown = SHUTDOWN.unpack(curr) != 0;\n\n                    // The returned tick might be newer than the event\n                    // which notified our waker. This is ok because the future\n                    // still didn't return `Poll::Ready`.\n                    let tick = TICK.unpack(curr) as u8;\n\n                    // The readiness state could have been cleared in the meantime,\n                    // but we allow the returned ready set to be empty.\n                    let ready = Ready::from_usize(READINESS.unpack(curr)).intersection(w.interest);\n\n                    return Poll::Ready(ReadyEvent {\n                        tick,\n                        ready,\n                        is_shutdown,\n                    });\n                }\n            }\n        }\n    }\n}\n\nimpl Drop for Readiness<'_> {\n    fn drop(&mut self) {\n        let mut waiters = self.scheduled_io.waiters.lock();\n\n        // Safety: `waiter` is only ever stored in `waiters`\n        unsafe {\n            waiters\n                .list\n                .remove(NonNull::new_unchecked(self.waiter.get()))\n        };\n    }\n}\n\nunsafe impl Send for Readiness<'_> {}\nunsafe impl Sync for Readiness<'_> {}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "a26b1f1a05872257889cd737c6748c14fca00f8b",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tokio/tokio/src/runtime/metrics/runtime.rs",
    "func": "use crate::runtime::Handle;\n\ncfg_unstable_metrics! {\n    use std::ops::Range;\n    use std::thread::ThreadId;\n    cfg_64bit_metrics! {\n        use std::sync::atomic::Ordering::Relaxed;\n    }\n    use std::time::Duration;\n}\n\n/// Handle to the runtime's metrics.\n///\n/// This handle is internally reference-counted and can be freely cloned. A\n/// `RuntimeMetrics` handle is obtained using the [`Runtime::metrics`] method.\n///\n/// [`Runtime::metrics`]: crate::runtime::Runtime::metrics()\n#[derive(Clone, Debug)]\npub struct RuntimeMetrics {\n    handle: Handle,\n}\n\nimpl RuntimeMetrics {\n    pub(crate) fn new(handle: Handle) -> RuntimeMetrics {\n        RuntimeMetrics { handle }\n    }\n\n    /// Returns the number of worker threads used by the runtime.\n    ///\n    /// The number of workers is set by configuring `worker_threads` on\n    /// `runtime::Builder`. When using the `current_thread` runtime, the return\n    /// value is always `1`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use tokio::runtime::Handle;\n    ///\n    /// #[tokio::main]\n    /// async fn main() {\n    ///     let metrics = Handle::current().metrics();\n    ///\n    ///     let n = metrics.num_workers();\n    ///     println!(\"Runtime is using {} workers\", n);\n    /// }\n    /// ```\n    pub fn num_workers(&self) -> usize {\n        self.handle.inner.num_workers()\n    }\n\n    /// Returns the current number of alive tasks in the runtime.\n    ///\n    /// This counter increases when a task is spawned and decreases when a\n    /// task exits.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use tokio::runtime::Handle;\n    ///\n    /// #[tokio::main]\n    /// async fn main() {\n    ///    let metrics = Handle::current().metrics();\n    ///\n    ///     let n = metrics.num_alive_tasks();\n    ///     println!(\"Runtime has {} alive tasks\", n);\n    /// }\n    /// ```\n    pub fn num_alive_tasks(&self) -> usize {\n        self.handle.inner.num_alive_tasks()\n    }\n\n    /// Returns the number of tasks currently scheduled in the runtime's\n    /// global queue.\n    ///\n    /// Tasks that are spawned or notified from a non-runtime thread are\n    /// scheduled using the runtime's global queue. This metric returns the\n    /// **current** number of tasks pending in the global queue. As such, the\n    /// returned value may increase or decrease as new tasks are scheduled and\n    /// processed.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use tokio::runtime::Handle;\n    ///\n    /// #[tokio::main]\n    /// async fn main() {\n    ///     let metrics = Handle::current().metrics();\n    ///\n    ///     let n = metrics.global_queue_depth();\n    ///     println!(\"{} tasks currently pending in the runtime's global queue\", n);\n    /// }\n    /// ```\n    pub fn global_queue_depth(&self) -> usize {\n        self.handle.inner.injection_queue_depth()\n    }\n\n    cfg_unstable_metrics! {\n\n        /// Returns the number of additional threads spawned by the runtime.\n        ///\n        /// The number of workers is set by configuring `max_blocking_threads` on\n        /// `runtime::Builder`.\n        ///\n        /// # Examples\n        ///\n        /// ```\n        /// use tokio::runtime::Handle;\n        ///\n        /// #[tokio::main]\n        /// async fn main() {\n        ///     let _ = tokio::task::spawn_blocking(move || {\n        ///         // Stand-in for compute-heavy work or using synchronous APIs\n        ///         1 + 1\n        ///     }).await;\n        ///     let metrics = Handle::current().metrics();\n        ///\n        ///     let n = metrics.num_blocking_threads();\n        ///     println!(\"Runtime has created {} threads\", n);\n        /// }\n        /// ```\n        pub fn num_blocking_threads(&self) -> usize {\n            self.handle.inner.num_blocking_threads()\n        }\n\n        #[deprecated = \"Renamed to num_alive_tasks\"]\n        /// Renamed to [`RuntimeMetrics::num_alive_tasks`]\n        pub fn active_tasks_count(&self) -> usize {\n            self.num_alive_tasks()\n        }\n\n        /// Returns the number of idle threads, which have spawned by the runtime\n        /// for `spawn_blocking` calls.\n        ///\n        /// # Examples\n        ///\n        /// ```\n        /// use tokio::runtime::Handle;\n        ///\n        /// #[tokio::main]\n        /// async fn main() {\n        ///     let _ = tokio::task::spawn_blocking(move || {\n        ///         // Stand-in for compute-heavy work or using synchronous APIs\n        ///         1 + 1\n        ///     }).await;\n        ///     let metrics = Handle::current().metrics();\n        ///\n        ///     let n = metrics.num_idle_blocking_threads();\n        ///     println!(\"Runtime has {} idle blocking thread pool threads\", n);\n        /// }\n        /// ```\n        pub fn num_idle_blocking_threads(&self) -> usize {\n            self.handle.inner.num_idle_blocking_threads()\n        }\n\n        /// Returns the thread id of the given worker thread.\n        ///\n        /// The returned value is `None` if the worker thread has not yet finished\n        /// starting up.\n        ///\n        /// If additional information about the thread, such as its native id, are\n        /// required, those can be collected in [`on_thread_start`] and correlated\n        /// using the thread id.\n        ///\n        /// [`on_thread_start`]: crate::runtime::Builder::on_thread_start\n        ///\n        /// # Arguments\n        ///\n        /// `worker` is the index of the worker being queried. The given value must\n        /// be between 0 and `num_workers()`. The index uniquely identifies a single\n        /// worker and will continue to identify the worker throughout the lifetime\n        /// of the runtime instance.\n        ///\n        /// # Panics\n        ///\n        /// The method panics when `worker` represents an invalid worker, i.e. is\n        /// greater than or equal to `num_workers()`.\n        ///\n        /// # Examples\n        ///\n        /// ```\n        /// use tokio::runtime::Handle;\n        ///\n        /// #[tokio::main]\n        /// async fn main() {\n        ///     let metrics = Handle::current().metrics();\n        ///\n        ///     let id = metrics.worker_thread_id(0);\n        ///     println!(\"worker 0 has id {:?}\", id);\n        /// }\n        /// ```\n        pub fn worker_thread_id(&self, worker: usize) -> Option<ThreadId> {\n            self.handle\n                .inner\n                .worker_metrics(worker)\n                .thread_id()\n        }\n\n        cfg_64bit_metrics! {\n            /// Returns the number of tasks spawned in this runtime since it was created.\n            ///\n            /// This count starts at zero when the runtime is created and increases by one each time a task is spawned.\n            ///\n            /// The counter is monotonically increasing. It is never decremented or\n            /// reset to zero.\n            ///\n            /// # Examples\n            ///\n            /// ```\n            /// use tokio::runtime::Handle;\n            ///\n            /// #[tokio::main]\n            /// async fn main() {\n            ///    let metrics = Handle::current().metrics();\n            ///\n            ///     let n = metrics.spawned_tasks_count();\n            ///     println!(\"Runtime has had {} tasks spawned\", n);\n            /// }\n            /// ```\n            pub fn spawned_tasks_count(&self) -> u64 {\n                self.handle.inner.spawned_tasks_count()\n            }\n\n            /// Returns the number of tasks scheduled from **outside** of the runtime.\n            ///\n            /// The remote schedule count starts at zero when the runtime is created and\n            /// increases by one each time a task is woken from **outside** of the\n            /// runtime. This usually means that a task is spawned or notified from a\n            /// non-runtime thread and must be queued using the Runtime's injection\n            /// queue, which tends to be slower.\n            ///\n            /// The counter is monotonically increasing. It is never decremented or\n            /// reset to zero.\n            ///\n            /// # Examples\n            ///\n            /// ```\n            /// use tokio::runtime::Handle;\n            ///\n            /// #[tokio::main]\n            /// async fn main() {\n            ///     let metrics = Handle::current().metrics();\n            ///\n            ///     let n = metrics.remote_schedule_count();\n            ///     println!(\"{} tasks were scheduled from outside the runtime\", n);\n            /// }\n            /// ```\n            pub fn remote_schedule_count(&self) -> u64 {\n                self.handle\n                    .inner\n                    .scheduler_metrics()\n                    .remote_schedule_count\n                    .load(Relaxed)\n            }\n\n            /// Returns the number of times that tasks have been forced to yield back to the scheduler\n            /// after exhausting their task budgets.\n            ///\n            /// This count starts at zero when the runtime is created and increases by one each time a task yields due to exhausting its budget.\n            ///\n            /// The counter is monotonically increasing. It is never decremented or\n            /// reset to zero.\n            pub fn budget_forced_yield_count(&self) -> u64 {\n                self.handle\n                    .inner\n                    .scheduler_metrics()\n                    .budget_forced_yield_count\n                    .load(Relaxed)\n            }\n\n            /// Returns the total number of times the given worker thread has parked.\n            ///\n            /// The worker park count starts at zero when the runtime is created and\n            /// increases by one each time the worker parks the thread waiting for new\n            /// inbound events to process. This usually means the worker has processed\n            /// all pending work and is currently idle.\n            ///\n            /// The counter is monotonically increasing. It is never decremented or\n            /// reset to zero.\n            ///\n            /// # Arguments\n            ///\n            /// `worker` is the index of the worker being queried. The given value must\n            /// be between 0 and `num_workers()`. The index uniquely identifies a single\n            /// worker and will continue to identify the worker throughout the lifetime\n            /// of the runtime instance.\n            ///\n            /// # Panics\n            ///\n            /// The method panics when `worker` represents an invalid worker, i.e. is\n            /// greater than or equal to `num_workers()`.\n            ///\n            /// # Examples\n            ///\n            /// ```\n            /// use tokio::runtime::Handle;\n            ///\n            /// #[tokio::main]\n            /// async fn main() {\n            ///     let metrics = Handle::current().metrics();\n            ///\n            ///     let n = metrics.worker_park_count(0);\n            ///     println!(\"worker 0 parked {} times\", n);\n            /// }\n            /// ```\n            pub fn worker_park_count(&self, worker: usize) -> u64 {\n                self.handle\n                    .inner\n                    .worker_metrics(worker)\n                    .park_count\n                    .load(Relaxed)\n            }\n\n            /// Returns the total number of times the given worker thread has parked\n            /// and unparked.\n            ///\n            /// The worker park/unpark count starts at zero when the runtime is created\n            /// and increases by one each time the worker parks the thread waiting for\n            /// new inbound events to process. This usually means the worker has processed\n            /// all pending work and is currently idle. When new work becomes available,\n            /// the worker is unparked and the park/unpark count is again increased by one.\n            ///\n            /// An odd count means that the worker is currently parked.\n            /// An even count means that the worker is currently active.\n            ///\n            /// The counter is monotonically increasing. It is never decremented or\n            /// reset to zero.\n            ///\n            /// # Arguments\n            ///\n            /// `worker` is the index of the worker being queried. The given value must\n            /// be between 0 and `num_workers()`. The index uniquely identifies a single\n            /// worker and will continue to identify the worker throughout the lifetime\n            /// of the runtime instance.\n            ///\n            /// # Panics\n            ///\n            /// The method panics when `worker` represents an invalid worker, i.e. is\n            /// greater than or equal to `num_workers()`.\n            ///\n            /// # Examples\n            ///\n            /// ```\n            /// use tokio::runtime::Handle;\n            ///\n            /// #[tokio::main]\n            /// async fn main() {\n            ///     let metrics = Handle::current().metrics();\n            ///     let n = metrics.worker_park_unpark_count(0);\n            ///\n            ///     println!(\"worker 0 parked and unparked {} times\", n);\n            ///\n            ///     if n % 2 == 0 {\n            ///         println!(\"worker 0 is active\");\n            ///     } else {\n            ///         println!(\"worker 0 is parked\");\n            ///     }\n            /// }\n            /// ```\n            pub fn worker_park_unpark_count(&self, worker: usize) -> u64 {\n                self.handle\n                    .inner\n                    .worker_metrics(worker)\n                    .park_unpark_count\n                    .load(Relaxed)\n            }\n\n\n            /// Returns the number of times the given worker thread unparked but\n            /// performed no work before parking again.\n            ///\n            /// The worker no-op count starts at zero when the runtime is created and\n            /// increases by one each time the worker unparks the thread but finds no\n            /// new work and goes back to sleep. This indicates a false-positive wake up.\n            ///\n            /// The counter is monotonically increasing. It is never decremented or\n            /// reset to zero.\n            ///\n            /// # Arguments\n            ///\n            /// `worker` is the index of the worker being queried. The given value must\n            /// be between 0 and `num_workers()`. The index uniquely identifies a single\n            /// worker and will continue to identify the worker throughout the lifetime\n            /// of the runtime instance.\n            ///\n            /// # Panics\n            ///\n            /// The method panics when `worker` represents an invalid worker, i.e. is\n            /// greater than or equal to `num_workers()`.\n            ///\n            /// # Examples\n            ///\n            /// ```\n            /// use tokio::runtime::Handle;\n            ///\n            /// #[tokio::main]\n            /// async fn main() {\n            ///     let metrics = Handle::current().metrics();\n            ///\n            ///     let n = metrics.worker_noop_count(0);\n            ///     println!(\"worker 0 had {} no-op unparks\", n);\n            /// }\n            /// ```\n            pub fn worker_noop_count(&self, worker: usize) -> u64 {\n                self.handle\n                    .inner\n                    .worker_metrics(worker)\n                    .noop_count\n                    .load(Relaxed)\n            }\n\n            /// Returns the number of tasks the given worker thread stole from\n            /// another worker thread.\n            ///\n            /// This metric only applies to the **multi-threaded** runtime and will\n            /// always return `0` when using the current thread runtime.\n            ///\n            /// The worker steal count starts at zero when the runtime is created and\n            /// increases by `N` each time the worker has processed its scheduled queue\n            /// and successfully steals `N` more pending tasks from another worker.\n            ///\n            /// The counter is monotonically increasing. It is never decremented or\n            /// reset to zero.\n            ///\n            /// # Arguments\n            ///\n            /// `worker` is the index of the worker being queried. The given value must\n            /// be between 0 and `num_workers()`. The index uniquely identifies a single\n            /// worker and will continue to identify the worker throughout the lifetime\n            /// of the runtime instance.\n            ///\n            /// # Panics\n            ///\n            /// The method panics when `worker` represents an invalid worker, i.e. is\n            /// greater than or equal to `num_workers()`.\n            ///\n            /// # Examples\n            ///\n            /// ```\n            /// use tokio::runtime::Handle;\n            ///\n            /// #[tokio::main]\n            /// async fn main() {\n            ///     let metrics = Handle::current().metrics();\n            ///\n            ///     let n = metrics.worker_steal_count(0);\n            ///     println!(\"worker 0 has stolen {} tasks\", n);\n            /// }\n            /// ```\n            pub fn worker_steal_count(&self, worker: usize) -> u64 {\n                self.handle\n                    .inner\n                    .worker_metrics(worker)\n                    .steal_count\n                    .load(Relaxed)\n            }\n\n            /// Returns the number of times the given worker thread stole tasks from\n            /// another worker thread.\n            ///\n            /// This metric only applies to the **multi-threaded** runtime and will\n            /// always return `0` when using the current thread runtime.\n            ///\n            /// The worker steal count starts at zero when the runtime is created and\n            /// increases by one each time the worker has processed its scheduled queue\n            /// and successfully steals more pending tasks from another worker.\n            ///\n            /// The counter is monotonically increasing. It is never decremented or\n            /// reset to zero.\n            ///\n            /// # Arguments\n            ///\n            /// `worker` is the index of the worker being queried. The given value must\n            /// be between 0 and `num_workers()`. The index uniquely identifies a single\n            /// worker and will continue to identify the worker throughout the lifetime\n            /// of the runtime instance.\n            ///\n            /// # Panics\n            ///\n            /// The method panics when `worker` represents an invalid worker, i.e. is\n            /// greater than or equal to `num_workers()`.\n            ///\n            /// # Examples\n            ///\n            /// ```\n            /// use tokio::runtime::Handle;\n            ///\n            /// #[tokio::main]\n            /// async fn main() {\n            ///     let metrics = Handle::current().metrics();\n            ///\n            ///     let n = metrics.worker_steal_operations(0);\n            ///     println!(\"worker 0 has stolen tasks {} times\", n);\n            /// }\n            /// ```\n            pub fn worker_steal_operations(&self, worker: usize) -> u64 {\n                self.handle\n                    .inner\n                    .worker_metrics(worker)\n                    .steal_operations\n                    .load(Relaxed)\n            }\n\n            /// Returns the number of tasks the given worker thread has polled.\n            ///\n            /// The worker poll count starts at zero when the runtime is created and\n            /// increases by one each time the worker polls a scheduled task.\n            ///\n            /// The counter is monotonically increasing. It is never decremented or\n            /// reset to zero.\n            ///\n            /// # Arguments\n            ///\n            /// `worker` is the index of the worker being queried. The given value must\n            /// be between 0 and `num_workers()`. The index uniquely identifies a single\n            /// worker and will continue to identify the worker throughout the lifetime\n            /// of the runtime instance.\n            ///\n            /// # Panics\n            ///\n            /// The method panics when `worker` represents an invalid worker, i.e. is\n            /// greater than or equal to `num_workers()`.\n            ///\n            /// # Examples\n            ///\n            /// ```\n            /// use tokio::runtime::Handle;\n            ///\n            /// #[tokio::main]\n            /// async fn main() {\n            ///     let metrics = Handle::current().metrics();\n            ///\n            ///     let n = metrics.worker_poll_count(0);\n            ///     println!(\"worker 0 has polled {} tasks\", n);\n            /// }\n            /// ```\n            pub fn worker_poll_count(&self, worker: usize) -> u64 {\n                self.handle\n                    .inner\n                    .worker_metrics(worker)\n                    .poll_count\n                    .load(Relaxed)\n            }\n\n            /// Returns the amount of time the given worker thread has been busy.\n            ///\n            /// The worker busy duration starts at zero when the runtime is created and\n            /// increases whenever the worker is spending time processing work. Using\n            /// this value can indicate the load of the given worker. If a lot of time\n            /// is spent busy, then the worker is under load and will check for inbound\n            /// events less often.\n            ///\n            /// The timer is monotonically increasing. It is never decremented or reset\n            /// to zero.\n            ///\n            /// # Arguments\n            ///\n            /// `worker` is the index of the worker being queried. The given value must\n            /// be between 0 and `num_workers()`. The index uniquely identifies a single\n            /// worker and will continue to identify the worker throughout the lifetime\n            /// of the runtime instance.\n            ///\n            /// # Panics\n            ///\n            /// The method panics when `worker` represents an invalid worker, i.e. is\n            /// greater than or equal to `num_workers()`.\n            ///\n            /// # Examples\n            ///\n            /// ```\n            /// use tokio::runtime::Handle;\n            ///\n            /// #[tokio::main]\n            /// async fn main() {\n            ///     let metrics = Handle::current().metrics();\n            ///\n            ///     let n = metrics.worker_total_busy_duration(0);\n            ///     println!(\"worker 0 was busy for a total of {:?}\", n);\n            /// }\n            /// ```\n            pub fn worker_total_busy_duration(&self, worker: usize) -> Duration {\n                let nanos = self\n                    .handle\n                    .inner\n                    .worker_metrics(worker)\n                    .busy_duration_total\n                    .load(Relaxed);\n                Duration::from_nanos(nanos)\n            }\n\n            /// Returns the number of tasks scheduled from **within** the runtime on the\n            /// given worker's local queue.\n            ///\n            /// The local schedule count starts at zero when the runtime is created and\n            /// increases by one each time a task is woken from **inside** of the\n            /// runtime on the given worker. This usually means that a task is spawned\n            /// or notified from within a runtime thread and will be queued on the\n            /// worker-local queue.\n            ///\n            /// The counter is monotonically increasing. It is never decremented or\n            /// reset to zero.\n            ///\n            /// # Arguments\n            ///\n            /// `worker` is the index of the worker being queried. The given value must\n            /// be between 0 and `num_workers()`. The index uniquely identifies a single\n            /// worker and will continue to identify the worker throughout the lifetime\n            /// of the runtime instance.\n            ///\n            /// # Panics\n            ///\n            /// The method panics when `worker` represents an invalid worker, i.e. is\n            /// greater than or equal to `num_workers()`.\n            ///\n            /// # Examples\n            ///\n            /// ```\n            /// use tokio::runtime::Handle;\n            ///\n            /// #[tokio::main]\n            /// async fn main() {\n            ///     let metrics = Handle::current().metrics();\n            ///\n            ///     let n = metrics.worker_local_schedule_count(0);\n            ///     println!(\"{} tasks were scheduled on the worker's local queue\", n);\n            /// }\n            /// ```\n            pub fn worker_local_schedule_count(&self, worker: usize) -> u64 {\n                self.handle\n                    .inner\n                    .worker_metrics(worker)\n                    .local_schedule_count\n                    .load(Relaxed)\n            }\n\n            /// Returns the number of times the given worker thread saturated its local\n            /// queue.\n            ///\n            /// This metric only applies to the **multi-threaded** scheduler.\n            ///\n            /// The worker overflow count starts at zero when the runtime is created and\n            /// increases by one each time the worker attempts to schedule a task\n            /// locally, but its local queue is full. When this happens, half of the\n            /// local queue is moved to the injection queue.\n            ///\n            /// The counter is monotonically increasing. It is never decremented or\n            /// reset to zero.\n            ///\n            /// # Arguments\n            ///\n            /// `worker` is the index of the worker being queried. The given value must\n            /// be between 0 and `num_workers()`. The index uniquely identifies a single\n            /// worker and will continue to identify the worker throughout the lifetime\n            /// of the runtime instance.\n            ///\n            /// # Panics\n            ///\n            /// The method panics when `worker` represents an invalid worker, i.e. is\n            /// greater than or equal to `num_workers()`.\n            ///\n            /// # Examples\n            ///\n            /// ```\n            /// use tokio::runtime::Handle;\n            ///\n            /// #[tokio::main]\n            /// async fn main() {\n            ///     let metrics = Handle::current().metrics();\n            ///\n            ///     let n = metrics.worker_overflow_count(0);\n            ///     println!(\"worker 0 has overflowed its queue {} times\", n);\n            /// }\n            /// ```\n            pub fn worker_overflow_count(&self, worker: usize) -> u64 {\n                self.handle\n                    .inner\n                    .worker_metrics(worker)\n                    .overflow_count\n                    .load(Relaxed)\n            }\n        }\n\n        /// Renamed to [`RuntimeMetrics::global_queue_depth`]\n        #[deprecated = \"Renamed to global_queue_depth\"]\n        #[doc(hidden)]\n        pub fn injection_queue_depth(&self) -> usize {\n            self.handle.inner.injection_queue_depth()\n        }\n\n        /// Returns the number of tasks currently scheduled in the given worker's\n        /// local queue.\n        ///\n        /// Tasks that are spawned or notified from within a runtime thread are\n        /// scheduled using that worker's local queue. This metric returns the\n        /// **current** number of tasks pending in the worker's local queue. As\n        /// such, the returned value may increase or decrease as new tasks are\n        /// scheduled and processed.\n        ///\n        /// # Arguments\n        ///\n        /// `worker` is the index of the worker being queried. The given value must\n        /// be between 0 and `num_workers()`. The index uniquely identifies a single\n        /// worker and will continue to identify the worker throughout the lifetime\n        /// of the runtime instance.\n        ///\n        /// # Panics\n        ///\n        /// The method panics when `worker` represents an invalid worker, i.e. is\n        /// greater than or equal to `num_workers()`.\n        ///\n        /// # Examples\n        ///\n        /// ```\n        /// use tokio::runtime::Handle;\n        ///\n        /// #[tokio::main]\n        /// async fn main() {\n        ///     let metrics = Handle::current().metrics();\n        ///\n        ///     let n = metrics.worker_local_queue_depth(0);\n        ///     println!(\"{} tasks currently pending in worker 0's local queue\", n);\n        /// }\n        /// ```\n        pub fn worker_local_queue_depth(&self, worker: usize) -> usize {\n            self.handle.inner.worker_local_queue_depth(worker)\n        }\n\n        /// Returns `true` if the runtime is tracking the distribution of task poll\n        /// times.\n        ///\n        /// Task poll times are not instrumented by default as doing so requires\n        /// calling [`Instant::now()`] twice per task poll. The feature is enabled\n        /// by calling [`enable_metrics_poll_time_histogram()`] when building the\n        /// runtime.\n        ///\n        /// # Examples\n        ///\n        /// ```\n        /// use tokio::runtime::{self, Handle};\n        ///\n        /// fn main() {\n        ///     runtime::Builder::new_current_thread()\n        ///         .enable_metrics_poll_time_histogram()\n        ///         .build()\n        ///         .unwrap()\n        ///         .block_on(async {\n        ///             let metrics = Handle::current().metrics();\n        ///             let enabled = metrics.poll_time_histogram_enabled();\n        ///\n        ///             println!(\"Tracking task poll time distribution: {:?}\", enabled);\n        ///         });\n        /// }\n        /// ```\n        ///\n        /// [`enable_metrics_poll_time_histogram()`]: crate::runtime::Builder::enable_metrics_poll_time_histogram\n        /// [`Instant::now()`]: std::time::Instant::now\n        pub fn poll_time_histogram_enabled(&self) -> bool {\n            self.handle\n                .inner\n                .worker_metrics(0)\n                .poll_count_histogram\n                .is_some()\n        }\n\n        #[deprecated(note = \"Renamed to `poll_time_histogram_enabled`\")]\n        #[doc(hidden)]\n        pub fn poll_count_histogram_enabled(&self) -> bool {\n            self.poll_time_histogram_enabled()\n        }\n\n        /// Returns the number of histogram buckets tracking the distribution of\n        /// task poll times.\n        ///\n        /// This value is configured by calling\n        /// [`metrics_poll_time_histogram_configuration()`] when building the runtime.\n        ///\n        /// # Examples\n        ///\n        /// ```\n        /// use tokio::runtime::{self, Handle};\n        ///\n        /// fn main() {\n        ///     runtime::Builder::new_current_thread()\n        ///         .enable_metrics_poll_time_histogram()\n        ///         .build()\n        ///         .unwrap()\n        ///         .block_on(async {\n        ///             let metrics = Handle::current().metrics();\n        ///             let buckets = metrics.poll_time_histogram_num_buckets();\n        ///\n        ///             println!(\"Histogram buckets: {:?}\", buckets);\n        ///         });\n        /// }\n        /// ```\n        ///\n        /// [`metrics_poll_time_histogram_configuration()`]:\n        ///     crate::runtime::Builder::metrics_poll_time_histogram_configuration\n        pub fn poll_time_histogram_num_buckets(&self) -> usize {\n            self.handle\n                .inner\n                .worker_metrics(0)\n                .poll_count_histogram\n                .as_ref()\n                .map(|histogram| histogram.num_buckets())\n                .unwrap_or_default()\n        }\n\n        /// Deprecated. Use [`poll_time_histogram_num_buckets()`] instead.\n        ///\n        /// [`poll_time_histogram_num_buckets()`]: Self::poll_time_histogram_num_buckets\n        #[doc(hidden)]\n        #[deprecated(note = \"renamed to `poll_time_histogram_num_buckets`.\")]\n        pub fn poll_count_histogram_num_buckets(&self) -> usize {\n            self.poll_time_histogram_num_buckets()\n        }\n\n        /// Returns the range of task poll times tracked by the given bucket.\n        ///\n        /// This value is configured by calling\n        /// [`metrics_poll_time_histogram_configuration()`] when building the runtime.\n        ///\n        /// # Panics\n        ///\n        /// The method panics if `bucket` represents an invalid bucket index, i.e.\n        /// is greater than or equal to `poll_time_histogram_num_buckets()`.\n        ///\n        /// # Examples\n        ///\n        /// ```\n        /// use tokio::runtime::{self, Handle};\n        ///\n        /// fn main() {\n        ///     runtime::Builder::new_current_thread()\n        ///         .enable_metrics_poll_time_histogram()\n        ///         .build()\n        ///         .unwrap()\n        ///         .block_on(async {\n        ///             let metrics = Handle::current().metrics();\n        ///             let buckets = metrics.poll_time_histogram_num_buckets();\n        ///\n        ///             for i in 0..buckets {\n        ///                 let range = metrics.poll_time_histogram_bucket_range(i);\n        ///                 println!(\"Histogram bucket {} range: {:?}\", i, range);\n        ///             }\n        ///         });\n        /// }\n        /// ```\n        ///\n        /// [`metrics_poll_time_histogram_configuration()`]:\n        ///     crate::runtime::Builder::metrics_poll_time_histogram_configuration\n        #[track_caller]\n        pub fn poll_time_histogram_bucket_range(&self, bucket: usize) -> Range<Duration> {\n            self.handle\n                .inner\n                .worker_metrics(0)\n                .poll_count_histogram\n                .as_ref()\n                .map(|histogram| {\n                    let range = histogram.bucket_range(bucket);\n                    std::ops::Range {\n                        start: Duration::from_nanos(range.start),\n                        end: Duration::from_nanos(range.end),\n                    }\n                })\n                .unwrap_or_default()\n        }\n\n        /// Deprecated. Use [`poll_time_histogram_bucket_range()`] instead.\n        ///\n        /// [`poll_time_histogram_bucket_range()`]: Self::poll_time_histogram_bucket_range\n        #[track_caller]\n        #[doc(hidden)]\n        #[deprecated(note = \"renamed to `poll_time_histogram_bucket_range`\")]\n        pub fn poll_count_histogram_bucket_range(&self, bucket: usize) -> Range<Duration> {\n            self.poll_time_histogram_bucket_range(bucket)\n        }\n\n        cfg_64bit_metrics! {\n            /// Returns the number of times the given worker polled tasks with a poll\n            /// duration within the given bucket's range.\n            ///\n            /// Each worker maintains its own histogram and the counts for each bucket\n            /// starts at zero when the runtime is created. Each time the worker polls a\n            /// task, it tracks the duration the task poll time took and increments the\n            /// associated bucket by 1.\n            ///\n            /// Each bucket is a monotonically increasing counter. It is never\n            /// decremented or reset to zero.\n            ///\n            /// # Arguments\n            ///\n            /// `worker` is the index of the worker being queried. The given value must\n            /// be between 0 and `num_workers()`. The index uniquely identifies a single\n            /// worker and will continue to identify the worker throughout the lifetime\n            /// of the runtime instance.\n            ///\n            /// `bucket` is the index of the bucket being queried. The bucket is scoped\n            /// to the worker. The range represented by the bucket can be queried by\n            /// calling [`poll_time_histogram_bucket_range()`]. Each worker maintains\n            /// identical bucket ranges.\n            ///\n            /// # Panics\n            ///\n            /// The method panics when `worker` represents an invalid worker, i.e. is\n            /// greater than or equal to `num_workers()` or if `bucket` represents an\n            /// invalid bucket.\n            ///\n            /// # Examples\n            ///\n            /// ```\n            /// use tokio::runtime::{self, Handle};\n            ///\n            /// fn main() {\n            ///     runtime::Builder::new_current_thread()\n            ///         .enable_metrics_poll_time_histogram()\n            ///         .build()\n            ///         .unwrap()\n            ///         .block_on(async {\n            ///             let metrics = Handle::current().metrics();\n            ///             let buckets = metrics.poll_time_histogram_num_buckets();\n            ///\n            ///             for worker in 0..metrics.num_workers() {\n            ///                 for i in 0..buckets {\n            ///                     let count = metrics.poll_time_histogram_bucket_count(worker, i);\n            ///                     println!(\"Poll count {}\", count);\n            ///                 }\n            ///             }\n            ///         });\n            /// }\n            /// ```\n            ///\n            /// [`poll_time_histogram_bucket_range()`]: crate::runtime::RuntimeMetrics::poll_time_histogram_bucket_range\n            #[track_caller]\n            pub fn poll_time_histogram_bucket_count(&self, worker: usize, bucket: usize) -> u64 {\n                self.handle\n                    .inner\n                    .worker_metrics(worker)\n                    .poll_count_histogram\n                    .as_ref()\n                    .map(|histogram| histogram.get(bucket))\n                    .unwrap_or_default()\n            }\n\n            #[doc(hidden)]\n            #[deprecated(note = \"use `poll_time_histogram_bucket_count` instead\")]\n            pub fn poll_count_histogram_bucket_count(&self, worker: usize, bucket: usize) -> u64 {\n                self.poll_time_histogram_bucket_count(worker, bucket)\n            }\n\n            /// Returns the mean duration of task polls, in nanoseconds.\n            ///\n            /// This is an exponentially weighted moving average. Currently, this metric\n            /// is only provided by the multi-threaded runtime.\n            ///\n            /// # Arguments\n            ///\n            /// `worker` is the index of the worker being queried. The given value must\n            /// be between 0 and `num_workers()`. The index uniquely identifies a single\n            /// worker and will continue to identify the worker throughout the lifetime\n            /// of the runtime instance.\n            ///\n            /// # Panics\n            ///\n            /// The method panics when `worker` represents an invalid worker, i.e. is\n            /// greater than or equal to `num_workers()`.\n            ///\n            /// # Examples\n            ///\n            /// ```\n            /// use tokio::runtime::Handle;\n            ///\n            /// #[tokio::main]\n            /// async fn main() {\n            ///     let metrics = Handle::current().metrics();\n            ///\n            ///     let n = metrics.worker_mean_poll_time(0);\n            ///     println!(\"worker 0 has a mean poll time of {:?}\", n);\n            /// }\n            /// ```\n            #[track_caller]\n            pub fn worker_mean_poll_time(&self, worker: usize) -> Duration {\n                let nanos = self\n                    .handle\n                    .inner\n                    .worker_metrics(worker)\n                    .mean_poll_time\n                    .load(Relaxed);\n                Duration::from_nanos(nanos)\n            }\n        }\n\n        /// Returns the number of tasks currently scheduled in the blocking\n        /// thread pool, spawned using `spawn_blocking`.\n        ///\n        /// This metric returns the **current** number of tasks pending in\n        /// blocking thread pool. As such, the returned value may increase\n        /// or decrease as new tasks are scheduled and processed.\n        ///\n        /// # Examples\n        ///\n        /// ```\n        /// use tokio::runtime::Handle;\n        ///\n        /// #[tokio::main]\n        /// async fn main() {\n        ///     let metrics = Handle::current().metrics();\n        ///\n        ///     let n = metrics.blocking_queue_depth();\n        ///     println!(\"{} tasks currently pending in the blocking thread pool\", n);\n        /// }\n        /// ```\n        pub fn blocking_queue_depth(&self) -> usize {\n            self.handle.inner.blocking_queue_depth()\n        }\n\n        cfg_net! {\n            cfg_64bit_metrics! {\n                /// Returns the number of file descriptors that have been registered with the\n                /// runtime's I/O driver.\n                ///\n                /// # Examples\n                ///\n                /// ```\n                /// use tokio::runtime::Handle;\n                ///\n                /// #[tokio::main]\n                /// async fn main() {\n                ///     let metrics = Handle::current().metrics();\n                ///\n                ///     let registered_fds = metrics.io_driver_fd_registered_count();\n                ///     println!(\"{} fds have been registered with the runtime's I/O driver.\", registered_fds);\n                ///\n                ///     let deregistered_fds = metrics.io_driver_fd_deregistered_count();\n                ///\n                ///     let current_fd_count = registered_fds - deregistered_fds;\n                ///     println!(\"{} fds are currently registered by the runtime's I/O driver.\", current_fd_count);\n                /// }\n                /// ```\n                pub fn io_driver_fd_registered_count(&self) -> u64 {\n                    self.with_io_driver_metrics(|m| {\n                        m.fd_registered_count.load(Relaxed)\n                    })\n                }\n\n                /// Returns the number of file descriptors that have been deregistered by the\n                /// runtime's I/O driver.\n                ///\n                /// # Examples\n                ///\n                /// ```\n                /// use tokio::runtime::Handle;\n                ///\n                /// #[tokio::main]\n                /// async fn main() {\n                ///     let metrics = Handle::current().metrics();\n                ///\n                ///     let n = metrics.io_driver_fd_deregistered_count();\n                ///     println!(\"{} fds have been deregistered by the runtime's I/O driver.\", n);\n                /// }\n                /// ```\n                pub fn io_driver_fd_deregistered_count(&self) -> u64 {\n                    self.with_io_driver_metrics(|m| {\n                        m.fd_deregistered_count.load(Relaxed)\n                    })\n                }\n\n                /// Returns the number of ready events processed by the runtime's\n                /// I/O driver.\n                ///\n                /// # Examples\n                ///\n                /// ```\n                /// use tokio::runtime::Handle;\n                ///\n                /// #[tokio::main]\n                /// async fn main() {\n                ///     let metrics = Handle::current().metrics();\n                ///\n                ///     let n = metrics.io_driver_ready_count();\n                ///     println!(\"{} ready events processed by the runtime's I/O driver.\", n);\n                /// }\n                /// ```\n                pub fn io_driver_ready_count(&self) -> u64 {\n                    self.with_io_driver_metrics(|m| m.ready_count.load(Relaxed))\n                }\n\n                fn with_io_driver_metrics<F>(&self, f: F) -> u64\n                where\n                    F: Fn(&super::IoDriverMetrics) -> u64,\n                {\n                    // TODO: Investigate if this should return 0, most of our metrics always increase\n                    // thus this breaks that guarantee.\n                    self.handle\n                        .inner\n                        .driver()\n                        .io\n                        .as_ref()\n                        .map(|h| f(&h.metrics))\n                        .unwrap_or(0)\n                }\n            }\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "2125470f10d71e0f8951f7fb52fef4ced4fa21d2",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tokio/tokio/src/runtime/scheduler/multi_thread/handle/metrics.rs",
    "func": "use super::Handle;\n\ncfg_unstable_metrics! {\n    use crate::runtime::{SchedulerMetrics, WorkerMetrics};\n}\n\nimpl Handle {\n    pub(crate) fn num_workers(&self) -> usize {\n        self.shared.worker_metrics.len()\n    }\n\n    pub(crate) fn num_alive_tasks(&self) -> usize {\n        self.shared.owned.num_alive_tasks()\n    }\n\n    pub(crate) fn injection_queue_depth(&self) -> usize {\n        self.shared.injection_queue_depth()\n    }\n\n    cfg_unstable_metrics! {\n        cfg_64bit_metrics! {\n            pub(crate) fn spawned_tasks_count(&self) -> u64 {\n                self.shared.owned.spawned_tasks_count()\n            }\n        }\n\n        pub(crate) fn num_blocking_threads(&self) -> usize {\n            // workers are currently spawned using spawn_blocking\n            self.blocking_spawner\n                .num_threads()\n                .saturating_sub(self.num_workers())\n        }\n\n        pub(crate) fn num_idle_blocking_threads(&self) -> usize {\n            self.blocking_spawner.num_idle_threads()\n        }\n\n        pub(crate) fn scheduler_metrics(&self) -> &SchedulerMetrics {\n            &self.shared.scheduler_metrics\n        }\n\n        pub(crate) fn worker_metrics(&self, worker: usize) -> &WorkerMetrics {\n            &self.shared.worker_metrics[worker]\n        }\n\n        pub(crate) fn worker_local_queue_depth(&self, worker: usize) -> usize {\n            self.shared.worker_local_queue_depth(worker)\n        }\n\n        pub(crate) fn blocking_queue_depth(&self) -> usize {\n            self.blocking_spawner.queue_depth()\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "608af386a90f6b022b08626b28f0721c6acca7f5",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tokio/tokio/src/runtime/scheduler/inject/metrics.rs",
    "func": "use super::Inject;\n\nimpl<T: 'static> Inject<T> {\n    pub(crate) fn len(&self) -> usize {\n        self.shared.len()\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "cbb931b80bc00e5013a142ae83d6f1d98855baed",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tokio/tokio/src/runtime/scheduler/multi_thread_alt/handle.rs",
    "func": "use crate::future::Future;\nuse crate::loom::sync::Arc;\nuse crate::runtime::scheduler::multi_thread_alt::worker;\nuse crate::runtime::{\n    blocking, driver,\n    task::{self, JoinHandle},\n    TaskHooks, TaskMeta,\n};\nuse crate::util::RngSeedGenerator;\n\nuse std::fmt;\n\ncfg_unstable_metrics! {\n    mod metrics;\n}\n\n/// Handle to the multi thread scheduler\npub(crate) struct Handle {\n    /// Task spawner\n    pub(super) shared: worker::Shared,\n\n    /// Resource driver handles\n    pub(crate) driver: driver::Handle,\n\n    /// Blocking pool spawner\n    pub(crate) blocking_spawner: blocking::Spawner,\n\n    /// Current random number generator seed\n    pub(crate) seed_generator: RngSeedGenerator,\n\n    /// User-supplied hooks to invoke for things\n    pub(crate) task_hooks: TaskHooks,\n}\n\nimpl Handle {\n    /// Spawns a future onto the thread pool\n    pub(crate) fn spawn<F>(me: &Arc<Self>, future: F, id: task::Id) -> JoinHandle<F::Output>\n    where\n        F: crate::future::Future + Send + 'static,\n        F::Output: Send + 'static,\n    {\n        Self::bind_new_task(me, future, id)\n    }\n\n    pub(crate) fn shutdown(&self) {\n        self.shared.close(self);\n        self.driver.unpark();\n    }\n\n    pub(super) fn bind_new_task<T>(me: &Arc<Self>, future: T, id: task::Id) -> JoinHandle<T::Output>\n    where\n        T: Future + Send + 'static,\n        T::Output: Send + 'static,\n    {\n        let (handle, notified) = me.shared.owned.bind(future, me.clone(), id);\n\n        me.task_hooks.spawn(&TaskMeta {\n            #[cfg(tokio_unstable)]\n            id,\n            _phantom: Default::default(),\n        });\n\n        if let Some(notified) = notified {\n            me.shared.schedule_task(notified, false);\n        }\n\n        handle\n    }\n}\n\ncfg_unstable! {\n    use std::num::NonZeroU64;\n\n    impl Handle {\n        pub(crate) fn owned_id(&self) -> NonZeroU64 {\n            self.shared.owned.id\n        }\n    }\n}\n\nimpl fmt::Debug for Handle {\n    fn fmt(&self, fmt: &mut fmt::Formatter<'_>) -> fmt::Result {\n        fmt.debug_struct(\"multi_thread::Handle { ... }\").finish()\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "6204eb1520276c09972329b951fa59f6767795a2",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tokio/tokio/src/runtime/scheduler/multi_thread_alt/worker/metrics.rs",
    "func": "use super::Shared;\n\nimpl Shared {\n    pub(crate) fn injection_queue_depth(&self) -> usize {\n        self.inject.len()\n    }\n\n    pub(crate) fn worker_local_queue_depth(&self, worker: usize) -> usize {\n        self.remotes[worker].steal.len()\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "e16ddda2190f58f1fdaf7597383d6cca9edb6b91",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tokio/tokio/src/runtime/scheduler/multi_thread_alt/worker/taskdump.rs",
    "func": "use super::{Core, Handle, Shared};\n\nuse crate::loom::sync::Arc;\nuse crate::runtime::scheduler::multi_thread_alt::Stats;\nuse crate::runtime::task::trace::trace_multi_thread;\nuse crate::runtime::{dump, WorkerMetrics};\n\nuse std::time::Duration;\n\nimpl Handle {\n    pub(super) fn trace_core(&self, mut core: Box<Core>) -> Box<Core> {\n        core.is_traced = false;\n\n        if core.is_shutdown {\n            return core;\n        }\n\n        // wait for other workers, or timeout without tracing\n        let timeout = Duration::from_millis(250); // a _very_ generous timeout\n        let barrier =\n            if let Some(barrier) = self.shared.trace_status.trace_start.wait_timeout(timeout) {\n                barrier\n            } else {\n                // don't attempt to trace\n                return core;\n            };\n\n        if !barrier.is_leader() {\n            // wait for leader to finish tracing\n            self.shared.trace_status.trace_end.wait();\n            return core;\n        }\n\n        // trace\n\n        let owned = &self.shared.owned;\n        let mut local = self.shared.steal_all();\n        let synced = &self.shared.synced;\n        let injection = &self.shared.inject;\n\n        // safety: `trace_multi_thread` is invoked with the same `synced` that `injection`\n        // was created with.\n        let traces = unsafe { trace_multi_thread(owned, &mut local, synced, injection) }\n            .into_iter()\n            .map(dump::Task::new)\n            .collect();\n\n        let result = dump::Dump::new(traces);\n\n        // stash the result\n        self.shared.trace_status.stash_result(result);\n\n        // allow other workers to proceed\n        self.shared.trace_status.trace_end.wait();\n\n        core\n    }\n}\n\nimpl Shared {\n    /// Steal all tasks from remotes into a single local queue.\n    pub(super) fn steal_all(&self) -> super::queue::Local<Arc<Handle>> {\n        let (_steal, mut local) = super::queue::local();\n\n        let worker_metrics = WorkerMetrics::new();\n        let mut stats = Stats::new(&worker_metrics);\n\n        for remote in self.remotes.iter() {\n            let steal = &remote.steal;\n            while !steal.is_empty() {\n                if let Some(task) = steal.steal_into(&mut local, &mut stats) {\n                    local.push_back([task].into_iter());\n                }\n            }\n        }\n\n        local\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "2d5def0c09689139897bbc83a4431c5d441b4a7a",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tokio/tokio/src/sync/task/atomic_waker.rs",
    "func": "#![cfg_attr(any(loom, not(feature = \"sync\")), allow(dead_code, unreachable_pub))]\n\nuse crate::loom::cell::UnsafeCell;\nuse crate::loom::hint;\nuse crate::loom::sync::atomic::AtomicUsize;\n\nuse std::fmt;\nuse std::panic::{resume_unwind, AssertUnwindSafe, RefUnwindSafe, UnwindSafe};\nuse std::sync::atomic::Ordering::{AcqRel, Acquire, Release};\nuse std::task::Waker;\n\n/// A synchronization primitive for task waking.\n///\n/// `AtomicWaker` will coordinate concurrent wakes with the consumer\n/// potentially \"waking\" the underlying task. This is useful in scenarios\n/// where a computation completes in another thread and wants to wake the\n/// consumer, but the consumer is in the process of being migrated to a new\n/// logical task.\n///\n/// Consumers should call `register` before checking the result of a computation\n/// and producers should call `wake` after producing the computation (this\n/// differs from the usual `thread::park` pattern). It is also permitted for\n/// `wake` to be called **before** `register`. This results in a no-op.\n///\n/// A single `AtomicWaker` may be reused for any number of calls to `register` or\n/// `wake`.\npub(crate) struct AtomicWaker {\n    state: AtomicUsize,\n    waker: UnsafeCell<Option<Waker>>,\n}\n\nimpl RefUnwindSafe for AtomicWaker {}\nimpl UnwindSafe for AtomicWaker {}\n\n// `AtomicWaker` is a multi-consumer, single-producer transfer cell. The cell\n// stores a `Waker` value produced by calls to `register` and many threads can\n// race to take the waker by calling `wake`.\n//\n// If a new `Waker` instance is produced by calling `register` before an existing\n// one is consumed, then the existing one is overwritten.\n//\n// While `AtomicWaker` is single-producer, the implementation ensures memory\n// safety. In the event of concurrent calls to `register`, there will be a\n// single winner whose waker will get stored in the cell. The losers will not\n// have their tasks woken. As such, callers should ensure to add synchronization\n// to calls to `register`.\n//\n// The implementation uses a single `AtomicUsize` value to coordinate access to\n// the `Waker` cell. There are two bits that are operated on independently. These\n// are represented by `REGISTERING` and `WAKING`.\n//\n// The `REGISTERING` bit is set when a producer enters the critical section. The\n// `WAKING` bit is set when a consumer enters the critical section. Neither\n// bit being set is represented by `WAITING`.\n//\n// A thread obtains an exclusive lock on the waker cell by transitioning the\n// state from `WAITING` to `REGISTERING` or `WAKING`, depending on the\n// operation the thread wishes to perform. When this transition is made, it is\n// guaranteed that no other thread will access the waker cell.\n//\n// # Registering\n//\n// On a call to `register`, an attempt to transition the state from WAITING to\n// REGISTERING is made. On success, the caller obtains a lock on the waker cell.\n//\n// If the lock is obtained, then the thread sets the waker cell to the waker\n// provided as an argument. Then it attempts to transition the state back from\n// `REGISTERING` -> `WAITING`.\n//\n// If this transition is successful, then the registering process is complete\n// and the next call to `wake` will observe the waker.\n//\n// If the transition fails, then there was a concurrent call to `wake` that\n// was unable to access the waker cell (due to the registering thread holding the\n// lock). To handle this, the registering thread removes the waker it just set\n// from the cell and calls `wake` on it. This call to wake represents the\n// attempt to wake by the other thread (that set the `WAKING` bit). The\n// state is then transitioned from `REGISTERING | WAKING` back to `WAITING`.\n// This transition must succeed because, at this point, the state cannot be\n// transitioned by another thread.\n//\n// # Waking\n//\n// On a call to `wake`, an attempt to transition the state from `WAITING` to\n// `WAKING` is made. On success, the caller obtains a lock on the waker cell.\n//\n// If the lock is obtained, then the thread takes ownership of the current value\n// in the waker cell, and calls `wake` on it. The state is then transitioned\n// back to `WAITING`. This transition must succeed as, at this point, the state\n// cannot be transitioned by another thread.\n//\n// If the thread is unable to obtain the lock, the `WAKING` bit is still set.\n// This is because it has either been set by the current thread but the previous\n// value included the `REGISTERING` bit **or** a concurrent thread is in the\n// `WAKING` critical section. Either way, no action must be taken.\n//\n// If the current thread is the only concurrent call to `wake` and another\n// thread is in the `register` critical section, when the other thread **exits**\n// the `register` critical section, it will observe the `WAKING` bit and\n// handle the waker itself.\n//\n// If another thread is in the `waker` critical section, then it will handle\n// waking the caller task.\n//\n// # A potential race (is safely handled).\n//\n// Imagine the following situation:\n//\n// * Thread A obtains the `wake` lock and wakes a task.\n//\n// * Before thread A releases the `wake` lock, the woken task is scheduled.\n//\n// * Thread B attempts to wake the task. In theory this should result in the\n//   task being woken, but it cannot because thread A still holds the wake\n//   lock.\n//\n// This case is handled by requiring users of `AtomicWaker` to call `register`\n// **before** attempting to observe the application state change that resulted\n// in the task being woken. The wakers also change the application state\n// before calling wake.\n//\n// Because of this, the task will do one of two things.\n//\n// 1) Observe the application state change that Thread B is waking on. In\n//    this case, it is OK for Thread B's wake to be lost.\n//\n// 2) Call register before attempting to observe the application state. Since\n//    Thread A still holds the `wake` lock, the call to `register` will result\n//    in the task waking itself and get scheduled again.\n\n/// Idle state.\nconst WAITING: usize = 0;\n\n/// A new waker value is being registered with the `AtomicWaker` cell.\nconst REGISTERING: usize = 0b01;\n\n/// The task currently registered with the `AtomicWaker` cell is being woken.\nconst WAKING: usize = 0b10;\n\nimpl AtomicWaker {\n    /// Create an `AtomicWaker`\n    pub(crate) fn new() -> AtomicWaker {\n        AtomicWaker {\n            state: AtomicUsize::new(WAITING),\n            waker: UnsafeCell::new(None),\n        }\n    }\n\n    /*\n    /// Registers the current waker to be notified on calls to `wake`.\n    pub(crate) fn register(&self, waker: Waker) {\n        self.do_register(waker);\n    }\n    */\n\n    /// Registers the provided waker to be notified on calls to `wake`.\n    ///\n    /// The new waker will take place of any previous wakers that were registered\n    /// by previous calls to `register`. Any calls to `wake` that happen after\n    /// a call to `register` (as defined by the memory ordering rules), will\n    /// wake the `register` caller's task.\n    ///\n    /// It is safe to call `register` with multiple other threads concurrently\n    /// calling `wake`. This will result in the `register` caller's current\n    /// task being woken once.\n    ///\n    /// This function is safe to call concurrently, but this is generally a bad\n    /// idea. Concurrent calls to `register` will attempt to register different\n    /// tasks to be woken. One of the callers will win and have its task set,\n    /// but there is no guarantee as to which caller will succeed.\n    pub(crate) fn register_by_ref(&self, waker: &Waker) {\n        self.do_register(waker);\n    }\n\n    fn do_register<W>(&self, waker: W)\n    where\n        W: WakerRef,\n    {\n        fn catch_unwind<F: FnOnce() -> R, R>(f: F) -> std::thread::Result<R> {\n            std::panic::catch_unwind(AssertUnwindSafe(f))\n        }\n\n        match self\n            .state\n            .compare_exchange(WAITING, REGISTERING, Acquire, Acquire)\n            .unwrap_or_else(|x| x)\n        {\n            WAITING => {\n                unsafe {\n                    // If `into_waker` panics (because it's code outside of\n                    // AtomicWaker) we need to prime a guard that is called on\n                    // unwind to restore the waker to a WAITING state. Otherwise\n                    // any future calls to register will incorrectly be stuck\n                    // believing it's being updated by someone else.\n                    let new_waker_or_panic = catch_unwind(move || waker.into_waker());\n\n                    // Set the field to contain the new waker, or if\n                    // `into_waker` panicked, leave the old value.\n                    let mut maybe_panic = None;\n                    let mut old_waker = None;\n                    match new_waker_or_panic {\n                        Ok(new_waker) => {\n                            old_waker = self.waker.with_mut(|t| (*t).take());\n                            self.waker.with_mut(|t| *t = Some(new_waker));\n                        }\n                        Err(panic) => maybe_panic = Some(panic),\n                    }\n\n                    // Release the lock. If the state transitioned to include\n                    // the `WAKING` bit, this means that a wake has been\n                    // called concurrently, so we have to remove the waker and\n                    // wake it.`\n                    //\n                    // Start by assuming that the state is `REGISTERING` as this\n                    // is what we jut set it to.\n                    let res = self\n                        .state\n                        .compare_exchange(REGISTERING, WAITING, AcqRel, Acquire);\n\n                    match res {\n                        Ok(_) => {\n                            // We don't want to give the caller the panic if it\n                            // was someone else who put in that waker.\n                            let _ = catch_unwind(move || {\n                                drop(old_waker);\n                            });\n                        }\n                        Err(actual) => {\n                            // This branch can only be reached if a\n                            // concurrent thread called `wake`. In this\n                            // case, `actual` **must** be `REGISTERING |\n                            // WAKING`.\n                            debug_assert_eq!(actual, REGISTERING | WAKING);\n\n                            // Take the waker to wake once the atomic operation has\n                            // completed.\n                            let mut waker = self.waker.with_mut(|t| (*t).take());\n\n                            // Just swap, because no one could change state\n                            // while state == `Registering | `Waking`\n                            self.state.swap(WAITING, AcqRel);\n\n                            // If `into_waker` panicked, then the waker in the\n                            // waker slot is actually the old waker.\n                            if maybe_panic.is_some() {\n                                old_waker = waker.take();\n                            }\n\n                            // We don't want to give the caller the panic if it\n                            // was someone else who put in that waker.\n                            if let Some(old_waker) = old_waker {\n                                let _ = catch_unwind(move || {\n                                    old_waker.wake();\n                                });\n                            }\n\n                            // The atomic swap was complete, now wake the waker\n                            // and return.\n                            //\n                            // If this panics, we end up in a consumed state and\n                            // return the panic to the caller.\n                            if let Some(waker) = waker {\n                                debug_assert!(maybe_panic.is_none());\n                                waker.wake();\n                            }\n                        }\n                    }\n\n                    if let Some(panic) = maybe_panic {\n                        // If `into_waker` panicked, return the panic to the caller.\n                        resume_unwind(panic);\n                    }\n                }\n            }\n            WAKING => {\n                // Currently in the process of waking the task, i.e.,\n                // `wake` is currently being called on the old waker.\n                // So, we call wake on the new waker.\n                //\n                // If this panics, someone else is responsible for restoring the\n                // state of the waker.\n                waker.wake();\n\n                // This is equivalent to a spin lock, so use a spin hint.\n                hint::spin_loop();\n            }\n            state => {\n                // In this case, a concurrent thread is holding the\n                // \"registering\" lock. This probably indicates a bug in the\n                // caller's code as racing to call `register` doesn't make much\n                // sense.\n                //\n                // We just want to maintain memory safety. It is ok to drop the\n                // call to `register`.\n                debug_assert!(state == REGISTERING || state == REGISTERING | WAKING);\n            }\n        }\n    }\n\n    /// Wakes the task that last called `register`.\n    ///\n    /// If `register` has not been called yet, then this does nothing.\n    pub(crate) fn wake(&self) {\n        if let Some(waker) = self.take_waker() {\n            // If wake panics, we've consumed the waker which is a legitimate\n            // outcome.\n            waker.wake();\n        }\n    }\n\n    /// Attempts to take the `Waker` value out of the `AtomicWaker` with the\n    /// intention that the caller will wake the task later.\n    pub(crate) fn take_waker(&self) -> Option<Waker> {\n        // AcqRel ordering is used in order to acquire the value of the `waker`\n        // cell as well as to establish a `release` ordering with whatever\n        // memory the `AtomicWaker` is associated with.\n        match self.state.fetch_or(WAKING, AcqRel) {\n            WAITING => {\n                // The waking lock has been acquired.\n                let waker = unsafe { self.waker.with_mut(|t| (*t).take()) };\n\n                // Release the lock\n                self.state.fetch_and(!WAKING, Release);\n\n                waker\n            }\n            state => {\n                // There is a concurrent thread currently updating the\n                // associated waker.\n                //\n                // Nothing more to do as the `WAKING` bit has been set. It\n                // doesn't matter if there are concurrent registering threads or\n                // not.\n                //\n                debug_assert!(\n                    state == REGISTERING || state == REGISTERING | WAKING || state == WAKING\n                );\n                None\n            }\n        }\n    }\n}\n\nimpl Default for AtomicWaker {\n    fn default() -> Self {\n        AtomicWaker::new()\n    }\n}\n\nimpl fmt::Debug for AtomicWaker {\n    fn fmt(&self, fmt: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(fmt, \"AtomicWaker\")\n    }\n}\n\nunsafe impl Send for AtomicWaker {}\nunsafe impl Sync for AtomicWaker {}\n\ntrait WakerRef {\n    fn wake(self);\n    fn into_waker(self) -> Waker;\n}\n\nimpl WakerRef for Waker {\n    fn wake(self) {\n        self.wake();\n    }\n\n    fn into_waker(self) -> Waker {\n        self\n    }\n}\n\nimpl WakerRef for &Waker {\n    fn wake(self) {\n        self.wake_by_ref();\n    }\n\n    fn into_waker(self) -> Waker {\n        self.clone()\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "bf912b9d8042e8abb5d9654ba2ca384358efe65f",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tokio/tokio/src/io/read_buf.rs",
    "func": "use std::fmt;\nuse std::mem::MaybeUninit;\n\n/// A wrapper around a byte buffer that is incrementally filled and initialized.\n///\n/// This type is a sort of \"double cursor\". It tracks three regions in the\n/// buffer: a region at the beginning of the buffer that has been logically\n/// filled with data, a region that has been initialized at some point but not\n/// yet logically filled, and a region at the end that may be uninitialized.\n/// The filled region is guaranteed to be a subset of the initialized region.\n///\n/// In summary, the contents of the buffer can be visualized as:\n///\n/// ```not_rust\n/// [             capacity              ]\n/// [ filled |         unfilled         ]\n/// [    initialized    | uninitialized ]\n/// ```\n///\n/// It is undefined behavior to de-initialize any bytes from the uninitialized\n/// region, since it is merely unknown whether this region is uninitialized or\n/// not, and if part of it turns out to be initialized, it must stay initialized.\npub struct ReadBuf<'a> {\n    buf: &'a mut [MaybeUninit<u8>],\n    filled: usize,\n    initialized: usize,\n}\n\nimpl<'a> ReadBuf<'a> {\n    /// Creates a new `ReadBuf` from a fully initialized buffer.\n    #[inline]\n    pub fn new(buf: &'a mut [u8]) -> ReadBuf<'a> {\n        let initialized = buf.len();\n        let buf = unsafe { slice_to_uninit_mut(buf) };\n        ReadBuf {\n            buf,\n            filled: 0,\n            initialized,\n        }\n    }\n\n    /// Creates a new `ReadBuf` from a fully uninitialized buffer.\n    ///\n    /// Use `assume_init` if part of the buffer is known to be already initialized.\n    #[inline]\n    pub fn uninit(buf: &'a mut [MaybeUninit<u8>]) -> ReadBuf<'a> {\n        ReadBuf {\n            buf,\n            filled: 0,\n            initialized: 0,\n        }\n    }\n\n    /// Returns the total capacity of the buffer.\n    #[inline]\n    pub fn capacity(&self) -> usize {\n        self.buf.len()\n    }\n\n    /// Returns a shared reference to the filled portion of the buffer.\n    #[inline]\n    pub fn filled(&self) -> &[u8] {\n        let slice = &self.buf[..self.filled];\n        // safety: filled describes how far into the buffer that the\n        // user has filled with bytes, so it's been initialized.\n        unsafe { slice_assume_init(slice) }\n    }\n\n    /// Returns a mutable reference to the filled portion of the buffer.\n    #[inline]\n    pub fn filled_mut(&mut self) -> &mut [u8] {\n        let slice = &mut self.buf[..self.filled];\n        // safety: filled describes how far into the buffer that the\n        // user has filled with bytes, so it's been initialized.\n        unsafe { slice_assume_init_mut(slice) }\n    }\n\n    /// Returns a new `ReadBuf` comprised of the unfilled section up to `n`.\n    #[inline]\n    pub fn take(&mut self, n: usize) -> ReadBuf<'_> {\n        let max = std::cmp::min(self.remaining(), n);\n        // Safety: We don't set any of the `unfilled_mut` with `MaybeUninit::uninit`.\n        unsafe { ReadBuf::uninit(&mut self.unfilled_mut()[..max]) }\n    }\n\n    /// Returns a shared reference to the initialized portion of the buffer.\n    ///\n    /// This includes the filled portion.\n    #[inline]\n    pub fn initialized(&self) -> &[u8] {\n        let slice = &self.buf[..self.initialized];\n        // safety: initialized describes how far into the buffer that the\n        // user has at some point initialized with bytes.\n        unsafe { slice_assume_init(slice) }\n    }\n\n    /// Returns a mutable reference to the initialized portion of the buffer.\n    ///\n    /// This includes the filled portion.\n    #[inline]\n    pub fn initialized_mut(&mut self) -> &mut [u8] {\n        let slice = &mut self.buf[..self.initialized];\n        // safety: initialized describes how far into the buffer that the\n        // user has at some point initialized with bytes.\n        unsafe { slice_assume_init_mut(slice) }\n    }\n\n    /// Returns a mutable reference to the entire buffer, without ensuring that it has been fully\n    /// initialized.\n    ///\n    /// The elements between 0 and `self.filled().len()` are filled, and those between 0 and\n    /// `self.initialized().len()` are initialized (and so can be converted to a `&mut [u8]`).\n    ///\n    /// The caller of this method must ensure that these invariants are upheld. For example, if the\n    /// caller initializes some of the uninitialized section of the buffer, it must call\n    /// [`assume_init`](Self::assume_init) with the number of bytes initialized.\n    ///\n    /// # Safety\n    ///\n    /// The caller must not de-initialize portions of the buffer that have already been initialized.\n    /// This includes any bytes in the region marked as uninitialized by `ReadBuf`.\n    #[inline]\n    pub unsafe fn inner_mut(&mut self) -> &mut [MaybeUninit<u8>] {\n        self.buf\n    }\n\n    /// Returns a mutable reference to the unfilled part of the buffer without ensuring that it has been fully\n    /// initialized.\n    ///\n    /// # Safety\n    ///\n    /// The caller must not de-initialize portions of the buffer that have already been initialized.\n    /// This includes any bytes in the region marked as uninitialized by `ReadBuf`.\n    #[inline]\n    pub unsafe fn unfilled_mut(&mut self) -> &mut [MaybeUninit<u8>] {\n        &mut self.buf[self.filled..]\n    }\n\n    /// Returns a mutable reference to the unfilled part of the buffer, ensuring it is fully initialized.\n    ///\n    /// Since `ReadBuf` tracks the region of the buffer that has been initialized, this is effectively \"free\" after\n    /// the first use.\n    #[inline]\n    pub fn initialize_unfilled(&mut self) -> &mut [u8] {\n        self.initialize_unfilled_to(self.remaining())\n    }\n\n    /// Returns a mutable reference to the first `n` bytes of the unfilled part of the buffer, ensuring it is\n    /// fully initialized.\n    ///\n    /// # Panics\n    ///\n    /// Panics if `self.remaining()` is less than `n`.\n    #[inline]\n    #[track_caller]\n    pub fn initialize_unfilled_to(&mut self, n: usize) -> &mut [u8] {\n        assert!(self.remaining() >= n, \"n overflows remaining\");\n\n        // This can't overflow, otherwise the assert above would have failed.\n        let end = self.filled + n;\n\n        if self.initialized < end {\n            unsafe {\n                self.buf[self.initialized..end]\n                    .as_mut_ptr()\n                    .write_bytes(0, end - self.initialized);\n            }\n            self.initialized = end;\n        }\n\n        let slice = &mut self.buf[self.filled..end];\n        // safety: just above, we checked that the end of the buf has\n        // been initialized to some value.\n        unsafe { slice_assume_init_mut(slice) }\n    }\n\n    /// Returns the number of bytes at the end of the slice that have not yet been filled.\n    #[inline]\n    pub fn remaining(&self) -> usize {\n        self.capacity() - self.filled\n    }\n\n    /// Clears the buffer, resetting the filled region to empty.\n    ///\n    /// The number of initialized bytes is not changed, and the contents of the buffer are not modified.\n    #[inline]\n    pub fn clear(&mut self) {\n        self.filled = 0;\n    }\n\n    /// Advances the size of the filled region of the buffer.\n    ///\n    /// The number of initialized bytes is not changed.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the filled region of the buffer would become larger than the initialized region.\n    #[inline]\n    #[track_caller]\n    pub fn advance(&mut self, n: usize) {\n        let new = self.filled.checked_add(n).expect(\"filled overflow\");\n        self.set_filled(new);\n    }\n\n    /// Sets the size of the filled region of the buffer.\n    ///\n    /// The number of initialized bytes is not changed.\n    ///\n    /// Note that this can be used to *shrink* the filled region of the buffer in addition to growing it (for\n    /// example, by a `AsyncRead` implementation that compresses data in-place).\n    ///\n    /// # Panics\n    ///\n    /// Panics if the filled region of the buffer would become larger than the initialized region.\n    #[inline]\n    #[track_caller]\n    pub fn set_filled(&mut self, n: usize) {\n        assert!(\n            n <= self.initialized,\n            \"filled must not become larger than initialized\"\n        );\n        self.filled = n;\n    }\n\n    /// Asserts that the first `n` unfilled bytes of the buffer are initialized.\n    ///\n    /// `ReadBuf` assumes that bytes are never de-initialized, so this method does nothing when called with fewer\n    /// bytes than are already known to be initialized.\n    ///\n    /// # Safety\n    ///\n    /// The caller must ensure that `n` unfilled bytes of the buffer have already been initialized.\n    #[inline]\n    pub unsafe fn assume_init(&mut self, n: usize) {\n        let new = self.filled + n;\n        if new > self.initialized {\n            self.initialized = new;\n        }\n    }\n\n    /// Appends data to the buffer, advancing the written position and possibly also the initialized position.\n    ///\n    /// # Panics\n    ///\n    /// Panics if `self.remaining()` is less than `buf.len()`.\n    #[inline]\n    #[track_caller]\n    pub fn put_slice(&mut self, buf: &[u8]) {\n        assert!(\n            self.remaining() >= buf.len(),\n            \"buf.len() must fit in remaining(); buf.len() = {}, remaining() = {}\",\n            buf.len(),\n            self.remaining()\n        );\n\n        let amt = buf.len();\n        // Cannot overflow, asserted above\n        let end = self.filled + amt;\n\n        // Safety: the length is asserted above\n        unsafe {\n            self.buf[self.filled..end]\n                .as_mut_ptr()\n                .cast::<u8>()\n                .copy_from_nonoverlapping(buf.as_ptr(), amt);\n        }\n\n        if self.initialized < end {\n            self.initialized = end;\n        }\n        self.filled = end;\n    }\n}\n\n#[cfg(feature = \"io-util\")]\n#[cfg_attr(docsrs, doc(cfg(feature = \"io-util\")))]\nunsafe impl<'a> bytes::BufMut for ReadBuf<'a> {\n    fn remaining_mut(&self) -> usize {\n        self.remaining()\n    }\n\n    // SAFETY: The caller guarantees that at least `cnt` unfilled bytes have been initialized.\n    unsafe fn advance_mut(&mut self, cnt: usize) {\n        self.assume_init(cnt);\n        self.advance(cnt);\n    }\n\n    fn chunk_mut(&mut self) -> &mut bytes::buf::UninitSlice {\n        // SAFETY: No region of `unfilled` will be deinitialized because it is\n        // exposed as an `UninitSlice`, whose API guarantees that the memory is\n        // never deinitialized.\n        let unfilled = unsafe { self.unfilled_mut() };\n        let len = unfilled.len();\n        let ptr = unfilled.as_mut_ptr() as *mut u8;\n\n        // SAFETY: The pointer is valid for `len` bytes because it comes from a\n        // slice of that length.\n        unsafe { bytes::buf::UninitSlice::from_raw_parts_mut(ptr, len) }\n    }\n}\n\nimpl fmt::Debug for ReadBuf<'_> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"ReadBuf\")\n            .field(\"filled\", &self.filled)\n            .field(\"initialized\", &self.initialized)\n            .field(\"capacity\", &self.capacity())\n            .finish()\n    }\n}\n\nunsafe fn slice_to_uninit_mut(slice: &mut [u8]) -> &mut [MaybeUninit<u8>] {\n    &mut *(slice as *mut [u8] as *mut [MaybeUninit<u8>])\n}\n\n// TODO: This could use `MaybeUninit::slice_assume_init` when it is stable.\nunsafe fn slice_assume_init(slice: &[MaybeUninit<u8>]) -> &[u8] {\n    &*(slice as *const [MaybeUninit<u8>] as *const [u8])\n}\n\n// TODO: This could use `MaybeUninit::slice_assume_init_mut` when it is stable.\nunsafe fn slice_assume_init_mut(slice: &mut [MaybeUninit<u8>]) -> &mut [u8] {\n    &mut *(slice as *mut [MaybeUninit<u8>] as *mut [u8])\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "eb754f0de2d22610e8038bcf600f41977be448fb",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tokio/tokio/src/io/util/buf_reader.rs",
    "func": "use crate::io::util::DEFAULT_BUF_SIZE;\nuse crate::io::{AsyncBufRead, AsyncRead, AsyncSeek, AsyncWrite, ReadBuf};\n\nuse pin_project_lite::pin_project;\nuse std::io::{self, IoSlice, SeekFrom};\nuse std::pin::Pin;\nuse std::task::{ready, Context, Poll};\nuse std::{cmp, fmt, mem};\n\npin_project! {\n    /// The `BufReader` struct adds buffering to any reader.\n    ///\n    /// It can be excessively inefficient to work directly with a [`AsyncRead`]\n    /// instance. A `BufReader` performs large, infrequent reads on the underlying\n    /// [`AsyncRead`] and maintains an in-memory buffer of the results.\n    ///\n    /// `BufReader` can improve the speed of programs that make *small* and\n    /// *repeated* read calls to the same file or network socket. It does not\n    /// help when reading very large amounts at once, or reading just one or a few\n    /// times. It also provides no advantage when reading from a source that is\n    /// already in memory, like a `Vec<u8>`.\n    ///\n    /// When the `BufReader` is dropped, the contents of its buffer will be\n    /// discarded. Creating multiple instances of a `BufReader` on the same\n    /// stream can cause data loss.\n    #[cfg_attr(docsrs, doc(cfg(feature = \"io-util\")))]\n    pub struct BufReader<R> {\n        #[pin]\n        pub(super) inner: R,\n        pub(super) buf: Box<[u8]>,\n        pub(super) pos: usize,\n        pub(super) cap: usize,\n        pub(super) seek_state: SeekState,\n    }\n}\n\nimpl<R: AsyncRead> BufReader<R> {\n    /// Creates a new `BufReader` with a default buffer capacity. The default is currently 8 KB,\n    /// but may change in the future.\n    pub fn new(inner: R) -> Self {\n        Self::with_capacity(DEFAULT_BUF_SIZE, inner)\n    }\n\n    /// Creates a new `BufReader` with the specified buffer capacity.\n    pub fn with_capacity(capacity: usize, inner: R) -> Self {\n        let buffer = vec![0; capacity];\n        Self {\n            inner,\n            buf: buffer.into_boxed_slice(),\n            pos: 0,\n            cap: 0,\n            seek_state: SeekState::Init,\n        }\n    }\n\n    /// Gets a reference to the underlying reader.\n    ///\n    /// It is inadvisable to directly read from the underlying reader.\n    pub fn get_ref(&self) -> &R {\n        &self.inner\n    }\n\n    /// Gets a mutable reference to the underlying reader.\n    ///\n    /// It is inadvisable to directly read from the underlying reader.\n    pub fn get_mut(&mut self) -> &mut R {\n        &mut self.inner\n    }\n\n    /// Gets a pinned mutable reference to the underlying reader.\n    ///\n    /// It is inadvisable to directly read from the underlying reader.\n    pub fn get_pin_mut(self: Pin<&mut Self>) -> Pin<&mut R> {\n        self.project().inner\n    }\n\n    /// Consumes this `BufReader`, returning the underlying reader.\n    ///\n    /// Note that any leftover data in the internal buffer is lost.\n    pub fn into_inner(self) -> R {\n        self.inner\n    }\n\n    /// Returns a reference to the internally buffered data.\n    ///\n    /// Unlike `fill_buf`, this will not attempt to fill the buffer if it is empty.\n    pub fn buffer(&self) -> &[u8] {\n        &self.buf[self.pos..self.cap]\n    }\n\n    /// Invalidates all data in the internal buffer.\n    #[inline]\n    fn discard_buffer(self: Pin<&mut Self>) {\n        let me = self.project();\n        *me.pos = 0;\n        *me.cap = 0;\n    }\n}\n\nimpl<R: AsyncRead> AsyncRead for BufReader<R> {\n    fn poll_read(\n        mut self: Pin<&mut Self>,\n        cx: &mut Context<'_>,\n        buf: &mut ReadBuf<'_>,\n    ) -> Poll<io::Result<()>> {\n        // If we don't have any buffered data and we're doing a massive read\n        // (larger than our internal buffer), bypass our internal buffer\n        // entirely.\n        if self.pos == self.cap && buf.remaining() >= self.buf.len() {\n            let res = ready!(self.as_mut().get_pin_mut().poll_read(cx, buf));\n            self.discard_buffer();\n            return Poll::Ready(res);\n        }\n        let rem = ready!(self.as_mut().poll_fill_buf(cx))?;\n        let amt = std::cmp::min(rem.len(), buf.remaining());\n        buf.put_slice(&rem[..amt]);\n        self.consume(amt);\n        Poll::Ready(Ok(()))\n    }\n}\n\nimpl<R: AsyncRead> AsyncBufRead for BufReader<R> {\n    fn poll_fill_buf(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<io::Result<&[u8]>> {\n        let me = self.project();\n\n        // If we've reached the end of our internal buffer then we need to fetch\n        // some more data from the underlying reader.\n        // Branch using `>=` instead of the more correct `==`\n        // to tell the compiler that the pos..cap slice is always valid.\n        if *me.pos >= *me.cap {\n            debug_assert!(*me.pos == *me.cap);\n            let mut buf = ReadBuf::new(me.buf);\n            ready!(me.inner.poll_read(cx, &mut buf))?;\n            *me.cap = buf.filled().len();\n            *me.pos = 0;\n        }\n        Poll::Ready(Ok(&me.buf[*me.pos..*me.cap]))\n    }\n\n    fn consume(self: Pin<&mut Self>, amt: usize) {\n        let me = self.project();\n        *me.pos = cmp::min(*me.pos + amt, *me.cap);\n    }\n}\n\n#[derive(Debug, Clone, Copy)]\npub(super) enum SeekState {\n    /// `start_seek` has not been called.\n    Init,\n    /// `start_seek` has been called, but `poll_complete` has not yet been called.\n    Start(SeekFrom),\n    /// Waiting for completion of the first `poll_complete` in the `n.checked_sub(remainder).is_none()` branch.\n    PendingOverflowed(i64),\n    /// Waiting for completion of `poll_complete`.\n    Pending,\n}\n\n/// Seeks to an offset, in bytes, in the underlying reader.\n///\n/// The position used for seeking with `SeekFrom::Current(_)` is the\n/// position the underlying reader would be at if the `BufReader` had no\n/// internal buffer.\n///\n/// Seeking always discards the internal buffer, even if the seek position\n/// would otherwise fall within it. This guarantees that calling\n/// `.into_inner()` immediately after a seek yields the underlying reader\n/// at the same position.\n///\n/// See [`AsyncSeek`] for more details.\n///\n/// Note: In the edge case where you're seeking with `SeekFrom::Current(n)`\n/// where `n` minus the internal buffer length overflows an `i64`, two\n/// seeks will be performed instead of one. If the second seek returns\n/// `Err`, the underlying reader will be left at the same position it would\n/// have if you called `seek` with `SeekFrom::Current(0)`.\nimpl<R: AsyncRead + AsyncSeek> AsyncSeek for BufReader<R> {\n    fn start_seek(self: Pin<&mut Self>, pos: SeekFrom) -> io::Result<()> {\n        // We needs to call seek operation multiple times.\n        // And we should always call both start_seek and poll_complete,\n        // as start_seek alone cannot guarantee that the operation will be completed.\n        // poll_complete receives a Context and returns a Poll, so it cannot be called\n        // inside start_seek.\n        *self.project().seek_state = SeekState::Start(pos);\n        Ok(())\n    }\n\n    fn poll_complete(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<io::Result<u64>> {\n        let res = match mem::replace(self.as_mut().project().seek_state, SeekState::Init) {\n            SeekState::Init => {\n                // 1.x AsyncSeek recommends calling poll_complete before start_seek.\n                // We don't have to guarantee that the value returned by\n                // poll_complete called without start_seek is correct,\n                // so we'll return 0.\n                return Poll::Ready(Ok(0));\n            }\n            SeekState::Start(SeekFrom::Current(n)) => {\n                let remainder = (self.cap - self.pos) as i64;\n                // it should be safe to assume that remainder fits within an i64 as the alternative\n                // means we managed to allocate 8 exbibytes and that's absurd.\n                // But it's not out of the realm of possibility for some weird underlying reader to\n                // support seeking by i64::MIN so we need to handle underflow when subtracting\n                // remainder.\n                if let Some(offset) = n.checked_sub(remainder) {\n                    self.as_mut()\n                        .get_pin_mut()\n                        .start_seek(SeekFrom::Current(offset))?;\n                } else {\n                    // seek backwards by our remainder, and then by the offset\n                    self.as_mut()\n                        .get_pin_mut()\n                        .start_seek(SeekFrom::Current(-remainder))?;\n                    if self.as_mut().get_pin_mut().poll_complete(cx)?.is_pending() {\n                        *self.as_mut().project().seek_state = SeekState::PendingOverflowed(n);\n                        return Poll::Pending;\n                    }\n\n                    // https://github.com/rust-lang/rust/pull/61157#issuecomment-495932676\n                    self.as_mut().discard_buffer();\n\n                    self.as_mut()\n                        .get_pin_mut()\n                        .start_seek(SeekFrom::Current(n))?;\n                }\n                self.as_mut().get_pin_mut().poll_complete(cx)?\n            }\n            SeekState::PendingOverflowed(n) => {\n                if self.as_mut().get_pin_mut().poll_complete(cx)?.is_pending() {\n                    *self.as_mut().project().seek_state = SeekState::PendingOverflowed(n);\n                    return Poll::Pending;\n                }\n\n                // https://github.com/rust-lang/rust/pull/61157#issuecomment-495932676\n                self.as_mut().discard_buffer();\n\n                self.as_mut()\n                    .get_pin_mut()\n                    .start_seek(SeekFrom::Current(n))?;\n                self.as_mut().get_pin_mut().poll_complete(cx)?\n            }\n            SeekState::Start(pos) => {\n                // Seeking with Start/End doesn't care about our buffer length.\n                self.as_mut().get_pin_mut().start_seek(pos)?;\n                self.as_mut().get_pin_mut().poll_complete(cx)?\n            }\n            SeekState::Pending => self.as_mut().get_pin_mut().poll_complete(cx)?,\n        };\n\n        match res {\n            Poll::Ready(res) => {\n                self.discard_buffer();\n                Poll::Ready(Ok(res))\n            }\n            Poll::Pending => {\n                *self.as_mut().project().seek_state = SeekState::Pending;\n                Poll::Pending\n            }\n        }\n    }\n}\n\nimpl<R: AsyncRead + AsyncWrite> AsyncWrite for BufReader<R> {\n    fn poll_write(\n        self: Pin<&mut Self>,\n        cx: &mut Context<'_>,\n        buf: &[u8],\n    ) -> Poll<io::Result<usize>> {\n        self.get_pin_mut().poll_write(cx, buf)\n    }\n\n    fn poll_write_vectored(\n        self: Pin<&mut Self>,\n        cx: &mut Context<'_>,\n        bufs: &[IoSlice<'_>],\n    ) -> Poll<io::Result<usize>> {\n        self.get_pin_mut().poll_write_vectored(cx, bufs)\n    }\n\n    fn is_write_vectored(&self) -> bool {\n        self.get_ref().is_write_vectored()\n    }\n\n    fn poll_flush(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<io::Result<()>> {\n        self.get_pin_mut().poll_flush(cx)\n    }\n\n    fn poll_shutdown(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<io::Result<()>> {\n        self.get_pin_mut().poll_shutdown(cx)\n    }\n}\n\nimpl<R: fmt::Debug> fmt::Debug for BufReader<R> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"BufReader\")\n            .field(\"reader\", &self.inner)\n            .field(\n                \"buffer\",\n                &format_args!(\"{}/{}\", self.cap - self.pos, self.buf.len()),\n            )\n            .finish()\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn assert_unpin() {\n        crate::is_unpin::<BufReader<()>>();\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "2ba767ec2983fa777c160686c45a743eea900f06",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tokio/tokio/src/io/util/sink.rs",
    "func": "use crate::io::util::poll_proceed_and_make_progress;\nuse crate::io::AsyncWrite;\n\nuse std::fmt;\nuse std::io;\nuse std::pin::Pin;\nuse std::task::{ready, Context, Poll};\n\ncfg_io_util! {\n    /// An async writer which will move data into the void.\n    ///\n    /// This struct is generally created by calling [`sink`][sink]. Please\n    /// see the documentation of `sink()` for more details.\n    ///\n    /// This is an asynchronous version of [`std::io::Sink`][std].\n    ///\n    /// [sink]: sink()\n    /// [std]: std::io::Sink\n    pub struct Sink {\n        _p: (),\n    }\n\n    /// Creates an instance of an async writer which will successfully consume all\n    /// data.\n    ///\n    /// All calls to [`poll_write`] on the returned instance will return\n    /// `Poll::Ready(Ok(buf.len()))` and the contents of the buffer will not be\n    /// inspected.\n    ///\n    /// This is an asynchronous version of [`std::io::sink`][std].\n    ///\n    /// [`poll_write`]: crate::io::AsyncWrite::poll_write()\n    /// [std]: std::io::sink\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use tokio::io::{self, AsyncWriteExt};\n    ///\n    /// #[tokio::main]\n    /// async fn main() -> io::Result<()> {\n    ///     let buffer = vec![1, 2, 3, 5, 8];\n    ///     let num_bytes = io::sink().write(&buffer).await?;\n    ///     assert_eq!(num_bytes, 5);\n    ///     Ok(())\n    /// }\n    /// ```\n    pub fn sink() -> Sink {\n        Sink { _p: () }\n    }\n}\n\nimpl AsyncWrite for Sink {\n    #[inline]\n    fn poll_write(\n        self: Pin<&mut Self>,\n        cx: &mut Context<'_>,\n        buf: &[u8],\n    ) -> Poll<Result<usize, io::Error>> {\n        ready!(crate::trace::trace_leaf(cx));\n        ready!(poll_proceed_and_make_progress(cx));\n        Poll::Ready(Ok(buf.len()))\n    }\n\n    #[inline]\n    fn poll_flush(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Result<(), io::Error>> {\n        ready!(crate::trace::trace_leaf(cx));\n        ready!(poll_proceed_and_make_progress(cx));\n        Poll::Ready(Ok(()))\n    }\n\n    #[inline]\n    fn poll_shutdown(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Result<(), io::Error>> {\n        ready!(crate::trace::trace_leaf(cx));\n        ready!(poll_proceed_and_make_progress(cx));\n        Poll::Ready(Ok(()))\n    }\n}\n\nimpl fmt::Debug for Sink {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.pad(\"Sink { .. }\")\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn assert_unpin() {\n        crate::is_unpin::<Sink>();\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "f4b41bade88b1e786ae9aa4285621d1f622ce379",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tokio/tokio/src/net/unix/pipe.rs",
    "func": "//! Unix pipe types.\n\nuse crate::io::interest::Interest;\nuse crate::io::{AsyncRead, AsyncWrite, PollEvented, ReadBuf, Ready};\n\nuse mio::unix::pipe as mio_pipe;\nuse std::fs::File;\nuse std::io::{self, Read, Write};\nuse std::os::unix::fs::OpenOptionsExt;\nuse std::os::unix::io::{AsFd, AsRawFd, BorrowedFd, FromRawFd, IntoRawFd, OwnedFd, RawFd};\nuse std::path::Path;\nuse std::pin::Pin;\nuse std::task::{Context, Poll};\n\ncfg_io_util! {\n    use bytes::BufMut;\n}\n\n/// Creates a new anonymous Unix pipe.\n///\n/// This function will open a new pipe and associate both pipe ends with the default\n/// event loop.\n///\n/// If you need to create a pipe for communication with a spawned process, you can\n/// use [`Stdio::piped()`] instead.\n///\n/// [`Stdio::piped()`]: std::process::Stdio::piped\n///\n/// # Errors\n///\n/// If creating a pipe fails, this function will return with the related OS error.\n///\n/// # Examples\n///\n/// Create a pipe and pass the writing end to a spawned process.\n///\n/// ```no_run\n/// use tokio::net::unix::pipe;\n/// use tokio::process::Command;\n/// # use tokio::io::AsyncReadExt;\n/// # use std::error::Error;\n///\n/// # async fn dox() -> Result<(), Box<dyn Error>> {\n/// let (tx, mut rx) = pipe::pipe()?;\n/// let mut buffer = String::new();\n///\n/// let status = Command::new(\"echo\")\n///     .arg(\"Hello, world!\")\n///     .stdout(tx.into_blocking_fd()?)\n///     .status();\n/// rx.read_to_string(&mut buffer).await?;\n///\n/// assert!(status.await?.success());\n/// assert_eq!(buffer, \"Hello, world!\\n\");\n/// # Ok(())\n/// # }\n/// ```\n///\n/// # Panics\n///\n/// This function panics if it is not called from within a runtime with\n/// IO enabled.\n///\n/// The runtime is usually set implicitly when this function is called\n/// from a future driven by a tokio runtime, otherwise runtime can be set\n/// explicitly with [`Runtime::enter`](crate::runtime::Runtime::enter) function.\npub fn pipe() -> io::Result<(Sender, Receiver)> {\n    let (tx, rx) = mio_pipe::new()?;\n    Ok((Sender::from_mio(tx)?, Receiver::from_mio(rx)?))\n}\n\n/// Options and flags which can be used to configure how a FIFO file is opened.\n///\n/// This builder allows configuring how to create a pipe end from a FIFO file.\n/// Generally speaking, when using `OpenOptions`, you'll first call [`new`],\n/// then chain calls to methods to set each option, then call either\n/// [`open_receiver`] or [`open_sender`], passing the path of the FIFO file you\n/// are trying to open. This will give you a [`io::Result`] with a pipe end\n/// inside that you can further operate on.\n///\n/// [`new`]: OpenOptions::new\n/// [`open_receiver`]: OpenOptions::open_receiver\n/// [`open_sender`]: OpenOptions::open_sender\n///\n/// # Examples\n///\n/// Opening a pair of pipe ends from a FIFO file:\n///\n/// ```no_run\n/// use tokio::net::unix::pipe;\n/// # use std::error::Error;\n///\n/// const FIFO_NAME: &str = \"path/to/a/fifo\";\n///\n/// # async fn dox() -> Result<(), Box<dyn Error>> {\n/// let rx = pipe::OpenOptions::new().open_receiver(FIFO_NAME)?;\n/// let tx = pipe::OpenOptions::new().open_sender(FIFO_NAME)?;\n/// # Ok(())\n/// # }\n/// ```\n///\n/// Opening a [`Sender`] on Linux when you are sure the file is a FIFO:\n///\n/// ```ignore\n/// use tokio::net::unix::pipe;\n/// use nix::{unistd::mkfifo, sys::stat::Mode};\n/// # use std::error::Error;\n///\n/// // Our program has exclusive access to this path.\n/// const FIFO_NAME: &str = \"path/to/a/new/fifo\";\n///\n/// # async fn dox() -> Result<(), Box<dyn Error>> {\n/// mkfifo(FIFO_NAME, Mode::S_IRWXU)?;\n/// let tx = pipe::OpenOptions::new()\n///     .read_write(true)\n///     .unchecked(true)\n///     .open_sender(FIFO_NAME)?;\n/// # Ok(())\n/// # }\n/// ```\n#[derive(Clone, Debug)]\npub struct OpenOptions {\n    #[cfg(target_os = \"linux\")]\n    read_write: bool,\n    unchecked: bool,\n}\n\nimpl OpenOptions {\n    /// Creates a blank new set of options ready for configuration.\n    ///\n    /// All options are initially set to `false`.\n    pub fn new() -> OpenOptions {\n        OpenOptions {\n            #[cfg(target_os = \"linux\")]\n            read_write: false,\n            unchecked: false,\n        }\n    }\n\n    /// Sets the option for read-write access.\n    ///\n    /// This option, when true, will indicate that a FIFO file will be opened\n    /// in read-write access mode. This operation is not defined by the POSIX\n    /// standard and is only guaranteed to work on Linux.\n    ///\n    /// # Examples\n    ///\n    /// Opening a [`Sender`] even if there are no open reading ends:\n    ///\n    /// ```ignore\n    /// use tokio::net::unix::pipe;\n    ///\n    /// let tx = pipe::OpenOptions::new()\n    ///     .read_write(true)\n    ///     .open_sender(\"path/to/a/fifo\");\n    /// ```\n    ///\n    /// Opening a resilient [`Receiver`] i.e. a reading pipe end which will not\n    /// fail with [`UnexpectedEof`] during reading if all writing ends of the\n    /// pipe close the FIFO file.\n    ///\n    /// [`UnexpectedEof`]: std::io::ErrorKind::UnexpectedEof\n    ///\n    /// ```ignore\n    /// use tokio::net::unix::pipe;\n    ///\n    /// let tx = pipe::OpenOptions::new()\n    ///     .read_write(true)\n    ///     .open_receiver(\"path/to/a/fifo\");\n    /// ```\n    #[cfg(target_os = \"linux\")]\n    #[cfg_attr(docsrs, doc(cfg(target_os = \"linux\")))]\n    pub fn read_write(&mut self, value: bool) -> &mut Self {\n        self.read_write = value;\n        self\n    }\n\n    /// Sets the option to skip the check for FIFO file type.\n    ///\n    /// By default, [`open_receiver`] and [`open_sender`] functions will check\n    /// if the opened file is a FIFO file. Set this option to `true` if you are\n    /// sure the file is a FIFO file.\n    ///\n    /// [`open_receiver`]: OpenOptions::open_receiver\n    /// [`open_sender`]: OpenOptions::open_sender\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use tokio::net::unix::pipe;\n    /// use nix::{unistd::mkfifo, sys::stat::Mode};\n    /// # use std::error::Error;\n    ///\n    /// // Our program has exclusive access to this path.\n    /// const FIFO_NAME: &str = \"path/to/a/new/fifo\";\n    ///\n    /// # async fn dox() -> Result<(), Box<dyn Error>> {\n    /// mkfifo(FIFO_NAME, Mode::S_IRWXU)?;\n    /// let rx = pipe::OpenOptions::new()\n    ///     .unchecked(true)\n    ///     .open_receiver(FIFO_NAME)?;\n    /// # Ok(())\n    /// # }\n    /// ```\n    pub fn unchecked(&mut self, value: bool) -> &mut Self {\n        self.unchecked = value;\n        self\n    }\n\n    /// Creates a [`Receiver`] from a FIFO file with the options specified by `self`.\n    ///\n    /// This function will open the FIFO file at the specified path, possibly\n    /// check if it is a pipe, and associate the pipe with the default event\n    /// loop for reading.\n    ///\n    /// # Errors\n    ///\n    /// If the file type check fails, this function will fail with `io::ErrorKind::InvalidInput`.\n    /// This function may also fail with other standard OS errors.\n    ///\n    /// # Panics\n    ///\n    /// This function panics if it is not called from within a runtime with\n    /// IO enabled.\n    ///\n    /// The runtime is usually set implicitly when this function is called\n    /// from a future driven by a tokio runtime, otherwise runtime can be set\n    /// explicitly with [`Runtime::enter`](crate::runtime::Runtime::enter) function.\n    pub fn open_receiver<P: AsRef<Path>>(&self, path: P) -> io::Result<Receiver> {\n        let file = self.open(path.as_ref(), PipeEnd::Receiver)?;\n        Receiver::from_file_unchecked(file)\n    }\n\n    /// Creates a [`Sender`] from a FIFO file with the options specified by `self`.\n    ///\n    /// This function will open the FIFO file at the specified path, possibly\n    /// check if it is a pipe, and associate the pipe with the default event\n    /// loop for writing.\n    ///\n    /// # Errors\n    ///\n    /// If the file type check fails, this function will fail with `io::ErrorKind::InvalidInput`.\n    /// If the file is not opened in read-write access mode and the file is not\n    /// currently open for reading, this function will fail with `ENXIO`.\n    /// This function may also fail with other standard OS errors.\n    ///\n    /// # Panics\n    ///\n    /// This function panics if it is not called from within a runtime with\n    /// IO enabled.\n    ///\n    /// The runtime is usually set implicitly when this function is called\n    /// from a future driven by a tokio runtime, otherwise runtime can be set\n    /// explicitly with [`Runtime::enter`](crate::runtime::Runtime::enter) function.\n    pub fn open_sender<P: AsRef<Path>>(&self, path: P) -> io::Result<Sender> {\n        let file = self.open(path.as_ref(), PipeEnd::Sender)?;\n        Sender::from_file_unchecked(file)\n    }\n\n    fn open(&self, path: &Path, pipe_end: PipeEnd) -> io::Result<File> {\n        let mut options = std::fs::OpenOptions::new();\n        options\n            .read(pipe_end == PipeEnd::Receiver)\n            .write(pipe_end == PipeEnd::Sender)\n            .custom_flags(libc::O_NONBLOCK);\n\n        #[cfg(target_os = \"linux\")]\n        if self.read_write {\n            options.read(true).write(true);\n        }\n\n        let file = options.open(path)?;\n\n        if !self.unchecked && !is_pipe(file.as_fd())? {\n            return Err(io::Error::new(io::ErrorKind::InvalidInput, \"not a pipe\"));\n        }\n\n        Ok(file)\n    }\n}\n\nimpl Default for OpenOptions {\n    fn default() -> OpenOptions {\n        OpenOptions::new()\n    }\n}\n\n#[derive(Clone, Copy, PartialEq, Eq, Debug)]\nenum PipeEnd {\n    Sender,\n    Receiver,\n}\n\n/// Writing end of a Unix pipe.\n///\n/// It can be constructed from a FIFO file with [`OpenOptions::open_sender`].\n///\n/// Opening a named pipe for writing involves a few steps.\n/// Call to [`OpenOptions::open_sender`] might fail with an error indicating\n/// different things:\n///\n/// * [`io::ErrorKind::NotFound`] - There is no file at the specified path.\n/// * [`io::ErrorKind::InvalidInput`] - The file exists, but it is not a FIFO.\n/// * [`ENXIO`] - The file is a FIFO, but no process has it open for reading.\n///   Sleep for a while and try again.\n/// * Other OS errors not specific to opening FIFO files.\n///\n/// Opening a `Sender` from a FIFO file should look like this:\n///\n/// ```no_run\n/// use tokio::net::unix::pipe;\n/// use tokio::time::{self, Duration};\n///\n/// const FIFO_NAME: &str = \"path/to/a/fifo\";\n///\n/// # async fn dox() -> Result<(), Box<dyn std::error::Error>> {\n/// // Wait for a reader to open the file.\n/// let tx = loop {\n///     match pipe::OpenOptions::new().open_sender(FIFO_NAME) {\n///         Ok(tx) => break tx,\n///         Err(e) if e.raw_os_error() == Some(libc::ENXIO) => {},\n///         Err(e) => return Err(e.into()),\n///     }\n///\n///     time::sleep(Duration::from_millis(50)).await;\n/// };\n/// # Ok(())\n/// # }\n/// ```\n///\n/// On Linux, it is possible to create a `Sender` without waiting in a sleeping\n/// loop. This is done by opening a named pipe in read-write access mode with\n/// `OpenOptions::read_write`. This way, a `Sender` can at the same time hold\n/// both a writing end and a reading end, and the latter allows to open a FIFO\n/// without [`ENXIO`] error since the pipe is open for reading as well.\n///\n/// `Sender` cannot be used to read from a pipe, so in practice the read access\n/// is only used when a FIFO is opened. However, using a `Sender` in read-write\n/// mode **may lead to lost data**, because written data will be dropped by the\n/// system as soon as all pipe ends are closed. To avoid lost data you have to\n/// make sure that a reading end has been opened before dropping a `Sender`.\n///\n/// Note that using read-write access mode with FIFO files is not defined by\n/// the POSIX standard and it is only guaranteed to work on Linux.\n///\n/// ```ignore\n/// use tokio::io::AsyncWriteExt;\n/// use tokio::net::unix::pipe;\n///\n/// const FIFO_NAME: &str = \"path/to/a/fifo\";\n///\n/// # async fn dox() -> Result<(), Box<dyn std::error::Error>> {\n/// let mut tx = pipe::OpenOptions::new()\n///     .read_write(true)\n///     .open_sender(FIFO_NAME)?;\n///\n/// // Asynchronously write to the pipe before a reader.\n/// tx.write_all(b\"hello world\").await?;\n/// # Ok(())\n/// # }\n/// ```\n///\n/// [`ENXIO`]: https://docs.rs/libc/latest/libc/constant.ENXIO.html\n#[derive(Debug)]\npub struct Sender {\n    io: PollEvented<mio_pipe::Sender>,\n}\n\nimpl Sender {\n    fn from_mio(mio_tx: mio_pipe::Sender) -> io::Result<Sender> {\n        let io = PollEvented::new_with_interest(mio_tx, Interest::WRITABLE)?;\n        Ok(Sender { io })\n    }\n\n    /// Creates a new `Sender` from a [`File`].\n    ///\n    /// This function is intended to construct a pipe from a [`File`] representing\n    /// a special FIFO file. It will check if the file is a pipe and has write access,\n    /// set it in non-blocking mode and perform the conversion.\n    ///\n    /// # Errors\n    ///\n    /// Fails with `io::ErrorKind::InvalidInput` if the file is not a pipe or it\n    /// does not have write access. Also fails with any standard OS error if it occurs.\n    ///\n    /// # Panics\n    ///\n    /// This function panics if it is not called from within a runtime with\n    /// IO enabled.\n    ///\n    /// The runtime is usually set implicitly when this function is called\n    /// from a future driven by a tokio runtime, otherwise runtime can be set\n    /// explicitly with [`Runtime::enter`](crate::runtime::Runtime::enter) function.\n    pub fn from_file(file: File) -> io::Result<Sender> {\n        Sender::from_owned_fd(file.into())\n    }\n\n    /// Creates a new `Sender` from an [`OwnedFd`].\n    ///\n    /// This function is intended to construct a pipe from an [`OwnedFd`] representing\n    /// an anonymous pipe or a special FIFO file. It will check if the file descriptor\n    /// is a pipe and has write access, set it in non-blocking mode and perform the\n    /// conversion.\n    ///\n    /// # Errors\n    ///\n    /// Fails with `io::ErrorKind::InvalidInput` if the file descriptor is not a pipe\n    /// or it does not have write access. Also fails with any standard OS error if it\n    /// occurs.\n    ///\n    /// # Panics\n    ///\n    /// This function panics if it is not called from within a runtime with\n    /// IO enabled.\n    ///\n    /// The runtime is usually set implicitly when this function is called\n    /// from a future driven by a tokio runtime, otherwise runtime can be set\n    /// explicitly with [`Runtime::enter`](crate::runtime::Runtime::enter) function.\n    pub fn from_owned_fd(owned_fd: OwnedFd) -> io::Result<Sender> {\n        if !is_pipe(owned_fd.as_fd())? {\n            return Err(io::Error::new(io::ErrorKind::InvalidInput, \"not a pipe\"));\n        }\n\n        let flags = get_file_flags(owned_fd.as_fd())?;\n        if has_write_access(flags) {\n            set_nonblocking(owned_fd.as_fd(), flags)?;\n            Sender::from_owned_fd_unchecked(owned_fd)\n        } else {\n            Err(io::Error::new(\n                io::ErrorKind::InvalidInput,\n                \"not in O_WRONLY or O_RDWR access mode\",\n            ))\n        }\n    }\n\n    /// Creates a new `Sender` from a [`File`] without checking pipe properties.\n    ///\n    /// This function is intended to construct a pipe from a File representing\n    /// a special FIFO file. The conversion assumes nothing about the underlying\n    /// file; it is left up to the user to make sure it is opened with write access,\n    /// represents a pipe and is set in non-blocking mode.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use tokio::net::unix::pipe;\n    /// use std::fs::OpenOptions;\n    /// use std::os::unix::fs::{FileTypeExt, OpenOptionsExt};\n    /// # use std::error::Error;\n    ///\n    /// const FIFO_NAME: &str = \"path/to/a/fifo\";\n    ///\n    /// # async fn dox() -> Result<(), Box<dyn Error>> {\n    /// let file = OpenOptions::new()\n    ///     .write(true)\n    ///     .custom_flags(libc::O_NONBLOCK)\n    ///     .open(FIFO_NAME)?;\n    /// if file.metadata()?.file_type().is_fifo() {\n    ///     let tx = pipe::Sender::from_file_unchecked(file)?;\n    ///     /* use the Sender */\n    /// }\n    /// # Ok(())\n    /// # }\n    /// ```\n    ///\n    /// # Panics\n    ///\n    /// This function panics if it is not called from within a runtime with\n    /// IO enabled.\n    ///\n    /// The runtime is usually set implicitly when this function is called\n    /// from a future driven by a tokio runtime, otherwise runtime can be set\n    /// explicitly with [`Runtime::enter`](crate::runtime::Runtime::enter) function.\n    pub fn from_file_unchecked(file: File) -> io::Result<Sender> {\n        Sender::from_owned_fd_unchecked(file.into())\n    }\n\n    /// Creates a new `Sender` from an [`OwnedFd`] without checking pipe properties.\n    ///\n    /// This function is intended to construct a pipe from an [`OwnedFd`] representing\n    /// an anonymous pipe or a special FIFO file. The conversion assumes nothing about\n    /// the underlying pipe; it is left up to the user to make sure that the file\n    /// descriptor represents the writing end of a pipe and the pipe is set in\n    /// non-blocking mode.\n    ///\n    /// # Panics\n    ///\n    /// This function panics if it is not called from within a runtime with\n    /// IO enabled.\n    ///\n    /// The runtime is usually set implicitly when this function is called\n    /// from a future driven by a tokio runtime, otherwise runtime can be set\n    /// explicitly with [`Runtime::enter`](crate::runtime::Runtime::enter) function.\n    pub fn from_owned_fd_unchecked(owned_fd: OwnedFd) -> io::Result<Sender> {\n        // Safety: OwnedFd represents a valid, open file descriptor.\n        let mio_tx = unsafe { mio_pipe::Sender::from_raw_fd(owned_fd.into_raw_fd()) };\n        Sender::from_mio(mio_tx)\n    }\n\n    /// Waits for any of the requested ready states.\n    ///\n    /// This function can be used instead of [`writable()`] to check the returned\n    /// ready set for [`Ready::WRITABLE`] and [`Ready::WRITE_CLOSED`] events.\n    ///\n    /// The function may complete without the pipe being ready. This is a\n    /// false-positive and attempting an operation will return with\n    /// `io::ErrorKind::WouldBlock`. The function can also return with an empty\n    /// [`Ready`] set, so you should always check the returned value and possibly\n    /// wait again if the requested states are not set.\n    ///\n    /// [`writable()`]: Self::writable\n    ///\n    /// # Cancel safety\n    ///\n    /// This method is cancel safe. Once a readiness event occurs, the method\n    /// will continue to return immediately until the readiness event is\n    /// consumed by an attempt to write that fails with `WouldBlock` or\n    /// `Poll::Pending`.\n    pub async fn ready(&self, interest: Interest) -> io::Result<Ready> {\n        let event = self.io.registration().readiness(interest).await?;\n        Ok(event.ready)\n    }\n\n    /// Waits for the pipe to become writable.\n    ///\n    /// This function is equivalent to `ready(Interest::WRITABLE)` and is usually\n    /// paired with [`try_write()`].\n    ///\n    /// [`try_write()`]: Self::try_write\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use tokio::net::unix::pipe;\n    /// use std::io;\n    ///\n    /// #[tokio::main]\n    /// async fn main() -> io::Result<()> {\n    ///     // Open a writing end of a fifo\n    ///     let tx = pipe::OpenOptions::new().open_sender(\"path/to/a/fifo\")?;\n    ///\n    ///     loop {\n    ///         // Wait for the pipe to be writable\n    ///         tx.writable().await?;\n    ///\n    ///         // Try to write data, this may still fail with `WouldBlock`\n    ///         // if the readiness event is a false positive.\n    ///         match tx.try_write(b\"hello world\") {\n    ///             Ok(n) => {\n    ///                 break;\n    ///             }\n    ///             Err(e) if e.kind() == io::ErrorKind::WouldBlock => {\n    ///                 continue;\n    ///             }\n    ///             Err(e) => {\n    ///                 return Err(e.into());\n    ///             }\n    ///         }\n    ///     }\n    ///\n    ///     Ok(())\n    /// }\n    /// ```\n    pub async fn writable(&self) -> io::Result<()> {\n        self.ready(Interest::WRITABLE).await?;\n        Ok(())\n    }\n\n    /// Polls for write readiness.\n    ///\n    /// If the pipe is not currently ready for writing, this method will\n    /// store a clone of the `Waker` from the provided `Context`. When the pipe\n    /// becomes ready for writing, `Waker::wake` will be called on the waker.\n    ///\n    /// Note that on multiple calls to `poll_write_ready` or `poll_write`, only\n    /// the `Waker` from the `Context` passed to the most recent call is\n    /// scheduled to receive a wakeup.\n    ///\n    /// This function is intended for cases where creating and pinning a future\n    /// via [`writable`] is not feasible. Where possible, using [`writable`] is\n    /// preferred, as this supports polling from multiple tasks at once.\n    ///\n    /// [`writable`]: Self::writable\n    ///\n    /// # Return value\n    ///\n    /// The function returns:\n    ///\n    /// * `Poll::Pending` if the pipe is not ready for writing.\n    /// * `Poll::Ready(Ok(()))` if the pipe is ready for writing.\n    /// * `Poll::Ready(Err(e))` if an error is encountered.\n    ///\n    /// # Errors\n    ///\n    /// This function may encounter any standard I/O error except `WouldBlock`.\n    pub fn poll_write_ready(&self, cx: &mut Context<'_>) -> Poll<io::Result<()>> {\n        self.io.registration().poll_write_ready(cx).map_ok(|_| ())\n    }\n\n    /// Tries to write a buffer to the pipe, returning how many bytes were\n    /// written.\n    ///\n    /// The function will attempt to write the entire contents of `buf`, but\n    /// only part of the buffer may be written. If the length of `buf` is not\n    /// greater than `PIPE_BUF` (an OS constant, 4096 under Linux), then the\n    /// write is guaranteed to be atomic, i.e. either the entire content of\n    /// `buf` will be written or this method will fail with `WouldBlock`. There\n    /// is no such guarantee if `buf` is larger than `PIPE_BUF`.\n    ///\n    /// This function is usually paired with [`writable`].\n    ///\n    /// [`writable`]: Self::writable\n    ///\n    /// # Return\n    ///\n    /// If data is successfully written, `Ok(n)` is returned, where `n` is the\n    /// number of bytes written. If the pipe is not ready to write data,\n    /// `Err(io::ErrorKind::WouldBlock)` is returned.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use tokio::net::unix::pipe;\n    /// use std::io;\n    ///\n    /// #[tokio::main]\n    /// async fn main() -> io::Result<()> {\n    ///     // Open a writing end of a fifo\n    ///     let tx = pipe::OpenOptions::new().open_sender(\"path/to/a/fifo\")?;\n    ///\n    ///     loop {\n    ///         // Wait for the pipe to be writable\n    ///         tx.writable().await?;\n    ///\n    ///         // Try to write data, this may still fail with `WouldBlock`\n    ///         // if the readiness event is a false positive.\n    ///         match tx.try_write(b\"hello world\") {\n    ///             Ok(n) => {\n    ///                 break;\n    ///             }\n    ///             Err(e) if e.kind() == io::ErrorKind::WouldBlock => {\n    ///                 continue;\n    ///             }\n    ///             Err(e) => {\n    ///                 return Err(e.into());\n    ///             }\n    ///         }\n    ///     }\n    ///\n    ///     Ok(())\n    /// }\n    /// ```\n    pub fn try_write(&self, buf: &[u8]) -> io::Result<usize> {\n        self.io\n            .registration()\n            .try_io(Interest::WRITABLE, || (&*self.io).write(buf))\n    }\n\n    /// Tries to write several buffers to the pipe, returning how many bytes\n    /// were written.\n    ///\n    /// Data is written from each buffer in order, with the final buffer read\n    /// from possible being only partially consumed. This method behaves\n    /// equivalently to a single call to [`try_write()`] with concatenated\n    /// buffers.\n    ///\n    /// If the total length of buffers is not greater than `PIPE_BUF` (an OS\n    /// constant, 4096 under Linux), then the write is guaranteed to be atomic,\n    /// i.e. either the entire contents of buffers will be written or this\n    /// method will fail with `WouldBlock`. There is no such guarantee if the\n    /// total length of buffers is greater than `PIPE_BUF`.\n    ///\n    /// This function is usually paired with [`writable`].\n    ///\n    /// [`try_write()`]: Self::try_write()\n    /// [`writable`]: Self::writable\n    ///\n    /// # Return\n    ///\n    /// If data is successfully written, `Ok(n)` is returned, where `n` is the\n    /// number of bytes written. If the pipe is not ready to write data,\n    /// `Err(io::ErrorKind::WouldBlock)` is returned.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use tokio::net::unix::pipe;\n    /// use std::io;\n    ///\n    /// #[tokio::main]\n    /// async fn main() -> io::Result<()> {\n    ///     // Open a writing end of a fifo\n    ///     let tx = pipe::OpenOptions::new().open_sender(\"path/to/a/fifo\")?;\n    ///\n    ///     let bufs = [io::IoSlice::new(b\"hello \"), io::IoSlice::new(b\"world\")];\n    ///\n    ///     loop {\n    ///         // Wait for the pipe to be writable\n    ///         tx.writable().await?;\n    ///\n    ///         // Try to write data, this may still fail with `WouldBlock`\n    ///         // if the readiness event is a false positive.\n    ///         match tx.try_write_vectored(&bufs) {\n    ///             Ok(n) => {\n    ///                 break;\n    ///             }\n    ///             Err(ref e) if e.kind() == io::ErrorKind::WouldBlock => {\n    ///                 continue;\n    ///             }\n    ///             Err(e) => {\n    ///                 return Err(e.into());\n    ///             }\n    ///         }\n    ///     }\n    ///\n    ///     Ok(())\n    /// }\n    /// ```\n    pub fn try_write_vectored(&self, buf: &[io::IoSlice<'_>]) -> io::Result<usize> {\n        self.io\n            .registration()\n            .try_io(Interest::WRITABLE, || (&*self.io).write_vectored(buf))\n    }\n\n    /// Converts the pipe into an [`OwnedFd`] in blocking mode.\n    ///\n    /// This function will deregister this pipe end from the event loop, set\n    /// it in blocking mode and perform the conversion.\n    pub fn into_blocking_fd(self) -> io::Result<OwnedFd> {\n        let fd = self.into_nonblocking_fd()?;\n        set_blocking(&fd)?;\n        Ok(fd)\n    }\n\n    /// Converts the pipe into an [`OwnedFd`] in nonblocking mode.\n    ///\n    /// This function will deregister this pipe end from the event loop and\n    /// perform the conversion. The returned file descriptor will be in nonblocking\n    /// mode.\n    pub fn into_nonblocking_fd(self) -> io::Result<OwnedFd> {\n        let mio_pipe = self.io.into_inner()?;\n\n        // Safety: the pipe is now deregistered from the event loop\n        // and we are the only owner of this pipe end.\n        let owned_fd = unsafe { OwnedFd::from_raw_fd(mio_pipe.into_raw_fd()) };\n\n        Ok(owned_fd)\n    }\n}\n\nimpl AsyncWrite for Sender {\n    fn poll_write(\n        self: Pin<&mut Self>,\n        cx: &mut Context<'_>,\n        buf: &[u8],\n    ) -> Poll<io::Result<usize>> {\n        self.io.poll_write(cx, buf)\n    }\n\n    fn poll_write_vectored(\n        self: Pin<&mut Self>,\n        cx: &mut Context<'_>,\n        bufs: &[io::IoSlice<'_>],\n    ) -> Poll<io::Result<usize>> {\n        self.io.poll_write_vectored(cx, bufs)\n    }\n\n    fn is_write_vectored(&self) -> bool {\n        true\n    }\n\n    fn poll_flush(self: Pin<&mut Self>, _: &mut Context<'_>) -> Poll<io::Result<()>> {\n        Poll::Ready(Ok(()))\n    }\n\n    fn poll_shutdown(self: Pin<&mut Self>, _: &mut Context<'_>) -> Poll<io::Result<()>> {\n        Poll::Ready(Ok(()))\n    }\n}\n\nimpl AsRawFd for Sender {\n    fn as_raw_fd(&self) -> RawFd {\n        self.io.as_raw_fd()\n    }\n}\n\nimpl AsFd for Sender {\n    fn as_fd(&self) -> BorrowedFd<'_> {\n        unsafe { BorrowedFd::borrow_raw(self.as_raw_fd()) }\n    }\n}\n\n/// Reading end of a Unix pipe.\n///\n/// It can be constructed from a FIFO file with [`OpenOptions::open_receiver`].\n///\n/// # Examples\n///\n/// Receiving messages from a named pipe in a loop:\n///\n/// ```no_run\n/// use tokio::net::unix::pipe;\n/// use tokio::io::{self, AsyncReadExt};\n///\n/// const FIFO_NAME: &str = \"path/to/a/fifo\";\n///\n/// # async fn dox() -> Result<(), Box<dyn std::error::Error>> {\n/// let mut rx = pipe::OpenOptions::new().open_receiver(FIFO_NAME)?;\n/// loop {\n///     let mut msg = vec![0; 256];\n///     match rx.read_exact(&mut msg).await {\n///         Ok(_) => {\n///             /* handle the message */\n///         }\n///         Err(e) if e.kind() == io::ErrorKind::UnexpectedEof => {\n///             // Writing end has been closed, we should reopen the pipe.\n///             rx = pipe::OpenOptions::new().open_receiver(FIFO_NAME)?;\n///         }\n///         Err(e) => return Err(e.into()),\n///     }\n/// }\n/// # }\n/// ```\n///\n/// On Linux, you can use a `Receiver` in read-write access mode to implement\n/// resilient reading from a named pipe. Unlike `Receiver` opened in read-only\n/// mode, read from a pipe in read-write mode will not fail with `UnexpectedEof`\n/// when the writing end is closed. This way, a `Receiver` can asynchronously\n/// wait for the next writer to open the pipe.\n///\n/// You should not use functions waiting for EOF such as [`read_to_end`] with\n/// a `Receiver` in read-write access mode, since it **may wait forever**.\n/// `Receiver` in this mode also holds an open writing end, which prevents\n/// receiving EOF.\n///\n/// To set the read-write access mode you can use `OpenOptions::read_write`.\n/// Note that using read-write access mode with FIFO files is not defined by\n/// the POSIX standard and it is only guaranteed to work on Linux.\n///\n/// ```ignore\n/// use tokio::net::unix::pipe;\n/// use tokio::io::AsyncReadExt;\n/// # use std::error::Error;\n///\n/// const FIFO_NAME: &str = \"path/to/a/fifo\";\n///\n/// # async fn dox() -> Result<(), Box<dyn Error>> {\n/// let mut rx = pipe::OpenOptions::new()\n///     .read_write(true)\n///     .open_receiver(FIFO_NAME)?;\n/// loop {\n///     let mut msg = vec![0; 256];\n///     rx.read_exact(&mut msg).await?;\n///     /* handle the message */\n/// }\n/// # }\n/// ```\n///\n/// [`read_to_end`]: crate::io::AsyncReadExt::read_to_end\n#[derive(Debug)]\npub struct Receiver {\n    io: PollEvented<mio_pipe::Receiver>,\n}\n\nimpl Receiver {\n    fn from_mio(mio_rx: mio_pipe::Receiver) -> io::Result<Receiver> {\n        let io = PollEvented::new_with_interest(mio_rx, Interest::READABLE)?;\n        Ok(Receiver { io })\n    }\n\n    /// Creates a new `Receiver` from a [`File`].\n    ///\n    /// This function is intended to construct a pipe from a [`File`] representing\n    /// a special FIFO file. It will check if the file is a pipe and has read access,\n    /// set it in non-blocking mode and perform the conversion.\n    ///\n    /// # Errors\n    ///\n    /// Fails with `io::ErrorKind::InvalidInput` if the file is not a pipe or it\n    /// does not have read access. Also fails with any standard OS error if it occurs.\n    ///\n    /// # Panics\n    ///\n    /// This function panics if it is not called from within a runtime with\n    /// IO enabled.\n    ///\n    /// The runtime is usually set implicitly when this function is called\n    /// from a future driven by a tokio runtime, otherwise runtime can be set\n    /// explicitly with [`Runtime::enter`](crate::runtime::Runtime::enter) function.\n    pub fn from_file(file: File) -> io::Result<Receiver> {\n        Receiver::from_owned_fd(file.into())\n    }\n\n    /// Creates a new `Receiver` from an [`OwnedFd`].\n    ///\n    /// This function is intended to construct a pipe from an [`OwnedFd`] representing\n    /// an anonymous pipe or a special FIFO file. It will check if the file descriptor\n    /// is a pipe and has read access, set it in non-blocking mode and perform the\n    /// conversion.\n    ///\n    /// # Errors\n    ///\n    /// Fails with `io::ErrorKind::InvalidInput` if the file descriptor is not a pipe\n    /// or it does not have read access. Also fails with any standard OS error if it\n    /// occurs.\n    ///\n    /// # Panics\n    ///\n    /// This function panics if it is not called from within a runtime with\n    /// IO enabled.\n    ///\n    /// The runtime is usually set implicitly when this function is called\n    /// from a future driven by a tokio runtime, otherwise runtime can be set\n    /// explicitly with [`Runtime::enter`](crate::runtime::Runtime::enter) function.\n    pub fn from_owned_fd(owned_fd: OwnedFd) -> io::Result<Receiver> {\n        if !is_pipe(owned_fd.as_fd())? {\n            return Err(io::Error::new(io::ErrorKind::InvalidInput, \"not a pipe\"));\n        }\n\n        let flags = get_file_flags(owned_fd.as_fd())?;\n        if has_read_access(flags) {\n            set_nonblocking(owned_fd.as_fd(), flags)?;\n            Receiver::from_owned_fd_unchecked(owned_fd)\n        } else {\n            Err(io::Error::new(\n                io::ErrorKind::InvalidInput,\n                \"not in O_RDONLY or O_RDWR access mode\",\n            ))\n        }\n    }\n\n    /// Creates a new `Receiver` from a [`File`] without checking pipe properties.\n    ///\n    /// This function is intended to construct a pipe from a File representing\n    /// a special FIFO file. The conversion assumes nothing about the underlying\n    /// file; it is left up to the user to make sure it is opened with read access,\n    /// represents a pipe and is set in non-blocking mode.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use tokio::net::unix::pipe;\n    /// use std::fs::OpenOptions;\n    /// use std::os::unix::fs::{FileTypeExt, OpenOptionsExt};\n    /// # use std::error::Error;\n    ///\n    /// const FIFO_NAME: &str = \"path/to/a/fifo\";\n    ///\n    /// # async fn dox() -> Result<(), Box<dyn Error>> {\n    /// let file = OpenOptions::new()\n    ///     .read(true)\n    ///     .custom_flags(libc::O_NONBLOCK)\n    ///     .open(FIFO_NAME)?;\n    /// if file.metadata()?.file_type().is_fifo() {\n    ///     let rx = pipe::Receiver::from_file_unchecked(file)?;\n    ///     /* use the Receiver */\n    /// }\n    /// # Ok(())\n    /// # }\n    /// ```\n    ///\n    /// # Panics\n    ///\n    /// This function panics if it is not called from within a runtime with\n    /// IO enabled.\n    ///\n    /// The runtime is usually set implicitly when this function is called\n    /// from a future driven by a tokio runtime, otherwise runtime can be set\n    /// explicitly with [`Runtime::enter`](crate::runtime::Runtime::enter) function.\n    pub fn from_file_unchecked(file: File) -> io::Result<Receiver> {\n        Receiver::from_owned_fd_unchecked(file.into())\n    }\n\n    /// Creates a new `Receiver` from an [`OwnedFd`] without checking pipe properties.\n    ///\n    /// This function is intended to construct a pipe from an [`OwnedFd`] representing\n    /// an anonymous pipe or a special FIFO file. The conversion assumes nothing about\n    /// the underlying pipe; it is left up to the user to make sure that the file\n    /// descriptor represents the reading end of a pipe and the pipe is set in\n    /// non-blocking mode.\n    ///\n    /// # Panics\n    ///\n    /// This function panics if it is not called from within a runtime with\n    /// IO enabled.\n    ///\n    /// The runtime is usually set implicitly when this function is called\n    /// from a future driven by a tokio runtime, otherwise runtime can be set\n    /// explicitly with [`Runtime::enter`](crate::runtime::Runtime::enter) function.\n    pub fn from_owned_fd_unchecked(owned_fd: OwnedFd) -> io::Result<Receiver> {\n        // Safety: OwnedFd represents a valid, open file descriptor.\n        let mio_rx = unsafe { mio_pipe::Receiver::from_raw_fd(owned_fd.into_raw_fd()) };\n        Receiver::from_mio(mio_rx)\n    }\n\n    /// Waits for any of the requested ready states.\n    ///\n    /// This function can be used instead of [`readable()`] to check the returned\n    /// ready set for [`Ready::READABLE`] and [`Ready::READ_CLOSED`] events.\n    ///\n    /// The function may complete without the pipe being ready. This is a\n    /// false-positive and attempting an operation will return with\n    /// `io::ErrorKind::WouldBlock`. The function can also return with an empty\n    /// [`Ready`] set, so you should always check the returned value and possibly\n    /// wait again if the requested states are not set.\n    ///\n    /// [`readable()`]: Self::readable\n    ///\n    /// # Cancel safety\n    ///\n    /// This method is cancel safe. Once a readiness event occurs, the method\n    /// will continue to return immediately until the readiness event is\n    /// consumed by an attempt to read that fails with `WouldBlock` or\n    /// `Poll::Pending`.\n    pub async fn ready(&self, interest: Interest) -> io::Result<Ready> {\n        let event = self.io.registration().readiness(interest).await?;\n        Ok(event.ready)\n    }\n\n    /// Waits for the pipe to become readable.\n    ///\n    /// This function is equivalent to `ready(Interest::READABLE)` and is usually\n    /// paired with [`try_read()`].\n    ///\n    /// [`try_read()`]: Self::try_read()\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use tokio::net::unix::pipe;\n    /// use std::io;\n    ///\n    /// #[tokio::main]\n    /// async fn main() -> io::Result<()> {\n    ///     // Open a reading end of a fifo\n    ///     let rx = pipe::OpenOptions::new().open_receiver(\"path/to/a/fifo\")?;\n    ///\n    ///     let mut msg = vec![0; 1024];\n    ///\n    ///     loop {\n    ///         // Wait for the pipe to be readable\n    ///         rx.readable().await?;\n    ///\n    ///         // Try to read data, this may still fail with `WouldBlock`\n    ///         // if the readiness event is a false positive.\n    ///         match rx.try_read(&mut msg) {\n    ///             Ok(n) => {\n    ///                 msg.truncate(n);\n    ///                 break;\n    ///             }\n    ///             Err(e) if e.kind() == io::ErrorKind::WouldBlock => {\n    ///                 continue;\n    ///             }\n    ///             Err(e) => {\n    ///                 return Err(e.into());\n    ///             }\n    ///         }\n    ///     }\n    ///\n    ///     println!(\"GOT = {:?}\", msg);\n    ///     Ok(())\n    /// }\n    /// ```\n    pub async fn readable(&self) -> io::Result<()> {\n        self.ready(Interest::READABLE).await?;\n        Ok(())\n    }\n\n    /// Polls for read readiness.\n    ///\n    /// If the pipe is not currently ready for reading, this method will\n    /// store a clone of the `Waker` from the provided `Context`. When the pipe\n    /// becomes ready for reading, `Waker::wake` will be called on the waker.\n    ///\n    /// Note that on multiple calls to `poll_read_ready` or `poll_read`, only\n    /// the `Waker` from the `Context` passed to the most recent call is\n    /// scheduled to receive a wakeup.\n    ///\n    /// This function is intended for cases where creating and pinning a future\n    /// via [`readable`] is not feasible. Where possible, using [`readable`] is\n    /// preferred, as this supports polling from multiple tasks at once.\n    ///\n    /// [`readable`]: Self::readable\n    ///\n    /// # Return value\n    ///\n    /// The function returns:\n    ///\n    /// * `Poll::Pending` if the pipe is not ready for reading.\n    /// * `Poll::Ready(Ok(()))` if the pipe is ready for reading.\n    /// * `Poll::Ready(Err(e))` if an error is encountered.\n    ///\n    /// # Errors\n    ///\n    /// This function may encounter any standard I/O error except `WouldBlock`.\n    pub fn poll_read_ready(&self, cx: &mut Context<'_>) -> Poll<io::Result<()>> {\n        self.io.registration().poll_read_ready(cx).map_ok(|_| ())\n    }\n\n    /// Tries to read data from the pipe into the provided buffer, returning how\n    /// many bytes were read.\n    ///\n    /// Reads any pending data from the pipe but does not wait for new data\n    /// to arrive. On success, returns the number of bytes read. Because\n    /// `try_read()` is non-blocking, the buffer does not have to be stored by\n    /// the async task and can exist entirely on the stack.\n    ///\n    /// Usually [`readable()`] is used with this function.\n    ///\n    /// [`readable()`]: Self::readable()\n    ///\n    /// # Return\n    ///\n    /// If data is successfully read, `Ok(n)` is returned, where `n` is the\n    /// number of bytes read. If `n` is `0`, then it can indicate one of two scenarios:\n    ///\n    /// 1. The pipe's writing end is closed and will no longer write data.\n    /// 2. The specified buffer was 0 bytes in length.\n    ///\n    /// If the pipe is not ready to read data,\n    /// `Err(io::ErrorKind::WouldBlock)` is returned.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use tokio::net::unix::pipe;\n    /// use std::io;\n    ///\n    /// #[tokio::main]\n    /// async fn main() -> io::Result<()> {\n    ///     // Open a reading end of a fifo\n    ///     let rx = pipe::OpenOptions::new().open_receiver(\"path/to/a/fifo\")?;\n    ///\n    ///     let mut msg = vec![0; 1024];\n    ///\n    ///     loop {\n    ///         // Wait for the pipe to be readable\n    ///         rx.readable().await?;\n    ///\n    ///         // Try to read data, this may still fail with `WouldBlock`\n    ///         // if the readiness event is a false positive.\n    ///         match rx.try_read(&mut msg) {\n    ///             Ok(n) => {\n    ///                 msg.truncate(n);\n    ///                 break;\n    ///             }\n    ///             Err(e) if e.kind() == io::ErrorKind::WouldBlock => {\n    ///                 continue;\n    ///             }\n    ///             Err(e) => {\n    ///                 return Err(e.into());\n    ///             }\n    ///         }\n    ///     }\n    ///\n    ///     println!(\"GOT = {:?}\", msg);\n    ///     Ok(())\n    /// }\n    /// ```\n    pub fn try_read(&self, buf: &mut [u8]) -> io::Result<usize> {\n        self.io\n            .registration()\n            .try_io(Interest::READABLE, || (&*self.io).read(buf))\n    }\n\n    /// Tries to read data from the pipe into the provided buffers, returning\n    /// how many bytes were read.\n    ///\n    /// Data is copied to fill each buffer in order, with the final buffer\n    /// written to possibly being only partially filled. This method behaves\n    /// equivalently to a single call to [`try_read()`] with concatenated\n    /// buffers.\n    ///\n    /// Reads any pending data from the pipe but does not wait for new data\n    /// to arrive. On success, returns the number of bytes read. Because\n    /// `try_read_vectored()` is non-blocking, the buffer does not have to be\n    /// stored by the async task and can exist entirely on the stack.\n    ///\n    /// Usually, [`readable()`] is used with this function.\n    ///\n    /// [`try_read()`]: Self::try_read()\n    /// [`readable()`]: Self::readable()\n    ///\n    /// # Return\n    ///\n    /// If data is successfully read, `Ok(n)` is returned, where `n` is the\n    /// number of bytes read. `Ok(0)` indicates the pipe's writing end is\n    /// closed and will no longer write data. If the pipe is not ready to read\n    /// data `Err(io::ErrorKind::WouldBlock)` is returned.\n    ///\n    /// # Examples\n    ///\n    /// ```no_run\n    /// use tokio::net::unix::pipe;\n    /// use std::io;\n    ///\n    /// #[tokio::main]\n    /// async fn main() -> io::Result<()> {\n    ///     // Open a reading end of a fifo\n    ///     let rx = pipe::OpenOptions::new().open_receiver(\"path/to/a/fifo\")?;\n    ///\n    ///     loop {\n    ///         // Wait for the pipe to be readable\n    ///         rx.readable().await?;\n    ///\n    ///         // Creating the buffer **after** the `await` prevents it from\n    ///         // being stored in the async task.\n    ///         let mut buf_a = [0; 512];\n    ///         let mut buf_b = [0; 1024];\n    ///         let mut bufs = [\n    ///             io::IoSliceMut::new(&mut buf_a),\n    ///             io::IoSliceMut::new(&mut buf_b),\n    ///         ];\n    ///\n    ///         // Try to read data, this may still fail with `WouldBlock`\n    ///         // if the readiness event is a false positive.\n    ///         match rx.try_read_vectored(&mut bufs) {\n    ///             Ok(0) => break,\n    ///             Ok(n) => {\n    ///                 println!(\"read {} bytes\", n);\n    ///             }\n    ///             Err(e) if e.kind() == io::ErrorKind::WouldBlock => {\n    ///                 continue;\n    ///             }\n    ///             Err(e) => {\n    ///                 return Err(e.into());\n    ///             }\n    ///         }\n    ///     }\n    ///\n    ///     Ok(())\n    /// }\n    /// ```\n    pub fn try_read_vectored(&self, bufs: &mut [io::IoSliceMut<'_>]) -> io::Result<usize> {\n        self.io\n            .registration()\n            .try_io(Interest::READABLE, || (&*self.io).read_vectored(bufs))\n    }\n\n    cfg_io_util! {\n        /// Tries to read data from the pipe into the provided buffer, advancing the\n        /// buffer's internal cursor, returning how many bytes were read.\n        ///\n        /// Reads any pending data from the pipe but does not wait for new data\n        /// to arrive. On success, returns the number of bytes read. Because\n        /// `try_read_buf()` is non-blocking, the buffer does not have to be stored by\n        /// the async task and can exist entirely on the stack.\n        ///\n        /// Usually, [`readable()`] or [`ready()`] is used with this function.\n        ///\n        /// [`readable()`]: Self::readable\n        /// [`ready()`]: Self::ready\n        ///\n        /// # Return\n        ///\n        /// If data is successfully read, `Ok(n)` is returned, where `n` is the\n        /// number of bytes read. `Ok(0)` indicates the pipe's writing end is\n        /// closed and will no longer write data. If the pipe is not ready to read\n        /// data `Err(io::ErrorKind::WouldBlock)` is returned.\n        ///\n        /// # Examples\n        ///\n        /// ```no_run\n        /// use tokio::net::unix::pipe;\n        /// use std::io;\n        ///\n        /// #[tokio::main]\n        /// async fn main() -> io::Result<()> {\n        ///     // Open a reading end of a fifo\n        ///     let rx = pipe::OpenOptions::new().open_receiver(\"path/to/a/fifo\")?;\n        ///\n        ///     loop {\n        ///         // Wait for the pipe to be readable\n        ///         rx.readable().await?;\n        ///\n        ///         let mut buf = Vec::with_capacity(4096);\n        ///\n        ///         // Try to read data, this may still fail with `WouldBlock`\n        ///         // if the readiness event is a false positive.\n        ///         match rx.try_read_buf(&mut buf) {\n        ///             Ok(0) => break,\n        ///             Ok(n) => {\n        ///                 println!(\"read {} bytes\", n);\n        ///             }\n        ///             Err(ref e) if e.kind() == io::ErrorKind::WouldBlock => {\n        ///                 continue;\n        ///             }\n        ///             Err(e) => {\n        ///                 return Err(e.into());\n        ///             }\n        ///         }\n        ///     }\n        ///\n        ///     Ok(())\n        /// }\n        /// ```\n        pub fn try_read_buf<B: BufMut>(&self, buf: &mut B) -> io::Result<usize> {\n            self.io.registration().try_io(Interest::READABLE, || {\n                use std::io::Read;\n\n                let dst = buf.chunk_mut();\n                let dst =\n                    unsafe { &mut *(dst as *mut _ as *mut [std::mem::MaybeUninit<u8>] as *mut [u8]) };\n\n                // Safety: `mio_pipe::Receiver` uses a `std::fs::File` underneath,\n                // which correctly handles reads into uninitialized memory.\n                let n = (&*self.io).read(dst)?;\n\n                unsafe {\n                    buf.advance_mut(n);\n                }\n\n                Ok(n)\n            })\n        }\n    }\n\n    /// Converts the pipe into an [`OwnedFd`] in blocking mode.\n    ///\n    /// This function will deregister this pipe end from the event loop, set\n    /// it in blocking mode and perform the conversion.\n    pub fn into_blocking_fd(self) -> io::Result<OwnedFd> {\n        let fd = self.into_nonblocking_fd()?;\n        set_blocking(&fd)?;\n        Ok(fd)\n    }\n\n    /// Converts the pipe into an [`OwnedFd`] in nonblocking mode.\n    ///\n    /// This function will deregister this pipe end from the event loop and\n    /// perform the conversion. Returned file descriptor will be in nonblocking\n    /// mode.\n    pub fn into_nonblocking_fd(self) -> io::Result<OwnedFd> {\n        let mio_pipe = self.io.into_inner()?;\n\n        // Safety: the pipe is now deregistered from the event loop\n        // and we are the only owner of this pipe end.\n        let owned_fd = unsafe { OwnedFd::from_raw_fd(mio_pipe.into_raw_fd()) };\n\n        Ok(owned_fd)\n    }\n}\n\nimpl AsyncRead for Receiver {\n    fn poll_read(\n        self: Pin<&mut Self>,\n        cx: &mut Context<'_>,\n        buf: &mut ReadBuf<'_>,\n    ) -> Poll<io::Result<()>> {\n        // Safety: `mio_pipe::Receiver` uses a `std::fs::File` underneath,\n        // which correctly handles reads into uninitialized memory.\n        unsafe { self.io.poll_read(cx, buf) }\n    }\n}\n\nimpl AsRawFd for Receiver {\n    fn as_raw_fd(&self) -> RawFd {\n        self.io.as_raw_fd()\n    }\n}\n\nimpl AsFd for Receiver {\n    fn as_fd(&self) -> BorrowedFd<'_> {\n        unsafe { BorrowedFd::borrow_raw(self.as_raw_fd()) }\n    }\n}\n\n/// Checks if the file descriptor is a pipe or a FIFO.\nfn is_pipe(fd: BorrowedFd<'_>) -> io::Result<bool> {\n    // Safety: `libc::stat` is C-like struct used for syscalls and all-zero\n    // byte pattern forms a valid value.\n    let mut stat: libc::stat = unsafe { std::mem::zeroed() };\n\n    // Safety: it's safe to call `fstat` with a valid, open file descriptor\n    // and a valid pointer to a `stat` struct.\n    let r = unsafe { libc::fstat(fd.as_raw_fd(), &mut stat) };\n\n    if r == -1 {\n        Err(io::Error::last_os_error())\n    } else {\n        Ok((stat.st_mode as libc::mode_t & libc::S_IFMT) == libc::S_IFIFO)\n    }\n}\n\n/// Gets file descriptor's flags by fcntl.\nfn get_file_flags(fd: BorrowedFd<'_>) -> io::Result<libc::c_int> {\n    // Safety: it's safe to use `fcntl` to read flags of a valid, open file descriptor.\n    let flags = unsafe { libc::fcntl(fd.as_raw_fd(), libc::F_GETFL) };\n    if flags < 0 {\n        Err(io::Error::last_os_error())\n    } else {\n        Ok(flags)\n    }\n}\n\n/// Checks for `O_RDONLY` or `O_RDWR` access mode.\nfn has_read_access(flags: libc::c_int) -> bool {\n    let mode = flags & libc::O_ACCMODE;\n    mode == libc::O_RDONLY || mode == libc::O_RDWR\n}\n\n/// Checks for `O_WRONLY` or `O_RDWR` access mode.\nfn has_write_access(flags: libc::c_int) -> bool {\n    let mode = flags & libc::O_ACCMODE;\n    mode == libc::O_WRONLY || mode == libc::O_RDWR\n}\n\n/// Sets file descriptor's flags with `O_NONBLOCK` by fcntl.\nfn set_nonblocking(fd: BorrowedFd<'_>, current_flags: libc::c_int) -> io::Result<()> {\n    let flags = current_flags | libc::O_NONBLOCK;\n\n    if flags != current_flags {\n        // Safety: it's safe to use `fcntl` to set the `O_NONBLOCK` flag of a valid,\n        // open file descriptor.\n        let ret = unsafe { libc::fcntl(fd.as_raw_fd(), libc::F_SETFL, flags) };\n        if ret < 0 {\n            return Err(io::Error::last_os_error());\n        }\n    }\n\n    Ok(())\n}\n\n/// Removes `O_NONBLOCK` from fd's flags.\nfn set_blocking<T: AsRawFd>(fd: &T) -> io::Result<()> {\n    // Safety: it's safe to use `fcntl` to read flags of a valid, open file descriptor.\n    let previous = unsafe { libc::fcntl(fd.as_raw_fd(), libc::F_GETFL) };\n    if previous == -1 {\n        return Err(io::Error::last_os_error());\n    }\n\n    let new = previous & !libc::O_NONBLOCK;\n\n    // Safety: it's safe to use `fcntl` to unset the `O_NONBLOCK` flag of a valid,\n    // open file descriptor.\n    let r = unsafe { libc::fcntl(fd.as_raw_fd(), libc::F_SETFL, new) };\n    if r == -1 {\n        Err(io::Error::last_os_error())\n    } else {\n        Ok(())\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "fc8ad51b7f1b859387e029fff2e34dee7a58b814",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tokio/tokio/src/macros/try_join.rs",
    "func": "macro_rules! doc {\n    ($try_join:item) => {\n        /// Waits on multiple concurrent branches, returning when **all** branches\n        /// complete with `Ok(_)` or on the first `Err(_)`.\n        ///\n        /// The `try_join!` macro must be used inside of async functions, closures, and\n        /// blocks.\n        ///\n        /// Similar to [`join!`], the `try_join!` macro takes a list of async\n        /// expressions and evaluates them concurrently on the same task. Each async\n        /// expression evaluates to a future and the futures from each expression are\n        /// multiplexed on the current task. The `try_join!` macro returns when **all**\n        /// branches return with `Ok` or when the **first** branch returns with `Err`.\n        ///\n        /// [`join!`]: macro@join\n        ///\n        /// # Notes\n        ///\n        /// The supplied futures are stored inline and do not require allocating a\n        /// `Vec`.\n        ///\n        /// ### Runtime characteristics\n        ///\n        /// By running all async expressions on the current task, the expressions are\n        /// able to run **concurrently** but not in **parallel**. This means all\n        /// expressions are run on the same thread and if one branch blocks the thread,\n        /// all other expressions will be unable to continue. If parallelism is\n        /// required, spawn each async expression using [`tokio::spawn`] and pass the\n        /// join handle to `try_join!`.\n        ///\n        /// [`tokio::spawn`]: crate::spawn\n        ///\n        /// # Examples\n        ///\n        /// Basic `try_join` with two branches.\n        ///\n        /// ```\n        /// async fn do_stuff_async() -> Result<(), &'static str> {\n        ///     // async work\n        /// # Ok(())\n        /// }\n        ///\n        /// async fn more_async_work() -> Result<(), &'static str> {\n        ///     // more here\n        /// # Ok(())\n        /// }\n        ///\n        /// #[tokio::main]\n        /// async fn main() {\n        ///     let res = tokio::try_join!(\n        ///         do_stuff_async(),\n        ///         more_async_work());\n        ///\n        ///     match res {\n        ///          Ok((first, second)) => {\n        ///              // do something with the values\n        ///          }\n        ///          Err(err) => {\n        ///             println!(\"processing failed; error = {}\", err);\n        ///          }\n        ///     }\n        /// }\n        /// ```\n        ///\n        /// Using `try_join!` with spawned tasks.\n        ///\n        /// ```\n        /// use tokio::task::JoinHandle;\n        ///\n        /// async fn do_stuff_async() -> Result<(), &'static str> {\n        ///     // async work\n        /// # Err(\"failed\")\n        /// }\n        ///\n        /// async fn more_async_work() -> Result<(), &'static str> {\n        ///     // more here\n        /// # Ok(())\n        /// }\n        ///\n        /// async fn flatten<T>(handle: JoinHandle<Result<T, &'static str>>) -> Result<T, &'static str> {\n        ///     match handle.await {\n        ///         Ok(Ok(result)) => Ok(result),\n        ///         Ok(Err(err)) => Err(err),\n        ///         Err(err) => Err(\"handling failed\"),\n        ///     }\n        /// }\n        ///\n        /// #[tokio::main]\n        /// async fn main() {\n        ///     let handle1 = tokio::spawn(do_stuff_async());\n        ///     let handle2 = tokio::spawn(more_async_work());\n        ///     match tokio::try_join!(flatten(handle1), flatten(handle2)) {\n        ///         Ok(val) => {\n        ///             // do something with the values\n        ///         }\n        ///         Err(err) => {\n        ///             println!(\"Failed with {}.\", err);\n        ///             # assert_eq!(err, \"failed\");\n        ///         }\n        ///     }\n        /// }\n        /// ```\n        #[macro_export]\n        #[cfg_attr(docsrs, doc(cfg(feature = \"macros\")))]\n        $try_join\n    };\n}\n\n#[cfg(doc)]\ndoc! {macro_rules! try_join {\n    ($($future:expr),*) => { unimplemented!() }\n}}\n\n#[cfg(not(doc))]\ndoc! {macro_rules! try_join {\n    (@ {\n        // One `_` for each branch in the `try_join!` macro. This is not used once\n        // normalization is complete.\n        ( $($count:tt)* )\n\n        // The expression `0+1+1+ ... +1` equal to the number of branches.\n        ( $($total:tt)* )\n\n        // Normalized try_join! branches\n        $( ( $($skip:tt)* ) $e:expr, )*\n\n    }) => {{\n        use $crate::macros::support::{maybe_done, poll_fn, Future, Pin};\n        use $crate::macros::support::Poll::{Ready, Pending};\n\n        // Safety: nothing must be moved out of `futures`. This is to satisfy\n        // the requirement of `Pin::new_unchecked` called below.\n        //\n        // We can't use the `pin!` macro for this because `futures` is a tuple\n        // and the standard library provides no way to pin-project to the fields\n        // of a tuple.\n        let mut futures = ( $( maybe_done($e), )* );\n\n        // This assignment makes sure that the `poll_fn` closure only has a\n        // reference to the futures, instead of taking ownership of them. This\n        // mitigates the issue described in\n        // <https://internals.rust-lang.org/t/surprising-soundness-trouble-around-pollfn/17484>\n        let mut futures = &mut futures;\n\n        // Each time the future created by poll_fn is polled, a different future will be polled first\n        // to ensure every future passed to join! gets a chance to make progress even if\n        // one of the futures consumes the whole budget.\n        //\n        // This is number of futures that will be skipped in the first loop\n        // iteration the next time.\n        let mut skip_next_time: u32 = 0;\n\n        poll_fn(move |cx| {\n            const COUNT: u32 = $($total)*;\n\n            let mut is_pending = false;\n\n            let mut to_run = COUNT;\n\n            // The number of futures that will be skipped in the first loop iteration\n            let mut skip = skip_next_time;\n\n            skip_next_time = if skip + 1 == COUNT { 0 } else { skip + 1 };\n\n            // This loop runs twice and the first `skip` futures\n            // are not polled in the first iteration.\n            loop {\n            $(\n                if skip == 0 {\n                    if to_run == 0 {\n                        // Every future has been polled\n                        break;\n                    }\n                    to_run -= 1;\n\n                    // Extract the future for this branch from the tuple.\n                    let ( $($skip,)* fut, .. ) = &mut *futures;\n\n                    // Safety: future is stored on the stack above\n                    // and never moved.\n                    let mut fut = unsafe { Pin::new_unchecked(fut) };\n\n                    // Try polling\n                    if fut.as_mut().poll(cx).is_pending() {\n                        is_pending = true;\n                    } else if fut.as_mut().output_mut().expect(\"expected completed future\").is_err() {\n                        return Ready(Err(fut.take_output().expect(\"expected completed future\").err().unwrap()))\n                    }\n                } else {\n                    // Future skipped, one less future to skip in the next iteration\n                    skip -= 1;\n                }\n            )*\n            }\n\n            if is_pending {\n                Pending\n            } else {\n                Ready(Ok(($({\n                    // Extract the future for this branch from the tuple.\n                    let ( $($skip,)* fut, .. ) = &mut futures;\n\n                    // Safety: future is stored on the stack above\n                    // and never moved.\n                    let mut fut = unsafe { Pin::new_unchecked(fut) };\n\n                    fut\n                        .take_output()\n                        .expect(\"expected completed future\")\n                        .ok()\n                        .expect(\"expected Ok(_)\")\n                },)*)))\n            }\n        }).await\n    }};\n\n    // ===== Normalize =====\n\n    (@ { ( $($s:tt)* ) ( $($n:tt)* ) $($t:tt)* } $e:expr, $($r:tt)* ) => {\n      $crate::try_join!(@{ ($($s)* _) ($($n)* + 1) $($t)* ($($s)*) $e, } $($r)*)\n    };\n\n    // ===== Entry point =====\n\n    ( $($e:expr),+ $(,)?) => {\n        $crate::try_join!(@{ () (0) } $($e,)*)\n    };\n\n    () => { async { Ok(()) }.await }\n}}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "d64c8d698eebb47efc7748d2725c126496bcbb20",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tokio/tokio-stream/tests/stream_once.rs",
    "func": "use tokio_stream::{self as stream, Stream, StreamExt};\n\n#[tokio::test]\nasync fn basic_usage() {\n    let mut one = stream::once(1);\n\n    assert_eq!(one.size_hint(), (1, Some(1)));\n    assert_eq!(Some(1), one.next().await);\n\n    assert_eq!(one.size_hint(), (0, Some(0)));\n    assert_eq!(None, one.next().await);\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "961f1f8e35e8b31bfa1a64e39af920c556924f83",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tokio/tokio-stream/src/stream_ext/all.rs",
    "func": "use crate::Stream;\n\nuse core::future::Future;\nuse core::marker::PhantomPinned;\nuse core::pin::Pin;\nuse core::task::{ready, Context, Poll};\nuse pin_project_lite::pin_project;\n\npin_project! {\n    /// Future for the [`all`](super::StreamExt::all) method.\n    #[derive(Debug)]\n    #[must_use = \"futures do nothing unless you `.await` or poll them\"]\n    pub struct AllFuture<'a, St: ?Sized, F> {\n        stream: &'a mut St,\n        f: F,\n        // Make this future `!Unpin` for compatibility with async trait methods.\n        #[pin]\n        _pin: PhantomPinned,\n    }\n}\n\nimpl<'a, St: ?Sized, F> AllFuture<'a, St, F> {\n    pub(super) fn new(stream: &'a mut St, f: F) -> Self {\n        Self {\n            stream,\n            f,\n            _pin: PhantomPinned,\n        }\n    }\n}\n\nimpl<St, F> Future for AllFuture<'_, St, F>\nwhere\n    St: ?Sized + Stream + Unpin,\n    F: FnMut(St::Item) -> bool,\n{\n    type Output = bool;\n\n    fn poll(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> {\n        let me = self.project();\n        let mut stream = Pin::new(me.stream);\n\n        // Take a maximum of 32 items from the stream before yielding.\n        for _ in 0..32 {\n            match ready!(stream.as_mut().poll_next(cx)) {\n                Some(v) => {\n                    if !(me.f)(v) {\n                        return Poll::Ready(false);\n                    }\n                }\n                None => return Poll::Ready(true),\n            }\n        }\n\n        cx.waker().wake_by_ref();\n        Poll::Pending\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "3d1d87d72cfd27e524cec8745e25187eccd54449",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tokio/tokio-test/tests/task.rs",
    "func": "use std::pin::Pin;\nuse std::task::{Context, Poll};\nuse tokio_stream::Stream;\nuse tokio_test::task;\n\n/// A [`Stream`] that has a stub size hint.\nstruct SizedStream;\n\nimpl Stream for SizedStream {\n    type Item = ();\n\n    fn poll_next(self: Pin<&mut Self>, _cx: &mut Context<'_>) -> Poll<Option<Self::Item>> {\n        Poll::Pending\n    }\n\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        (100, Some(200))\n    }\n}\n\n#[test]\nfn test_spawn_stream_size_hint() {\n    let spawn = task::spawn(SizedStream);\n    assert_eq!(spawn.size_hint(), (100, Some(200)));\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "2e468c56b3ae5851f3c3b07640bf495af0fe5dc2",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/ripgrep/crates/searcher/examples/search-stdin.rs",
    "func": "use std::env;\nuse std::error::Error;\nuse std::io;\nuse std::process;\n\nuse grep_regex::RegexMatcher;\nuse grep_searcher::sinks::UTF8;\nuse grep_searcher::Searcher;\n\nfn main() {\n    if let Err(err) = example() {\n        eprintln!(\"{}\", err);\n        process::exit(1);\n    }\n}\n\nfn example() -> Result<(), Box<dyn Error>> {\n    let pattern = match env::args().nth(1) {\n        Some(pattern) => pattern,\n        None => {\n            return Err(From::from(format!(\"Usage: search-stdin <pattern>\")))\n        }\n    };\n    let matcher = RegexMatcher::new(&pattern)?;\n    Searcher::new().search_reader(\n        &matcher,\n        io::stdin(),\n        UTF8(|lnum, line| {\n            print!(\"{}:{}\", lnum, line);\n            Ok(true)\n        }),\n    )?;\n    Ok(())\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "35a3f05b8acbfcf693c4544b55e78efbc332e780",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/ripgrep/crates/searcher/src/macros.rs",
    "func": "/// Like assert_eq, but nicer output for long strings.\n#[cfg(test)]\n#[macro_export]\nmacro_rules! assert_eq_printed {\n    ($expected:expr, $got:expr, $($tt:tt)*) => {\n        let expected = &*$expected;\n        let got = &*$got;\n        let label = format!($($tt)*);\n        if expected != got {\n            panic!(\"\nprinted outputs differ! (label: {})\n\nexpected:\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n{}\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\ngot:\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n{}\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\", label, expected, got);\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "7306bed762013c87357eaaaa3d8a87fa88b30603",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/ripgrep/crates/printer/src/standard.rs",
    "func": "use std::{\n    cell::{Cell, RefCell},\n    cmp,\n    io::{self, Write},\n    path::Path,\n    sync::Arc,\n    time::Instant,\n};\n\nuse {\n    bstr::ByteSlice,\n    grep_matcher::{Match, Matcher},\n    grep_searcher::{\n        LineStep, Searcher, Sink, SinkContext, SinkContextKind, SinkFinish,\n        SinkMatch,\n    },\n    termcolor::{ColorSpec, NoColor, WriteColor},\n};\n\nuse crate::{\n    color::ColorSpecs,\n    counter::CounterWriter,\n    hyperlink::{self, HyperlinkConfig},\n    stats::Stats,\n    util::{\n        find_iter_at_in_context, trim_ascii_prefix, trim_line_terminator,\n        DecimalFormatter, PrinterPath, Replacer, Sunk,\n    },\n};\n\n/// The configuration for the standard printer.\n///\n/// This is manipulated by the StandardBuilder and then referenced by the\n/// actual implementation. Once a printer is build, the configuration is frozen\n/// and cannot changed.\n#[derive(Debug, Clone)]\nstruct Config {\n    colors: ColorSpecs,\n    hyperlink: HyperlinkConfig,\n    stats: bool,\n    heading: bool,\n    path: bool,\n    only_matching: bool,\n    per_match: bool,\n    per_match_one_line: bool,\n    replacement: Arc<Option<Vec<u8>>>,\n    max_columns: Option<u64>,\n    max_columns_preview: bool,\n    max_matches: Option<u64>,\n    column: bool,\n    byte_offset: bool,\n    trim_ascii: bool,\n    separator_search: Arc<Option<Vec<u8>>>,\n    separator_context: Arc<Option<Vec<u8>>>,\n    separator_field_match: Arc<Vec<u8>>,\n    separator_field_context: Arc<Vec<u8>>,\n    separator_path: Option<u8>,\n    path_terminator: Option<u8>,\n}\n\nimpl Default for Config {\n    fn default() -> Config {\n        Config {\n            colors: ColorSpecs::default(),\n            hyperlink: HyperlinkConfig::default(),\n            stats: false,\n            heading: false,\n            path: true,\n            only_matching: false,\n            per_match: false,\n            per_match_one_line: false,\n            replacement: Arc::new(None),\n            max_columns: None,\n            max_columns_preview: false,\n            max_matches: None,\n            column: false,\n            byte_offset: false,\n            trim_ascii: false,\n            separator_search: Arc::new(None),\n            separator_context: Arc::new(Some(b\"--\".to_vec())),\n            separator_field_match: Arc::new(b\":\".to_vec()),\n            separator_field_context: Arc::new(b\"-\".to_vec()),\n            separator_path: None,\n            path_terminator: None,\n        }\n    }\n}\n\n/// A builder for the \"standard\" grep-like printer.\n///\n/// The builder permits configuring how the printer behaves. Configurable\n/// behavior includes, but is not limited to, limiting the number of matches,\n/// tweaking separators, executing pattern replacements, recording statistics\n/// and setting colors.\n///\n/// Some configuration options, such as the display of line numbers or\n/// contextual lines, are drawn directly from the\n/// `grep_searcher::Searcher`'s configuration.\n///\n/// Once a `Standard` printer is built, its configuration cannot be changed.\n#[derive(Clone, Debug)]\npub struct StandardBuilder {\n    config: Config,\n}\n\nimpl StandardBuilder {\n    /// Return a new builder for configuring the standard printer.\n    pub fn new() -> StandardBuilder {\n        StandardBuilder { config: Config::default() }\n    }\n\n    /// Build a printer using any implementation of `termcolor::WriteColor`.\n    ///\n    /// The implementation of `WriteColor` used here controls whether colors\n    /// are used or not when colors have been configured using the\n    /// `color_specs` method.\n    ///\n    /// For maximum portability, callers should generally use either\n    /// `termcolor::StandardStream` or `termcolor::BufferedStandardStream`\n    /// where appropriate, which will automatically enable colors on Windows\n    /// when possible.\n    ///\n    /// However, callers may also provide an arbitrary writer using the\n    /// `termcolor::Ansi` or `termcolor::NoColor` wrappers, which always enable\n    /// colors via ANSI escapes or always disable colors, respectively.\n    ///\n    /// As a convenience, callers may use `build_no_color` to automatically\n    /// select the `termcolor::NoColor` wrapper to avoid needing to import\n    /// from `termcolor` explicitly.\n    pub fn build<W: WriteColor>(&self, wtr: W) -> Standard<W> {\n        Standard {\n            config: self.config.clone(),\n            wtr: RefCell::new(CounterWriter::new(wtr)),\n            matches: vec![],\n        }\n    }\n\n    /// Build a printer from any implementation of `io::Write` and never emit\n    /// any colors, regardless of the user color specification settings.\n    ///\n    /// This is a convenience routine for\n    /// `StandardBuilder::build(termcolor::NoColor::new(wtr))`.\n    pub fn build_no_color<W: io::Write>(\n        &self,\n        wtr: W,\n    ) -> Standard<NoColor<W>> {\n        self.build(NoColor::new(wtr))\n    }\n\n    /// Set the user color specifications to use for coloring in this printer.\n    ///\n    /// A [`UserColorSpec`](crate::UserColorSpec) can be constructed from\n    /// a string in accordance with the color specification format. See\n    /// the `UserColorSpec` type documentation for more details on the\n    /// format. A [`ColorSpecs`] can then be generated from zero or more\n    /// `UserColorSpec`s.\n    ///\n    /// Regardless of the color specifications provided here, whether color\n    /// is actually used or not is determined by the implementation of\n    /// `WriteColor` provided to `build`. For example, if `termcolor::NoColor`\n    /// is provided to `build`, then no color will ever be printed regardless\n    /// of the color specifications provided here.\n    ///\n    /// This completely overrides any previous color specifications. This does\n    /// not add to any previously provided color specifications on this\n    /// builder.\n    pub fn color_specs(&mut self, specs: ColorSpecs) -> &mut StandardBuilder {\n        self.config.colors = specs;\n        self\n    }\n\n    /// Set the configuration to use for hyperlinks output by this printer.\n    ///\n    /// Regardless of the hyperlink format provided here, whether hyperlinks\n    /// are actually used or not is determined by the implementation of\n    /// `WriteColor` provided to `build`. For example, if `termcolor::NoColor`\n    /// is provided to `build`, then no hyperlinks will ever be printed\n    /// regardless of the format provided here.\n    ///\n    /// This completely overrides any previous hyperlink format.\n    ///\n    /// The default configuration results in not emitting any hyperlinks.\n    pub fn hyperlink(\n        &mut self,\n        config: HyperlinkConfig,\n    ) -> &mut StandardBuilder {\n        self.config.hyperlink = config;\n        self\n    }\n\n    /// Enable the gathering of various aggregate statistics.\n    ///\n    /// When this is enabled (it's disabled by default), statistics will be\n    /// gathered for all uses of `Standard` printer returned by `build`,\n    /// including but not limited to, the total number of matches, the total\n    /// number of bytes searched and the total number of bytes printed.\n    ///\n    /// Aggregate statistics can be accessed via the sink's\n    /// [`StandardSink::stats`] method.\n    ///\n    /// When this is enabled, this printer may need to do extra work in order\n    /// to compute certain statistics, which could cause the search to take\n    /// longer.\n    ///\n    /// For a complete description of available statistics, see [`Stats`].\n    pub fn stats(&mut self, yes: bool) -> &mut StandardBuilder {\n        self.config.stats = yes;\n        self\n    }\n\n    /// Enable the use of \"headings\" in the printer.\n    ///\n    /// When this is enabled, and if a file path has been given to the printer,\n    /// then the file path will be printed once on its own line before showing\n    /// any matches. If the heading is not the first thing emitted by the\n    /// printer, then a line terminator is printed before the heading.\n    ///\n    /// By default, this option is disabled. When disabled, the printer will\n    /// not show any heading and will instead print the file path (if one is\n    /// given) on the same line as each matching (or context) line.\n    pub fn heading(&mut self, yes: bool) -> &mut StandardBuilder {\n        self.config.heading = yes;\n        self\n    }\n\n    /// When enabled, if a path was given to the printer, then it is shown in\n    /// the output (either as a heading or as a prefix to each matching line).\n    /// When disabled, then no paths are ever included in the output even when\n    /// a path is provided to the printer.\n    ///\n    /// This is enabled by default.\n    pub fn path(&mut self, yes: bool) -> &mut StandardBuilder {\n        self.config.path = yes;\n        self\n    }\n\n    /// Only print the specific matches instead of the entire line containing\n    /// each match. Each match is printed on its own line. When multi line\n    /// search is enabled, then matches spanning multiple lines are printed\n    /// such that only the matching portions of each line are shown.\n    pub fn only_matching(&mut self, yes: bool) -> &mut StandardBuilder {\n        self.config.only_matching = yes;\n        self\n    }\n\n    /// Print at least one line for every match.\n    ///\n    /// This is similar to the `only_matching` option, except the entire line\n    /// is printed for each match. This is typically useful in conjunction with\n    /// the `column` option, which will show the starting column number for\n    /// every match on every line.\n    ///\n    /// When multi-line mode is enabled, each match is printed, including every\n    /// line in the match. As with single line matches, if a line contains\n    /// multiple matches (even if only partially), then that line is printed\n    /// once for each match it participates in, assuming it's the first line in\n    /// that match. In multi-line mode, column numbers only indicate the start\n    /// of a match. Subsequent lines in a multi-line match always have a column\n    /// number of `1`.\n    ///\n    /// When a match contains multiple lines, enabling `per_match_one_line`\n    /// will cause only the first line each in match to be printed.\n    pub fn per_match(&mut self, yes: bool) -> &mut StandardBuilder {\n        self.config.per_match = yes;\n        self\n    }\n\n    /// Print at most one line per match when `per_match` is enabled.\n    ///\n    /// By default, every line in each match found is printed when `per_match`\n    /// is enabled. However, this is sometimes undesirable, e.g., when you\n    /// only ever want one line per match.\n    ///\n    /// This is only applicable when multi-line matching is enabled, since\n    /// otherwise, matches are guaranteed to span one line.\n    ///\n    /// This is disabled by default.\n    pub fn per_match_one_line(&mut self, yes: bool) -> &mut StandardBuilder {\n        self.config.per_match_one_line = yes;\n        self\n    }\n\n    /// Set the bytes that will be used to replace each occurrence of a match\n    /// found.\n    ///\n    /// The replacement bytes given may include references to capturing groups,\n    /// which may either be in index form (e.g., `$2`) or can reference named\n    /// capturing groups if present in the original pattern (e.g., `$foo`).\n    ///\n    /// For documentation on the full format, please see the `Capture` trait's\n    /// `interpolate` method in the\n    /// [grep-printer](https://docs.rs/grep-printer) crate.\n    pub fn replacement(\n        &mut self,\n        replacement: Option<Vec<u8>>,\n    ) -> &mut StandardBuilder {\n        self.config.replacement = Arc::new(replacement);\n        self\n    }\n\n    /// Set the maximum number of columns allowed for each line printed. A\n    /// single column is heuristically defined as a single byte.\n    ///\n    /// If a line is found which exceeds this maximum, then it is replaced\n    /// with a message indicating that the line has been omitted.\n    ///\n    /// The default is to not specify a limit, in which each matching or\n    /// contextual line is printed regardless of how long it is.\n    pub fn max_columns(&mut self, limit: Option<u64>) -> &mut StandardBuilder {\n        self.config.max_columns = limit;\n        self\n    }\n\n    /// When enabled, if a line is found to be over the configured maximum\n    /// column limit (measured in terms of bytes), then a preview of the long\n    /// line will be printed instead.\n    ///\n    /// The preview will correspond to the first `N` *grapheme clusters* of\n    /// the line, where `N` is the limit configured by `max_columns`.\n    ///\n    /// If no limit is set, then enabling this has no effect.\n    ///\n    /// This is disabled by default.\n    pub fn max_columns_preview(&mut self, yes: bool) -> &mut StandardBuilder {\n        self.config.max_columns_preview = yes;\n        self\n    }\n\n    /// Set the maximum amount of matching lines that are printed.\n    ///\n    /// If multi line search is enabled and a match spans multiple lines, then\n    /// that match is counted exactly once for the purposes of enforcing this\n    /// limit, regardless of how many lines it spans.\n    pub fn max_matches(&mut self, limit: Option<u64>) -> &mut StandardBuilder {\n        self.config.max_matches = limit;\n        self\n    }\n\n    /// Print the column number of the first match in a line.\n    ///\n    /// This option is convenient for use with `per_match` which will print a\n    /// line for every match along with the starting offset for that match.\n    ///\n    /// Column numbers are computed in terms of bytes from the start of the\n    /// line being printed.\n    ///\n    /// This is disabled by default.\n    pub fn column(&mut self, yes: bool) -> &mut StandardBuilder {\n        self.config.column = yes;\n        self\n    }\n\n    /// Print the absolute byte offset of the beginning of each line printed.\n    ///\n    /// The absolute byte offset starts from the beginning of each search and\n    /// is zero based.\n    ///\n    /// If the `only_matching` option is set, then this will print the absolute\n    /// byte offset of the beginning of each match.\n    pub fn byte_offset(&mut self, yes: bool) -> &mut StandardBuilder {\n        self.config.byte_offset = yes;\n        self\n    }\n\n    /// When enabled, all lines will have prefix ASCII whitespace trimmed\n    /// before being written.\n    ///\n    /// This is disabled by default.\n    pub fn trim_ascii(&mut self, yes: bool) -> &mut StandardBuilder {\n        self.config.trim_ascii = yes;\n        self\n    }\n\n    /// Set the separator used between sets of search results.\n    ///\n    /// When this is set, then it will be printed on its own line immediately\n    /// before the results for a single search if and only if a previous search\n    /// had already printed results. In effect, this permits showing a divider\n    /// between sets of search results that does not appear at the beginning\n    /// or end of all search results.\n    ///\n    /// To reproduce the classic grep format, this is typically set to `--`\n    /// (the same as the context separator) if and only if contextual lines\n    /// have been requested, but disabled otherwise.\n    ///\n    /// By default, this is disabled.\n    pub fn separator_search(\n        &mut self,\n        sep: Option<Vec<u8>>,\n    ) -> &mut StandardBuilder {\n        self.config.separator_search = Arc::new(sep);\n        self\n    }\n\n    /// Set the separator used between discontiguous runs of search context,\n    /// but only when the searcher is configured to report contextual lines.\n    ///\n    /// The separator is always printed on its own line, even if it's empty.\n    ///\n    /// If no separator is set, then nothing is printed when a context break\n    /// occurs.\n    ///\n    /// By default, this is set to `--`.\n    pub fn separator_context(\n        &mut self,\n        sep: Option<Vec<u8>>,\n    ) -> &mut StandardBuilder {\n        self.config.separator_context = Arc::new(sep);\n        self\n    }\n\n    /// Set the separator used between fields emitted for matching lines.\n    ///\n    /// For example, when the searcher has line numbers enabled, this printer\n    /// will print the line number before each matching line. The bytes given\n    /// here will be written after the line number but before the matching\n    /// line.\n    ///\n    /// By default, this is set to `:`.\n    pub fn separator_field_match(\n        &mut self,\n        sep: Vec<u8>,\n    ) -> &mut StandardBuilder {\n        self.config.separator_field_match = Arc::new(sep);\n        self\n    }\n\n    /// Set the separator used between fields emitted for context lines.\n    ///\n    /// For example, when the searcher has line numbers enabled, this printer\n    /// will print the line number before each context line. The bytes given\n    /// here will be written after the line number but before the context\n    /// line.\n    ///\n    /// By default, this is set to `-`.\n    pub fn separator_field_context(\n        &mut self,\n        sep: Vec<u8>,\n    ) -> &mut StandardBuilder {\n        self.config.separator_field_context = Arc::new(sep);\n        self\n    }\n\n    /// Set the path separator used when printing file paths.\n    ///\n    /// When a printer is configured with a file path, and when a match is\n    /// found, that file path will be printed (either as a heading or as a\n    /// prefix to each matching or contextual line, depending on other\n    /// configuration settings). Typically, printing is done by emitting the\n    /// file path as is. However, this setting provides the ability to use a\n    /// different path separator from what the current environment has\n    /// configured.\n    ///\n    /// A typical use for this option is to permit cygwin users on Windows to\n    /// set the path separator to `/` instead of using the system default of\n    /// `\\`.\n    pub fn separator_path(&mut self, sep: Option<u8>) -> &mut StandardBuilder {\n        self.config.separator_path = sep;\n        self\n    }\n\n    /// Set the path terminator used.\n    ///\n    /// The path terminator is a byte that is printed after every file path\n    /// emitted by this printer.\n    ///\n    /// If no path terminator is set (the default), then paths are terminated\n    /// by either new lines (for when `heading` is enabled) or the match or\n    /// context field separators (e.g., `:` or `-`).\n    pub fn path_terminator(\n        &mut self,\n        terminator: Option<u8>,\n    ) -> &mut StandardBuilder {\n        self.config.path_terminator = terminator;\n        self\n    }\n}\n\n/// The standard printer, which implements grep-like formatting, including\n/// color support.\n///\n/// A default printer can be created with either of the `Standard::new` or\n/// `Standard::new_no_color` constructors. However, there are a considerable\n/// number of options that configure this printer's output. Those options can\n/// be configured using [`StandardBuilder`].\n///\n/// This type is generic over `W`, which represents any implementation\n/// of the `termcolor::WriteColor` trait. If colors are not desired,\n/// then the `new_no_color` constructor can be used, or, alternatively,\n/// the `termcolor::NoColor` adapter can be used to wrap any `io::Write`\n/// implementation without enabling any colors.\n#[derive(Clone, Debug)]\npub struct Standard<W> {\n    config: Config,\n    wtr: RefCell<CounterWriter<W>>,\n    matches: Vec<Match>,\n}\n\nimpl<W: WriteColor> Standard<W> {\n    /// Return a standard printer with a default configuration that writes\n    /// matches to the given writer.\n    ///\n    /// The writer should be an implementation of `termcolor::WriteColor`\n    /// and not just a bare implementation of `io::Write`. To use a normal\n    /// `io::Write` implementation (simultaneously sacrificing colors), use\n    /// the `new_no_color` constructor.\n    pub fn new(wtr: W) -> Standard<W> {\n        StandardBuilder::new().build(wtr)\n    }\n}\n\nimpl<W: io::Write> Standard<NoColor<W>> {\n    /// Return a standard printer with a default configuration that writes\n    /// matches to the given writer.\n    ///\n    /// The writer can be any implementation of `io::Write`. With this\n    /// constructor, the printer will never emit colors.\n    pub fn new_no_color(wtr: W) -> Standard<NoColor<W>> {\n        StandardBuilder::new().build_no_color(wtr)\n    }\n}\n\nimpl<W: WriteColor> Standard<W> {\n    /// Return an implementation of `Sink` for the standard printer.\n    ///\n    /// This does not associate the printer with a file path, which means this\n    /// implementation will never print a file path along with the matches.\n    pub fn sink<'s, M: Matcher>(\n        &'s mut self,\n        matcher: M,\n    ) -> StandardSink<'static, 's, M, W> {\n        let interpolator =\n            hyperlink::Interpolator::new(&self.config.hyperlink);\n        let stats = if self.config.stats { Some(Stats::new()) } else { None };\n        let needs_match_granularity = self.needs_match_granularity();\n        StandardSink {\n            matcher,\n            standard: self,\n            replacer: Replacer::new(),\n            interpolator,\n            path: None,\n            start_time: Instant::now(),\n            match_count: 0,\n            after_context_remaining: 0,\n            binary_byte_offset: None,\n            stats,\n            needs_match_granularity,\n        }\n    }\n\n    /// Return an implementation of `Sink` associated with a file path.\n    ///\n    /// When the printer is associated with a path, then it may, depending on\n    /// its configuration, print the path along with the matches found.\n    pub fn sink_with_path<'p, 's, M, P>(\n        &'s mut self,\n        matcher: M,\n        path: &'p P,\n    ) -> StandardSink<'p, 's, M, W>\n    where\n        M: Matcher,\n        P: ?Sized + AsRef<Path>,\n    {\n        if !self.config.path {\n            return self.sink(matcher);\n        }\n        let interpolator =\n            hyperlink::Interpolator::new(&self.config.hyperlink);\n        let stats = if self.config.stats { Some(Stats::new()) } else { None };\n        let ppath = PrinterPath::new(path.as_ref())\n            .with_separator(self.config.separator_path);\n        let needs_match_granularity = self.needs_match_granularity();\n        StandardSink {\n            matcher,\n            standard: self,\n            replacer: Replacer::new(),\n            interpolator,\n            path: Some(ppath),\n            start_time: Instant::now(),\n            match_count: 0,\n            after_context_remaining: 0,\n            binary_byte_offset: None,\n            stats,\n            needs_match_granularity,\n        }\n    }\n\n    /// Returns true if and only if the configuration of the printer requires\n    /// us to find each individual match in the lines reported by the searcher.\n    ///\n    /// We care about this distinction because finding each individual match\n    /// costs more, so we only do it when we need to.\n    fn needs_match_granularity(&self) -> bool {\n        let supports_color = self.wtr.borrow().supports_color();\n        let match_colored = !self.config.colors.matched().is_none();\n\n        // Coloring requires identifying each individual match.\n        (supports_color && match_colored)\n        // The column feature requires finding the position of the first match.\n        || self.config.column\n        // Requires finding each match for performing replacement.\n        || self.config.replacement.is_some()\n        // Emitting a line for each match requires finding each match.\n        || self.config.per_match\n        // Emitting only the match requires finding each match.\n        || self.config.only_matching\n        // Computing certain statistics requires finding each match.\n        || self.config.stats\n    }\n}\n\nimpl<W> Standard<W> {\n    /// Returns true if and only if this printer has written at least one byte\n    /// to the underlying writer during any of the previous searches.\n    pub fn has_written(&self) -> bool {\n        self.wtr.borrow().total_count() > 0\n    }\n\n    /// Return a mutable reference to the underlying writer.\n    pub fn get_mut(&mut self) -> &mut W {\n        self.wtr.get_mut().get_mut()\n    }\n\n    /// Consume this printer and return back ownership of the underlying\n    /// writer.\n    pub fn into_inner(self) -> W {\n        self.wtr.into_inner().into_inner()\n    }\n}\n\n/// An implementation of `Sink` associated with a matcher and an optional file\n/// path for the standard printer.\n///\n/// A `Sink` can be created via the [`Standard::sink`] or\n/// [`Standard::sink_with_path`] methods, depending on whether you want to\n/// include a file path in the printer's output.\n///\n/// Building a `StandardSink` is cheap, and callers should create a new one\n/// for each thing that is searched. After a search has completed, callers may\n/// query this sink for information such as whether a match occurred or whether\n/// binary data was found (and if so, the offset at which it occurred).\n///\n/// This type is generic over a few type parameters:\n///\n/// * `'p` refers to the lifetime of the file path, if one is provided. When\n/// no file path is given, then this is `'static`.\n/// * `'s` refers to the lifetime of the [`Standard`] printer that this type\n/// borrows.\n/// * `M` refers to the type of matcher used by\n/// `grep_searcher::Searcher` that is reporting results to this sink.\n/// * `W` refers to the underlying writer that this printer is writing its\n/// output to.\n#[derive(Debug)]\npub struct StandardSink<'p, 's, M: Matcher, W> {\n    matcher: M,\n    standard: &'s mut Standard<W>,\n    replacer: Replacer<M>,\n    interpolator: hyperlink::Interpolator,\n    path: Option<PrinterPath<'p>>,\n    start_time: Instant,\n    match_count: u64,\n    after_context_remaining: u64,\n    binary_byte_offset: Option<u64>,\n    stats: Option<Stats>,\n    needs_match_granularity: bool,\n}\n\nimpl<'p, 's, M: Matcher, W: WriteColor> StandardSink<'p, 's, M, W> {\n    /// Returns true if and only if this printer received a match in the\n    /// previous search.\n    ///\n    /// This is unaffected by the result of searches before the previous\n    /// search on this sink.\n    pub fn has_match(&self) -> bool {\n        self.match_count > 0\n    }\n\n    /// Return the total number of matches reported to this sink.\n    ///\n    /// This corresponds to the number of times `Sink::matched` is called\n    /// on the previous search.\n    ///\n    /// This is unaffected by the result of searches before the previous\n    /// search on this sink.\n    pub fn match_count(&self) -> u64 {\n        self.match_count\n    }\n\n    /// If binary data was found in the previous search, this returns the\n    /// offset at which the binary data was first detected.\n    ///\n    /// The offset returned is an absolute offset relative to the entire\n    /// set of bytes searched.\n    ///\n    /// This is unaffected by the result of searches before the previous\n    /// search. e.g., If the search prior to the previous search found binary\n    /// data but the previous search found no binary data, then this will\n    /// return `None`.\n    pub fn binary_byte_offset(&self) -> Option<u64> {\n        self.binary_byte_offset\n    }\n\n    /// Return a reference to the stats produced by the printer for all\n    /// searches executed on this sink.\n    ///\n    /// This only returns stats if they were requested via the\n    /// [`StandardBuilder`] configuration.\n    pub fn stats(&self) -> Option<&Stats> {\n        self.stats.as_ref()\n    }\n\n    /// Execute the matcher over the given bytes and record the match\n    /// locations if the current configuration demands match granularity.\n    fn record_matches(\n        &mut self,\n        searcher: &Searcher,\n        bytes: &[u8],\n        range: std::ops::Range<usize>,\n    ) -> io::Result<()> {\n        self.standard.matches.clear();\n        if !self.needs_match_granularity {\n            return Ok(());\n        }\n        // If printing requires knowing the location of each individual match,\n        // then compute and stored those right now for use later. While this\n        // adds an extra copy for storing the matches, we do amortize the\n        // allocation for it and this greatly simplifies the printing logic to\n        // the extent that it's easy to ensure that we never do more than\n        // one search to find the matches (well, for replacements, we do one\n        // additional search to perform the actual replacement).\n        let matches = &mut self.standard.matches;\n        find_iter_at_in_context(\n            searcher,\n            &self.matcher,\n            bytes,\n            range.clone(),\n            |m| {\n                let (s, e) = (m.start() - range.start, m.end() - range.start);\n                matches.push(Match::new(s, e));\n                true\n            },\n        )?;\n        // Don't report empty matches appearing at the end of the bytes.\n        if !matches.is_empty()\n            && matches.last().unwrap().is_empty()\n            && matches.last().unwrap().start() >= range.end\n        {\n            matches.pop().unwrap();\n        }\n        Ok(())\n    }\n\n    /// If the configuration specifies a replacement, then this executes the\n    /// replacement, lazily allocating memory if necessary.\n    ///\n    /// To access the result of a replacement, use `replacer.replacement()`.\n    fn replace(\n        &mut self,\n        searcher: &Searcher,\n        bytes: &[u8],\n        range: std::ops::Range<usize>,\n    ) -> io::Result<()> {\n        self.replacer.clear();\n        if self.standard.config.replacement.is_some() {\n            let replacement = (*self.standard.config.replacement)\n                .as_ref()\n                .map(|r| &*r)\n                .unwrap();\n            self.replacer.replace_all(\n                searcher,\n                &self.matcher,\n                bytes,\n                range,\n                replacement,\n            )?;\n        }\n        Ok(())\n    }\n\n    /// Returns true if this printer should quit.\n    ///\n    /// This implements the logic for handling quitting after seeing a certain\n    /// amount of matches. In most cases, the logic is simple, but we must\n    /// permit all \"after\" contextual lines to print after reaching the limit.\n    fn should_quit(&self) -> bool {\n        let limit = match self.standard.config.max_matches {\n            None => return false,\n            Some(limit) => limit,\n        };\n        if self.match_count < limit {\n            return false;\n        }\n        self.after_context_remaining == 0\n    }\n\n    /// Returns whether the current match count exceeds the configured limit.\n    /// If there is no limit, then this always returns false.\n    fn match_more_than_limit(&self) -> bool {\n        let limit = match self.standard.config.max_matches {\n            None => return false,\n            Some(limit) => limit,\n        };\n        self.match_count > limit\n    }\n}\n\nimpl<'p, 's, M: Matcher, W: WriteColor> Sink for StandardSink<'p, 's, M, W> {\n    type Error = io::Error;\n\n    fn matched(\n        &mut self,\n        searcher: &Searcher,\n        mat: &SinkMatch<'_>,\n    ) -> Result<bool, io::Error> {\n        self.match_count += 1;\n        // When we've exceeded our match count, then the remaining context\n        // lines should not be reset, but instead, decremented. This avoids a\n        // bug where we display more matches than a configured limit. The main\n        // idea here is that 'matched' might be called again while printing\n        // an after-context line. In that case, we should treat this as a\n        // contextual line rather than a matching line for the purposes of\n        // termination.\n        if self.match_more_than_limit() {\n            self.after_context_remaining =\n                self.after_context_remaining.saturating_sub(1);\n        } else {\n            self.after_context_remaining = searcher.after_context() as u64;\n        }\n\n        self.record_matches(\n            searcher,\n            mat.buffer(),\n            mat.bytes_range_in_buffer(),\n        )?;\n        self.replace(searcher, mat.buffer(), mat.bytes_range_in_buffer())?;\n\n        if let Some(ref mut stats) = self.stats {\n            stats.add_matches(self.standard.matches.len() as u64);\n            stats.add_matched_lines(mat.lines().count() as u64);\n        }\n        if searcher.binary_detection().convert_byte().is_some() {\n            if self.binary_byte_offset.is_some() {\n                return Ok(false);\n            }\n        }\n\n        StandardImpl::from_match(searcher, self, mat).sink()?;\n        Ok(!self.should_quit())\n    }\n\n    fn context(\n        &mut self,\n        searcher: &Searcher,\n        ctx: &SinkContext<'_>,\n    ) -> Result<bool, io::Error> {\n        self.standard.matches.clear();\n        self.replacer.clear();\n\n        if ctx.kind() == &SinkContextKind::After {\n            self.after_context_remaining =\n                self.after_context_remaining.saturating_sub(1);\n        }\n        if searcher.invert_match() {\n            self.record_matches(searcher, ctx.bytes(), 0..ctx.bytes().len())?;\n            self.replace(searcher, ctx.bytes(), 0..ctx.bytes().len())?;\n        }\n        if searcher.binary_detection().convert_byte().is_some() {\n            if self.binary_byte_offset.is_some() {\n                return Ok(false);\n            }\n        }\n\n        StandardImpl::from_context(searcher, self, ctx).sink()?;\n        Ok(!self.should_quit())\n    }\n\n    fn context_break(\n        &mut self,\n        searcher: &Searcher,\n    ) -> Result<bool, io::Error> {\n        StandardImpl::new(searcher, self).write_context_separator()?;\n        Ok(true)\n    }\n\n    fn binary_data(\n        &mut self,\n        searcher: &Searcher,\n        binary_byte_offset: u64,\n    ) -> Result<bool, io::Error> {\n        if searcher.binary_detection().quit_byte().is_some() {\n            if let Some(ref path) = self.path {\n                log::debug!(\n                    \"ignoring {path}: found binary data at \\\n                     offset {binary_byte_offset}\",\n                    path = path.as_path().display(),\n                );\n            }\n        }\n        self.binary_byte_offset = Some(binary_byte_offset);\n        Ok(true)\n    }\n\n    fn begin(&mut self, _searcher: &Searcher) -> Result<bool, io::Error> {\n        self.standard.wtr.borrow_mut().reset_count();\n        self.start_time = Instant::now();\n        self.match_count = 0;\n        self.after_context_remaining = 0;\n        self.binary_byte_offset = None;\n        if self.standard.config.max_matches == Some(0) {\n            return Ok(false);\n        }\n        Ok(true)\n    }\n\n    fn finish(\n        &mut self,\n        searcher: &Searcher,\n        finish: &SinkFinish,\n    ) -> Result<(), io::Error> {\n        if let Some(offset) = self.binary_byte_offset {\n            StandardImpl::new(searcher, self).write_binary_message(offset)?;\n        }\n        if let Some(stats) = self.stats.as_mut() {\n            stats.add_elapsed(self.start_time.elapsed());\n            stats.add_searches(1);\n            if self.match_count > 0 {\n                stats.add_searches_with_match(1);\n            }\n            stats.add_bytes_searched(finish.byte_count());\n            stats.add_bytes_printed(self.standard.wtr.borrow().count());\n        }\n        Ok(())\n    }\n}\n\n/// The actual implementation of the standard printer. This couples together\n/// the searcher, the sink implementation and information about the match.\n///\n/// A StandardImpl is initialized every time a match or a contextual line is\n/// reported.\n#[derive(Debug)]\nstruct StandardImpl<'a, M: Matcher, W> {\n    searcher: &'a Searcher,\n    sink: &'a StandardSink<'a, 'a, M, W>,\n    sunk: Sunk<'a>,\n    /// Set to true if and only if we are writing a match with color.\n    in_color_match: Cell<bool>,\n}\n\nimpl<'a, M: Matcher, W: WriteColor> StandardImpl<'a, M, W> {\n    /// Bundle self with a searcher and return the core implementation of Sink.\n    fn new(\n        searcher: &'a Searcher,\n        sink: &'a StandardSink<'_, '_, M, W>,\n    ) -> StandardImpl<'a, M, W> {\n        StandardImpl {\n            searcher,\n            sink,\n            sunk: Sunk::empty(),\n            in_color_match: Cell::new(false),\n        }\n    }\n\n    /// Bundle self with a searcher and return the core implementation of Sink\n    /// for use with handling matching lines.\n    fn from_match(\n        searcher: &'a Searcher,\n        sink: &'a StandardSink<'_, '_, M, W>,\n        mat: &'a SinkMatch<'a>,\n    ) -> StandardImpl<'a, M, W> {\n        let sunk = Sunk::from_sink_match(\n            mat,\n            &sink.standard.matches,\n            sink.replacer.replacement(),\n        );\n        StandardImpl { sunk, ..StandardImpl::new(searcher, sink) }\n    }\n\n    /// Bundle self with a searcher and return the core implementation of Sink\n    /// for use with handling contextual lines.\n    fn from_context(\n        searcher: &'a Searcher,\n        sink: &'a StandardSink<'_, '_, M, W>,\n        ctx: &'a SinkContext<'a>,\n    ) -> StandardImpl<'a, M, W> {\n        let sunk = Sunk::from_sink_context(\n            ctx,\n            &sink.standard.matches,\n            sink.replacer.replacement(),\n        );\n        StandardImpl { sunk, ..StandardImpl::new(searcher, sink) }\n    }\n\n    fn sink(&self) -> io::Result<()> {\n        self.write_search_prelude()?;\n        if self.sunk.matches().is_empty() {\n            if self.multi_line() && !self.is_context() {\n                self.sink_fast_multi_line()\n            } else {\n                self.sink_fast()\n            }\n        } else {\n            if self.multi_line() && !self.is_context() {\n                self.sink_slow_multi_line()\n            } else {\n                self.sink_slow()\n            }\n        }\n    }\n\n    /// Print matches (limited to one line) quickly by avoiding the detection\n    /// of each individual match in the lines reported in the given\n    /// `SinkMatch`.\n    ///\n    /// This should only be used when the configuration does not demand match\n    /// granularity and the searcher is not in multi line mode.\n    fn sink_fast(&self) -> io::Result<()> {\n        debug_assert!(self.sunk.matches().is_empty());\n        debug_assert!(!self.multi_line() || self.is_context());\n\n        self.write_prelude(\n            self.sunk.absolute_byte_offset(),\n            self.sunk.line_number(),\n            None,\n        )?;\n        self.write_line(self.sunk.bytes())\n    }\n\n    /// Print matches (possibly spanning more than one line) quickly by\n    /// avoiding the detection of each individual match in the lines reported\n    /// in the given `SinkMatch`.\n    ///\n    /// This should only be used when the configuration does not demand match\n    /// granularity. This may be used when the searcher is in multi line mode.\n    fn sink_fast_multi_line(&self) -> io::Result<()> {\n        debug_assert!(self.sunk.matches().is_empty());\n        // This isn't actually a required invariant for using this method,\n        // but if we wind up here and multi line mode is disabled, then we\n        // should still treat it as a bug since we should be using matched_fast\n        // instead.\n        debug_assert!(self.multi_line());\n\n        let line_term = self.searcher.line_terminator().as_byte();\n        let mut absolute_byte_offset = self.sunk.absolute_byte_offset();\n        for (i, line) in self.sunk.lines(line_term).enumerate() {\n            self.write_prelude(\n                absolute_byte_offset,\n                self.sunk.line_number().map(|n| n + i as u64),\n                None,\n            )?;\n            absolute_byte_offset += line.len() as u64;\n\n            self.write_line(line)?;\n        }\n        Ok(())\n    }\n\n    /// Print a matching line where the configuration of the printer requires\n    /// finding each individual match (e.g., for coloring).\n    fn sink_slow(&self) -> io::Result<()> {\n        debug_assert!(!self.sunk.matches().is_empty());\n        debug_assert!(!self.multi_line() || self.is_context());\n\n        if self.config().only_matching {\n            for &m in self.sunk.matches() {\n                self.write_prelude(\n                    self.sunk.absolute_byte_offset() + m.start() as u64,\n                    self.sunk.line_number(),\n                    Some(m.start() as u64 + 1),\n                )?;\n\n                let buf = &self.sunk.bytes()[m];\n                self.write_colored_line(&[Match::new(0, buf.len())], buf)?;\n            }\n        } else if self.config().per_match {\n            for &m in self.sunk.matches() {\n                self.write_prelude(\n                    self.sunk.absolute_byte_offset() + m.start() as u64,\n                    self.sunk.line_number(),\n                    Some(m.start() as u64 + 1),\n                )?;\n                self.write_colored_line(&[m], self.sunk.bytes())?;\n            }\n        } else {\n            self.write_prelude(\n                self.sunk.absolute_byte_offset(),\n                self.sunk.line_number(),\n                Some(self.sunk.matches()[0].start() as u64 + 1),\n            )?;\n            self.write_colored_line(self.sunk.matches(), self.sunk.bytes())?;\n        }\n        Ok(())\n    }\n\n    fn sink_slow_multi_line(&self) -> io::Result<()> {\n        debug_assert!(!self.sunk.matches().is_empty());\n        debug_assert!(self.multi_line());\n\n        if self.config().only_matching {\n            return self.sink_slow_multi_line_only_matching();\n        } else if self.config().per_match {\n            return self.sink_slow_multi_per_match();\n        }\n\n        let line_term = self.searcher.line_terminator().as_byte();\n        let bytes = self.sunk.bytes();\n        let matches = self.sunk.matches();\n        let mut midx = 0;\n        let mut count = 0;\n        let mut stepper = LineStep::new(line_term, 0, bytes.len());\n        while let Some((start, end)) = stepper.next(bytes) {\n            let mut line = Match::new(start, end);\n            self.write_prelude(\n                self.sunk.absolute_byte_offset() + line.start() as u64,\n                self.sunk.line_number().map(|n| n + count),\n                Some(matches[0].start() as u64 + 1),\n            )?;\n            count += 1;\n            self.trim_ascii_prefix(bytes, &mut line);\n            if self.exceeds_max_columns(&bytes[line]) {\n                self.write_exceeded_line(bytes, line, matches, &mut midx)?;\n            } else {\n                self.write_colored_matches(bytes, line, matches, &mut midx)?;\n                self.write_line_term()?;\n            }\n        }\n        Ok(())\n    }\n\n    fn sink_slow_multi_line_only_matching(&self) -> io::Result<()> {\n        let line_term = self.searcher.line_terminator().as_byte();\n        let spec = self.config().colors.matched();\n        let bytes = self.sunk.bytes();\n        let matches = self.sunk.matches();\n        let mut midx = 0;\n        let mut count = 0;\n        let mut stepper = LineStep::new(line_term, 0, bytes.len());\n        while let Some((start, end)) = stepper.next(bytes) {\n            let mut line = Match::new(start, end);\n            self.trim_line_terminator(bytes, &mut line);\n            self.trim_ascii_prefix(bytes, &mut line);\n            while !line.is_empty() {\n                if matches[midx].end() <= line.start() {\n                    if midx + 1 < matches.len() {\n                        midx += 1;\n                        continue;\n                    } else {\n                        break;\n                    }\n                }\n                let m = matches[midx];\n\n                if line.start() < m.start() {\n                    let upto = cmp::min(line.end(), m.start());\n                    line = line.with_start(upto);\n                } else {\n                    let upto = cmp::min(line.end(), m.end());\n                    self.write_prelude(\n                        self.sunk.absolute_byte_offset() + m.start() as u64,\n                        self.sunk.line_number().map(|n| n + count),\n                        Some(m.start() as u64 + 1),\n                    )?;\n\n                    let this_line = line.with_end(upto);\n                    line = line.with_start(upto);\n                    if self.exceeds_max_columns(&bytes[this_line]) {\n                        self.write_exceeded_line(\n                            bytes, this_line, matches, &mut midx,\n                        )?;\n                    } else {\n                        self.write_spec(spec, &bytes[this_line])?;\n                        self.write_line_term()?;\n                    }\n                }\n            }\n            count += 1;\n        }\n        Ok(())\n    }\n\n    fn sink_slow_multi_per_match(&self) -> io::Result<()> {\n        let line_term = self.searcher.line_terminator().as_byte();\n        let spec = self.config().colors.matched();\n        let bytes = self.sunk.bytes();\n        for &m in self.sunk.matches() {\n            let mut count = 0;\n            let mut stepper = LineStep::new(line_term, 0, bytes.len());\n            while let Some((start, end)) = stepper.next(bytes) {\n                let mut line = Match::new(start, end);\n                if line.start() >= m.end() {\n                    break;\n                } else if line.end() <= m.start() {\n                    count += 1;\n                    continue;\n                }\n                self.write_prelude(\n                    self.sunk.absolute_byte_offset() + line.start() as u64,\n                    self.sunk.line_number().map(|n| n + count),\n                    Some(m.start().saturating_sub(line.start()) as u64 + 1),\n                )?;\n                count += 1;\n                self.trim_line_terminator(bytes, &mut line);\n                self.trim_ascii_prefix(bytes, &mut line);\n                if self.exceeds_max_columns(&bytes[line]) {\n                    self.write_exceeded_line(bytes, line, &[m], &mut 0)?;\n                    continue;\n                }\n\n                while !line.is_empty() {\n                    if m.end() <= line.start() {\n                        self.write(&bytes[line])?;\n                        line = line.with_start(line.end());\n                    } else if line.start() < m.start() {\n                        let upto = cmp::min(line.end(), m.start());\n                        self.write(&bytes[line.with_end(upto)])?;\n                        line = line.with_start(upto);\n                    } else {\n                        let upto = cmp::min(line.end(), m.end());\n                        self.write_spec(spec, &bytes[line.with_end(upto)])?;\n                        line = line.with_start(upto);\n                    }\n                }\n                self.write_line_term()?;\n                // It turns out that vimgrep really only wants one line per\n                // match, even when a match spans multiple lines. So when\n                // that option is enabled, we just quit after printing the\n                // first line.\n                //\n                // See: https://github.com/BurntSushi/ripgrep/issues/1866\n                if self.config().per_match_one_line {\n                    break;\n                }\n            }\n        }\n        Ok(())\n    }\n\n    /// Write the beginning part of a matching line. This (may) include things\n    /// like the file path, line number among others, depending on the\n    /// configuration and the parameters given.\n    #[inline(always)]\n    fn write_prelude(\n        &self,\n        absolute_byte_offset: u64,\n        line_number: Option<u64>,\n        column: Option<u64>,\n    ) -> io::Result<()> {\n        let mut prelude = PreludeWriter::new(self);\n        prelude.start(line_number, column)?;\n        prelude.write_path()?;\n        prelude.write_line_number(line_number)?;\n        prelude.write_column_number(column)?;\n        prelude.write_byte_offset(absolute_byte_offset)?;\n        prelude.end()\n    }\n\n    #[inline(always)]\n    fn write_line(&self, line: &[u8]) -> io::Result<()> {\n        let line = if !self.config().trim_ascii {\n            line\n        } else {\n            let lineterm = self.searcher.line_terminator();\n            let full_range = Match::new(0, line.len());\n            let range = trim_ascii_prefix(lineterm, line, full_range);\n            &line[range]\n        };\n        if self.exceeds_max_columns(line) {\n            let range = Match::new(0, line.len());\n            self.write_exceeded_line(\n                line,\n                range,\n                self.sunk.matches(),\n                &mut 0,\n            )?;\n        } else {\n            // self.write_trim(line)?;\n            self.write(line)?;\n            if !self.has_line_terminator(line) {\n                self.write_line_term()?;\n            }\n        }\n        Ok(())\n    }\n\n    fn write_colored_line(\n        &self,\n        matches: &[Match],\n        bytes: &[u8],\n    ) -> io::Result<()> {\n        // If we know we aren't going to emit color, then we can go faster.\n        let spec = self.config().colors.matched();\n        if !self.wtr().borrow().supports_color() || spec.is_none() {\n            return self.write_line(bytes);\n        }\n\n        let mut line = Match::new(0, bytes.len());\n        self.trim_ascii_prefix(bytes, &mut line);\n        if self.exceeds_max_columns(bytes) {\n            self.write_exceeded_line(bytes, line, matches, &mut 0)\n        } else {\n            self.write_colored_matches(bytes, line, matches, &mut 0)?;\n            self.write_line_term()?;\n            Ok(())\n        }\n    }\n\n    /// Write the `line` portion of `bytes`, with appropriate coloring for\n    /// each `match`, starting at `match_index`.\n    ///\n    /// This accounts for trimming any whitespace prefix and will *never* print\n    /// a line terminator. If a match exceeds the range specified by `line`,\n    /// then only the part of the match within `line` (if any) is printed.\n    fn write_colored_matches(\n        &self,\n        bytes: &[u8],\n        mut line: Match,\n        matches: &[Match],\n        match_index: &mut usize,\n    ) -> io::Result<()> {\n        self.trim_line_terminator(bytes, &mut line);\n        if matches.is_empty() {\n            self.write(&bytes[line])?;\n            return Ok(());\n        }\n        while !line.is_empty() {\n            if matches[*match_index].end() <= line.start() {\n                if *match_index + 1 < matches.len() {\n                    *match_index += 1;\n                    continue;\n                } else {\n                    self.end_color_match()?;\n                    self.write(&bytes[line])?;\n                    break;\n                }\n            }\n\n            let m = matches[*match_index];\n            if line.start() < m.start() {\n                let upto = cmp::min(line.end(), m.start());\n                self.end_color_match()?;\n                self.write(&bytes[line.with_end(upto)])?;\n                line = line.with_start(upto);\n            } else {\n                let upto = cmp::min(line.end(), m.end());\n                self.start_color_match()?;\n                self.write(&bytes[line.with_end(upto)])?;\n                line = line.with_start(upto);\n            }\n        }\n        self.end_color_match()?;\n        Ok(())\n    }\n\n    fn write_exceeded_line(\n        &self,\n        bytes: &[u8],\n        mut line: Match,\n        matches: &[Match],\n        match_index: &mut usize,\n    ) -> io::Result<()> {\n        if self.config().max_columns_preview {\n            let original = line;\n            let end = bytes[line]\n                .grapheme_indices()\n                .map(|(_, end, _)| end)\n                .take(self.config().max_columns.unwrap_or(0) as usize)\n                .last()\n                .unwrap_or(0)\n                + line.start();\n            line = line.with_end(end);\n            self.write_colored_matches(bytes, line, matches, match_index)?;\n\n            if matches.is_empty() {\n                self.write(b\" [... omitted end of long line]\")?;\n            } else {\n                let remaining = matches\n                    .iter()\n                    .filter(|m| {\n                        m.start() >= line.end() && m.start() < original.end()\n                    })\n                    .count();\n                let tense = if remaining == 1 { \"match\" } else { \"matches\" };\n                write!(\n                    self.wtr().borrow_mut(),\n                    \" [... {} more {}]\",\n                    remaining,\n                    tense,\n                )?;\n            }\n            self.write_line_term()?;\n            return Ok(());\n        }\n        if self.sunk.original_matches().is_empty() {\n            if self.is_context() {\n                self.write(b\"[Omitted long context line]\")?;\n            } else {\n                self.write(b\"[Omitted long matching line]\")?;\n            }\n        } else {\n            if self.config().only_matching {\n                if self.is_context() {\n                    self.write(b\"[Omitted long context line]\")?;\n                } else {\n                    self.write(b\"[Omitted long matching line]\")?;\n                }\n            } else {\n                write!(\n                    self.wtr().borrow_mut(),\n                    \"[Omitted long line with {} matches]\",\n                    self.sunk.original_matches().len(),\n                )?;\n            }\n        }\n        self.write_line_term()?;\n        Ok(())\n    }\n\n    /// If this printer has a file path associated with it, then this will\n    /// write that path to the underlying writer followed by a line terminator.\n    /// (If a path terminator is set, then that is used instead of the line\n    /// terminator.)\n    fn write_path_line(&self) -> io::Result<()> {\n        if let Some(path) = self.path() {\n            self.write_path_hyperlink(path)?;\n            if let Some(term) = self.config().path_terminator {\n                self.write(&[term])?;\n            } else {\n                self.write_line_term()?;\n            }\n        }\n        Ok(())\n    }\n\n    fn write_search_prelude(&self) -> io::Result<()> {\n        let this_search_written = self.wtr().borrow().count() > 0;\n        if this_search_written {\n            return Ok(());\n        }\n        if let Some(ref sep) = *self.config().separator_search {\n            let ever_written = self.wtr().borrow().total_count() > 0;\n            if ever_written {\n                self.write(sep)?;\n                self.write_line_term()?;\n            }\n        }\n        if self.config().heading {\n            self.write_path_line()?;\n        }\n        Ok(())\n    }\n\n    fn write_binary_message(&self, offset: u64) -> io::Result<()> {\n        if self.sink.match_count == 0 {\n            return Ok(());\n        }\n\n        let bin = self.searcher.binary_detection();\n        if let Some(byte) = bin.quit_byte() {\n            if let Some(path) = self.path() {\n                self.write_path_hyperlink(path)?;\n                self.write(b\": \")?;\n            }\n            let remainder = format!(\n                \"WARNING: stopped searching binary file after match \\\n                 (found {:?} byte around offset {})\\n\",\n                [byte].as_bstr(),\n                offset,\n            );\n            self.write(remainder.as_bytes())?;\n        } else if let Some(byte) = bin.convert_byte() {\n            if let Some(path) = self.path() {\n                self.write_path_hyperlink(path)?;\n                self.write(b\": \")?;\n            }\n            let remainder = format!(\n                \"binary file matches (found {:?} byte around offset {})\\n\",\n                [byte].as_bstr(),\n                offset,\n            );\n            self.write(remainder.as_bytes())?;\n        }\n        Ok(())\n    }\n\n    fn write_context_separator(&self) -> io::Result<()> {\n        if let Some(ref sep) = *self.config().separator_context {\n            self.write(sep)?;\n            self.write_line_term()?;\n        }\n        Ok(())\n    }\n\n    fn write_line_term(&self) -> io::Result<()> {\n        self.write(self.searcher.line_terminator().as_bytes())\n    }\n\n    fn write_spec(&self, spec: &ColorSpec, buf: &[u8]) -> io::Result<()> {\n        let mut wtr = self.wtr().borrow_mut();\n        wtr.set_color(spec)?;\n        wtr.write_all(buf)?;\n        wtr.reset()?;\n        Ok(())\n    }\n\n    fn write_path(&self, path: &PrinterPath) -> io::Result<()> {\n        let mut wtr = self.wtr().borrow_mut();\n        wtr.set_color(self.config().colors.path())?;\n        wtr.write_all(path.as_bytes())?;\n        wtr.reset()\n    }\n\n    fn write_path_hyperlink(&self, path: &PrinterPath) -> io::Result<()> {\n        let status = self.start_hyperlink(path, None, None)?;\n        self.write_path(path)?;\n        self.end_hyperlink(status)\n    }\n\n    fn start_hyperlink(\n        &self,\n        path: &PrinterPath,\n        line_number: Option<u64>,\n        column: Option<u64>,\n    ) -> io::Result<hyperlink::InterpolatorStatus> {\n        let Some(hyperpath) = path.as_hyperlink() else {\n            return Ok(hyperlink::InterpolatorStatus::inactive());\n        };\n        let values =\n            hyperlink::Values::new(hyperpath).line(line_number).column(column);\n        self.sink.interpolator.begin(&values, &mut *self.wtr().borrow_mut())\n    }\n\n    fn end_hyperlink(\n        &self,\n        status: hyperlink::InterpolatorStatus,\n    ) -> io::Result<()> {\n        self.sink.interpolator.finish(status, &mut *self.wtr().borrow_mut())\n    }\n\n    fn start_color_match(&self) -> io::Result<()> {\n        if self.in_color_match.get() {\n            return Ok(());\n        }\n        self.wtr().borrow_mut().set_color(self.config().colors.matched())?;\n        self.in_color_match.set(true);\n        Ok(())\n    }\n\n    fn end_color_match(&self) -> io::Result<()> {\n        if !self.in_color_match.get() {\n            return Ok(());\n        }\n        self.wtr().borrow_mut().reset()?;\n        self.in_color_match.set(false);\n        Ok(())\n    }\n\n    fn write(&self, buf: &[u8]) -> io::Result<()> {\n        self.wtr().borrow_mut().write_all(buf)\n    }\n\n    fn trim_line_terminator(&self, buf: &[u8], line: &mut Match) {\n        trim_line_terminator(&self.searcher, buf, line);\n    }\n\n    fn has_line_terminator(&self, buf: &[u8]) -> bool {\n        self.searcher.line_terminator().is_suffix(buf)\n    }\n\n    fn is_context(&self) -> bool {\n        self.sunk.context_kind().is_some()\n    }\n\n    /// Return the underlying configuration for this printer.\n    fn config(&self) -> &'a Config {\n        &self.sink.standard.config\n    }\n\n    /// Return the underlying writer that we are printing to.\n    fn wtr(&self) -> &'a RefCell<CounterWriter<W>> {\n        &self.sink.standard.wtr\n    }\n\n    /// Return the path associated with this printer, if one exists.\n    fn path(&self) -> Option<&'a PrinterPath<'a>> {\n        self.sink.path.as_ref()\n    }\n\n    /// Return the appropriate field separator based on whether we are emitting\n    /// matching or contextual lines.\n    fn separator_field(&self) -> &[u8] {\n        if self.is_context() {\n            &self.config().separator_field_context\n        } else {\n            &self.config().separator_field_match\n        }\n    }\n\n    /// Returns true if and only if the given line exceeds the maximum number\n    /// of columns set. If no maximum is set, then this always returns false.\n    fn exceeds_max_columns(&self, line: &[u8]) -> bool {\n        self.config().max_columns.map_or(false, |m| line.len() as u64 > m)\n    }\n\n    /// Returns true if and only if the searcher may report matches over\n    /// multiple lines.\n    ///\n    /// Note that this doesn't just return whether the searcher is in multi\n    /// line mode, but also checks if the matter can match over multiple lines.\n    /// If it can't, then we don't need multi line handling, even if the\n    /// searcher has multi line mode enabled.\n    fn multi_line(&self) -> bool {\n        self.searcher.multi_line_with_matcher(&self.sink.matcher)\n    }\n\n    /// Trim prefix ASCII spaces from the given slice and return the\n    /// corresponding range.\n    ///\n    /// This stops trimming a prefix as soon as it sees non-whitespace or a\n    /// line terminator.\n    fn trim_ascii_prefix(&self, slice: &[u8], range: &mut Match) {\n        if !self.config().trim_ascii {\n            return;\n        }\n        let lineterm = self.searcher.line_terminator();\n        *range = trim_ascii_prefix(lineterm, slice, *range)\n    }\n}\n\n/// A writer for the prelude (the beginning part of a matching line).\n///\n/// This encapsulates the state needed to print the prelude.\nstruct PreludeWriter<'a, M: Matcher, W> {\n    std: &'a StandardImpl<'a, M, W>,\n    next_separator: PreludeSeparator,\n    field_separator: &'a [u8],\n    interp_status: hyperlink::InterpolatorStatus,\n}\n\n/// A type of separator used in the prelude\nenum PreludeSeparator {\n    /// No separator.\n    None,\n    /// The field separator, either for a matching or contextual line.\n    FieldSeparator,\n    /// The path terminator.\n    PathTerminator,\n}\n\nimpl<'a, M: Matcher, W: WriteColor> PreludeWriter<'a, M, W> {\n    /// Creates a new prelude printer.\n    #[inline(always)]\n    fn new(std: &'a StandardImpl<'a, M, W>) -> PreludeWriter<'a, M, W> {\n        PreludeWriter {\n            std,\n            next_separator: PreludeSeparator::None,\n            field_separator: std.separator_field(),\n            interp_status: hyperlink::InterpolatorStatus::inactive(),\n        }\n    }\n\n    /// Starts the prelude with a hyperlink when applicable.\n    ///\n    /// If a heading was written, and the hyperlink format is invariant on\n    /// the line number, then this doesn't hyperlink each line prelude, as it\n    /// wouldn't point to the line anyway. The hyperlink on the heading should\n    /// be sufficient and less confusing.\n    #[inline(always)]\n    fn start(\n        &mut self,\n        line_number: Option<u64>,\n        column: Option<u64>,\n    ) -> io::Result<()> {\n        let Some(path) = self.std.path() else { return Ok(()) };\n        if self.config().hyperlink.format().is_line_dependent()\n            || !self.config().heading\n        {\n            self.interp_status =\n                self.std.start_hyperlink(path, line_number, column)?;\n        }\n        Ok(())\n    }\n\n    /// Ends the prelude and writes the remaining output.\n    #[inline(always)]\n    fn end(&mut self) -> io::Result<()> {\n        self.std.end_hyperlink(std::mem::replace(\n            &mut self.interp_status,\n            hyperlink::InterpolatorStatus::inactive(),\n        ))?;\n        self.write_separator()\n    }\n\n    /// If this printer has a file path associated with it, then this will\n    /// write that path to the underlying writer followed by the given field\n    /// separator. (If a path terminator is set, then that is used instead of\n    /// the field separator.)\n    #[inline(always)]\n    fn write_path(&mut self) -> io::Result<()> {\n        // The prelude doesn't handle headings, only what comes before a match\n        // on the same line. So if we are emitting paths in headings, we should\n        // not do it here on each line.\n        if self.config().heading {\n            return Ok(());\n        }\n        let Some(path) = self.std.path() else { return Ok(()) };\n        self.write_separator()?;\n        self.std.write_path(path)?;\n\n        self.next_separator = if self.config().path_terminator.is_some() {\n            PreludeSeparator::PathTerminator\n        } else {\n            PreludeSeparator::FieldSeparator\n        };\n        Ok(())\n    }\n\n    /// Writes the line number field if present.\n    #[inline(always)]\n    fn write_line_number(&mut self, line: Option<u64>) -> io::Result<()> {\n        let Some(line_number) = line else { return Ok(()) };\n        self.write_separator()?;\n        let n = DecimalFormatter::new(line_number);\n        self.std.write_spec(self.config().colors.line(), n.as_bytes())?;\n        self.next_separator = PreludeSeparator::FieldSeparator;\n        Ok(())\n    }\n\n    /// Writes the column number field if present and configured to do so.\n    #[inline(always)]\n    fn write_column_number(&mut self, column: Option<u64>) -> io::Result<()> {\n        if !self.config().column {\n            return Ok(());\n        }\n        let Some(column_number) = column else { return Ok(()) };\n        self.write_separator()?;\n        let n = DecimalFormatter::new(column_number);\n        self.std.write_spec(self.config().colors.column(), n.as_bytes())?;\n        self.next_separator = PreludeSeparator::FieldSeparator;\n        Ok(())\n    }\n\n    /// Writes the byte offset field if configured to do so.\n    #[inline(always)]\n    fn write_byte_offset(&mut self, offset: u64) -> io::Result<()> {\n        if !self.config().byte_offset {\n            return Ok(());\n        }\n        self.write_separator()?;\n        let n = DecimalFormatter::new(offset);\n        self.std.write_spec(self.config().colors.column(), n.as_bytes())?;\n        self.next_separator = PreludeSeparator::FieldSeparator;\n        Ok(())\n    }\n\n    /// Writes the separator defined by the preceding field.\n    ///\n    /// This is called before writing the contents of a field, and at\n    /// the end of the prelude.\n    #[inline(always)]\n    fn write_separator(&mut self) -> io::Result<()> {\n        match self.next_separator {\n            PreludeSeparator::None => {}\n            PreludeSeparator::FieldSeparator => {\n                self.std.write(self.field_separator)?;\n            }\n            PreludeSeparator::PathTerminator => {\n                if let Some(term) = self.config().path_terminator {\n                    self.std.write(&[term])?;\n                }\n            }\n        }\n        self.next_separator = PreludeSeparator::None;\n        Ok(())\n    }\n\n    #[inline(always)]\n    fn config(&self) -> &Config {\n        self.std.config()\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use grep_matcher::LineTerminator;\n    use grep_regex::{RegexMatcher, RegexMatcherBuilder};\n    use grep_searcher::SearcherBuilder;\n    use termcolor::{Ansi, NoColor};\n\n    use super::{ColorSpecs, Standard, StandardBuilder};\n\n    const SHERLOCK: &'static str = \"\\\nFor the Doctor Watsons of this world, as opposed to the Sherlock\nHolmeses, success in the province of detective work must always\nbe, to a very large extent, the result of luck. Sherlock Holmes\ncan extract a clew from a wisp of straw or a flake of cigar ash;\nbut Doctor Watson has to have it taken out for him and dusted,\nand exhibited clearly, with a label attached.\\\n\";\n\n    #[allow(dead_code)]\n    const SHERLOCK_CRLF: &'static str = \"\\\nFor the Doctor Watsons of this world, as opposed to the Sherlock\\r\nHolmeses, success in the province of detective work must always\\r\nbe, to a very large extent, the result of luck. Sherlock Holmes\\r\ncan extract a clew from a wisp of straw or a flake of cigar ash;\\r\nbut Doctor Watson has to have it taken out for him and dusted,\\r\nand exhibited clearly, with a label attached.\\\n\";\n\n    fn printer_contents(printer: &mut Standard<NoColor<Vec<u8>>>) -> String {\n        String::from_utf8(printer.get_mut().get_ref().to_owned()).unwrap()\n    }\n\n    fn printer_contents_ansi(printer: &mut Standard<Ansi<Vec<u8>>>) -> String {\n        String::from_utf8(printer.get_mut().get_ref().to_owned()).unwrap()\n    }\n\n    #[test]\n    fn reports_match() {\n        let matcher = RegexMatcher::new(\"Sherlock\").unwrap();\n        let mut printer = StandardBuilder::new().build(NoColor::new(vec![]));\n        let mut sink = printer.sink(&matcher);\n        SearcherBuilder::new()\n            .line_number(false)\n            .build()\n            .search_reader(&matcher, SHERLOCK.as_bytes(), &mut sink)\n            .unwrap();\n        assert!(sink.has_match());\n\n        let matcher = RegexMatcher::new(\"zzzzz\").unwrap();\n        let mut printer = StandardBuilder::new().build(NoColor::new(vec![]));\n        let mut sink = printer.sink(&matcher);\n        SearcherBuilder::new()\n            .line_number(false)\n            .build()\n            .search_reader(&matcher, SHERLOCK.as_bytes(), &mut sink)\n            .unwrap();\n        assert!(!sink.has_match());\n    }\n\n    #[test]\n    fn reports_binary() {\n        use grep_searcher::BinaryDetection;\n\n        let matcher = RegexMatcher::new(\"Sherlock\").unwrap();\n        let mut printer = StandardBuilder::new().build(NoColor::new(vec![]));\n        let mut sink = printer.sink(&matcher);\n        SearcherBuilder::new()\n            .line_number(false)\n            .build()\n            .search_reader(&matcher, SHERLOCK.as_bytes(), &mut sink)\n            .unwrap();\n        assert!(sink.binary_byte_offset().is_none());\n\n        let matcher = RegexMatcher::new(\".+\").unwrap();\n        let mut printer = StandardBuilder::new().build(NoColor::new(vec![]));\n        let mut sink = printer.sink(&matcher);\n        SearcherBuilder::new()\n            .line_number(false)\n            .binary_detection(BinaryDetection::quit(b'\\x00'))\n            .build()\n            .search_reader(&matcher, &b\"abc\\x00\"[..], &mut sink)\n            .unwrap();\n        assert_eq!(sink.binary_byte_offset(), Some(3));\n    }\n\n    #[test]\n    fn reports_stats() {\n        use std::time::Duration;\n\n        let matcher = RegexMatcher::new(\"Sherlock|opposed\").unwrap();\n        let mut printer =\n            StandardBuilder::new().stats(true).build(NoColor::new(vec![]));\n        let stats = {\n            let mut sink = printer.sink(&matcher);\n            SearcherBuilder::new()\n                .line_number(false)\n                .build()\n                .search_reader(&matcher, SHERLOCK.as_bytes(), &mut sink)\n                .unwrap();\n            sink.stats().unwrap().clone()\n        };\n        let buf = printer_contents(&mut printer);\n\n        assert!(stats.elapsed() > Duration::default());\n        assert_eq!(stats.searches(), 1);\n        assert_eq!(stats.searches_with_match(), 1);\n        assert_eq!(stats.bytes_searched(), SHERLOCK.len() as u64);\n        assert_eq!(stats.bytes_printed(), buf.len() as u64);\n        assert_eq!(stats.matched_lines(), 2);\n        assert_eq!(stats.matches(), 3);\n    }\n\n    #[test]\n    fn reports_stats_multiple() {\n        use std::time::Duration;\n\n        let matcher = RegexMatcher::new(\"Sherlock|opposed\").unwrap();\n        let mut printer =\n            StandardBuilder::new().stats(true).build(NoColor::new(vec![]));\n        let stats = {\n            let mut sink = printer.sink(&matcher);\n            SearcherBuilder::new()\n                .line_number(false)\n                .build()\n                .search_reader(&matcher, SHERLOCK.as_bytes(), &mut sink)\n                .unwrap();\n            SearcherBuilder::new()\n                .line_number(false)\n                .build()\n                .search_reader(&matcher, &b\"zzzzzzzzzz\"[..], &mut sink)\n                .unwrap();\n            SearcherBuilder::new()\n                .line_number(false)\n                .build()\n                .search_reader(&matcher, SHERLOCK.as_bytes(), &mut sink)\n                .unwrap();\n            sink.stats().unwrap().clone()\n        };\n        let buf = printer_contents(&mut printer);\n\n        assert!(stats.elapsed() > Duration::default());\n        assert_eq!(stats.searches(), 3);\n        assert_eq!(stats.searches_with_match(), 2);\n        assert_eq!(stats.bytes_searched(), 10 + 2 * SHERLOCK.len() as u64);\n        assert_eq!(stats.bytes_printed(), buf.len() as u64);\n        assert_eq!(stats.matched_lines(), 4);\n        assert_eq!(stats.matches(), 6);\n    }\n\n    #[test]\n    fn context_break() {\n        let matcher = RegexMatcher::new(\"Watson\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .separator_context(Some(b\"--abc--\".to_vec()))\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(false)\n            .before_context(1)\n            .after_context(1)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\nFor the Doctor Watsons of this world, as opposed to the Sherlock\nHolmeses, success in the province of detective work must always\n--abc--\ncan extract a clew from a wisp of straw or a flake of cigar ash;\nbut Doctor Watson has to have it taken out for him and dusted,\nand exhibited clearly, with a label attached.\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn context_break_multiple_no_heading() {\n        let matcher = RegexMatcher::new(\"Watson\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .separator_search(Some(b\"--xyz--\".to_vec()))\n            .separator_context(Some(b\"--abc--\".to_vec()))\n            .build(NoColor::new(vec![]));\n\n        SearcherBuilder::new()\n            .line_number(false)\n            .before_context(1)\n            .after_context(1)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n        SearcherBuilder::new()\n            .line_number(false)\n            .before_context(1)\n            .after_context(1)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\nFor the Doctor Watsons of this world, as opposed to the Sherlock\nHolmeses, success in the province of detective work must always\n--abc--\ncan extract a clew from a wisp of straw or a flake of cigar ash;\nbut Doctor Watson has to have it taken out for him and dusted,\nand exhibited clearly, with a label attached.\n--xyz--\nFor the Doctor Watsons of this world, as opposed to the Sherlock\nHolmeses, success in the province of detective work must always\n--abc--\ncan extract a clew from a wisp of straw or a flake of cigar ash;\nbut Doctor Watson has to have it taken out for him and dusted,\nand exhibited clearly, with a label attached.\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn context_break_multiple_heading() {\n        let matcher = RegexMatcher::new(\"Watson\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .heading(true)\n            .separator_search(Some(b\"--xyz--\".to_vec()))\n            .separator_context(Some(b\"--abc--\".to_vec()))\n            .build(NoColor::new(vec![]));\n\n        SearcherBuilder::new()\n            .line_number(false)\n            .before_context(1)\n            .after_context(1)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n        SearcherBuilder::new()\n            .line_number(false)\n            .before_context(1)\n            .after_context(1)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\nFor the Doctor Watsons of this world, as opposed to the Sherlock\nHolmeses, success in the province of detective work must always\n--abc--\ncan extract a clew from a wisp of straw or a flake of cigar ash;\nbut Doctor Watson has to have it taken out for him and dusted,\nand exhibited clearly, with a label attached.\n--xyz--\nFor the Doctor Watsons of this world, as opposed to the Sherlock\nHolmeses, success in the province of detective work must always\n--abc--\ncan extract a clew from a wisp of straw or a flake of cigar ash;\nbut Doctor Watson has to have it taken out for him and dusted,\nand exhibited clearly, with a label attached.\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn path() {\n        let matcher = RegexMatcher::new(\"Watson\").unwrap();\n        let mut printer =\n            StandardBuilder::new().path(false).build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(true)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink_with_path(&matcher, \"sherlock\"),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\n1:For the Doctor Watsons of this world, as opposed to the Sherlock\n5:but Doctor Watson has to have it taken out for him and dusted,\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn separator_field() {\n        let matcher = RegexMatcher::new(\"Watson\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .separator_field_match(b\"!!\".to_vec())\n            .separator_field_context(b\"^^\".to_vec())\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(false)\n            .before_context(1)\n            .after_context(1)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink_with_path(&matcher, \"sherlock\"),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\nsherlock!!For the Doctor Watsons of this world, as opposed to the Sherlock\nsherlock^^Holmeses, success in the province of detective work must always\n--\nsherlock^^can extract a clew from a wisp of straw or a flake of cigar ash;\nsherlock!!but Doctor Watson has to have it taken out for him and dusted,\nsherlock^^and exhibited clearly, with a label attached.\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn separator_path() {\n        let matcher = RegexMatcher::new(\"Watson\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .separator_path(Some(b'Z'))\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(false)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink_with_path(&matcher, \"books/sherlock\"),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\nbooksZsherlock:For the Doctor Watsons of this world, as opposed to the Sherlock\nbooksZsherlock:but Doctor Watson has to have it taken out for him and dusted,\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn path_terminator() {\n        let matcher = RegexMatcher::new(\"Watson\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .path_terminator(Some(b'Z'))\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(false)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink_with_path(&matcher, \"books/sherlock\"),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\nbooks/sherlockZFor the Doctor Watsons of this world, as opposed to the Sherlock\nbooks/sherlockZbut Doctor Watson has to have it taken out for him and dusted,\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn heading() {\n        let matcher = RegexMatcher::new(\"Watson\").unwrap();\n        let mut printer =\n            StandardBuilder::new().heading(true).build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(false)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink_with_path(&matcher, \"sherlock\"),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\nsherlock\nFor the Doctor Watsons of this world, as opposed to the Sherlock\nbut Doctor Watson has to have it taken out for him and dusted,\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn no_heading() {\n        let matcher = RegexMatcher::new(\"Watson\").unwrap();\n        let mut printer =\n            StandardBuilder::new().heading(false).build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(false)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink_with_path(&matcher, \"sherlock\"),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\nsherlock:For the Doctor Watsons of this world, as opposed to the Sherlock\nsherlock:but Doctor Watson has to have it taken out for him and dusted,\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn no_heading_multiple() {\n        let matcher = RegexMatcher::new(\"Watson\").unwrap();\n        let mut printer =\n            StandardBuilder::new().heading(false).build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(false)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink_with_path(&matcher, \"sherlock\"),\n            )\n            .unwrap();\n\n        let matcher = RegexMatcher::new(\"Sherlock\").unwrap();\n        SearcherBuilder::new()\n            .line_number(false)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink_with_path(&matcher, \"sherlock\"),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\nsherlock:For the Doctor Watsons of this world, as opposed to the Sherlock\nsherlock:but Doctor Watson has to have it taken out for him and dusted,\nsherlock:For the Doctor Watsons of this world, as opposed to the Sherlock\nsherlock:be, to a very large extent, the result of luck. Sherlock Holmes\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn heading_multiple() {\n        let matcher = RegexMatcher::new(\"Watson\").unwrap();\n        let mut printer =\n            StandardBuilder::new().heading(true).build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(false)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink_with_path(&matcher, \"sherlock\"),\n            )\n            .unwrap();\n\n        let matcher = RegexMatcher::new(\"Sherlock\").unwrap();\n        SearcherBuilder::new()\n            .line_number(false)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink_with_path(&matcher, \"sherlock\"),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\nsherlock\nFor the Doctor Watsons of this world, as opposed to the Sherlock\nbut Doctor Watson has to have it taken out for him and dusted,\nsherlock\nFor the Doctor Watsons of this world, as opposed to the Sherlock\nbe, to a very large extent, the result of luck. Sherlock Holmes\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn trim_ascii() {\n        let matcher = RegexMatcher::new(\"Watson\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .trim_ascii(true)\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(false)\n            .build()\n            .search_reader(\n                &matcher,\n                \"   Watson\".as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\nWatson\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn trim_ascii_multi_line() {\n        let matcher = RegexMatcher::new(\"(?s:.{0})Watson\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .trim_ascii(true)\n            .stats(true)\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(false)\n            .multi_line(true)\n            .build()\n            .search_reader(\n                &matcher,\n                \"   Watson\".as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\nWatson\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn trim_ascii_with_line_term() {\n        let matcher = RegexMatcher::new(\"Watson\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .trim_ascii(true)\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(true)\n            .before_context(1)\n            .build()\n            .search_reader(\n                &matcher,\n                \"\\n   Watson\".as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\n1-\n2:Watson\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn line_number() {\n        let matcher = RegexMatcher::new(\"Watson\").unwrap();\n        let mut printer = StandardBuilder::new().build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(true)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\n1:For the Doctor Watsons of this world, as opposed to the Sherlock\n5:but Doctor Watson has to have it taken out for him and dusted,\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn line_number_multi_line() {\n        let matcher = RegexMatcher::new(\"(?s)Watson.+Watson\").unwrap();\n        let mut printer = StandardBuilder::new().build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(true)\n            .multi_line(true)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\n1:For the Doctor Watsons of this world, as opposed to the Sherlock\n2:Holmeses, success in the province of detective work must always\n3:be, to a very large extent, the result of luck. Sherlock Holmes\n4:can extract a clew from a wisp of straw or a flake of cigar ash;\n5:but Doctor Watson has to have it taken out for him and dusted,\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn column_number() {\n        let matcher = RegexMatcher::new(\"Watson\").unwrap();\n        let mut printer =\n            StandardBuilder::new().column(true).build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(false)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\n16:For the Doctor Watsons of this world, as opposed to the Sherlock\n12:but Doctor Watson has to have it taken out for him and dusted,\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn column_number_multi_line() {\n        let matcher = RegexMatcher::new(\"(?s)Watson.+Watson\").unwrap();\n        let mut printer =\n            StandardBuilder::new().column(true).build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(false)\n            .multi_line(true)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\n16:For the Doctor Watsons of this world, as opposed to the Sherlock\n16:Holmeses, success in the province of detective work must always\n16:be, to a very large extent, the result of luck. Sherlock Holmes\n16:can extract a clew from a wisp of straw or a flake of cigar ash;\n16:but Doctor Watson has to have it taken out for him and dusted,\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn byte_offset() {\n        let matcher = RegexMatcher::new(\"Watson\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .byte_offset(true)\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(false)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\n0:For the Doctor Watsons of this world, as opposed to the Sherlock\n258:but Doctor Watson has to have it taken out for him and dusted,\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn byte_offset_multi_line() {\n        let matcher = RegexMatcher::new(\"(?s)Watson.+Watson\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .byte_offset(true)\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(false)\n            .multi_line(true)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\n0:For the Doctor Watsons of this world, as opposed to the Sherlock\n65:Holmeses, success in the province of detective work must always\n129:be, to a very large extent, the result of luck. Sherlock Holmes\n193:can extract a clew from a wisp of straw or a flake of cigar ash;\n258:but Doctor Watson has to have it taken out for him and dusted,\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn max_columns() {\n        let matcher = RegexMatcher::new(\"ash|dusted\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .max_columns(Some(63))\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(false)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\n[Omitted long matching line]\nbut Doctor Watson has to have it taken out for him and dusted,\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn max_columns_preview() {\n        let matcher = RegexMatcher::new(\"exhibited|dusted\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .max_columns(Some(46))\n            .max_columns_preview(true)\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(false)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\nbut Doctor Watson has to have it taken out for [... omitted end of long line]\nand exhibited clearly, with a label attached.\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn max_columns_with_count() {\n        let matcher = RegexMatcher::new(\"cigar|ash|dusted\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .stats(true)\n            .max_columns(Some(63))\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(false)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\n[Omitted long line with 2 matches]\nbut Doctor Watson has to have it taken out for him and dusted,\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn max_columns_with_count_preview_no_match() {\n        let matcher = RegexMatcher::new(\"exhibited|has to have it\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .stats(true)\n            .max_columns(Some(46))\n            .max_columns_preview(true)\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(false)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\nbut Doctor Watson has to have it taken out for [... 0 more matches]\nand exhibited clearly, with a label attached.\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn max_columns_with_count_preview_one_match() {\n        let matcher = RegexMatcher::new(\"exhibited|dusted\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .stats(true)\n            .max_columns(Some(46))\n            .max_columns_preview(true)\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(false)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\nbut Doctor Watson has to have it taken out for [... 1 more match]\nand exhibited clearly, with a label attached.\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn max_columns_with_count_preview_two_matches() {\n        let matcher =\n            RegexMatcher::new(\"exhibited|dusted|has to have it\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .stats(true)\n            .max_columns(Some(46))\n            .max_columns_preview(true)\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(false)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\nbut Doctor Watson has to have it taken out for [... 1 more match]\nand exhibited clearly, with a label attached.\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn max_columns_multi_line() {\n        let matcher = RegexMatcher::new(\"(?s)ash.+dusted\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .max_columns(Some(63))\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(false)\n            .multi_line(true)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\n[Omitted long matching line]\nbut Doctor Watson has to have it taken out for him and dusted,\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn max_columns_multi_line_preview() {\n        let matcher =\n            RegexMatcher::new(\"(?s)clew|cigar ash.+have it|exhibited\")\n                .unwrap();\n        let mut printer = StandardBuilder::new()\n            .stats(true)\n            .max_columns(Some(46))\n            .max_columns_preview(true)\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(false)\n            .multi_line(true)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\ncan extract a clew from a wisp of straw or a f [... 1 more match]\nbut Doctor Watson has to have it taken out for [... 0 more matches]\nand exhibited clearly, with a label attached.\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn max_matches() {\n        let matcher = RegexMatcher::new(\"Sherlock\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .max_matches(Some(1))\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(false)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\nFor the Doctor Watsons of this world, as opposed to the Sherlock\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn max_matches_context() {\n        // after context: 1\n        let matcher = RegexMatcher::new(\"Doctor Watsons\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .max_matches(Some(1))\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(false)\n            .after_context(1)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\nFor the Doctor Watsons of this world, as opposed to the Sherlock\nHolmeses, success in the province of detective work must always\n\";\n        assert_eq_printed!(expected, got);\n\n        // after context: 4\n        let mut printer = StandardBuilder::new()\n            .max_matches(Some(1))\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(false)\n            .after_context(4)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\nFor the Doctor Watsons of this world, as opposed to the Sherlock\nHolmeses, success in the province of detective work must always\nbe, to a very large extent, the result of luck. Sherlock Holmes\ncan extract a clew from a wisp of straw or a flake of cigar ash;\nbut Doctor Watson has to have it taken out for him and dusted,\n\";\n        assert_eq_printed!(expected, got);\n\n        // after context: 1, max matches: 2\n        let matcher = RegexMatcher::new(\"Doctor Watsons|but Doctor\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .max_matches(Some(2))\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(false)\n            .after_context(1)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\nFor the Doctor Watsons of this world, as opposed to the Sherlock\nHolmeses, success in the province of detective work must always\n--\nbut Doctor Watson has to have it taken out for him and dusted,\nand exhibited clearly, with a label attached.\n\";\n        assert_eq_printed!(expected, got);\n\n        // after context: 4, max matches: 2\n        let mut printer = StandardBuilder::new()\n            .max_matches(Some(2))\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(false)\n            .after_context(4)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\nFor the Doctor Watsons of this world, as opposed to the Sherlock\nHolmeses, success in the province of detective work must always\nbe, to a very large extent, the result of luck. Sherlock Holmes\ncan extract a clew from a wisp of straw or a flake of cigar ash;\nbut Doctor Watson has to have it taken out for him and dusted,\nand exhibited clearly, with a label attached.\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn max_matches_multi_line1() {\n        let matcher = RegexMatcher::new(\"(?s:.{0})Sherlock\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .max_matches(Some(1))\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(false)\n            .multi_line(true)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\nFor the Doctor Watsons of this world, as opposed to the Sherlock\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn max_matches_multi_line2() {\n        let matcher =\n            RegexMatcher::new(r\"(?s)Watson.+?(Holmeses|clearly)\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .max_matches(Some(1))\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(false)\n            .multi_line(true)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\nFor the Doctor Watsons of this world, as opposed to the Sherlock\nHolmeses, success in the province of detective work must always\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn only_matching() {\n        let matcher = RegexMatcher::new(\"Doctor Watsons|Sherlock\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .only_matching(true)\n            .column(true)\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(true)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\n1:9:Doctor Watsons\n1:57:Sherlock\n3:49:Sherlock\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn only_matching_multi_line1() {\n        let matcher =\n            RegexMatcher::new(r\"(?s:.{0})(Doctor Watsons|Sherlock)\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .only_matching(true)\n            .column(true)\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .multi_line(true)\n            .line_number(true)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\n1:9:Doctor Watsons\n1:57:Sherlock\n3:49:Sherlock\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn only_matching_multi_line2() {\n        let matcher =\n            RegexMatcher::new(r\"(?s)Watson.+?(Holmeses|clearly)\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .only_matching(true)\n            .column(true)\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .multi_line(true)\n            .line_number(true)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\n1:16:Watsons of this world, as opposed to the Sherlock\n2:16:Holmeses\n5:12:Watson has to have it taken out for him and dusted,\n6:12:and exhibited clearly\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn only_matching_max_columns() {\n        let matcher = RegexMatcher::new(\"Doctor Watsons|Sherlock\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .only_matching(true)\n            .max_columns(Some(10))\n            .column(true)\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(true)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\n1:9:[Omitted long matching line]\n1:57:Sherlock\n3:49:Sherlock\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn only_matching_max_columns_preview() {\n        let matcher = RegexMatcher::new(\"Doctor Watsons|Sherlock\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .only_matching(true)\n            .max_columns(Some(10))\n            .max_columns_preview(true)\n            .column(true)\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(true)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\n1:9:Doctor Wat [... 0 more matches]\n1:57:Sherlock\n3:49:Sherlock\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn only_matching_max_columns_multi_line1() {\n        // The `(?s:.{0})` trick fools the matcher into thinking that it\n        // can match across multiple lines without actually doing so. This is\n        // so we can test multi-line handling in the case of a match on only\n        // one line.\n        let matcher =\n            RegexMatcher::new(r\"(?s:.{0})(Doctor Watsons|Sherlock)\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .only_matching(true)\n            .max_columns(Some(10))\n            .column(true)\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .multi_line(true)\n            .line_number(true)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\n1:9:[Omitted long matching line]\n1:57:Sherlock\n3:49:Sherlock\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn only_matching_max_columns_preview_multi_line1() {\n        // The `(?s:.{0})` trick fools the matcher into thinking that it\n        // can match across multiple lines without actually doing so. This is\n        // so we can test multi-line handling in the case of a match on only\n        // one line.\n        let matcher =\n            RegexMatcher::new(r\"(?s:.{0})(Doctor Watsons|Sherlock)\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .only_matching(true)\n            .max_columns(Some(10))\n            .max_columns_preview(true)\n            .column(true)\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .multi_line(true)\n            .line_number(true)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\n1:9:Doctor Wat [... 0 more matches]\n1:57:Sherlock\n3:49:Sherlock\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn only_matching_max_columns_multi_line2() {\n        let matcher =\n            RegexMatcher::new(r\"(?s)Watson.+?(Holmeses|clearly)\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .only_matching(true)\n            .max_columns(Some(50))\n            .column(true)\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .multi_line(true)\n            .line_number(true)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\n1:16:Watsons of this world, as opposed to the Sherlock\n2:16:Holmeses\n5:12:[Omitted long matching line]\n6:12:and exhibited clearly\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn only_matching_max_columns_preview_multi_line2() {\n        let matcher =\n            RegexMatcher::new(r\"(?s)Watson.+?(Holmeses|clearly)\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .only_matching(true)\n            .max_columns(Some(50))\n            .max_columns_preview(true)\n            .column(true)\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .multi_line(true)\n            .line_number(true)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\n1:16:Watsons of this world, as opposed to the Sherlock\n2:16:Holmeses\n5:12:Watson has to have it taken out for him and dusted [... 0 more matches]\n6:12:and exhibited clearly\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn per_match() {\n        let matcher = RegexMatcher::new(\"Doctor Watsons|Sherlock\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .per_match(true)\n            .column(true)\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(true)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\n1:9:For the Doctor Watsons of this world, as opposed to the Sherlock\n1:57:For the Doctor Watsons of this world, as opposed to the Sherlock\n3:49:be, to a very large extent, the result of luck. Sherlock Holmes\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn per_match_multi_line1() {\n        let matcher =\n            RegexMatcher::new(r\"(?s:.{0})(Doctor Watsons|Sherlock)\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .per_match(true)\n            .column(true)\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .multi_line(true)\n            .line_number(true)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\n1:9:For the Doctor Watsons of this world, as opposed to the Sherlock\n1:57:For the Doctor Watsons of this world, as opposed to the Sherlock\n3:49:be, to a very large extent, the result of luck. Sherlock Holmes\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn per_match_multi_line2() {\n        let matcher =\n            RegexMatcher::new(r\"(?s)Watson.+?(Holmeses|clearly)\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .per_match(true)\n            .column(true)\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .multi_line(true)\n            .line_number(true)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\n1:16:For the Doctor Watsons of this world, as opposed to the Sherlock\n2:1:Holmeses, success in the province of detective work must always\n5:12:but Doctor Watson has to have it taken out for him and dusted,\n6:1:and exhibited clearly, with a label attached.\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn per_match_multi_line3() {\n        let matcher =\n            RegexMatcher::new(r\"(?s)Watson.+?Holmeses|always.+?be\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .per_match(true)\n            .column(true)\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .multi_line(true)\n            .line_number(true)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\n1:16:For the Doctor Watsons of this world, as opposed to the Sherlock\n2:1:Holmeses, success in the province of detective work must always\n2:58:Holmeses, success in the province of detective work must always\n3:1:be, to a very large extent, the result of luck. Sherlock Holmes\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn per_match_multi_line1_only_first_line() {\n        let matcher =\n            RegexMatcher::new(r\"(?s:.{0})(Doctor Watsons|Sherlock)\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .per_match(true)\n            .per_match_one_line(true)\n            .column(true)\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .multi_line(true)\n            .line_number(true)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\n1:9:For the Doctor Watsons of this world, as opposed to the Sherlock\n1:57:For the Doctor Watsons of this world, as opposed to the Sherlock\n3:49:be, to a very large extent, the result of luck. Sherlock Holmes\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn per_match_multi_line2_only_first_line() {\n        let matcher =\n            RegexMatcher::new(r\"(?s)Watson.+?(Holmeses|clearly)\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .per_match(true)\n            .per_match_one_line(true)\n            .column(true)\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .multi_line(true)\n            .line_number(true)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\n1:16:For the Doctor Watsons of this world, as opposed to the Sherlock\n5:12:but Doctor Watson has to have it taken out for him and dusted,\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn per_match_multi_line3_only_first_line() {\n        let matcher =\n            RegexMatcher::new(r\"(?s)Watson.+?Holmeses|always.+?be\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .per_match(true)\n            .per_match_one_line(true)\n            .column(true)\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .multi_line(true)\n            .line_number(true)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\n1:16:For the Doctor Watsons of this world, as opposed to the Sherlock\n2:58:Holmeses, success in the province of detective work must always\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn replacement_passthru() {\n        let matcher = RegexMatcher::new(r\"Sherlock|Doctor (\\w+)\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .replacement(Some(b\"doctah $1 MD\".to_vec()))\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(true)\n            .passthru(true)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\n1:For the doctah Watsons MD of this world, as opposed to the doctah  MD\n2-Holmeses, success in the province of detective work must always\n3:be, to a very large extent, the result of luck. doctah  MD Holmes\n4-can extract a clew from a wisp of straw or a flake of cigar ash;\n5:but doctah Watson MD has to have it taken out for him and dusted,\n6-and exhibited clearly, with a label attached.\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn replacement() {\n        let matcher = RegexMatcher::new(r\"Sherlock|Doctor (\\w+)\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .replacement(Some(b\"doctah $1 MD\".to_vec()))\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(true)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\n1:For the doctah Watsons MD of this world, as opposed to the doctah  MD\n3:be, to a very large extent, the result of luck. doctah  MD Holmes\n5:but doctah Watson MD has to have it taken out for him and dusted,\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    // This is a somewhat weird test that checks the behavior of attempting\n    // to replace a line terminator with something else.\n    //\n    // See: https://github.com/BurntSushi/ripgrep/issues/1311\n    #[test]\n    fn replacement_multi_line() {\n        let matcher = RegexMatcher::new(r\"\\n\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .replacement(Some(b\"?\".to_vec()))\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(true)\n            .multi_line(true)\n            .build()\n            .search_reader(\n                &matcher,\n                \"hello\\nworld\\n\".as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"1:hello?world?\\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn replacement_multi_line_diff_line_term() {\n        let matcher = RegexMatcherBuilder::new()\n            .line_terminator(Some(b'\\x00'))\n            .build(r\"\\n\")\n            .unwrap();\n        let mut printer = StandardBuilder::new()\n            .replacement(Some(b\"?\".to_vec()))\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_terminator(LineTerminator::byte(b'\\x00'))\n            .line_number(true)\n            .multi_line(true)\n            .build()\n            .search_reader(\n                &matcher,\n                \"hello\\nworld\\n\".as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"1:hello?world?\\x00\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn replacement_multi_line_combine_lines() {\n        let matcher = RegexMatcher::new(r\"\\n(.)?\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .replacement(Some(b\"?$1\".to_vec()))\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(true)\n            .multi_line(true)\n            .build()\n            .search_reader(\n                &matcher,\n                \"hello\\nworld\\n\".as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"1:hello?world?\\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn replacement_max_columns() {\n        let matcher = RegexMatcher::new(r\"Sherlock|Doctor (\\w+)\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .max_columns(Some(67))\n            .replacement(Some(b\"doctah $1 MD\".to_vec()))\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(true)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\n1:[Omitted long line with 2 matches]\n3:be, to a very large extent, the result of luck. doctah  MD Holmes\n5:but doctah Watson MD has to have it taken out for him and dusted,\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn replacement_max_columns_preview1() {\n        let matcher = RegexMatcher::new(r\"Sherlock|Doctor (\\w+)\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .max_columns(Some(67))\n            .max_columns_preview(true)\n            .replacement(Some(b\"doctah $1 MD\".to_vec()))\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(true)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\n1:For the doctah Watsons MD of this world, as opposed to the doctah   [... 0 more matches]\n3:be, to a very large extent, the result of luck. doctah  MD Holmes\n5:but doctah Watson MD has to have it taken out for him and dusted,\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn replacement_max_columns_preview2() {\n        let matcher =\n            RegexMatcher::new(\"exhibited|dusted|has to have it\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .max_columns(Some(43))\n            .max_columns_preview(true)\n            .replacement(Some(b\"xxx\".to_vec()))\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(false)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\nbut Doctor Watson xxx taken out for him and [... 1 more match]\nand xxx clearly, with a label attached.\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn replacement_only_matching() {\n        let matcher = RegexMatcher::new(r\"Sherlock|Doctor (\\w+)\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .only_matching(true)\n            .replacement(Some(b\"doctah $1 MD\".to_vec()))\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(true)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\n1:doctah Watsons MD\n1:doctah  MD\n3:doctah  MD\n5:doctah Watson MD\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn replacement_per_match() {\n        let matcher = RegexMatcher::new(r\"Sherlock|Doctor (\\w+)\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .per_match(true)\n            .replacement(Some(b\"doctah $1 MD\".to_vec()))\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(true)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\n1:For the doctah Watsons MD of this world, as opposed to the doctah  MD\n1:For the doctah Watsons MD of this world, as opposed to the doctah  MD\n3:be, to a very large extent, the result of luck. doctah  MD Holmes\n5:but doctah Watson MD has to have it taken out for him and dusted,\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn invert() {\n        let matcher = RegexMatcher::new(r\"Sherlock\").unwrap();\n        let mut printer = StandardBuilder::new().build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(true)\n            .invert_match(true)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\n2:Holmeses, success in the province of detective work must always\n4:can extract a clew from a wisp of straw or a flake of cigar ash;\n5:but Doctor Watson has to have it taken out for him and dusted,\n6:and exhibited clearly, with a label attached.\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn invert_multi_line() {\n        let matcher = RegexMatcher::new(r\"(?s:.{0})Sherlock\").unwrap();\n        let mut printer = StandardBuilder::new().build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .multi_line(true)\n            .line_number(true)\n            .invert_match(true)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\n2:Holmeses, success in the province of detective work must always\n4:can extract a clew from a wisp of straw or a flake of cigar ash;\n5:but Doctor Watson has to have it taken out for him and dusted,\n6:and exhibited clearly, with a label attached.\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn invert_context() {\n        let matcher = RegexMatcher::new(r\"Sherlock\").unwrap();\n        let mut printer = StandardBuilder::new().build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(true)\n            .invert_match(true)\n            .before_context(1)\n            .after_context(1)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\n1-For the Doctor Watsons of this world, as opposed to the Sherlock\n2:Holmeses, success in the province of detective work must always\n3-be, to a very large extent, the result of luck. Sherlock Holmes\n4:can extract a clew from a wisp of straw or a flake of cigar ash;\n5:but Doctor Watson has to have it taken out for him and dusted,\n6:and exhibited clearly, with a label attached.\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn invert_context_multi_line() {\n        let matcher = RegexMatcher::new(r\"(?s:.{0})Sherlock\").unwrap();\n        let mut printer = StandardBuilder::new().build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .multi_line(true)\n            .line_number(true)\n            .invert_match(true)\n            .before_context(1)\n            .after_context(1)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\n1-For the Doctor Watsons of this world, as opposed to the Sherlock\n2:Holmeses, success in the province of detective work must always\n3-be, to a very large extent, the result of luck. Sherlock Holmes\n4:can extract a clew from a wisp of straw or a flake of cigar ash;\n5:but Doctor Watson has to have it taken out for him and dusted,\n6:and exhibited clearly, with a label attached.\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn invert_context_only_matching() {\n        let matcher = RegexMatcher::new(r\"Sherlock\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .only_matching(true)\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(true)\n            .invert_match(true)\n            .before_context(1)\n            .after_context(1)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\n1-Sherlock\n2:Holmeses, success in the province of detective work must always\n3-Sherlock\n4:can extract a clew from a wisp of straw or a flake of cigar ash;\n5:but Doctor Watson has to have it taken out for him and dusted,\n6:and exhibited clearly, with a label attached.\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn invert_context_only_matching_multi_line() {\n        let matcher = RegexMatcher::new(r\"(?s:.{0})Sherlock\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .only_matching(true)\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .multi_line(true)\n            .line_number(true)\n            .invert_match(true)\n            .before_context(1)\n            .after_context(1)\n            .build()\n            .search_reader(\n                &matcher,\n                SHERLOCK.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"\\\n1-Sherlock\n2:Holmeses, success in the province of detective work must always\n3-Sherlock\n4:can extract a clew from a wisp of straw or a flake of cigar ash;\n5:but Doctor Watson has to have it taken out for him and dusted,\n6:and exhibited clearly, with a label attached.\n\";\n        assert_eq_printed!(expected, got);\n    }\n\n    #[test]\n    fn regression_search_empty_with_crlf() {\n        let matcher =\n            RegexMatcherBuilder::new().crlf(true).build(r\"x?\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .color_specs(ColorSpecs::default_with_color())\n            .build(Ansi::new(vec![]));\n        SearcherBuilder::new()\n            .line_terminator(LineTerminator::crlf())\n            .build()\n            .search_reader(&matcher, &b\"\\n\"[..], printer.sink(&matcher))\n            .unwrap();\n\n        let got = printer_contents_ansi(&mut printer);\n        assert!(!got.is_empty());\n    }\n\n    #[test]\n    fn regression_after_context_with_match() {\n        let haystack = \"\\\na\nb\nc\nd\ne\nd\ne\nd\ne\nd\ne\n\";\n\n        let matcher = RegexMatcherBuilder::new().build(r\"d\").unwrap();\n        let mut printer = StandardBuilder::new()\n            .max_matches(Some(1))\n            .build(NoColor::new(vec![]));\n        SearcherBuilder::new()\n            .line_number(true)\n            .after_context(2)\n            .build()\n            .search_reader(\n                &matcher,\n                haystack.as_bytes(),\n                printer.sink(&matcher),\n            )\n            .unwrap();\n\n        let got = printer_contents(&mut printer);\n        let expected = \"4:d\\n5-e\\n6:d\\n\";\n        assert_eq_printed!(expected, got);\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "56bc227076acc6a6af46573406d36562d8acae05",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/ripgrep/crates/cli/src/process.rs",
    "func": "use std::{\n    io::{self, Read},\n    process,\n};\n\n/// An error that can occur while running a command and reading its output.\n///\n/// This error can be seamlessly converted to an `io::Error` via a `From`\n/// implementation.\n#[derive(Debug)]\npub struct CommandError {\n    kind: CommandErrorKind,\n}\n\n#[derive(Debug)]\nenum CommandErrorKind {\n    Io(io::Error),\n    Stderr(Vec<u8>),\n}\n\nimpl CommandError {\n    /// Create an error from an I/O error.\n    pub(crate) fn io(ioerr: io::Error) -> CommandError {\n        CommandError { kind: CommandErrorKind::Io(ioerr) }\n    }\n\n    /// Create an error from the contents of stderr (which may be empty).\n    pub(crate) fn stderr(bytes: Vec<u8>) -> CommandError {\n        CommandError { kind: CommandErrorKind::Stderr(bytes) }\n    }\n\n    /// Returns true if and only if this error has empty data from stderr.\n    pub(crate) fn is_empty(&self) -> bool {\n        match self.kind {\n            CommandErrorKind::Stderr(ref bytes) => bytes.is_empty(),\n            _ => false,\n        }\n    }\n}\n\nimpl std::error::Error for CommandError {}\n\nimpl std::fmt::Display for CommandError {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self.kind {\n            CommandErrorKind::Io(ref e) => e.fmt(f),\n            CommandErrorKind::Stderr(ref bytes) => {\n                let msg = String::from_utf8_lossy(bytes);\n                if msg.trim().is_empty() {\n                    write!(f, \"<stderr is empty>\")\n                } else {\n                    let div = \"-\".repeat(79);\n                    write!(\n                        f,\n                        \"\\n{div}\\n{msg}\\n{div}\",\n                        div = div,\n                        msg = msg.trim()\n                    )\n                }\n            }\n        }\n    }\n}\n\nimpl From<io::Error> for CommandError {\n    fn from(ioerr: io::Error) -> CommandError {\n        CommandError { kind: CommandErrorKind::Io(ioerr) }\n    }\n}\n\nimpl From<CommandError> for io::Error {\n    fn from(cmderr: CommandError) -> io::Error {\n        match cmderr.kind {\n            CommandErrorKind::Io(ioerr) => ioerr,\n            CommandErrorKind::Stderr(_) => {\n                io::Error::new(io::ErrorKind::Other, cmderr)\n            }\n        }\n    }\n}\n\n/// Configures and builds a streaming reader for process output.\n#[derive(Clone, Debug, Default)]\npub struct CommandReaderBuilder {\n    async_stderr: bool,\n}\n\nimpl CommandReaderBuilder {\n    /// Create a new builder with the default configuration.\n    pub fn new() -> CommandReaderBuilder {\n        CommandReaderBuilder::default()\n    }\n\n    /// Build a new streaming reader for the given command's output.\n    ///\n    /// The caller should set everything that's required on the given command\n    /// before building a reader, such as its arguments, environment and\n    /// current working directory. Settings such as the stdout and stderr (but\n    /// not stdin) pipes will be overridden so that they can be controlled by\n    /// the reader.\n    ///\n    /// If there was a problem spawning the given command, then its error is\n    /// returned.\n    pub fn build(\n        &self,\n        command: &mut process::Command,\n    ) -> Result<CommandReader, CommandError> {\n        let mut child = command\n            .stdout(process::Stdio::piped())\n            .stderr(process::Stdio::piped())\n            .spawn()?;\n        let stderr = if self.async_stderr {\n            StderrReader::r#async(child.stderr.take().unwrap())\n        } else {\n            StderrReader::sync(child.stderr.take().unwrap())\n        };\n        Ok(CommandReader { child, stderr, eof: false })\n    }\n\n    /// When enabled, the reader will asynchronously read the contents of the\n    /// command's stderr output. When disabled, stderr is only read after the\n    /// stdout stream has been exhausted (or if the process quits with an error\n    /// code).\n    ///\n    /// Note that when enabled, this may require launching an additional\n    /// thread in order to read stderr. This is done so that the process being\n    /// executed is never blocked from writing to stdout or stderr. If this is\n    /// disabled, then it is possible for the process to fill up the stderr\n    /// buffer and deadlock.\n    ///\n    /// This is enabled by default.\n    pub fn async_stderr(&mut self, yes: bool) -> &mut CommandReaderBuilder {\n        self.async_stderr = yes;\n        self\n    }\n}\n\n/// A streaming reader for a command's output.\n///\n/// The purpose of this reader is to provide an easy way to execute processes\n/// whose stdout is read in a streaming way while also making the processes'\n/// stderr available when the process fails with an exit code. This makes it\n/// possible to execute processes while surfacing the underlying failure mode\n/// in the case of an error.\n///\n/// Moreover, by default, this reader will asynchronously read the processes'\n/// stderr. This prevents subtle deadlocking bugs for noisy processes that\n/// write a lot to stderr. Currently, the entire contents of stderr is read\n/// on to the heap.\n///\n/// # Example\n///\n/// This example shows how to invoke `gzip` to decompress the contents of a\n/// file. If the `gzip` command reports a failing exit status, then its stderr\n/// is returned as an error.\n///\n/// ```no_run\n/// use std::{io::Read, process::Command};\n///\n/// use grep_cli::CommandReader;\n///\n/// let mut cmd = Command::new(\"gzip\");\n/// cmd.arg(\"-d\").arg(\"-c\").arg(\"/usr/share/man/man1/ls.1.gz\");\n///\n/// let mut rdr = CommandReader::new(&mut cmd)?;\n/// let mut contents = vec![];\n/// rdr.read_to_end(&mut contents)?;\n/// # Ok::<(), Box<dyn std::error::Error>>(())\n/// ```\n#[derive(Debug)]\npub struct CommandReader {\n    child: process::Child,\n    stderr: StderrReader,\n    /// This is set to true once 'read' returns zero bytes. When this isn't\n    /// set and we close the reader, then we anticipate a pipe error when\n    /// reaping the child process and silence it.\n    eof: bool,\n}\n\nimpl CommandReader {\n    /// Create a new streaming reader for the given command using the default\n    /// configuration.\n    ///\n    /// The caller should set everything that's required on the given command\n    /// before building a reader, such as its arguments, environment and\n    /// current working directory. Settings such as the stdout and stderr (but\n    /// not stdin) pipes will be overridden so that they can be controlled by\n    /// the reader.\n    ///\n    /// If there was a problem spawning the given command, then its error is\n    /// returned.\n    ///\n    /// If the caller requires additional configuration for the reader\n    /// returned, then use [`CommandReaderBuilder`].\n    pub fn new(\n        cmd: &mut process::Command,\n    ) -> Result<CommandReader, CommandError> {\n        CommandReaderBuilder::new().build(cmd)\n    }\n\n    /// Closes the CommandReader, freeing any resources used by its underlying\n    /// child process. If the child process exits with a nonzero exit code, the\n    /// returned Err value will include its stderr.\n    ///\n    /// `close` is idempotent, meaning it can be safely called multiple times.\n    /// The first call closes the CommandReader and any subsequent calls do\n    /// nothing.\n    ///\n    /// This method should be called after partially reading a file to prevent\n    /// resource leakage. However there is no need to call `close` explicitly\n    /// if your code always calls `read` to EOF, as `read` takes care of\n    /// calling `close` in this case.\n    ///\n    /// `close` is also called in `drop` as a last line of defense against\n    /// resource leakage. Any error from the child process is then printed as a\n    /// warning to stderr. This can be avoided by explicitly calling `close`\n    /// before the CommandReader is dropped.\n    pub fn close(&mut self) -> io::Result<()> {\n        // Dropping stdout closes the underlying file descriptor, which should\n        // cause a well-behaved child process to exit. If child.stdout is None\n        // we assume that close() has already been called and do nothing.\n        let stdout = match self.child.stdout.take() {\n            None => return Ok(()),\n            Some(stdout) => stdout,\n        };\n        drop(stdout);\n        if self.child.wait()?.success() {\n            Ok(())\n        } else {\n            let err = self.stderr.read_to_end();\n            // In the specific case where we haven't consumed the full data\n            // from the child process, then closing stdout above results in\n            // a pipe signal being thrown in most cases. But I don't think\n            // there is any reliable and portable way of detecting it. Instead,\n            // if we know we haven't hit EOF (so we anticipate a broken pipe\n            // error) and if stderr otherwise doesn't have anything on it, then\n            // we assume total success.\n            if !self.eof && err.is_empty() {\n                return Ok(());\n            }\n            Err(io::Error::from(err))\n        }\n    }\n}\n\nimpl Drop for CommandReader {\n    fn drop(&mut self) {\n        if let Err(error) = self.close() {\n            log::warn!(\"{}\", error);\n        }\n    }\n}\n\nimpl io::Read for CommandReader {\n    fn read(&mut self, buf: &mut [u8]) -> io::Result<usize> {\n        let stdout = match self.child.stdout {\n            None => return Ok(0),\n            Some(ref mut stdout) => stdout,\n        };\n        let nread = stdout.read(buf)?;\n        if nread == 0 {\n            self.eof = true;\n            self.close().map(|_| 0)\n        } else {\n            Ok(nread)\n        }\n    }\n}\n\n/// A reader that encapsulates the asynchronous or synchronous reading of\n/// stderr.\n#[derive(Debug)]\nenum StderrReader {\n    Async(Option<std::thread::JoinHandle<CommandError>>),\n    Sync(process::ChildStderr),\n}\n\nimpl StderrReader {\n    /// Create a reader for stderr that reads contents asynchronously.\n    fn r#async(mut stderr: process::ChildStderr) -> StderrReader {\n        let handle =\n            std::thread::spawn(move || stderr_to_command_error(&mut stderr));\n        StderrReader::Async(Some(handle))\n    }\n\n    /// Create a reader for stderr that reads contents synchronously.\n    fn sync(stderr: process::ChildStderr) -> StderrReader {\n        StderrReader::Sync(stderr)\n    }\n\n    /// Consumes all of stderr on to the heap and returns it as an error.\n    ///\n    /// If there was a problem reading stderr itself, then this returns an I/O\n    /// command error.\n    fn read_to_end(&mut self) -> CommandError {\n        match *self {\n            StderrReader::Async(ref mut handle) => {\n                let handle = handle\n                    .take()\n                    .expect(\"read_to_end cannot be called more than once\");\n                handle.join().expect(\"stderr reading thread does not panic\")\n            }\n            StderrReader::Sync(ref mut stderr) => {\n                stderr_to_command_error(stderr)\n            }\n        }\n    }\n}\n\nfn stderr_to_command_error(stderr: &mut process::ChildStderr) -> CommandError {\n    let mut bytes = vec![];\n    match stderr.read_to_end(&mut bytes) {\n        Ok(_) => CommandError::stderr(bytes),\n        Err(err) => CommandError::io(err),\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "88ec52c17251e8c485ef53544534c97e24257b16",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/tests/sql_err_tests.rs",
    "func": "#![allow(unused_imports, dead_code)]\n\npub mod common;\npub use common::{bakery_chain::*, setup::*, TestContext};\npub use sea_orm::{\n    entity::*, error::DbErr, error::SqlErr, tests_cfg, ConnectionTrait, DatabaseConnection,\n    DbBackend, EntityName, ExecResult,\n};\nuse uuid::Uuid;\n\n#[sea_orm_macros::test]\nasync fn main() {\n    let ctx = TestContext::new(\"bakery_chain_sql_err_tests\").await;\n    create_tables(&ctx.db).await.unwrap();\n    test_error(&ctx.db).await;\n    ctx.delete().await;\n}\n\npub async fn test_error(db: &DatabaseConnection) {\n    let mud_cake = cake::ActiveModel {\n        name: Set(\"Moldy Cake\".to_owned()),\n        price: Set(rust_dec(10.25)),\n        gluten_free: Set(false),\n        serial: Set(Uuid::new_v4()),\n        bakery_id: Set(None),\n        ..Default::default()\n    };\n\n    let cake = mud_cake.save(db).await.expect(\"could not insert cake\");\n\n    // if compiling without sqlx, this assignment will complain,\n    // but the whole test is useless in that case anyway.\n    #[allow(unused_variables)]\n    let error: DbErr = cake\n        .into_active_model()\n        .insert(db)\n        .await\n        .expect_err(\"inserting should fail due to duplicate primary key\");\n\n    assert!(matches!(\n        error.sql_err(),\n        Some(SqlErr::UniqueConstraintViolation(_))\n    ));\n\n    let fk_cake = cake::ActiveModel {\n        name: Set(\"fk error Cake\".to_owned()),\n        price: Set(rust_dec(10.25)),\n        gluten_free: Set(false),\n        serial: Set(Uuid::new_v4()),\n        bakery_id: Set(Some(1000)),\n        ..Default::default()\n    };\n\n    let fk_error = fk_cake\n        .insert(db)\n        .await\n        .expect_err(\"create foreign key should fail with non-primary key\");\n\n    assert!(matches!(\n        fk_error.sql_err(),\n        Some(SqlErr::ForeignKeyConstraintViolation(_))\n    ));\n\n    let invalid_error = DbErr::Custom(\"random error\".to_string());\n    assert_eq!(invalid_error.sql_err(), None)\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "7fcfca30be24ec93bff0822e8f4a58ec3eda2647",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/tests/connection_tests.rs",
    "func": "#![allow(unused_imports, dead_code)]\n\npub mod common;\n\npub use common::{bakery_chain::*, setup::*, TestContext};\nuse pretty_assertions::assert_eq;\nuse sea_orm::prelude::*;\n\n#[sea_orm_macros::test]\npub async fn connection_ping() {\n    let ctx = TestContext::new(\"connection_ping\").await;\n\n    ctx.db.ping().await.unwrap();\n\n    ctx.delete().await;\n}\n\n#[sea_orm_macros::test]\n#[cfg(feature = \"sqlx-mysql\")]\npub async fn connection_ping_closed_mysql() {\n    let ctx = std::rc::Rc::new(Box::new(TestContext::new(\"connection_ping_closed\").await));\n    let ctx_ping = std::rc::Rc::clone(&ctx);\n\n    ctx.db.get_mysql_connection_pool().close().await;\n    assert_eq!(\n        ctx_ping.db.ping().await,\n        Err(DbErr::ConnectionAcquire(ConnAcquireErr::ConnectionClosed))\n    );\n\n    let base_url = std::env::var(\"DATABASE_URL\").unwrap();\n    let mut opt = sea_orm::ConnectOptions::new(format!(\"{base_url}/connection_ping_closed\"));\n    opt\n        // The connection pool has a single connection only\n        .max_connections(1)\n        // A controlled connection acquire timeout\n        .acquire_timeout(std::time::Duration::from_secs(2));\n\n    let db = sea_orm::Database::connect(opt).await.unwrap();\n\n    async fn transaction_blocked(db: &DatabaseConnection) {\n        let _txn = sea_orm::TransactionTrait::begin(db).await.unwrap();\n        // Occupy the only connection, thus forcing others fail to acquire connection\n        tokio::time::sleep(std::time::Duration::from_secs(3)).await;\n    }\n\n    async fn transaction(db: &DatabaseConnection) {\n        // Should fail to acquire\n        let txn = sea_orm::TransactionTrait::begin(db).await;\n        assert_eq!(\n            txn.expect_err(\"should be a time out\"),\n            crate::DbErr::ConnectionAcquire(ConnAcquireErr::Timeout)\n        )\n    }\n\n    tokio::join!(transaction_blocked(&db), transaction(&db));\n\n    ctx.delete().await;\n}\n\n#[sea_orm_macros::test]\n#[cfg(feature = \"sqlx-sqlite\")]\npub async fn connection_ping_closed_sqlite() {\n    let ctx = std::rc::Rc::new(Box::new(TestContext::new(\"connection_ping_closed\").await));\n    let ctx_ping = std::rc::Rc::clone(&ctx);\n\n    ctx.db.get_sqlite_connection_pool().close().await;\n    assert_eq!(\n        ctx_ping.db.ping().await,\n        Err(DbErr::ConnectionAcquire(ConnAcquireErr::ConnectionClosed))\n    );\n\n    let base_url = std::env::var(\"DATABASE_URL\").unwrap();\n    let mut opt = sea_orm::ConnectOptions::new(base_url);\n    opt\n        // The connection pool has a single connection only\n        .max_connections(1)\n        // A controlled connection acquire timeout\n        .acquire_timeout(std::time::Duration::from_secs(2));\n\n    let db = sea_orm::Database::connect(opt).await.unwrap();\n\n    async fn transaction_blocked(db: &DatabaseConnection) {\n        let _txn = sea_orm::TransactionTrait::begin(db).await.unwrap();\n        // Occupy the only connection, thus forcing others fail to acquire connection\n        tokio::time::sleep(std::time::Duration::from_secs(3)).await;\n    }\n\n    async fn transaction(db: &DatabaseConnection) {\n        // Should fail to acquire\n        let txn = sea_orm::TransactionTrait::begin(db).await;\n        assert_eq!(\n            txn.expect_err(\"should be a time out\"),\n            crate::DbErr::ConnectionAcquire(ConnAcquireErr::Timeout)\n        )\n    }\n\n    tokio::join!(transaction_blocked(&db), transaction(&db));\n\n    ctx.delete().await;\n}\n\n#[sea_orm_macros::test]\n#[cfg(feature = \"sqlx-postgres\")]\npub async fn connection_ping_closed_postgres() {\n    let ctx = std::rc::Rc::new(Box::new(TestContext::new(\"connection_ping_closed\").await));\n    let ctx_ping = std::rc::Rc::clone(&ctx);\n\n    ctx.db.get_postgres_connection_pool().close().await;\n    assert_eq!(\n        ctx_ping.db.ping().await,\n        Err(DbErr::ConnectionAcquire(ConnAcquireErr::ConnectionClosed))\n    );\n\n    let base_url = std::env::var(\"DATABASE_URL\").unwrap();\n    let mut opt = sea_orm::ConnectOptions::new(format!(\"{base_url}/connection_ping_closed\"));\n    opt\n        // The connection pool has a single connection only\n        .max_connections(1)\n        // A controlled connection acquire timeout\n        .acquire_timeout(std::time::Duration::from_secs(2));\n\n    let db = sea_orm::Database::connect(opt).await.unwrap();\n\n    async fn transaction_blocked(db: &DatabaseConnection) {\n        let _txn = sea_orm::TransactionTrait::begin(db).await.unwrap();\n        // Occupy the only connection, thus forcing others fail to acquire connection\n        tokio::time::sleep(std::time::Duration::from_secs(3)).await;\n    }\n\n    async fn transaction(db: &DatabaseConnection) {\n        // Should fail to acquire\n        let txn = sea_orm::TransactionTrait::begin(db).await;\n        assert_eq!(\n            txn.expect_err(\"should be a time out\"),\n            crate::DbErr::ConnectionAcquire(ConnAcquireErr::Timeout)\n        )\n    }\n\n    tokio::join!(transaction_blocked(&db), transaction(&db));\n\n    ctx.delete().await;\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "fc19363fc0a05579bd170b34315f50cdc0075480",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/tests/crud/updates.rs",
    "func": "pub use super::*;\nuse sea_orm::{query::*, DbErr};\nuse uuid::Uuid;\n\npub async fn test_update_cake(db: &DbConn) {\n    let seaside_bakery = bakery::ActiveModel {\n        name: Set(\"SeaSide Bakery\".to_owned()),\n        profit_margin: Set(10.4),\n        ..Default::default()\n    };\n    let bakery_insert_res = Bakery::insert(seaside_bakery)\n        .exec(db)\n        .await\n        .expect(\"could not insert bakery\");\n\n    let mud_cake = cake::ActiveModel {\n        name: Set(\"Mud Cake\".to_owned()),\n        price: Set(rust_dec(10.25)),\n        gluten_free: Set(false),\n        serial: Set(Uuid::new_v4()),\n        bakery_id: Set(Some(bakery_insert_res.last_insert_id)),\n        ..Default::default()\n    };\n\n    let cake_insert_res = Cake::insert(mud_cake)\n        .exec(db)\n        .await\n        .expect(\"could not insert cake\");\n\n    let cake: Option<cake::Model> = Cake::find_by_id(cake_insert_res.last_insert_id)\n        .one(db)\n        .await\n        .expect(\"could not find cake\");\n\n    assert!(cake.is_some());\n    let cake_model = cake.unwrap();\n    assert_eq!(cake_model.name, \"Mud Cake\");\n    assert_eq!(cake_model.price, rust_dec(10.25));\n    assert!(!cake_model.gluten_free);\n\n    let large_number = \"1234_5678_9012.3456\".parse().unwrap();\n\n    let mut cake_am: cake::ActiveModel = cake_model.into();\n    cake_am.name = Set(\"Extra chocolate mud cake\".to_owned());\n    cake_am.price = Set(large_number);\n\n    let _cake_update_res: cake::Model = cake_am.update(db).await.expect(\"could not update cake\");\n\n    let cake: Option<cake::Model> = Cake::find_by_id(cake_insert_res.last_insert_id)\n        .one(db)\n        .await\n        .expect(\"could not find cake\");\n    let cake_model = cake.unwrap();\n    assert_eq!(cake_model.name, \"Extra chocolate mud cake\");\n    assert_eq!(cake_model.price, large_number);\n    assert!(!cake_model.gluten_free);\n}\n\npub async fn test_update_bakery(db: &DbConn) {\n    let seaside_bakery = bakery::ActiveModel {\n        name: Set(\"SeaSide Bakery\".to_owned()),\n        profit_margin: Set(10.4),\n        ..Default::default()\n    };\n    let bakery_insert_res = Bakery::insert(seaside_bakery)\n        .exec(db)\n        .await\n        .expect(\"could not insert bakery\");\n\n    let bakery: Option<bakery::Model> = Bakery::find_by_id(bakery_insert_res.last_insert_id)\n        .one(db)\n        .await\n        .expect(\"could not find bakery\");\n\n    assert!(bakery.is_some());\n    let bakery_model = bakery.unwrap();\n    assert_eq!(bakery_model.name, \"SeaSide Bakery\");\n    assert!((bakery_model.profit_margin - 10.40).abs() < f64::EPSILON);\n\n    let mut bakery_am: bakery::ActiveModel = bakery_model.into();\n    bakery_am.name = Set(\"SeaBreeze Bakery\".to_owned());\n    bakery_am.profit_margin = Set(12.00);\n\n    let _bakery_update_res: bakery::Model =\n        bakery_am.update(db).await.expect(\"could not update bakery\");\n\n    let bakery: Option<bakery::Model> = Bakery::find_by_id(bakery_insert_res.last_insert_id)\n        .one(db)\n        .await\n        .expect(\"could not find bakery\");\n    let bakery_model = bakery.unwrap();\n    assert_eq!(bakery_model.name, \"SeaBreeze Bakery\");\n    assert!((bakery_model.profit_margin - 12.00).abs() < f64::EPSILON);\n}\n\npub async fn test_update_deleted_customer(db: &DbConn) {\n    let init_n_customers = Customer::find().count(db).await.unwrap();\n\n    let customer = customer::ActiveModel {\n        name: Set(\"John\".to_owned()),\n        notes: Set(None),\n        ..Default::default()\n    }\n    .save(db)\n    .await\n    .expect(\"could not insert customer\");\n\n    assert_eq!(\n        Customer::find().count(db).await.unwrap(),\n        init_n_customers + 1\n    );\n\n    let customer_id = customer.id.clone().unwrap();\n\n    let _ = customer.delete(db).await;\n    assert_eq!(Customer::find().count(db).await.unwrap(), init_n_customers);\n\n    let customer = customer::ActiveModel {\n        id: Set(customer_id),\n        name: Set(\"John 2\".to_owned()),\n        ..Default::default()\n    };\n\n    let customer_update_res = customer.update(db).await;\n\n    assert_eq!(customer_update_res, Err(DbErr::RecordNotUpdated));\n\n    assert_eq!(Customer::find().count(db).await.unwrap(), init_n_customers);\n\n    let customer: Option<customer::Model> = Customer::find_by_id(customer_id)\n        .one(db)\n        .await\n        .expect(\"could not find customer\");\n\n    assert_eq!(customer, None);\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "852c5d4dd4b618a6bd68f21cff661a3b22fd1d3e",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/tests/common/bakery_chain/cakes_bakers.rs",
    "func": "use sea_orm::entity::prelude::*;\n\n#[derive(Clone, Debug, PartialEq, Eq, DeriveEntityModel)]\n#[sea_orm(table_name = \"cakes_bakers\")]\npub struct Model {\n    #[sea_orm(primary_key)]\n    pub cake_id: i32,\n    #[sea_orm(primary_key)]\n    pub baker_id: i32,\n}\n\n#[derive(Copy, Clone, Debug, EnumIter, DeriveRelation)]\npub enum Relation {\n    #[sea_orm(\n        belongs_to = \"super::cake::Entity\",\n        from = \"Column::CakeId\",\n        to = \"super::cake::Column::Id\",\n        on_update = \"Cascade\",\n        on_delete = \"Cascade\"\n    )]\n    Cake,\n    #[sea_orm(\n        belongs_to = \"super::baker::Entity\",\n        from = \"Column::BakerId\",\n        to = \"super::baker::Column::Id\"\n    )]\n    Baker,\n}\n\nimpl ActiveModelBehavior for ActiveModel {}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "c979c02cc4711d6406b47970cce7a49d9a271f13",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/tests/common/features/repository.rs",
    "func": "use super::edit_log;\nuse sea_orm::{entity::prelude::*, ConnectionTrait, Set, TryIntoModel};\nuse serde::Serialize;\n\n#[derive(Clone, Debug, PartialEq, Eq, DeriveEntityModel, Serialize)]\n#[sea_orm(table_name = \"repository\")]\npub struct Model {\n    #[sea_orm(primary_key, auto_increment = false)]\n    pub id: String,\n    pub owner: String,\n    pub name: String,\n    pub description: Option<String>,\n}\n\n#[derive(Copy, Clone, Debug, EnumIter, DeriveRelation)]\npub enum Relation {}\n\n#[async_trait::async_trait]\nimpl ActiveModelBehavior for ActiveModel {\n    async fn before_save<C>(self, db: &C, _: bool) -> Result<Self, DbErr>\n    where\n        C: ConnectionTrait,\n    {\n        let model = self.clone().try_into_model()?;\n        insert_edit_log(\"before_save\", &model, db).await?;\n        Ok(self)\n    }\n\n    async fn after_save<C>(model: Model, db: &C, _: bool) -> Result<Model, DbErr>\n    where\n        C: ConnectionTrait,\n    {\n        insert_edit_log(\"after_save\", &model, db).await?;\n        Ok(model)\n    }\n\n    async fn before_delete<C>(self, db: &C) -> Result<Self, DbErr>\n    where\n        C: ConnectionTrait,\n    {\n        let model = self.clone().try_into_model()?;\n        insert_edit_log(\"before_delete\", &model, db).await?;\n        Ok(self)\n    }\n\n    async fn after_delete<C>(self, db: &C) -> Result<Self, DbErr>\n    where\n        C: ConnectionTrait,\n    {\n        let model = self.clone().try_into_model()?;\n        insert_edit_log(\"after_delete\", &model, db).await?;\n        Ok(self)\n    }\n}\n\nasync fn insert_edit_log<T, M, C>(action: T, model: &M, db: &C) -> Result<(), DbErr>\nwhere\n    T: Into<String>,\n    M: Serialize,\n    C: ConnectionTrait,\n{\n    edit_log::ActiveModel {\n        action: Set(action.into()),\n        values: Set(serde_json::json!(model)),\n        ..Default::default()\n    }\n    .insert(db)\n    .await?;\n\n    Ok(())\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "34ad9e8ef23163eba0662f6d0cc16cdc82b0e13c",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/sea-orm-migration/tests/main.rs",
    "func": "mod common;\n\nuse common::migrator::*;\nuse sea_orm::{ConnectOptions, ConnectionTrait, Database, DbBackend, DbErr, Statement};\nuse sea_orm_migration::{migrator::MigrationStatus, prelude::*};\n\n#[async_std::test]\nasync fn main() -> Result<(), DbErr> {\n    tracing_subscriber::fmt()\n        .with_max_level(tracing::Level::DEBUG)\n        .with_test_writer()\n        .init();\n\n    let url = &std::env::var(\"DATABASE_URL\").expect(\"Environment variable 'DATABASE_URL' not set\");\n\n    run_migration(url, default::Migrator, \"sea_orm_migration\", \"public\").await?;\n    run_migration(\n        url,\n        default::Migrator,\n        \"sea_orm_migration_schema\",\n        \"my_schema\",\n    )\n    .await?;\n\n    run_migration(\n        url,\n        override_migration_table_name::Migrator,\n        \"sea_orm_migration_table_name\",\n        \"public\",\n    )\n    .await?;\n    run_migration(\n        url,\n        override_migration_table_name::Migrator,\n        \"sea_orm_migration_table_name_schema\",\n        \"my_schema\",\n    )\n    .await?;\n\n    Ok(())\n}\n\nasync fn run_migration<Migrator>(\n    url: &str,\n    _: Migrator,\n    db_name: &str,\n    schema: &str,\n) -> Result<(), DbErr>\nwhere\n    Migrator: MigratorTrait,\n{\n    let db_connect = |url: String| async {\n        let connect_options = ConnectOptions::new(url)\n            .set_schema_search_path(format!(\"{schema},public\"))\n            .to_owned();\n\n        Database::connect(connect_options).await\n    };\n\n    let db = db_connect(url.to_owned()).await?;\n\n    let db = &match db.get_database_backend() {\n        DbBackend::MySql => {\n            db.execute(Statement::from_string(\n                db.get_database_backend(),\n                format!(\"CREATE DATABASE IF NOT EXISTS `{db_name}`;\"),\n            ))\n            .await?;\n\n            let url = format!(\"{url}/{db_name}\");\n            db_connect(url).await?\n        }\n        DbBackend::Postgres => {\n            db.execute(Statement::from_string(\n                db.get_database_backend(),\n                format!(\"DROP DATABASE IF EXISTS \\\"{db_name}\\\";\"),\n            ))\n            .await?;\n            db.execute(Statement::from_string(\n                db.get_database_backend(),\n                format!(\"CREATE DATABASE \\\"{db_name}\\\";\"),\n            ))\n            .await?;\n\n            let url = format!(\"{url}/{db_name}\");\n            let db = db_connect(url).await?;\n\n            db.execute(Statement::from_string(\n                db.get_database_backend(),\n                format!(\"CREATE SCHEMA IF NOT EXISTS \\\"{schema}\\\";\"),\n            ))\n            .await?;\n\n            db\n        }\n        DbBackend::Sqlite => db,\n    };\n    let manager = SchemaManager::new(db);\n\n    println!(\"\\nMigrator::status\");\n    Migrator::status(db).await?;\n\n    println!(\"\\nMigrator::install\");\n    Migrator::install(db).await?;\n\n    let migration_table_name = Migrator::migration_table_name().to_string();\n    let migration_table_name = migration_table_name.as_str();\n    assert!(manager.has_table(migration_table_name).await?);\n    if migration_table_name != \"seaql_migrations\" {\n        assert!(!manager.has_table(\"seaql_migrations\").await?);\n    }\n\n    println!(\"\\nMigrator::reset\");\n    Migrator::reset(db).await?;\n\n    assert!(!manager.has_table(\"cake\").await?);\n    assert!(!manager.has_table(\"fruit\").await?);\n\n    println!(\"\\nMigrator::up\");\n    Migrator::up(db, Some(0)).await?;\n\n    assert!(!manager.has_table(\"cake\").await?);\n    assert!(!manager.has_table(\"fruit\").await?);\n\n    println!(\"\\nMigrator::up\");\n    Migrator::up(db, Some(1)).await?;\n\n    println!(\"\\nMigrator::get_pending_migrations\");\n    let migrations = Migrator::get_pending_migrations(db).await?;\n    assert_eq!(migrations.len(), 5);\n\n    let migration = migrations.get(0).unwrap();\n    assert_eq!(migration.name(), \"m20220118_000002_create_fruit_table\");\n    assert_eq!(migration.status(), MigrationStatus::Pending);\n\n    assert!(manager.has_table(\"cake\").await?);\n    assert!(!manager.has_table(\"fruit\").await?);\n\n    println!(\"\\nMigrator::down\");\n    Migrator::down(db, Some(0)).await?;\n\n    assert!(manager.has_table(\"cake\").await?);\n    assert!(!manager.has_table(\"fruit\").await?);\n\n    println!(\"\\nMigrator::down\");\n    Migrator::down(db, Some(1)).await?;\n\n    assert!(!manager.has_table(\"cake\").await?);\n    assert!(!manager.has_table(\"fruit\").await?);\n\n    // Tests rolling back changes of \"migrate up\" when running migration on Postgres\n    if matches!(db.get_database_backend(), DbBackend::Postgres) {\n        println!(\"\\nRoll back changes when encounter errors\");\n\n        // Set a flag to throw error inside `m20230109_000001_seed_cake_table.rs`\n        std::env::set_var(\"ABORT_MIGRATION\", \"YES\");\n\n        // Should throw an error\n        println!(\"\\nMigrator::up\");\n        assert_eq!(\n            Migrator::up(db, None).await,\n            Err(DbErr::Migration(\n                \"Abort migration and rollback changes\".into()\n            ))\n        );\n\n        println!(\"\\nMigrator::status\");\n        Migrator::status(db).await?;\n\n        // Check migrations have been rolled back\n        assert!(!manager.has_table(\"cake\").await?);\n        assert!(!manager.has_table(\"fruit\").await?);\n\n        // Unset the flag\n        std::env::remove_var(\"ABORT_MIGRATION\");\n    }\n\n    println!(\"\\nMigrator::up\");\n    Migrator::up(db, None).await?;\n\n    println!(\"\\nMigrator::get_applied_migrations\");\n    let migrations = Migrator::get_applied_migrations(db).await?;\n    assert_eq!(migrations.len(), 6);\n\n    assert!(!manager.has_index(\"cake\", \"non_existent_index\").await?);\n    assert!(manager.has_index(\"cake\", \"cake_name_index\").await?);\n\n    let migration = migrations.get(0).unwrap();\n    assert_eq!(migration.name(), \"m20220118_000001_create_cake_table\");\n    assert_eq!(migration.status(), MigrationStatus::Applied);\n\n    println!(\"\\nMigrator::status\");\n    Migrator::status(db).await?;\n\n    assert!(manager.has_table(\"cake\").await?);\n    assert!(manager.has_table(\"fruit\").await?);\n\n    assert!(manager.has_column(\"cake\", \"name\").await?);\n    assert!(manager.has_column(\"fruit\", \"cake_id\").await?);\n\n    // Tests rolling back changes of \"migrate down\" when running migration on Postgres\n    if matches!(db.get_database_backend(), DbBackend::Postgres) {\n        println!(\"\\nRoll back changes when encounter errors\");\n\n        // Set a flag to throw error inside `m20230109_000001_seed_cake_table.rs`\n        std::env::set_var(\"ABORT_MIGRATION\", \"YES\");\n\n        // Should throw an error\n        println!(\"\\nMigrator::down\");\n        assert_eq!(\n            Migrator::down(db, None).await,\n            Err(DbErr::Migration(\n                \"Abort migration and rollback changes\".into()\n            ))\n        );\n\n        println!(\"\\nMigrator::status\");\n        Migrator::status(db).await?;\n\n        // Check migrations have been rolled back\n        assert!(manager.has_table(\"cake\").await?);\n        assert!(manager.has_table(\"fruit\").await?);\n\n        // Unset the flag\n        std::env::remove_var(\"ABORT_MIGRATION\");\n    }\n\n    println!(\"\\nMigrator::down\");\n    Migrator::down(db, None).await?;\n\n    assert!(manager.has_table(migration_table_name).await?);\n    if migration_table_name != \"seaql_migrations\" {\n        assert!(!manager.has_table(\"seaql_migrations\").await?);\n    }\n\n    assert!(!manager.has_table(\"cake\").await?);\n    assert!(!manager.has_table(\"fruit\").await?);\n\n    println!(\"\\nMigrator::fresh\");\n    Migrator::fresh(db).await?;\n\n    assert!(manager.has_table(\"cake\").await?);\n    assert!(manager.has_table(\"fruit\").await?);\n\n    println!(\"\\nMigrator::refresh\");\n    Migrator::refresh(db).await?;\n\n    assert!(manager.has_table(\"cake\").await?);\n    assert!(manager.has_table(\"fruit\").await?);\n\n    println!(\"\\nMigrator::reset\");\n    Migrator::reset(db).await?;\n\n    assert!(!manager.has_table(\"cake\").await?);\n    assert!(!manager.has_table(\"fruit\").await?);\n\n    println!(\"\\nMigrator::status\");\n    Migrator::status(db).await?;\n\n    Ok(())\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "2df6fa51f41e21058e48b67ba765bf3a82b5a51c",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/sea-orm-migration/tests/common/migration/m20230109_000001_seed_cake_table.rs",
    "func": "use sea_orm_migration::prelude::*;\nuse sea_orm_migration::sea_orm::{entity::*, query::*};\n\n#[derive(DeriveMigrationName)]\npub struct Migration;\n\n#[async_trait::async_trait]\nimpl MigrationTrait for Migration {\n    async fn up(&self, manager: &SchemaManager) -> Result<(), DbErr> {\n        let db = manager.get_connection();\n\n        let transaction = db.begin().await?;\n\n        cake::ActiveModel {\n            name: Set(\"Cheesecake\".to_owned()),\n            ..Default::default()\n        }\n        .insert(&transaction)\n        .await?;\n\n        if std::env::var_os(\"ABORT_MIGRATION\").eq(&Some(\"YES\".into())) {\n            return Err(DbErr::Migration(\n                \"Abort migration and rollback changes\".into(),\n            ));\n        }\n\n        transaction.commit().await?;\n\n        Ok(())\n    }\n\n    async fn down(&self, manager: &SchemaManager) -> Result<(), DbErr> {\n        let db = manager.get_connection();\n\n        let transaction = db.begin().await?;\n\n        cake::Entity::delete_many()\n            .filter(cake::Column::Name.eq(\"Cheesecake\"))\n            .exec(&transaction)\n            .await?;\n\n        transaction.commit().await?;\n\n        Ok(())\n    }\n}\n\nmod cake {\n    use sea_orm_migration::sea_orm::entity::prelude::*;\n\n    #[derive(Clone, Debug, PartialEq, Eq, DeriveEntityModel)]\n    #[sea_orm(table_name = \"cake\")]\n    pub struct Model {\n        #[sea_orm(primary_key)]\n        pub id: i32,\n        pub name: String,\n    }\n\n    #[derive(Copy, Clone, Debug, EnumIter, DeriveRelation)]\n    pub enum Relation {}\n\n    impl ActiveModelBehavior for ActiveModel {}\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "e43ebf5a803e0736071b0e56b184b79a17b9cbb7",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/sea-orm-migration/src/migrator.rs",
    "func": "use futures::Future;\nuse std::collections::HashSet;\nuse std::fmt::Display;\nuse std::pin::Pin;\nuse std::time::SystemTime;\nuse tracing::info;\n\nuse sea_orm::sea_query::{\n    self, extension::postgres::Type, Alias, Expr, ForeignKey, IntoIden, JoinType, Order, Query,\n    SelectStatement, SimpleExpr, Table,\n};\nuse sea_orm::{\n    ActiveModelTrait, ActiveValue, Condition, ConnectionTrait, DbBackend, DbErr, DeriveIden,\n    DynIden, EntityTrait, FromQueryResult, Iterable, QueryFilter, Schema, Statement,\n    TransactionTrait,\n};\nuse sea_schema::{mysql::MySql, postgres::Postgres, probe::SchemaProbe, sqlite::Sqlite};\n\nuse super::{seaql_migrations, IntoSchemaManagerConnection, MigrationTrait, SchemaManager};\n\n#[derive(Copy, Clone, Debug, PartialEq, Eq)]\n/// Status of migration\npub enum MigrationStatus {\n    /// Not yet applied\n    Pending,\n    /// Applied\n    Applied,\n}\n\nimpl Display for MigrationStatus {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        let status = match self {\n            MigrationStatus::Pending => \"Pending\",\n            MigrationStatus::Applied => \"Applied\",\n        };\n        write!(f, \"{status}\")\n    }\n}\n\npub struct Migration {\n    migration: Box<dyn MigrationTrait>,\n    status: MigrationStatus,\n}\n\nimpl Migration {\n    /// Get migration name from MigrationName trait implementation\n    pub fn name(&self) -> &str {\n        self.migration.name()\n    }\n\n    /// Get migration status\n    pub fn status(&self) -> MigrationStatus {\n        self.status\n    }\n}\n\n/// Performing migrations on a database\n#[async_trait::async_trait]\npub trait MigratorTrait: Send {\n    /// Vector of migrations in time sequence\n    fn migrations() -> Vec<Box<dyn MigrationTrait>>;\n\n    /// Name of the migration table, it is `seaql_migrations` by default\n    fn migration_table_name() -> DynIden {\n        seaql_migrations::Entity.into_iden()\n    }\n\n    /// Get list of migrations wrapped in `Migration` struct\n    fn get_migration_files() -> Vec<Migration> {\n        Self::migrations()\n            .into_iter()\n            .map(|migration| Migration {\n                migration,\n                status: MigrationStatus::Pending,\n            })\n            .collect()\n    }\n\n    /// Get list of applied migrations from database\n    async fn get_migration_models<C>(db: &C) -> Result<Vec<seaql_migrations::Model>, DbErr>\n    where\n        C: ConnectionTrait,\n    {\n        Self::install(db).await?;\n        let stmt = Query::select()\n            .table_name(Self::migration_table_name())\n            .columns(seaql_migrations::Column::iter().map(IntoIden::into_iden))\n            .order_by(seaql_migrations::Column::Version, Order::Asc)\n            .to_owned();\n        let builder = db.get_database_backend();\n        seaql_migrations::Model::find_by_statement(builder.build(&stmt))\n            .all(db)\n            .await\n    }\n\n    /// Get list of migrations with status\n    async fn get_migration_with_status<C>(db: &C) -> Result<Vec<Migration>, DbErr>\n    where\n        C: ConnectionTrait,\n    {\n        Self::install(db).await?;\n        let mut migration_files = Self::get_migration_files();\n        let migration_models = Self::get_migration_models(db).await?;\n\n        let migration_in_db: HashSet<String> = migration_models\n            .into_iter()\n            .map(|model| model.version)\n            .collect();\n        let migration_in_fs: HashSet<String> = migration_files\n            .iter()\n            .map(|file| file.migration.name().to_string())\n            .collect();\n\n        let pending_migrations = &migration_in_fs - &migration_in_db;\n        for migration_file in migration_files.iter_mut() {\n            if !pending_migrations.contains(migration_file.migration.name()) {\n                migration_file.status = MigrationStatus::Applied;\n            }\n        }\n\n        let missing_migrations_in_fs = &migration_in_db - &migration_in_fs;\n        let errors: Vec<String> = missing_migrations_in_fs\n            .iter()\n            .map(|missing_migration| {\n                format!(\"Migration file of version '{missing_migration}' is missing, this migration has been applied but its file is missing\")\n            }).collect();\n\n        if !errors.is_empty() {\n            Err(DbErr::Custom(errors.join(\"\\n\")))\n        } else {\n            Ok(migration_files)\n        }\n    }\n\n    /// Get list of pending migrations\n    async fn get_pending_migrations<C>(db: &C) -> Result<Vec<Migration>, DbErr>\n    where\n        C: ConnectionTrait,\n    {\n        Self::install(db).await?;\n        Ok(Self::get_migration_with_status(db)\n            .await?\n            .into_iter()\n            .filter(|file| file.status == MigrationStatus::Pending)\n            .collect())\n    }\n\n    /// Get list of applied migrations\n    async fn get_applied_migrations<C>(db: &C) -> Result<Vec<Migration>, DbErr>\n    where\n        C: ConnectionTrait,\n    {\n        Self::install(db).await?;\n        Ok(Self::get_migration_with_status(db)\n            .await?\n            .into_iter()\n            .filter(|file| file.status == MigrationStatus::Applied)\n            .collect())\n    }\n\n    /// Create migration table `seaql_migrations` in the database\n    async fn install<C>(db: &C) -> Result<(), DbErr>\n    where\n        C: ConnectionTrait,\n    {\n        let builder = db.get_database_backend();\n        let table_name = Self::migration_table_name();\n        let schema = Schema::new(builder);\n        let mut stmt = schema\n            .create_table_from_entity(seaql_migrations::Entity)\n            .table_name(table_name);\n        stmt.if_not_exists();\n        db.execute(builder.build(&stmt)).await.map(|_| ())\n    }\n\n    /// Check the status of all migrations\n    async fn status<C>(db: &C) -> Result<(), DbErr>\n    where\n        C: ConnectionTrait,\n    {\n        Self::install(db).await?;\n\n        info!(\"Checking migration status\");\n\n        for Migration { migration, status } in Self::get_migration_with_status(db).await? {\n            info!(\"Migration '{}'... {}\", migration.name(), status);\n        }\n\n        Ok(())\n    }\n\n    /// Drop all tables from the database, then reapply all migrations\n    async fn fresh<'c, C>(db: C) -> Result<(), DbErr>\n    where\n        C: IntoSchemaManagerConnection<'c>,\n    {\n        exec_with_connection::<'_, _, _>(db, move |manager| {\n            Box::pin(async move { exec_fresh::<Self>(manager).await })\n        })\n        .await\n    }\n\n    /// Rollback all applied migrations, then reapply all migrations\n    async fn refresh<'c, C>(db: C) -> Result<(), DbErr>\n    where\n        C: IntoSchemaManagerConnection<'c>,\n    {\n        exec_with_connection::<'_, _, _>(db, move |manager| {\n            Box::pin(async move {\n                exec_down::<Self>(manager, None).await?;\n                exec_up::<Self>(manager, None).await\n            })\n        })\n        .await\n    }\n\n    /// Rollback all applied migrations\n    async fn reset<'c, C>(db: C) -> Result<(), DbErr>\n    where\n        C: IntoSchemaManagerConnection<'c>,\n    {\n        exec_with_connection::<'_, _, _>(db, move |manager| {\n            Box::pin(async move { exec_down::<Self>(manager, None).await })\n        })\n        .await\n    }\n\n    /// Apply pending migrations\n    async fn up<'c, C>(db: C, steps: Option<u32>) -> Result<(), DbErr>\n    where\n        C: IntoSchemaManagerConnection<'c>,\n    {\n        exec_with_connection::<'_, _, _>(db, move |manager| {\n            Box::pin(async move { exec_up::<Self>(manager, steps).await })\n        })\n        .await\n    }\n\n    /// Rollback applied migrations\n    async fn down<'c, C>(db: C, steps: Option<u32>) -> Result<(), DbErr>\n    where\n        C: IntoSchemaManagerConnection<'c>,\n    {\n        exec_with_connection::<'_, _, _>(db, move |manager| {\n            Box::pin(async move { exec_down::<Self>(manager, steps).await })\n        })\n        .await\n    }\n}\n\nasync fn exec_with_connection<'c, C, F>(db: C, f: F) -> Result<(), DbErr>\nwhere\n    C: IntoSchemaManagerConnection<'c>,\n    F: for<'b> Fn(\n        &'b SchemaManager<'_>,\n    ) -> Pin<Box<dyn Future<Output = Result<(), DbErr>> + Send + 'b>>,\n{\n    let db = db.into_schema_manager_connection();\n\n    match db.get_database_backend() {\n        DbBackend::Postgres => {\n            let transaction = db.begin().await?;\n            let manager = SchemaManager::new(&transaction);\n            f(&manager).await?;\n            transaction.commit().await\n        }\n        DbBackend::MySql | DbBackend::Sqlite => {\n            let manager = SchemaManager::new(db);\n            f(&manager).await\n        }\n    }\n}\n\nasync fn exec_fresh<M>(manager: &SchemaManager<'_>) -> Result<(), DbErr>\nwhere\n    M: MigratorTrait + ?Sized,\n{\n    let db = manager.get_connection();\n\n    M::install(db).await?;\n    let db_backend = db.get_database_backend();\n\n    // Temporarily disable the foreign key check\n    if db_backend == DbBackend::Sqlite {\n        info!(\"Disabling foreign key check\");\n        db.execute(Statement::from_string(\n            db_backend,\n            \"PRAGMA foreign_keys = OFF\".to_owned(),\n        ))\n        .await?;\n        info!(\"Foreign key check disabled\");\n    }\n\n    // Drop all foreign keys\n    if db_backend == DbBackend::MySql {\n        info!(\"Dropping all foreign keys\");\n        let stmt = query_mysql_foreign_keys(db);\n        let rows = db.query_all(db_backend.build(&stmt)).await?;\n        for row in rows.into_iter() {\n            let constraint_name: String = row.try_get(\"\", \"CONSTRAINT_NAME\")?;\n            let table_name: String = row.try_get(\"\", \"TABLE_NAME\")?;\n            info!(\n                \"Dropping foreign key '{}' from table '{}'\",\n                constraint_name, table_name\n            );\n            let mut stmt = ForeignKey::drop();\n            stmt.table(Alias::new(table_name.as_str()))\n                .name(constraint_name.as_str());\n            db.execute(db_backend.build(&stmt)).await?;\n            info!(\"Foreign key '{}' has been dropped\", constraint_name);\n        }\n        info!(\"All foreign keys dropped\");\n    }\n\n    // Drop all tables\n    let stmt = query_tables(db).await;\n    let rows = db.query_all(db_backend.build(&stmt)).await?;\n    for row in rows.into_iter() {\n        let table_name: String = row.try_get(\"\", \"table_name\")?;\n        info!(\"Dropping table '{}'\", table_name);\n        let mut stmt = Table::drop();\n        stmt.table(Alias::new(table_name.as_str()))\n            .if_exists()\n            .cascade();\n        db.execute(db_backend.build(&stmt)).await?;\n        info!(\"Table '{}' has been dropped\", table_name);\n    }\n\n    // Drop all types\n    if db_backend == DbBackend::Postgres {\n        info!(\"Dropping all types\");\n        let stmt = query_pg_types(db);\n        let rows = db.query_all(db_backend.build(&stmt)).await?;\n        for row in rows {\n            let type_name: String = row.try_get(\"\", \"typname\")?;\n            info!(\"Dropping type '{}'\", type_name);\n            let mut stmt = Type::drop();\n            stmt.name(Alias::new(&type_name));\n            db.execute(db_backend.build(&stmt)).await?;\n            info!(\"Type '{}' has been dropped\", type_name);\n        }\n    }\n\n    // Restore the foreign key check\n    if db_backend == DbBackend::Sqlite {\n        info!(\"Restoring foreign key check\");\n        db.execute(Statement::from_string(\n            db_backend,\n            \"PRAGMA foreign_keys = ON\".to_owned(),\n        ))\n        .await?;\n        info!(\"Foreign key check restored\");\n    }\n\n    // Reapply all migrations\n    exec_up::<M>(manager, None).await\n}\n\nasync fn exec_up<M>(manager: &SchemaManager<'_>, mut steps: Option<u32>) -> Result<(), DbErr>\nwhere\n    M: MigratorTrait + ?Sized,\n{\n    let db = manager.get_connection();\n\n    M::install(db).await?;\n\n    if let Some(steps) = steps {\n        info!(\"Applying {} pending migrations\", steps);\n    } else {\n        info!(\"Applying all pending migrations\");\n    }\n\n    let migrations = M::get_pending_migrations(db).await?.into_iter();\n    if migrations.len() == 0 {\n        info!(\"No pending migrations\");\n    }\n    for Migration { migration, .. } in migrations {\n        if let Some(steps) = steps.as_mut() {\n            if steps == &0 {\n                break;\n            }\n            *steps -= 1;\n        }\n        info!(\"Applying migration '{}'\", migration.name());\n        migration.up(manager).await?;\n        info!(\"Migration '{}' has been applied\", migration.name());\n        let now = SystemTime::now()\n            .duration_since(SystemTime::UNIX_EPOCH)\n            .expect(\"SystemTime before UNIX EPOCH!\");\n        seaql_migrations::Entity::insert(seaql_migrations::ActiveModel {\n            version: ActiveValue::Set(migration.name().to_owned()),\n            applied_at: ActiveValue::Set(now.as_secs() as i64),\n        })\n        .table_name(M::migration_table_name())\n        .exec(db)\n        .await?;\n    }\n\n    Ok(())\n}\n\nasync fn exec_down<M>(manager: &SchemaManager<'_>, mut steps: Option<u32>) -> Result<(), DbErr>\nwhere\n    M: MigratorTrait + ?Sized,\n{\n    let db = manager.get_connection();\n\n    M::install(db).await?;\n\n    if let Some(steps) = steps {\n        info!(\"Rolling back {} applied migrations\", steps);\n    } else {\n        info!(\"Rolling back all applied migrations\");\n    }\n\n    let migrations = M::get_applied_migrations(db).await?.into_iter().rev();\n    if migrations.len() == 0 {\n        info!(\"No applied migrations\");\n    }\n    for Migration { migration, .. } in migrations {\n        if let Some(steps) = steps.as_mut() {\n            if steps == &0 {\n                break;\n            }\n            *steps -= 1;\n        }\n        info!(\"Rolling back migration '{}'\", migration.name());\n        migration.down(manager).await?;\n        info!(\"Migration '{}' has been rollbacked\", migration.name());\n        seaql_migrations::Entity::delete_many()\n            .filter(Expr::col(seaql_migrations::Column::Version).eq(migration.name()))\n            .table_name(M::migration_table_name())\n            .exec(db)\n            .await?;\n    }\n\n    Ok(())\n}\n\nasync fn query_tables<C>(db: &C) -> SelectStatement\nwhere\n    C: ConnectionTrait,\n{\n    match db.get_database_backend() {\n        DbBackend::MySql => MySql.query_tables(),\n        DbBackend::Postgres => Postgres.query_tables(),\n        DbBackend::Sqlite => Sqlite.query_tables(),\n    }\n}\n\nfn get_current_schema<C>(db: &C) -> SimpleExpr\nwhere\n    C: ConnectionTrait,\n{\n    match db.get_database_backend() {\n        DbBackend::MySql => MySql::get_current_schema(),\n        DbBackend::Postgres => Postgres::get_current_schema(),\n        DbBackend::Sqlite => unimplemented!(),\n    }\n}\n\n#[derive(DeriveIden)]\nenum InformationSchema {\n    #[sea_orm(iden = \"information_schema\")]\n    Schema,\n    #[sea_orm(iden = \"TABLE_NAME\")]\n    TableName,\n    #[sea_orm(iden = \"CONSTRAINT_NAME\")]\n    ConstraintName,\n    TableConstraints,\n    TableSchema,\n    ConstraintType,\n}\n\nfn query_mysql_foreign_keys<C>(db: &C) -> SelectStatement\nwhere\n    C: ConnectionTrait,\n{\n    let mut stmt = Query::select();\n    stmt.columns([\n        InformationSchema::TableName,\n        InformationSchema::ConstraintName,\n    ])\n    .from((\n        InformationSchema::Schema,\n        InformationSchema::TableConstraints,\n    ))\n    .cond_where(\n        Condition::all()\n            .add(Expr::expr(get_current_schema(db)).equals((\n                InformationSchema::TableConstraints,\n                InformationSchema::TableSchema,\n            )))\n            .add(\n                Expr::col((\n                    InformationSchema::TableConstraints,\n                    InformationSchema::ConstraintType,\n                ))\n                .eq(\"FOREIGN KEY\"),\n            ),\n    );\n    stmt\n}\n\n#[derive(DeriveIden)]\nenum PgType {\n    Table,\n    Typname,\n    Typnamespace,\n    Typelem,\n}\n\n#[derive(DeriveIden)]\nenum PgNamespace {\n    Table,\n    Oid,\n    Nspname,\n}\n\nfn query_pg_types<C>(db: &C) -> SelectStatement\nwhere\n    C: ConnectionTrait,\n{\n    let mut stmt = Query::select();\n    stmt.column(PgType::Typname)\n        .from(PgType::Table)\n        .join(\n            JoinType::LeftJoin,\n            PgNamespace::Table,\n            Expr::col((PgNamespace::Table, PgNamespace::Oid))\n                .equals((PgType::Table, PgType::Typnamespace)),\n        )\n        .cond_where(\n            Condition::all()\n                .add(\n                    Expr::expr(get_current_schema(db))\n                        .equals((PgNamespace::Table, PgNamespace::Nspname)),\n                )\n                .add(Expr::col((PgType::Table, PgType::Typelem)).eq(0)),\n        );\n    stmt\n}\n\ntrait QueryTable {\n    type Statement;\n\n    fn table_name(self, table_name: DynIden) -> Self::Statement;\n}\n\nimpl QueryTable for SelectStatement {\n    type Statement = SelectStatement;\n\n    fn table_name(mut self, table_name: DynIden) -> SelectStatement {\n        self.from(table_name);\n        self\n    }\n}\n\nimpl QueryTable for sea_query::TableCreateStatement {\n    type Statement = sea_query::TableCreateStatement;\n\n    fn table_name(mut self, table_name: DynIden) -> sea_query::TableCreateStatement {\n        self.table(table_name);\n        self\n    }\n}\n\nimpl<A> QueryTable for sea_orm::Insert<A>\nwhere\n    A: ActiveModelTrait,\n{\n    type Statement = sea_orm::Insert<A>;\n\n    fn table_name(mut self, table_name: DynIden) -> sea_orm::Insert<A> {\n        sea_orm::QueryTrait::query(&mut self).into_table(table_name);\n        self\n    }\n}\n\nimpl<E> QueryTable for sea_orm::DeleteMany<E>\nwhere\n    E: EntityTrait,\n{\n    type Statement = sea_orm::DeleteMany<E>;\n\n    fn table_name(mut self, table_name: DynIden) -> sea_orm::DeleteMany<E> {\n        sea_orm::QueryTrait::query(&mut self).from_table(table_name);\n        self\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "792ed668e7956a325bc31a57ce41da9b3ea25cce",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/sea-orm-macros/src/derives/primary_key.rs",
    "func": "use heck::ToSnakeCase;\nuse proc_macro2::{Ident, TokenStream};\nuse quote::{quote, quote_spanned};\nuse syn::{Data, DataEnum, Expr, Fields, LitStr, Variant};\n\n/// Method to derive a Primary Key for a Model using the [PrimaryKeyTrait](sea_orm::PrimaryKeyTrait)\npub fn expand_derive_primary_key(ident: Ident, data: Data) -> syn::Result<TokenStream> {\n    let variants = match data {\n        syn::Data::Enum(DataEnum { variants, .. }) => variants,\n        _ => {\n            return Ok(quote_spanned! {\n                ident.span() => compile_error!(\"you can only derive DerivePrimaryKey on enums\");\n            })\n        }\n    };\n\n    if variants.is_empty() {\n        return Ok(quote_spanned! {\n            ident.span() => compile_error!(\"Entity must have a primary key column. See <https://github.com/SeaQL/sea-orm/issues/485> for details.\");\n        });\n    }\n\n    let variant: Vec<TokenStream> = variants\n        .iter()\n        .map(|Variant { ident, fields, .. }| match fields {\n            Fields::Named(_) => quote! { #ident{..} },\n            Fields::Unnamed(_) => quote! { #ident(..) },\n            Fields::Unit => quote! { #ident },\n        })\n        .collect();\n\n    let name: Vec<TokenStream> = variants\n        .iter()\n        .map(|v| {\n            let mut column_name = v.ident.to_string().to_snake_case();\n            for attr in v.attrs.iter() {\n                if !attr.path().is_ident(\"sea_orm\") {\n                    continue;\n                }\n\n                attr.parse_nested_meta(|meta| {\n                    if meta.path.is_ident(\"column_name\") {\n                        column_name = meta.value()?.parse::<LitStr>()?.value();\n                    } else {\n                        // Reads the value expression to advance the parse stream.\n                        // Some parameters, such as `primary_key`, do not have any value,\n                        // so ignoring an error occurred here.\n                        let _: Option<Expr> = meta.value().and_then(|v| v.parse()).ok();\n                    }\n\n                    Ok(())\n                })?;\n            }\n            Ok::<TokenStream, syn::Error>(quote! { #column_name })\n        })\n        .collect::<Result<_, _>>()?;\n\n    Ok(quote!(\n        #[automatically_derived]\n        impl sea_orm::Iden for #ident {\n            fn unquoted(&self, s: &mut dyn std::fmt::Write) {\n                write!(s, \"{}\", sea_orm::IdenStatic::as_str(self)).unwrap();\n            }\n        }\n\n        #[automatically_derived]\n        impl sea_orm::IdenStatic for #ident {\n            fn as_str(&self) -> &str {\n                match self {\n                    #(Self::#variant => #name),*\n                }\n            }\n        }\n\n        #[automatically_derived]\n        impl sea_orm::PrimaryKeyToColumn for #ident {\n            type Column = Column;\n\n            fn into_column(self) -> Self::Column {\n                match self {\n                    #(Self::#variant => Self::Column::#variant,)*\n                }\n            }\n\n            fn from_column(col: Self::Column) -> Option<Self> {\n                match col {\n                    #(Self::Column::#variant => Some(Self::#variant),)*\n                    _ => None,\n                }\n            }\n        }\n    ))\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "836c484e53c8981dadfd87259d8fcf73393d37c0",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/examples/loco_seaography/src/lib.rs",
    "func": "pub mod app;\npub mod controllers;\npub mod graphql;\npub mod mailers;\npub mod models;\npub mod tasks;\npub mod views;\npub mod workers;\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "57e13b5a2eaeddb091de347e03c4fc1724256d39",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/examples/loco_seaography/src/controllers/files.rs",
    "func": "#![allow(clippy::missing_errors_doc)]\n#![allow(clippy::unnecessary_struct_initialization)]\n#![allow(clippy::unused_async)]\nuse std::path::PathBuf;\n\nuse axum::{body::Body, debug_handler, extract::Multipart};\nuse loco_rs::prelude::*;\nuse sea_orm::QueryOrder;\nuse tokio::{fs, io::AsyncWriteExt};\nuse tokio_util::io::ReaderStream;\n\nuse crate::models::_entities::files;\n\nconst UPLOAD_DIR: &str = \"./uploads\";\n\n#[debug_handler]\npub async fn upload(\n    _auth: auth::JWT,\n    Path(notes_id): Path<i32>,\n    State(ctx): State<AppContext>,\n    mut multipart: Multipart,\n) -> Result<Response> {\n    // Collect all uploaded files\n    let mut files = Vec::new();\n\n    // Iterate all files in the POST body\n    while let Some(field) = multipart.next_field().await.map_err(|err| {\n        tracing::error!(error = ?err,\"could not readd multipart\");\n        Error::BadRequest(\"could not readd multipart\".into())\n    })? {\n        // Get the file name\n        let file_name = match field.file_name() {\n            Some(file_name) => file_name.to_string(),\n            _ => return Err(Error::BadRequest(\"file name not found\".into())),\n        };\n\n        // Get the file content as bytes\n        let content = field.bytes().await.map_err(|err| {\n            tracing::error!(error = ?err,\"could not readd bytes\");\n            Error::BadRequest(\"could not readd bytes\".into())\n        })?;\n\n        // Create a folder to store the uploaded file\n        let now = chrono::offset::Local::now()\n            .format(\"%Y%m%d_%H%M%S\")\n            .to_string();\n        let uuid = uuid::Uuid::new_v4().to_string();\n        let folder = format!(\"{now}_{uuid}\");\n        let upload_folder = PathBuf::from(UPLOAD_DIR).join(&folder);\n        fs::create_dir_all(&upload_folder).await?;\n\n        // Write the file into the newly created folder\n        let path = upload_folder.join(file_name);\n        let mut f = fs::OpenOptions::new()\n            .create_new(true)\n            .write(true)\n            .open(&path)\n            .await?;\n        f.write_all(&content).await?;\n        f.flush().await?;\n\n        // Record the file upload in database\n        let file = files::ActiveModel {\n            notes_id: ActiveValue::Set(notes_id),\n            file_path: ActiveValue::Set(\n                path.strip_prefix(UPLOAD_DIR)\n                    .unwrap()\n                    .to_str()\n                    .unwrap()\n                    .to_string(),\n            ),\n            ..Default::default()\n        }\n        .insert(&ctx.db)\n        .await?;\n\n        files.push(file);\n    }\n\n    format::json(files)\n}\n\n#[debug_handler]\npub async fn list(\n    _auth: auth::JWT,\n    Path(notes_id): Path<i32>,\n    State(ctx): State<AppContext>,\n) -> Result<Response> {\n    // Fetch all files uploaded for a specific notes\n    let files = files::Entity::find()\n        .filter(files::Column::NotesId.eq(notes_id))\n        .order_by_asc(files::Column::Id)\n        .all(&ctx.db)\n        .await?;\n\n    format::json(files)\n}\n\n#[debug_handler]\npub async fn view(\n    _auth: auth::JWT,\n    Path(files_id): Path<i32>,\n    State(ctx): State<AppContext>,\n) -> Result<Response> {\n    // Fetch the file info from database\n    let file = files::Entity::find_by_id(files_id)\n        .one(&ctx.db)\n        .await?\n        .expect(\"File not found\");\n\n    // Stream the file\n    let file = fs::File::open(format!(\"{UPLOAD_DIR}/{}\", file.file_path)).await?;\n    let stream = ReaderStream::new(file);\n    let body = Body::from_stream(stream);\n\n    Ok(format::render().response().body(body)?)\n}\n\npub fn routes() -> Routes {\n    // Bind the routes\n    Routes::new()\n        .prefix(\"files\")\n        .add(\"/upload/:notes_id\", post(upload))\n        .add(\"/list/:notes_id\", get(list))\n        .add(\"/view/:files_id\", get(view))\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "6ff458f0dd8251dcd508746cf6d74b43c1bbb9c9",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/examples/loco_seaography/src/graphql/mod.rs",
    "func": "pub mod query_root;\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "457804b0aac74c4a09afb7ec32f75ceba79ccd88",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/examples/react_admin/backend/src/mailers/mod.rs",
    "func": "pub mod auth;\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "5098404dfb4b28acba69d3ff240478040fd13e75",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/examples/react_admin/backend/src/tasks/seed.rs",
    "func": "//! This task implements data seeding functionality for initializing new\n//! development/demo environments.\n//!\n//! # Example\n//!\n//! Run the task with the following command:\n//! ```sh\n//! cargo run task\n//! ```\n//!\n//! To override existing data and reset the data structure, use the following\n//! command with the `refresh:true` argument:\n//! ```sh\n//! cargo run task seed_data refresh:true\n//! ```\n\nuse loco_rs::{db, prelude::*};\nuse migration::Migrator;\n\nuse crate::app::App;\n\n#[allow(clippy::module_name_repetitions)]\npub struct SeedData;\n#[async_trait]\nimpl Task for SeedData {\n    fn task(&self) -> TaskInfo {\n        TaskInfo {\n            name: \"seed_data\".to_string(),\n            detail: \"Task for seeding data\".to_string(),\n        }\n    }\n\n    async fn run(&self, app_context: &AppContext, vars: &task::Vars) -> Result<()> {\n        let refresh = vars\n            .cli_arg(\"refresh\")\n            .is_ok_and(|refresh| refresh == \"true\");\n\n        if refresh {\n            db::reset::<Migrator>(&app_context.db).await?;\n        }\n        let path = std::path::Path::new(\"src/fixtures\");\n        db::run_app_seed::<App>(&app_context.db, path).await?;\n        Ok(())\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "1bc795f348d607c083d5dd2c4edac3410b48c334",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/examples/react_admin/backend/src/views/user.rs",
    "func": "use serde::{Deserialize, Serialize};\n\nuse crate::models::_entities::users;\n\n#[derive(Debug, Deserialize, Serialize)]\npub struct CurrentResponse {\n    pub pid: String,\n    pub name: String,\n    pub email: String,\n}\n\nimpl CurrentResponse {\n    #[must_use]\n    pub fn new(user: &users::Model) -> Self {\n        Self {\n            pid: user.pid.to_string(),\n            name: user.name.clone(),\n            email: user.email.clone(),\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "12ae37b0a2aa8b90a195c7c220e0a1d51a8f7ef4",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/examples/seaography_example/migration/src/entity/cake.rs",
    "func": "//! `SeaORM` Entity. Generated by sea-orm-codegen 0.12.1\n\nuse sea_orm::entity::prelude::*;\n\n#[derive(Clone, Debug, PartialEq, DeriveEntityModel, Eq)]\n#[sea_orm(table_name = \"cake\")]\npub struct Model {\n    #[sea_orm(primary_key)]\n    pub id: i32,\n    pub name: String,\n    #[sea_orm(column_type = \"Decimal(Some((16, 4)))\")]\n    pub price: Decimal,\n    pub bakery_id: Option<i32>,\n    pub gluten_free: i8,\n}\n\n#[derive(Copy, Clone, Debug, EnumIter, DeriveRelation)]\npub enum Relation {\n    #[sea_orm(\n        belongs_to = \"super::bakery::Entity\",\n        from = \"Column::BakeryId\",\n        to = \"super::bakery::Column::Id\",\n        on_update = \"Cascade\",\n        on_delete = \"Cascade\"\n    )]\n    Bakery,\n    #[sea_orm(has_many = \"super::cake_baker::Entity\")]\n    CakeBaker,\n}\n\nimpl Related<super::bakery::Entity> for Entity {\n    fn to() -> RelationDef {\n        Relation::Bakery.def()\n    }\n}\n\nimpl Related<super::cake_baker::Entity> for Entity {\n    fn to() -> RelationDef {\n        Relation::CakeBaker.def()\n    }\n}\n\nimpl Related<super::baker::Entity> for Entity {\n    fn to() -> RelationDef {\n        super::cake_baker::Relation::Baker.def()\n    }\n    fn via() -> Option<RelationDef> {\n        Some(super::cake_baker::Relation::Cake.def().rev())\n    }\n}\n\nimpl ActiveModelBehavior for ActiveModel {}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "99eddcf901e617693c926f325f9bdc232345ae51",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/examples/loco_example/src/bin/main.rs",
    "func": "use loco_rs::cli;\nuse migration::Migrator;\nuse todolist::app::App;\n\n#[tokio::main]\nasync fn main() -> eyre::Result<()> {\n    cli::main::<App, Migrator>().await?;\n    Ok(())\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "134e5615e5ddab0626e831481d2d8cfb6d288aef",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/examples/rocket_example/service/tests/prepare.rs",
    "func": "use ::entity::post;\nuse sea_orm::*;\n\n#[cfg(feature = \"mock\")]\npub fn prepare_mock_db() -> DatabaseConnection {\n    MockDatabase::new(DatabaseBackend::Postgres)\n        .append_query_results([\n            [post::Model {\n                id: 1,\n                title: \"Title A\".to_owned(),\n                text: \"Text A\".to_owned(),\n            }],\n            [post::Model {\n                id: 5,\n                title: \"Title C\".to_owned(),\n                text: \"Text C\".to_owned(),\n            }],\n            [post::Model {\n                id: 6,\n                title: \"Title D\".to_owned(),\n                text: \"Text D\".to_owned(),\n            }],\n            [post::Model {\n                id: 1,\n                title: \"Title A\".to_owned(),\n                text: \"Text A\".to_owned(),\n            }],\n            [post::Model {\n                id: 1,\n                title: \"New Title A\".to_owned(),\n                text: \"New Text A\".to_owned(),\n            }],\n            [post::Model {\n                id: 5,\n                title: \"Title C\".to_owned(),\n                text: \"Text C\".to_owned(),\n            }],\n        ])\n        .append_exec_results([\n            MockExecResult {\n                last_insert_id: 6,\n                rows_affected: 1,\n            },\n            MockExecResult {\n                last_insert_id: 6,\n                rows_affected: 5,\n            },\n        ])\n        .into_connection()\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "1623344f2a055377f58c3773b04e6514e699665c",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/examples/rocket_example/service/src/query.rs",
    "func": "use ::entity::{post, post::Entity as Post};\nuse sea_orm::*;\n\npub struct Query;\n\nimpl Query {\n    pub async fn find_post_by_id(db: &DbConn, id: i32) -> Result<Option<post::Model>, DbErr> {\n        Post::find_by_id(id).one(db).await\n    }\n\n    /// If ok, returns (post models, num pages).\n    pub async fn find_posts_in_page(\n        db: &DbConn,\n        page: u64,\n        posts_per_page: u64,\n    ) -> Result<(Vec<post::Model>, u64), DbErr> {\n        // Setup paginator\n        let paginator = Post::find()\n            .order_by_asc(post::Column::Id)\n            .paginate(db, posts_per_page);\n        let num_pages = paginator.num_pages().await?;\n\n        // Fetch paginated posts\n        paginator.fetch_page(page - 1).await.map(|p| (p, num_pages))\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "113b7b0b4c674da73a339dafb3a630e7423929a8",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/examples/tonic_example/service/src/query.rs",
    "func": "use ::entity::{post, post::Entity as Post};\nuse sea_orm::*;\n\npub struct Query;\n\nimpl Query {\n    pub async fn find_post_by_id(db: &DbConn, id: i32) -> Result<Option<post::Model>, DbErr> {\n        Post::find_by_id(id).one(db).await\n    }\n\n    /// If ok, returns (post models, num pages).\n    pub async fn find_posts_in_page(\n        db: &DbConn,\n        page: u64,\n        posts_per_page: u64,\n    ) -> Result<(Vec<post::Model>, u64), DbErr> {\n        // Setup paginator\n        let paginator = Post::find()\n            .order_by_asc(post::Column::Id)\n            .paginate(db, posts_per_page);\n        let num_pages = paginator.num_pages().await?;\n\n        // Fetch paginated posts\n        paginator.fetch_page(page - 1).await.map(|p| (p, num_pages))\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "f2fb7ae64a5c2350eae5dac687d9d65e78eded4c",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/examples/rocket_okapi_example/service/tests/mock.rs",
    "func": "mod prepare;\n\nuse entity::post;\nuse prepare::prepare_mock_db;\nuse rocket_okapi_example_service::{Mutation, Query};\n\n#[tokio::test]\nasync fn main() {\n    let db = &prepare_mock_db();\n\n    {\n        let post = Query::find_post_by_id(db, 1).await.unwrap().unwrap();\n\n        assert_eq!(post.id, 1);\n    }\n\n    {\n        let post = Query::find_post_by_id(db, 5).await.unwrap().unwrap();\n\n        assert_eq!(post.id, 5);\n    }\n\n    {\n        let post = Mutation::create_post(\n            db,\n            post::Model {\n                id: 0,\n                title: \"Title D\".to_owned(),\n                text: \"Text D\".to_owned(),\n            },\n        )\n        .await\n        .unwrap();\n\n        assert_eq!(\n            post,\n            post::ActiveModel {\n                id: sea_orm::ActiveValue::Unchanged(6),\n                title: sea_orm::ActiveValue::Unchanged(\"Title D\".to_owned()),\n                text: sea_orm::ActiveValue::Unchanged(\"Text D\".to_owned())\n            }\n        );\n    }\n\n    {\n        let post = Mutation::update_post_by_id(\n            db,\n            1,\n            post::Model {\n                id: 1,\n                title: \"New Title A\".to_owned(),\n                text: \"New Text A\".to_owned(),\n            },\n        )\n        .await\n        .unwrap();\n\n        assert_eq!(\n            post,\n            post::Model {\n                id: 1,\n                title: \"New Title A\".to_owned(),\n                text: \"New Text A\".to_owned(),\n            }\n        );\n    }\n\n    {\n        let result = Mutation::delete_post(db, 5).await.unwrap();\n\n        assert_eq!(result.rows_affected, 1);\n    }\n\n    {\n        let result = Mutation::delete_all_posts(db).await.unwrap();\n\n        assert_eq!(result.rows_affected, 5);\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "5cddf11f19b2cbe1c5c8aaa5f44c4a7f61061d69",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/examples/rocket_okapi_example/service/src/lib.rs",
    "func": "mod mutation;\nmod query;\n\npub use mutation::*;\npub use query::*;\n\npub use sea_orm;\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "842b203cf7a6a60b577b56d0bdf694e4a8ab7eee",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/examples/salvo_example/service/tests/prepare.rs",
    "func": "use ::entity::post;\nuse sea_orm::*;\n\n#[cfg(feature = \"mock\")]\npub fn prepare_mock_db() -> DatabaseConnection {\n    MockDatabase::new(DatabaseBackend::Postgres)\n        .append_query_results([\n            [post::Model {\n                id: 1,\n                title: \"Title A\".to_owned(),\n                text: \"Text A\".to_owned(),\n            }],\n            [post::Model {\n                id: 5,\n                title: \"Title C\".to_owned(),\n                text: \"Text C\".to_owned(),\n            }],\n            [post::Model {\n                id: 6,\n                title: \"Title D\".to_owned(),\n                text: \"Text D\".to_owned(),\n            }],\n            [post::Model {\n                id: 1,\n                title: \"Title A\".to_owned(),\n                text: \"Text A\".to_owned(),\n            }],\n            [post::Model {\n                id: 1,\n                title: \"New Title A\".to_owned(),\n                text: \"New Text A\".to_owned(),\n            }],\n            [post::Model {\n                id: 5,\n                title: \"Title C\".to_owned(),\n                text: \"Text C\".to_owned(),\n            }],\n        ])\n        .append_exec_results([\n            MockExecResult {\n                last_insert_id: 6,\n                rows_affected: 1,\n            },\n            MockExecResult {\n                last_insert_id: 6,\n                rows_affected: 5,\n            },\n        ])\n        .into_connection()\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "576b31dcf994353ebc02ec13cee604c6f41d2d8a",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/examples/salvo_example/service/src/lib.rs",
    "func": "mod mutation;\nmod query;\n\npub use mutation::*;\npub use query::*;\n\npub use sea_orm;\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "51f919538fe153ffc136cbfdc0d28964927e1524",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/examples/poem_example/api/src/lib.rs",
    "func": "use std::env;\n\nuse entity::post;\nuse migration::{Migrator, MigratorTrait};\nuse poem::endpoint::StaticFilesEndpoint;\nuse poem::error::InternalServerError;\nuse poem::http::StatusCode;\nuse poem::listener::TcpListener;\nuse poem::web::{Data, Form, Html, Path, Query};\nuse poem::{get, handler, post, EndpointExt, Error, IntoResponse, Result, Route, Server};\nuse poem_example_service::{\n    sea_orm::{Database, DatabaseConnection},\n    Mutation as MutationCore, Query as QueryCore,\n};\nuse serde::Deserialize;\nuse tera::Tera;\n\nconst DEFAULT_POSTS_PER_PAGE: u64 = 5;\n\n#[derive(Debug, Clone)]\nstruct AppState {\n    templates: tera::Tera,\n    conn: DatabaseConnection,\n}\n\n#[derive(Deserialize)]\nstruct Params {\n    page: Option<u64>,\n    posts_per_page: Option<u64>,\n}\n\n#[handler]\nasync fn create(state: Data<&AppState>, form: Form<post::Model>) -> Result<impl IntoResponse> {\n    let form = form.0;\n    let conn = &state.conn;\n\n    MutationCore::create_post(conn, form)\n        .await\n        .map_err(InternalServerError)?;\n\n    Ok(StatusCode::FOUND.with_header(\"location\", \"/\"))\n}\n\n#[handler]\nasync fn list(state: Data<&AppState>, Query(params): Query<Params>) -> Result<impl IntoResponse> {\n    let conn = &state.conn;\n    let page = params.page.unwrap_or(1);\n    let posts_per_page = params.posts_per_page.unwrap_or(DEFAULT_POSTS_PER_PAGE);\n\n    let (posts, num_pages) = QueryCore::find_posts_in_page(conn, page, posts_per_page)\n        .await\n        .map_err(InternalServerError)?;\n\n    let mut ctx = tera::Context::new();\n    ctx.insert(\"posts\", &posts);\n    ctx.insert(\"page\", &page);\n    ctx.insert(\"posts_per_page\", &posts_per_page);\n    ctx.insert(\"num_pages\", &num_pages);\n\n    let body = state\n        .templates\n        .render(\"index.html.tera\", &ctx)\n        .map_err(InternalServerError)?;\n    Ok(Html(body))\n}\n\n#[handler]\nasync fn new(state: Data<&AppState>) -> Result<impl IntoResponse> {\n    let ctx = tera::Context::new();\n    let body = state\n        .templates\n        .render(\"new.html.tera\", &ctx)\n        .map_err(InternalServerError)?;\n    Ok(Html(body))\n}\n\n#[handler]\nasync fn edit(state: Data<&AppState>, Path(id): Path<i32>) -> Result<impl IntoResponse> {\n    let conn = &state.conn;\n\n    let post: post::Model = QueryCore::find_post_by_id(conn, id)\n        .await\n        .map_err(InternalServerError)?\n        .ok_or_else(|| Error::from_status(StatusCode::NOT_FOUND))?;\n\n    let mut ctx = tera::Context::new();\n    ctx.insert(\"post\", &post);\n\n    let body = state\n        .templates\n        .render(\"edit.html.tera\", &ctx)\n        .map_err(InternalServerError)?;\n    Ok(Html(body))\n}\n\n#[handler]\nasync fn update(\n    state: Data<&AppState>,\n    Path(id): Path<i32>,\n    form: Form<post::Model>,\n) -> Result<impl IntoResponse> {\n    let conn = &state.conn;\n    let form = form.0;\n\n    MutationCore::update_post_by_id(conn, id, form)\n        .await\n        .map_err(InternalServerError)?;\n\n    Ok(StatusCode::FOUND.with_header(\"location\", \"/\"))\n}\n\n#[handler]\nasync fn delete(state: Data<&AppState>, Path(id): Path<i32>) -> Result<impl IntoResponse> {\n    let conn = &state.conn;\n\n    MutationCore::delete_post(conn, id)\n        .await\n        .map_err(InternalServerError)?;\n\n    Ok(StatusCode::FOUND.with_header(\"location\", \"/\"))\n}\n\n#[tokio::main]\nasync fn start() -> std::io::Result<()> {\n    std::env::set_var(\"RUST_LOG\", \"debug\");\n    tracing_subscriber::fmt::init();\n\n    // get env vars\n    dotenvy::dotenv().ok();\n    let db_url = env::var(\"DATABASE_URL\").expect(\"DATABASE_URL is not set in .env file\");\n    let host = env::var(\"HOST\").expect(\"HOST is not set in .env file\");\n    let port = env::var(\"PORT\").expect(\"PORT is not set in .env file\");\n    let server_url = format!(\"{host}:{port}\");\n\n    // create post table if not exists\n    let conn = Database::connect(&db_url).await.unwrap();\n    Migrator::up(&conn, None).await.unwrap();\n    let templates = Tera::new(concat!(env!(\"CARGO_MANIFEST_DIR\"), \"/templates/**/*\")).unwrap();\n    let state = AppState { templates, conn };\n\n    println!(\"Starting server at {server_url}\");\n\n    let app = Route::new()\n        .at(\"/\", post(create).get(list))\n        .at(\"/new\", new)\n        .at(\"/:id\", get(edit).post(update))\n        .at(\"/delete/:id\", post(delete))\n        .nest(\n            \"/static\",\n            StaticFilesEndpoint::new(concat!(env!(\"CARGO_MANIFEST_DIR\"), \"/static\")),\n        )\n        .data(state);\n    let server = Server::new(TcpListener::bind(format!(\"{host}:{port}\")));\n    server.run(app).await\n}\n\npub fn main() {\n    let result = start();\n\n    if let Some(err) = result.err() {\n        println!(\"Error: {err}\");\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "7624a18c34e0ad25114f59fbd0f6af7471e3a1f5",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/examples/poem_example/src/main.rs",
    "func": "fn main() {\n    poem_example_api::main();\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "fd5569c7e25d4ae7cc1ae5e4ea4836fea9825576",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/issues/1473/src/main.rs",
    "func": "use sea_orm::{DeriveIden, Iden};\n\n#[derive(DeriveIden)]\nenum Character {\n    Table,\n    Id,\n}\n\n#[derive(DeriveIden)]\nstruct Glyph;\n\nfn main() {\n    assert_eq!(Character::Table.to_string(), \"character\");\n    assert_eq!(Character::Id.to_string(), \"id\");\n    assert_eq!(Glyph.to_string(), \"glyph\");\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "176a18bb1346cdbeb4821553873144093a0d12aa",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/sea-orm-rocket/lib/src/lib.rs",
    "func": "//! SeaORM Rocket support crate.\n#![deny(missing_docs)]\n\n/// Re-export of the `figment` crate.\n#[doc(inline)]\npub use rocket::figment;\n\npub use rocket;\n\nmod config;\nmod database;\nmod error;\nmod pool;\n\npub use self::config::Config;\npub use self::database::{Connection, Database, Initializer};\npub use self::error::Error;\npub use self::pool::{MockPool, Pool};\n\npub use sea_orm_rocket_codegen::*;\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "e4a77d87e104104a3baa11e3916b120855572061",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/src/schema/mod.rs",
    "func": "use crate::DbBackend;\n\nmod entity;\n\n/// This is a helper struct to convert [`EntityTrait`](crate::EntityTrait)\n/// into different [`sea_query`](crate::sea_query) statements.\n#[derive(Debug)]\npub struct Schema {\n    backend: DbBackend,\n}\n\nimpl Schema {\n    /// Create a helper for a specific database backend\n    pub fn new(backend: DbBackend) -> Self {\n        Self { backend }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "bacfa357069fcf24ab53739ddc4b180cf4e01816",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/src/query/mod.rs",
    "func": "pub(crate) mod combine;\nmod delete;\nmod helper;\nmod insert;\nmod join;\n#[cfg(feature = \"with-json\")]\nmod json;\nmod loader;\nmod select;\nmod traits;\nmod update;\nmod util;\n\npub use combine::{SelectA, SelectB};\npub use delete::*;\npub use helper::*;\npub use insert::*;\n#[cfg(feature = \"with-json\")]\npub use json::*;\npub use loader::*;\npub use select::*;\npub use traits::*;\npub use update::*;\npub use util::*;\n\npub use crate::{\n    ConnectionTrait, CursorTrait, InsertResult, PaginatorTrait, Statement, StreamTrait,\n    TransactionTrait, UpdateResult, Value, Values,\n};\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "fb441090956b78c3087fc6266d8c48fd62b7786b",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/src/tests_cfg/indexes.rs",
    "func": "//! An entity definition for testing table index creation.\nuse crate as sea_orm;\nuse crate::entity::prelude::*;\n\n#[derive(Copy, Clone, Default, Debug, DeriveEntity)]\npub struct Entity;\n\nimpl EntityName for Entity {\n    fn schema_name(&self) -> Option<&str> {\n        Some(\"public\")\n    }\n\n    fn table_name(&self) -> &str {\n        \"indexes\"\n    }\n}\n\n#[derive(Clone, Debug, PartialEq, Eq, DeriveModel, DeriveActiveModel)]\npub struct Model {\n    pub indexes_id: i32,\n    pub unique_attr: i32,\n    pub index1_attr: i32,\n    pub index2_attr: i32,\n}\n\n#[derive(Copy, Clone, Debug, EnumIter, DeriveColumn)]\npub enum Column {\n    IndexesId,\n    UniqueAttr,\n    Index1Attr,\n    Index2Attr,\n}\n\n#[derive(Copy, Clone, Debug, EnumIter, DerivePrimaryKey)]\npub enum PrimaryKey {\n    IndexesId,\n}\n\nimpl PrimaryKeyTrait for PrimaryKey {\n    type ValueType = i32;\n\n    fn auto_increment() -> bool {\n        true\n    }\n}\n\n#[derive(Copy, Clone, Debug, EnumIter, DeriveRelation)]\npub enum Relation {}\n\nimpl ColumnTrait for Column {\n    type EntityName = Entity;\n\n    fn def(&self) -> ColumnDef {\n        match self {\n            Self::IndexesId => ColumnType::Integer.def(),\n            Self::UniqueAttr => ColumnType::Integer.def().unique(),\n            Self::Index1Attr => ColumnType::Integer.def().indexed(),\n            Self::Index2Attr => ColumnType::Integer.def().indexed().unique(),\n        }\n    }\n}\n\nimpl ActiveModelBehavior for ActiveModel {}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "f5e106afba61cbd8d866b2ac86eb0c34e5596727",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/src/tests_cfg/cake_seaography.rs",
    "func": "use crate as sea_orm;\nuse crate::entity::prelude::*;\n\n#[derive(Clone, Debug, PartialEq, Eq, DeriveEntityModel)]\n#[sea_orm(table_name = \"cake\")]\npub struct Model {\n    #[sea_orm(primary_key)]\n    pub id: i32,\n    #[sea_orm(column_name = \"name\", enum_name = \"Name\")]\n    pub name: String,\n}\n\n#[derive(Copy, Clone, Debug, EnumIter, DeriveRelation)]\npub enum Relation {\n    #[sea_orm(has_many = \"super::fruit::Entity\")]\n    Fruit,\n    #[sea_orm(\n        has_many = \"super::fruit::Entity\",\n        on_condition = r#\"super::fruit::Column::Name.like(\"%tropical%\")\"#\n    )]\n    TropicalFruit,\n    #[sea_orm(\n        has_many = \"super::fruit::Entity\",\n        condition_type = \"any\",\n        on_condition = r#\"super::fruit::Column::Name.like(\"%tropical%\")\"#\n    )]\n    OrTropicalFruit,\n}\n\nimpl Related<super::fruit::Entity> for Entity {\n    fn to() -> RelationDef {\n        Relation::Fruit.def()\n    }\n}\n\nimpl Related<super::filling::Entity> for Entity {\n    fn to() -> RelationDef {\n        super::cake_filling::Relation::Filling.def()\n    }\n\n    fn via() -> Option<RelationDef> {\n        Some(super::cake_filling::Relation::Cake.def().rev())\n    }\n}\n\n#[derive(Copy, Clone, Debug, EnumIter, DeriveRelatedEntity)]\npub enum RelatedEntity {\n    #[sea_orm(entity = \"super::fruit::Entity\")]\n    Fruit,\n    #[sea_orm(entity = \"super::filling::Entity\")]\n    Filling,\n    #[sea_orm(\n        entity = \"super::fruit::Entity\",\n        def = \"Relation::TropicalFruit.def()\"\n    )]\n    TropicalFruit,\n    #[sea_orm(\n        entity = \"super::fruit::Entity\",\n        def = \"Relation::OrTropicalFruit.def()\"\n    )]\n    OrTropicalFruit,\n}\n\nimpl ActiveModelBehavior for ActiveModel {}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "68105bd5e8a92b04036f9e5b09a82e7e73f44452",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/sea-orm-codegen/tests/compact_with_schema_name/fruit.rs",
    "func": "//! SeaORM Entity. Generated by sea-orm-codegen 0.1.0\n\nuse sea_orm::entity::prelude::*;\n\n#[derive(Clone, Debug, PartialEq, DeriveEntityModel, Eq)]\n#[sea_orm(schema_name = \"schema_name\", table_name = \"fruit\")]\npub struct Model {\n    #[sea_orm(primary_key)]\n    pub id: i32,\n    pub name: String,\n    pub cake_id: Option<i32> ,\n}\n\n#[derive(Copy, Clone, Debug, EnumIter, DeriveRelation)]\npub enum Relation {\n    #[sea_orm(\n        belongs_to = \"super::cake::Entity\",\n        from = \"Column::CakeId\",\n        to = \"super::cake::Column::Id\",\n    )]\n    Cake,\n    #[sea_orm(has_many = \"super::vendor::Entity\")]\n    Vendor,\n}\n\nimpl Related<super::cake::Entity> for Entity {\n    fn to() -> RelationDef {\n        Relation::Cake.def()\n    }\n}\n\nimpl Related<super::vendor::Entity> for Entity {\n    fn to() -> RelationDef {\n        Relation::Vendor.def()\n    }\n}\n\nimpl ActiveModelBehavior for ActiveModel {}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "2f97a2f141c817766a2ec2ab1ee10f24e53f7609",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/sea-orm-codegen/tests/compact_with_derives/cake_none.rs",
    "func": "//! SeaORM Entity. Generated by sea-orm-codegen 0.1.0\n\nuse sea_orm::entity::prelude:: * ;\n\n#[derive(Clone, Debug, PartialEq, DeriveEntityModel, Eq)]\n#[sea_orm(table_name = \"cake\")]\npub struct Model {\n    #[sea_orm(primary_key)]\n    pub id: i32,\n    #[sea_orm(column_type = \"Text\", nullable)]\n    pub name: Option<String> ,\n}\n\n#[derive(Copy, Clone, Debug, EnumIter, DeriveRelation)]\npub enum Relation {\n    #[sea_orm(has_many = \"super::fruit::Entity\")]\n    Fruit,\n}\n\nimpl Related<super::fruit::Entity> for Entity {\n    fn to() -> RelationDef {\n        Relation::Fruit.def()\n    }\n}\n\nimpl Related<super::filling::Entity> for Entity {\n    fn to() -> RelationDef {\n        super::cake_filling::Relation::Filling.def()\n    }\n    fn via() -> Option<RelationDef> {\n        Some(super::cake_filling::Relation::Cake.def().rev())\n    }\n}\n\nimpl ActiveModelBehavior for ActiveModel {}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "b5673edfb1508a83d1c44bf234f3b7ba73abaac5",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/sea-orm-codegen/tests/expanded_with_schema_name/cake_filling.rs",
    "func": "//! SeaORM Entity. Generated by sea-orm-codegen 0.1.0\n\nuse sea_orm::entity::prelude::*;\n\n#[derive(Copy, Clone, Default, Debug, DeriveEntity)]\npub struct Entity;\n\nimpl EntityName for Entity {\n    fn schema_name(&self) -> Option< &str > {\n        Some(\"schema_name\")\n    }\n\n    fn table_name(&self) -> &str {\n        \"_cake_filling_\"\n    }\n}\n\n#[derive(Clone, Debug, PartialEq, DeriveModel, DeriveActiveModel, Eq)]\npub struct Model {\n    pub cake_id: i32,\n    pub filling_id: i32,\n}\n\n#[derive(Copy, Clone, Debug, EnumIter, DeriveColumn)]\npub enum Column {\n    CakeId,\n    FillingId,\n}\n\n#[derive(Copy, Clone, Debug, EnumIter, DerivePrimaryKey)]\npub enum PrimaryKey {\n    CakeId,\n    FillingId,\n}\n\nimpl PrimaryKeyTrait for PrimaryKey {\n    type ValueType = (i32, i32);\n\n    fn auto_increment() -> bool {\n        false\n    }\n}\n\n#[derive(Copy, Clone, Debug, EnumIter)]\npub enum Relation {\n    Cake,\n    Filling,\n}\n\nimpl ColumnTrait for Column {\n    type EntityName = Entity;\n    fn def(&self) -> ColumnDef {\n        match self {\n            Self::CakeId => ColumnType::Integer.def(),\n            Self::FillingId => ColumnType::Integer.def(),\n        }\n    }\n}\n\nimpl RelationTrait for Relation {\n    fn def(&self) -> RelationDef {\n        match self {\n            Self::Cake => Entity::belongs_to(super::cake::Entity)\n                .from(Column::CakeId)\n                .to(super::cake::Column::Id)\n                .into(),\n            Self::Filling => Entity::belongs_to(super::filling::Entity)\n                .from(Column::FillingId)\n                .to(super::filling::Column::Id)\n                .into(),\n        }\n    }\n}\n\nimpl Related<super::cake::Entity> for Entity {\n    fn to() -> RelationDef {\n        Relation::Cake.def()\n    }\n}\n\nimpl Related<super::filling::Entity> for Entity {\n    fn to() -> RelationDef {\n        Relation::Filling.def()\n    }\n}\n\nimpl ActiveModelBehavior for ActiveModel {}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "a738dc7e9fd265e02f513d02506bfe87fee4d929",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/sea-orm-codegen/src/entity/conjunct_relation.rs",
    "func": "use heck::{ToSnakeCase, ToUpperCamelCase};\nuse proc_macro2::Ident;\nuse quote::format_ident;\n\nuse crate::util::escape_rust_keyword;\n\n#[derive(Clone, Debug)]\npub struct ConjunctRelation {\n    pub(crate) via: String,\n    pub(crate) to: String,\n}\n\nimpl ConjunctRelation {\n    pub fn get_via_snake_case(&self) -> Ident {\n        format_ident!(\"{}\", escape_rust_keyword(self.via.to_snake_case()))\n    }\n\n    pub fn get_to_snake_case(&self) -> Ident {\n        format_ident!(\"{}\", escape_rust_keyword(self.to.to_snake_case()))\n    }\n\n    pub fn get_to_upper_camel_case(&self) -> Ident {\n        format_ident!(\"{}\", self.to.to_upper_camel_case())\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use crate::ConjunctRelation;\n\n    fn setup() -> Vec<ConjunctRelation> {\n        vec![\n            ConjunctRelation {\n                via: \"cake_filling\".to_owned(),\n                to: \"cake\".to_owned(),\n            },\n            ConjunctRelation {\n                via: \"cake_filling\".to_owned(),\n                to: \"filling\".to_owned(),\n            },\n        ]\n    }\n\n    #[test]\n    fn test_get_via_snake_case() {\n        let conjunct_relations = setup();\n        let via_vec = vec![\"cake_filling\", \"cake_filling\"];\n        for (con_rel, via) in conjunct_relations.into_iter().zip(via_vec) {\n            assert_eq!(con_rel.get_via_snake_case(), via);\n        }\n    }\n\n    #[test]\n    fn test_get_to_snake_case() {\n        let conjunct_relations = setup();\n        let to_vec = vec![\"cake\", \"filling\"];\n        for (con_rel, to) in conjunct_relations.into_iter().zip(to_vec) {\n            assert_eq!(con_rel.get_to_snake_case(), to);\n        }\n    }\n\n    #[test]\n    fn test_get_to_upper_camel_case() {\n        let conjunct_relations = setup();\n        let to_vec = vec![\"Cake\", \"Filling\"];\n        for (con_rel, to) in conjunct_relations.into_iter().zip(to_vec) {\n            assert_eq!(con_rel.get_to_upper_camel_case(), to);\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "271b0707dfc48bd67e31127f3019004b65f7241a",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/pingora/pingora-cache/src/lock.rs",
    "func": "// Copyright 2024 Cloudflare, Inc.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n// http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n//! Cache lock\n\nuse crate::key::CacheHashKey;\n\nuse crate::hashtable::ConcurrentHashTable;\nuse pingora_timeout::timeout;\nuse std::sync::Arc;\n\nconst N_SHARDS: usize = 16;\n\n/// The global cache locking manager\npub struct CacheLock {\n    lock_table: ConcurrentHashTable<LockStub, N_SHARDS>,\n    timeout: Duration, // fixed timeout value for now\n}\n\n/// A struct representing locked cache access\n#[derive(Debug)]\npub enum Locked {\n    /// The writer is allowed to fetch the asset\n    Write(WritePermit),\n    /// The reader waits for the writer to fetch the asset\n    Read(ReadLock),\n}\n\nimpl Locked {\n    /// Is this a write lock\n    pub fn is_write(&self) -> bool {\n        matches!(self, Self::Write(_))\n    }\n}\n\nimpl CacheLock {\n    /// Create a new [CacheLock] with the given lock timeout\n    ///\n    /// When the timeout is reached, the read locks are automatically unlocked\n    pub fn new(timeout: Duration) -> Self {\n        CacheLock {\n            lock_table: ConcurrentHashTable::new(),\n            timeout,\n        }\n    }\n\n    /// Try to lock a cache fetch\n    ///\n    /// Users should call after a cache miss before fetching the asset.\n    /// The returned [Locked] will tell the caller either to fetch or wait.\n    pub fn lock<K: CacheHashKey>(&self, key: &K) -> Locked {\n        let hash = key.combined_bin();\n        let key = u128::from_be_bytes(hash); // endianness doesn't matter\n        let table = self.lock_table.get(key);\n        if let Some(lock) = table.read().get(&key) {\n            // already has an ongoing request\n            if lock.0.lock_status() != LockStatus::Dangling {\n                return Locked::Read(lock.read_lock());\n            }\n            // Dangling: the previous writer quit without unlocking the lock. Requests should\n            // compete for the write lock again.\n        }\n\n        let (permit, stub) = WritePermit::new(self.timeout);\n        let mut table = table.write();\n        // check again in case another request already added it\n        if let Some(lock) = table.get(&key) {\n            if lock.0.lock_status() != LockStatus::Dangling {\n                return Locked::Read(lock.read_lock());\n            }\n        }\n        table.insert(key, stub);\n        Locked::Write(permit)\n    }\n\n    /// Release a lock for the given key\n    ///\n    /// When the write lock is dropped without being released, the read lock holders will consider\n    /// it to be failed so that they will compete for the write lock again.\n    pub fn release<K: CacheHashKey>(&self, key: &K, reason: LockStatus) {\n        let hash = key.combined_bin();\n        let key = u128::from_be_bytes(hash); // endianness doesn't matter\n        if let Some(lock) = self.lock_table.write(key).remove(&key) {\n            // make sure that the caller didn't forget to unlock it\n            if lock.0.locked() {\n                lock.0.unlock(reason);\n            }\n        }\n    }\n}\n\nuse log::warn;\nuse std::sync::atomic::{AtomicU8, Ordering};\nuse std::time::{Duration, Instant};\nuse strum::IntoStaticStr;\nuse tokio::sync::Semaphore;\n\n/// Status which the read locks could possibly see.\n#[derive(Debug, Copy, Clone, PartialEq, Eq, IntoStaticStr)]\npub enum LockStatus {\n    /// Waiting for the writer to populate the asset\n    Waiting,\n    /// The writer finishes, readers can start\n    Done,\n    /// The writer encountered error, such as network issue. A new writer will be elected.\n    TransientError,\n    /// The writer observed that no cache lock is needed (e.g., uncacheable), readers should start\n    /// to fetch independently without a new writer\n    GiveUp,\n    /// The write lock is dropped without being unlocked\n    Dangling,\n    /// The lock is held for too long\n    Timeout,\n}\n\nimpl From<LockStatus> for u8 {\n    fn from(l: LockStatus) -> u8 {\n        match l {\n            LockStatus::Waiting => 0,\n            LockStatus::Done => 1,\n            LockStatus::TransientError => 2,\n            LockStatus::GiveUp => 3,\n            LockStatus::Dangling => 4,\n            LockStatus::Timeout => 5,\n        }\n    }\n}\n\nimpl From<u8> for LockStatus {\n    fn from(v: u8) -> Self {\n        match v {\n            0 => Self::Waiting,\n            1 => Self::Done,\n            2 => Self::TransientError,\n            3 => Self::GiveUp,\n            4 => Self::Dangling,\n            5 => Self::Timeout,\n            _ => Self::GiveUp, // placeholder\n        }\n    }\n}\n\n#[derive(Debug)]\nstruct LockCore {\n    pub lock_start: Instant,\n    pub timeout: Duration,\n    pub(super) lock: Semaphore,\n    // use u8 for Atomic enum\n    lock_status: AtomicU8,\n}\n\nimpl LockCore {\n    pub fn new_arc(timeout: Duration) -> Arc<Self> {\n        Arc::new(LockCore {\n            lock: Semaphore::new(0),\n            timeout,\n            lock_start: Instant::now(),\n            lock_status: AtomicU8::new(LockStatus::Waiting.into()),\n        })\n    }\n\n    fn locked(&self) -> bool {\n        self.lock.available_permits() == 0\n    }\n\n    fn unlock(&self, reason: LockStatus) {\n        self.lock_status.store(reason.into(), Ordering::SeqCst);\n        // Any small positive number will do, 10 is used for RwLock as well.\n        // No need to wake up all at once.\n        self.lock.add_permits(10);\n    }\n\n    fn lock_status(&self) -> LockStatus {\n        self.lock_status.load(Ordering::SeqCst).into()\n    }\n}\n\n// all 3 structs below are just Arc<LockCore> with different interfaces\n\n/// ReadLock: the requests who get it need to wait until it is released\n#[derive(Debug)]\npub struct ReadLock(Arc<LockCore>);\n\nimpl ReadLock {\n    /// Wait for the writer to release the lock\n    pub async fn wait(&self) {\n        if !self.locked() || self.expired() {\n            return;\n        }\n\n        // TODO: need to be careful not to wake everyone up at the same time\n        // (maybe not an issue because regular cache lock release behaves that way)\n        if let Some(duration) = self.0.timeout.checked_sub(self.0.lock_start.elapsed()) {\n            match timeout(duration, self.0.lock.acquire()).await {\n                Ok(Ok(_)) => { // permit is returned to Semaphore right away\n                }\n                Ok(Err(e)) => {\n                    warn!(\"error acquiring semaphore {e:?}\")\n                }\n                Err(_) => {\n                    self.0\n                        .lock_status\n                        .store(LockStatus::Timeout.into(), Ordering::SeqCst);\n                }\n            }\n        }\n    }\n\n    /// Test if it is still locked\n    pub fn locked(&self) -> bool {\n        self.0.locked()\n    }\n\n    /// Whether the lock is expired, e.g., the writer has been holding the lock for too long\n    pub fn expired(&self) -> bool {\n        // NOTE: this is whether the lock is currently expired\n        // not whether it was timed out during wait()\n        self.0.lock_start.elapsed() >= self.0.timeout\n    }\n\n    /// The current status of the lock\n    pub fn lock_status(&self) -> LockStatus {\n        let status = self.0.lock_status();\n        if matches!(status, LockStatus::Waiting) && self.expired() {\n            LockStatus::Timeout\n        } else {\n            status\n        }\n    }\n}\n\n/// WritePermit: requires who get it need to populate the cache and then release it\n#[derive(Debug)]\npub struct WritePermit(Arc<LockCore>);\n\nimpl WritePermit {\n    fn new(timeout: Duration) -> (WritePermit, LockStub) {\n        let lock = LockCore::new_arc(timeout);\n        let stub = LockStub(lock.clone());\n        (WritePermit(lock), stub)\n    }\n\n    fn unlock(&self, reason: LockStatus) {\n        self.0.unlock(reason)\n    }\n}\n\nimpl Drop for WritePermit {\n    fn drop(&mut self) {\n        // Writer exited without properly unlocking. We let others to compete for the write lock again\n        if self.0.locked() {\n            self.unlock(LockStatus::Dangling);\n        }\n    }\n}\n\nstruct LockStub(Arc<LockCore>);\nimpl LockStub {\n    pub fn read_lock(&self) -> ReadLock {\n        ReadLock(self.0.clone())\n    }\n}\n\n#[cfg(test)]\nmod test {\n    use super::*;\n    use crate::CacheKey;\n\n    #[test]\n    fn test_get_release() {\n        let cache_lock = CacheLock::new(Duration::from_secs(1000));\n        let key1 = CacheKey::new(\"\", \"a\", \"1\");\n        let locked1 = cache_lock.lock(&key1);\n        assert!(locked1.is_write()); // write permit\n        let locked2 = cache_lock.lock(&key1);\n        assert!(!locked2.is_write()); // read lock\n        cache_lock.release(&key1, LockStatus::Done);\n        let locked3 = cache_lock.lock(&key1);\n        assert!(locked3.is_write()); // write permit again\n    }\n\n    #[tokio::test]\n    async fn test_lock() {\n        let cache_lock = CacheLock::new(Duration::from_secs(1000));\n        let key1 = CacheKey::new(\"\", \"a\", \"1\");\n        let permit = match cache_lock.lock(&key1) {\n            Locked::Write(w) => w,\n            _ => panic!(),\n        };\n        let lock = match cache_lock.lock(&key1) {\n            Locked::Read(r) => r,\n            _ => panic!(),\n        };\n        assert!(lock.locked());\n        let handle = tokio::spawn(async move {\n            lock.wait().await;\n            assert_eq!(lock.lock_status(), LockStatus::Done);\n        });\n        permit.unlock(LockStatus::Done);\n        handle.await.unwrap(); // check lock is unlocked and the task is returned\n    }\n\n    #[tokio::test]\n    async fn test_lock_timeout() {\n        let cache_lock = CacheLock::new(Duration::from_secs(1));\n        let key1 = CacheKey::new(\"\", \"a\", \"1\");\n        let permit = match cache_lock.lock(&key1) {\n            Locked::Write(w) => w,\n            _ => panic!(),\n        };\n        let lock = match cache_lock.lock(&key1) {\n            Locked::Read(r) => r,\n            _ => panic!(),\n        };\n        assert!(lock.locked());\n\n        let handle = tokio::spawn(async move {\n            // timed out\n            lock.wait().await;\n            assert_eq!(lock.lock_status(), LockStatus::Timeout);\n        });\n\n        tokio::time::sleep(Duration::from_secs(2)).await;\n\n        // expired lock\n        let lock2 = match cache_lock.lock(&key1) {\n            Locked::Read(r) => r,\n            _ => panic!(),\n        };\n        assert!(lock2.locked());\n        assert_eq!(lock2.lock_status(), LockStatus::Timeout);\n        lock2.wait().await;\n        assert_eq!(lock2.lock_status(), LockStatus::Timeout);\n\n        permit.unlock(LockStatus::Done);\n        handle.await.unwrap();\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "1f6e6779ff5c6bf74f609dfb023ef8067a0e2bd7",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/pingora/pingora-core/src/utils/tls/rustls.rs",
    "func": "// Copyright 2024 Cloudflare, Inc.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n// http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\nuse ouroboros::self_referencing;\nuse pingora_error::Result;\nuse pingora_rustls::CertificateDer;\nuse std::hash::{Hash, Hasher};\nuse x509_parser::prelude::{FromDer, X509Certificate};\n\n/// Get the organization and serial number associated with the given certificate\n/// see https://en.wikipedia.org/wiki/X.509#Structure_of_a_certificate\npub fn get_organization_serial(x509cert: &WrappedX509) -> Result<(Option<String>, String)> {\n    let serial = get_serial(x509cert)?;\n    Ok((get_organization(x509cert), serial))\n}\n\nfn get_organization_serial_x509(\n    x509cert: &X509Certificate<'_>,\n) -> Result<(Option<String>, String)> {\n    let serial = x509cert.raw_serial_as_string();\n    Ok((get_organization_x509(x509cert), serial))\n}\n\n/// Get the serial number associated with the given certificate\n/// see https://en.wikipedia.org/wiki/X.509#Structure_of_a_certificate\npub fn get_serial(x509cert: &WrappedX509) -> Result<String> {\n    Ok(x509cert.borrow_cert().raw_serial_as_string())\n}\n\n/// Return the organization associated with the X509 certificate.\n/// see https://en.wikipedia.org/wiki/X.509#Structure_of_a_certificate\npub fn get_organization(x509cert: &WrappedX509) -> Option<String> {\n    get_organization_x509(x509cert.borrow_cert())\n}\n\n/// Return the organization associated with the X509 certificate.\n/// see https://en.wikipedia.org/wiki/X.509#Structure_of_a_certificate\npub fn get_organization_x509(x509cert: &X509Certificate<'_>) -> Option<String> {\n    x509cert\n        .subject\n        .iter_organization()\n        .filter_map(|a| a.as_str().ok())\n        .map(|a| a.to_string())\n        .reduce(|cur, next| cur + &next)\n}\n\n/// Return the organization associated with the X509 certificate (as bytes).\n/// see https://en.wikipedia.org/wiki/X.509#Structure_of_a_certificate\npub fn get_organization_serial_bytes(cert: &[u8]) -> Result<(Option<String>, String)> {\n    let (_, x509cert) = x509_parser::certificate::X509Certificate::from_der(cert)\n        .expect(\"Failed to parse certificate from DER format.\");\n\n    get_organization_serial_x509(&x509cert)\n}\n\n/// Return the organization unit associated with the X509 certificate.\n/// see https://en.wikipedia.org/wiki/X.509#Structure_of_a_certificate\npub fn get_organization_unit(x509cert: &WrappedX509) -> Option<String> {\n    x509cert\n        .borrow_cert()\n        .subject\n        .iter_organizational_unit()\n        .filter_map(|a| a.as_str().ok())\n        .map(|a| a.to_string())\n        .reduce(|cur, next| cur + &next)\n}\n\n/// Get a combination of the common names for the given certificate\n/// see https://en.wikipedia.org/wiki/X.509#Structure_of_a_certificate\npub fn get_common_name(x509cert: &WrappedX509) -> Option<String> {\n    x509cert\n        .borrow_cert()\n        .subject\n        .iter_common_name()\n        .filter_map(|a| a.as_str().ok())\n        .map(|a| a.to_string())\n        .reduce(|cur, next| cur + &next)\n}\n\n/// Get the `not_after` field for the valid time period for the given cert\n/// see https://en.wikipedia.org/wiki/X.509#Structure_of_a_certificate\npub fn get_not_after(x509cert: &WrappedX509) -> String {\n    x509cert.borrow_cert().validity.not_after.to_string()\n}\n\n/// This type contains a list of one or more certificates and an associated private key. The leaf\n/// certificate should always be first.\npub struct CertKey {\n    key: Vec<u8>,\n    certificates: Vec<WrappedX509>,\n}\n\n#[self_referencing]\n#[derive(Debug)]\npub struct WrappedX509 {\n    raw_cert: Vec<u8>,\n\n    #[borrows(raw_cert)]\n    #[covariant]\n    cert: X509Certificate<'this>,\n}\n\nfn parse_x509<C>(raw_cert: &C) -> X509Certificate<'_>\nwhere\n    C: AsRef<[u8]>,\n{\n    X509Certificate::from_der(raw_cert.as_ref())\n        .expect(\"Failed to parse certificate from DER format.\")\n        .1\n}\n\nimpl Clone for CertKey {\n    fn clone(&self) -> Self {\n        CertKey {\n            key: self.key.clone(),\n            certificates: self\n                .certificates\n                .iter()\n                .map(|wrapper| WrappedX509::new(wrapper.borrow_raw_cert().clone(), parse_x509))\n                .collect::<Vec<_>>(),\n        }\n    }\n}\n\nimpl CertKey {\n    /// Create a new `CertKey` given a list of certificates and a private key.\n    pub fn new(certificates: Vec<Vec<u8>>, key: Vec<u8>) -> CertKey {\n        assert!(\n            !certificates.is_empty() && !certificates.first().unwrap().is_empty(),\n            \"expected a non-empty vector of certificates in CertKey::new\"\n        );\n\n        CertKey {\n            key,\n            certificates: certificates\n                .into_iter()\n                .map(|raw_cert| WrappedX509::new(raw_cert, parse_x509))\n                .collect::<Vec<_>>(),\n        }\n    }\n\n    /// Peek at the leaf certificate.\n    pub fn leaf(&self) -> &WrappedX509 {\n        // This is safe due to the assertion in creation of a `CertKey`\n        &self.certificates[0]\n    }\n\n    /// Return the key.\n    pub fn key(&self) -> &Vec<u8> {\n        &self.key\n    }\n\n    /// Return a slice of intermediate certificates. An empty slice means there are none.\n    pub fn intermediates(&self) -> Vec<&WrappedX509> {\n        self.certificates.iter().skip(1).collect()\n    }\n\n    /// Return the organization from the leaf certificate.\n    pub fn organization(&self) -> Option<String> {\n        get_organization(self.leaf())\n    }\n\n    /// Return the serial from the leaf certificate.\n    pub fn serial(&self) -> String {\n        get_serial(self.leaf()).unwrap()\n    }\n}\n\nimpl WrappedX509 {\n    pub fn not_after(&self) -> String {\n        self.borrow_cert().validity.not_after.to_string()\n    }\n}\n\n// hide private key\nimpl std::fmt::Debug for CertKey {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        f.debug_struct(\"CertKey\")\n            .field(\"X509\", &self.leaf())\n            .finish()\n    }\n}\n\nimpl std::fmt::Display for CertKey {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        let leaf = self.leaf();\n        if let Some(cn) = get_common_name(leaf) {\n            // Write CN if it exists\n            write!(f, \"CN: {cn},\")?;\n        } else if let Some(org_unit) = get_organization_unit(leaf) {\n            // CA cert might not have CN, so print its unit name instead\n            write!(f, \"Org Unit: {org_unit},\")?;\n        }\n        write!(f, \", expire: {}\", get_not_after(leaf))\n        // ignore the details of the private key\n    }\n}\n\nimpl Hash for CertKey {\n    fn hash<H: Hasher>(&self, state: &mut H) {\n        for certificate in &self.certificates {\n            if let Ok(serial) = get_serial(certificate) {\n                serial.hash(state)\n            }\n        }\n    }\n}\n\nimpl<'a> From<&'a WrappedX509> for CertificateDer<'static> {\n    fn from(value: &'a WrappedX509) -> Self {\n        CertificateDer::from(value.borrow_raw_cert().as_slice().to_owned())\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "f42ae3ab8c5ed203670f4378ccfd2188a3bb9367",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/pingora/pingora-core/src/protocols/digest.rs",
    "func": "// Copyright 2024 Cloudflare, Inc.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n// http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n//! Extra information about the connection\n\nuse std::sync::Arc;\nuse std::time::{Duration, SystemTime};\n\nuse once_cell::sync::OnceCell;\n\nuse super::l4::ext::{get_original_dest, get_recv_buf, get_tcp_info, TCP_INFO};\nuse super::l4::socket::SocketAddr;\nuse super::raw_connect::ProxyDigest;\nuse super::tls::digest::SslDigest;\n\n/// The information can be extracted from a connection\n#[derive(Clone, Debug, Default)]\npub struct Digest {\n    /// Information regarding the TLS of this connection if any\n    pub ssl_digest: Option<Arc<SslDigest>>,\n    /// Timing information\n    pub timing_digest: Vec<Option<TimingDigest>>,\n    /// information regarding the CONNECT proxy this connection uses.\n    pub proxy_digest: Option<Arc<ProxyDigest>>,\n    /// Information about underlying socket/fd of this connection\n    pub socket_digest: Option<Arc<SocketDigest>>,\n}\n\n/// The interface to return protocol related information\npub trait ProtoDigest {\n    fn get_digest(&self) -> Option<&Digest> {\n        None\n    }\n}\n\n/// The timing information of the connection\n#[derive(Clone, Debug)]\npub struct TimingDigest {\n    /// When this connection was established\n    pub established_ts: SystemTime,\n}\n\nimpl Default for TimingDigest {\n    fn default() -> Self {\n        TimingDigest {\n            established_ts: SystemTime::UNIX_EPOCH,\n        }\n    }\n}\n\n#[derive(Debug)]\n/// The interface to return socket-related information\npub struct SocketDigest {\n    #[cfg(unix)]\n    raw_fd: std::os::unix::io::RawFd,\n    #[cfg(windows)]\n    raw_sock: std::os::windows::io::RawSocket,\n    /// Remote socket address\n    pub peer_addr: OnceCell<Option<SocketAddr>>,\n    /// Local socket address\n    pub local_addr: OnceCell<Option<SocketAddr>>,\n    /// Original destination address\n    pub original_dst: OnceCell<Option<SocketAddr>>,\n}\n\nimpl SocketDigest {\n    #[cfg(unix)]\n    pub fn from_raw_fd(raw_fd: std::os::unix::io::RawFd) -> SocketDigest {\n        SocketDigest {\n            raw_fd,\n            peer_addr: OnceCell::new(),\n            local_addr: OnceCell::new(),\n            original_dst: OnceCell::new(),\n        }\n    }\n\n    #[cfg(windows)]\n    pub fn from_raw_socket(raw_sock: std::os::windows::io::RawSocket) -> SocketDigest {\n        SocketDigest {\n            raw_sock,\n            peer_addr: OnceCell::new(),\n            local_addr: OnceCell::new(),\n            original_dst: OnceCell::new(),\n        }\n    }\n\n    #[cfg(unix)]\n    pub fn peer_addr(&self) -> Option<&SocketAddr> {\n        self.peer_addr\n            .get_or_init(|| SocketAddr::from_raw_fd(self.raw_fd, true))\n            .as_ref()\n    }\n\n    #[cfg(windows)]\n    pub fn peer_addr(&self) -> Option<&SocketAddr> {\n        self.peer_addr\n            .get_or_init(|| SocketAddr::from_raw_socket(self.raw_sock, true))\n            .as_ref()\n    }\n\n    #[cfg(unix)]\n    pub fn local_addr(&self) -> Option<&SocketAddr> {\n        self.local_addr\n            .get_or_init(|| SocketAddr::from_raw_fd(self.raw_fd, false))\n            .as_ref()\n    }\n\n    #[cfg(windows)]\n    pub fn local_addr(&self) -> Option<&SocketAddr> {\n        self.local_addr\n            .get_or_init(|| SocketAddr::from_raw_socket(self.raw_sock, false))\n            .as_ref()\n    }\n\n    fn is_inet(&self) -> bool {\n        self.local_addr().and_then(|p| p.as_inet()).is_some()\n    }\n\n    #[cfg(unix)]\n    pub fn tcp_info(&self) -> Option<TCP_INFO> {\n        if self.is_inet() {\n            get_tcp_info(self.raw_fd).ok()\n        } else {\n            None\n        }\n    }\n\n    #[cfg(windows)]\n    pub fn tcp_info(&self) -> Option<TCP_INFO> {\n        if self.is_inet() {\n            get_tcp_info(self.raw_sock).ok()\n        } else {\n            None\n        }\n    }\n\n    #[cfg(unix)]\n    pub fn get_recv_buf(&self) -> Option<usize> {\n        if self.is_inet() {\n            get_recv_buf(self.raw_fd).ok()\n        } else {\n            None\n        }\n    }\n\n    #[cfg(windows)]\n    pub fn get_recv_buf(&self) -> Option<usize> {\n        if self.is_inet() {\n            get_recv_buf(self.raw_sock).ok()\n        } else {\n            None\n        }\n    }\n\n    #[cfg(unix)]\n    pub fn original_dst(&self) -> Option<&SocketAddr> {\n        self.original_dst\n            .get_or_init(|| {\n                get_original_dest(self.raw_fd)\n                    .ok()\n                    .flatten()\n                    .map(SocketAddr::Inet)\n            })\n            .as_ref()\n    }\n\n    #[cfg(windows)]\n    pub fn original_dst(&self) -> Option<&SocketAddr> {\n        self.original_dst\n            .get_or_init(|| {\n                get_original_dest(self.raw_sock)\n                    .ok()\n                    .flatten()\n                    .map(SocketAddr::Inet)\n            })\n            .as_ref()\n    }\n}\n\n/// The interface to return timing information\npub trait GetTimingDigest {\n    /// Return the timing for each layer from the lowest layer to upper\n    fn get_timing_digest(&self) -> Vec<Option<TimingDigest>>;\n    fn get_read_pending_time(&self) -> Duration {\n        Duration::ZERO\n    }\n    fn get_write_pending_time(&self) -> Duration {\n        Duration::ZERO\n    }\n}\n\n/// The interface to set or return proxy information\npub trait GetProxyDigest {\n    fn get_proxy_digest(&self) -> Option<Arc<ProxyDigest>>;\n    fn set_proxy_digest(&mut self, _digest: ProxyDigest) {}\n}\n\n/// The interface to set or return socket information\npub trait GetSocketDigest {\n    fn get_socket_digest(&self) -> Option<Arc<SocketDigest>>;\n    fn set_socket_digest(&mut self, _socket_digest: SocketDigest) {}\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "83cd6e5c7142dedb0e292458593fc44d5f1c1ccb",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/pingora/pingora-core/src/protocols/http/v2/client.rs",
    "func": "// Copyright 2024 Cloudflare, Inc.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n// http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n//! HTTP/2 client session and connection\n// TODO: this module needs a refactor\n\nuse bytes::Bytes;\nuse futures::FutureExt;\nuse h2::client::{self, ResponseFuture, SendRequest};\nuse h2::{Reason, RecvStream, SendStream};\nuse http::HeaderMap;\nuse log::{debug, error, warn};\nuse pingora_error::{Error, ErrorType, ErrorType::*, OrErr, Result, RetryType};\nuse pingora_http::{RequestHeader, ResponseHeader};\nuse pingora_timeout::timeout;\nuse std::sync::atomic::{AtomicBool, Ordering};\nuse std::sync::Arc;\nuse std::time::Duration;\nuse tokio::io::{AsyncRead, AsyncWrite};\nuse tokio::sync::watch;\n\nuse crate::connectors::http::v2::ConnectionRef;\nuse crate::protocols::{Digest, SocketAddr, UniqueIDType};\n\npub const PING_TIMEDOUT: ErrorType = ErrorType::new(\"PingTimedout\");\n\npub struct Http2Session {\n    send_req: SendRequest<Bytes>,\n    send_body: Option<SendStream<Bytes>>,\n    resp_fut: Option<ResponseFuture>,\n    req_sent: Option<Box<RequestHeader>>,\n    response_header: Option<ResponseHeader>,\n    response_body_reader: Option<RecvStream>,\n    /// The read timeout, which will be applied to both reading the header and the body.\n    /// The timeout is reset on every read. This is not a timeout on the overall duration of the\n    /// response.\n    pub read_timeout: Option<Duration>,\n    pub(crate) conn: ConnectionRef,\n    // Indicate that whether a END_STREAM is already sent\n    ended: bool,\n}\n\nimpl Drop for Http2Session {\n    fn drop(&mut self) {\n        self.conn.release_stream();\n    }\n}\n\nimpl Http2Session {\n    pub(crate) fn new(send_req: SendRequest<Bytes>, conn: ConnectionRef) -> Self {\n        Http2Session {\n            send_req,\n            send_body: None,\n            resp_fut: None,\n            req_sent: None,\n            response_header: None,\n            response_body_reader: None,\n            read_timeout: None,\n            conn,\n            ended: false,\n        }\n    }\n\n    fn sanitize_request_header(req: &mut RequestHeader) -> Result<()> {\n        req.set_version(http::Version::HTTP_2);\n        if req.uri.authority().is_some() {\n            return Ok(());\n        }\n        // use host header to populate :authority field\n        let Some(authority) = req.headers.get(http::header::HOST).map(|v| v.as_bytes()) else {\n            return Error::e_explain(InvalidHTTPHeader, \"no authority header for h2\");\n        };\n        let uri = http::uri::Builder::new()\n            .scheme(\"https\") // fixed for now\n            .authority(authority)\n            .path_and_query(req.uri.path_and_query().as_ref().unwrap().as_str())\n            .build();\n        match uri {\n            Ok(uri) => {\n                req.set_uri(uri);\n                Ok(())\n            }\n            Err(_) => Error::e_explain(\n                InvalidHTTPHeader,\n                format!(\"invalid authority from host {authority:?}\"),\n            ),\n        }\n    }\n\n    /// Write the request header to the server\n    pub fn write_request_header(&mut self, mut req: Box<RequestHeader>, end: bool) -> Result<()> {\n        if self.req_sent.is_some() {\n            // cannot send again, TODO: warn\n            return Ok(());\n        }\n        Self::sanitize_request_header(&mut req)?;\n        let parts = req.as_owned_parts();\n        let request = http::Request::from_parts(parts, ());\n        // There is no write timeout for h2 because the actual write happens async from this fn\n        let (resp_fut, send_body) = self\n            .send_req\n            .send_request(request, end)\n            .or_err(H2Error, \"while sending request\")\n            .map_err(|e| self.handle_err(e))?;\n        self.req_sent = Some(req);\n        self.send_body = Some(send_body);\n        self.resp_fut = Some(resp_fut);\n        self.ended = self.ended || end;\n\n        Ok(())\n    }\n\n    /// Write a request body chunk\n    pub fn write_request_body(&mut self, data: Bytes, end: bool) -> Result<()> {\n        if self.ended {\n            warn!(\"Try to write request body after end of stream, dropping the extra data\");\n            return Ok(());\n        }\n\n        let body_writer = self\n            .send_body\n            .as_mut()\n            .expect(\"Try to write request body before sending request header\");\n\n        write_body(body_writer, data, end).map_err(|e| self.handle_err(e))?;\n        self.ended = self.ended || end;\n        Ok(())\n    }\n\n    /// Signal that the request body has ended\n    pub fn finish_request_body(&mut self) -> Result<()> {\n        if self.ended {\n            return Ok(());\n        }\n\n        let body_writer = self\n            .send_body\n            .as_mut()\n            .expect(\"Try to finish request stream before sending request header\");\n\n        // Just send an empty data frame with end of stream set\n        body_writer\n            .send_data(\"\".into(), true)\n            .or_err(WriteError, \"while writing empty h2 request body\")\n            .map_err(|e| self.handle_err(e))?;\n        self.ended = true;\n        Ok(())\n    }\n\n    /// Read the response header\n    pub async fn read_response_header(&mut self) -> Result<()> {\n        // TODO: how to read 1xx headers?\n        // https://github.com/hyperium/h2/issues/167\n\n        if self.response_header.is_some() {\n            panic!(\"H2 response header is already read\")\n        }\n\n        let Some(resp_fut) = self.resp_fut.take() else {\n            panic!(\"Try to  response header is already read\")\n        };\n\n        let res = match self.read_timeout {\n            Some(t) => timeout(t, resp_fut)\n                .await\n                .map_err(|_| Error::explain(ReadTimedout, \"while reading h2 response header\"))\n                .map_err(|e| self.handle_err(e))?,\n            None => resp_fut.await,\n        };\n        let (resp, body_reader) = res.map_err(handle_read_header_error)?.into_parts();\n        self.response_header = Some(resp.into());\n        self.response_body_reader = Some(body_reader);\n\n        Ok(())\n    }\n\n    /// Read the response body\n    ///\n    /// `None` means, no more body to read\n    pub async fn read_response_body(&mut self) -> Result<Option<Bytes>> {\n        let Some(body_reader) = self.response_body_reader.as_mut() else {\n            // req is not sent or response is already read\n            // TODO: warn\n            return Ok(None);\n        };\n\n        let fut = body_reader.data();\n        let res = match self.read_timeout {\n            Some(t) => timeout(t, fut)\n                .await\n                .map_err(|_| Error::explain(ReadTimedout, \"while reading h2 response body\"))?,\n            None => fut.await,\n        };\n        let body = res\n            .transpose()\n            .or_err(ReadError, \"while read h2 response body\")\n            .map_err(|mut e| {\n                // cannot use handle_err() because of borrow checker\n                if self.conn.ping_timedout() {\n                    e.etype = PING_TIMEDOUT;\n                }\n                e\n            })?;\n\n        if let Some(data) = body.as_ref() {\n            body_reader\n                .flow_control()\n                .release_capacity(data.len())\n                .or_err(ReadError, \"while releasing h2 response body capacity\")?;\n        }\n\n        Ok(body)\n    }\n\n    /// Whether the response has ended\n    pub fn response_finished(&self) -> bool {\n        // if response_body_reader doesn't exist, the response is not even read yet\n        self.response_body_reader\n            .as_ref()\n            .map_or(false, |reader| reader.is_end_stream())\n    }\n\n    /// Check whether stream finished with error.\n    /// Like `response_finished`, but also attempts to poll the h2 stream for errors that may have\n    /// caused the stream to terminate, and returns them as `H2Error`s.\n    pub fn check_response_end_or_error(&mut self) -> Result<bool> {\n        let Some(reader) = self.response_body_reader.as_mut() else {\n            // response is not even read\n            return Ok(false);\n        };\n\n        if !reader.is_end_stream() {\n            return Ok(false);\n        }\n\n        // https://github.com/hyperium/h2/issues/806\n        // The fundamental issue is that h2::RecvStream may return `is_end_stream` true\n        // when the stream was naturally closed via END_STREAM /OR/ if there was an error\n        // while reading data frames that forced the closure.\n        // The h2 API as-is makes it difficult to determine which situation is occurring.\n        //\n        // `poll_data` should be returning None after `is_end_stream`, if the stream\n        // is truly expecting no more data to be sent.\n        // https://docs.rs/h2/latest/h2/struct.RecvStream.html#method.is_end_stream\n        // So poll the data once to check this condition. If an error is returned, that indicates\n        // that the stream closed due to an error e.g. h2 protocol error.\n        match reader.data().now_or_never() {\n            Some(None) => Ok(true),\n            Some(Some(Ok(_))) => Error::e_explain(H2Error, \"unexpected data after end stream\"),\n            Some(Some(Err(e))) => Error::e_because(H2Error, \"while checking end stream\", e),\n            None => {\n                // RecvStream data() should be ready to poll after the stream ends,\n                // this indicates an unexpected change in the h2 crate\n                panic!(\"data() not ready after end stream\")\n            }\n        }\n    }\n\n    /// Read the optional trailer headers\n    pub async fn read_trailers(&mut self) -> Result<Option<HeaderMap>> {\n        let Some(reader) = self.response_body_reader.as_mut() else {\n            // response is not even read\n            // TODO: warn\n            return Ok(None);\n        };\n        let fut = reader.trailers();\n\n        let res = match self.read_timeout {\n            Some(t) => timeout(t, fut)\n                .await\n                .map_err(|_| Error::explain(ReadTimedout, \"while reading h2 trailer\"))\n                .map_err(|e| self.handle_err(e))?,\n            None => fut.await,\n        };\n        match res {\n            Ok(t) => Ok(t),\n            Err(e) => {\n                // GOAWAY with no error: this is graceful shutdown, continue as if no trailer\n                // RESET_STREAM with no error: https://datatracker.ietf.org/doc/html/rfc9113#section-8.1:\n                // this is to signal client to stop uploading request without breaking the response.\n                // TODO: should actually stop uploading\n                // TODO: should we try reading again?\n                // TODO: handle this when reading headers and body as well\n                // https://github.com/hyperium/h2/issues/741\n\n                if (e.is_go_away() || e.is_reset())\n                    && e.is_remote()\n                    && e.reason() == Some(Reason::NO_ERROR)\n                {\n                    Ok(None)\n                } else {\n                    Err(e)\n                }\n            }\n        }\n        .or_err(ReadError, \"while reading h2 trailers\")\n    }\n\n    /// The request header if it is already sent\n    pub fn request_header(&self) -> Option<&RequestHeader> {\n        self.req_sent.as_deref()\n    }\n\n    /// The response header if it is already read\n    pub fn response_header(&self) -> Option<&ResponseHeader> {\n        self.response_header.as_ref()\n    }\n\n    /// Give up the http session abruptly.\n    pub fn shutdown(&mut self) {\n        if !self.ended || !self.response_finished() {\n            if let Some(send_body) = self.send_body.as_mut() {\n                send_body.send_reset(h2::Reason::INTERNAL_ERROR)\n            }\n        }\n    }\n\n    /// Drop everything in this h2 stream. Return the connection ref.\n    /// After this function the underlying h2 connection should already notify the closure of this\n    /// stream so that another stream can be created if needed.\n    pub(crate) fn conn(&self) -> ConnectionRef {\n        self.conn.clone()\n    }\n\n    /// Whether ping timeout occurred. After a ping timeout, the h2 connection will be terminated.\n    /// Ongoing h2 streams will receive an stream/connection error. The streams should check this\n    /// flag to tell whether the error is triggered by the timeout.\n    pub(crate) fn ping_timedout(&self) -> bool {\n        self.conn.ping_timedout()\n    }\n\n    /// Return the [Digest] of the connection\n    ///\n    /// For reused connection, the timing in the digest will reflect its initial handshakes\n    /// The caller should check if the connection is reused to avoid misuse the timing field.\n    pub fn digest(&self) -> Option<&Digest> {\n        Some(self.conn.digest())\n    }\n\n    /// Return a mutable [Digest] reference for the connection\n    ///\n    /// Will return `None` if multiple H2 streams are open.\n    pub fn digest_mut(&mut self) -> Option<&mut Digest> {\n        self.conn.digest_mut()\n    }\n\n    /// Return the server (peer) address recorded in the connection digest.\n    pub fn server_addr(&self) -> Option<&SocketAddr> {\n        self.conn\n            .digest()\n            .socket_digest\n            .as_ref()\n            .map(|d| d.peer_addr())?\n    }\n\n    /// Return the client (local) address recorded in the connection digest.\n    pub fn client_addr(&self) -> Option<&SocketAddr> {\n        self.conn\n            .digest()\n            .socket_digest\n            .as_ref()\n            .map(|d| d.local_addr())?\n    }\n\n    /// the FD of the underlying connection\n    pub fn fd(&self) -> UniqueIDType {\n        self.conn.id()\n    }\n\n    /// take the body sender to another task to perform duplex read and write\n    pub fn take_request_body_writer(&mut self) -> Option<SendStream<Bytes>> {\n        self.send_body.take()\n    }\n\n    fn handle_err(&self, mut e: Box<Error>) -> Box<Error> {\n        if self.ping_timedout() {\n            e.etype = PING_TIMEDOUT;\n        }\n\n        // is_go_away: retry via another connection, this connection is being teardown\n        // should retry\n        if self.response_header.is_none() {\n            if let Some(err) = e.root_cause().downcast_ref::<h2::Error>() {\n                if err.is_go_away()\n                    && err.is_remote()\n                    && err.reason().map_or(false, |r| r == h2::Reason::NO_ERROR)\n                {\n                    e.retry = true.into();\n                }\n            }\n        }\n        e\n    }\n}\n\n/// A helper function to write the request body\npub fn write_body(send_body: &mut SendStream<Bytes>, data: Bytes, end: bool) -> Result<()> {\n    let data_len = data.len();\n    send_body.reserve_capacity(data_len);\n    send_body\n        .send_data(data, end)\n        .or_err(WriteError, \"while writing h2 request body\")\n}\n\n/* helper functions */\n\n/* Types of errors during h2 header read\n 1. peer requests to downgrade to h1, mostly IIS server for NTLM: we will downgrade and retry\n 2. peer sends invalid h2 frames, usually sending h1 only header: we will downgrade and retry\n 3. peer sends GO_AWAY(NO_ERROR) connection is being shut down: we will retry\n 4. peer IO error on reused conn, usually firewall kills old conn: we will retry\n 5. All other errors will terminate the request\n*/\nfn handle_read_header_error(e: h2::Error) -> Box<Error> {\n    if e.is_remote()\n        && e.reason()\n            .map_or(false, |r| r == h2::Reason::HTTP_1_1_REQUIRED)\n    {\n        let mut err = Error::because(H2Downgrade, \"while reading h2 header\", e);\n        err.retry = true.into();\n        err\n    } else if e.is_go_away()\n        && e.is_library()\n        && e.reason()\n            .map_or(false, |r| r == h2::Reason::PROTOCOL_ERROR)\n    {\n        // remote send invalid H2 responses\n        let mut err = Error::because(InvalidH2, \"while reading h2 header\", e);\n        err.retry = true.into();\n        err\n    } else if e.is_go_away()\n        && e.is_remote()\n        && e.reason().map_or(false, |r| r == h2::Reason::NO_ERROR)\n    {\n        // is_go_away: retry via another connection, this connection is being teardown\n        let mut err = Error::because(H2Error, \"while reading h2 header\", e);\n        err.retry = true.into();\n        err\n    } else if e.is_io() {\n        // is_io: typical if a previously reused connection silently drops it\n        // only retry if the connection is reused\n        let true_io_error = e.get_io().unwrap().raw_os_error().is_some();\n        let mut err = Error::because(ReadError, \"while reading h2 header\", e);\n        if true_io_error {\n            err.retry = RetryType::ReusedOnly;\n        } // else could be TLS error, which is unsafe to retry\n        err\n    } else {\n        Error::because(H2Error, \"while reading h2 header\", e)\n    }\n}\n\nuse tokio::sync::oneshot;\n\npub async fn drive_connection<S>(\n    mut c: client::Connection<S>,\n    id: UniqueIDType,\n    closed: watch::Sender<bool>,\n    ping_interval: Option<Duration>,\n    ping_timeout_occurred: Arc<AtomicBool>,\n) where\n    S: AsyncRead + AsyncWrite + Send + Unpin,\n{\n    let interval = ping_interval.unwrap_or(Duration::ZERO);\n    if !interval.is_zero() {\n        // for ping to inform this fn to drop the connection\n        let (tx, rx) = oneshot::channel::<()>();\n        // for this fn to inform ping to give up when it is already dropped\n        let dropped = Arc::new(AtomicBool::new(false));\n        let dropped2 = dropped.clone();\n\n        if let Some(ping_pong) = c.ping_pong() {\n            pingora_runtime::current_handle().spawn(async move {\n                do_ping_pong(ping_pong, interval, tx, dropped2, id).await;\n            });\n        } else {\n            warn!(\"Cannot get ping-pong handler from h2 connection\");\n        }\n\n        tokio::select! {\n            r = c => match r {\n                Ok(_) => debug!(\"H2 connection finished fd: {id}\"),\n                Err(e) => debug!(\"H2 connection fd: {id} errored: {e:?}\"),\n            },\n            r = rx => match r {\n                Ok(_) => {\n                    ping_timeout_occurred.store(true, Ordering::Relaxed);\n                    warn!(\"H2 connection Ping timeout/Error fd: {id}, closing conn\");\n                },\n                Err(e) => warn!(\"H2 connection Ping Rx error {e:?}\"),\n            },\n        };\n\n        dropped.store(true, Ordering::Relaxed);\n    } else {\n        match c.await {\n            Ok(_) => debug!(\"H2 connection finished fd: {id}\"),\n            Err(e) => debug!(\"H2 connection fd: {id} errored: {e:?}\"),\n        }\n    }\n    let _ = closed.send(true);\n}\n\nconst PING_TIMEOUT: Duration = Duration::from_secs(5);\n\nasync fn do_ping_pong(\n    mut ping_pong: h2::PingPong,\n    interval: Duration,\n    tx: oneshot::Sender<()>,\n    dropped: Arc<AtomicBool>,\n    id: UniqueIDType,\n) {\n    // delay before sending the first ping, no need to race with the first request\n    tokio::time::sleep(interval).await;\n    loop {\n        if dropped.load(Ordering::Relaxed) {\n            break;\n        }\n        let ping_fut = ping_pong.ping(h2::Ping::opaque());\n        debug!(\"H2 fd: {id} ping sent\");\n        match tokio::time::timeout(PING_TIMEOUT, ping_fut).await {\n            Err(_) => {\n                error!(\"H2 fd: {id} ping timeout\");\n                let _ = tx.send(());\n                break;\n            }\n            Ok(r) => match r {\n                Ok(_) => {\n                    debug!(\"H2 fd: {} pong received\", id);\n                    tokio::time::sleep(interval).await;\n                }\n                Err(e) => {\n                    if dropped.load(Ordering::Relaxed) {\n                        // drive_connection() exits first, no need to error again\n                        break;\n                    }\n                    error!(\"H2 fd: {id} ping error: {e}\");\n                    let _ = tx.send(());\n                    break;\n                }\n            },\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "db366d77485f8577db9c7bd9502b8e80d6ceae85",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/pingora/pingora-core/src/protocols/http/compression/zstd.rs",
    "func": "// Copyright 2024 Cloudflare, Inc.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n// http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\nuse super::{Encode, COMPRESSION_ERROR};\nuse bytes::Bytes;\nuse parking_lot::Mutex;\nuse pingora_error::{OrErr, Result};\nuse std::io::Write;\nuse std::time::{Duration, Instant};\nuse zstd::stream::write::Encoder;\n\npub struct Compressor {\n    compress: Mutex<Encoder<'static, Vec<u8>>>,\n    total_in: usize,\n    total_out: usize,\n    duration: Duration,\n}\n\nimpl Compressor {\n    pub fn new(level: u32) -> Self {\n        Compressor {\n            // Mutex because Encoder is not Sync\n            // https://github.com/gyscos/zstd-rs/issues/186\n            compress: Mutex::new(Encoder::new(vec![], level as i32).unwrap()),\n            total_in: 0,\n            total_out: 0,\n            duration: Duration::new(0, 0),\n        }\n    }\n}\n\nimpl Encode for Compressor {\n    fn encode(&mut self, input: &[u8], end: bool) -> Result<Bytes> {\n        // reserve at most 16k\n        const MAX_INIT_COMPRESSED_BUF_SIZE: usize = 16 * 1024;\n        let start = Instant::now();\n        self.total_in += input.len();\n        let mut compress = self.compress.lock();\n        // reserve at most input size, cap at 16k, compressed output should be smaller\n        compress\n            .get_mut()\n            .reserve(std::cmp::min(MAX_INIT_COMPRESSED_BUF_SIZE, input.len()));\n        compress\n            .write_all(input)\n            .or_err(COMPRESSION_ERROR, \"while compress zstd\")?;\n        // write to vec will never fail.\n        if end {\n            compress\n                .do_finish()\n                .or_err(COMPRESSION_ERROR, \"while compress zstd\")?;\n        }\n        self.total_out += compress.get_ref().len();\n        self.duration += start.elapsed();\n        Ok(std::mem::take(compress.get_mut()).into()) // into() Bytes will drop excess capacity\n    }\n\n    fn stat(&self) -> (&'static str, usize, usize, Duration) {\n        (\"zstd\", self.total_in, self.total_out, self.duration)\n    }\n}\n\n#[cfg(test)]\nmod tests_stream {\n    use super::*;\n\n    #[test]\n    fn compress_zstd_data() {\n        let mut compressor = Compressor::new(11);\n        let input = b\"adcdefgabcdefghadcdefgabcdefghadcdefgabcdefghadcdefgabcdefgh\\n\";\n        let compressed = compressor.encode(&input[..], false).unwrap();\n        // waiting for more data\n        assert!(compressed.is_empty());\n\n        let compressed = compressor.encode(&input[..], true).unwrap();\n\n        // the zstd Magic_Number\n        assert_eq!(&compressed[..4], &[0x28, 0xB5, 0x2F, 0xFD]);\n        assert!(compressed.len() < input.len());\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "fa8c6e38d7fb20110eb2c05d1af2f72f60780f93",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/serde/serde_derive_internals/src/ast.rs",
    "func": "//! A Serde ast, parsed from the Syn ast and ready to generate Rust code.\n\nuse crate::internals::{attr, check, Ctxt, Derive};\nuse syn::punctuated::Punctuated;\nuse syn::Token;\n\n/// A source data structure annotated with `#[derive(Serialize)]` and/or `#[derive(Deserialize)]`,\n/// parsed into an internal representation.\npub struct Container<'a> {\n    /// The struct or enum name (without generics).\n    pub ident: syn::Ident,\n    /// Attributes on the structure, parsed for Serde.\n    pub attrs: attr::Container,\n    /// The contents of the struct or enum.\n    pub data: Data<'a>,\n    /// Any generics on the struct or enum.\n    pub generics: &'a syn::Generics,\n    /// Original input.\n    pub original: &'a syn::DeriveInput,\n}\n\n/// The fields of a struct or enum.\n///\n/// Analogous to `syn::Data`.\npub enum Data<'a> {\n    Enum(Vec<Variant<'a>>),\n    Struct(Style, Vec<Field<'a>>),\n}\n\n/// A variant of an enum.\npub struct Variant<'a> {\n    pub ident: syn::Ident,\n    pub attrs: attr::Variant,\n    pub style: Style,\n    pub fields: Vec<Field<'a>>,\n    pub original: &'a syn::Variant,\n}\n\n/// A field of a struct.\npub struct Field<'a> {\n    pub member: syn::Member,\n    pub attrs: attr::Field,\n    pub ty: &'a syn::Type,\n    pub original: &'a syn::Field,\n}\n\n#[derive(Copy, Clone)]\npub enum Style {\n    /// Named fields.\n    Struct,\n    /// Many unnamed fields.\n    Tuple,\n    /// One unnamed field.\n    Newtype,\n    /// No fields.\n    Unit,\n}\n\nimpl<'a> Container<'a> {\n    /// Convert the raw Syn ast into a parsed container object, collecting errors in `cx`.\n    pub fn from_ast(\n        cx: &Ctxt,\n        item: &'a syn::DeriveInput,\n        derive: Derive,\n    ) -> Option<Container<'a>> {\n        let attrs = attr::Container::from_ast(cx, item);\n\n        let mut data = match &item.data {\n            syn::Data::Enum(data) => Data::Enum(enum_from_ast(cx, &data.variants, attrs.default())),\n            syn::Data::Struct(data) => {\n                let (style, fields) = struct_from_ast(cx, &data.fields, None, attrs.default());\n                Data::Struct(style, fields)\n            }\n            syn::Data::Union(_) => {\n                cx.error_spanned_by(item, \"Serde does not support derive for unions\");\n                return None;\n            }\n        };\n\n        match &mut data {\n            Data::Enum(variants) => {\n                for variant in variants {\n                    variant.attrs.rename_by_rules(attrs.rename_all_rules());\n                    for field in &mut variant.fields {\n                        field.attrs.rename_by_rules(\n                            variant\n                                .attrs\n                                .rename_all_rules()\n                                .or(attrs.rename_all_fields_rules()),\n                        );\n                    }\n                }\n            }\n            Data::Struct(_, fields) => {\n                for field in fields {\n                    field.attrs.rename_by_rules(attrs.rename_all_rules());\n                }\n            }\n        }\n\n        let mut item = Container {\n            ident: item.ident.clone(),\n            attrs,\n            data,\n            generics: &item.generics,\n            original: item,\n        };\n        check::check(cx, &mut item, derive);\n        Some(item)\n    }\n}\n\nimpl<'a> Data<'a> {\n    pub fn all_fields(&'a self) -> Box<dyn Iterator<Item = &'a Field<'a>> + 'a> {\n        match self {\n            Data::Enum(variants) => {\n                Box::new(variants.iter().flat_map(|variant| variant.fields.iter()))\n            }\n            Data::Struct(_, fields) => Box::new(fields.iter()),\n        }\n    }\n\n    pub fn has_getter(&self) -> bool {\n        self.all_fields().any(|f| f.attrs.getter().is_some())\n    }\n}\n\nfn enum_from_ast<'a>(\n    cx: &Ctxt,\n    variants: &'a Punctuated<syn::Variant, Token![,]>,\n    container_default: &attr::Default,\n) -> Vec<Variant<'a>> {\n    let variants: Vec<Variant> = variants\n        .iter()\n        .map(|variant| {\n            let attrs = attr::Variant::from_ast(cx, variant);\n            let (style, fields) =\n                struct_from_ast(cx, &variant.fields, Some(&attrs), container_default);\n            Variant {\n                ident: variant.ident.clone(),\n                attrs,\n                style,\n                fields,\n                original: variant,\n            }\n        })\n        .collect();\n\n    let index_of_last_tagged_variant = variants\n        .iter()\n        .rposition(|variant| !variant.attrs.untagged());\n    if let Some(index_of_last_tagged_variant) = index_of_last_tagged_variant {\n        for variant in &variants[..index_of_last_tagged_variant] {\n            if variant.attrs.untagged() {\n                cx.error_spanned_by(&variant.ident, \"all variants with the #[serde(untagged)] attribute must be placed at the end of the enum\");\n            }\n        }\n    }\n\n    variants\n}\n\nfn struct_from_ast<'a>(\n    cx: &Ctxt,\n    fields: &'a syn::Fields,\n    attrs: Option<&attr::Variant>,\n    container_default: &attr::Default,\n) -> (Style, Vec<Field<'a>>) {\n    match fields {\n        syn::Fields::Named(fields) => (\n            Style::Struct,\n            fields_from_ast(cx, &fields.named, attrs, container_default),\n        ),\n        syn::Fields::Unnamed(fields) if fields.unnamed.len() == 1 => (\n            Style::Newtype,\n            fields_from_ast(cx, &fields.unnamed, attrs, container_default),\n        ),\n        syn::Fields::Unnamed(fields) => (\n            Style::Tuple,\n            fields_from_ast(cx, &fields.unnamed, attrs, container_default),\n        ),\n        syn::Fields::Unit => (Style::Unit, Vec::new()),\n    }\n}\n\nfn fields_from_ast<'a>(\n    cx: &Ctxt,\n    fields: &'a Punctuated<syn::Field, Token![,]>,\n    attrs: Option<&attr::Variant>,\n    container_default: &attr::Default,\n) -> Vec<Field<'a>> {\n    fields\n        .iter()\n        .enumerate()\n        .map(|(i, field)| Field {\n            member: match &field.ident {\n                Some(ident) => syn::Member::Named(ident.clone()),\n                None => syn::Member::Unnamed(i.into()),\n            },\n            attrs: attr::Field::from_ast(cx, i, field, attrs, container_default),\n            ty: &field.ty,\n            original: field,\n        })\n        .collect()\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "4b2c21bcfe72bff1e6906a7ed45392eba4604c4c",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/serde/serde_derive_internals/src/symbol.rs",
    "func": "use std::fmt::{self, Display};\nuse syn::{Ident, Path};\n\n#[derive(Copy, Clone)]\npub struct Symbol(&'static str);\n\npub const ALIAS: Symbol = Symbol(\"alias\");\npub const BORROW: Symbol = Symbol(\"borrow\");\npub const BOUND: Symbol = Symbol(\"bound\");\npub const CONTENT: Symbol = Symbol(\"content\");\npub const CRATE: Symbol = Symbol(\"crate\");\npub const DEFAULT: Symbol = Symbol(\"default\");\npub const DENY_UNKNOWN_FIELDS: Symbol = Symbol(\"deny_unknown_fields\");\npub const DESERIALIZE: Symbol = Symbol(\"deserialize\");\npub const DESERIALIZE_WITH: Symbol = Symbol(\"deserialize_with\");\npub const EXPECTING: Symbol = Symbol(\"expecting\");\npub const FIELD_IDENTIFIER: Symbol = Symbol(\"field_identifier\");\npub const FLATTEN: Symbol = Symbol(\"flatten\");\npub const FROM: Symbol = Symbol(\"from\");\npub const GETTER: Symbol = Symbol(\"getter\");\npub const INTO: Symbol = Symbol(\"into\");\npub const NON_EXHAUSTIVE: Symbol = Symbol(\"non_exhaustive\");\npub const OTHER: Symbol = Symbol(\"other\");\npub const REMOTE: Symbol = Symbol(\"remote\");\npub const RENAME: Symbol = Symbol(\"rename\");\npub const RENAME_ALL: Symbol = Symbol(\"rename_all\");\npub const RENAME_ALL_FIELDS: Symbol = Symbol(\"rename_all_fields\");\npub const REPR: Symbol = Symbol(\"repr\");\npub const SERDE: Symbol = Symbol(\"serde\");\npub const SERIALIZE: Symbol = Symbol(\"serialize\");\npub const SERIALIZE_WITH: Symbol = Symbol(\"serialize_with\");\npub const SKIP: Symbol = Symbol(\"skip\");\npub const SKIP_DESERIALIZING: Symbol = Symbol(\"skip_deserializing\");\npub const SKIP_SERIALIZING: Symbol = Symbol(\"skip_serializing\");\npub const SKIP_SERIALIZING_IF: Symbol = Symbol(\"skip_serializing_if\");\npub const TAG: Symbol = Symbol(\"tag\");\npub const TRANSPARENT: Symbol = Symbol(\"transparent\");\npub const TRY_FROM: Symbol = Symbol(\"try_from\");\npub const UNTAGGED: Symbol = Symbol(\"untagged\");\npub const VARIANT_IDENTIFIER: Symbol = Symbol(\"variant_identifier\");\npub const WITH: Symbol = Symbol(\"with\");\n\nimpl PartialEq<Symbol> for Ident {\n    fn eq(&self, word: &Symbol) -> bool {\n        self == word.0\n    }\n}\n\nimpl PartialEq<Symbol> for &Ident {\n    fn eq(&self, word: &Symbol) -> bool {\n        *self == word.0\n    }\n}\n\nimpl PartialEq<Symbol> for Path {\n    fn eq(&self, word: &Symbol) -> bool {\n        self.is_ident(word.0)\n    }\n}\n\nimpl PartialEq<Symbol> for &Path {\n    fn eq(&self, word: &Symbol) -> bool {\n        self.is_ident(word.0)\n    }\n}\n\nimpl Display for Symbol {\n    fn fmt(&self, formatter: &mut fmt::Formatter) -> fmt::Result {\n        formatter.write_str(self.0)\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "251ea143c9ad97856a1a73521b3ce0fe5b09f118",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/serde/serde/src/macros.rs",
    "func": "// Super explicit first paragraph because this shows up at the top level and\n// trips up people who are just looking for basic Serialize / Deserialize\n// documentation.\n//\n/// Helper macro when implementing the `Deserializer` part of a new data format\n/// for Serde.\n///\n/// Some [`Deserializer`] implementations for self-describing formats do not\n/// care what hint the [`Visitor`] gives them, they just want to blindly call\n/// the [`Visitor`] method corresponding to the data they can tell is in the\n/// input. This requires repetitive implementations of all the [`Deserializer`]\n/// trait methods.\n///\n/// ```edition2021\n/// # use serde::forward_to_deserialize_any;\n/// # use serde::de::{value, Deserializer, Visitor};\n/// #\n/// # struct MyDeserializer;\n/// #\n/// # impl<'de> Deserializer<'de> for MyDeserializer {\n/// #     type Error = value::Error;\n/// #\n/// #     fn deserialize_any<V>(self, _: V) -> Result<V::Value, Self::Error>\n/// #     where\n/// #         V: Visitor<'de>,\n/// #     {\n/// #         unimplemented!()\n/// #     }\n/// #\n/// #[inline]\n/// fn deserialize_bool<V>(self, visitor: V) -> Result<V::Value, Self::Error>\n/// where\n///     V: Visitor<'de>,\n/// {\n///     self.deserialize_any(visitor)\n/// }\n/// #\n/// #     forward_to_deserialize_any! {\n/// #         i8 i16 i32 i64 i128 u8 u16 u32 u64 u128 f32 f64 char str string\n/// #         bytes byte_buf option unit unit_struct newtype_struct seq tuple\n/// #         tuple_struct map struct enum identifier ignored_any\n/// #     }\n/// # }\n/// ```\n///\n/// The `forward_to_deserialize_any!` macro implements these simple forwarding\n/// methods so that they forward directly to [`Deserializer::deserialize_any`].\n/// You can choose which methods to forward.\n///\n/// ```edition2021\n/// # use serde::forward_to_deserialize_any;\n/// # use serde::de::{value, Deserializer, Visitor};\n/// #\n/// # struct MyDeserializer;\n/// #\n/// impl<'de> Deserializer<'de> for MyDeserializer {\n/// #   type Error = value::Error;\n/// #\n///     fn deserialize_any<V>(self, visitor: V) -> Result<V::Value, Self::Error>\n///     where\n///         V: Visitor<'de>,\n///     {\n///         /* ... */\n/// #       let _ = visitor;\n/// #       unimplemented!()\n///     }\n///\n///     forward_to_deserialize_any! {\n///         bool i8 i16 i32 i64 i128 u8 u16 u32 u64 u128 f32 f64 char str string\n///         bytes byte_buf option unit unit_struct newtype_struct seq tuple\n///         tuple_struct map struct enum identifier ignored_any\n///     }\n/// }\n/// ```\n///\n/// The macro assumes the convention that your `Deserializer` lifetime parameter\n/// is called `'de` and that the `Visitor` type parameters on each method are\n/// called `V`. A different type parameter and a different lifetime can be\n/// specified explicitly if necessary.\n///\n/// ```edition2021\n/// # use serde::forward_to_deserialize_any;\n/// # use serde::de::{value, Deserializer, Visitor};\n/// # use std::marker::PhantomData;\n/// #\n/// # struct MyDeserializer<V>(PhantomData<V>);\n/// #\n/// # impl<'q, V> Deserializer<'q> for MyDeserializer<V> {\n/// #     type Error = value::Error;\n/// #\n/// #     fn deserialize_any<W>(self, visitor: W) -> Result<W::Value, Self::Error>\n/// #     where\n/// #         W: Visitor<'q>,\n/// #     {\n/// #         unimplemented!()\n/// #     }\n/// #\n/// forward_to_deserialize_any! {\n///     <W: Visitor<'q>>\n///     bool i8 i16 i32 i64 i128 u8 u16 u32 u64 u128 f32 f64 char str string\n///     bytes byte_buf option unit unit_struct newtype_struct seq tuple\n///     tuple_struct map struct enum identifier ignored_any\n/// }\n/// # }\n/// ```\n///\n/// [`Deserializer`]: trait.Deserializer.html\n/// [`Visitor`]: de/trait.Visitor.html\n/// [`Deserializer::deserialize_any`]: trait.Deserializer.html#tymethod.deserialize_any\n#[macro_export(local_inner_macros)]\nmacro_rules! forward_to_deserialize_any {\n    (<$visitor:ident: Visitor<$lifetime:tt>> $($func:ident)*) => {\n        $(forward_to_deserialize_any_helper!{$func<$lifetime, $visitor>})*\n    };\n    // This case must be after the previous one.\n    ($($func:ident)*) => {\n        $(forward_to_deserialize_any_helper!{$func<'de, V>})*\n    };\n}\n\n#[doc(hidden)]\n#[macro_export]\nmacro_rules! forward_to_deserialize_any_method {\n    ($func:ident<$l:tt, $v:ident>($($arg:ident : $ty:ty),*)) => {\n        #[inline]\n        fn $func<$v>(self, $($arg: $ty,)* visitor: $v) -> $crate::__private::Result<$v::Value, <Self as $crate::de::Deserializer<$l>>::Error>\n        where\n            $v: $crate::de::Visitor<$l>,\n        {\n            $(\n                let _ = $arg;\n            )*\n            self.deserialize_any(visitor)\n        }\n    };\n}\n\n#[doc(hidden)]\n#[macro_export(local_inner_macros)]\nmacro_rules! forward_to_deserialize_any_helper {\n    (bool<$l:tt, $v:ident>) => {\n        forward_to_deserialize_any_method!{deserialize_bool<$l, $v>()}\n    };\n    (i8<$l:tt, $v:ident>) => {\n        forward_to_deserialize_any_method!{deserialize_i8<$l, $v>()}\n    };\n    (i16<$l:tt, $v:ident>) => {\n        forward_to_deserialize_any_method!{deserialize_i16<$l, $v>()}\n    };\n    (i32<$l:tt, $v:ident>) => {\n        forward_to_deserialize_any_method!{deserialize_i32<$l, $v>()}\n    };\n    (i64<$l:tt, $v:ident>) => {\n        forward_to_deserialize_any_method!{deserialize_i64<$l, $v>()}\n    };\n    (i128<$l:tt, $v:ident>) => {\n        forward_to_deserialize_any_method!{deserialize_i128<$l, $v>()}\n    };\n    (u8<$l:tt, $v:ident>) => {\n        forward_to_deserialize_any_method!{deserialize_u8<$l, $v>()}\n    };\n    (u16<$l:tt, $v:ident>) => {\n        forward_to_deserialize_any_method!{deserialize_u16<$l, $v>()}\n    };\n    (u32<$l:tt, $v:ident>) => {\n        forward_to_deserialize_any_method!{deserialize_u32<$l, $v>()}\n    };\n    (u64<$l:tt, $v:ident>) => {\n        forward_to_deserialize_any_method!{deserialize_u64<$l, $v>()}\n    };\n    (u128<$l:tt, $v:ident>) => {\n        forward_to_deserialize_any_method!{deserialize_u128<$l, $v>()}\n    };\n    (f32<$l:tt, $v:ident>) => {\n        forward_to_deserialize_any_method!{deserialize_f32<$l, $v>()}\n    };\n    (f64<$l:tt, $v:ident>) => {\n        forward_to_deserialize_any_method!{deserialize_f64<$l, $v>()}\n    };\n    (char<$l:tt, $v:ident>) => {\n        forward_to_deserialize_any_method!{deserialize_char<$l, $v>()}\n    };\n    (str<$l:tt, $v:ident>) => {\n        forward_to_deserialize_any_method!{deserialize_str<$l, $v>()}\n    };\n    (string<$l:tt, $v:ident>) => {\n        forward_to_deserialize_any_method!{deserialize_string<$l, $v>()}\n    };\n    (bytes<$l:tt, $v:ident>) => {\n        forward_to_deserialize_any_method!{deserialize_bytes<$l, $v>()}\n    };\n    (byte_buf<$l:tt, $v:ident>) => {\n        forward_to_deserialize_any_method!{deserialize_byte_buf<$l, $v>()}\n    };\n    (option<$l:tt, $v:ident>) => {\n        forward_to_deserialize_any_method!{deserialize_option<$l, $v>()}\n    };\n    (unit<$l:tt, $v:ident>) => {\n        forward_to_deserialize_any_method!{deserialize_unit<$l, $v>()}\n    };\n    (unit_struct<$l:tt, $v:ident>) => {\n        forward_to_deserialize_any_method!{deserialize_unit_struct<$l, $v>(name: &'static str)}\n    };\n    (newtype_struct<$l:tt, $v:ident>) => {\n        forward_to_deserialize_any_method!{deserialize_newtype_struct<$l, $v>(name: &'static str)}\n    };\n    (seq<$l:tt, $v:ident>) => {\n        forward_to_deserialize_any_method!{deserialize_seq<$l, $v>()}\n    };\n    (tuple<$l:tt, $v:ident>) => {\n        forward_to_deserialize_any_method!{deserialize_tuple<$l, $v>(len: usize)}\n    };\n    (tuple_struct<$l:tt, $v:ident>) => {\n        forward_to_deserialize_any_method!{deserialize_tuple_struct<$l, $v>(name: &'static str, len: usize)}\n    };\n    (map<$l:tt, $v:ident>) => {\n        forward_to_deserialize_any_method!{deserialize_map<$l, $v>()}\n    };\n    (struct<$l:tt, $v:ident>) => {\n        forward_to_deserialize_any_method!{deserialize_struct<$l, $v>(name: &'static str, fields: &'static [&'static str])}\n    };\n    (enum<$l:tt, $v:ident>) => {\n        forward_to_deserialize_any_method!{deserialize_enum<$l, $v>(name: &'static str, variants: &'static [&'static str])}\n    };\n    (identifier<$l:tt, $v:ident>) => {\n        forward_to_deserialize_any_method!{deserialize_identifier<$l, $v>()}\n    };\n    (ignored_any<$l:tt, $v:ident>) => {\n        forward_to_deserialize_any_method!{deserialize_ignored_any<$l, $v>()}\n    };\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "e13aa5777bd93429f8a49499425878f15813b68b",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/serde/test_suite/tests/test_de.rs",
    "func": "#![allow(\n    clippy::cast_lossless,\n    clippy::decimal_literal_representation,\n    clippy::derive_partial_eq_without_eq,\n    clippy::empty_enum,\n    clippy::manual_assert,\n    clippy::needless_pass_by_value,\n    clippy::uninlined_format_args,\n    clippy::unreadable_literal\n)]\n#![cfg_attr(feature = \"unstable\", feature(never_type))]\n\nuse serde::de::value::{F32Deserializer, F64Deserializer};\nuse serde::de::{Deserialize, DeserializeOwned, Deserializer, IntoDeserializer};\nuse serde_derive::Deserialize;\nuse serde_test::{assert_de_tokens, Configure, Token};\nuse std::collections::{BTreeMap, BTreeSet, HashMap, HashSet};\nuse std::default::Default;\nuse std::ffi::{CStr, CString, OsString};\nuse std::fmt::Debug;\nuse std::iter;\nuse std::net;\nuse std::num::{\n    NonZeroI128, NonZeroI16, NonZeroI32, NonZeroI64, NonZeroI8, NonZeroIsize, NonZeroU128,\n    NonZeroU16, NonZeroU32, NonZeroU64, NonZeroU8, NonZeroUsize, Saturating, Wrapping,\n};\nuse std::ops::Bound;\nuse std::path::{Path, PathBuf};\nuse std::rc::{Rc, Weak as RcWeak};\nuse std::sync::atomic::{\n    AtomicBool, AtomicI16, AtomicI32, AtomicI8, AtomicIsize, AtomicU16, AtomicU32, AtomicU8,\n    AtomicUsize, Ordering,\n};\n#[cfg(target_arch = \"x86_64\")]\nuse std::sync::atomic::{AtomicI64, AtomicU64};\nuse std::sync::{Arc, Weak as ArcWeak};\nuse std::time::{Duration, UNIX_EPOCH};\n\n#[macro_use]\nmod macros;\n\n//////////////////////////////////////////////////////////////////////////\n\n#[derive(Copy, Clone, PartialEq, Debug, Deserialize)]\nstruct UnitStruct;\n\n#[derive(Copy, Clone, PartialEq, Debug, Deserialize)]\nstruct GenericUnitStruct<const N: u8>;\n\n#[derive(PartialEq, Debug, Deserialize)]\nstruct NewtypeStruct(i32);\n\n#[derive(PartialEq, Debug, Deserialize)]\nstruct TupleStruct(i32, i32, i32);\n\n#[derive(PartialEq, Debug, Deserialize)]\nstruct Struct {\n    a: i32,\n    b: i32,\n    #[serde(skip_deserializing)]\n    c: i32,\n}\n\n#[derive(PartialEq, Debug, Deserialize)]\n#[serde(default)]\nstruct StructDefault<T> {\n    a: i32,\n    b: T,\n}\n\nimpl Default for StructDefault<String> {\n    fn default() -> Self {\n        StructDefault {\n            a: 100,\n            b: \"default\".to_string(),\n        }\n    }\n}\n\n#[derive(PartialEq, Debug, Deserialize)]\nstruct StructSkipAll {\n    #[serde(skip_deserializing)]\n    a: i32,\n}\n\n#[derive(PartialEq, Debug, Deserialize)]\n#[serde(default)]\nstruct StructSkipDefault {\n    #[serde(skip_deserializing)]\n    a: i32,\n}\n\n#[derive(PartialEq, Debug, Deserialize)]\n#[serde(default)]\npub struct StructSkipDefaultGeneric<T> {\n    #[serde(skip_deserializing)]\n    t: T,\n}\n\nimpl Default for StructSkipDefault {\n    fn default() -> Self {\n        StructSkipDefault { a: 16 }\n    }\n}\n\n#[derive(PartialEq, Debug, Deserialize)]\n#[serde(deny_unknown_fields)]\nstruct StructSkipAllDenyUnknown {\n    #[serde(skip_deserializing)]\n    a: i32,\n}\n\n#[derive(Default, PartialEq, Debug)]\nstruct NotDeserializable;\n\n#[derive(PartialEq, Debug, Deserialize)]\nenum Enum {\n    #[allow(dead_code)]\n    #[serde(skip_deserializing)]\n    Skipped,\n    Unit,\n    Simple(i32),\n    Seq(i32, i32, i32),\n    Map {\n        a: i32,\n        b: i32,\n        c: i32,\n    },\n    SimpleWithSkipped(#[serde(skip_deserializing)] NotDeserializable),\n}\n\n#[derive(PartialEq, Debug, Deserialize)]\nenum EnumOther {\n    Unit,\n    #[serde(other)]\n    Other,\n}\n\n#[derive(PartialEq, Debug)]\nstruct IgnoredAny;\n\nimpl<'de> Deserialize<'de> for IgnoredAny {\n    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>\n    where\n        D: Deserializer<'de>,\n    {\n        serde::de::IgnoredAny::deserialize(deserializer)?;\n        Ok(IgnoredAny)\n    }\n}\n\n//////////////////////////////////////////////////////////////////////////\n\n#[track_caller]\nfn test<'de, T>(value: T, tokens: &'de [Token])\nwhere\n    T: Deserialize<'de> + PartialEq + Debug,\n{\n    // Test ser/de roundtripping\n    assert_de_tokens(&value, tokens);\n\n    // Test that the tokens are ignorable\n    assert_de_tokens_ignore(tokens);\n}\n\n#[derive(Debug)]\nstruct SkipPartialEq<T>(T);\n\nimpl<'de, T> Deserialize<'de> for SkipPartialEq<T>\nwhere\n    T: Deserialize<'de>,\n{\n    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>\n    where\n        D: Deserializer<'de>,\n    {\n        T::deserialize(deserializer).map(SkipPartialEq)\n    }\n}\n\nimpl<T> PartialEq for SkipPartialEq<T> {\n    fn eq(&self, _other: &Self) -> bool {\n        true\n    }\n}\n\n#[track_caller]\nfn assert_de_tokens_ignore(ignorable_tokens: &[Token]) {\n    #[derive(PartialEq, Debug, Deserialize)]\n    struct IgnoreBase {\n        a: i32,\n    }\n\n    // Embed the tokens to be ignored in the normal token\n    // stream for an IgnoreBase type\n    let concated_tokens: Vec<Token> = vec![\n        Token::Map { len: Some(2) },\n        Token::Str(\"a\"),\n        Token::I32(1),\n        Token::Str(\"ignored\"),\n    ]\n    .into_iter()\n    .chain(ignorable_tokens.iter().copied())\n    .chain(iter::once(Token::MapEnd))\n    .collect();\n\n    let expected = IgnoreBase { a: 1 };\n    assert_de_tokens(&expected, &concated_tokens);\n}\n\n//////////////////////////////////////////////////////////////////////////\n\n#[test]\nfn test_bool() {\n    test(true, &[Token::Bool(true)]);\n    test(false, &[Token::Bool(false)]);\n}\n\n#[test]\nfn test_i8() {\n    let test = test::<i8>;\n\n    // from signed\n    test(-128, &[Token::I8(-128)]);\n    test(-128, &[Token::I16(-128)]);\n    test(-128, &[Token::I32(-128)]);\n    test(-128, &[Token::I64(-128)]);\n    test(127, &[Token::I8(127)]);\n    test(127, &[Token::I16(127)]);\n    test(127, &[Token::I32(127)]);\n    test(127, &[Token::I64(127)]);\n\n    // from unsigned\n    test(0, &[Token::U8(0)]);\n    test(0, &[Token::U16(0)]);\n    test(0, &[Token::U32(0)]);\n    test(0, &[Token::U64(0)]);\n    test(127, &[Token::U8(127)]);\n    test(127, &[Token::U16(127)]);\n    test(127, &[Token::U32(127)]);\n    test(127, &[Token::U64(127)]);\n}\n\n#[test]\nfn test_i16() {\n    let test = test::<i16>;\n\n    // from signed\n    test(-128, &[Token::I8(-128)]);\n    test(-32768, &[Token::I16(-32768)]);\n    test(-32768, &[Token::I32(-32768)]);\n    test(-32768, &[Token::I64(-32768)]);\n    test(127, &[Token::I8(127)]);\n    test(32767, &[Token::I16(32767)]);\n    test(32767, &[Token::I32(32767)]);\n    test(32767, &[Token::I64(32767)]);\n\n    // from unsigned\n    test(0, &[Token::U8(0)]);\n    test(0, &[Token::U16(0)]);\n    test(0, &[Token::U32(0)]);\n    test(0, &[Token::U64(0)]);\n    test(255, &[Token::U8(255)]);\n    test(32767, &[Token::U16(32767)]);\n    test(32767, &[Token::U32(32767)]);\n    test(32767, &[Token::U64(32767)]);\n}\n\n#[test]\nfn test_i32() {\n    let test = test::<i32>;\n\n    // from signed\n    test(-128, &[Token::I8(-128)]);\n    test(-32768, &[Token::I16(-32768)]);\n    test(-2147483648, &[Token::I32(-2147483648)]);\n    test(-2147483648, &[Token::I64(-2147483648)]);\n    test(127, &[Token::I8(127)]);\n    test(32767, &[Token::I16(32767)]);\n    test(2147483647, &[Token::I32(2147483647)]);\n    test(2147483647, &[Token::I64(2147483647)]);\n\n    // from unsigned\n    test(0, &[Token::U8(0)]);\n    test(0, &[Token::U16(0)]);\n    test(0, &[Token::U32(0)]);\n    test(0, &[Token::U64(0)]);\n    test(255, &[Token::U8(255)]);\n    test(65535, &[Token::U16(65535)]);\n    test(2147483647, &[Token::U32(2147483647)]);\n    test(2147483647, &[Token::U64(2147483647)]);\n}\n\n#[test]\nfn test_i64() {\n    let test = test::<i64>;\n\n    // from signed\n    test(-128, &[Token::I8(-128)]);\n    test(-32768, &[Token::I16(-32768)]);\n    test(-2147483648, &[Token::I32(-2147483648)]);\n    test(-9223372036854775808, &[Token::I64(-9223372036854775808)]);\n    test(127, &[Token::I8(127)]);\n    test(32767, &[Token::I16(32767)]);\n    test(2147483647, &[Token::I32(2147483647)]);\n    test(9223372036854775807, &[Token::I64(9223372036854775807)]);\n\n    // from unsigned\n    test(0, &[Token::U8(0)]);\n    test(0, &[Token::U16(0)]);\n    test(0, &[Token::U32(0)]);\n    test(0, &[Token::U64(0)]);\n    test(255, &[Token::U8(255)]);\n    test(65535, &[Token::U16(65535)]);\n    test(4294967295, &[Token::U32(4294967295)]);\n    test(9223372036854775807, &[Token::U64(9223372036854775807)]);\n}\n\n#[test]\nfn test_i128() {\n    let test = test::<i128>;\n\n    // from signed\n    test(-128, &[Token::I8(-128)]);\n    test(-32768, &[Token::I16(-32768)]);\n    test(-2147483648, &[Token::I32(-2147483648)]);\n    test(-9223372036854775808, &[Token::I64(-9223372036854775808)]);\n    test(127, &[Token::I8(127)]);\n    test(32767, &[Token::I16(32767)]);\n    test(2147483647, &[Token::I32(2147483647)]);\n    test(9223372036854775807, &[Token::I64(9223372036854775807)]);\n\n    // from unsigned\n    test(0, &[Token::U8(0)]);\n    test(0, &[Token::U16(0)]);\n    test(0, &[Token::U32(0)]);\n    test(0, &[Token::U64(0)]);\n    test(255, &[Token::U8(255)]);\n    test(65535, &[Token::U16(65535)]);\n    test(4294967295, &[Token::U32(4294967295)]);\n    test(18446744073709551615, &[Token::U64(18446744073709551615)]);\n}\n\n#[test]\nfn test_isize() {\n    let test = test::<isize>;\n\n    // from signed\n    test(-10, &[Token::I8(-10)]);\n    test(-10, &[Token::I16(-10)]);\n    test(-10, &[Token::I32(-10)]);\n    test(-10, &[Token::I64(-10)]);\n    test(10, &[Token::I8(10)]);\n    test(10, &[Token::I16(10)]);\n    test(10, &[Token::I32(10)]);\n    test(10, &[Token::I64(10)]);\n\n    // from unsigned\n    test(0, &[Token::U8(0)]);\n    test(0, &[Token::U16(0)]);\n    test(0, &[Token::U32(0)]);\n    test(0, &[Token::U64(0)]);\n    test(10, &[Token::U8(10)]);\n    test(10, &[Token::U16(10)]);\n    test(10, &[Token::U32(10)]);\n    test(10, &[Token::U64(10)]);\n}\n\n#[test]\nfn test_u8() {\n    let test = test::<u8>;\n\n    // from signed\n    test(0, &[Token::I8(0)]);\n    test(0, &[Token::I16(0)]);\n    test(0, &[Token::I32(0)]);\n    test(0, &[Token::I64(0)]);\n    test(127, &[Token::I8(127)]);\n    test(255, &[Token::I16(255)]);\n    test(255, &[Token::I32(255)]);\n    test(255, &[Token::I64(255)]);\n\n    // from unsigned\n    test(0, &[Token::U8(0)]);\n    test(0, &[Token::U16(0)]);\n    test(0, &[Token::U32(0)]);\n    test(0, &[Token::U64(0)]);\n    test(255, &[Token::U8(255)]);\n    test(255, &[Token::U16(255)]);\n    test(255, &[Token::U32(255)]);\n    test(255, &[Token::U64(255)]);\n}\n\n#[test]\nfn test_u16() {\n    let test = test::<u16>;\n\n    // from signed\n    test(0, &[Token::I8(0)]);\n    test(0, &[Token::I16(0)]);\n    test(0, &[Token::I32(0)]);\n    test(0, &[Token::I64(0)]);\n    test(127, &[Token::I8(127)]);\n    test(32767, &[Token::I16(32767)]);\n    test(65535, &[Token::I32(65535)]);\n    test(65535, &[Token::I64(65535)]);\n\n    // from unsigned\n    test(0, &[Token::U8(0)]);\n    test(0, &[Token::U16(0)]);\n    test(0, &[Token::U32(0)]);\n    test(0, &[Token::U64(0)]);\n    test(255, &[Token::U8(255)]);\n    test(65535, &[Token::U16(65535)]);\n    test(65535, &[Token::U32(65535)]);\n    test(65535, &[Token::U64(65535)]);\n}\n\n#[test]\nfn test_u32() {\n    let test = test::<u32>;\n\n    // from signed\n    test(0, &[Token::I8(0)]);\n    test(0, &[Token::I16(0)]);\n    test(0, &[Token::I32(0)]);\n    test(0, &[Token::I64(0)]);\n    test(127, &[Token::I8(127)]);\n    test(32767, &[Token::I16(32767)]);\n    test(2147483647, &[Token::I32(2147483647)]);\n    test(4294967295, &[Token::I64(4294967295)]);\n\n    // from unsigned\n    test(0, &[Token::U8(0)]);\n    test(0, &[Token::U16(0)]);\n    test(0, &[Token::U32(0)]);\n    test(0, &[Token::U64(0)]);\n    test(255, &[Token::U8(255)]);\n    test(65535, &[Token::U16(65535)]);\n    test(4294967295, &[Token::U32(4294967295)]);\n    test(4294967295, &[Token::U64(4294967295)]);\n}\n\n#[test]\nfn test_u64() {\n    let test = test::<u64>;\n\n    // from signed\n    test(0, &[Token::I8(0)]);\n    test(0, &[Token::I16(0)]);\n    test(0, &[Token::I32(0)]);\n    test(0, &[Token::I64(0)]);\n    test(127, &[Token::I8(127)]);\n    test(32767, &[Token::I16(32767)]);\n    test(2147483647, &[Token::I32(2147483647)]);\n    test(9223372036854775807, &[Token::I64(9223372036854775807)]);\n\n    // from unsigned\n    test(0, &[Token::U8(0)]);\n    test(0, &[Token::U16(0)]);\n    test(0, &[Token::U32(0)]);\n    test(0, &[Token::U64(0)]);\n    test(255, &[Token::U8(255)]);\n    test(65535, &[Token::U16(65535)]);\n    test(4294967295, &[Token::U32(4294967295)]);\n    test(18446744073709551615, &[Token::U64(18446744073709551615)]);\n}\n\n#[test]\nfn test_u128() {\n    let test = test::<u128>;\n\n    // from signed\n    test(0, &[Token::I8(0)]);\n    test(0, &[Token::I16(0)]);\n    test(0, &[Token::I32(0)]);\n    test(0, &[Token::I64(0)]);\n    test(127, &[Token::I8(127)]);\n    test(32767, &[Token::I16(32767)]);\n    test(2147483647, &[Token::I32(2147483647)]);\n    test(9223372036854775807, &[Token::I64(9223372036854775807)]);\n\n    // from unsigned\n    test(0, &[Token::U8(0)]);\n    test(0, &[Token::U16(0)]);\n    test(0, &[Token::U32(0)]);\n    test(0, &[Token::U64(0)]);\n    test(255, &[Token::U8(255)]);\n    test(65535, &[Token::U16(65535)]);\n    test(4294967295, &[Token::U32(4294967295)]);\n    test(18446744073709551615, &[Token::U64(18446744073709551615)]);\n}\n\n#[test]\nfn test_usize() {\n    let test = test::<usize>;\n\n    // from signed\n    test(0, &[Token::I8(0)]);\n    test(0, &[Token::I16(0)]);\n    test(0, &[Token::I32(0)]);\n    test(0, &[Token::I64(0)]);\n    test(10, &[Token::I8(10)]);\n    test(10, &[Token::I16(10)]);\n    test(10, &[Token::I32(10)]);\n    test(10, &[Token::I64(10)]);\n\n    // from unsigned\n    test(0, &[Token::U8(0)]);\n    test(0, &[Token::U16(0)]);\n    test(0, &[Token::U32(0)]);\n    test(0, &[Token::U64(0)]);\n    test(10, &[Token::U8(10)]);\n    test(10, &[Token::U16(10)]);\n    test(10, &[Token::U32(10)]);\n    test(10, &[Token::U64(10)]);\n}\n\n#[test]\nfn test_nonzero_i8() {\n    let test = |value, tokens| test(NonZeroI8::new(value).unwrap(), tokens);\n\n    // from signed\n    test(-128, &[Token::I8(-128)]);\n    test(-128, &[Token::I16(-128)]);\n    test(-128, &[Token::I32(-128)]);\n    test(-128, &[Token::I64(-128)]);\n    test(127, &[Token::I8(127)]);\n    test(127, &[Token::I16(127)]);\n    test(127, &[Token::I32(127)]);\n    test(127, &[Token::I64(127)]);\n\n    // from unsigned\n    test(1, &[Token::U8(1)]);\n    test(1, &[Token::U16(1)]);\n    test(1, &[Token::U32(1)]);\n    test(1, &[Token::U64(1)]);\n    test(127, &[Token::U8(127)]);\n    test(127, &[Token::U16(127)]);\n    test(127, &[Token::U32(127)]);\n    test(127, &[Token::U64(127)]);\n}\n\n#[test]\nfn test_nonzero_i16() {\n    let test = |value, tokens| test(NonZeroI16::new(value).unwrap(), tokens);\n\n    // from signed\n    test(-128, &[Token::I8(-128)]);\n    test(-32768, &[Token::I16(-32768)]);\n    test(-32768, &[Token::I32(-32768)]);\n    test(-32768, &[Token::I64(-32768)]);\n    test(127, &[Token::I8(127)]);\n    test(32767, &[Token::I16(32767)]);\n    test(32767, &[Token::I32(32767)]);\n    test(32767, &[Token::I64(32767)]);\n\n    // from unsigned\n    test(1, &[Token::U8(1)]);\n    test(1, &[Token::U16(1)]);\n    test(1, &[Token::U32(1)]);\n    test(1, &[Token::U64(1)]);\n    test(255, &[Token::U8(255)]);\n    test(32767, &[Token::U16(32767)]);\n    test(32767, &[Token::U32(32767)]);\n    test(32767, &[Token::U64(32767)]);\n}\n\n#[test]\nfn test_nonzero_i32() {\n    let test = |value, tokens| test(NonZeroI32::new(value).unwrap(), tokens);\n\n    // from signed\n    test(-128, &[Token::I8(-128)]);\n    test(-32768, &[Token::I16(-32768)]);\n    test(-2147483648, &[Token::I32(-2147483648)]);\n    test(-2147483648, &[Token::I64(-2147483648)]);\n    test(127, &[Token::I8(127)]);\n    test(32767, &[Token::I16(32767)]);\n    test(2147483647, &[Token::I32(2147483647)]);\n    test(2147483647, &[Token::I64(2147483647)]);\n\n    // from unsigned\n    test(1, &[Token::U8(1)]);\n    test(1, &[Token::U16(1)]);\n    test(1, &[Token::U32(1)]);\n    test(1, &[Token::U64(1)]);\n    test(255, &[Token::U8(255)]);\n    test(65535, &[Token::U16(65535)]);\n    test(2147483647, &[Token::U32(2147483647)]);\n    test(2147483647, &[Token::U64(2147483647)]);\n}\n\n#[test]\nfn test_nonzero_i64() {\n    let test = |value, tokens| test(NonZeroI64::new(value).unwrap(), tokens);\n\n    // from signed\n    test(-128, &[Token::I8(-128)]);\n    test(-32768, &[Token::I16(-32768)]);\n    test(-2147483648, &[Token::I32(-2147483648)]);\n    test(-9223372036854775808, &[Token::I64(-9223372036854775808)]);\n    test(127, &[Token::I8(127)]);\n    test(32767, &[Token::I16(32767)]);\n    test(2147483647, &[Token::I32(2147483647)]);\n    test(9223372036854775807, &[Token::I64(9223372036854775807)]);\n\n    // from unsigned\n    test(1, &[Token::U8(1)]);\n    test(1, &[Token::U16(1)]);\n    test(1, &[Token::U32(1)]);\n    test(1, &[Token::U64(1)]);\n    test(255, &[Token::U8(255)]);\n    test(65535, &[Token::U16(65535)]);\n    test(4294967295, &[Token::U32(4294967295)]);\n    test(9223372036854775807, &[Token::U64(9223372036854775807)]);\n}\n\n#[test]\nfn test_nonzero_i128() {\n    let test = |value, tokens| test(NonZeroI128::new(value).unwrap(), tokens);\n\n    // from signed\n    test(-128, &[Token::I8(-128)]);\n    test(-32768, &[Token::I16(-32768)]);\n    test(-2147483648, &[Token::I32(-2147483648)]);\n    test(-9223372036854775808, &[Token::I64(-9223372036854775808)]);\n    test(127, &[Token::I8(127)]);\n    test(32767, &[Token::I16(32767)]);\n    test(2147483647, &[Token::I32(2147483647)]);\n    test(9223372036854775807, &[Token::I64(9223372036854775807)]);\n\n    // from unsigned\n    test(1, &[Token::U8(1)]);\n    test(1, &[Token::U16(1)]);\n    test(1, &[Token::U32(1)]);\n    test(1, &[Token::U64(1)]);\n    test(255, &[Token::U8(255)]);\n    test(65535, &[Token::U16(65535)]);\n    test(4294967295, &[Token::U32(4294967295)]);\n    test(18446744073709551615, &[Token::U64(18446744073709551615)]);\n}\n\n#[test]\nfn test_nonzero_isize() {\n    let test = |value, tokens| test(NonZeroIsize::new(value).unwrap(), tokens);\n\n    // from signed\n    test(-10, &[Token::I8(-10)]);\n    test(-10, &[Token::I16(-10)]);\n    test(-10, &[Token::I32(-10)]);\n    test(-10, &[Token::I64(-10)]);\n    test(10, &[Token::I8(10)]);\n    test(10, &[Token::I16(10)]);\n    test(10, &[Token::I32(10)]);\n    test(10, &[Token::I64(10)]);\n\n    // from unsigned\n    test(1, &[Token::U8(1)]);\n    test(1, &[Token::U16(1)]);\n    test(1, &[Token::U32(1)]);\n    test(1, &[Token::U64(1)]);\n    test(10, &[Token::U8(10)]);\n    test(10, &[Token::U16(10)]);\n    test(10, &[Token::U32(10)]);\n    test(10, &[Token::U64(10)]);\n}\n\n#[test]\nfn test_nonzero_u8() {\n    let test = |value, tokens| test(NonZeroU8::new(value).unwrap(), tokens);\n\n    // from signed\n    test(1, &[Token::I8(1)]);\n    test(1, &[Token::I16(1)]);\n    test(1, &[Token::I32(1)]);\n    test(1, &[Token::I64(1)]);\n    test(127, &[Token::I8(127)]);\n    test(255, &[Token::I16(255)]);\n    test(255, &[Token::I32(255)]);\n    test(255, &[Token::I64(255)]);\n\n    // from unsigned\n    test(1, &[Token::U8(1)]);\n    test(1, &[Token::U16(1)]);\n    test(1, &[Token::U32(1)]);\n    test(1, &[Token::U64(1)]);\n    test(255, &[Token::U8(255)]);\n    test(255, &[Token::U16(255)]);\n    test(255, &[Token::U32(255)]);\n    test(255, &[Token::U64(255)]);\n}\n\n#[test]\nfn test_nonzero_u16() {\n    let test = |value, tokens| test(NonZeroU16::new(value).unwrap(), tokens);\n\n    // from signed\n    test(1, &[Token::I8(1)]);\n    test(1, &[Token::I16(1)]);\n    test(1, &[Token::I32(1)]);\n    test(1, &[Token::I64(1)]);\n    test(127, &[Token::I8(127)]);\n    test(32767, &[Token::I16(32767)]);\n    test(65535, &[Token::I32(65535)]);\n    test(65535, &[Token::I64(65535)]);\n\n    // from unsigned\n    test(1, &[Token::U8(1)]);\n    test(1, &[Token::U16(1)]);\n    test(1, &[Token::U32(1)]);\n    test(1, &[Token::U64(1)]);\n    test(255, &[Token::U8(255)]);\n    test(65535, &[Token::U16(65535)]);\n    test(65535, &[Token::U32(65535)]);\n    test(65535, &[Token::U64(65535)]);\n}\n\n#[test]\nfn test_nonzero_u32() {\n    let test = |value, tokens| test(NonZeroU32::new(value).unwrap(), tokens);\n\n    // from signed\n    test(1, &[Token::I8(1)]);\n    test(1, &[Token::I16(1)]);\n    test(1, &[Token::I32(1)]);\n    test(1, &[Token::I64(1)]);\n    test(127, &[Token::I8(127)]);\n    test(32767, &[Token::I16(32767)]);\n    test(2147483647, &[Token::I32(2147483647)]);\n    test(4294967295, &[Token::I64(4294967295)]);\n\n    // from unsigned\n    test(1, &[Token::U8(1)]);\n    test(1, &[Token::U16(1)]);\n    test(1, &[Token::U32(1)]);\n    test(1, &[Token::U64(1)]);\n    test(255, &[Token::U8(255)]);\n    test(65535, &[Token::U16(65535)]);\n    test(4294967295, &[Token::U32(4294967295)]);\n    test(4294967295, &[Token::U64(4294967295)]);\n}\n\n#[test]\nfn test_nonzero_u64() {\n    let test = |value, tokens| test(NonZeroU64::new(value).unwrap(), tokens);\n\n    // from signed\n    test(1, &[Token::I8(1)]);\n    test(1, &[Token::I16(1)]);\n    test(1, &[Token::I32(1)]);\n    test(1, &[Token::I64(1)]);\n    test(127, &[Token::I8(127)]);\n    test(32767, &[Token::I16(32767)]);\n    test(2147483647, &[Token::I32(2147483647)]);\n    test(9223372036854775807, &[Token::I64(9223372036854775807)]);\n\n    // from unsigned\n    test(1, &[Token::U8(1)]);\n    test(1, &[Token::U16(1)]);\n    test(1, &[Token::U32(1)]);\n    test(1, &[Token::U64(1)]);\n    test(255, &[Token::U8(255)]);\n    test(65535, &[Token::U16(65535)]);\n    test(4294967295, &[Token::U32(4294967295)]);\n    test(18446744073709551615, &[Token::U64(18446744073709551615)]);\n}\n\n#[test]\nfn test_nonzero_u128() {\n    let test = |value, tokens| test(NonZeroU128::new(value).unwrap(), tokens);\n\n    // from signed\n    test(1, &[Token::I8(1)]);\n    test(1, &[Token::I16(1)]);\n    test(1, &[Token::I32(1)]);\n    test(1, &[Token::I64(1)]);\n    test(127, &[Token::I8(127)]);\n    test(32767, &[Token::I16(32767)]);\n    test(2147483647, &[Token::I32(2147483647)]);\n    test(9223372036854775807, &[Token::I64(9223372036854775807)]);\n\n    // from unsigned\n    test(1, &[Token::U8(1)]);\n    test(1, &[Token::U16(1)]);\n    test(1, &[Token::U32(1)]);\n    test(1, &[Token::U64(1)]);\n    test(255, &[Token::U8(255)]);\n    test(65535, &[Token::U16(65535)]);\n    test(4294967295, &[Token::U32(4294967295)]);\n    test(18446744073709551615, &[Token::U64(18446744073709551615)]);\n}\n\n#[test]\nfn test_nonzero_usize() {\n    let test = |value, tokens| test(NonZeroUsize::new(value).unwrap(), tokens);\n\n    // from signed\n    test(1, &[Token::I8(1)]);\n    test(1, &[Token::I16(1)]);\n    test(1, &[Token::I32(1)]);\n    test(1, &[Token::I64(1)]);\n    test(10, &[Token::I8(10)]);\n    test(10, &[Token::I16(10)]);\n    test(10, &[Token::I32(10)]);\n    test(10, &[Token::I64(10)]);\n\n    // from unsigned\n    test(1, &[Token::U8(1)]);\n    test(1, &[Token::U16(1)]);\n    test(1, &[Token::U32(1)]);\n    test(1, &[Token::U64(1)]);\n    test(10, &[Token::U8(10)]);\n    test(10, &[Token::U16(10)]);\n    test(10, &[Token::U32(10)]);\n    test(10, &[Token::U64(10)]);\n}\n\n#[test]\nfn test_f32() {\n    let test = test::<f32>;\n\n    test(1.11, &[Token::F32(1.11)]);\n    test(1.11, &[Token::F64(1.11)]);\n}\n\n#[test]\nfn test_f64() {\n    let test = test::<f64>;\n\n    test(1.11f32 as f64, &[Token::F32(1.11)]);\n    test(1.11, &[Token::F64(1.11)]);\n}\n\n#[test]\nfn test_nan() {\n    let f32_deserializer = F32Deserializer::<serde::de::value::Error>::new;\n    let f64_deserializer = F64Deserializer::<serde::de::value::Error>::new;\n\n    let pos_f32_nan = f32_deserializer(f32::NAN.copysign(1.0));\n    let pos_f64_nan = f64_deserializer(f64::NAN.copysign(1.0));\n    assert!(f32::deserialize(pos_f32_nan).unwrap().is_sign_positive());\n    assert!(f32::deserialize(pos_f64_nan).unwrap().is_sign_positive());\n    assert!(f64::deserialize(pos_f32_nan).unwrap().is_sign_positive());\n    assert!(f64::deserialize(pos_f64_nan).unwrap().is_sign_positive());\n\n    let neg_f32_nan = f32_deserializer(f32::NAN.copysign(-1.0));\n    let neg_f64_nan = f64_deserializer(f64::NAN.copysign(-1.0));\n    assert!(f32::deserialize(neg_f32_nan).unwrap().is_sign_negative());\n    assert!(f32::deserialize(neg_f64_nan).unwrap().is_sign_negative());\n    assert!(f64::deserialize(neg_f32_nan).unwrap().is_sign_negative());\n    assert!(f64::deserialize(neg_f64_nan).unwrap().is_sign_negative());\n}\n\n#[test]\nfn test_char() {\n    test('a', &[Token::Char('a')]);\n    test('a', &[Token::Str(\"a\")]);\n    test('a', &[Token::String(\"a\")]);\n}\n\n#[test]\nfn test_string() {\n    test(\"abc\".to_owned(), &[Token::Str(\"abc\")]);\n    test(\"abc\".to_owned(), &[Token::String(\"abc\")]);\n    test(\"a\".to_owned(), &[Token::Char('a')]);\n}\n\n#[test]\nfn test_option() {\n    test(None::<i32>, &[Token::Unit]);\n    test(None::<i32>, &[Token::None]);\n    test(Some(1), &[Token::Some, Token::I32(1)]);\n}\n\n#[test]\nfn test_result() {\n    test(\n        Ok::<i32, i32>(0),\n        &[\n            Token::Enum { name: \"Result\" },\n            Token::Str(\"Ok\"),\n            Token::I32(0),\n        ],\n    );\n    test(\n        Err::<i32, i32>(1),\n        &[\n            Token::Enum { name: \"Result\" },\n            Token::Str(\"Err\"),\n            Token::I32(1),\n        ],\n    );\n}\n\n#[test]\nfn test_unit() {\n    test((), &[Token::Unit]);\n}\n\n#[test]\nfn test_unit_struct() {\n    test(UnitStruct, &[Token::Unit]);\n    test(UnitStruct, &[Token::UnitStruct { name: \"UnitStruct\" }]);\n}\n\n#[test]\nfn test_generic_unit_struct() {\n    test(GenericUnitStruct::<8>, &[Token::Unit]);\n    test(\n        GenericUnitStruct::<8>,\n        &[Token::UnitStruct {\n            name: \"GenericUnitStruct\",\n        }],\n    );\n}\n\n#[test]\nfn test_newtype_struct() {\n    test(\n        NewtypeStruct(1),\n        &[\n            Token::NewtypeStruct {\n                name: \"NewtypeStruct\",\n            },\n            Token::I32(1),\n        ],\n    );\n}\n\n#[test]\nfn test_tuple_struct() {\n    test(\n        TupleStruct(1, 2, 3),\n        &[\n            Token::Seq { len: Some(3) },\n            Token::I32(1),\n            Token::I32(2),\n            Token::I32(3),\n            Token::SeqEnd,\n        ],\n    );\n    test(\n        TupleStruct(1, 2, 3),\n        &[\n            Token::Seq { len: None },\n            Token::I32(1),\n            Token::I32(2),\n            Token::I32(3),\n            Token::SeqEnd,\n        ],\n    );\n    test(\n        TupleStruct(1, 2, 3),\n        &[\n            Token::TupleStruct {\n                name: \"TupleStruct\",\n                len: 3,\n            },\n            Token::I32(1),\n            Token::I32(2),\n            Token::I32(3),\n            Token::TupleStructEnd,\n        ],\n    );\n    test(\n        TupleStruct(1, 2, 3),\n        &[\n            Token::TupleStruct {\n                name: \"TupleStruct\",\n                len: 3,\n            },\n            Token::I32(1),\n            Token::I32(2),\n            Token::I32(3),\n            Token::TupleStructEnd,\n        ],\n    );\n}\n\n#[test]\nfn test_btreeset() {\n    test(\n        BTreeSet::<isize>::new(),\n        &[Token::Seq { len: Some(0) }, Token::SeqEnd],\n    );\n    test(\n        btreeset![btreeset![], btreeset![1], btreeset![2, 3]],\n        &[\n            Token::Seq { len: Some(3) },\n            Token::Seq { len: Some(0) },\n            Token::SeqEnd,\n            Token::Seq { len: Some(1) },\n            Token::I32(1),\n            Token::SeqEnd,\n            Token::Seq { len: Some(2) },\n            Token::I32(2),\n            Token::I32(3),\n            Token::SeqEnd,\n            Token::SeqEnd,\n        ],\n    );\n    test(\n        BTreeSet::<isize>::new(),\n        &[\n            Token::TupleStruct {\n                name: \"Anything\",\n                len: 0,\n            },\n            Token::TupleStructEnd,\n        ],\n    );\n}\n\n#[test]\nfn test_hashset() {\n    test(\n        HashSet::<isize>::new(),\n        &[Token::Seq { len: Some(0) }, Token::SeqEnd],\n    );\n    test(\n        hashset![1, 2, 3],\n        &[\n            Token::Seq { len: Some(3) },\n            Token::I32(1),\n            Token::I32(2),\n            Token::I32(3),\n            Token::SeqEnd,\n        ],\n    );\n    test(\n        HashSet::<isize>::new(),\n        &[\n            Token::TupleStruct {\n                name: \"Anything\",\n                len: 0,\n            },\n            Token::TupleStructEnd,\n        ],\n    );\n    test(\n        hashset![foldhash::fast::FixedState; 1, 2, 3],\n        &[\n            Token::Seq { len: Some(3) },\n            Token::I32(1),\n            Token::I32(2),\n            Token::I32(3),\n            Token::SeqEnd,\n        ],\n    );\n}\n\n#[test]\nfn test_vec() {\n    test(\n        Vec::<isize>::new(),\n        &[Token::Seq { len: Some(0) }, Token::SeqEnd],\n    );\n\n    test(\n        vec![vec![], vec![1], vec![2, 3]],\n        &[\n            Token::Seq { len: Some(3) },\n            Token::Seq { len: Some(0) },\n            Token::SeqEnd,\n            Token::Seq { len: Some(1) },\n            Token::I32(1),\n            Token::SeqEnd,\n            Token::Seq { len: Some(2) },\n            Token::I32(2),\n            Token::I32(3),\n            Token::SeqEnd,\n            Token::SeqEnd,\n        ],\n    );\n    test(\n        Vec::<isize>::new(),\n        &[\n            Token::TupleStruct {\n                name: \"Anything\",\n                len: 0,\n            },\n            Token::TupleStructEnd,\n        ],\n    );\n}\n\n#[test]\nfn test_array() {\n    test([0; 0], &[Token::Seq { len: Some(0) }, Token::SeqEnd]);\n    test([0; 0], &[Token::Tuple { len: 0 }, Token::TupleEnd]);\n    test(\n        ([0; 0], [1], [2, 3]),\n        &[\n            Token::Seq { len: Some(3) },\n            Token::Seq { len: Some(0) },\n            Token::SeqEnd,\n            Token::Seq { len: Some(1) },\n            Token::I32(1),\n            Token::SeqEnd,\n            Token::Seq { len: Some(2) },\n            Token::I32(2),\n            Token::I32(3),\n            Token::SeqEnd,\n            Token::SeqEnd,\n        ],\n    );\n    test(\n        ([0; 0], [1], [2, 3]),\n        &[\n            Token::Tuple { len: 3 },\n            Token::Tuple { len: 0 },\n            Token::TupleEnd,\n            Token::Tuple { len: 1 },\n            Token::I32(1),\n            Token::TupleEnd,\n            Token::Tuple { len: 2 },\n            Token::I32(2),\n            Token::I32(3),\n            Token::TupleEnd,\n            Token::TupleEnd,\n        ],\n    );\n    test(\n        [0; 0],\n        &[\n            Token::TupleStruct {\n                name: \"Anything\",\n                len: 0,\n            },\n            Token::TupleStructEnd,\n        ],\n    );\n}\n\n#[test]\nfn test_tuple() {\n    test(\n        (1,),\n        &[Token::Seq { len: Some(1) }, Token::I32(1), Token::SeqEnd],\n    );\n    test(\n        (1, 2, 3),\n        &[\n            Token::Seq { len: Some(3) },\n            Token::I32(1),\n            Token::I32(2),\n            Token::I32(3),\n            Token::SeqEnd,\n        ],\n    );\n    test(\n        (1,),\n        &[Token::Tuple { len: 1 }, Token::I32(1), Token::TupleEnd],\n    );\n    test(\n        (1, 2, 3),\n        &[\n            Token::Tuple { len: 3 },\n            Token::I32(1),\n            Token::I32(2),\n            Token::I32(3),\n            Token::TupleEnd,\n        ],\n    );\n}\n\n#[test]\nfn test_btreemap() {\n    test(\n        BTreeMap::<isize, isize>::new(),\n        &[Token::Map { len: Some(0) }, Token::MapEnd],\n    );\n    test(\n        btreemap![1 => 2],\n        &[\n            Token::Map { len: Some(1) },\n            Token::I32(1),\n            Token::I32(2),\n            Token::MapEnd,\n        ],\n    );\n    test(\n        btreemap![1 => 2, 3 => 4],\n        &[\n            Token::Map { len: Some(2) },\n            Token::I32(1),\n            Token::I32(2),\n            Token::I32(3),\n            Token::I32(4),\n            Token::MapEnd,\n        ],\n    );\n    test(\n        btreemap![1 => btreemap![], 2 => btreemap![3 => 4, 5 => 6]],\n        &[\n            Token::Map { len: Some(2) },\n            Token::I32(1),\n            Token::Map { len: Some(0) },\n            Token::MapEnd,\n            Token::I32(2),\n            Token::Map { len: Some(2) },\n            Token::I32(3),\n            Token::I32(4),\n            Token::I32(5),\n            Token::I32(6),\n            Token::MapEnd,\n            Token::MapEnd,\n        ],\n    );\n    test(\n        BTreeMap::<isize, isize>::new(),\n        &[\n            Token::Struct {\n                name: \"Anything\",\n                len: 0,\n            },\n            Token::StructEnd,\n        ],\n    );\n}\n\n#[test]\nfn test_hashmap() {\n    test(\n        HashMap::<isize, isize>::new(),\n        &[Token::Map { len: Some(0) }, Token::MapEnd],\n    );\n    test(\n        hashmap![1 => 2],\n        &[\n            Token::Map { len: Some(1) },\n            Token::I32(1),\n            Token::I32(2),\n            Token::MapEnd,\n        ],\n    );\n    test(\n        hashmap![1 => 2, 3 => 4],\n        &[\n            Token::Map { len: Some(2) },\n            Token::I32(1),\n            Token::I32(2),\n            Token::I32(3),\n            Token::I32(4),\n            Token::MapEnd,\n        ],\n    );\n    test(\n        hashmap![1 => hashmap![], 2 => hashmap![3 => 4, 5 => 6]],\n        &[\n            Token::Map { len: Some(2) },\n            Token::I32(1),\n            Token::Map { len: Some(0) },\n            Token::MapEnd,\n            Token::I32(2),\n            Token::Map { len: Some(2) },\n            Token::I32(3),\n            Token::I32(4),\n            Token::I32(5),\n            Token::I32(6),\n            Token::MapEnd,\n            Token::MapEnd,\n        ],\n    );\n    test(\n        HashMap::<isize, isize>::new(),\n        &[\n            Token::Struct {\n                name: \"Anything\",\n                len: 0,\n            },\n            Token::StructEnd,\n        ],\n    );\n    test(\n        hashmap![foldhash::fast::FixedState; 1 => 2, 3 => 4],\n        &[\n            Token::Map { len: Some(2) },\n            Token::I32(1),\n            Token::I32(2),\n            Token::I32(3),\n            Token::I32(4),\n            Token::MapEnd,\n        ],\n    );\n}\n\n#[test]\nfn test_struct() {\n    test(\n        Struct { a: 1, b: 2, c: 0 },\n        &[\n            Token::Map { len: Some(3) },\n            Token::Str(\"a\"),\n            Token::I32(1),\n            Token::Str(\"b\"),\n            Token::I32(2),\n            Token::MapEnd,\n        ],\n    );\n    test(\n        Struct { a: 1, b: 2, c: 0 },\n        &[\n            Token::Map { len: Some(3) },\n            Token::U8(0),\n            Token::I32(1),\n            Token::U8(1),\n            Token::I32(2),\n            Token::MapEnd,\n        ],\n    );\n    test(\n        Struct { a: 1, b: 2, c: 0 },\n        &[\n            Token::Map { len: Some(3) },\n            Token::U16(0),\n            Token::I32(1),\n            Token::U16(1),\n            Token::I32(2),\n            Token::MapEnd,\n        ],\n    );\n    test(\n        Struct { a: 1, b: 2, c: 0 },\n        &[\n            Token::Map { len: Some(3) },\n            Token::U32(0),\n            Token::I32(1),\n            Token::U32(1),\n            Token::I32(2),\n            Token::MapEnd,\n        ],\n    );\n    test(\n        Struct { a: 1, b: 2, c: 0 },\n        &[\n            Token::Map { len: Some(3) },\n            Token::U64(0),\n            Token::I32(1),\n            Token::U64(1),\n            Token::I32(2),\n            Token::MapEnd,\n        ],\n    );\n    // Mixed key types\n    test(\n        Struct { a: 1, b: 2, c: 0 },\n        &[\n            Token::Map { len: Some(3) },\n            Token::U8(0),\n            Token::I32(1),\n            Token::U64(1),\n            Token::I32(2),\n            Token::MapEnd,\n        ],\n    );\n    test(\n        Struct { a: 1, b: 2, c: 0 },\n        &[\n            Token::Map { len: Some(3) },\n            Token::U8(0),\n            Token::I32(1),\n            Token::Str(\"b\"),\n            Token::I32(2),\n            Token::MapEnd,\n        ],\n    );\n    test(\n        Struct { a: 1, b: 2, c: 0 },\n        &[\n            Token::Struct {\n                name: \"Struct\",\n                len: 2,\n            },\n            Token::Str(\"a\"),\n            Token::I32(1),\n            Token::Str(\"b\"),\n            Token::I32(2),\n            Token::StructEnd,\n        ],\n    );\n    test(\n        Struct { a: 1, b: 2, c: 0 },\n        &[\n            Token::Seq { len: Some(3) },\n            Token::I32(1),\n            Token::I32(2),\n            Token::SeqEnd,\n        ],\n    );\n}\n\n#[test]\nfn test_struct_borrowed_keys() {\n    test(\n        Struct { a: 1, b: 2, c: 0 },\n        &[\n            Token::Map { len: Some(3) },\n            Token::BorrowedStr(\"a\"),\n            Token::I32(1),\n            Token::BorrowedStr(\"b\"),\n            Token::I32(2),\n            Token::MapEnd,\n        ],\n    );\n    test(\n        Struct { a: 1, b: 2, c: 0 },\n        &[\n            Token::Struct {\n                name: \"Struct\",\n                len: 2,\n            },\n            Token::BorrowedStr(\"a\"),\n            Token::I32(1),\n            Token::BorrowedStr(\"b\"),\n            Token::I32(2),\n            Token::StructEnd,\n        ],\n    );\n}\n\n#[test]\nfn test_struct_owned_keys() {\n    test(\n        Struct { a: 1, b: 2, c: 0 },\n        &[\n            Token::Map { len: Some(3) },\n            Token::String(\"a\"),\n            Token::I32(1),\n            Token::String(\"b\"),\n            Token::I32(2),\n            Token::MapEnd,\n        ],\n    );\n    test(\n        Struct { a: 1, b: 2, c: 0 },\n        &[\n            Token::Struct {\n                name: \"Struct\",\n                len: 2,\n            },\n            Token::String(\"a\"),\n            Token::I32(1),\n            Token::String(\"b\"),\n            Token::I32(2),\n            Token::StructEnd,\n        ],\n    );\n}\n\n#[test]\nfn test_struct_with_skip() {\n    test(\n        Struct { a: 1, b: 2, c: 0 },\n        &[\n            Token::Map { len: Some(3) },\n            Token::Str(\"a\"),\n            Token::I32(1),\n            Token::Str(\"b\"),\n            Token::I32(2),\n            Token::Str(\"c\"),\n            Token::I32(3),\n            Token::Str(\"d\"),\n            Token::I32(4),\n            Token::MapEnd,\n        ],\n    );\n    test(\n        Struct { a: 1, b: 2, c: 0 },\n        &[\n            Token::Map { len: Some(3) },\n            Token::U8(0),\n            Token::I32(1),\n            Token::U16(1),\n            Token::I32(2),\n            Token::U32(2),\n            Token::I32(3),\n            Token::U64(3),\n            Token::I32(4),\n            Token::MapEnd,\n        ],\n    );\n    test(\n        Struct { a: 1, b: 2, c: 0 },\n        &[\n            Token::Struct {\n                name: \"Struct\",\n                len: 2,\n            },\n            Token::Str(\"a\"),\n            Token::I32(1),\n            Token::Str(\"b\"),\n            Token::I32(2),\n            Token::Str(\"c\"),\n            Token::I32(3),\n            Token::Str(\"d\"),\n            Token::I32(4),\n            Token::StructEnd,\n        ],\n    );\n}\n\n#[test]\nfn test_struct_skip_all() {\n    test(\n        StructSkipAll { a: 0 },\n        &[\n            Token::Struct {\n                name: \"StructSkipAll\",\n                len: 0,\n            },\n            Token::StructEnd,\n        ],\n    );\n    test(\n        StructSkipAll { a: 0 },\n        &[\n            Token::Struct {\n                name: \"StructSkipAll\",\n                len: 0,\n            },\n            Token::Str(\"a\"),\n            Token::I32(1),\n            Token::Str(\"b\"),\n            Token::I32(2),\n            Token::StructEnd,\n        ],\n    );\n}\n\n#[test]\nfn test_struct_skip_default() {\n    test(\n        StructSkipDefault { a: 16 },\n        &[\n            Token::Struct {\n                name: \"StructSkipDefault\",\n                len: 0,\n            },\n            Token::StructEnd,\n        ],\n    );\n}\n\n#[test]\nfn test_struct_skip_all_deny_unknown() {\n    test(\n        StructSkipAllDenyUnknown { a: 0 },\n        &[\n            Token::Struct {\n                name: \"StructSkipAllDenyUnknown\",\n                len: 0,\n            },\n            Token::StructEnd,\n        ],\n    );\n}\n\n#[test]\nfn test_struct_default() {\n    test(\n        StructDefault {\n            a: 50,\n            b: \"overwritten\".to_string(),\n        },\n        &[\n            Token::Struct {\n                name: \"StructDefault\",\n                len: 2,\n            },\n            Token::Str(\"a\"),\n            Token::I32(50),\n            Token::Str(\"b\"),\n            Token::String(\"overwritten\"),\n            Token::StructEnd,\n        ],\n    );\n    test(\n        StructDefault {\n            a: 100,\n            b: \"default\".to_string(),\n        },\n        &[\n            Token::Struct {\n                name: \"StructDefault\",\n                len: 2,\n            },\n            Token::StructEnd,\n        ],\n    );\n}\n\n#[test]\nfn test_enum_unit() {\n    test(\n        Enum::Unit,\n        &[Token::UnitVariant {\n            name: \"Enum\",\n            variant: \"Unit\",\n        }],\n    );\n}\n\n#[test]\nfn test_enum_simple() {\n    test(\n        Enum::Simple(1),\n        &[\n            Token::NewtypeVariant {\n                name: \"Enum\",\n                variant: \"Simple\",\n            },\n            Token::I32(1),\n        ],\n    );\n}\n\n#[test]\nfn test_enum_simple_with_skipped() {\n    test(\n        Enum::SimpleWithSkipped(NotDeserializable),\n        &[Token::UnitVariant {\n            name: \"Enum\",\n            variant: \"SimpleWithSkipped\",\n        }],\n    );\n}\n\n#[test]\nfn test_enum_seq() {\n    test(\n        Enum::Seq(1, 2, 3),\n        &[\n            Token::TupleVariant {\n                name: \"Enum\",\n                variant: \"Seq\",\n                len: 3,\n            },\n            Token::I32(1),\n            Token::I32(2),\n            Token::I32(3),\n            Token::TupleVariantEnd,\n        ],\n    );\n}\n\n#[test]\nfn test_enum_map() {\n    test(\n        Enum::Map { a: 1, b: 2, c: 3 },\n        &[\n            Token::StructVariant {\n                name: \"Enum\",\n                variant: \"Map\",\n                len: 3,\n            },\n            Token::Str(\"a\"),\n            Token::I32(1),\n            Token::Str(\"b\"),\n            Token::I32(2),\n            Token::Str(\"c\"),\n            Token::I32(3),\n            Token::StructVariantEnd,\n        ],\n    );\n}\n\n#[test]\nfn test_enum_unit_usize() {\n    test(\n        Enum::Unit,\n        &[Token::Enum { name: \"Enum\" }, Token::U32(0), Token::Unit],\n    );\n}\n\n#[test]\nfn test_enum_unit_bytes() {\n    test(\n        Enum::Unit,\n        &[\n            Token::Enum { name: \"Enum\" },\n            Token::Bytes(b\"Unit\"),\n            Token::Unit,\n        ],\n    );\n}\n\n#[test]\nfn test_enum_other_unit() {\n    test(\n        EnumOther::Unit,\n        &[\n            Token::Enum { name: \"EnumOther\" },\n            Token::Str(\"Unit\"),\n            Token::Unit,\n        ],\n    );\n    test(\n        EnumOther::Unit,\n        &[Token::Enum { name: \"EnumOther\" }, Token::U8(0), Token::Unit],\n    );\n    test(\n        EnumOther::Unit,\n        &[\n            Token::Enum { name: \"EnumOther\" },\n            Token::U16(0),\n            Token::Unit,\n        ],\n    );\n    test(\n        EnumOther::Unit,\n        &[\n            Token::Enum { name: \"EnumOther\" },\n            Token::U32(0),\n            Token::Unit,\n        ],\n    );\n    test(\n        EnumOther::Unit,\n        &[\n            Token::Enum { name: \"EnumOther\" },\n            Token::U64(0),\n            Token::Unit,\n        ],\n    );\n}\n\n#[test]\nfn test_enum_other() {\n    test(\n        EnumOther::Other,\n        &[\n            Token::Enum { name: \"EnumOther\" },\n            Token::Str(\"Foo\"),\n            Token::Unit,\n        ],\n    );\n    test(\n        EnumOther::Other,\n        &[\n            Token::Enum { name: \"EnumOther\" },\n            Token::U8(42),\n            Token::Unit,\n        ],\n    );\n    test(\n        EnumOther::Other,\n        &[\n            Token::Enum { name: \"EnumOther\" },\n            Token::U16(42),\n            Token::Unit,\n        ],\n    );\n    test(\n        EnumOther::Other,\n        &[\n            Token::Enum { name: \"EnumOther\" },\n            Token::U32(42),\n            Token::Unit,\n        ],\n    );\n    test(\n        EnumOther::Other,\n        &[\n            Token::Enum { name: \"EnumOther\" },\n            Token::U64(42),\n            Token::Unit,\n        ],\n    );\n}\n\n#[test]\nfn test_box() {\n    test(Box::new(0i32), &[Token::I32(0)]);\n}\n\n#[test]\nfn test_boxed_slice() {\n    test(\n        Box::new([0, 1, 2]),\n        &[\n            Token::Seq { len: Some(3) },\n            Token::I32(0),\n            Token::I32(1),\n            Token::I32(2),\n            Token::SeqEnd,\n        ],\n    );\n}\n\n#[test]\nfn test_duration() {\n    test(\n        Duration::new(1, 2),\n        &[\n            Token::Struct {\n                name: \"Duration\",\n                len: 2,\n            },\n            Token::Str(\"secs\"),\n            Token::U64(1),\n            Token::Str(\"nanos\"),\n            Token::U32(2),\n            Token::StructEnd,\n        ],\n    );\n    test(\n        Duration::new(1, 2),\n        &[\n            Token::Seq { len: Some(2) },\n            Token::I64(1),\n            Token::I64(2),\n            Token::SeqEnd,\n        ],\n    );\n}\n\n#[test]\nfn test_system_time() {\n    test(\n        UNIX_EPOCH + Duration::new(1, 2),\n        &[\n            Token::Struct {\n                name: \"SystemTime\",\n                len: 2,\n            },\n            Token::Str(\"secs_since_epoch\"),\n            Token::U64(1),\n            Token::Str(\"nanos_since_epoch\"),\n            Token::U32(2),\n            Token::StructEnd,\n        ],\n    );\n    test(\n        UNIX_EPOCH + Duration::new(1, 2),\n        &[\n            Token::Seq { len: Some(2) },\n            Token::I64(1),\n            Token::I64(2),\n            Token::SeqEnd,\n        ],\n    );\n}\n\n#[test]\nfn test_range() {\n    test(\n        1u32..2u32,\n        &[\n            Token::Struct {\n                name: \"Range\",\n                len: 2,\n            },\n            Token::Str(\"start\"),\n            Token::U32(1),\n            Token::Str(\"end\"),\n            Token::U32(2),\n            Token::StructEnd,\n        ],\n    );\n    test(\n        1u32..2u32,\n        &[\n            Token::Seq { len: Some(2) },\n            Token::U64(1),\n            Token::U64(2),\n            Token::SeqEnd,\n        ],\n    );\n}\n\n#[test]\nfn test_range_inclusive() {\n    test(\n        1u32..=2u32,\n        &[\n            Token::Struct {\n                name: \"RangeInclusive\",\n                len: 2,\n            },\n            Token::Str(\"start\"),\n            Token::U32(1),\n            Token::Str(\"end\"),\n            Token::U32(2),\n            Token::StructEnd,\n        ],\n    );\n    test(\n        1u32..=2u32,\n        &[\n            Token::Seq { len: Some(2) },\n            Token::U64(1),\n            Token::U64(2),\n            Token::SeqEnd,\n        ],\n    );\n}\n\n#[test]\nfn test_range_from() {\n    test(\n        1u32..,\n        &[\n            Token::Struct {\n                name: \"RangeFrom\",\n                len: 1,\n            },\n            Token::Str(\"start\"),\n            Token::U32(1),\n            Token::StructEnd,\n        ],\n    );\n    test(\n        1u32..,\n        &[Token::Seq { len: Some(1) }, Token::U32(1), Token::SeqEnd],\n    );\n}\n\n#[test]\nfn test_range_to() {\n    test(\n        ..2u32,\n        &[\n            Token::Struct {\n                name: \"RangeTo\",\n                len: 1,\n            },\n            Token::Str(\"end\"),\n            Token::U32(2),\n            Token::StructEnd,\n        ],\n    );\n    test(\n        ..2u32,\n        &[Token::Seq { len: Some(1) }, Token::U32(2), Token::SeqEnd],\n    );\n}\n\n#[test]\nfn test_bound() {\n    test(\n        Bound::Unbounded::<()>,\n        &[\n            Token::Enum { name: \"Bound\" },\n            Token::Str(\"Unbounded\"),\n            Token::Unit,\n        ],\n    );\n    test(\n        Bound::Included(0),\n        &[\n            Token::Enum { name: \"Bound\" },\n            Token::Str(\"Included\"),\n            Token::U8(0),\n        ],\n    );\n    test(\n        Bound::Excluded(0),\n        &[\n            Token::Enum { name: \"Bound\" },\n            Token::Str(\"Excluded\"),\n            Token::U8(0),\n        ],\n    );\n}\n\n#[test]\nfn test_path() {\n    test(\n        Path::new(\"/usr/local/lib\"),\n        &[Token::BorrowedStr(\"/usr/local/lib\")],\n    );\n    test(\n        Path::new(\"/usr/local/lib\"),\n        &[Token::BorrowedBytes(b\"/usr/local/lib\")],\n    );\n}\n\n#[test]\nfn test_path_buf() {\n    test(\n        PathBuf::from(\"/usr/local/lib\"),\n        &[Token::Str(\"/usr/local/lib\")],\n    );\n    test(\n        PathBuf::from(\"/usr/local/lib\"),\n        &[Token::String(\"/usr/local/lib\")],\n    );\n    test(\n        PathBuf::from(\"/usr/local/lib\"),\n        &[Token::Bytes(b\"/usr/local/lib\")],\n    );\n    test(\n        PathBuf::from(\"/usr/local/lib\"),\n        &[Token::ByteBuf(b\"/usr/local/lib\")],\n    );\n}\n\n#[test]\nfn test_boxed_path() {\n    test(\n        PathBuf::from(\"/usr/local/lib\").into_boxed_path(),\n        &[Token::Str(\"/usr/local/lib\")],\n    );\n    test(\n        PathBuf::from(\"/usr/local/lib\").into_boxed_path(),\n        &[Token::String(\"/usr/local/lib\")],\n    );\n    test(\n        PathBuf::from(\"/usr/local/lib\").into_boxed_path(),\n        &[Token::Bytes(b\"/usr/local/lib\")],\n    );\n    test(\n        PathBuf::from(\"/usr/local/lib\").into_boxed_path(),\n        &[Token::ByteBuf(b\"/usr/local/lib\")],\n    );\n}\n\n#[test]\nfn test_cstring() {\n    test(CString::new(\"abc\").unwrap(), &[Token::Bytes(b\"abc\")]);\n}\n\n#[test]\nfn test_rc() {\n    test(Rc::new(true), &[Token::Bool(true)]);\n}\n\n#[test]\nfn test_rc_weak_some() {\n    test(\n        SkipPartialEq(RcWeak::<bool>::new()),\n        &[Token::Some, Token::Bool(true)],\n    );\n}\n\n#[test]\nfn test_rc_weak_none() {\n    test(SkipPartialEq(RcWeak::<bool>::new()), &[Token::None]);\n}\n\n#[test]\nfn test_arc() {\n    test(Arc::new(true), &[Token::Bool(true)]);\n}\n\n#[test]\nfn test_arc_weak_some() {\n    test(\n        SkipPartialEq(ArcWeak::<bool>::new()),\n        &[Token::Some, Token::Bool(true)],\n    );\n}\n\n#[test]\nfn test_arc_weak_none() {\n    test(SkipPartialEq(ArcWeak::<bool>::new()), &[Token::None]);\n}\n\n#[test]\nfn test_wrapping() {\n    test(Wrapping(1usize), &[Token::U32(1)]);\n    test(Wrapping(1usize), &[Token::U64(1)]);\n}\n\n#[test]\nfn test_saturating() {\n    test(Saturating(1usize), &[Token::U32(1)]);\n    test(Saturating(1usize), &[Token::U64(1)]);\n    test(Saturating(0u8), &[Token::I8(0)]);\n    test(Saturating(0u16), &[Token::I16(0)]);\n\n    // saturate input values at the minimum or maximum value\n    test(Saturating(u8::MAX), &[Token::U16(u16::MAX)]);\n    test(Saturating(u8::MAX), &[Token::U16(u8::MAX as u16 + 1)]);\n    test(Saturating(u16::MAX), &[Token::U32(u32::MAX)]);\n    test(Saturating(u32::MAX), &[Token::U64(u64::MAX)]);\n    test(Saturating(u8::MIN), &[Token::I8(i8::MIN)]);\n    test(Saturating(u16::MIN), &[Token::I16(i16::MIN)]);\n    test(Saturating(u32::MIN), &[Token::I32(i32::MIN)]);\n    test(Saturating(i8::MIN), &[Token::I16(i16::MIN)]);\n    test(Saturating(i16::MIN), &[Token::I32(i32::MIN)]);\n    test(Saturating(i32::MIN), &[Token::I64(i64::MIN)]);\n\n    test(Saturating(u8::MIN), &[Token::I8(-1)]);\n    test(Saturating(u16::MIN), &[Token::I16(-1)]);\n\n    #[cfg(target_pointer_width = \"64\")]\n    {\n        test(Saturating(usize::MIN), &[Token::U64(u64::MIN)]);\n        test(Saturating(usize::MAX), &[Token::U64(u64::MAX)]);\n        test(Saturating(isize::MIN), &[Token::I64(i64::MIN)]);\n        test(Saturating(isize::MAX), &[Token::I64(i64::MAX)]);\n        test(Saturating(0usize), &[Token::I64(i64::MIN)]);\n\n        test(\n            Saturating(9_223_372_036_854_775_807usize),\n            &[Token::I64(i64::MAX)],\n        );\n    }\n}\n\n#[test]\nfn test_rc_dst() {\n    test(Rc::<str>::from(\"s\"), &[Token::Str(\"s\")]);\n    test(\n        Rc::<[bool]>::from(&[true][..]),\n        &[\n            Token::Seq { len: Some(1) },\n            Token::Bool(true),\n            Token::SeqEnd,\n        ],\n    );\n}\n\n#[test]\nfn test_arc_dst() {\n    test(Arc::<str>::from(\"s\"), &[Token::Str(\"s\")]);\n    test(\n        Arc::<[bool]>::from(&[true][..]),\n        &[\n            Token::Seq { len: Some(1) },\n            Token::Bool(true),\n            Token::SeqEnd,\n        ],\n    );\n}\n\n#[test]\nfn test_ignored_any() {\n    test(IgnoredAny, &[Token::Str(\"s\")]);\n    test(\n        IgnoredAny,\n        &[\n            Token::Seq { len: Some(1) },\n            Token::Bool(true),\n            Token::SeqEnd,\n        ],\n    );\n    test(\n        IgnoredAny,\n        &[Token::Enum { name: \"E\" }, Token::Str(\"Rust\"), Token::Unit],\n    );\n}\n\n#[test]\nfn test_net_ipv4addr_readable() {\n    test(\n        \"1.2.3.4\".parse::<net::Ipv4Addr>().unwrap().readable(),\n        &[Token::Str(\"1.2.3.4\")],\n    );\n}\n\n#[test]\nfn test_net_ipv6addr_readable() {\n    test(\n        \"::1\".parse::<net::Ipv6Addr>().unwrap().readable(),\n        &[Token::Str(\"::1\")],\n    );\n}\n\n#[test]\nfn test_net_ipaddr_readable() {\n    test(\n        \"1.2.3.4\".parse::<net::IpAddr>().unwrap().readable(),\n        &[Token::Str(\"1.2.3.4\")],\n    );\n}\n\n#[test]\nfn test_net_socketaddr_readable() {\n    test(\n        \"1.2.3.4:1234\"\n            .parse::<net::SocketAddr>()\n            .unwrap()\n            .readable(),\n        &[Token::Str(\"1.2.3.4:1234\")],\n    );\n    test(\n        \"1.2.3.4:1234\"\n            .parse::<net::SocketAddrV4>()\n            .unwrap()\n            .readable(),\n        &[Token::Str(\"1.2.3.4:1234\")],\n    );\n    test(\n        \"[::1]:1234\"\n            .parse::<net::SocketAddrV6>()\n            .unwrap()\n            .readable(),\n        &[Token::Str(\"[::1]:1234\")],\n    );\n}\n\n#[test]\nfn test_net_ipv4addr_compact() {\n    test(\n        net::Ipv4Addr::from(*b\"1234\").compact(),\n        &seq![\n            Token::Tuple { len: 4 },\n            b\"1234\".iter().copied().map(Token::U8),\n            Token::TupleEnd\n        ],\n    );\n}\n\n#[test]\nfn test_net_ipv6addr_compact() {\n    test(\n        net::Ipv6Addr::from(*b\"1234567890123456\").compact(),\n        &seq![\n            Token::Tuple { len: 4 },\n            b\"1234567890123456\".iter().copied().map(Token::U8),\n            Token::TupleEnd\n        ],\n    );\n}\n\n#[test]\nfn test_net_ipaddr_compact() {\n    test(\n        net::IpAddr::from(*b\"1234\").compact(),\n        &seq![\n            Token::NewtypeVariant {\n                name: \"IpAddr\",\n                variant: \"V4\"\n            },\n            Token::Tuple { len: 4 },\n            b\"1234\".iter().copied().map(Token::U8),\n            Token::TupleEnd\n        ],\n    );\n}\n\n#[test]\nfn test_net_socketaddr_compact() {\n    test(\n        net::SocketAddr::from((*b\"1234567890123456\", 1234)).compact(),\n        &seq![\n            Token::NewtypeVariant {\n                name: \"SocketAddr\",\n                variant: \"V6\"\n            },\n            Token::Tuple { len: 2 },\n            Token::Tuple { len: 16 },\n            b\"1234567890123456\".iter().copied().map(Token::U8),\n            Token::TupleEnd,\n            Token::U16(1234),\n            Token::TupleEnd\n        ],\n    );\n    test(\n        net::SocketAddr::from((*b\"1234\", 1234)).compact(),\n        &seq![\n            Token::NewtypeVariant {\n                name: \"SocketAddr\",\n                variant: \"V4\"\n            },\n            Token::Tuple { len: 2 },\n            Token::Tuple { len: 4 },\n            b\"1234\".iter().copied().map(Token::U8),\n            Token::TupleEnd,\n            Token::U16(1234),\n            Token::TupleEnd\n        ],\n    );\n    test(\n        net::SocketAddrV4::new(net::Ipv4Addr::from(*b\"1234\"), 1234).compact(),\n        &seq![\n            Token::Tuple { len: 2 },\n            Token::Tuple { len: 4 },\n            b\"1234\".iter().copied().map(Token::U8),\n            Token::TupleEnd,\n            Token::U16(1234),\n            Token::TupleEnd\n        ],\n    );\n    test(\n        net::SocketAddrV6::new(net::Ipv6Addr::from(*b\"1234567890123456\"), 1234, 0, 0).compact(),\n        &seq![\n            Token::Tuple { len: 2 },\n            Token::Tuple { len: 16 },\n            b\"1234567890123456\".iter().copied().map(Token::U8),\n            Token::TupleEnd,\n            Token::U16(1234),\n            Token::TupleEnd\n        ],\n    );\n}\n\n#[cfg(feature = \"unstable\")]\n#[test]\nfn test_never_result() {\n    test(\n        Ok::<u8, !>(0),\n        &[\n            Token::NewtypeVariant {\n                name: \"Result\",\n                variant: \"Ok\",\n            },\n            Token::U8(0),\n        ],\n    );\n}\n\n#[cfg(unix)]\n#[test]\nfn test_osstring() {\n    use std::os::unix::ffi::OsStringExt;\n\n    let value = OsString::from_vec(vec![1, 2, 3]);\n    let tokens = [\n        Token::Enum { name: \"OsString\" },\n        Token::Str(\"Unix\"),\n        Token::Seq { len: Some(2) },\n        Token::U8(1),\n        Token::U8(2),\n        Token::U8(3),\n        Token::SeqEnd,\n    ];\n\n    assert_de_tokens(&value, &tokens);\n    assert_de_tokens_ignore(&tokens);\n}\n\n#[cfg(windows)]\n#[test]\nfn test_osstring() {\n    use std::os::windows::ffi::OsStringExt;\n\n    let value = OsString::from_wide(&[1, 2, 3]);\n    let tokens = [\n        Token::Enum { name: \"OsString\" },\n        Token::Str(\"Windows\"),\n        Token::Seq { len: Some(2) },\n        Token::U16(1),\n        Token::U16(2),\n        Token::U16(3),\n        Token::SeqEnd,\n    ];\n\n    assert_de_tokens(&value, &tokens);\n    assert_de_tokens_ignore(&tokens);\n}\n\n#[test]\nfn test_cstr() {\n    assert_de_tokens::<Box<CStr>>(\n        &CString::new(\"abc\").unwrap().into_boxed_c_str(),\n        &[Token::Bytes(b\"abc\")],\n    );\n}\n\n#[test]\nfn test_atomics() {\n    fn test<L, A, T>(load: L, val: T)\n    where\n        L: Fn(&A, Ordering) -> T,\n        A: DeserializeOwned,\n        T: PartialEq + Debug + Copy + for<'de> IntoDeserializer<'de>,\n    {\n        match A::deserialize(val.into_deserializer()) {\n            Ok(v) => {\n                let loaded = load(&v, Ordering::Relaxed);\n                assert_eq!(val, loaded);\n            }\n            Err(e) => panic!(\"tokens failed to deserialize: {}\", e),\n        }\n    }\n\n    test(AtomicBool::load, true);\n    test(AtomicI8::load, -127i8);\n    test(AtomicI16::load, -510i16);\n    test(AtomicI32::load, -131072i32);\n    test(AtomicIsize::load, -131072isize);\n    test(AtomicU8::load, 127u8);\n    test(AtomicU16::load, 510u16);\n    test(AtomicU32::load, 131072u32);\n    test(AtomicUsize::load, 131072usize);\n\n    #[cfg(target_arch = \"x86_64\")]\n    {\n        test(AtomicI64::load, -8589934592i64);\n        test(AtomicU64::load, 8589934592u64);\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "f0e168b9b1b984ff6fb4b19f57d5543cbbf23e85",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/serde/test_suite/tests/test_roundtrip.rs",
    "func": "use serde_test::{assert_tokens, Configure, Token};\nuse std::net;\n\n#[macro_use]\n#[allow(unused_macros)]\nmod macros;\n\n#[test]\nfn ip_addr_roundtrip() {\n    assert_tokens(\n        &net::IpAddr::from(*b\"1234\").compact(),\n        &seq![\n            Token::NewtypeVariant {\n                name: \"IpAddr\",\n                variant: \"V4\"\n            },\n            Token::Tuple { len: 4 },\n            b\"1234\".iter().copied().map(Token::U8),\n            Token::TupleEnd,\n        ],\n    );\n}\n\n#[test]\nfn socket_addr_roundtrip() {\n    assert_tokens(\n        &net::SocketAddr::from((*b\"1234567890123456\", 1234)).compact(),\n        &seq![\n            Token::NewtypeVariant {\n                name: \"SocketAddr\",\n                variant: \"V6\"\n            },\n            Token::Tuple { len: 2 },\n            Token::Tuple { len: 16 },\n            b\"1234567890123456\".iter().copied().map(Token::U8),\n            Token::TupleEnd,\n            Token::U16(1234),\n            Token::TupleEnd,\n        ],\n    );\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "dc8c1ed9fa8664773e141b671d421a3443b049d5",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/serde/test_suite/tests/ui/type-attribute/into.rs",
    "func": "use serde_derive::Serialize;\n\n#[derive(Serialize)]\n#[serde(into = \"Option<T\")]\nenum TestOne {\n    Testing,\n    One,\n    Two,\n    Three,\n}\n\nfn main() {}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "350c9a544428efee119d621a38ec1baabb6940f0",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/serde/test_suite/tests/ui/conflict/alias.rs",
    "func": "use serde_derive::Deserialize;\n\n#[derive(Deserialize)]\nstruct S1 {\n    #[serde(alias = \"a\", alias = \"b\", alias = \"c\")]\n    a: (),\n\n    // Warning on \"c\" and \"b\"\n    #[serde(alias = \"c\")]\n    b: (),\n\n    #[serde(skip_deserializing)]\n    c: (),\n}\n\n#[derive(Deserialize)]\nstruct S2 {\n    #[serde(alias = \"b\", alias = \"c\")]\n    a: (),\n\n    // Warning on \"c\"\n    #[serde(rename = \"c\")]\n    b: (),\n}\n\n#[derive(Deserialize)]\n#[serde(rename_all = \"UPPERCASE\")]\nstruct S3 {\n    #[serde(alias = \"B\", alias = \"c\")]\n    a: (),\n\n    // Warning on \"b\" because this collides with the \"B\" above after applying\n    // rename rules\n    b: (),\n}\n\nfn main() {\n    __FAIL__;\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "125d68a55701ee47f8b68d23cbc05e1c3473cbf2",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/serde/test_suite/tests/ui/conflict/internal-tag.rs",
    "func": "use serde_derive::Serialize;\n\n#[derive(Serialize)]\n#[serde(tag = \"conflict\")]\nenum E {\n    A {\n        #[serde(rename = \"conflict\")]\n        x: (),\n    },\n}\n\nfn main() {}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "d740144c0149075f60ac72f8438907b25f045ca8",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/serde/test_suite/tests/ui/default-attribute/incorrect_type_struct.rs",
    "func": "// Tests that type error points to the path in attribute\n\nuse serde_derive::Deserialize;\n\n#[derive(Deserialize)]\n#[serde(default = \"main\")]\nstruct Struct {\n    #[serde(default = \"main\")]\n    f1: u8,\n    f2: u8,\n    #[serde(default = \"main\")]\n    f3: i8,\n}\n\nfn main() {}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "04e0ab49c82d546b8b63f5f1734f6913a7d692bd",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/serde/test_suite/tests/ui/default-attribute/incorrect_type_enum_adjacently_tagged.rs",
    "func": "// Tests that type error points to the path in attribute\n\nuse serde_derive::Deserialize;\n\n#[derive(Deserialize)]\n#[serde(tag = \"tag\", content = \"content\")]\nenum Enum {\n    // Newtype variants do not use the provided path, so it is forbidden here\n    // Newtype(#[serde(default = \"main\")] u8),\n    Tuple(u8, #[serde(default = \"main\")] i8),\n    Struct {\n        #[serde(default = \"main\")]\n        f1: u8,\n        f2: u8,\n        #[serde(default = \"main\")]\n        f3: i8,\n    },\n}\n\nfn main() {}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "13a33ef44f143e9c863f53cfe229763e1dd71810",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/serde/test_suite/tests/ui/default-attribute/unit_path.rs",
    "func": "use serde_derive::Deserialize;\n\n#[derive(Deserialize)]\n#[serde(default = \"default_u\")]\nstruct Unit;\n\nfn main() {}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "17b96f533d90676e5baa5bfcb4833d0c6305e2fe",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/serde/test_suite/tests/ui/unknown-attribute/variant.rs",
    "func": "use serde_derive::Serialize;\n\n#[derive(Serialize)]\nenum E {\n    #[serde(abc = \"xyz\")]\n    V,\n}\n\nfn main() {}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "6007e2bed122b5d02379c429a928d22ac09f20df",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/serde/test_suite/tests/ui/identifier/variant_struct.rs",
    "func": "use serde_derive::Deserialize;\n\n#[derive(Deserialize)]\n#[serde(variant_identifier)]\nstruct S;\n\nfn main() {}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "fa17b962835739680d1cfab01fe4d055ae94d6f3",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/serde/test_suite/tests/ui/identifier/not_unit.rs",
    "func": "use serde_derive::Deserialize;\n\n#[derive(Deserialize)]\n#[serde(field_identifier)]\nenum F {\n    A,\n    #[serde(other)]\n    Other(u8, u8),\n}\n\nfn main() {}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "df80a63c6a31d6176418d7e84778eb74785ebed7",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/serde/test_suite/tests/ui/rename/container_unknown_rename_rule.rs",
    "func": "use serde_derive::Serialize;\n\n#[derive(Serialize)]\n#[serde(rename_all = \"abc\")]\nstruct S {\n    name: u8,\n    long_name: u8,\n    very_long_name: u8,\n}\n\nfn main() {}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "91761780d1573f8d111be5316336461dbea5d6f8",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/yew/packages/yew-macro/tests/function_component_attr/mut-ref-props-param-fail.rs",
    "func": "use yew::prelude::*;\n\n#[derive(Clone, Properties, PartialEq)]\nstruct Props {\n    a: usize,\n}\n\n#[function_component(Comp)]\nfn comp(props: &mut Props) -> Html {\n    html! {\n        <p>\n            { props.a }\n        </p>\n    }\n}\n\nfn main() {}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "788b2406d9fcffa99eb93f12fe5ed6b5d0938f57",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/yew/packages/yew-macro/tests/function_component_attr/generic-props-fail.rs",
    "func": "use yew::prelude::*;\n\n#[derive(Clone, Properties, PartialEq)]\nstruct Props {\n    a: usize,\n}\n\n#[function_component(Comp)]\nfn comp<P>(_props: &P) -> Html\nwhere\n    P: Properties + PartialEq,\n{\n    html! {\n        <p></p>\n    }\n}\n\nstruct MissingTypeBounds;\n\nfn compile_fail() {\n    // missing prop 'a'\n    html! { <Comp<Props> /> };\n\n    // invalid type parameter\n    html! { <Comp<INVALID> /> };\n    // parameter doesn't match bounds\n    html! { <Comp<MissingTypeBounds> /> };\n\n    // missing type param\n    html! { <Comp /> };\n}\n\nfn main() {}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "1d16f8ca69f41a0e0bec078d1c45e5157c8fea30",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/yew/packages/yew-macro/tests/html_macro/list-pass.rs",
    "func": "#![no_implicit_prelude]\n\n// Shadow primitives\n#[allow(non_camel_case_types)]\npub struct bool;\n#[allow(non_camel_case_types)]\npub struct char;\n#[allow(non_camel_case_types)]\npub struct f32;\n#[allow(non_camel_case_types)]\npub struct f64;\n#[allow(non_camel_case_types)]\npub struct i128;\n#[allow(non_camel_case_types)]\npub struct i16;\n#[allow(non_camel_case_types)]\npub struct i32;\n#[allow(non_camel_case_types)]\npub struct i64;\n#[allow(non_camel_case_types)]\npub struct i8;\n#[allow(non_camel_case_types)]\npub struct isize;\n#[allow(non_camel_case_types)]\npub struct str;\n#[allow(non_camel_case_types)]\npub struct u128;\n#[allow(non_camel_case_types)]\npub struct u16;\n#[allow(non_camel_case_types)]\npub struct u32;\n#[allow(non_camel_case_types)]\npub struct u64;\n#[allow(non_camel_case_types)]\npub struct u8;\n#[allow(non_camel_case_types)]\npub struct usize;\n\nfn main() {\n    _ = ::yew::html! {};\n    _ = ::yew::html! { <></> };\n    _ = ::yew::html! {\n        <>\n            <></>\n            <></>\n        </>\n    };\n    _ = ::yew::html! {\n        <key={::std::string::ToString::to_string(\"key\")}>\n        </>\n    };\n\n    let children = ::std::vec![\n        ::yew::html! { <span>{ \"Hello\" }</span> },\n        ::yew::html! { <span>{ \"World\" }</span> },\n    ];\n    _ = ::yew::html! { <>{ children }</> };\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "e1ac350d99caf3869eb0a0f57787b70edfd22c51",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/yew/packages/yew-macro/tests/html_macro/generic-component-pass.rs",
    "func": "#![no_implicit_prelude]\n\n// Shadow primitives\n#[allow(non_camel_case_types)]\npub struct bool;\n#[allow(non_camel_case_types)]\npub struct char;\n#[allow(non_camel_case_types)]\npub struct f32;\n#[allow(non_camel_case_types)]\npub struct f64;\n#[allow(non_camel_case_types)]\npub struct i128;\n#[allow(non_camel_case_types)]\npub struct i16;\n#[allow(non_camel_case_types)]\npub struct i32;\n#[allow(non_camel_case_types)]\npub struct i64;\n#[allow(non_camel_case_types)]\npub struct i8;\n#[allow(non_camel_case_types)]\npub struct isize;\n#[allow(non_camel_case_types)]\npub struct str;\n#[allow(non_camel_case_types)]\npub struct u128;\n#[allow(non_camel_case_types)]\npub struct u16;\n#[allow(non_camel_case_types)]\npub struct u32;\n#[allow(non_camel_case_types)]\npub struct u64;\n#[allow(non_camel_case_types)]\npub struct u8;\n#[allow(non_camel_case_types)]\npub struct usize;\n\npub struct Generic<T> {\n    marker: ::std::marker::PhantomData<T>,\n}\n\nimpl<T> ::yew::Component for Generic<T>\nwhere\n    T: 'static,\n{\n    type Message = ();\n    type Properties = ();\n\n    fn create(_ctx: &::yew::Context<Self>) -> Self {\n        ::std::unimplemented!()\n    }\n    fn view(&self, _ctx: &::yew::Context<Self>) -> ::yew::Html {\n        ::std::unimplemented!()\n    }\n}\n\npub struct Generic2<T1, T2> {\n    marker: ::std::marker::PhantomData<(T1, T2)>,\n}\n\nimpl<T1, T2> ::yew::Component for Generic2<T1, T2>\nwhere\n    T1: 'static,\n    T2: 'static,\n{\n    type Message = ();\n    type Properties = ();\n\n    fn create(_ctx: &::yew::Context<Self>) -> Self {\n        ::std::unimplemented!()\n    }\n    fn view(&self, _ctx: &::yew::Context<Self>) -> ::yew::Html {\n        ::std::unimplemented!()\n    }\n}\n\nfn compile_pass() {\n    _ = ::yew::html! { <Generic<::std::string::String> /> };\n    _ = ::yew::html! { <Generic<(u8, bool)> /> };\n    _ = ::yew::html! { <Generic<(u8, bool)> ></Generic<(u8, bool)>> };\n    _ = ::yew::html! { <Generic<::std::string::String> ></Generic<::std::string::String>> };\n\n    _ = ::yew::html! { <Generic<::std::vec::Vec<::std::string::String>> /> };\n    _ = ::yew::html! { <Generic<::std::vec::Vec<::std::string::String>>></ Generic<::std::vec::Vec<::std::string::String>>> };\n\n    _ = ::yew::html! { <Generic<::std::primitive::usize> /> };\n    _ = ::yew::html! { <Generic<::std::primitive::usize>></Generic<::std::primitive::usize>> };\n    _ = ::yew::html! { <Generic<::std::string::String, > /> };\n    _ = ::yew::html! { <Generic<::std::string::String, >></Generic<::std::string::String,>> };\n\n    _ = ::yew::html! { <Generic2<::std::string::String, ::std::string::String> /> };\n    _ = ::yew::html! { <Generic2<::std::string::String, ::std::string::String>></Generic2<::std::string::String, ::std::string::String>> };\n\n    _ = ::yew::html! { <Generic2<::std::string::String, ::std::string::String, > /> };\n    _ = ::yew::html! { <Generic2<::std::string::String, ::std::string::String, >></Generic2<::std::string::String, ::std::string::String, >> };\n}\n\nfn main() {}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "2f465f295de0c525a45b988d960814b44cff0ad7",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/yew/packages/yew-macro/tests/html_macro/component-any-children-pass.rs",
    "func": "#![no_implicit_prelude]\n\n// Shadow primitives\n#[allow(non_camel_case_types)]\npub struct bool;\n#[allow(non_camel_case_types)]\npub struct char;\n#[allow(non_camel_case_types)]\npub struct f32;\n#[allow(non_camel_case_types)]\npub struct f64;\n#[allow(non_camel_case_types)]\npub struct i128;\n#[allow(non_camel_case_types)]\npub struct i16;\n#[allow(non_camel_case_types)]\npub struct i32;\n#[allow(non_camel_case_types)]\npub struct i64;\n#[allow(non_camel_case_types)]\npub struct i8;\n#[allow(non_camel_case_types)]\npub struct isize;\n#[allow(non_camel_case_types)]\npub struct str;\n#[allow(non_camel_case_types)]\npub struct u128;\n#[allow(non_camel_case_types)]\npub struct u16;\n#[allow(non_camel_case_types)]\npub struct u32;\n#[allow(non_camel_case_types)]\npub struct u64;\n#[allow(non_camel_case_types)]\npub struct u8;\n#[allow(non_camel_case_types)]\npub struct usize;\n\n#[derive(\n    ::std::clone::Clone, ::yew::Properties, ::std::default::Default, ::std::cmp::PartialEq,\n)]\npub struct ContainerProperties {\n    pub int: ::std::primitive::i32,\n    // You can use Html as Children.\n    #[prop_or_default]\n    pub children: ::yew::Html,\n    #[prop_or_default]\n    pub header: ::yew::Html,\n}\n\npub struct Container;\nimpl ::yew::Component for Container {\n    type Message = ();\n    type Properties = ContainerProperties;\n\n    fn create(_ctx: &::yew::Context<Self>) -> Self {\n        ::std::unimplemented!()\n    }\n\n    fn view(&self, _ctx: &::yew::Context<Self>) -> ::yew::Html {\n        ::std::unimplemented!()\n    }\n}\n\n#[derive(::std::clone::Clone, ::std::cmp::PartialEq)]\npub enum ChildrenVariants {\n    Child(::yew::virtual_dom::VChild<Child>),\n    AltChild(::yew::virtual_dom::VChild<AltChild>),\n}\n\nimpl ::std::convert::From<::yew::virtual_dom::VChild<Child>> for ChildrenVariants {\n    fn from(comp: ::yew::virtual_dom::VChild<Child>) -> Self {\n        ChildrenVariants::Child(comp)\n    }\n}\n\nimpl ::std::convert::From<::yew::virtual_dom::VChild<AltChild>> for ChildrenVariants {\n    fn from(comp: ::yew::virtual_dom::VChild<AltChild>) -> Self {\n        ChildrenVariants::AltChild(comp)\n    }\n}\n\nimpl ::std::convert::Into<::yew::virtual_dom::VNode> for ChildrenVariants {\n    fn into(self) -> ::yew::virtual_dom::VNode {\n        match self {\n            Self::Child(comp) => ::yew::virtual_dom::VNode::VComp(::std::rc::Rc::new(::std::convert::Into::<\n                ::yew::virtual_dom::VComp,\n            >::into(comp))),\n            Self::AltChild(comp) => ::yew::virtual_dom::VNode::VComp(::std::rc::Rc::new(::std::convert::Into::<\n                ::yew::virtual_dom::VComp,\n            >::into(comp))),\n        }\n    }\n}\n\n#[derive(\n    ::std::clone::Clone, ::yew::Properties, ::std::default::Default, ::std::cmp::PartialEq,\n)]\npub struct ChildProperties {\n    #[prop_or_default]\n    pub string: ::std::string::String,\n    #[prop_or_default]\n    pub r#fn: ::std::primitive::i32,\n    #[prop_or_default]\n    pub r#ref: ::yew::NodeRef,\n    pub int: ::std::primitive::i32,\n    #[prop_or_default]\n    pub opt_str: ::std::option::Option<::std::string::String>,\n    #[prop_or_default]\n    pub vec: ::std::vec::Vec<::std::primitive::i32>,\n    #[prop_or_default]\n    pub optional_callback: ::std::option::Option<::yew::Callback<()>>,\n}\n\npub struct Child;\nimpl ::yew::Component for Child {\n    type Message = ();\n    type Properties = ChildProperties;\n\n    fn create(_ctx: &::yew::Context<Self>) -> Self {\n        ::std::unimplemented!()\n    }\n\n    fn view(&self, _ctx: &::yew::Context<Self>) -> ::yew::Html {\n        ::std::unimplemented!()\n    }\n}\n\npub struct AltChild;\nimpl ::yew::Component for AltChild {\n    type Message = ();\n    type Properties = ();\n\n    fn create(_ctx: &::yew::Context<Self>) -> Self {\n        ::std::unimplemented!()\n    }\n\n    fn view(&self, _ctx: &::yew::Context<Self>) -> ::yew::Html {\n        ::std::unimplemented!()\n    }\n}\n\nmod scoped {\n    pub use super::{Child, Container};\n}\n\n#[derive(\n    ::std::clone::Clone, ::yew::Properties, ::std::default::Default, ::std::cmp::PartialEq,\n)]\npub struct RenderPropProps {\n    // You can use Callback<()> as Children.\n    #[prop_or_default]\n    pub children: ::yew::Callback<()>,\n}\n\n#[::yew::function_component]\npub fn RenderPropComp(_props: &RenderPropProps) -> ::yew::Html {\n    ::yew::html! {}\n}\n\nfn compile_pass() {\n    _ = ::yew::html! { <Child int=1 /> };\n    _ = ::yew::html! { <Child int=1 r#fn=1 /> };\n\n    _ = ::yew::html! {\n        <>\n            <Child int=1 />\n            <scoped::Child int=1 />\n        </>\n    };\n\n    let props = <<Child as ::yew::Component>::Properties as ::std::default::Default>::default();\n    let node_ref = <::yew::NodeRef as ::std::default::Default>::default();\n    _ = ::yew::html! {\n        <>\n            <Child ..::std::clone::Clone::clone(&props) />\n            <Child int={1} ..props />\n            <Child r#ref={::std::clone::Clone::clone(&node_ref)} int={2} ..::yew::props!(Child::Properties { int: 5 }) />\n            <Child int=3 r#ref={::std::clone::Clone::clone(&node_ref)} ..::yew::props!(Child::Properties { int: 5 }) />\n            <Child r#ref={::std::clone::Clone::clone(&node_ref)} ..::yew::props!(Child::Properties { int: 5 }) />\n            <Child r#ref={&node_ref} ..<<Child as ::yew::Component>::Properties as ::std::default::Default>::default() />\n            <Child r#ref={node_ref} ..<<Child as ::yew::Component>::Properties as ::std::default::Default>::default() />\n        </>\n    };\n\n    _ = ::yew::html! {\n        <>\n            <Child int=1 string=\"child\" />\n            <Child int=1 />\n            <Child int={1+1} />\n            <Child int=1 vec={::std::vec![1]} />\n            <Child string={<::std::string::String as ::std::convert::From<&'static ::std::primitive::str>>::from(\"child\")} int=1 />\n\n            <Child opt_str=\"child\" int=1 />\n            <Child opt_str={<::std::string::String as ::std::convert::From<&'static ::std::primitive::str>>::from(\"child\")} int=1 />\n            <Child opt_str={::std::option::Option::Some(\"child\")} int=1 />\n            <Child opt_str={::std::option::Option::Some(<::std::string::String as ::std::convert::From<&'static ::std::primitive::str>>::from(\"child\"))} int=1 />\n        </>\n    };\n\n    let name_expr = \"child\";\n    _ = ::yew::html! {\n        <Child int=1 string={name_expr} />\n    };\n\n    let string = \"child\";\n    let int = 1;\n    _ = ::yew::html! {\n        <Child {int} {string} />\n    };\n\n    _ = ::yew::html! {\n        <>\n            <Child int=1 />\n            <Child int=1 optional_callback={::std::option::Option::Some(<::yew::Callback<()> as ::std::convert::From<_>>::from(|_| ()))} />\n            <Child int=1 optional_callback={<::yew::Callback<()> as ::std::convert::From<_>>::from(|_| ())} />\n            <Child int=1 optional_callback={::std::option::Option::None::<::yew::Callback<_>>} />\n        </>\n    };\n\n    let node_ref = <::yew::NodeRef as ::std::default::Default>::default();\n    _ = ::yew::html! {\n        <>\n            <Child int=1 r#ref={node_ref} />\n        </>\n    };\n\n    let int = 1;\n    let node_ref = <::yew::NodeRef as ::std::default::Default>::default();\n    _ = ::yew::html! {\n        <>\n            <Child {int} r#ref={node_ref} />\n        </>\n    };\n\n    let props = <<Container as ::yew::Component>::Properties as ::std::default::Default>::default();\n    let child_props =\n        <<Child as ::yew::Component>::Properties as ::std::default::Default>::default();\n    _ = ::yew::html! {\n        <>\n            <Container int=1 />\n            <Container int=1></Container>\n\n            <Container ..::std::clone::Clone::clone(&props)>\n                <div>{ \"hello world\" }</div>\n            </Container>\n\n            <Container int=1 ..::std::clone::Clone::clone(&props)>\n                <div>{ \"hello world\" }</div>\n            </Container>\n\n            <Container int=1 ..::std::clone::Clone::clone(&props)>\n                <Child int=2 opt_str=\"hello\" ..::std::clone::Clone::clone(&child_props) />\n            </Container>\n\n            <Container int=1 ..::std::clone::Clone::clone(&props)>\n                <Child int=2 vec={::std::vec![0]} ..::std::clone::Clone::clone(&child_props) />\n            </Container>\n\n\n            <Container int=1 ..props>\n                <Child int=2 string=\"hello\" ..child_props />\n            </Container>\n\n            <Container int=1>\n                <Child int=2 />\n            </Container>\n\n            <scoped::Container int=1>\n                <scoped::Container int=2/>\n            </scoped::Container>\n\n            <Container int=1 children={::yew::html::ChildrenRenderer::new(\n                ::std::vec![::yew::html!{ \"::std::string::String\" }]\n            )} />\n            <Container int=1 header={::yew::html!{\n                <Child int=2 />\n            }} />\n        </>\n    };\n\n    let variants = || -> ::std::vec::Vec<ChildrenVariants> {\n        ::std::vec![\n            ChildrenVariants::Child(::yew::virtual_dom::VChild::new(\n                <ChildProperties as ::std::default::Default>::default(),\n                ::std::option::Option::None,\n            )),\n            ChildrenVariants::AltChild(::yew::virtual_dom::VChild::new(\n                (),\n                ::std::option::Option::None\n            )),\n        ]\n    };\n\n    _ = ::yew::html! {\n        <>\n            {\n                ::std::iter::Iterator::collect::<::yew::virtual_dom::VNode>(\n                    ::std::iter::Iterator::filter(\n                        ::std::iter::IntoIterator::into_iter(variants()),\n                        |c| match c {\n                            ChildrenVariants::Child(_) => true,\n                            _ => false,\n                        }\n                    )\n                )\n            }\n            <div>\n                {\n                    ::std::iter::Iterator::collect::<::yew::virtual_dom::VNode>(\n                        ::std::iter::Iterator::filter(\n                            ::std::iter::IntoIterator::into_iter(variants()),\n                            |c| match c {\n                                ChildrenVariants::AltChild(_) => true,\n                                _ => false,\n                            }\n                        )\n                    )\n                }\n            </div>\n        </>\n    };\n\n    _ = ::yew::html_nested! { 1 };\n\n    _ = ::yew::html! {\n        <RenderPropComp>\n            {|_arg| {}}\n        </RenderPropComp>\n    };\n}\nfn main() {}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "3ff34530f17a8ba00e592dcf2b7fb70e8256dcf1",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/yew/packages/yew-macro/tests/html_macro/html-if-pass.rs",
    "func": "#![no_implicit_prelude]\n\nfn compile_pass_lit() {\n    _ = ::yew::html! { if true {} };\n    _ = ::yew::html! { if true { <div/> } };\n    _ = ::yew::html! { if true { <div/><div/> } };\n    _ = ::yew::html! { if true { <><div/><div/></> } };\n    _ = ::yew::html! { if true { { ::yew::html! {} } } };\n    _ = ::yew::html! { if true { { { let _x = 42; ::yew::html! {} } } } };\n    _ = ::yew::html! { if true {} else {} };\n    _ = ::yew::html! { if true {} else if true {} };\n    _ = ::yew::html! { if true {} else if true {} else {} };\n    _ = ::yew::html! { if let ::std::option::Option::Some(text) = ::std::option::Option::Some(\"text\") { <span>{ text }</span> } };\n    _ = ::yew::html! { <><div/>if true {}<div/></> };\n    _ = ::yew::html! { <div>if true {}</div> };\n}\n\nfn compile_pass_expr() {\n    let condition = true;\n\n    _ = ::yew::html! { if condition {} };\n    _ = ::yew::html! { if condition { <div/> } };\n    _ = ::yew::html! { if condition { <div/><div/> } };\n    _ = ::yew::html! { if condition { <><div/><div/></> } };\n    _ = ::yew::html! { if condition { { ::yew::html! {} } } };\n    _ = ::yew::html! { if condition { { { let _x = 42; ::yew::html! {} } } } };\n    _ = ::yew::html! { if condition {} else {} };\n    _ = ::yew::html! { if condition {} else if condition {} };\n    _ = ::yew::html! { if condition {} else if condition {} else {} };\n    _ = ::yew::html! { if let ::std::option::Option::Some(text) = ::std::option::Option::Some(\"text\") { <span>{ text }</span> } };\n    _ = ::yew::html! { <><div/>if condition {}<div/></> };\n    _ = ::yew::html! { <div>if condition {}</div> };\n}\n\nfn main() {}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "51731e9c45292f0efdf8503c65ae09424f4380dc",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/yew/packages/yew-macro/tests/props_macro/resolve-prop-pass.rs",
    "func": "#![no_implicit_prelude]\n\n// Shadow primitives\n#[allow(non_camel_case_types)]\npub struct bool;\n#[allow(non_camel_case_types)]\npub struct char;\n#[allow(non_camel_case_types)]\npub struct f32;\n#[allow(non_camel_case_types)]\npub struct f64;\n#[allow(non_camel_case_types)]\npub struct i128;\n#[allow(non_camel_case_types)]\npub struct i16;\n#[allow(non_camel_case_types)]\npub struct i32;\n#[allow(non_camel_case_types)]\npub struct i64;\n#[allow(non_camel_case_types)]\npub struct i8;\n#[allow(non_camel_case_types)]\npub struct isize;\n#[allow(non_camel_case_types)]\npub struct str;\n#[allow(non_camel_case_types)]\npub struct u128;\n#[allow(non_camel_case_types)]\npub struct u16;\n#[allow(non_camel_case_types)]\npub struct u32;\n#[allow(non_camel_case_types)]\npub struct u64;\n#[allow(non_camel_case_types)]\npub struct u8;\n#[allow(non_camel_case_types)]\npub struct usize;\n\n#[derive(::std::clone::Clone, ::yew::Properties, ::std::cmp::PartialEq)]\nstruct Props {\n    n: ::std::primitive::i32,\n}\n\nstruct MyComp;\nimpl ::yew::Component for MyComp {\n    type Message = ();\n    type Properties = Props;\n\n    fn create(_ctx: &::yew::Context<Self>) -> Self {\n        ::std::unimplemented!()\n    }\n    fn view(&self, _ctx: &::yew::Context<Self>) -> ::yew::Html {\n        ::std::unimplemented!()\n    }\n}\n\nfn compile_pass() {\n    ::yew::props!(Props { n: 1 });\n    ::yew::props!(self::Props { n: 1 });\n    ::yew::props!(MyComp::Properties { n: 2 });\n    ::yew::props!(self::MyComp::Properties { n: 3 });\n    ::yew::props!(<MyComp as ::yew::Component>::Properties { n: 5});\n}\n\nfn main() {}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "ab71344a0d6ced1baeaa050ac751018e51251cf5",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/yew/packages/yew-macro/src/classes/mod.rs",
    "func": "use proc_macro2::TokenStream;\nuse quote::{quote, quote_spanned, ToTokens};\nuse syn::parse::{Parse, ParseStream};\nuse syn::punctuated::Punctuated;\nuse syn::spanned::Spanned;\nuse syn::{Expr, ExprLit, Lit, LitStr, Token};\n\n/// List of HTML classes.\npub struct Classes(Punctuated<ClassExpr, Token![,]>);\n\nimpl Parse for Classes {\n    fn parse(input: ParseStream) -> syn::Result<Self> {\n        input\n            .parse_terminated(ClassExpr::parse, Token![,])\n            .map(Self)\n    }\n}\n\nimpl ToTokens for Classes {\n    fn to_tokens(&self, tokens: &mut TokenStream) {\n        let n = self.0.len();\n        let push_classes = self.0.iter().map(|x| match x {\n            ClassExpr::Lit(class) => quote! {\n                unsafe { __yew_classes.unchecked_push(#class) };\n            },\n            ClassExpr::Expr(class) => quote_spanned! {class.span()=>\n                __yew_classes.push(#class);\n            },\n        });\n        tokens.extend(quote! {\n            {\n                let mut __yew_classes = ::yew::html::Classes::with_capacity(#n);\n                #(#push_classes)*\n                __yew_classes\n            }\n        });\n    }\n}\n\nenum ClassExpr {\n    Lit(LitStr),\n    Expr(Box<Expr>),\n}\n\nimpl Parse for ClassExpr {\n    fn parse(input: ParseStream) -> syn::Result<Self> {\n        match input.parse()? {\n            Expr::Lit(ExprLit {\n                lit: Lit::Str(lit_str),\n                ..\n            }) => {\n                let value = lit_str.value();\n                let classes = value.split_whitespace().collect::<Vec<_>>();\n                if classes.len() > 1 {\n                    let fix = classes\n                        .into_iter()\n                        .map(|class| format!(\"\\\"{class}\\\"\"))\n                        .collect::<Vec<_>>()\n                        .join(\", \");\n                    let msg = format!(\n                        \"string literals must not contain more than one class (hint: use `{fix}`)\"\n                    );\n\n                    Err(syn::Error::new(lit_str.span(), msg))\n                } else {\n                    Ok(Self::Lit(lit_str))\n                }\n            }\n            expr => Ok(Self::Expr(Box::new(expr))),\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "4c604be2856174a6c8eff63471f1bb1da32319d3",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/yew/packages/yew-macro/src/hook/body.rs",
    "func": "use std::sync::{Arc, Mutex};\n\nuse proc_macro_error::emit_error;\nuse syn::spanned::Spanned;\nuse syn::visit_mut::VisitMut;\nuse syn::{\n    parse_quote_spanned, visit_mut, Expr, ExprCall, ExprClosure, ExprForLoop, ExprIf, ExprLoop,\n    ExprMatch, ExprWhile, Ident, Item,\n};\n\n#[derive(Debug)]\npub struct BodyRewriter {\n    branch_lock: Arc<Mutex<()>>,\n    ctx_ident: Ident,\n}\n\nimpl BodyRewriter {\n    pub fn new(ctx_ident: Ident) -> Self {\n        Self {\n            branch_lock: Arc::default(),\n            ctx_ident,\n        }\n    }\n\n    fn is_branched(&self) -> bool {\n        self.branch_lock.try_lock().is_err()\n    }\n\n    fn with_branch<F, O>(&mut self, f: F) -> O\n    where\n        F: FnOnce(&mut BodyRewriter) -> O,\n    {\n        let branch_lock = self.branch_lock.clone();\n        let _branched = branch_lock.try_lock();\n        f(self)\n    }\n}\n\nimpl VisitMut for BodyRewriter {\n    fn visit_expr_call_mut(&mut self, i: &mut ExprCall) {\n        let ctx_ident = &self.ctx_ident;\n\n        // Only rewrite hook calls.\n        if let Expr::Path(ref m) = &*i.func {\n            if let Some(m) = m.path.segments.last().as_ref().map(|m| &m.ident) {\n                if m.to_string().starts_with(\"use_\") {\n                    if self.is_branched() {\n                        emit_error!(\n                            m,\n                            \"hooks cannot be called at this position.\";\n                            help = \"move hooks to the top-level of your function.\";\n                            note = \"see: https://yew.rs/docs/next/concepts/function-components/hooks\"\n                        );\n                    } else {\n                        *i = parse_quote_spanned! { i.span() => ::yew::functional::Hook::run(#i, #ctx_ident) };\n                    }\n\n                    return;\n                }\n            }\n        }\n\n        visit_mut::visit_expr_call_mut(self, i);\n    }\n\n    fn visit_expr_mut(&mut self, i: &mut Expr) {\n        let ctx_ident = &self.ctx_ident;\n\n        match &mut *i {\n            Expr::Macro(m) => {\n                if let Some(ident) = m.mac.path.segments.last().as_ref().map(|m| &m.ident) {\n                    if ident.to_string().starts_with(\"use_\") {\n                        if self.is_branched() {\n                            emit_error!(\n                                ident,\n                                \"hooks cannot be called at this position.\";\n                                help = \"move hooks to the top-level of your function.\";\n                                note = \"see: https://yew.rs/docs/next/concepts/function-components/hooks\"\n                            );\n                        } else {\n                            *i = parse_quote_spanned! { i.span() => ::yew::functional::Hook::run(#i, #ctx_ident) };\n                        }\n                    } else {\n                        visit_mut::visit_expr_macro_mut(self, m);\n                    }\n                }\n            }\n            _ => visit_mut::visit_expr_mut(self, i),\n        }\n    }\n\n    fn visit_expr_closure_mut(&mut self, i: &mut ExprClosure) {\n        self.with_branch(move |m| visit_mut::visit_expr_closure_mut(m, i))\n    }\n\n    fn visit_expr_if_mut(&mut self, i: &mut ExprIf) {\n        for it in &mut i.attrs {\n            visit_mut::visit_attribute_mut(self, it);\n        }\n\n        visit_mut::visit_expr_mut(self, &mut i.cond);\n\n        self.with_branch(|m| visit_mut::visit_block_mut(m, &mut i.then_branch));\n\n        if let Some(it) = &mut i.else_branch {\n            self.with_branch(|m| visit_mut::visit_expr_mut(m, &mut (it).1));\n        }\n    }\n\n    fn visit_expr_loop_mut(&mut self, i: &mut ExprLoop) {\n        self.with_branch(|m| visit_mut::visit_expr_loop_mut(m, i));\n    }\n\n    fn visit_expr_for_loop_mut(&mut self, i: &mut ExprForLoop) {\n        for it in &mut i.attrs {\n            visit_mut::visit_attribute_mut(self, it);\n        }\n        if let Some(it) = &mut i.label {\n            visit_mut::visit_label_mut(self, it);\n        }\n        visit_mut::visit_pat_mut(self, &mut i.pat);\n        visit_mut::visit_expr_mut(self, &mut i.expr);\n\n        self.with_branch(|m| visit_mut::visit_block_mut(m, &mut i.body));\n    }\n\n    fn visit_expr_match_mut(&mut self, i: &mut ExprMatch) {\n        for it in &mut i.attrs {\n            visit_mut::visit_attribute_mut(self, it);\n        }\n\n        visit_mut::visit_expr_mut(self, &mut i.expr);\n\n        self.with_branch(|m| {\n            for it in &mut i.arms {\n                visit_mut::visit_arm_mut(m, it);\n            }\n        });\n    }\n\n    fn visit_expr_while_mut(&mut self, i: &mut ExprWhile) {\n        for it in &mut i.attrs {\n            visit_mut::visit_attribute_mut(self, it);\n        }\n        if let Some(it) = &mut i.label {\n            visit_mut::visit_label_mut(self, it);\n        }\n\n        self.with_branch(|m| visit_mut::visit_expr_mut(m, &mut i.cond));\n        self.with_branch(|m| visit_mut::visit_block_mut(m, &mut i.body));\n    }\n\n    fn visit_item_mut(&mut self, _i: &mut Item) {\n        // We don't do anything for items.\n        // for components / hooks in other components / hooks, apply the attribute again.\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "9bd1475e28f36b8e7e13cc027428d9f2c3a5a7bf",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/yew/packages/yew-agent-macro/src/reactor.rs",
    "func": "use proc_macro2::{Span, TokenStream};\nuse quote::quote;\nuse syn::{Ident, ReturnType, Signature, Type};\n\nuse crate::agent_fn::{AgentFn, AgentFnType, AgentName};\n\npub struct ReactorFn {}\n\nimpl AgentFnType for ReactorFn {\n    type OutputType = ();\n    type RecvType = Type;\n\n    fn attr_name() -> &'static str {\n        \"reactor\"\n    }\n\n    fn agent_type_name() -> &'static str {\n        \"reactor\"\n    }\n\n    fn parse_recv_type(sig: &Signature) -> syn::Result<Self::RecvType> {\n        let mut inputs = sig.inputs.iter();\n        let arg = inputs\n            .next()\n            .ok_or_else(|| syn::Error::new_spanned(&sig.ident, \"expected 1 argument\"))?;\n\n        let ty = Self::extract_fn_arg_type(arg)?;\n\n        Self::assert_no_left_argument(inputs, 1)?;\n\n        Ok(ty)\n    }\n\n    fn parse_output_type(sig: &Signature) -> syn::Result<Self::OutputType> {\n        match &sig.output {\n            ReturnType::Default => {}\n            ReturnType::Type(_, ty) => {\n                return Err(syn::Error::new_spanned(\n                    ty,\n                    \"reactor agents cannot return any value\",\n                ))\n            }\n        }\n\n        Ok(())\n    }\n}\n\npub fn reactor_impl(name: AgentName, mut agent_fn: AgentFn<ReactorFn>) -> syn::Result<TokenStream> {\n    agent_fn.merge_agent_name(name)?;\n\n    if !agent_fn.is_async {\n        return Err(syn::Error::new_spanned(\n            &agent_fn.name,\n            \"reactor agents must be asynchronous\",\n        ));\n    }\n\n    let struct_attrs = agent_fn.filter_attrs_for_agent_struct();\n    let reactor_impl_attrs = agent_fn.filter_attrs_for_agent_impl();\n    let phantom_generics = agent_fn.phantom_generics();\n    let reactor_name = agent_fn.agent_name();\n    let fn_name = agent_fn.inner_fn_ident();\n    let inner_fn = agent_fn.print_inner_fn();\n\n    let AgentFn {\n        recv_type,\n        generics,\n        vis,\n        ..\n    } = agent_fn;\n\n    let (impl_generics, ty_generics, where_clause) = generics.split_for_impl();\n    let fn_generics = ty_generics.as_turbofish();\n\n    let scope_ident = Ident::new(\"_scope\", Span::mixed_site());\n\n    let fn_call = quote! { #fn_name #fn_generics (#scope_ident).await };\n    let crate_name = quote! { yew_agent };\n\n    let quoted = quote! {\n        #(#struct_attrs)*\n        #[allow(unused_parens)]\n        #vis struct #reactor_name #generics #where_clause {\n            inner: ::std::pin::Pin<::std::boxed::Box<dyn ::std::future::Future<Output = ()>>>,\n            _marker: ::std::marker::PhantomData<(#phantom_generics)>,\n        }\n\n        // we cannot disable any lints here because it will be applied to the function body\n        // as well.\n        #(#reactor_impl_attrs)*\n        impl #impl_generics ::#crate_name::reactor::Reactor for #reactor_name #ty_generics #where_clause {\n            type Scope = #recv_type;\n\n            fn create(#scope_ident: Self::Scope) -> Self {\n                #inner_fn\n\n                Self {\n                    inner: ::std::boxed::Box::pin(\n                        async move {\n                            #fn_call\n                        }\n                    ),\n                    _marker: ::std::marker::PhantomData,\n                }\n            }\n        }\n\n        impl #impl_generics ::std::future::Future for #reactor_name #ty_generics #where_clause {\n            type Output = ();\n\n            fn poll(mut self: ::std::pin::Pin<&mut Self>, cx: &mut ::std::task::Context<'_>) -> ::std::task::Poll<Self::Output> {\n                ::std::future::Future::poll(::std::pin::Pin::new(&mut self.inner), cx)\n            }\n        }\n\n        impl #impl_generics ::#crate_name::Registrable for #reactor_name #ty_generics #where_clause {\n            type Registrar = ::#crate_name::reactor::ReactorRegistrar<Self>;\n\n            fn registrar() -> Self::Registrar {\n                ::#crate_name::reactor::ReactorRegistrar::<Self>::new()\n            }\n        }\n\n        impl #impl_generics ::#crate_name::Spawnable for #reactor_name #ty_generics #where_clause {\n            type Spawner = ::#crate_name::reactor::ReactorSpawner<Self>;\n\n            fn spawner() -> Self::Spawner {\n                ::#crate_name::reactor::ReactorSpawner::<Self>::new()\n            }\n        }\n    };\n\n    Ok(quoted)\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "c0164a68c8fe74fcf52ee26b6b92943cc804d798",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/yew/packages/yew-agent/src/oneshot/mod.rs",
    "func": "//! This module provides task agent implementation.\n\nmod hooks;\nmod provider;\n\n#[doc(inline)]\npub use gloo_worker::oneshot::{Oneshot, OneshotBridge, OneshotRegistrar, OneshotSpawner};\npub use hooks::{use_oneshot_runner, UseOneshotRunnerHandle};\npub use provider::OneshotProvider;\npub(crate) use provider::OneshotProviderState;\n/// A procedural macro to create oneshot agents.\npub use yew_agent_macro::oneshot;\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "2989ee0779c5ceed4aeaa33cbb8a3cbaef576ae6",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/yew/packages/yew/tests/use_transitive_state.rs",
    "func": "#![cfg(feature = \"hydration\")]\n#![cfg(target_arch = \"wasm32\")]\n\nuse std::time::Duration;\n\nmod common;\n\nuse common::obtain_result_by_id;\nuse wasm_bindgen_test::*;\nuse yew::platform::time::sleep;\nuse yew::prelude::*;\nuse yew::{Renderer, ServerRenderer};\n\nwasm_bindgen_test::wasm_bindgen_test_configure!(run_in_browser);\n\n#[wasm_bindgen_test]\nasync fn use_transitive_state_works() {\n    #[function_component]\n    fn Comp() -> HtmlResult {\n        let ctr = use_transitive_state!((), |_| -> u32 { 12345 })?.unwrap_or_default();\n\n        Ok(html! {\n            <div>\n                {*ctr}\n            </div>\n        })\n    }\n\n    #[function_component]\n    fn App() -> Html {\n        html! {\n            <Suspense fallback={Html::default()}>\n                <div>\n                    <Comp />\n                </div>\n            </Suspense>\n        }\n    }\n\n    let s = ServerRenderer::<App>::new().render().await;\n\n    assert_eq!(\n        s,\n        // div text content should be 0 but state should be 12345.\n        r#\"<!--<[use_transitive_state::use_transitive_state_works::{{closure}}::App]>--><!--<[yew::suspense::component::feat_csr_ssr::Suspense]>--><!--<[yew::suspense::component::feat_csr_ssr::BaseSuspense]>--><!--<?>--><div><!--<[use_transitive_state::use_transitive_state_works::{{closure}}::Comp]>--><div>0</div><script type=\"application/x-yew-comp-state\">ATkwAAAB</script><!--</[use_transitive_state::use_transitive_state_works::{{closure}}::Comp]>--></div><!--</?>--><!--</[yew::suspense::component::feat_csr_ssr::BaseSuspense]>--><!--</[yew::suspense::component::feat_csr_ssr::Suspense]>--><!--</[use_transitive_state::use_transitive_state_works::{{closure}}::App]>-->\"#\n    );\n\n    gloo::utils::document()\n        .query_selector(\"#output\")\n        .unwrap()\n        .unwrap()\n        .set_inner_html(&s);\n\n    sleep(Duration::ZERO).await;\n\n    Renderer::<App>::with_root(gloo::utils::document().get_element_by_id(\"output\").unwrap())\n        .hydrate();\n\n    sleep(Duration::from_millis(100)).await;\n\n    let result = obtain_result_by_id(\"output\");\n\n    // no placeholders, hydration is successful and div text content now becomes 12345.\n    assert_eq!(result, r#\"<div><div>12345</div></div>\"#);\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "fb7918cbf0c3db334207eb6bbdf499bf6319ad11",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/yew/packages/yew/src/context.rs",
    "func": "//! This module defines the `ContextProvider` component.\n\nuse std::cell::RefCell;\n\nuse slab::Slab;\n\nuse crate::html::Scope;\nuse crate::{Callback, Component, Context, Html, Properties};\n\n/// Props for [`ContextProvider`]\n#[derive(Debug, Clone, PartialEq, Properties)]\npub struct ContextProviderProps<T: Clone + PartialEq> {\n    /// Context value to be passed down\n    pub context: T,\n    /// Children\n    pub children: Html,\n}\n\n/// The context provider component.\n///\n/// Every child (direct or indirect) of this component may access the context value.\n/// In order to consume contexts, [`Scope::context`][Scope::context] method is used,\n/// In function components the `use_context` hook is used.\n#[derive(Debug)]\npub struct ContextProvider<T: Clone + PartialEq + 'static> {\n    context: T,\n    consumers: RefCell<Slab<Callback<T>>>,\n}\n\n/// Owns the connection to a context provider. When dropped, the component will\n/// no longer receive updates from the provider.\n#[derive(Debug)]\npub struct ContextHandle<T: Clone + PartialEq + 'static> {\n    provider: Scope<ContextProvider<T>>,\n    key: usize,\n}\n\nimpl<T: Clone + PartialEq + 'static> Drop for ContextHandle<T> {\n    fn drop(&mut self) {\n        if let Some(component) = self.provider.get_component() {\n            component.consumers.borrow_mut().remove(self.key);\n        }\n    }\n}\n\nimpl<T: Clone + PartialEq> ContextProvider<T> {\n    /// Add the callback to the subscriber list to be called whenever the context changes.\n    /// The consumer is unsubscribed as soon as the callback is dropped.\n    pub(crate) fn subscribe_consumer(\n        &self,\n        callback: Callback<T>,\n        scope: Scope<Self>,\n    ) -> (T, ContextHandle<T>) {\n        let ctx = self.context.clone();\n        let key = self.consumers.borrow_mut().insert(callback);\n\n        (\n            ctx,\n            ContextHandle {\n                provider: scope,\n                key,\n            },\n        )\n    }\n\n    /// Notify all subscribed consumers and remove dropped consumers from the list.\n    fn notify_consumers(&mut self) {\n        let consumers: Vec<Callback<T>> = self\n            .consumers\n            .borrow()\n            .iter()\n            .map(|(_, v)| v.clone())\n            .collect();\n        for consumer in consumers {\n            consumer.emit(self.context.clone());\n        }\n    }\n}\n\nimpl<T: Clone + PartialEq + 'static> Component for ContextProvider<T> {\n    type Message = ();\n    type Properties = ContextProviderProps<T>;\n\n    fn create(ctx: &Context<Self>) -> Self {\n        let props = ctx.props();\n        Self {\n            context: props.context.clone(),\n            consumers: RefCell::new(Slab::new()),\n        }\n    }\n\n    fn changed(&mut self, ctx: &Context<Self>, old_props: &Self::Properties) -> bool {\n        let props = ctx.props();\n\n        let should_render = old_props.children != props.children;\n\n        if self.context != props.context {\n            self.context = props.context.clone();\n            self.notify_consumers();\n        }\n\n        should_render\n    }\n\n    fn view(&self, ctx: &Context<Self>) -> Html {\n        ctx.props().children.clone()\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "a812f05ddb28010f84d8e47999ba3c13038456c0",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/yew/packages/yew/src/functional/hooks/use_prepared_state/mod.rs",
    "func": "#[cfg(feature = \"hydration\")]\npub(super) mod feat_hydration;\n#[cfg(all(feature = \"hydration\", feature = \"ssr\"))]\nmod feat_hydration_ssr;\n#[cfg(not(any(feature = \"hydration\", feature = \"ssr\")))]\npub(super) mod feat_none;\n#[cfg(feature = \"ssr\")]\nmod feat_ssr;\n\n#[cfg(all(feature = \"hydration\", not(feature = \"ssr\")))]\npub use feat_hydration::*;\n#[cfg(all(feature = \"ssr\", feature = \"hydration\"))]\npub use feat_hydration_ssr::*;\n#[cfg(not(any(feature = \"hydration\", feature = \"ssr\")))]\npub use feat_none::*;\n#[cfg(all(feature = \"ssr\", not(feature = \"hydration\")))]\npub use feat_ssr::*;\n/// Use a state prepared on the server side and its value is sent to the client side during\n/// hydration.\n///\n/// The component sees the same value on the server side and client side if the component is\n/// hydrated.\n///\n/// It accepts a closure as the first argument and a dependency type as the second argument.\n/// It returns `SuspensionResult<Option<Rc<T>>>`.\n///\n/// During hydration, it will only return `Ok(Some(Rc<T>))` if the component is hydrated from a\n/// server-side rendering artifact and its dependency value matches.\n///\n/// `let state = use_prepared_state!(|deps| -> ReturnType { ... }, deps)?;`\n///\n/// It has the following signature:\n///\n/// ```\n/// # use serde::de::DeserializeOwned;\n/// # use serde::Serialize;\n/// # use std::rc::Rc;\n/// use yew::prelude::*;\n/// use yew::suspense::SuspensionResult;\n///\n/// #[hook]\n/// pub fn use_prepared_state<T, D, F>(deps: D, f: F) -> SuspensionResult<Option<Rc<T>>>\n/// where\n///     D: Serialize + DeserializeOwned + PartialEq + 'static,\n///     T: Serialize + DeserializeOwned + 'static,\n///     F: FnOnce(Rc<D>) -> T,\n/// # { todo!() }\n/// ```\n///\n/// The first argument can also be an [async closure](https://github.com/rust-lang/rust/issues/62290).\n///\n/// `let state = use_prepared_state!(async |deps| -> ReturnType { ... }, deps)?;`\n///\n/// When accepting an async closure, it has the following signature:\n///\n/// ```\n/// # use serde::de::DeserializeOwned;\n/// # use serde::Serialize;\n/// # use std::rc::Rc;\n/// # use std::future::Future;\n/// use yew::prelude::*;\n/// use yew::suspense::SuspensionResult;\n///\n/// #[hook]\n/// pub fn use_prepared_state<T, D, F, U>(\n///         deps: D,\n///         f: F,\n///     ) -> SuspensionResult<Option<Rc<T>>>\n///     where\n///         D: Serialize + DeserializeOwned + PartialEq + 'static,\n///         T: Serialize + DeserializeOwned + 'static,\n///         F: FnOnce(Rc<D>) -> U,\n///         U: 'static + Future<Output = T>,\n/// # { todo!() }\n/// ```\n///\n/// During server-side rendering, a value of type `T` will be calculated from the first\n/// closure.\n///\n/// If the bundle is compiled without server-side rendering, the closure will be stripped\n/// automatically.\n///\n/// # Note\n///\n/// You MUST denote the return type of the closure with `|deps| -> ReturnType { ... }`. This\n/// type is used during client side rendering to deserialize the state prepared on the server\n/// side.\n///\n/// Whilst async closure is an unstable feature, the procedural macro will rewrite this to a\n/// closure that returns an async block automatically. You can use this hook with async closure\n/// in stable Rust.\npub use use_prepared_state_macro as use_prepared_state;\n// With SSR.\n#[doc(hidden)]\n#[cfg(feature = \"ssr\")]\npub use yew_macro::use_prepared_state_with_closure as use_prepared_state_macro;\n// Without SSR.\n#[doc(hidden)]\n#[cfg(not(feature = \"ssr\"))]\npub use yew_macro::use_prepared_state_without_closure as use_prepared_state_macro;\n\n#[cfg(any(feature = \"hydration\", feature = \"ssr\"))]\nmod feat_any_hydration_ssr {\n    use std::marker::PhantomData;\n    #[cfg(feature = \"ssr\")]\n    use std::rc::Rc;\n\n    use serde::de::DeserializeOwned;\n    use serde::Serialize;\n\n    use crate::functional::PreparedState;\n\n    pub(super) struct PreparedStateBase<T, D>\n    where\n        D: Serialize + DeserializeOwned + PartialEq + 'static,\n        T: Serialize + DeserializeOwned + 'static,\n    {\n        #[cfg(feature = \"ssr\")]\n        pub state: Option<Rc<T>>,\n        #[cfg(feature = \"ssr\")]\n        pub deps: Option<Rc<D>>,\n        #[cfg(feature = \"hydration\")]\n        pub has_buf: bool,\n        pub _marker: PhantomData<(T, D)>,\n    }\n\n    impl<T, D> PreparedState for PreparedStateBase<T, D>\n    where\n        D: Serialize + DeserializeOwned + PartialEq + 'static,\n        T: Serialize + DeserializeOwned + 'static,\n    {\n        #[cfg(feature = \"ssr\")]\n        fn prepare(&self) -> String {\n            use base64ct::{Base64, Encoding};\n\n            let state = bincode::serialize(&(self.state.as_deref(), self.deps.as_deref()))\n                .expect(\"failed to prepare state\");\n\n            Base64::encode_string(&state)\n        }\n    }\n}\n\n#[cfg(any(feature = \"hydration\", feature = \"ssr\"))]\nuse feat_any_hydration_ssr::PreparedStateBase;\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "1fc2a6945f8d7fe01d3278e9e307e2aa407c7398",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/yew/packages/yew/src/dom_bundle/bnode.rs",
    "func": "//! This module contains the bundle version of an abstract node [BNode]\n\nuse std::fmt;\n\nuse web_sys::{Element, Node};\n\nuse super::{BComp, BList, BPortal, BRaw, BSubtree, BSuspense, BTag, BText, DomSlot};\nuse crate::dom_bundle::{Reconcilable, ReconcileTarget};\nuse crate::html::AnyScope;\nuse crate::utils::RcExt;\nuse crate::virtual_dom::{Key, VNode};\n\n/// The bundle implementation to [VNode].\npub(super) enum BNode {\n    /// A bind between `VTag` and `Element`.\n    Tag(Box<BTag>),\n    /// A bind between `VText` and `TextNode`.\n    Text(BText),\n    /// A bind between `VComp` and `Element`.\n    Comp(BComp),\n    /// A holder for a list of other nodes.\n    List(BList),\n    /// A portal to another part of the document\n    Portal(BPortal),\n    /// A holder for any `Node` (necessary for replacing node).\n    Ref(Node),\n    /// A suspendible document fragment.\n    Suspense(Box<BSuspense>),\n    /// A raw HTML string, represented by [`AttrValue`](crate::AttrValue).\n    Raw(BRaw),\n}\n\nimpl BNode {\n    /// Get the key of the underlying node\n    pub fn key(&self) -> Option<&Key> {\n        match self {\n            Self::Comp(bsusp) => bsusp.key(),\n            Self::List(blist) => blist.key(),\n            Self::Ref(_) => None,\n            Self::Tag(btag) => btag.key(),\n            Self::Text(_) => None,\n            Self::Portal(bportal) => bportal.key(),\n            Self::Suspense(bsusp) => bsusp.key(),\n            Self::Raw(_) => None,\n        }\n    }\n}\n\nimpl ReconcileTarget for BNode {\n    /// Remove VNode from parent.\n    fn detach(self, root: &BSubtree, parent: &Element, parent_to_detach: bool) {\n        match self {\n            Self::Tag(vtag) => vtag.detach(root, parent, parent_to_detach),\n            Self::Text(btext) => btext.detach(root, parent, parent_to_detach),\n            Self::Comp(bsusp) => bsusp.detach(root, parent, parent_to_detach),\n            Self::List(blist) => blist.detach(root, parent, parent_to_detach),\n            Self::Ref(ref node) => {\n                // Always remove user-defined nodes to clear possible parent references of them\n                if parent.remove_child(node).is_err() {\n                    tracing::warn!(\"Node not found to remove VRef\");\n                }\n            }\n            Self::Portal(bportal) => bportal.detach(root, parent, parent_to_detach),\n            Self::Suspense(bsusp) => bsusp.detach(root, parent, parent_to_detach),\n            Self::Raw(raw) => raw.detach(root, parent, parent_to_detach),\n        }\n    }\n\n    fn shift(&self, next_parent: &Element, slot: DomSlot) -> DomSlot {\n        match self {\n            Self::Tag(ref vtag) => vtag.shift(next_parent, slot),\n            Self::Text(ref btext) => btext.shift(next_parent, slot),\n            Self::Comp(ref bsusp) => bsusp.shift(next_parent, slot),\n            Self::List(ref vlist) => vlist.shift(next_parent, slot),\n            Self::Ref(ref node) => {\n                slot.insert(next_parent, node);\n\n                DomSlot::at(node.clone())\n            }\n            Self::Portal(ref vportal) => vportal.shift(next_parent, slot),\n            Self::Suspense(ref vsuspense) => vsuspense.shift(next_parent, slot),\n            Self::Raw(ref braw) => braw.shift(next_parent, slot),\n        }\n    }\n}\n\nimpl Reconcilable for VNode {\n    type Bundle = BNode;\n\n    fn attach(\n        self,\n        root: &BSubtree,\n        parent_scope: &AnyScope,\n        parent: &Element,\n        slot: DomSlot,\n    ) -> (DomSlot, Self::Bundle) {\n        match self {\n            VNode::VTag(vtag) => {\n                let (node_ref, tag) =\n                    RcExt::unwrap_or_clone(vtag).attach(root, parent_scope, parent, slot);\n                (node_ref, tag.into())\n            }\n            VNode::VText(vtext) => {\n                let (node_ref, text) = vtext.attach(root, parent_scope, parent, slot);\n                (node_ref, text.into())\n            }\n            VNode::VComp(vcomp) => {\n                let (node_ref, comp) =\n                    RcExt::unwrap_or_clone(vcomp).attach(root, parent_scope, parent, slot);\n                (node_ref, comp.into())\n            }\n            VNode::VList(vlist) => {\n                let (node_ref, list) =\n                    RcExt::unwrap_or_clone(vlist).attach(root, parent_scope, parent, slot);\n                (node_ref, list.into())\n            }\n            VNode::VRef(node) => {\n                slot.insert(parent, &node);\n                (DomSlot::at(node.clone()), BNode::Ref(node))\n            }\n            VNode::VPortal(vportal) => {\n                let (node_ref, portal) =\n                    RcExt::unwrap_or_clone(vportal).attach(root, parent_scope, parent, slot);\n                (node_ref, portal.into())\n            }\n            VNode::VSuspense(vsuspsense) => {\n                let (node_ref, suspsense) =\n                    RcExt::unwrap_or_clone(vsuspsense).attach(root, parent_scope, parent, slot);\n                (node_ref, suspsense.into())\n            }\n            VNode::VRaw(vraw) => {\n                let (node_ref, raw) = vraw.attach(root, parent_scope, parent, slot);\n                (node_ref, raw.into())\n            }\n        }\n    }\n\n    fn reconcile_node(\n        self,\n        root: &BSubtree,\n        parent_scope: &AnyScope,\n        parent: &Element,\n        slot: DomSlot,\n        bundle: &mut BNode,\n    ) -> DomSlot {\n        self.reconcile(root, parent_scope, parent, slot, bundle)\n    }\n\n    fn reconcile(\n        self,\n        root: &BSubtree,\n        parent_scope: &AnyScope,\n        parent: &Element,\n        slot: DomSlot,\n        bundle: &mut BNode,\n    ) -> DomSlot {\n        match self {\n            VNode::VTag(vtag) => RcExt::unwrap_or_clone(vtag).reconcile_node(\n                root,\n                parent_scope,\n                parent,\n                slot,\n                bundle,\n            ),\n            VNode::VText(vtext) => vtext.reconcile_node(root, parent_scope, parent, slot, bundle),\n            VNode::VComp(vcomp) => RcExt::unwrap_or_clone(vcomp).reconcile_node(\n                root,\n                parent_scope,\n                parent,\n                slot,\n                bundle,\n            ),\n            VNode::VList(vlist) => RcExt::unwrap_or_clone(vlist).reconcile_node(\n                root,\n                parent_scope,\n                parent,\n                slot,\n                bundle,\n            ),\n            VNode::VRef(node) => match bundle {\n                BNode::Ref(ref n) if &node == n => DomSlot::at(node),\n                _ => VNode::VRef(node).replace(root, parent_scope, parent, slot, bundle),\n            },\n            VNode::VPortal(vportal) => RcExt::unwrap_or_clone(vportal).reconcile_node(\n                root,\n                parent_scope,\n                parent,\n                slot,\n                bundle,\n            ),\n            VNode::VSuspense(vsuspsense) => RcExt::unwrap_or_clone(vsuspsense).reconcile_node(\n                root,\n                parent_scope,\n                parent,\n                slot,\n                bundle,\n            ),\n            VNode::VRaw(vraw) => vraw.reconcile_node(root, parent_scope, parent, slot, bundle),\n        }\n    }\n}\n\nimpl From<BText> for BNode {\n    #[inline]\n    fn from(btext: BText) -> Self {\n        Self::Text(btext)\n    }\n}\n\nimpl From<BList> for BNode {\n    #[inline]\n    fn from(blist: BList) -> Self {\n        Self::List(blist)\n    }\n}\n\nimpl From<BTag> for BNode {\n    #[inline]\n    fn from(btag: BTag) -> Self {\n        Self::Tag(Box::new(btag))\n    }\n}\n\nimpl From<BComp> for BNode {\n    #[inline]\n    fn from(bcomp: BComp) -> Self {\n        Self::Comp(bcomp)\n    }\n}\n\nimpl From<BPortal> for BNode {\n    #[inline]\n    fn from(bportal: BPortal) -> Self {\n        Self::Portal(bportal)\n    }\n}\n\nimpl From<BSuspense> for BNode {\n    #[inline]\n    fn from(bsusp: BSuspense) -> Self {\n        Self::Suspense(Box::new(bsusp))\n    }\n}\n\nimpl From<BRaw> for BNode {\n    #[inline]\n    fn from(braw: BRaw) -> Self {\n        Self::Raw(braw)\n    }\n}\n\nimpl fmt::Debug for BNode {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match *self {\n            Self::Tag(ref vtag) => vtag.fmt(f),\n            Self::Text(ref btext) => btext.fmt(f),\n            Self::Comp(ref bsusp) => bsusp.fmt(f),\n            Self::List(ref vlist) => vlist.fmt(f),\n            Self::Ref(ref vref) => write!(f, \"VRef ( \\\"{}\\\" )\", crate::utils::print_node(vref)),\n            Self::Portal(ref vportal) => vportal.fmt(f),\n            Self::Suspense(ref bsusp) => bsusp.fmt(f),\n            Self::Raw(ref braw) => braw.fmt(f),\n        }\n    }\n}\n\n#[cfg(feature = \"hydration\")]\nmod feat_hydration {\n    use super::*;\n    use crate::dom_bundle::{Fragment, Hydratable};\n\n    impl Hydratable for VNode {\n        fn hydrate(\n            self,\n            root: &BSubtree,\n            parent_scope: &AnyScope,\n            parent: &Element,\n            fragment: &mut Fragment,\n        ) -> Self::Bundle {\n            match self {\n                VNode::VTag(vtag) => RcExt::unwrap_or_clone(vtag)\n                    .hydrate(root, parent_scope, parent, fragment)\n                    .into(),\n                VNode::VText(vtext) => vtext.hydrate(root, parent_scope, parent, fragment).into(),\n                VNode::VComp(vcomp) => RcExt::unwrap_or_clone(vcomp)\n                    .hydrate(root, parent_scope, parent, fragment)\n                    .into(),\n                VNode::VList(vlist) => RcExt::unwrap_or_clone(vlist)\n                    .hydrate(root, parent_scope, parent, fragment)\n                    .into(),\n                // You cannot hydrate a VRef.\n                VNode::VRef(_) => {\n                    panic!(\n                        \"VRef is not hydratable. Try moving it to a component mounted after an \\\n                         effect.\"\n                    )\n                }\n                // You cannot hydrate a VPortal.\n                VNode::VPortal(_) => {\n                    panic!(\n                        \"VPortal is not hydratable. Try creating your portal by delaying it with \\\n                         use_effect.\"\n                    )\n                }\n                VNode::VSuspense(vsuspense) => RcExt::unwrap_or_clone(vsuspense)\n                    .hydrate(root, parent_scope, parent, fragment)\n                    .into(),\n                VNode::VRaw(vraw) => vraw.hydrate(root, parent_scope, parent, fragment).into(),\n            }\n        }\n    }\n}\n\n#[cfg(all(target_arch = \"wasm32\", not(target_os = \"wasi\")))]\n#[cfg(test)]\nmod layout_tests {\n    use wasm_bindgen_test::{wasm_bindgen_test as test, wasm_bindgen_test_configure};\n\n    use super::*;\n    use crate::tests::layout_tests::{diff_layouts, TestLayout};\n\n    wasm_bindgen_test_configure!(run_in_browser);\n\n    #[test]\n    fn diff() {\n        let document = gloo::utils::document();\n        let vref_node_1 = VNode::VRef(document.create_element(\"i\").unwrap().into());\n        let vref_node_2 = VNode::VRef(document.create_element(\"b\").unwrap().into());\n\n        let layout1 = TestLayout {\n            name: \"1\",\n            node: vref_node_1,\n            expected: \"<i></i>\",\n        };\n\n        let layout2 = TestLayout {\n            name: \"2\",\n            node: vref_node_2,\n            expected: \"<b></b>\",\n        };\n\n        diff_layouts(vec![layout1, layout2]);\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "3b1b60985e503d31d33f34e8527450c061283d49",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/yew/examples/async_clock/src/services.rs",
    "func": "use std::time::Duration;\n\nuse chrono::{DateTime, Local};\nuse futures::{Stream, StreamExt};\nuse gloo_net::http::Request;\nuse yew::platform::pinned::mpsc::UnboundedSender;\nuse yew::platform::spawn_local;\nuse yew::platform::time::{interval, sleep};\nuse yew::{AttrValue, Callback};\n\nconst ONE_SEC: Duration = Duration::from_secs(1);\nconst TEN_SECS: Duration = Duration::from_secs(10);\n\n/// Demonstration code to show how to use async code in a yew component.\npub async fn initialize_atomic_clocks() {\n    // aligning with atomic clocks :-)\n    sleep(ONE_SEC).await;\n}\n\n/// Returns a stream of time updates.\npub fn stream_time() -> impl Stream<Item = DateTime<Local>> {\n    interval(ONE_SEC).map(|_| Local::now())\n}\n\n/// Emit entertaining jokes every 10 seconds.\npub fn emit_jokes(joke_cb: Callback<AttrValue>) {\n    // Spawn a background task that will fetch a joke and send it to the component.\n    spawn_local(async move {\n        loop {\n            // Fetch the online joke\n            let fun_fact =\n                Request::get(\"https://v2.jokeapi.dev/joke/Programming?format=txt&safe-mode\")\n                    .send()\n                    .await\n                    .unwrap()\n                    .text()\n                    .await\n                    .unwrap();\n\n            // Emit it to the component\n            joke_cb.emit(AttrValue::from(fun_fact));\n            sleep(TEN_SECS).await;\n        }\n    });\n}\n\n/// Background task that computes the fun score from jokes that are delivered on the channel.\npub fn compute_fun_score(fun_score_cb: Callback<i16>) -> UnboundedSender<AttrValue> {\n    let (tx, mut rx) = yew::platform::pinned::mpsc::unbounded::<AttrValue>();\n\n    // Read endlessly from the UnboundedReceiver and compute the fun score.\n    spawn_local(async move {\n        while let Some(joke) = rx.next().await {\n            sleep(ONE_SEC).await;\n            let score = joke.len() as i16;\n            fun_score_cb.emit(score);\n        }\n    });\n\n    tx\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "87c85ee4e30b70621be1b45806704be4baa07be9",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/yew/examples/boids/src/slider.rs",
    "func": "use std::cell::Cell;\n\nuse web_sys::HtmlInputElement;\nuse yew::events::InputEvent;\nuse yew::{html, Callback, Component, Context, Html, Properties, TargetCast};\n\nthread_local! {\n    static SLIDER_ID: Cell<usize> = Cell::default();\n}\nfn next_slider_id() -> usize {\n    SLIDER_ID.with(|cell| cell.replace(cell.get() + 1))\n}\n\n#[derive(Clone, Debug, PartialEq, Properties)]\npub struct Props {\n    pub label: &'static str,\n    pub value: f64,\n    pub onchange: Callback<f64>,\n    #[prop_or_default]\n    pub precision: Option<usize>,\n    #[prop_or_default]\n    pub percentage: bool,\n    #[prop_or_default]\n    pub min: f64,\n    pub max: f64,\n    #[prop_or_default]\n    pub step: Option<f64>,\n}\n\npub struct Slider {\n    id: usize,\n}\nimpl Component for Slider {\n    type Message = ();\n    type Properties = Props;\n\n    fn create(_ctx: &Context<Self>) -> Self {\n        Self {\n            id: next_slider_id(),\n        }\n    }\n\n    fn update(&mut self, _ctx: &Context<Self>, _msg: Self::Message) -> bool {\n        unimplemented!()\n    }\n\n    fn view(&self, ctx: &Context<Self>) -> Html {\n        let Props {\n            label,\n            value,\n            ref onchange,\n            precision,\n            percentage,\n            min,\n            max,\n            step,\n        } = *ctx.props();\n\n        let precision = precision.unwrap_or_else(|| usize::from(percentage));\n\n        let display_value = if percentage {\n            format!(\"{:.p$}%\", 100.0 * value, p = precision)\n        } else {\n            format!(\"{value:.precision$}\")\n        };\n\n        let id = format!(\"slider-{}\", self.id);\n        let step = step.unwrap_or_else(|| {\n            let p = if percentage { precision + 2 } else { precision };\n            10f64.powi(-(p as i32))\n        });\n\n        let oninput = onchange.reform(|e: InputEvent| {\n            let input: HtmlInputElement = e.target_unchecked_into();\n            input.value_as_number()\n        });\n\n        html! {\n            <div class=\"slider\">\n                <label for={id.clone()} class=\"slider__label\">{ label }</label>\n                <input type=\"range\"\n                    value={value.to_string()}\n                    {id}\n                    class=\"slider__input\"\n                    min={min.to_string()} max={max.to_string()} step={step.to_string()}\n                    {oninput}\n                />\n                <span class=\"slider__value\">{ display_value }</span>\n            </div>\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "ce69a60f82e4981e149226aa4ea966c2ada2158d",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/yew/examples/boids/src/main.rs",
    "func": "use settings::Settings;\nuse simulation::Simulation;\nuse slider::Slider;\nuse yew::html::Scope;\nuse yew::{html, Component, Context, Html};\n\nmod boid;\nmod math;\nmod settings;\nmod simulation;\nmod slider;\n\npub enum Msg {\n    ChangeSettings(Settings),\n    ResetSettings,\n    RestartSimulation,\n    TogglePause,\n}\n\npub struct App {\n    settings: Settings,\n    generation: usize,\n    paused: bool,\n}\nimpl Component for App {\n    type Message = Msg;\n    type Properties = ();\n\n    fn create(_ctx: &Context<Self>) -> Self {\n        Self {\n            settings: Settings::load(),\n            generation: 0,\n            paused: false,\n        }\n    }\n\n    fn update(&mut self, _ctx: &Context<Self>, msg: Msg) -> bool {\n        match msg {\n            Msg::ChangeSettings(settings) => {\n                self.settings = settings;\n                self.settings.store();\n                true\n            }\n            Msg::ResetSettings => {\n                self.settings = Settings::default();\n                Settings::remove();\n                true\n            }\n            Msg::RestartSimulation => {\n                self.generation = self.generation.wrapping_add(1);\n                true\n            }\n            Msg::TogglePause => {\n                self.paused = !self.paused;\n                true\n            }\n        }\n    }\n\n    fn view(&self, ctx: &Context<Self>) -> Html {\n        let Self {\n            ref settings,\n            generation,\n            paused,\n            ..\n        } = *self;\n\n        html! {\n            <>\n                <h1 class=\"title\">{ \"Boids\" }</h1>\n                <Simulation settings={settings.clone()} {generation} {paused} />\n                { self.view_panel(ctx.link()) }\n            </>\n        }\n    }\n}\nimpl App {\n    fn view_panel(&self, link: &Scope<Self>) -> Html {\n        let pause_text = if self.paused { \"Resume\" } else { \"Pause\" };\n        html! {\n            <div class=\"panel\">\n                { self.view_settings(link) }\n                <div class=\"panel__buttons\">\n                    <button onclick={link.callback(|_| Msg::TogglePause)}>{ pause_text }</button>\n                    <button onclick={link.callback(|_| Msg::ResetSettings)}>{ \"Use Defaults\" }</button>\n                    <button onclick={link.callback(|_| Msg::RestartSimulation)}>{ \"Restart\" }</button>\n                </div>\n            </div>\n        }\n    }\n\n    fn view_settings(&self, link: &Scope<Self>) -> Html {\n        let Self { settings, .. } = self;\n\n        // This helper macro creates a callback which applies the new value to the current settings\n        // and sends `Msg::ChangeSettings`. Thanks to this, we don't need to have\n        // \"ChangeBoids\", \"ChangeCohesion\", etc. messages, but it comes at the cost of\n        // cloning the `Settings` struct each time.\n        macro_rules! settings_callback {\n            ($link:expr, $settings:ident; $key:ident as $ty:ty) => {{\n                let settings = $settings.clone();\n                $link.callback(move |value| {\n                    let mut settings = settings.clone();\n                    settings.$key = value as $ty;\n                    Msg::ChangeSettings(settings)\n                })\n            }};\n            ($link:expr, $settings:ident; $key:ident) => {\n                settings_callback!($link, $settings; $key as f64)\n            }\n        }\n\n        html! {\n            <div class=\"settings\">\n                <Slider label=\"Number of Boids\"\n                    min=1.0 max=600.0\n                    onchange={settings_callback!(link, settings; boids as usize)}\n                    value={settings.boids as f64}\n                />\n                <Slider label=\"View Distance\"\n                    max=500.0 step=10.0\n                    onchange={settings_callback!(link, settings; visible_range)}\n                    value={settings.visible_range}\n                />\n                <Slider label=\"Spacing\"\n                    max=100.0\n                    onchange={settings_callback!(link, settings; min_distance)}\n                    value={settings.min_distance}\n                />\n                <Slider label=\"Max Speed\"\n                    max=50.0\n                    onchange={settings_callback!(link, settings; max_speed)}\n                    value={settings.max_speed}\n                />\n                <Slider label=\"Cohesion\"\n                    max=0.5 percentage=true\n                    onchange={settings_callback!(link, settings; cohesion_factor)}\n                    value={settings.cohesion_factor}\n                />\n                <Slider label=\"Separation\"\n                    max=1.0 percentage=true\n                    onchange={settings_callback!(link, settings; separation_factor)}\n                    value={settings.separation_factor}\n                />\n                <Slider label=\"Alignment\"\n                    max=0.5 percentage=true\n                    onchange={settings_callback!(link, settings; alignment_factor)}\n                    value={settings.alignment_factor}\n                />\n                <Slider label=\"Turn Speed\"\n                    max=1.5 percentage=true\n                    onchange={settings_callback!(link, settings; turn_speed_ratio)}\n                    value={settings.turn_speed_ratio}\n                />\n                <Slider label=\"Color Adaption\"\n                    max=1.5 percentage=true\n                    onchange={settings_callback!(link, settings; color_adapt_factor)}\n                    value={settings.color_adapt_factor}\n                />\n            </div>\n        }\n    }\n}\n\nfn main() {\n    yew::Renderer::<App>::new().render();\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "34f3532f60c92e765b2c3d7c24a120c268a35fb3",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/yew/examples/router/src/main.rs",
    "func": "use yew::prelude::*;\nuse yew_router::prelude::*;\n\nmod components;\nmod content;\nmod generator;\nmod pages;\nuse pages::author::Author;\nuse pages::author_list::AuthorList;\nuse pages::home::Home;\nuse pages::page_not_found::PageNotFound;\nuse pages::post::Post;\nuse pages::post_list::PostList;\nuse yew::html::Scope;\n\n#[derive(Routable, PartialEq, Eq, Clone, Debug)]\npub enum Route {\n    #[at(\"/posts/:id\")]\n    Post { id: u64 },\n    #[at(\"/posts\")]\n    Posts,\n    #[at(\"/authors/:id\")]\n    Author { id: u64 },\n    #[at(\"/authors\")]\n    Authors,\n    #[at(\"/\")]\n    Home,\n    #[not_found]\n    #[at(\"/404\")]\n    NotFound,\n}\n\npub enum Msg {\n    ToggleNavbar,\n}\n\npub struct App {\n    navbar_active: bool,\n}\nimpl Component for App {\n    type Message = Msg;\n    type Properties = ();\n\n    fn create(_ctx: &Context<Self>) -> Self {\n        Self {\n            navbar_active: false,\n        }\n    }\n\n    fn update(&mut self, _ctx: &Context<Self>, msg: Self::Message) -> bool {\n        match msg {\n            Msg::ToggleNavbar => {\n                self.navbar_active = !self.navbar_active;\n                true\n            }\n        }\n    }\n\n    fn view(&self, ctx: &Context<Self>) -> Html {\n        html! {\n            <BrowserRouter>\n                { self.view_nav(ctx.link()) }\n\n                <main>\n                    <Switch<Route> render={switch} />\n                </main>\n                <footer class=\"footer\">\n                    <div class=\"content has-text-centered\">\n                        { \"Powered by \" }\n                        <a href=\"https://yew.rs\">{ \"Yew\" }</a>\n                        { \" using \" }\n                        <a href=\"https://bulma.io\">{ \"Bulma\" }</a>\n                        { \" and images from \" }\n                        <a href=\"https://unsplash.com\">{ \"Unsplash\" }</a>\n                    </div>\n                </footer>\n            </BrowserRouter>\n        }\n    }\n}\nimpl App {\n    fn view_nav(&self, link: &Scope<Self>) -> Html {\n        let Self { navbar_active, .. } = *self;\n\n        let active_class = if !navbar_active { \"is-active\" } else { \"\" };\n\n        html! {\n            <nav class=\"navbar is-primary\" role=\"navigation\" aria-label=\"main navigation\">\n                <div class=\"navbar-brand\">\n                    <h1 class=\"navbar-item is-size-3\">{ \"Yew Blog\" }</h1>\n\n                    <button class={classes!(\"navbar-burger\", \"burger\", active_class)}\n                        aria-label=\"menu\" aria-expanded=\"false\"\n                        onclick={link.callback(|_| Msg::ToggleNavbar)}\n                    >\n                        <span aria-hidden=\"true\"></span>\n                        <span aria-hidden=\"true\"></span>\n                        <span aria-hidden=\"true\"></span>\n                    </button>\n                </div>\n                <div class={classes!(\"navbar-menu\", active_class)}>\n                    <div class=\"navbar-start\">\n                        <Link<Route> classes={classes!(\"navbar-item\")} to={Route::Home}>\n                            { \"Home\" }\n                        </Link<Route>>\n                        <Link<Route> classes={classes!(\"navbar-item\")} to={Route::Posts}>\n                            { \"Posts\" }\n                        </Link<Route>>\n\n                        <div class=\"navbar-item has-dropdown is-hoverable\">\n                            <div class=\"navbar-link\">\n                                { \"More\" }\n                            </div>\n                            <div class=\"navbar-dropdown\">\n                                <Link<Route> classes={classes!(\"navbar-item\")} to={Route::Authors}>\n                                    { \"Meet the authors\" }\n                                </Link<Route>>\n                            </div>\n                        </div>\n                    </div>\n                </div>\n            </nav>\n        }\n    }\n}\n\nfn switch(routes: Route) -> Html {\n    match routes {\n        Route::Post { id } => {\n            html! { <Post seed={id} /> }\n        }\n        Route::Posts => {\n            html! { <PostList /> }\n        }\n        Route::Author { id } => {\n            html! { <Author seed={id} /> }\n        }\n        Route::Authors => {\n            html! { <AuthorList /> }\n        }\n        Route::Home => {\n            html! { <Home /> }\n        }\n        Route::NotFound => {\n            html! { <PageNotFound /> }\n        }\n    }\n}\n\nfn main() {\n    wasm_logger::init(wasm_logger::Config::new(log::Level::Trace));\n    yew::Renderer::<App>::new().render();\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "1657e7aa037a72a55087243488b8b8a947b66a90",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/yew/examples/webgl/src/main.rs",
    "func": "use std::cell::RefCell;\nuse std::rc::Rc;\n\nuse wasm_bindgen::prelude::*;\nuse wasm_bindgen::JsCast;\nuse web_sys::{window, HtmlCanvasElement, WebGlRenderingContext as GL, WebGlRenderingContext};\nuse yew::{html, Component, Context, Html, NodeRef};\n\n// Wrap gl in Rc (Arc for multi-threaded) so it can be injected into the render-loop closure.\npub struct App {\n    node_ref: NodeRef,\n}\n\nimpl Component for App {\n    type Message = ();\n    type Properties = ();\n\n    fn create(_ctx: &Context<Self>) -> Self {\n        Self {\n            node_ref: NodeRef::default(),\n        }\n    }\n\n    fn view(&self, _ctx: &Context<Self>) -> Html {\n        html! {\n            <canvas ref={self.node_ref.clone()} />\n        }\n    }\n\n    fn rendered(&mut self, _ctx: &Context<Self>, first_render: bool) {\n        // Only start the render loop if it's the first render\n        // There's no loop cancellation taking place, so if multiple renders happen,\n        // there would be multiple loops running. That doesn't *really* matter here because\n        // there's no props update and no SSR is taking place, but it is something to keep in\n        // consideration\n        if !first_render {\n            return;\n        }\n        // Once rendered, store references for the canvas and GL context. These can be used for\n        // resizing the rendering area when the window or canvas element are resized, as well as\n        // for making GL calls.\n        let canvas = self.node_ref.cast::<HtmlCanvasElement>().unwrap();\n        let gl: GL = canvas\n            .get_context(\"webgl\")\n            .unwrap()\n            .unwrap()\n            .dyn_into()\n            .unwrap();\n        Self::render_gl(gl);\n    }\n}\n\nimpl App {\n    fn request_animation_frame(f: &Closure<dyn FnMut()>) {\n        window()\n            .unwrap()\n            .request_animation_frame(f.as_ref().unchecked_ref())\n            .expect(\"should register `requestAnimationFrame` OK\");\n    }\n\n    fn render_gl(gl: WebGlRenderingContext) {\n        // This should log only once -- not once per frame\n\n        let mut timestamp = 0.0;\n\n        let vert_code = include_str!(\"./basic.vert\");\n        let frag_code = include_str!(\"./basic.frag\");\n\n        // This list of vertices will draw two triangles to cover the entire canvas.\n        let vertices: Vec<f32> = vec![\n            -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, 1.0,\n        ];\n        let vertex_buffer = gl.create_buffer().unwrap();\n        let verts = js_sys::Float32Array::from(vertices.as_slice());\n\n        gl.bind_buffer(GL::ARRAY_BUFFER, Some(&vertex_buffer));\n        gl.buffer_data_with_array_buffer_view(GL::ARRAY_BUFFER, &verts, GL::STATIC_DRAW);\n\n        let vert_shader = gl.create_shader(GL::VERTEX_SHADER).unwrap();\n        gl.shader_source(&vert_shader, vert_code);\n        gl.compile_shader(&vert_shader);\n\n        let frag_shader = gl.create_shader(GL::FRAGMENT_SHADER).unwrap();\n        gl.shader_source(&frag_shader, frag_code);\n        gl.compile_shader(&frag_shader);\n\n        let shader_program = gl.create_program().unwrap();\n        gl.attach_shader(&shader_program, &vert_shader);\n        gl.attach_shader(&shader_program, &frag_shader);\n        gl.link_program(&shader_program);\n\n        gl.use_program(Some(&shader_program));\n\n        // Attach the position vector as an attribute for the GL context.\n        let position = gl.get_attrib_location(&shader_program, \"a_position\") as u32;\n        gl.vertex_attrib_pointer_with_i32(position, 2, GL::FLOAT, false, 0, 0);\n        gl.enable_vertex_attrib_array(position);\n\n        // Attach the time as a uniform for the GL context.\n        let time = gl.get_uniform_location(&shader_program, \"u_time\");\n        gl.uniform1f(time.as_ref(), timestamp as f32);\n\n        gl.draw_arrays(GL::TRIANGLES, 0, 6);\n\n        // Gloo-render's request_animation_frame has this extra closure\n        // wrapping logic running every frame, unnecessary cost.\n        // Here constructing the wrapped closure just once.\n\n        let cb = Rc::new(RefCell::new(None));\n\n        *cb.borrow_mut() = Some(Closure::wrap(Box::new({\n            let cb = cb.clone();\n            move || {\n                // This should repeat every frame\n                timestamp += 20.0;\n                gl.uniform1f(time.as_ref(), timestamp as f32);\n                gl.draw_arrays(GL::TRIANGLES, 0, 6);\n                App::request_animation_frame(cb.borrow().as_ref().unwrap());\n            }\n        }) as Box<dyn FnMut()>));\n\n        App::request_animation_frame(cb.borrow().as_ref().unwrap());\n    }\n}\n\nfn main() {\n    yew::Renderer::<App>::new().render();\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "752f1620b6a470b31cedd470bce85190eb29bec6",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/yew/examples/function_router/src/pages/mod.rs",
    "func": "pub mod author;\npub mod author_list;\npub mod home;\npub mod page_not_found;\npub mod post;\npub mod post_list;\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "0257e3076c0c08e25eac57f0bf657344caab2812",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/yew/examples/function_memory_game/src/helper.rs",
    "func": "use nanoid::nanoid;\nuse rand::seq::SliceRandom;\nuse rand::thread_rng;\n\nuse crate::constant::RAW_CARDS;\nuse crate::state::Card;\n\npub fn shuffle_cards() -> Vec<Card> {\n    let mut raw_cards = RAW_CARDS;\n\n    raw_cards.shuffle(&mut thread_rng());\n\n    raw_cards\n        .iter()\n        .map(|&p| Card {\n            id: nanoid!(),\n            flipped: false,\n            name: p,\n        })\n        .collect()\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "4b1c5ab983c88c169908eb605ecf888126435c27",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/yew/examples/wasi_ssr_module/src/main.rs",
    "func": "#![allow(unused_imports)]\n#![allow(non_snake_case)]\n\nmod router;\n\nuse anyhow::Result;\nuse router::{switch, Route};\nuse yew::prelude::*;\nuse yew::LocalServerRenderer;\n\n#[function_component]\nfn Content() -> Html {\n    use yew_router::prelude::*;\n\n    html! {\n        <>\n            <h1>{\"Yew WASI SSR demo\"}</h1>\n            <Switch<Route> render={switch} />\n        </>\n    }\n}\n\n#[function_component]\nfn App() -> Html {\n    use yew_router::history::{AnyHistory, History, MemoryHistory};\n    use yew_router::prelude::*;\n\n    let history = AnyHistory::from(MemoryHistory::new());\n    history.push(\"/\");\n\n    html! {\n        <div>\n            <Router history={history}>\n                <Content />\n            </Router>\n        </div>\n    }\n}\n\npub async fn render() -> Result<String> {\n    let renderer = LocalServerRenderer::<App>::new();\n    let html_raw = renderer.render().await;\n\n    let mut body = String::new();\n    body.push_str(\"<body>\");\n    body.push_str(\"<div id='app' style='width: 100vw; height: 100vh; position: fixed;'>\");\n    body.push_str(&html_raw);\n    body.push_str(\"</div>\");\n    body.push_str(\"</body>\");\n\n    Ok(body)\n}\n\n#[tokio::main(flavor = \"current_thread\")]\nasync fn main() -> Result<()> {\n    let ret = render().await?;\n    println!(\"{}\", ret);\n\n    Ok(())\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "ce9927beb9b62f6c99d26dcdb88972c09dd2a96d",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/yew/examples/node_refs/src/main.rs",
    "func": "mod input;\n\nuse input::InputComponent;\nuse web_sys::HtmlInputElement;\nuse yew::prelude::*;\n\npub enum Msg {\n    HoverIndex(usize),\n    Submit,\n}\n\npub struct App {\n    refs: Vec<NodeRef>,\n    focus_index: usize,\n    email_error: String,\n    password_error: String,\n}\nimpl App {\n    fn apply_focus(&self) {\n        if let Some(input) = self.refs[self.focus_index].cast::<HtmlInputElement>() {\n            input.focus().unwrap();\n        }\n    }\n}\nimpl Component for App {\n    type Message = Msg;\n    type Properties = ();\n\n    fn create(_ctx: &Context<Self>) -> Self {\n        Self {\n            focus_index: 0,\n            refs: vec![NodeRef::default(), NodeRef::default()],\n            email_error: \"\".to_string(),\n            password_error: \"\".to_string(),\n        }\n    }\n\n    fn rendered(&mut self, _ctx: &Context<Self>, first_render: bool) {\n        if first_render {\n            self.apply_focus();\n        }\n    }\n\n    fn update(&mut self, _ctx: &Context<Self>, msg: Self::Message) -> bool {\n        match msg {\n            Msg::HoverIndex(index) => {\n                self.focus_index = index;\n                self.apply_focus();\n                false\n            }\n            Msg::Submit => {\n                let email = &self.refs[0];\n                let password = &self.refs[1];\n                let email_value = email.cast::<HtmlInputElement>().unwrap().value();\n                let password_value = password.cast::<HtmlInputElement>().unwrap().value();\n\n                self.email_error.clear();\n                self.password_error.clear();\n\n                if !(email_value.contains('@') && email_value.contains('.')) {\n                    self.email_error.push_str(\"Invalid email.\")\n                }\n                if password_value.len() < 8 {\n                    self.password_error\n                        .push_str(\"Password must be at least 8 characters long.\")\n                }\n                true\n            }\n        }\n    }\n\n    fn view(&self, ctx: &Context<Self>) -> Html {\n        html! {\n            <div class=\"main\">\n                <div id=\"left-pane\">\n                    <div>\n                        <h1>{\"Create your account\"}</h1>\n                        <div class=\"input-container\">\n                            <label>{ \"Email\" }</label>\n                            <input\n                                type=\"text\"\n                                ref={&self.refs[0]}\n                                class=\"input-element\"\n                                onmouseover={ctx.link().callback(|_| Msg::HoverIndex(0))}\n                                placeholder=\"abcd@xyz.com\"\n                            />\n                            <div class=\"error\">{self.email_error.clone()}</div>\n                        </div>\n                        <div class=\"input-container\">\n                            <label>{ \"Password\" }</label>\n                            <InputComponent\n                                input_ref={&self.refs[1]}\n                                on_hover={ctx.link().callback(|_| Msg::HoverIndex(1))}\n                                placeholder=\"password\"\n                            />\n                            <div class=\"error\">{self.password_error.clone()}</div>\n                        </div>\n                        <button onclick={ctx.link().callback(|_| Msg::Submit)}>{\"Create\"}</button>\n                    </div>\n                </div>\n                <div id=\"right-pane\">\n                    <div>\n                        <div id=\"graphic\"></div>\n                        <h1>{ \"Node Refs Example\" }</h1>\n                        <p>{ \"Refs can be used to access and manipulate DOM elements directly\" }</p>\n                        <ul>\n                            <li>{ \"First input will focus on mount\" }</li>\n                            <li>{ \"Each input will focus on hover\" }</li>\n                        </ul>\n                    </div>\n                </div>\n            </div>\n        }\n    }\n}\n\nfn main() {\n    yew::Renderer::<App>::new().render();\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "594793af5421a70248e9111006f2a0bdeadb53f6",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/starship/build.rs",
    "func": "use std::fs::{self, File};\nuse std::io;\nuse std::io::Write;\n\nuse shadow_rs::SdResult;\n\nfn main() -> SdResult<()> {\n    shadow_rs::new_hook(gen_presets_hook)?;\n\n    #[cfg(windows)]\n    {\n        let mut res = winres::WindowsResource::new();\n        res.set_manifest_file(\"starship.exe.manifest\")\n            .set_icon(\"media/icon.ico\");\n        res.compile()?;\n    }\n\n    Ok(())\n}\n\nfn gen_presets_hook(mut file: &File) -> SdResult<()> {\n    println!(\"cargo:rerun-if-changed=docs/public/presets/toml\");\n    let paths = fs::read_dir(\"docs/public/presets/toml\")?;\n    let mut sortedpaths = paths.collect::<io::Result<Vec<_>>>()?;\n    sortedpaths.sort_by_key(std::fs::DirEntry::path);\n\n    let mut presets = String::new();\n    let mut match_arms = String::new();\n    for unwrapped in sortedpaths {\n        let file_name = unwrapped.file_name();\n        let full_path = dunce::canonicalize(unwrapped.path())?;\n        let full_path = full_path.to_str().expect(\"failed to convert to string\");\n        let name = file_name\n            .to_str()\n            .and_then(|v| v.strip_suffix(\".toml\"))\n            .expect(\"Failed to process filename\");\n        presets.push_str(format!(\"print::Preset(\\\"{name}\\\"),\\n\").as_str());\n        match_arms.push_str(format!(r#\"\"{name}\" => include_bytes!(r\"{full_path}\"),\"#).as_str());\n    }\n\n    writeln!(\n        file,\n        r#\"\nuse crate::print;\n\npub fn get_preset_list<'a>() -> &'a [print::Preset] {{\n    &[\n        {presets}\n    ]\n}}\n\npub fn get_preset_content(name: &str) -> &[u8] {{\n    match name {{\n    {match_arms}\n    _ => unreachable!(),\n    }}\n}}\n\"#\n    )?;\n    Ok(())\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "d72511f34686c3865989678575ac8d05ba781580",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/starship/src/logger.rs",
    "func": "use crate::utils;\nuse log::{Level, LevelFilter, Metadata, Record};\nuse nu_ansi_term::Color;\nuse std::sync::OnceLock;\nuse std::{\n    cmp,\n    collections::HashSet,\n    env,\n    fs::{self, File, OpenOptions},\n    io::Write,\n    path::{Path, PathBuf},\n    sync::{Mutex, RwLock},\n};\n\npub struct StarshipLogger {\n    log_file: OnceLock<Result<Mutex<File>, std::io::Error>>,\n    log_file_path: PathBuf,\n    log_file_content: RwLock<HashSet<String>>,\n    log_level: Level,\n}\n\n/// Returns the path to the log directory.\npub fn get_log_dir() -> PathBuf {\n    env::var_os(\"STARSHIP_CACHE\")\n        .map(PathBuf::from)\n        .unwrap_or_else(|| {\n            utils::home_dir()\n                .map(|home| home.join(\".cache\"))\n                .or_else(dirs::cache_dir)\n                .unwrap_or_else(std::env::temp_dir)\n                .join(\"starship\")\n        })\n}\n\n/// Deletes all log files in the log directory that were modified more than 24 hours ago.\npub fn cleanup_log_files<P: AsRef<Path>>(path: P) {\n    let log_dir = path.as_ref();\n    let Ok(log_files) = fs::read_dir(log_dir) else {\n        // Avoid noisily handling errors in this cleanup function.\n        return;\n    };\n\n    for file in log_files {\n        // Skip files that can't be read.\n        let Ok(file) = file else {\n            continue;\n        };\n\n        // Avoid deleting files that don't look like log files.\n        if !file\n            .path()\n            .file_name()\n            .unwrap_or_default()\n            .to_str()\n            .unwrap_or_default()\n            .starts_with(\"session_\")\n            || file.path().extension() != Some(\"log\".as_ref())\n        {\n            continue;\n        }\n\n        // Read metadata to check file age.\n        let Ok(metadata) = file.metadata() else {\n            continue;\n        };\n\n        // Avoid handling anything that isn't a file.\n        if !metadata.is_file() {\n            continue;\n        }\n\n        // Get the file's modification time.\n        let Ok(modified) = metadata.modified() else {\n            continue;\n        };\n\n        // Delete the file if it hasn't changed in 24 hours.\n        if modified.elapsed().unwrap_or_default().as_secs() > 60 * 60 * 24 {\n            let _ = fs::remove_file(file.path());\n        }\n    }\n}\n\nimpl Default for StarshipLogger {\n    fn default() -> Self {\n        let log_dir = get_log_dir();\n\n        if let Err(err) = fs::create_dir_all(&log_dir) {\n            eprintln!(\"Unable to create log dir {log_dir:?}: {err:?}!\")\n        };\n        let session_log_file = log_dir.join(format!(\n            \"session_{}.log\",\n            env::var(\"STARSHIP_SESSION_KEY\").unwrap_or_default()\n        ));\n\n        Self {\n            log_file_content: RwLock::new(\n                fs::read_to_string(&session_log_file)\n                    .unwrap_or_default()\n                    .lines()\n                    .map(std::string::ToString::to_string)\n                    .collect(),\n            ),\n            log_file: OnceLock::new(),\n            log_file_path: session_log_file,\n            log_level: env::var(\"STARSHIP_LOG\")\n                .map(|level| match level.to_ascii_lowercase().as_str() {\n                    \"trace\" => Level::Trace,\n                    \"debug\" => Level::Debug,\n                    \"info\" => Level::Info,\n                    \"warn\" => Level::Warn,\n                    \"error\" => Level::Error,\n                    _ => Level::Warn,\n                })\n                .unwrap_or_else(|_| Level::Warn),\n        }\n    }\n}\n\nimpl StarshipLogger {\n    /// Override the minimum log level\n    pub fn set_log_level(&mut self, level: log::Level) {\n        self.log_level = level;\n    }\n\n    /// Override the log level path\n    /// This won't change anything if a log file was already opened\n    pub fn set_log_file_path(&mut self, path: PathBuf) {\n        let contents = fs::read_to_string(&path)\n            .unwrap_or_default()\n            .lines()\n            .map(std::string::ToString::to_string)\n            .collect();\n        self.log_file_content = RwLock::new(contents);\n        self.log_file_path = path;\n    }\n}\n\nimpl log::Log for StarshipLogger {\n    fn enabled(&self, metadata: &Metadata) -> bool {\n        metadata.level() <= self.log_level\n    }\n\n    fn log(&self, record: &Record) {\n        // Early return if the log level is not enabled\n        if !self.enabled(record.metadata()) {\n            return;\n        }\n\n        let to_print = format!(\n            \"[{}] - ({}): {}\",\n            record.level(),\n            record.module_path().unwrap_or_default(),\n            record.args()\n        );\n\n        // A log message is only printed or written to the log file,\n        // if it's not already in the log file or has been printed in this session.\n        // To help with debugging, duplicate detection only runs if the log level is warn or lower\n        let is_debug = record.level() > Level::Warn;\n        let is_duplicate = {\n            !is_debug\n                && self\n                    .log_file_content\n                    .read()\n                    .map(|c| c.contains(to_print.as_str()))\n                    .unwrap_or(false)\n        };\n\n        if is_duplicate {\n            return;\n        }\n\n        // Write warning messages to the log file\n        // If log level is error, only write error messages to the log file\n        if record.level() <= cmp::min(Level::Warn, self.log_level) {\n            let log_file = match self.log_file.get_or_init(|| {\n                OpenOptions::new()\n                    .create(true)\n                    .append(true)\n                    .open(&self.log_file_path)\n                    .map(Mutex::new)\n            }) {\n                Ok(log_file) => log_file,\n                Err(err) => {\n                    eprintln!(\n                        \"Unable to open session log file {:?}: {err:?}!\",\n                        self.log_file_path\n                    );\n                    return;\n                }\n            };\n\n            let mut file_handle = match log_file.lock() {\n                Ok(file_handle) => file_handle,\n                Err(err) => {\n                    eprintln!(\"Log file writer mutex was poisoned! {err:?}\",);\n                    return;\n                }\n            };\n            if let Err(err) = writeln!(file_handle, \"{to_print}\") {\n                eprintln!(\"Unable to write to session log file {err:?}!\",);\n            };\n        }\n\n        // Print messages to stderr\n        eprintln!(\n            \"[{}] - ({}): {}\",\n            match record.level() {\n                Level::Trace => Color::Blue.dimmed().paint(format!(\"{}\", record.level())),\n                Level::Debug => Color::Cyan.paint(format!(\"{}\", record.level())),\n                Level::Info => Color::White.paint(format!(\"{}\", record.level())),\n                Level::Warn => Color::Yellow.paint(format!(\"{}\", record.level())),\n                Level::Error => Color::Red.paint(format!(\"{}\", record.level())),\n            },\n            record.module_path().unwrap_or_default(),\n            record.args()\n        );\n\n        // Add to duplicate detection set\n        if let Ok(mut c) = self.log_file_content.write() {\n            c.insert(to_print);\n        }\n    }\n\n    fn flush(&self) {\n        if let Some(Ok(m)) = self.log_file.get() {\n            let result = match m.lock() {\n                Ok(mut file) => file.flush(),\n                Err(err) => return eprintln!(\"Log file writer mutex was poisoned: {err:?}\"),\n            };\n            if let Err(err) = result {\n                eprintln!(\"Unable to flush the log file: {err:?}\");\n            }\n        }\n    }\n}\n\npub fn init() {\n    log::set_boxed_logger(Box::<StarshipLogger>::default()).unwrap();\n    log::set_max_level(LevelFilter::Trace);\n}\n\n#[cfg(test)]\nmod test {\n    use super::*;\n    use crate::utils::read_file;\n    use log::Log;\n    use std::fs::{File, FileTimes};\n    use std::io;\n    use std::time::SystemTime;\n\n    #[test]\n    fn test_log_to_file() -> io::Result<()> {\n        let log_dir = tempfile::tempdir()?;\n        let log_file = log_dir.path().join(\"test.log\");\n\n        let mut logger = StarshipLogger::default();\n        logger.set_log_file_path(log_file.clone());\n        logger.set_log_level(Level::Warn);\n\n        // Load at all log levels\n        logger.log(\n            &Record::builder()\n                .level(Level::Error)\n                .args(format_args!(\"error\"))\n                .build(),\n        );\n        logger.log(\n            &Record::builder()\n                .level(Level::Warn)\n                .args(format_args!(\"warn\"))\n                .build(),\n        );\n        logger.log(\n            &Record::builder()\n                .level(Level::Info)\n                .args(format_args!(\"info\"))\n                .build(),\n        );\n        logger.log(\n            &Record::builder()\n                .level(Level::Debug)\n                .args(format_args!(\"debug\"))\n                .build(),\n        );\n        logger.log(\n            &Record::builder()\n                .level(Level::Trace)\n                .args(format_args!(\"trace\"))\n                .build(),\n        );\n\n        // Print duplicate messages\n        logger.log(\n            &Record::builder()\n                .level(Level::Warn)\n                .args(format_args!(\"warn\"))\n                .build(),\n        );\n        logger.log(\n            &Record::builder()\n                .level(Level::Error)\n                .args(format_args!(\"error\"))\n                .build(),\n        );\n\n        logger.flush();\n        drop(logger);\n\n        let content = read_file(log_file)?;\n\n        assert_eq!(content, \"[ERROR] - (): error\\n[WARN] - (): warn\\n\");\n\n        log_dir.close()\n    }\n\n    #[test]\n    fn test_dedup_from_file() -> io::Result<()> {\n        let log_dir = tempfile::tempdir()?;\n        let log_file = log_dir.path().join(\"test.log\");\n        {\n            let mut file = File::create(&log_file)?;\n            file.write_all(b\"[WARN] - (): warn\\n\")?;\n            file.sync_all()?;\n        }\n\n        let mut logger = StarshipLogger::default();\n        logger.set_log_file_path(log_file.clone());\n        logger.set_log_level(Level::Warn);\n\n        // This message should not be printed or written to the log file\n        logger.log(\n            &Record::builder()\n                .level(Level::Warn)\n                .args(format_args!(\"warn\"))\n                .build(),\n        );\n        // This message should be printed and written to the log file\n        logger.log(\n            &Record::builder()\n                .level(Level::Warn)\n                .args(format_args!(\"warn2\"))\n                .build(),\n        );\n\n        logger.flush();\n        drop(logger);\n\n        let content = read_file(log_file)?;\n\n        assert_eq!(content, \"[WARN] - (): warn\\n[WARN] - (): warn2\\n\");\n\n        log_dir.close()\n    }\n\n    #[test]\n    fn test_cleanup() -> io::Result<()> {\n        let log_dir = tempfile::tempdir()?;\n\n        // Should not be deleted\n        let non_matching_file = log_dir.path().join(\"non-matching.log\");\n        let non_matching_file2 = log_dir.path().join(\"session_.exe\");\n        let new_file = log_dir.path().join(\"session_new.log\");\n        let directory = log_dir.path().join(\"session_dir.log\");\n\n        // Should be deleted\n        let old_file = log_dir.path().join(\"session_old.log\");\n\n        for file in &[\n            &non_matching_file,\n            &non_matching_file2,\n            &new_file,\n            &old_file,\n        ] {\n            File::create(file)?;\n        }\n        fs::create_dir(&directory)?;\n\n        let times = FileTimes::new()\n            .set_accessed(SystemTime::UNIX_EPOCH)\n            .set_modified(SystemTime::UNIX_EPOCH);\n\n        // Set all files except the new file to be older than 24 hours\n        for file in &[\n            &non_matching_file,\n            &non_matching_file2,\n            &old_file,\n            &directory,\n        ] {\n            let Ok(f) = File::open(file) else {\n                panic!(\"Unable to open file {file:?}!\")\n            };\n\n            match f.set_times(times) {\n                Err(err) if err.kind() == io::ErrorKind::PermissionDenied => {\n                    // Ignore permission errors (e.g. on Windows)\n                    eprintln!(\"Unable to set file times for {file:?}: {err:?}\");\n                    return Ok(());\n                }\n                other => other,\n            }?;\n            f.sync_all()?;\n        }\n\n        cleanup_log_files(log_dir.path());\n\n        for file in &[\n            &non_matching_file,\n            &non_matching_file2,\n            &new_file,\n            &directory,\n        ] {\n            assert!(file.exists(), \"File {file:?} should exist\");\n        }\n\n        assert!(!old_file.exists(), \"File {old_file:?} should not exist\");\n\n        log_dir.close()\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "82522f8400add3b134b3f5184cc68e240dd12a0a",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/starship/src/formatter/parser.rs",
    "func": "// Can't rename internal Pest names\n#![allow(clippy::upper_case_acronyms)]\n\nuse pest::{error::Error, iterators::Pair, Parser};\nuse pest_derive::*;\n\nuse super::model::*;\n\n#[derive(Parser)]\n#[grammar = \"formatter/spec.pest\"]\nstruct IdentParser;\n\nfn parse_value(value: Pair<Rule>) -> FormatElement {\n    match value.as_rule() {\n        Rule::text => FormatElement::Text(parse_text(value).into()),\n        Rule::variable => FormatElement::Variable(parse_variable(value).into()),\n        Rule::textgroup => FormatElement::TextGroup(parse_textgroup(value)),\n        Rule::conditional => {\n            FormatElement::Conditional(parse_format(value.into_inner().next().unwrap()))\n        }\n        _ => unreachable!(),\n    }\n}\n\nfn parse_textgroup(textgroup: Pair<Rule>) -> TextGroup {\n    let mut inner_rules = textgroup.into_inner();\n    let format = inner_rules.next().unwrap();\n    let style = inner_rules.next().unwrap();\n\n    TextGroup {\n        format: parse_format(format),\n        style: parse_style(style),\n    }\n}\n\nfn parse_variable(variable: Pair<Rule>) -> &str {\n    variable.into_inner().next().unwrap().as_str()\n}\n\nfn parse_text(text: Pair<Rule>) -> String {\n    text.into_inner()\n        .flat_map(|pair| pair.as_str().chars())\n        .collect()\n}\n\nfn parse_format(format: Pair<Rule>) -> Vec<FormatElement> {\n    format.into_inner().map(parse_value).collect()\n}\n\nfn parse_style(style: Pair<Rule>) -> Vec<StyleElement> {\n    style\n        .into_inner()\n        .map(|pair| match pair.as_rule() {\n            Rule::string => StyleElement::Text(pair.as_str().into()),\n            Rule::variable => StyleElement::Variable(parse_variable(pair).into()),\n            _ => unreachable!(),\n        })\n        .collect()\n}\n\npub fn parse(format: &str) -> Result<Vec<FormatElement>, Box<Error<Rule>>> {\n    IdentParser::parse(Rule::expression, format)\n        .map(|pairs| {\n            pairs\n                .take_while(|pair| pair.as_rule() != Rule::EOI)\n                .map(parse_value)\n                .collect()\n        })\n        .map_err(Box::new)\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "a6e619d408e6e8e611e8d9b8207073a6a62441e9",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/starship/src/modules/container.rs",
    "func": "use super::{Context, Module};\n\n#[cfg(not(target_os = \"linux\"))]\npub fn module<'a>(_context: &'a Context) -> Option<Module<'a>> {\n    None\n}\n\n#[cfg(target_os = \"linux\")]\npub fn module<'a>(context: &'a Context) -> Option<Module<'a>> {\n    use super::ModuleConfig;\n    use crate::configs::container::ContainerConfig;\n    use crate::formatter::StringFormatter;\n    use crate::utils::{self, read_file};\n\n    pub fn container_name(context: &Context) -> Option<String> {\n        use crate::utils::context_path;\n\n        if context_path(context, \"/proc/vz\").exists() && !context_path(context, \"/proc/bc\").exists()\n        {\n            // OpenVZ\n            return Some(\"OpenVZ\".into());\n        }\n\n        if context_path(context, \"/run/host/container-manager\").exists() {\n            // OCI\n            return Some(\"OCI\".into());\n        }\n\n        let container_env_path = context_path(context, \"/run/.containerenv\");\n\n        if container_env_path.exists() {\n            // podman and others\n\n            let image_res = read_file(container_env_path)\n                .map(|s| {\n                    s.lines()\n                        .find_map(|l| {\n                            if let Some(name_val) = l.strip_prefix(\"name=\\\"\") {\n                                return name_val.strip_suffix('\"').map(|n| n.to_string());\n                            }\n\n                            l.starts_with(\"image=\\\"\").then(|| {\n                                let r = l.split_at(7).1;\n                                let name = r.rfind('/').map(|n| r.split_at(n + 1).1);\n                                String::from(name.unwrap_or(r).trim_end_matches('\"'))\n                            })\n                        })\n                        .unwrap_or_else(|| \"podman\".into())\n                })\n                .unwrap_or_else(|_| \"podman\".into());\n\n            return Some(image_res);\n        }\n\n        // WSL with systemd will set the contents of this file to \"wsl\"\n        // Avoid showing the container module in that case\n        // Honor the contents of this file if \"docker\" and not running in podman or wsl\n        let systemd_path = context_path(context, \"/run/systemd/container\");\n        if let Ok(s) = utils::read_file(systemd_path) {\n            match s.trim() {\n                \"docker\" => return Some(\"Docker\".into()),\n                \"wsl\" => (),\n                _ => return Some(\"Systemd\".into()),\n            }\n        }\n\n        if context_path(context, \"/.dockerenv\").exists() {\n            // docker\n            return Some(\"Docker\".into());\n        }\n\n        None\n    }\n\n    let mut module = context.new_module(\"container\");\n    let config: ContainerConfig = ContainerConfig::try_load(module.config);\n\n    if config.disabled {\n        return None;\n    }\n\n    let container_name = container_name(context)?;\n\n    let parsed = StringFormatter::new(config.format).and_then(|formatter| {\n        formatter\n            .map_meta(|variable, _| match variable {\n                \"symbol\" => Some(config.symbol),\n                _ => None,\n            })\n            .map_style(|variable| match variable {\n                \"style\" => Some(Ok(config.style)),\n                _ => None,\n            })\n            .map(|variable| match variable {\n                \"name\" => Some(Ok(&container_name)),\n                _ => None,\n            })\n            .parse(None, Some(context))\n    });\n\n    module.set_segments(match parsed {\n        Ok(segments) => segments,\n        Err(error) => {\n            log::warn!(\"Error in module `container`: \\n{}\", error);\n            return None;\n        }\n    });\n\n    Some(module)\n}\n\n#[cfg(test)]\nmod tests {\n    use crate::test::ModuleRenderer;\n    use crate::utils;\n    use nu_ansi_term::Color;\n    use std::fs;\n\n    #[test]\n    fn test_none_if_disabled() {\n        let expected = None;\n        let actual = ModuleRenderer::new(\"container\")\n            // For a custom config\n            .config(toml::toml! {\n               [container]\n               disabled = true\n            })\n            // Run the module and collect the output\n            .collect();\n\n        assert_eq!(expected, actual);\n    }\n\n    fn containerenv(\n        image: Option<&str>,\n        name: Option<&str>,\n    ) -> std::io::Result<(Option<String>, Option<String>)> {\n        let renderer = ModuleRenderer::new(\"container\")\n            // For a custom config\n            .config(toml::toml! {\n               [container]\n               disabled = false\n            });\n\n        let root_path = renderer.root_path();\n\n        // simulate file found on ubuntu images to ensure podman containerenv is preferred\n        let systemd_path = root_path.join(\"run/systemd/container\");\n\n        fs::create_dir_all(systemd_path.parent().unwrap())?;\n        utils::write_file(&systemd_path, \"docker\\n\")?;\n\n        let containerenv = root_path.join(\"run/.containerenv\");\n\n        fs::create_dir_all(containerenv.parent().unwrap())?;\n\n        let contents = name.map(|n| format!(\"name=\\\"{n}\\\"\\n\")).unwrap_or_default()\n            + &image\n                .map(|i| format!(\"image=\\\"{i}\\\"\\n\"))\n                .unwrap_or_default();\n        utils::write_file(&containerenv, contents)?;\n\n        // The output of the module\n        let actual = renderer\n            // Run the module and collect the output\n            .collect();\n\n        // The value that should be rendered by the module.\n        let expected = Some(format!(\n            \"{} \",\n            Color::Red\n                .bold()\n                .dimmed()\n                .paint(format!(\"\u2b22 [{}]\", name.unwrap_or(image.unwrap_or(\"podman\"))))\n        ));\n\n        Ok((actual, expected))\n    }\n\n    #[test]\n    #[cfg(target_os = \"linux\")]\n    fn test_containerenv() -> std::io::Result<()> {\n        let (actual, expected) = containerenv(None, None)?;\n\n        // Assert that the actual and expected values are the same\n        assert_eq!(actual, expected);\n\n        Ok(())\n    }\n\n    #[test]\n    #[cfg(target_os = \"linux\")]\n    fn test_containerenv_fedora() -> std::io::Result<()> {\n        let (actual, expected) = containerenv(Some(\"fedora-toolbox:35\"), None)?;\n\n        // Assert that the actual and expected values are the same\n        assert_eq!(actual, expected);\n\n        Ok(())\n    }\n\n    #[test]\n    #[cfg(target_os = \"linux\")]\n    fn test_containerenv_fedora_with_name() -> std::io::Result<()> {\n        let (actual, expected) = containerenv(Some(\"fedora-toolbox:35\"), Some(\"my-fedora\"))?;\n\n        // Assert that the actual and expected values are the same\n        assert_eq!(actual, expected);\n\n        Ok(())\n    }\n\n    #[cfg(target_os = \"linux\")]\n    fn containerenv_systemd(\n        name: Option<&str>,\n        display: Option<&str>,\n    ) -> std::io::Result<(Option<String>, Option<String>)> {\n        let renderer = ModuleRenderer::new(\"container\")\n            // For a custom config\n            .config(toml::toml! {\n               [container]\n               disabled = false\n            });\n\n        let root_path = renderer.root_path();\n\n        let systemd_path = root_path.join(\"run/systemd/container\");\n\n        fs::create_dir_all(systemd_path.parent().unwrap())?;\n\n        let contents = match name {\n            Some(name) => format!(\"{name}\\n\"),\n            None => \"systemd-nspawn\\n\".to_string(),\n        };\n        utils::write_file(&systemd_path, contents)?;\n\n        // The output of the module\n        let actual = renderer\n            // Run the module and collect the output\n            .collect();\n\n        // The value that should be rendered by the module.\n        let expected = display.map(|_| {\n            format!(\n                \"{} \",\n                Color::Red\n                    .bold()\n                    .dimmed()\n                    .paint(format!(\"\u2b22 [{}]\", display.unwrap_or(\"Systemd\")))\n            )\n        });\n\n        Ok((actual, expected))\n    }\n\n    #[test]\n    #[cfg(target_os = \"linux\")]\n    fn test_containerenv_systemd() -> std::io::Result<()> {\n        let (actual, expected) = containerenv_systemd(None, Some(\"Systemd\"))?;\n\n        // Assert that the actual and expected values are the same\n        assert_eq!(actual, expected);\n\n        Ok(())\n    }\n\n    #[test]\n    #[cfg(target_os = \"linux\")]\n    fn test_containerenv_docker_in_systemd() -> std::io::Result<()> {\n        let (actual, expected) = containerenv_systemd(Some(\"docker\"), Some(\"Docker\"))?;\n\n        // Assert that the actual and expected values are the same\n        assert_eq!(actual, expected);\n\n        Ok(())\n    }\n\n    #[test]\n    #[cfg(target_os = \"linux\")]\n    fn test_containerenv_wsl_in_systemd() -> std::io::Result<()> {\n        let (actual, expected) = containerenv_systemd(Some(\"wsl\"), None)?;\n\n        // Assert that the actual and expected values are the same\n        assert_eq!(actual, expected);\n\n        Ok(())\n    }\n\n    #[test]\n    #[cfg(not(target_os = \"linux\"))]\n    fn test_containerenv() -> std::io::Result<()> {\n        let (actual, expected) = containerenv(None, None)?;\n\n        // Assert that the actual and expected values are not the same\n        assert_ne!(actual, expected);\n\n        Ok(())\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "bb5220a7c8bba37885a1fab21ecf8797ecc581b6",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/starship/src/modules/azure.rs",
    "func": "use serde::{Deserialize, Serialize};\nuse std::fs;\nuse std::path::PathBuf;\n\nuse super::{Context, Module, ModuleConfig};\n\nuse crate::configs::azure::AzureConfig;\nuse crate::formatter::StringFormatter;\n\n#[derive(Serialize, Deserialize, Clone)]\n#[serde(rename_all = \"camelCase\")]\nstruct AzureProfile {\n    installation_id: String,\n    #[serde(default, skip_serializing_if = \"Vec::is_empty\")]\n    subscriptions: Vec<Subscription>,\n}\n\n#[derive(Serialize, Deserialize, Clone)]\nstruct User {\n    name: String,\n}\n\n#[derive(Serialize, Deserialize, Clone)]\n#[serde(rename_all = \"camelCase\")]\nstruct Subscription {\n    name: String,\n    user: User,\n    is_default: bool,\n}\n\npub fn module<'a>(context: &'a Context) -> Option<Module<'a>> {\n    let mut module = context.new_module(\"azure\");\n    let config = AzureConfig::try_load(module.config);\n\n    if config.disabled {\n        return None;\n    };\n\n    let subscription: Option<Subscription> = get_azure_profile_info(context);\n\n    if subscription.is_none() {\n        log::info!(\"Could not find Subscriptions in azureProfile.json\");\n        return None;\n    }\n\n    let subscription = subscription.unwrap();\n\n    let parsed = StringFormatter::new(config.format).and_then(|formatter| {\n        formatter\n            .map_meta(|variable, _| match variable {\n                \"symbol\" => Some(config.symbol),\n                _ => None,\n            })\n            .map_style(|variable| match variable {\n                \"style\" => Some(Ok(config.style)),\n                _ => None,\n            })\n            .map(|variable| match variable {\n                \"subscription\" => Some(Ok(config\n                    .subscription_aliases\n                    .get(&subscription.name)\n                    .copied()\n                    .unwrap_or(&subscription.name))),\n                \"username\" => Some(Ok(&subscription.user.name)),\n                _ => None,\n            })\n            .parse(None, Some(context))\n    });\n\n    module.set_segments(match parsed {\n        Ok(segments) => segments,\n        Err(error) => {\n            log::warn!(\"Error in module `azure`:\\n{}\", error);\n            return None;\n        }\n    });\n\n    Some(module)\n}\n\nfn get_azure_profile_info(context: &Context) -> Option<Subscription> {\n    let mut config_path = get_config_file_location(context)?;\n    config_path.push(\"azureProfile.json\");\n\n    let azure_profile = load_azure_profile(&config_path)?;\n    azure_profile\n        .subscriptions\n        .into_iter()\n        .find(|s| s.is_default)\n}\n\nfn load_azure_profile(config_path: &PathBuf) -> Option<AzureProfile> {\n    let json_data = fs::read_to_string(config_path).ok()?;\n    let sanitized_json_data = json_data.strip_prefix('\\u{feff}').unwrap_or(&json_data);\n    if let Ok(azure_profile) = serde_json::from_str::<AzureProfile>(sanitized_json_data) {\n        Some(azure_profile)\n    } else {\n        log::info!(\"Failed to parse azure profile.\");\n        None\n    }\n}\n\nfn get_config_file_location(context: &Context) -> Option<PathBuf> {\n    context\n        .get_env(\"AZURE_CONFIG_DIR\")\n        .map(PathBuf::from)\n        .or_else(|| {\n            let mut home = context.get_home()?;\n            home.push(\".azure\");\n            Some(home)\n        })\n}\n\n#[cfg(test)]\nmod tests {\n    use crate::modules::azure::load_azure_profile;\n    use crate::test::ModuleRenderer;\n    use ini::Ini;\n    use nu_ansi_term::Color;\n    use std::fs::File;\n    use std::io::{self, Write};\n    use std::path::PathBuf;\n\n    use tempfile::TempDir;\n\n    fn generate_test_config(dir: &TempDir, azure_profile_contents: &str) -> io::Result<()> {\n        save_string_to_file(\n            dir,\n            azure_profile_contents.to_string(),\n            String::from(\"azureProfile.json\"),\n        )?;\n\n        Ok(())\n    }\n    #[test]\n    fn subscription_set_correctly() -> io::Result<()> {\n        let dir = tempfile::tempdir()?;\n\n        let azure_profile_contents = r#\"{\n            \"installationId\": \"3deacd2a-b9db-77e1-aa42-23e2f8dfffc3\",\n            \"subscriptions\": [\n                {\n                \"id\": \"f568c543-d12e-de0b-3d85-69843598b565\",\n                \"name\": \"Subscription 2\",\n                \"state\": \"Enabled\",\n                \"user\": {\n                  \"name\": \"user@domain.com\",\n                  \"type\": \"user\"\n                },\n                \"isDefault\": false,\n                \"tenantId\": \"0e8a15ec-b0f5-d355-7062-8ece54c59aee\",\n                \"environmentName\": \"AzureCloud\",\n                \"homeTenantId\": \"0e8a15ec-b0f5-d355-7062-8ece54c59aee\",\n                \"managedByTenants\": []\n              },\n              {\n                \"id\": \"d4442d26-ea6d-46c4-07cb-4f70b8ae5465\",\n                \"name\": \"Subscription 3\",\n                \"state\": \"Enabled\",\n                \"user\": {\n                  \"name\": \"user@domain.com\",\n                  \"type\": \"user\"\n                },\n                \"isDefault\": false,\n                \"tenantId\": \"a4e1bb4b-5330-2d50-339d-b9674d3a87bc\",\n                \"environmentName\": \"AzureCloud\",\n                \"homeTenantId\": \"a4e1bb4b-5330-2d50-339d-b9674d3a87bc\",\n                \"managedByTenants\": []\n              },\n              {\n                \"id\": \"f3935dc9-92b5-9a93-da7b-42c325d86939\",\n                \"name\": \"Subscription 1\",\n                \"state\": \"Enabled\",\n                \"user\": {\n                  \"name\": \"user@domain.com\",\n                  \"type\": \"user\"\n                },\n                \"isDefault\": true,\n                \"tenantId\": \"f0273a19-7779-e40a-00a1-53b8331b3bb6\",\n                \"environmentName\": \"AzureCloud\",\n                \"homeTenantId\": \"f0273a19-7779-e40a-00a1-53b8331b3bb6\",\n                \"managedByTenants\": []\n              }\n            ]\n          }\n        \"#;\n\n        generate_test_config(&dir, azure_profile_contents)?;\n        let dir_path = &dir.path().to_string_lossy();\n        let actual = ModuleRenderer::new(\"azure\")\n            .config(toml::toml! {\n            [azure]\n            disabled = false\n            })\n            .env(\"AZURE_CONFIG_DIR\", dir_path.as_ref())\n            .collect();\n        let expected = Some(format!(\n            \"on {} \",\n            Color::Blue.bold().paint(\"\udb82\udc05 Subscription 1\")\n        ));\n        assert_eq!(actual, expected);\n        dir.close()\n    }\n\n    #[test]\n    fn user_name_set_correctly() -> io::Result<()> {\n        let dir = tempfile::tempdir()?;\n\n        let azure_profile_contents = r#\"{\n            \"installationId\": \"3deacd2a-b9db-77e1-aa42-23e2f8dfffc3\",\n            \"subscriptions\": [\n                {\n                \"id\": \"f568c543-d12e-de0b-3d85-69843598b565\",\n                \"name\": \"Subscription 2\",\n                \"state\": \"Enabled\",\n                \"user\": {\n                  \"name\": \"user@domain.com\",\n                  \"type\": \"user\"\n                },\n                \"isDefault\": false,\n                \"tenantId\": \"0e8a15ec-b0f5-d355-7062-8ece54c59aee\",\n                \"environmentName\": \"AzureCloud\",\n                \"homeTenantId\": \"0e8a15ec-b0f5-d355-7062-8ece54c59aee\",\n                \"managedByTenants\": []\n              },\n              {\n                \"id\": \"d4442d26-ea6d-46c4-07cb-4f70b8ae5465\",\n                \"name\": \"Subscription 3\",\n                \"state\": \"Enabled\",\n                \"user\": {\n                  \"name\": \"user@domain.com\",\n                  \"type\": \"user\"\n                },\n                \"isDefault\": false,\n                \"tenantId\": \"a4e1bb4b-5330-2d50-339d-b9674d3a87bc\",\n                \"environmentName\": \"AzureCloud\",\n                \"homeTenantId\": \"a4e1bb4b-5330-2d50-339d-b9674d3a87bc\",\n                \"managedByTenants\": []\n              },\n              {\n                \"id\": \"f3935dc9-92b5-9a93-da7b-42c325d86939\",\n                \"name\": \"Subscription 1\",\n                \"state\": \"Enabled\",\n                \"user\": {\n                  \"name\": \"user@domain.com\",\n                  \"type\": \"user\"\n                },\n                \"isDefault\": true,\n                \"tenantId\": \"f0273a19-7779-e40a-00a1-53b8331b3bb6\",\n                \"environmentName\": \"AzureCloud\",\n                \"homeTenantId\": \"f0273a19-7779-e40a-00a1-53b8331b3bb6\",\n                \"managedByTenants\": []\n              }\n            ]\n          }\n        \"#;\n\n        generate_test_config(&dir, azure_profile_contents)?;\n        let dir_path = &dir.path().to_string_lossy();\n        let actual = ModuleRenderer::new(\"azure\")\n            .config(toml::toml! {\n            [azure]\n            format = \"on [$symbol($username)]($style)\"\n            disabled = false\n            })\n            .env(\"AZURE_CONFIG_DIR\", dir_path.as_ref())\n            .collect();\n        let expected = Some(format!(\n            \"on {}\",\n            Color::Blue.bold().paint(\"\udb82\udc05 user@domain.com\")\n        ));\n        assert_eq!(actual, expected);\n        dir.close()\n    }\n\n    #[test]\n    fn subscription_name_empty() -> io::Result<()> {\n        let dir = tempfile::tempdir()?;\n\n        let azure_profile_contents = r#\"{\n            \"installationId\": \"3deacd2a-b9db-77e1-aa42-23e2f8dfffc3\",\n            \"subscriptions\": [\n                {\n                \"id\": \"f568c543-d12e-de0b-3d85-69843598b565\",\n                \"name\": \"Subscription 2\",\n                \"state\": \"Enabled\",\n                \"user\": {\n                  \"name\": \"user@domain.com\",\n                  \"type\": \"user\"\n                },\n                \"isDefault\": false,\n                \"tenantId\": \"0e8a15ec-b0f5-d355-7062-8ece54c59aee\",\n                \"environmentName\": \"AzureCloud\",\n                \"homeTenantId\": \"0e8a15ec-b0f5-d355-7062-8ece54c59aee\",\n                \"managedByTenants\": []\n              },\n              {\n                \"id\": \"d4442d26-ea6d-46c4-07cb-4f70b8ae5465\",\n                \"name\": \"Subscription 3\",\n                \"state\": \"Enabled\",\n                \"user\": {\n                  \"name\": \"user@domain.com\",\n                  \"type\": \"user\"\n                },\n                \"isDefault\": false,\n                \"tenantId\": \"a4e1bb4b-5330-2d50-339d-b9674d3a87bc\",\n                \"environmentName\": \"AzureCloud\",\n                \"homeTenantId\": \"a4e1bb4b-5330-2d50-339d-b9674d3a87bc\",\n                \"managedByTenants\": []\n              },\n              {\n                \"id\": \"f3935dc9-92b5-9a93-da7b-42c325d86939\",\n                \"name\": \"\",\n                \"state\": \"Enabled\",\n                \"user\": {\n                  \"name\": \"user@domain.com\",\n                  \"type\": \"user\"\n                },\n                \"isDefault\": true,\n                \"tenantId\": \"f0273a19-7779-e40a-00a1-53b8331b3bb6\",\n                \"environmentName\": \"AzureCloud\",\n                \"homeTenantId\": \"f0273a19-7779-e40a-00a1-53b8331b3bb6\",\n                \"managedByTenants\": []\n              }\n            ]\n          }\n        \"#;\n\n        generate_test_config(&dir, azure_profile_contents)?;\n        let dir_path = &dir.path().to_string_lossy();\n        let actual = ModuleRenderer::new(\"azure\")\n            .config(toml::toml! {\n            [azure]\n            format = \"on [$symbol($subscription:$username)]($style)\"\n            disabled = false\n            })\n            .env(\"AZURE_CONFIG_DIR\", dir_path.as_ref())\n            .collect();\n        let expected = Some(format!(\n            \"on {}\",\n            Color::Blue.bold().paint(\"\udb82\udc05 :user@domain.com\")\n        ));\n        assert_eq!(actual, expected);\n        dir.close()\n    }\n\n    #[test]\n    fn user_name_empty() -> io::Result<()> {\n        let dir = tempfile::tempdir()?;\n\n        let azure_profile_contents = r#\"{\n            \"installationId\": \"3deacd2a-b9db-77e1-aa42-23e2f8dfffc3\",\n            \"subscriptions\": [\n                {\n                \"id\": \"f568c543-d12e-de0b-3d85-69843598b565\",\n                \"name\": \"Subscription 2\",\n                \"state\": \"Enabled\",\n                \"user\": {\n                  \"name\": \"user@domain.com\",\n                  \"type\": \"user\"\n                },\n                \"isDefault\": false,\n                \"tenantId\": \"0e8a15ec-b0f5-d355-7062-8ece54c59aee\",\n                \"environmentName\": \"AzureCloud\",\n                \"homeTenantId\": \"0e8a15ec-b0f5-d355-7062-8ece54c59aee\",\n                \"managedByTenants\": []\n              },\n              {\n                \"id\": \"d4442d26-ea6d-46c4-07cb-4f70b8ae5465\",\n                \"name\": \"Subscription 3\",\n                \"state\": \"Enabled\",\n                \"user\": {\n                  \"name\": \"user@domain.com\",\n                  \"type\": \"user\"\n                },\n                \"isDefault\": false,\n                \"tenantId\": \"a4e1bb4b-5330-2d50-339d-b9674d3a87bc\",\n                \"environmentName\": \"AzureCloud\",\n                \"homeTenantId\": \"a4e1bb4b-5330-2d50-339d-b9674d3a87bc\",\n                \"managedByTenants\": []\n              },\n              {\n                \"id\": \"f3935dc9-92b5-9a93-da7b-42c325d86939\",\n                \"name\": \"Subscription 1\",\n                \"state\": \"Enabled\",\n                \"user\": {\n                  \"name\": \"\",\n                  \"type\": \"user\"\n                },\n                \"isDefault\": true,\n                \"tenantId\": \"f0273a19-7779-e40a-00a1-53b8331b3bb6\",\n                \"environmentName\": \"AzureCloud\",\n                \"homeTenantId\": \"f0273a19-7779-e40a-00a1-53b8331b3bb6\",\n                \"managedByTenants\": []\n              }\n            ]\n          }\n        \"#;\n\n        generate_test_config(&dir, azure_profile_contents)?;\n        let dir_path = &dir.path().to_string_lossy();\n        let actual = ModuleRenderer::new(\"azure\")\n            .config(toml::toml! {\n            [azure]\n            format = \"on [$symbol($subscription:$username)]($style)\"\n            disabled = false\n            })\n            .env(\"AZURE_CONFIG_DIR\", dir_path.as_ref())\n            .collect();\n        let expected = Some(format!(\n            \"on {}\",\n            Color::Blue.bold().paint(\"\udb82\udc05 Subscription 1:\")\n        ));\n        assert_eq!(actual, expected);\n        dir.close()\n    }\n\n    #[test]\n    fn user_name_missing_from_profile() -> io::Result<()> {\n        let dir = tempfile::tempdir()?;\n\n        let azure_profile_contents = r#\"{\n            \"installationId\": \"3deacd2a-b9db-77e1-aa42-23e2f8dfffc3\",\n            \"subscriptions\": [\n                {\n                \"id\": \"f568c543-d12e-de0b-3d85-69843598b565\",\n                \"name\": \"Subscription 2\",\n                \"state\": \"Enabled\",\n                \"user\": {\n                  \"type\": \"user\"\n                },\n                \"isDefault\": false,\n                \"tenantId\": \"0e8a15ec-b0f5-d355-7062-8ece54c59aee\",\n                \"environmentName\": \"AzureCloud\",\n                \"homeTenantId\": \"0e8a15ec-b0f5-d355-7062-8ece54c59aee\",\n                \"managedByTenants\": []\n              },\n              {\n                \"id\": \"d4442d26-ea6d-46c4-07cb-4f70b8ae5465\",\n                \"name\": \"Subscription 3\",\n                \"state\": \"Enabled\",\n                \"user\": {\n                  \"name\": \"user@domain.com\",\n                  \"type\": \"user\"\n                },\n                \"isDefault\": false,\n                \"tenantId\": \"a4e1bb4b-5330-2d50-339d-b9674d3a87bc\",\n                \"environmentName\": \"AzureCloud\",\n                \"homeTenantId\": \"a4e1bb4b-5330-2d50-339d-b9674d3a87bc\",\n                \"managedByTenants\": []\n              },\n              {\n                \"id\": \"f3935dc9-92b5-9a93-da7b-42c325d86939\",\n                \"name\": \"Subscription 1\",\n                \"state\": \"Enabled\",\n                \"user\": {\n                  \"name\": \"\",\n                  \"type\": \"user\"\n                },\n                \"isDefault\": true,\n                \"tenantId\": \"f0273a19-7779-e40a-00a1-53b8331b3bb6\",\n                \"environmentName\": \"AzureCloud\",\n                \"homeTenantId\": \"f0273a19-7779-e40a-00a1-53b8331b3bb6\",\n                \"managedByTenants\": []\n              }\n            ]\n          }\n        \"#;\n\n        generate_test_config(&dir, azure_profile_contents)?;\n        let dir_path = &dir.path().to_string_lossy();\n        let actual = ModuleRenderer::new(\"azure\")\n            .config(toml::toml! {\n            [azure]\n            format = \"on [$symbol($subscription:$username)]($style)\"\n            disabled = false\n            })\n            .env(\"AZURE_CONFIG_DIR\", dir_path.as_ref())\n            .collect();\n        let expected = None;\n        assert_eq!(actual, expected);\n        dir.close()\n    }\n\n    #[test]\n    fn subscription_name_missing_from_profile() -> io::Result<()> {\n        let dir = tempfile::tempdir()?;\n\n        let azure_profile_contents = r#\"{\n            \"installationId\": \"3deacd2a-b9db-77e1-aa42-23e2f8dfffc3\",\n            \"subscriptions\": [\n                {\n                \"id\": \"f568c543-d12e-de0b-3d85-69843598b565\",\n                \"name\": \"Subscription 2\",\n                \"state\": \"Enabled\",\n                \"user\": {\n                  \"name\": \"user@domain.com\",\n                  \"type\": \"user\"\n                },\n                \"isDefault\": false,\n                \"tenantId\": \"0e8a15ec-b0f5-d355-7062-8ece54c59aee\",\n                \"environmentName\": \"AzureCloud\",\n                \"homeTenantId\": \"0e8a15ec-b0f5-d355-7062-8ece54c59aee\",\n                \"managedByTenants\": []\n              },\n              {\n                \"id\": \"d4442d26-ea6d-46c4-07cb-4f70b8ae5465\",\n                \"name\": \"Subscription 3\",\n                \"state\": \"Enabled\",\n                \"user\": {\n                  \"name\": \"user@domain.com\",\n                  \"type\": \"user\"\n                },\n                \"isDefault\": false,\n                \"tenantId\": \"a4e1bb4b-5330-2d50-339d-b9674d3a87bc\",\n                \"environmentName\": \"AzureCloud\",\n                \"homeTenantId\": \"a4e1bb4b-5330-2d50-339d-b9674d3a87bc\",\n                \"managedByTenants\": []\n              },\n              {\n                \"id\": \"f3935dc9-92b5-9a93-da7b-42c325d86939\",\n                \"state\": \"Enabled\",\n                \"user\": {\n                  \"name\": \"user@domain.com\",\n                  \"type\": \"user\"\n                },\n                \"isDefault\": true,\n                \"tenantId\": \"f0273a19-7779-e40a-00a1-53b8331b3bb6\",\n                \"environmentName\": \"AzureCloud\",\n                \"homeTenantId\": \"f0273a19-7779-e40a-00a1-53b8331b3bb6\",\n                \"managedByTenants\": []\n              }\n            ]\n          }\n        \"#;\n\n        generate_test_config(&dir, azure_profile_contents)?;\n        let dir_path = &dir.path().to_string_lossy();\n        let actual = ModuleRenderer::new(\"azure\")\n            .config(toml::toml! {\n            [azure]\n            format = \"on [$symbol($subscription:$username)]($style)\"\n            disabled = false\n            })\n            .env(\"AZURE_CONFIG_DIR\", dir_path.as_ref())\n            .collect();\n        let expected = None;\n        assert_eq!(actual, expected);\n        dir.close()\n    }\n\n    #[test]\n    fn subscription_name_and_username_found() -> io::Result<()> {\n        let dir = tempfile::tempdir()?;\n\n        let azure_profile_contents = r#\"{\n            \"installationId\": \"3deacd2a-b9db-77e1-aa42-23e2f8dfffc3\",\n            \"subscriptions\": [\n                {\n                \"id\": \"f568c543-d12e-de0b-3d85-69843598b565\",\n                \"name\": \"Subscription 2\",\n                \"state\": \"Enabled\",\n                \"user\": {\n                  \"name\": \"user@domain.com\",\n                  \"type\": \"user\"\n                },\n                \"isDefault\": false,\n                \"tenantId\": \"0e8a15ec-b0f5-d355-7062-8ece54c59aee\",\n                \"environmentName\": \"AzureCloud\",\n                \"homeTenantId\": \"0e8a15ec-b0f5-d355-7062-8ece54c59aee\",\n                \"managedByTenants\": []\n              },\n              {\n                \"id\": \"d4442d26-ea6d-46c4-07cb-4f70b8ae5465\",\n                \"name\": \"Subscription 3\",\n                \"state\": \"Enabled\",\n                \"user\": {\n                  \"name\": \"user@domain.com\",\n                  \"type\": \"user\"\n                },\n                \"isDefault\": false, \n                \"tenantId\": \"a4e1bb4b-5330-2d50-339d-b9674d3a87bc\",\n                \"environmentName\": \"AzureCloud\",\n                \"homeTenantId\": \"a4e1bb4b-5330-2d50-339d-b9674d3a87bc\",\n                \"managedByTenants\": []\n              },\n              {\n                \"id\": \"f3935dc9-92b5-9a93-da7b-42c325d86939\",\n                \"name\": \"Subscription 1\",\n                \"state\": \"Enabled\",\n                \"user\": {\n                  \"name\": \"user@domain.com\",\n                  \"type\": \"user\"\n                },\n                \"isDefault\": true,\n                \"tenantId\": \"f0273a19-7779-e40a-00a1-53b8331b3bb6\",\n                \"environmentName\": \"AzureCloud\",\n                \"homeTenantId\": \"f0273a19-7779-e40a-00a1-53b8331b3bb6\",\n                \"managedByTenants\": []\n              }\n            ]\n          }\n        \"#;\n\n        generate_test_config(&dir, azure_profile_contents)?;\n        let dir_path = &dir.path().to_string_lossy();\n        let actual = ModuleRenderer::new(\"azure\")\n            .config(toml::toml! {\n            [azure]\n            format = \"on [$symbol($subscription:$username)]($style)\"\n            disabled = false\n            })\n            .env(\"AZURE_CONFIG_DIR\", dir_path.as_ref())\n            .collect();\n        let expected = Some(format!(\n            \"on {}\",\n            Color::Blue.bold().paint(\"\udb82\udc05 Subscription 1:user@domain.com\")\n        ));\n        assert_eq!(actual, expected);\n        dir.close()\n    }\n\n    #[test]\n    fn subscription_name_with_alias() -> io::Result<()> {\n        let dir = tempfile::tempdir()?;\n\n        let azure_profile_contents = r#\"{\n            \"installationId\": \"3deacd2a-b9db-77e1-aa42-23e2f8dfffc3\",\n            \"subscriptions\": [\n                {\n                \"id\": \"f568c543-d12e-de0b-3d85-69843598b565\",\n                \"name\": \"VeryLongSubscriptionName\",\n                \"state\": \"Enabled\",\n                \"user\": {\n                  \"name\": \"user@domain.com\",\n                  \"type\": \"user\"\n                },\n                \"isDefault\": false,\n                \"tenantId\": \"0e8a15ec-b0f5-d355-7062-8ece54c59aee\",\n                \"environmentName\": \"AzureCloud\",\n                \"homeTenantId\": \"0e8a15ec-b0f5-d355-7062-8ece54c59aee\",\n                \"managedByTenants\": []\n              },\n              {\n                \"id\": \"d4442d26-ea6d-46c4-07cb-4f70b8ae5465\",\n                \"name\": \"AnotherLongSubscriptionName\",\n                \"state\": \"Enabled\",\n                \"user\": {\n                  \"name\": \"user@domain.com\",\n                  \"type\": \"user\"\n                },\n                \"isDefault\": false, \n                \"tenantId\": \"a4e1bb4b-5330-2d50-339d-b9674d3a87bc\",\n                \"environmentName\": \"AzureCloud\",\n                \"homeTenantId\": \"a4e1bb4b-5330-2d50-339d-b9674d3a87bc\",\n                \"managedByTenants\": []\n              },\n              {\n                \"id\": \"f3935dc9-92b5-9a93-da7b-42c325d86939\",\n                \"name\": \"TheLastLongSubscriptionName\",\n                \"state\": \"Enabled\",\n                \"user\": {\n                  \"name\": \"user@domain.com\",\n                  \"type\": \"user\"\n                },\n                \"isDefault\": true,\n                \"tenantId\": \"f0273a19-7779-e40a-00a1-53b8331b3bb6\",\n                \"environmentName\": \"AzureCloud\",\n                \"homeTenantId\": \"f0273a19-7779-e40a-00a1-53b8331b3bb6\",\n                \"managedByTenants\": []\n              }\n            ]\n          }\n        \"#;\n\n        generate_test_config(&dir, azure_profile_contents)?;\n        let dir_path = &dir.path().to_string_lossy();\n        let actual = ModuleRenderer::new(\"azure\")\n            .config(toml::toml! {\n                [azure]\n                format = \"on [$symbol($subscription:$username)]($style)\"\n                disabled = false\n                [azure.subscription_aliases]\n                VeryLongSubscriptionName = \"vlsn\"\n                AnotherLongSubscriptionName = \"alsn\"\n                TheLastLongSubscriptionName = \"tllsn\"\n            })\n            .env(\"AZURE_CONFIG_DIR\", dir_path.as_ref())\n            .collect();\n        let expected = Some(format!(\n            \"on {}\",\n            Color::Blue.bold().paint(\"\udb82\udc05 tllsn:user@domain.com\")\n        ));\n        assert_eq!(actual, expected);\n        dir.close()\n    }\n\n    #[test]\n    fn subscription_azure_profile_empty() -> io::Result<()> {\n        let dir = tempfile::tempdir()?;\n\n        let mut clouds_config_ini = Ini::new();\n        clouds_config_ini\n            .with_section(Some(\"AzureCloud\"))\n            .set(\"subscription\", \"f3935dc9-92b5-9a93-da7b-42c325d86939\");\n\n        //let azure_profile_contents = \"\\u{feff}{\\\"installationId\\\": \\\"2652263e-40f8-11ed-ae3b-367ddada549c\\\", \\\"subscriptions\\\": []}\";\n        let azure_profile_contents = r#\"{\n            \"installationId\": \"3deacd2a-b9db-77e1-aa42-23e2f8dfffc3\",\n            \"subscriptions\": []\n          }\n        \"#;\n\n        generate_test_config(&dir, azure_profile_contents)?;\n        let dir_path = &dir.path().to_string_lossy();\n        let actual = ModuleRenderer::new(\"azure\")\n            .config(toml::toml! {\n              [azure]\n              disabled = false\n            })\n            .env(\"AZURE_CONFIG_DIR\", dir_path.as_ref())\n            .collect();\n        let expected = None;\n        assert_eq!(actual, expected);\n        dir.close()\n    }\n\n    #[test]\n    fn azure_profile_with_leading_char() -> io::Result<()> {\n        let dir = tempfile::tempdir()?;\n\n        let bom = vec![239, 187, 191];\n        let mut bom_str = String::from_utf8(bom).unwrap();\n\n        let json_str =\n            r#\"{\"installationId\": \"3deacd2a-b9db-77e1-aa42-23e2f8dfffc3\", \"subscriptions\": []}\"#;\n\n        bom_str.push_str(json_str);\n\n        let dir_path_no_bom = save_string_to_file(&dir, bom_str, String::from(\"bom.json\"))?;\n        let sanitized_json = load_azure_profile(&dir_path_no_bom).unwrap();\n\n        assert_eq!(\n            sanitized_json.installation_id,\n            \"3deacd2a-b9db-77e1-aa42-23e2f8dfffc3\"\n        );\n        assert!(sanitized_json.subscriptions.is_empty());\n        dir.close()\n    }\n\n    #[test]\n    fn azure_profile_without_leading_char() -> io::Result<()> {\n        let dir = tempfile::tempdir()?;\n\n        let json_str =\n            r#\"{\"installationId\": \"3deacd2a-b9db-77e1-aa42-23e2f8dfffc3\", \"subscriptions\": []}\"#;\n\n        let dir_path_no_bom =\n            save_string_to_file(&dir, json_str.to_string(), String::from(\"bom.json\"))?;\n        let sanitized_json = load_azure_profile(&dir_path_no_bom).unwrap();\n\n        assert_eq!(\n            sanitized_json.installation_id,\n            \"3deacd2a-b9db-77e1-aa42-23e2f8dfffc3\"\n        );\n        assert!(sanitized_json.subscriptions.is_empty());\n        dir.close()\n    }\n\n    #[test]\n    fn files_missing() -> io::Result<()> {\n        let dir = tempfile::tempdir()?;\n\n        let dir_path = &dir.path().to_string_lossy();\n\n        let actual = ModuleRenderer::new(\"azure\")\n            .env(\"AZURE_CONFIG_DIR\", dir_path.as_ref())\n            .collect();\n        let expected = None;\n        assert_eq!(actual, expected);\n        dir.close()\n    }\n\n    fn save_string_to_file(\n        dir: &TempDir,\n        contents: String,\n        file_name: String,\n    ) -> Result<PathBuf, io::Error> {\n        let bom_file_path = dir.path().join(file_name);\n        let mut bom_file = File::create(&bom_file_path)?;\n        bom_file.write_all(contents.as_bytes())?;\n        bom_file.sync_all()?;\n        Ok(bom_file_path)\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "ee8015f68e78b56a6ed1df991447c354bbb5cac9",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/starship/src/modules/status.rs",
    "func": "use std::string::ToString;\n\nuse super::{Context, Module, ModuleConfig};\n\nuse crate::configs::status::StatusConfig;\nuse crate::formatter::{string_formatter::StringFormatterError, StringFormatter};\nuse crate::segment::Segment;\n\ntype ExitCode = i32;\ntype SignalNumber = u32;\n#[derive(PartialEq)]\nenum PipeStatusStatus<'a> {\n    Disabled,\n    NoPipe,\n    Pipe(&'a Vec<std::string::String>),\n}\n\n/// Creates a module with the status of the last command\n///\n/// Will display the status\npub fn module<'a>(context: &'a Context) -> Option<Module<'a>> {\n    let mut module = context.new_module(\"status\");\n    let config = StatusConfig::try_load(module.config);\n\n    // As we default to disabled=true, we have to check here after loading our config module,\n    // before it was only checking against whatever is in the config starship.toml\n    if config.disabled {\n        return None;\n    };\n\n    let exit_code = context.properties.status_code.as_deref().unwrap_or(\"0\");\n\n    let pipestatus_status = match &context.properties.pipestatus {\n        None => PipeStatusStatus::Disabled,\n        Some(ps) => match ps.len() > 1 {\n            true => PipeStatusStatus::Pipe(ps),\n            false => PipeStatusStatus::NoPipe,\n        },\n    };\n\n    let pipestatus_status = match config.pipestatus {\n        true => pipestatus_status,\n        false => PipeStatusStatus::Disabled,\n    };\n\n    // Exit code is zero while success_symbol and pipestatus are all zero or disabled/missing\n    if exit_code == \"0\"\n        && config.success_symbol.is_empty()\n        && (match pipestatus_status {\n            PipeStatusStatus::Pipe(ps) => ps.iter().all(|s| s == \"0\"),\n            _ => true,\n        })\n    {\n        return None;\n    }\n\n    let segment_format = config.pipestatus_segment_format.unwrap_or(config.format);\n    let segment_format_with_separator = [segment_format, config.pipestatus_separator].join(\"\");\n\n    // Create pipestatus segments\n    let pipestatus = match pipestatus_status {\n        PipeStatusStatus::Pipe(ps) => ps\n            .iter()\n            .enumerate()\n            .filter_map(|(i, ec)| {\n                let formatted = format_exit_code(\n                    ec.as_str(),\n                    if i == ps.len() - 1 {\n                        segment_format\n                    } else {\n                        &segment_format_with_separator\n                    },\n                    None,\n                    &config,\n                    context,\n                );\n                match formatted {\n                    Ok(segments) => Some(segments),\n                    Err(e) => {\n                        log::warn!(\"Error parsing format string in `status.pipestatus_segment_format`: {e:?}\");\n                        None\n                    }\n                }\n            })\n            .flatten()\n            .collect(),\n        _ => Vec::new(),\n    };\n\n    let main_format = match pipestatus_status {\n        PipeStatusStatus::Pipe(_) => config.pipestatus_format,\n        _ => config.format,\n    };\n    let parsed = format_exit_code(exit_code, main_format, Some(pipestatus), &config, context);\n\n    module.set_segments(match parsed {\n        Ok(segments) => segments,\n        Err(_error) => {\n            log::warn!(\"Error parsing format string in `status.format`\");\n            return None;\n        }\n    });\n    Some(module)\n}\n\nfn format_exit_code<'a>(\n    exit_code: &'a str,\n    format: &'a str,\n    pipestatus: Option<Vec<Segment>>,\n    config: &'a StatusConfig,\n    context: &'a Context,\n) -> Result<Vec<Segment>, StringFormatterError> {\n    // First, parse as i64 to accept both i32 or u32, then normalize to i32.\n    let exit_code_int: ExitCode = match exit_code.parse::<i64>() {\n        Ok(i) => i as ExitCode,\n        Err(_) => {\n            log::warn!(\"Error parsing exit_code string to int\");\n            return Ok(Vec::new());\n        }\n    };\n\n    let hex_status = format!(\"0x{exit_code_int:X}\");\n\n    let common_meaning = status_common_meaning(exit_code_int);\n\n    let raw_signal_number = match config.recognize_signal_code {\n        true => status_to_signal(exit_code_int),\n        false => None,\n    };\n    let signal_number = raw_signal_number.map(|sn| sn.to_string());\n    let signal_name =\n        raw_signal_number.and_then(|sn| status_signal_name(sn).or(signal_number.as_deref()));\n\n    // If not a signal and not a common meaning, it should at least print the raw exit code number\n    let maybe_exit_code_number = match common_meaning.is_none() && signal_name.is_none() {\n        true => Some(exit_code),\n        false => None,\n    };\n\n    StringFormatter::new(format).and_then(|formatter| {\n        formatter\n            .map_meta(|var, _| match var {\n                \"symbol\" => match exit_code_int {\n                    0 => Some(config.success_symbol),\n                    126 if config.map_symbol => Some(config.not_executable_symbol),\n                    127 if config.map_symbol => Some(config.not_found_symbol),\n                    130 if config.recognize_signal_code && config.map_symbol => {\n                        Some(config.sigint_symbol)\n                    }\n                    x if (129..256).contains(&x)\n                        && config.recognize_signal_code\n                        && config.map_symbol =>\n                    {\n                        Some(config.signal_symbol)\n                    }\n                    _ => Some(config.symbol),\n                },\n                _ => None,\n            })\n            .map_style(|variable| match variable {\n                \"style\" => Some(Ok(config.style)),\n                _ => None,\n            })\n            .map(|variable| match variable {\n                \"status\" => Some(Ok(exit_code)),\n                \"hex_status\" => Some(Ok(hex_status.as_ref())),\n                \"int\" => Some(Ok(exit_code)),\n                \"maybe_int\" => Ok(maybe_exit_code_number).transpose(),\n                \"common_meaning\" => Ok(common_meaning).transpose(),\n                \"signal_number\" => Ok(signal_number.as_deref()).transpose(),\n                \"signal_name\" => Ok(signal_name).transpose(),\n                _ => None,\n            })\n            .map_variables_to_segments(|variable| match variable {\n                \"pipestatus\" if pipestatus.is_none() => {\n                    // We might enter this case if pipestatus hasn't\n                    // been processed yet, which means that it has been\n                    // set in format\n                    log::warn!(\"pipestatus variable is only available in pipestatus_format\");\n                    None\n                }\n                \"pipestatus\" => pipestatus.clone().map(Ok),\n                _ => None,\n            })\n            .parse(None, Some(context))\n    })\n}\n\nfn status_common_meaning(ex: ExitCode) -> Option<&'static str> {\n    // Over 128 are Signal exit code\n    if ex > 128 {\n        return None;\n    }\n    match ex {\n        0 => Some(\"\"), // SUCCESS can be defined by $success_symbol if the user wishes too.\n        1 => Some(\"ERROR\"),\n        2 => Some(\"USAGE\"),\n\n        // status codes 64-78 from libc\n        64 => Some(\"USAGE\"),\n        65 => Some(\"DATAERR\"),\n        66 => Some(\"NOINPUT\"),\n        67 => Some(\"NOUSER\"),\n        68 => Some(\"NOHOST\"),\n        69 => Some(\"UNAVAILABLE\"),\n        70 => Some(\"SOFTWARE\"),\n        71 => Some(\"OSERR\"),\n        72 => Some(\"OSFILE\"),\n        73 => Some(\"CANTCREAT\"),\n        74 => Some(\"IOERR\"),\n        75 => Some(\"TEMPFAIL\"),\n        76 => Some(\"PROTOCOL\"),\n        77 => Some(\"NOPERM\"),\n        78 => Some(\"CONFIG\"),\n\n        126 => Some(\"NOPERM\"),\n        127 => Some(\"NOTFOUND\"),\n        _ => None,\n    }\n}\n\nfn status_to_signal(ex: ExitCode) -> Option<SignalNumber> {\n    if ex < 129 {\n        return None;\n    }\n    let sn = ex - 128;\n    Some(sn as u32)\n}\n\nfn status_signal_name(signal: SignalNumber) -> Option<&'static str> {\n    match signal {\n        1 => Some(\"HUP\"),     // 128 + 1\n        2 => Some(\"INT\"),     // 128 + 2\n        3 => Some(\"QUIT\"),    // 128 + 3\n        4 => Some(\"ILL\"),     // 128 + 4\n        5 => Some(\"TRAP\"),    // 128 + 5\n        6 => Some(\"IOT\"),     // 128 + 6\n        7 => Some(\"BUS\"),     // 128 + 7\n        8 => Some(\"FPE\"),     // 128 + 8\n        9 => Some(\"KILL\"),    // 128 + 9\n        10 => Some(\"USR1\"),   // 128 + 10\n        11 => Some(\"SEGV\"),   // 128 + 11\n        12 => Some(\"USR2\"),   // 128 + 12\n        13 => Some(\"PIPE\"),   // 128 + 13\n        14 => Some(\"ALRM\"),   // 128 + 14\n        15 => Some(\"TERM\"),   // 128 + 15\n        16 => Some(\"STKFLT\"), // 128 + 16\n        17 => Some(\"CHLD\"),   // 128 + 17\n        18 => Some(\"CONT\"),   // 128 + 18\n        19 => Some(\"STOP\"),   // 128 + 19\n        20 => Some(\"TSTP\"),   // 128 + 20\n        21 => Some(\"TTIN\"),   // 128 + 21\n        22 => Some(\"TTOU\"),   // 128 + 22\n        _ => None,\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use nu_ansi_term::{Color, Style};\n\n    use crate::test::ModuleRenderer;\n\n    #[test]\n    fn success_status_success_symbol_empty() {\n        let expected = None;\n\n        // Status code 0 and success_symbol = \"\"\n        let actual = ModuleRenderer::new(\"status\")\n            .config(toml::toml! {\n                [status]\n                success_symbol = \"\"\n                disabled = false\n            })\n            .status(0)\n            .collect();\n        assert_eq!(expected, actual);\n\n        // Status code 0 and success_symbol is missing\n        let actual = ModuleRenderer::new(\"status\")\n            .config(toml::toml! {\n                [status]\n                disabled = false\n            })\n            .status(0)\n            .collect();\n        assert_eq!(expected, actual);\n\n        // No status code and success_symbol = \"\"\n        let actual = ModuleRenderer::new(\"status\")\n            .config(toml::toml! {\n                [status]\n                success_symbol = \"\"\n                disabled = false\n            })\n            .collect();\n        assert_eq!(expected, actual);\n\n        // No status code and success_symbol is missing\n        let actual = ModuleRenderer::new(\"status\")\n            .config(toml::toml! {\n                [status]\n                disabled = false\n            })\n            .collect();\n        assert_eq!(expected, actual);\n    }\n\n    #[test]\n    fn success_status_success_symbol_filled() {\n        let expected = Some(format!(\"{} \", Color::Red.bold().paint(\"\u2714\ufe0f0\")));\n\n        // Status code 0\n        let actual = ModuleRenderer::new(\"status\")\n            .config(toml::toml! {\n                [status]\n                success_symbol = \"\u2714\ufe0f\"\n                disabled = false\n            })\n            .status(0)\n            .collect();\n        assert_eq!(expected, actual);\n\n        // No status code\n        let actual = ModuleRenderer::new(\"status\")\n            .config(toml::toml! {\n                [status]\n                success_symbol = \"\u2714\ufe0f\"\n                disabled = false\n            })\n            .collect();\n        assert_eq!(expected, actual);\n    }\n\n    #[test]\n    fn not_enabled() {\n        let expected = None;\n\n        let actual = ModuleRenderer::new(\"status\").status(1).collect();\n        assert_eq!(expected, actual);\n    }\n\n    #[test]\n    fn failure_status() {\n        let exit_values = [1, 2, 130];\n\n        for status in &exit_values {\n            let expected = Some(format!(\n                \"{} \",\n                Color::Red.bold().paint(format!(\"\u274c{status}\"))\n            ));\n            let actual = ModuleRenderer::new(\"status\")\n                .config(toml::toml! {\n                    [status]\n                    symbol = \"\u274c\"\n                    disabled = false\n                })\n                .status(*status)\n                .collect();\n            assert_eq!(expected, actual);\n        }\n    }\n\n    #[test]\n    fn failure_plaintext_status() {\n        let exit_values = [1, 2, 130];\n\n        for status in &exit_values {\n            let expected = Some(format!(\n                \"{} \",\n                Color::Red.bold().paint(format!(\"x {status}\"))\n            ));\n            let actual = ModuleRenderer::new(\"status\")\n                .config(toml::toml! {\n                    [status]\n                    symbol = \"[x](bold red) \"\n                    disabled = false\n                })\n                .status(*status)\n                .collect();\n            assert_eq!(expected, actual);\n        }\n    }\n\n    #[test]\n    fn failure_hex_status() {\n        let exit_values = [1, 2, 130, -2_147_467_260, 2_147_500_036];\n        let string_values = [\"0x1\", \"0x2\", \"0x82\", \"0x80004004\", \"0x80004004\"];\n\n        for (exit_value, string_value) in exit_values.iter().zip(string_values) {\n            let expected = Some(format!(\n                \"{} \",\n                Color::Red.bold().paint(format!(\"\u274c{string_value}\"))\n            ));\n            let actual = ModuleRenderer::new(\"status\")\n                .config(toml::toml! {\n                    [status]\n                    symbol = \"\u274c\"\n                    disabled = false\n                    format = \"[${symbol}${hex_status}]($style) \"\n                })\n                .status(*exit_value)\n                .collect();\n            assert_eq!(expected, actual);\n        }\n    }\n\n    #[test]\n    fn signal_name() {\n        let exit_values = [1, 2, 126, 127, 130, 101];\n        let exit_values_name = [\n            Some(\"ERROR\"),\n            Some(\"USAGE\"),\n            Some(\"NOPERM\"),\n            Some(\"NOTFOUND\"),\n            Some(\"INT\"),\n            None,\n        ];\n\n        for (status, name) in exit_values.iter().zip(&exit_values_name) {\n            let expected = name.map(std::string::ToString::to_string);\n            let actual = ModuleRenderer::new(\"status\")\n                .config(toml::toml! {\n                    [status]\n                    format = \"$common_meaning$signal_name\"\n                    disabled = false\n                })\n                .status(*status)\n                .collect();\n            assert_eq!(expected, actual);\n        }\n    }\n\n    #[test]\n    fn exit_code_name_no_signal() {\n        let exit_values = [\n            1, 2, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 126, 127, 130, 101,\n            132,\n        ];\n        let exit_values_name = [\n            Some(\"ERROR\"),\n            Some(\"USAGE\"),\n            Some(\"USAGE\"),\n            Some(\"DATAERR\"),\n            Some(\"NOINPUT\"),\n            Some(\"NOUSER\"),\n            Some(\"NOHOST\"),\n            Some(\"UNAVAILABLE\"),\n            Some(\"SOFTWARE\"),\n            Some(\"OSERR\"),\n            Some(\"OSFILE\"),\n            Some(\"CANTCREAT\"),\n            Some(\"IOERR\"),\n            Some(\"TEMPFAIL\"),\n            Some(\"PROTOCOL\"),\n            Some(\"NOPERM\"),\n            Some(\"CONFIG\"),\n            Some(\"NOPERM\"),\n            Some(\"NOTFOUND\"),\n            None,\n            None,\n            None,\n        ];\n\n        for (status, name) in exit_values.iter().zip(&exit_values_name) {\n            let expected = name.map(std::string::ToString::to_string);\n            let actual = ModuleRenderer::new(\"status\")\n                .config(toml::toml! {\n                    [status]\n                    format = \"$common_meaning$signal_name\"\n                    recognize_signal_code = false\n                    disabled = false\n                })\n                .status(*status)\n                .collect();\n            assert_eq!(expected, actual);\n        }\n    }\n\n    #[test]\n    fn maybe_exit_code_number() {\n        let exit_values = [1, 2, 126, 127, 130, 101, 6, -3];\n        let exit_values_name = [\n            None,\n            None,\n            None,\n            None,\n            None,\n            Some(\"101\"),\n            Some(\"6\"),\n            Some(\"-3\"),\n        ];\n\n        for (status, name) in exit_values.iter().zip(&exit_values_name) {\n            let expected = name.map(std::string::ToString::to_string);\n            let actual = ModuleRenderer::new(\"status\")\n                .config(toml::toml! {\n                    [status]\n                    format = \"$maybe_int\"\n                    disabled = false\n                })\n                .status(*status)\n                .collect();\n            assert_eq!(expected, actual);\n        }\n    }\n\n    #[test]\n    fn special_symbols() {\n        let exit_values = [1, 126, 127, 130, 131];\n        let exit_values_name = [\"\ud83d\udd34\", \"\ud83d\udeab\", \"\ud83d\udd0d\", \"\ud83e\uddf1\", \"\u26a1\"];\n\n        for (status, name) in exit_values.iter().zip(&exit_values_name) {\n            let expected = Some((*name).to_string());\n            let actual = ModuleRenderer::new(\"status\")\n                .config(toml::toml! {\n                    [status]\n                    format = \"$symbol\"\n                    symbol = \"\ud83d\udd34\"\n                    not_executable_symbol = \"\ud83d\udeab\"\n                    not_found_symbol = \"\ud83d\udd0d\"\n                    sigint_symbol = \"\ud83e\uddf1\"\n                    signal_symbol = \"\u26a1\"\n                    recognize_signal_code = true\n                    map_symbol = true\n                    disabled = false\n                })\n                .status(*status)\n                .collect();\n            assert_eq!(expected, actual);\n        }\n    }\n\n    #[test]\n    fn special_symbols_no_signals() {\n        let exit_values = [1, 126, 127, 130, 131];\n        let exit_values_name = [\"\ud83d\udd34\", \"\ud83d\udeab\", \"\ud83d\udd0d\", \"\ud83d\udd34\", \"\ud83d\udd34\"];\n\n        for (status, name) in exit_values.iter().zip(&exit_values_name) {\n            let expected = Some((*name).to_string());\n            let actual = ModuleRenderer::new(\"status\")\n                .config(toml::toml! {\n                    [status]\n                    format = \"$symbol\"\n                    symbol = \"\ud83d\udd34\"\n                    not_executable_symbol = \"\ud83d\udeab\"\n                    not_found_symbol = \"\ud83d\udd0d\"\n                    sigint_symbol = \"\ud83e\uddf1\"\n                    signal_symbol = \"\u26a1\"\n                    recognize_signal_code = false\n                    map_symbol = true\n                    disabled = false\n                })\n                .status(*status)\n                .collect();\n            assert_eq!(expected, actual);\n        }\n    }\n\n    #[test]\n    fn pipeline_uses_pipestatus_format() {\n        let exit_values = [\n            [0, 1, 0, 0],\n            [0, 1, 2, 3],\n            [130, 126, 131, 127],\n            [1, 1, 1, 1],\n        ];\n        let exit_values_rendered = [\n            \"PSF \ud83d\udfe2=\ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2\",\n            \"PSF \ud83d\udfe2=\ud83d\udd34 \ud83d\udd34 \ud83d\udd34\",\n            \"PSF \ud83e\uddf1=\ud83d\udeab \u26a1 \ud83d\udd0d\",\n            \"PSF \ud83d\udd34=\ud83d\udd34 \ud83d\udd34 \ud83d\udd34\",\n        ];\n\n        for (status, rendered) in exit_values.iter().zip(&exit_values_rendered) {\n            let main_exit_code = status[0];\n            let pipe_exit_code = &status[1..];\n\n            let expected = Some((*rendered).to_string());\n            let actual = ModuleRenderer::new(\"status\")\n                .config(toml::toml! {\n                    [status]\n                    format = \"$symbol\"\n                    symbol = \"\ud83d\udd34\"\n                    success_symbol = \"\ud83d\udfe2\"\n                    not_executable_symbol = \"\ud83d\udeab\"\n                    not_found_symbol = \"\ud83d\udd0d\"\n                    sigint_symbol = \"\ud83e\uddf1\"\n                    signal_symbol = \"\u26a1\"\n                    recognize_signal_code = true\n                    map_symbol = true\n                    pipestatus = true\n                    pipestatus_separator = \" \"\n                    pipestatus_format = \"PSF $symbol=$pipestatus\"\n                    disabled = false\n                })\n                .status(main_exit_code)\n                .pipestatus(pipe_exit_code)\n                .collect();\n            assert_eq!(expected, actual);\n        }\n    }\n\n    #[test]\n    fn pipeline_no_map_symbols() {\n        let exit_values = [\n            [0, 1, 0, 0],\n            [0, 1, 2, 3],\n            [130, 126, 131, 127],\n            [1, 1, 1, 1],\n        ];\n        let exit_values_rendered = [\n            \"PSF \ud83d\udfe2=\ud83d\udd341 \ud83d\udfe20 \ud83d\udfe20\",\n            \"PSF \ud83d\udfe2=\ud83d\udd341 \ud83d\udd342 \ud83d\udd343\",\n            \"PSF INT\ud83d\udd34=\ud83d\udd34126 \ud83d\udd341313 \ud83d\udd34127\",\n            \"PSF \ud83d\udd34=\ud83d\udd341 \ud83d\udd341 \ud83d\udd341\",\n        ];\n\n        for (status, rendered) in exit_values.iter().zip(&exit_values_rendered) {\n            let main_exit_code = status[0];\n            let pipe_exit_code = &status[1..];\n\n            let expected = Some((*rendered).to_string());\n            let actual = ModuleRenderer::new(\"status\")\n                .config(toml::toml! {\n                    [status]\n                    format = \"$symbol$int$signal_number\"\n                    symbol = \"\ud83d\udd34\"\n                    success_symbol = \"\ud83d\udfe2\"\n                    not_executable_symbol = \"\ud83d\udeab\"\n                    not_found_symbol = \"\ud83d\udd0d\"\n                    sigint_symbol = \"\ud83e\uddf1\"\n                    signal_symbol = \"\u26a1\"\n                    recognize_signal_code = true\n                    map_symbol = false\n                    pipestatus = true\n                    pipestatus_separator = \" \"\n                    pipestatus_format = \"PSF $signal_name$symbol=$pipestatus\"\n                    disabled = false\n                })\n                .status(main_exit_code)\n                .pipestatus(pipe_exit_code)\n                .collect();\n            assert_eq!(expected, actual);\n        }\n    }\n\n    #[test]\n    fn successful_pipeline() {\n        let pipe_exit_code = [0, 0, 0];\n\n        let main_exit_code = 0;\n\n        let expected = None;\n\n        let actual = ModuleRenderer::new(\"status\")\n            .config(toml::toml! {\n                [status]\n                disabled = false\n            })\n            .status(main_exit_code)\n            .pipestatus(&pipe_exit_code)\n            .collect();\n        assert_eq!(expected, actual);\n    }\n\n    #[test]\n    fn successful_pipeline_pipestatus_enabled() {\n        let pipe_exit_code = [0, 0, 0];\n\n        let main_exit_code = 0;\n\n        let expected = None;\n\n        let actual = ModuleRenderer::new(\"status\")\n            .config(toml::toml! {\n                [status]\n                disabled = false\n                pipestatus = true\n            })\n            .status(main_exit_code)\n            .pipestatus(&pipe_exit_code)\n            .collect();\n        assert_eq!(expected, actual);\n    }\n\n    #[test]\n    fn pipeline_disabled() {\n        let exit_values = [[130, 126, 131, 127], [1, 1, 1, 1]];\n        let exit_values_rendered = [\"F \ud83e\uddf1\", \"F \ud83d\udd34\"];\n\n        for (status, rendered) in exit_values.iter().zip(&exit_values_rendered) {\n            let main_exit_code = status[0];\n            let pipe_exit_code = &status[1..];\n\n            let expected = Some((*rendered).to_string());\n            let actual = ModuleRenderer::new(\"status\")\n                .config(toml::toml! {\n                    [status]\n                    format = \"F $symbol\"\n                    symbol = \"\ud83d\udd34\"\n                    success_symbol = \"\ud83d\udfe2\"\n                    not_executable_symbol = \"\ud83d\udeab\"\n                    not_found_symbol = \"\ud83d\udd0d\"\n                    sigint_symbol = \"\ud83e\uddf1\"\n                    signal_symbol = \"\u26a1\"\n                    recognize_signal_code = true\n                    map_symbol = true\n                    pipestatus = false\n                    pipestatus_separator = \" \"\n                    pipestatus_format = \"PSF $symbol=$pipestatus\"\n                    disabled = false\n                })\n                .status(main_exit_code)\n                .pipestatus(pipe_exit_code)\n                .collect();\n            assert_eq!(expected, actual);\n        }\n    }\n\n    #[test]\n    fn pipeline_long() {\n        let exit_values = [\n            [130, 0, 0, 0, 30, 1, 2, 3, 142, 0, 0, 0, 130],\n            [1, 0, 0, 0, 30, 127, 126, 3, 142, 0, 230, 0, 2],\n        ];\n        let exit_values_rendered = [\n            \"PSF 130INT=\ud83d\udfe2|\ud83d\udfe2|\ud83d\udfe2|\ud83d\udd3430|\ud83d\udd34|\ud83d\udd34|\ud83d\udd343|\u26a1|\ud83d\udfe2|\ud83d\udfe2|\ud83d\udfe2|\ud83e\uddf1\",\n            \"PSF 1ERROR=\ud83d\udfe2|\ud83d\udfe2|\ud83d\udfe2|\ud83d\udd3430|\ud83d\udd0d|\ud83d\udeab|\ud83d\udd343|\u26a1|\ud83d\udfe2|\u26a1|\ud83d\udfe2|\ud83d\udd34\",\n        ];\n\n        for (status, rendered) in exit_values.iter().zip(&exit_values_rendered) {\n            let main_exit_code = status[0];\n            let pipe_exit_code = &status[1..];\n\n            let expected = Some((*rendered).to_string());\n            let actual = ModuleRenderer::new(\"status\")\n                .config(toml::toml! {\n                    [status]\n                    format = \"$symbol$maybe_int\"\n                    symbol = \"\ud83d\udd34\"\n                    success_symbol = \"\ud83d\udfe2\"\n                    not_executable_symbol = \"\ud83d\udeab\"\n                    not_found_symbol = \"\ud83d\udd0d\"\n                    sigint_symbol = \"\ud83e\uddf1\"\n                    signal_symbol = \"\u26a1\"\n                    recognize_signal_code = true\n                    map_symbol = true\n                    pipestatus = true\n                    pipestatus_separator = \"|\"\n                    pipestatus_format = \"PSF $int$common_meaning$signal_name=$pipestatus\"\n                    disabled = false\n                })\n                .status(main_exit_code)\n                .pipestatus(pipe_exit_code)\n                .collect();\n            assert_eq!(expected, actual);\n        }\n    }\n\n    #[test]\n    fn pipestatus_segment_format() {\n        let pipe_exit_code = &[0, 1];\n        let main_exit_code = 1;\n\n        let expected = Some(\"[0]|[1] => <1>\".to_string());\n        let actual = ModuleRenderer::new(\"status\")\n            .config(toml::toml! {\n                [status]\n                format = \"\\\\($status\\\\)\"\n                pipestatus = true\n                pipestatus_separator = \"|\"\n                pipestatus_format = \"$pipestatus => <$status>\"\n                pipestatus_segment_format = \"\\\\[$status\\\\]\"\n                disabled = false\n            })\n            .status(main_exit_code)\n            .pipestatus(pipe_exit_code)\n            .collect();\n        assert_eq!(expected, actual);\n    }\n\n    #[test]\n    fn pipestatus_separator_format() {\n        let pipe_exit_code = &[0, 1, 2];\n        let main_exit_code = 2;\n\n        let style = Style::new().on(Color::Red).fg(Color::White).bold();\n        let sep_style = Style::new().on(Color::Green).fg(Color::White).italic();\n        let expected = Some(format!(\n            \"{}{}{}{}{}\",\n            style.paint(\"[0\"),\n            sep_style.paint(\"|\"),\n            style.paint(\"1\"),\n            sep_style.paint(\"|\"),\n            style.paint(\"2] => <2>\"),\n        ));\n        let actual = ModuleRenderer::new(\"status\")\n            .config(toml::toml! {\n                [status]\n                format = \"\\\\($status\\\\)\"\n                style = \"fg:white bg:red bold\"\n                pipestatus = true\n                pipestatus_separator = \"[|](fg:white bg:green italic)\"\n                pipestatus_format = \"[\\\\[]($style)$pipestatus[\\\\] => <$status>]($style)\"\n                pipestatus_segment_format = \"[$status]($style)\"\n                disabled = false\n            })\n            .status(main_exit_code)\n            .pipestatus(pipe_exit_code)\n            .collect();\n        assert_eq!(expected, actual);\n    }\n\n    #[test]\n    fn pipestatus_width() {\n        let pipe_exit_code = &[0, 1, 2];\n        let main_exit_code = 2;\n\n        let renderer = ModuleRenderer::new(\"status\")\n            .config(toml::toml! {\n                format = \"$fill$status\"\n                [status]\n                style = \"fg:white bg:red bold\"\n                pipestatus = true\n                pipestatus_segment_format = \"[$status](bg:blue fg:yellow)\"\n                disabled = false\n            })\n            .status(main_exit_code)\n            .pipestatus(pipe_exit_code)\n            .width(100);\n        let context = crate::modules::Context::from(renderer);\n        let actual = crate::print::get_prompt(context);\n\n        let mut escaping = false;\n        let mut width = 0;\n        for c in actual.chars() {\n            if c == '\\x1B' {\n                escaping = true;\n            }\n            if escaping {\n                escaping = !c.is_ascii_alphabetic();\n                continue;\n            }\n            width += 1;\n        }\n        assert_eq!(width, 100);\n    }\n\n    #[test]\n    fn pipestatus_segment_format_err() {\n        let pipe_exit_code = &[0, 1, 2];\n        let main_exit_code = 2;\n\n        let expected = Some(format!(\n            \"{}\",\n            Style::new()\n                .on(Color::Red)\n                .fg(Color::White)\n                .bold()\n                .paint(\"[] => <2>\"),\n        ));\n        let actual = ModuleRenderer::new(\"status\")\n            .config(toml::toml! {\n                [status]\n                style = \"fg:white bg:red bold\"\n                pipestatus = true\n                pipestatus_format = \"[\\\\[]($style)$pipestatus[\\\\] => <$status>]($style)\"\n                pipestatus_segment_format = \"${\"\n                disabled = false\n            })\n            .status(main_exit_code)\n            .pipestatus(pipe_exit_code)\n            .collect();\n        assert_eq!(expected, actual);\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "3424e43f8387f91d30854ce830e54a24713e6364",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/starship/src/modules/elm.rs",
    "func": "use super::{Context, Module, ModuleConfig};\n\nuse crate::configs::elm::ElmConfig;\nuse crate::formatter::StringFormatter;\nuse crate::formatter::VersionFormatter;\n\n/// Creates a module with the current Elm version\npub fn module<'a>(context: &'a Context) -> Option<Module<'a>> {\n    let mut module = context.new_module(\"elm\");\n    let config: ElmConfig = ElmConfig::try_load(module.config);\n\n    let is_elm_project = context\n        .try_begin_scan()?\n        .set_files(&config.detect_files)\n        .set_extensions(&config.detect_extensions)\n        .set_folders(&config.detect_folders)\n        .is_match();\n\n    if !is_elm_project {\n        return None;\n    }\n\n    let parsed = StringFormatter::new(config.format).and_then(|formatter| {\n        formatter\n            .map_meta(|var, _| match var {\n                \"symbol\" => Some(config.symbol),\n                _ => None,\n            })\n            .map_style(|variable| match variable {\n                \"style\" => Some(Ok(config.style)),\n                _ => None,\n            })\n            .map(|variable| match variable {\n                \"version\" => {\n                    let elm_version = context.exec_cmd(\"elm\", &[\"--version\"])?.stdout;\n                    VersionFormatter::format_module_version(\n                        module.get_name(),\n                        elm_version.trim(),\n                        config.version_format,\n                    )\n                    .map(Ok)\n                }\n                _ => None,\n            })\n            .parse(None, Some(context))\n    });\n\n    module.set_segments(match parsed {\n        Ok(segments) => segments,\n        Err(error) => {\n            log::warn!(\"Error in module `elm`:\\n{}\", error);\n            return None;\n        }\n    });\n\n    Some(module)\n}\n\n#[cfg(test)]\nmod tests {\n    use crate::test::ModuleRenderer;\n    use nu_ansi_term::Color;\n    use std::fs::{self, File};\n    use std::io;\n\n    #[test]\n    fn folder_without_elm() -> io::Result<()> {\n        let dir = tempfile::tempdir()?;\n        let actual = ModuleRenderer::new(\"elm\").path(dir.path()).collect();\n        let expected = None;\n        assert_eq!(expected, actual);\n        dir.close()\n    }\n\n    #[test]\n    fn folder_with_elm_json() -> io::Result<()> {\n        let dir = tempfile::tempdir()?;\n        File::create(dir.path().join(\"elm.json\"))?.sync_all()?;\n        let actual = ModuleRenderer::new(\"elm\").path(dir.path()).collect();\n        let expected = Some(format!(\"via {}\", Color::Cyan.bold().paint(\"\ud83c\udf33 v0.19.1 \")));\n        assert_eq!(expected, actual);\n        dir.close()\n    }\n\n    #[test]\n    fn folder_with_elm_package_json() -> io::Result<()> {\n        let dir = tempfile::tempdir()?;\n        File::create(dir.path().join(\"elm-package.json\"))?.sync_all()?;\n        let actual = ModuleRenderer::new(\"elm\").path(dir.path()).collect();\n        let expected = Some(format!(\"via {}\", Color::Cyan.bold().paint(\"\ud83c\udf33 v0.19.1 \")));\n        assert_eq!(expected, actual);\n        dir.close()\n    }\n\n    #[test]\n    fn folder_with_elm_version() -> io::Result<()> {\n        let dir = tempfile::tempdir()?;\n        File::create(dir.path().join(\".elm-version\"))?.sync_all()?;\n        let actual = ModuleRenderer::new(\"elm\").path(dir.path()).collect();\n        let expected = Some(format!(\"via {}\", Color::Cyan.bold().paint(\"\ud83c\udf33 v0.19.1 \")));\n        assert_eq!(expected, actual);\n        dir.close()\n    }\n\n    #[test]\n    fn folder_with_elm_stuff_directory() -> io::Result<()> {\n        let dir = tempfile::tempdir()?;\n        let elmstuff = dir.path().join(\"elm-stuff\");\n        fs::create_dir_all(elmstuff)?;\n        let actual = ModuleRenderer::new(\"elm\").path(dir.path()).collect();\n        let expected = Some(format!(\"via {}\", Color::Cyan.bold().paint(\"\ud83c\udf33 v0.19.1 \")));\n        assert_eq!(expected, actual);\n        dir.close()\n    }\n\n    #[test]\n    fn folder_with_elm_file() -> io::Result<()> {\n        let dir = tempfile::tempdir()?;\n        File::create(dir.path().join(\"main.elm\"))?.sync_all()?;\n        let actual = ModuleRenderer::new(\"elm\").path(dir.path()).collect();\n        let expected = Some(format!(\"via {}\", Color::Cyan.bold().paint(\"\ud83c\udf33 v0.19.1 \")));\n        assert_eq!(expected, actual);\n        dir.close()\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "aad924840eb3625e28d65e94edbecc7585d34a98",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/starship/src/modules/rlang.rs",
    "func": "use super::{Context, Module, ModuleConfig};\nuse crate::formatter::VersionFormatter;\n\nuse crate::configs::rlang::RLangConfig;\nuse crate::formatter::StringFormatter;\nuse crate::utils::get_command_string_output;\n\npub fn module<'a>(context: &'a Context) -> Option<Module<'a>> {\n    let mut module = context.new_module(\"rlang\");\n    let config: RLangConfig = RLangConfig::try_load(module.config);\n\n    let is_r_project = context\n        .try_begin_scan()?\n        .set_files(&config.detect_files)\n        .set_extensions(&config.detect_extensions)\n        .set_folders(&config.detect_folders)\n        .is_match();\n    if !is_r_project {\n        return None;\n    }\n\n    let parsed = StringFormatter::new(config.format).and_then(|formatter| {\n        formatter\n            .map_meta(|var, _| match var {\n                \"symbol\" => Some(config.symbol),\n                _ => None,\n            })\n            .map_style(|variable| match variable {\n                \"style\" => Some(Ok(config.style)),\n                _ => None,\n            })\n            .map(|variable| match variable {\n                \"version\" => {\n                    let r_version_string =\n                        get_command_string_output(context.exec_cmd(\"R\", &[\"--version\"])?);\n                    let r_version = parse_r_version(&r_version_string)?;\n                    VersionFormatter::format_module_version(\n                        module.get_name(),\n                        &r_version,\n                        config.version_format,\n                    )\n                    .map(Ok)\n                }\n                _ => None,\n            })\n            .parse(None, Some(context))\n    });\n\n    module.set_segments(match parsed {\n        Ok(segments) => segments,\n        Err(error) => {\n            log::warn!(\"Error in module `rlang`:\\n{}\", error);\n            return None;\n        }\n    });\n\n    Some(module)\n}\n\nfn parse_r_version(r_version: &str) -> Option<String> {\n    r_version\n        .lines()\n        // take first line\n        .next()?\n        // split into [\"R\", \"version\", \"3.6.3\", \"(2020-02-29)\", ...]\n        .split_whitespace()\n        // and pick version entry at index 2, i.e. \"3.6.3\".\n        .nth(2)\n        .map(ToString::to_string)\n}\n\n#[cfg(test)]\nmod tests {\n    use super::parse_r_version;\n    use crate::test::ModuleRenderer;\n    use nu_ansi_term::Color;\n    use std::fs;\n    use std::fs::File;\n    use std::io;\n\n    #[test]\n    fn test_parse_r_version() {\n        let r_v3 = r#\"R version 4.1.0 (2021-05-18) -- \"Camp Pontanezen\"\nCopyright (C) 2021 The R Foundation for Statistical Computing\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\\n\n\nR is free software and comes with ABSOLUTELY NO WARRANTY.\nYou are welcome to redistribute it under the terms of the\nGNU General Public License versions 2 or 3.\nFor more information about these matters see\nhttps://www.gnu.org/licenses/.\"#;\n        assert_eq!(parse_r_version(r_v3), Some(String::from(\"4.1.0\")));\n    }\n\n    #[test]\n    fn folder_with_r_files() -> io::Result<()> {\n        let dir = tempfile::tempdir()?;\n        File::create(dir.path().join(\"analysis.R\"))?.sync_all()?;\n        check_r_render(&dir);\n        dir.close()\n    }\n\n    #[test]\n    fn folder_with_rd_files() -> io::Result<()> {\n        let dir = tempfile::tempdir()?;\n        File::create(dir.path().join(\"analysis.Rd\"))?.sync_all()?;\n        check_r_render(&dir);\n        dir.close()\n    }\n\n    #[test]\n    fn folder_with_rmd_files() -> io::Result<()> {\n        let dir = tempfile::tempdir()?;\n        File::create(dir.path().join(\"analysis.Rmd\"))?.sync_all()?;\n        check_r_render(&dir);\n        dir.close()\n    }\n\n    #[test]\n    fn folder_with_rproj_files() -> io::Result<()> {\n        let dir = tempfile::tempdir()?;\n        File::create(dir.path().join(\"analysis.Rproj\"))?.sync_all()?;\n        check_r_render(&dir);\n        dir.close()\n    }\n\n    #[test]\n    fn folder_with_rsx_files() -> io::Result<()> {\n        let dir = tempfile::tempdir()?;\n        File::create(dir.path().join(\"analysis.Rsx\"))?.sync_all()?;\n        check_r_render(&dir);\n        dir.close()\n    }\n\n    #[test]\n    fn folder_with_description_files() -> io::Result<()> {\n        let dir = tempfile::tempdir()?;\n        File::create(dir.path().join(\"DESCRIPTION\"))?.sync_all()?;\n        check_r_render(&dir);\n        dir.close()\n    }\n\n    #[test]\n    fn folder_with_rproj_user_folder() -> io::Result<()> {\n        let dir = tempfile::tempdir()?;\n        let rprofile = dir.path().join(\".Rproj.user\");\n        fs::create_dir_all(rprofile)?;\n        check_r_render(&dir);\n        dir.close()\n    }\n\n    fn check_r_render(dir: &tempfile::TempDir) {\n        let actual = ModuleRenderer::new(\"rlang\").path(dir.path()).collect();\n        let expected = Some(format!(\"via {}\", Color::Blue.bold().paint(\"\ud83d\udcd0 v4.1.0 \")));\n        assert_eq!(expected, actual);\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "1fc2e5ef7a6d95de135ae36b04ee612c1834bd0a",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/starship/src/configs/swift.rs",
    "func": "use serde::{Deserialize, Serialize};\n\n#[derive(Clone, Deserialize, Serialize)]\n#[cfg_attr(\n    feature = \"config-schema\",\n    derive(schemars::JsonSchema),\n    schemars(deny_unknown_fields)\n)]\n#[serde(default)]\npub struct SwiftConfig<'a> {\n    pub format: &'a str,\n    pub version_format: &'a str,\n    pub symbol: &'a str,\n    pub style: &'a str,\n    pub disabled: bool,\n    pub detect_extensions: Vec<&'a str>,\n    pub detect_files: Vec<&'a str>,\n    pub detect_folders: Vec<&'a str>,\n}\n\nimpl<'a> Default for SwiftConfig<'a> {\n    fn default() -> Self {\n        SwiftConfig {\n            format: \"via [$symbol($version )]($style)\",\n            version_format: \"v${raw}\",\n            symbol: \"\ud83d\udc26 \",\n            style: \"bold 202\",\n            disabled: false,\n            detect_extensions: vec![\"swift\"],\n            detect_files: vec![\"Package.swift\"],\n            detect_folders: vec![],\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "ef2646462bf2a20c4f7947bd949349a8937a6590",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/starship/src/configs/nix_shell.rs",
    "func": "use serde::{Deserialize, Serialize};\n\n#[derive(Clone, Deserialize, Serialize)]\n#[cfg_attr(\n    feature = \"config-schema\",\n    derive(schemars::JsonSchema),\n    schemars(deny_unknown_fields)\n)]\n#[serde(default)]\npub struct NixShellConfig<'a> {\n    pub format: &'a str,\n    pub symbol: &'a str,\n    pub style: &'a str,\n    pub impure_msg: &'a str,\n    pub pure_msg: &'a str,\n    pub unknown_msg: &'a str,\n    pub disabled: bool,\n    pub heuristic: bool,\n}\n\n/* The trailing double spaces in `symbol` are needed to work around issues with\nmultiwidth emoji support in some shells. Please do not file a PR to change this\nunless you can show that your changes do not affect this workaround.  */\nimpl<'a> Default for NixShellConfig<'a> {\n    fn default() -> Self {\n        NixShellConfig {\n            format: \"via [$symbol$state( \\\\($name\\\\))]($style) \",\n            symbol: \"\u2744\ufe0f  \",\n            style: \"bold blue\",\n            impure_msg: \"impure\",\n            pure_msg: \"pure\",\n            unknown_msg: \"\",\n            disabled: false,\n            heuristic: false,\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "c03a08cd8602f3e8a09e6193c448acbe01328d69",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/starship/src/configs/direnv.rs",
    "func": "use serde::{Deserialize, Serialize};\n\n#[derive(Clone, Deserialize, Serialize)]\n#[cfg_attr(\n    feature = \"config-schema\",\n    derive(schemars::JsonSchema),\n    schemars(deny_unknown_fields)\n)]\n#[serde(default)]\npub struct DirenvConfig<'a> {\n    pub format: &'a str,\n    pub symbol: &'a str,\n    pub style: &'a str,\n    pub disabled: bool,\n    pub detect_extensions: Vec<&'a str>,\n    pub detect_files: Vec<&'a str>,\n    pub detect_folders: Vec<&'a str>,\n    pub allowed_msg: &'a str,\n    pub not_allowed_msg: &'a str,\n    pub denied_msg: &'a str,\n    pub loaded_msg: &'a str,\n    pub unloaded_msg: &'a str,\n}\n\nimpl<'a> Default for DirenvConfig<'a> {\n    fn default() -> Self {\n        Self {\n            format: \"[$symbol$loaded/$allowed]($style) \",\n            symbol: \"direnv \",\n            style: \"bold bright-yellow\",\n            disabled: true,\n            detect_extensions: vec![],\n            detect_files: vec![\".envrc\"],\n            detect_folders: vec![],\n            allowed_msg: \"allowed\",\n            not_allowed_msg: \"not allowed\",\n            denied_msg: \"denied\",\n            loaded_msg: \"loaded\",\n            unloaded_msg: \"not loaded\",\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "cb83799ca4855cb68310bd8b74c16a369151d143",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/starship/src/configs/python.rs",
    "func": "use crate::config::VecOr;\n\nuse serde::{Deserialize, Serialize};\n\n#[derive(Clone, Deserialize, Serialize)]\n#[cfg_attr(\n    feature = \"config-schema\",\n    derive(schemars::JsonSchema),\n    schemars(deny_unknown_fields)\n)]\n#[serde(default)]\npub struct PythonConfig<'a> {\n    pub pyenv_version_name: bool,\n    pub pyenv_prefix: &'a str,\n    pub python_binary: VecOr<&'a str>,\n    pub format: &'a str,\n    pub version_format: &'a str,\n    pub style: &'a str,\n    pub symbol: &'a str,\n    pub disabled: bool,\n    pub detect_extensions: Vec<&'a str>,\n    pub detect_files: Vec<&'a str>,\n    pub detect_folders: Vec<&'a str>,\n    pub detect_env_vars: Vec<&'a str>,\n}\n\nimpl<'a> Default for PythonConfig<'a> {\n    fn default() -> Self {\n        PythonConfig {\n            pyenv_version_name: false,\n            pyenv_prefix: \"pyenv \",\n            python_binary: VecOr(vec![\"python\", \"python3\", \"python2\"]),\n            format: \"via [${symbol}${pyenv_prefix}(${version} )(\\\\($virtualenv\\\\) )]($style)\",\n            version_format: \"v${raw}\",\n            style: \"yellow bold\",\n            symbol: \"\ud83d\udc0d \",\n            disabled: false,\n            detect_extensions: vec![\"py\", \"ipynb\"],\n            detect_files: vec![\n                \"requirements.txt\",\n                \".python-version\",\n                \"pyproject.toml\",\n                \"Pipfile\",\n                \"tox.ini\",\n                \"setup.py\",\n                \"__init__.py\",\n                \"pixi.toml\",\n            ],\n            detect_folders: vec![],\n            detect_env_vars: vec![\"VIRTUAL_ENV\"],\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "ae7b76f8be7b4983c034f1b0806aadeadffde58b",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/starship/src/configs/ruby.rs",
    "func": "use serde::{Deserialize, Serialize};\n\n#[derive(Clone, Deserialize, Serialize)]\n#[cfg_attr(\n    feature = \"config-schema\",\n    derive(schemars::JsonSchema),\n    schemars(deny_unknown_fields)\n)]\n#[serde(default)]\npub struct RubyConfig<'a> {\n    pub format: &'a str,\n    pub version_format: &'a str,\n    pub symbol: &'a str,\n    pub style: &'a str,\n    pub disabled: bool,\n    pub detect_extensions: Vec<&'a str>,\n    pub detect_files: Vec<&'a str>,\n    pub detect_folders: Vec<&'a str>,\n    pub detect_variables: Vec<&'a str>,\n}\n\nimpl<'a> Default for RubyConfig<'a> {\n    fn default() -> Self {\n        RubyConfig {\n            format: \"via [$symbol($version )]($style)\",\n            version_format: \"v${raw}\",\n            symbol: \"\ud83d\udc8e \",\n            style: \"bold red\",\n            disabled: false,\n            detect_extensions: vec![\"rb\"],\n            detect_files: vec![\"Gemfile\", \".ruby-version\"],\n            detect_folders: vec![],\n            detect_variables: vec![\"RUBY_VERSION\", \"RBENV_VERSION\"],\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "b4a0241155c94face7304436657fca28cfbad7c8",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/starship/src/configs/helm.rs",
    "func": "use serde::{Deserialize, Serialize};\n\n#[derive(Clone, Deserialize, Serialize)]\n#[cfg_attr(\n    feature = \"config-schema\",\n    derive(schemars::JsonSchema),\n    schemars(deny_unknown_fields)\n)]\n#[serde(default)]\npub struct HelmConfig<'a> {\n    pub format: &'a str,\n    pub version_format: &'a str,\n    pub symbol: &'a str,\n    pub style: &'a str,\n    pub disabled: bool,\n    pub detect_extensions: Vec<&'a str>,\n    pub detect_files: Vec<&'a str>,\n    pub detect_folders: Vec<&'a str>,\n}\n\nimpl<'a> Default for HelmConfig<'a> {\n    fn default() -> Self {\n        HelmConfig {\n            format: \"via [$symbol($version )]($style)\",\n            version_format: \"v${raw}\",\n            symbol: \"\u2388 \",\n            style: \"bold white\",\n            disabled: false,\n            detect_extensions: vec![],\n            detect_files: vec![\"helmfile.yaml\", \"Chart.yaml\"],\n            detect_folders: vec![],\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "9b1ccb5e806ba149ebb8f2795fbf0b2316918cb6",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/starship/src/configs/scala.rs",
    "func": "use serde::{Deserialize, Serialize};\n\n#[derive(Clone, Deserialize, Serialize)]\n#[cfg_attr(\n    feature = \"config-schema\",\n    derive(schemars::JsonSchema),\n    schemars(deny_unknown_fields)\n)]\n#[serde(default)]\npub struct ScalaConfig<'a> {\n    pub format: &'a str,\n    pub version_format: &'a str,\n    pub disabled: bool,\n    pub style: &'a str,\n    pub symbol: &'a str,\n    pub detect_extensions: Vec<&'a str>,\n    pub detect_files: Vec<&'a str>,\n    pub detect_folders: Vec<&'a str>,\n}\n\nimpl<'a> Default for ScalaConfig<'a> {\n    fn default() -> Self {\n        ScalaConfig {\n            format: \"via [$symbol($version )]($style)\",\n            version_format: \"v${raw}\",\n            disabled: false,\n            style: \"red bold\",\n            symbol: \"\ud83c\udd82 \",\n            detect_extensions: vec![\"sbt\", \"scala\"],\n            detect_files: vec![\".scalaenv\", \".sbtenv\", \"build.sbt\"],\n            detect_folders: vec![\".metals\"],\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "75a0016dce64ab908c426f68b2bfcb4d613e07c9",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/starship/src/configs/git_branch.rs",
    "func": "use serde::{Deserialize, Serialize};\n\n#[derive(Clone, Deserialize, Serialize)]\n#[cfg_attr(\n    feature = \"config-schema\",\n    derive(schemars::JsonSchema),\n    schemars(deny_unknown_fields)\n)]\n#[serde(default)]\npub struct GitBranchConfig<'a> {\n    pub format: &'a str,\n    pub symbol: &'a str,\n    pub style: &'a str,\n    pub truncation_length: i64,\n    pub truncation_symbol: &'a str,\n    pub only_attached: bool,\n    pub always_show_remote: bool,\n    pub ignore_branches: Vec<&'a str>,\n    pub disabled: bool,\n}\n\nimpl<'a> Default for GitBranchConfig<'a> {\n    fn default() -> Self {\n        GitBranchConfig {\n            format: \"on [$symbol$branch(:$remote_branch)]($style) \",\n            symbol: \"\ue0a0 \",\n            style: \"bold purple\",\n            truncation_length: i64::MAX,\n            truncation_symbol: \"\u2026\",\n            only_attached: false,\n            always_show_remote: false,\n            ignore_branches: vec![],\n            disabled: false,\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "4e9210b739662e1ee2ac2e013f3ff7fe43dc2253",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/starship/src/configs/git_commit.rs",
    "func": "use serde::{Deserialize, Serialize};\n\n#[derive(Clone, Deserialize, Serialize)]\n#[cfg_attr(\n    feature = \"config-schema\",\n    derive(schemars::JsonSchema),\n    schemars(deny_unknown_fields)\n)]\n#[serde(default)]\npub struct GitCommitConfig<'a> {\n    pub commit_hash_length: usize,\n    pub format: &'a str,\n    pub style: &'a str,\n    pub only_detached: bool,\n    pub disabled: bool,\n    pub tag_symbol: &'a str,\n    pub tag_disabled: bool,\n    pub tag_max_candidates: usize,\n}\n\nimpl<'a> Default for GitCommitConfig<'a> {\n    fn default() -> Self {\n        GitCommitConfig {\n            // be consistent with git by default, which has DEFAULT_ABBREV set to 7\n            commit_hash_length: 7,\n            format: \"[\\\\($hash$tag\\\\)]($style) \",\n            style: \"green bold\",\n            only_detached: true,\n            disabled: false,\n            tag_symbol: \" \ud83c\udff7  \",\n            tag_disabled: true,\n            tag_max_candidates: 0,\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "151ed39cb0ea8e3f6b7af2edefb9cb5adff400cc",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/starship/src/configs/gradle.rs",
    "func": "use serde::{Deserialize, Serialize};\n\n#[derive(Clone, Deserialize, Serialize)]\n#[cfg_attr(\n    feature = \"config-schema\",\n    derive(schemars::JsonSchema),\n    schemars(deny_unknown_fields)\n)]\n#[serde(default)]\npub struct GradleConfig<'a> {\n    pub format: &'a str,\n    pub version_format: &'a str,\n    pub symbol: &'a str,\n    pub style: &'a str,\n    pub disabled: bool,\n    pub recursive: bool,\n    pub detect_extensions: Vec<&'a str>,\n    pub detect_files: Vec<&'a str>,\n    pub detect_folders: Vec<&'a str>,\n}\n\nimpl<'a> Default for GradleConfig<'a> {\n    fn default() -> Self {\n        GradleConfig {\n            format: \"via [$symbol($version )]($style)\",\n            version_format: \"v${raw}\",\n            symbol: \"\ud83c\udd76 \",\n            style: \"bold bright-cyan\",\n            disabled: false,\n            recursive: false,\n            detect_extensions: vec![\"gradle\", \"gradle.kts\"],\n            detect_files: vec![],\n            detect_folders: vec![\"gradle\"],\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "f08b22d8be6cb50f4419d872115956be185da1d0",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bat/src/bin/bat/config.rs",
    "func": "use std::env;\nuse std::ffi::OsString;\nuse std::fs;\nuse std::io::{self, Write};\nuse std::path::PathBuf;\n\nuse crate::directories::PROJECT_DIRS;\n\n#[cfg(not(target_os = \"windows\"))]\nconst DEFAULT_SYSTEM_CONFIG_PREFIX: &str = \"/etc\";\n\n#[cfg(target_os = \"windows\")]\nconst DEFAULT_SYSTEM_CONFIG_PREFIX: &str = \"C:\\\\ProgramData\";\n\npub fn system_config_file() -> PathBuf {\n    let folder = option_env!(\"BAT_SYSTEM_CONFIG_PREFIX\").unwrap_or(DEFAULT_SYSTEM_CONFIG_PREFIX);\n    let mut path = PathBuf::from(folder);\n\n    path.push(\"bat\");\n    path.push(\"config\");\n\n    path\n}\n\npub fn config_file() -> PathBuf {\n    env::var(\"BAT_CONFIG_PATH\")\n        .ok()\n        .map(PathBuf::from)\n        .unwrap_or_else(|| PROJECT_DIRS.config_dir().join(\"config\"))\n}\n\npub fn generate_config_file() -> bat::error::Result<()> {\n    let config_file = config_file();\n    if config_file.is_file() {\n        println!(\n            \"A config file already exists at: {}\",\n            config_file.to_string_lossy()\n        );\n\n        print!(\"Overwrite? (y/N): \");\n        io::stdout().flush()?;\n        let mut decision = String::new();\n        io::stdin().read_line(&mut decision)?;\n\n        if !decision.trim().eq_ignore_ascii_case(\"Y\") {\n            return Ok(());\n        }\n    } else {\n        let config_dir = config_file.parent();\n        match config_dir {\n            Some(path) => fs::create_dir_all(path)?,\n            None => {\n                return Err(format!(\n                    \"Unable to write config file to: {}\",\n                    config_file.to_string_lossy()\n                )\n                .into());\n            }\n        }\n    }\n\n    let default_config = r#\"# This is `bat`s configuration file. Each line either contains a comment or\n# a command-line option that you want to pass to `bat` by default. You can\n# run `bat --help` to get a list of all possible configuration options.\n\n# Specify desired highlighting theme (e.g. \"TwoDark\"). Run `bat --list-themes`\n# for a list of all available themes\n#--theme=\"TwoDark\"\n\n# Enable this to use italic text on the terminal. This is not supported on all\n# terminal emulators (like tmux, by default):\n#--italic-text=always\n\n# Uncomment the following line to disable automatic paging:\n#--paging=never\n\n# Uncomment the following line if you are using less version >= 551 and want to\n# enable mouse scrolling support in `bat` when running inside tmux. This might\n# disable text selection, unless you press shift.\n#--pager=\"less --RAW-CONTROL-CHARS --quit-if-one-screen --mouse\"\n\n# Syntax mappings: map a certain filename pattern to a language.\n#   Example 1: use the C++ syntax for Arduino .ino files\n#   Example 2: Use \".gitignore\"-style highlighting for \".ignore\" files\n#--map-syntax \"*.ino:C++\"\n#--map-syntax \".ignore:Git Ignore\"\n\"#;\n\n    fs::write(&config_file, default_config).map_err(|e| {\n        format!(\n            \"Failed to create config file at '{}': {}\",\n            config_file.to_string_lossy(),\n            e\n        )\n    })?;\n\n    println!(\n        \"Success! Config file written to {}\",\n        config_file.to_string_lossy()\n    );\n\n    Ok(())\n}\n\npub fn get_args_from_config_file() -> Result<Vec<OsString>, shell_words::ParseError> {\n    let mut config = String::new();\n\n    if let Ok(c) = fs::read_to_string(system_config_file()) {\n        config.push_str(&c);\n        config.push('\\n');\n    }\n\n    if let Ok(c) = fs::read_to_string(config_file()) {\n        config.push_str(&c);\n    }\n\n    get_args_from_str(&config)\n}\n\npub fn get_args_from_env_opts_var() -> Option<Result<Vec<OsString>, shell_words::ParseError>> {\n    env::var(\"BAT_OPTS\").ok().map(|s| get_args_from_str(&s))\n}\n\nfn get_args_from_str(content: &str) -> Result<Vec<OsString>, shell_words::ParseError> {\n    let args_per_line = content\n        .split('\\n')\n        .map(|line| line.trim())\n        .filter(|line| !line.is_empty())\n        .filter(|line| !line.starts_with('#'))\n        .map(shell_words::split)\n        .collect::<Result<Vec<_>, _>>()?;\n\n    Ok(args_per_line\n        .iter()\n        .flatten()\n        .map(|line| line.into())\n        .collect())\n}\n\npub fn get_args_from_env_vars() -> Vec<OsString> {\n    [\n        (\"--tabs\", \"BAT_TABS\"),\n        (\"--theme\", bat::theme::env::BAT_THEME),\n        (\"--theme-dark\", bat::theme::env::BAT_THEME_DARK),\n        (\"--theme-light\", bat::theme::env::BAT_THEME_LIGHT),\n        (\"--pager\", \"BAT_PAGER\"),\n        (\"--paging\", \"BAT_PAGING\"),\n        (\"--style\", \"BAT_STYLE\"),\n    ]\n    .iter()\n    .filter_map(|(flag, key)| {\n        env::var(key)\n            .ok()\n            .map(|var| [flag.to_string(), var].join(\"=\"))\n    })\n    .map(|a| a.into())\n    .collect()\n}\n\n#[test]\nfn empty() {\n    let args = get_args_from_str(\"\").unwrap();\n    assert!(args.is_empty());\n}\n\n#[test]\nfn single() {\n    assert_eq!(vec![\"--plain\"], get_args_from_str(\"--plain\").unwrap());\n}\n\n#[test]\nfn multiple() {\n    assert_eq!(\n        vec![\"--plain\", \"--language=cpp\"],\n        get_args_from_str(\"--plain --language=cpp\").unwrap()\n    );\n}\n\n#[test]\nfn quotes() {\n    assert_eq!(\n        vec![\"--theme\", \"Sublime Snazzy\"],\n        get_args_from_str(\"--theme \\\"Sublime Snazzy\\\"\").unwrap()\n    );\n}\n\n#[test]\nfn multi_line() {\n    let config = \"\n    -p\n    --style numbers,changes\n\n    --color=always\n    \";\n    assert_eq!(\n        vec![\"-p\", \"--style\", \"numbers,changes\", \"--color=always\"],\n        get_args_from_str(config).unwrap()\n    );\n}\n\n#[test]\nfn comments() {\n    let config = \"\n    # plain style\n    -p\n\n    # show line numbers and Git modifications\n    --style numbers,changes\n\n    # Always show ANSI colors\n    --color=always\n    \";\n    assert_eq!(\n        vec![\"-p\", \"--style\", \"numbers,changes\", \"--color=always\"],\n        get_args_from_str(config).unwrap()\n    );\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "55b24f580225b018120be9796f15c3a505d3ea58",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/axum/axum-core/src/macros.rs",
    "func": "/// Private API.\n#[cfg(feature = \"tracing\")]\n#[doc(hidden)]\n#[macro_export]\nmacro_rules! __log_rejection {\n    (\n        rejection_type = $ty:ident,\n        body_text = $body_text:expr,\n        status = $status:expr,\n    ) => {\n        {\n            $crate::__private::tracing::event!(\n                target: \"axum::rejection\",\n                $crate::__private::tracing::Level::TRACE,\n                status = $status.as_u16(),\n                body = $body_text,\n                rejection_type = ::std::any::type_name::<$ty>(),\n                \"rejecting request\",\n            );\n        }\n    };\n}\n\n#[cfg(not(feature = \"tracing\"))]\n#[doc(hidden)]\n#[macro_export]\nmacro_rules! __log_rejection {\n    (\n        rejection_type = $ty:ident,\n        body_text = $body_text:expr,\n        status = $status:expr,\n    ) => {};\n}\n\n/// Private API.\n#[doc(hidden)]\n#[macro_export]\nmacro_rules! __define_rejection {\n    (\n        #[status = $status:ident]\n        #[body = $body:expr]\n        $(#[$m:meta])*\n        pub struct $name:ident;\n    ) => {\n        $(#[$m])*\n        #[derive(Debug)]\n        #[non_exhaustive]\n        pub struct $name;\n\n        impl $crate::response::IntoResponse for $name {\n            fn into_response(self) -> $crate::response::Response {\n                $crate::__log_rejection!(\n                    rejection_type = $name,\n                    body_text = $body,\n                    status = http::StatusCode::$status,\n                );\n                (self.status(), $body).into_response()\n            }\n        }\n\n        impl $name {\n            /// Get the response body text used for this rejection.\n            pub fn body_text(&self) -> String {\n                $body.into()\n            }\n\n            /// Get the status code used for this rejection.\n            pub fn status(&self) -> http::StatusCode {\n                http::StatusCode::$status\n            }\n        }\n\n        impl std::fmt::Display for $name {\n            fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n                write!(f, \"{}\", $body)\n            }\n        }\n\n        impl std::error::Error for $name {}\n\n        impl Default for $name {\n            fn default() -> Self {\n                Self\n            }\n        }\n    };\n\n    (\n        #[status = $status:ident]\n        #[body = $body:expr]\n        $(#[$m:meta])*\n        pub struct $name:ident (Error);\n    ) => {\n        $(#[$m])*\n        #[derive(Debug)]\n        pub struct $name(pub(crate) $crate::Error);\n\n        impl $name {\n            pub(crate) fn from_err<E>(err: E) -> Self\n            where\n                E: Into<$crate::BoxError>,\n            {\n                Self($crate::Error::new(err))\n            }\n        }\n\n        impl $crate::response::IntoResponse for $name {\n            fn into_response(self) -> $crate::response::Response {\n                $crate::__log_rejection!(\n                    rejection_type = $name,\n                    body_text = self.body_text(),\n                    status = http::StatusCode::$status,\n                );\n                (self.status(), self.body_text()).into_response()\n            }\n        }\n\n        impl $name {\n            /// Get the response body text used for this rejection.\n            pub fn body_text(&self) -> String {\n                format!(concat!($body, \": {}\"), self.0).into()\n            }\n\n            /// Get the status code used for this rejection.\n            pub fn status(&self) -> http::StatusCode {\n                http::StatusCode::$status\n            }\n        }\n\n        impl std::fmt::Display for $name {\n            fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n                write!(f, \"{}\", $body)\n            }\n        }\n\n        impl std::error::Error for $name {\n            fn source(&self) -> Option<&(dyn std::error::Error + 'static)> {\n                Some(&self.0)\n            }\n        }\n    };\n}\n\n/// Private API.\n#[doc(hidden)]\n#[macro_export]\nmacro_rules! __composite_rejection {\n    (\n        $(#[$m:meta])*\n        pub enum $name:ident {\n            $($variant:ident),+\n            $(,)?\n        }\n    ) => {\n        $(#[$m])*\n        #[derive(Debug)]\n        #[non_exhaustive]\n        pub enum $name {\n            $(\n                #[allow(missing_docs)]\n                $variant($variant)\n            ),+\n        }\n\n        impl $crate::response::IntoResponse for $name {\n            fn into_response(self) -> $crate::response::Response {\n                match self {\n                    $(\n                        Self::$variant(inner) => inner.into_response(),\n                    )+\n                }\n            }\n        }\n\n        impl $name {\n            /// Get the response body text used for this rejection.\n            pub fn body_text(&self) -> String {\n                match self {\n                    $(\n                        Self::$variant(inner) => inner.body_text(),\n                    )+\n                }\n            }\n\n            /// Get the status code used for this rejection.\n            pub fn status(&self) -> http::StatusCode {\n                match self {\n                    $(\n                        Self::$variant(inner) => inner.status(),\n                    )+\n                }\n            }\n        }\n\n        $(\n            impl From<$variant> for $name {\n                fn from(inner: $variant) -> Self {\n                    Self::$variant(inner)\n                }\n            }\n        )+\n\n        impl std::fmt::Display for $name {\n            fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n                match self {\n                    $(\n                        Self::$variant(inner) => write!(f, \"{inner}\"),\n                    )+\n                }\n            }\n        }\n\n        impl std::error::Error for $name {\n            fn source(&self) -> Option<&(dyn std::error::Error + 'static)> {\n                match self {\n                    $(\n                        Self::$variant(inner) => inner.source(),\n                    )+\n                }\n            }\n        }\n    };\n}\n\n#[rustfmt::skip]\nmacro_rules! all_the_tuples {\n    ($name:ident) => {\n        $name!([], T1);\n        $name!([T1], T2);\n        $name!([T1, T2], T3);\n        $name!([T1, T2, T3], T4);\n        $name!([T1, T2, T3, T4], T5);\n        $name!([T1, T2, T3, T4, T5], T6);\n        $name!([T1, T2, T3, T4, T5, T6], T7);\n        $name!([T1, T2, T3, T4, T5, T6, T7], T8);\n        $name!([T1, T2, T3, T4, T5, T6, T7, T8], T9);\n        $name!([T1, T2, T3, T4, T5, T6, T7, T8, T9], T10);\n        $name!([T1, T2, T3, T4, T5, T6, T7, T8, T9, T10], T11);\n        $name!([T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11], T12);\n        $name!([T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12], T13);\n        $name!([T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13], T14);\n        $name!([T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14], T15);\n        $name!([T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15], T16);\n    };\n}\n\nmacro_rules! all_the_tuples_no_last_special_case {\n    ($name:ident) => {\n        $name!(T1);\n        $name!(T1, T2);\n        $name!(T1, T2, T3);\n        $name!(T1, T2, T3, T4);\n        $name!(T1, T2, T3, T4, T5);\n        $name!(T1, T2, T3, T4, T5, T6);\n        $name!(T1, T2, T3, T4, T5, T6, T7);\n        $name!(T1, T2, T3, T4, T5, T6, T7, T8);\n        $name!(T1, T2, T3, T4, T5, T6, T7, T8, T9);\n        $name!(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10);\n        $name!(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11);\n        $name!(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12);\n        $name!(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13);\n        $name!(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14);\n        $name!(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15);\n        $name!(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16);\n    };\n}\n\n/// Private API.\n#[doc(hidden)]\n#[macro_export]\nmacro_rules! __impl_deref {\n    ($ident:ident) => {\n        impl<T> std::ops::Deref for $ident<T> {\n            type Target = T;\n\n            #[inline]\n            fn deref(&self) -> &Self::Target {\n                &self.0\n            }\n        }\n\n        impl<T> std::ops::DerefMut for $ident<T> {\n            #[inline]\n            fn deref_mut(&mut self) -> &mut Self::Target {\n                &mut self.0\n            }\n        }\n    };\n\n    ($ident:ident: $ty:ty) => {\n        impl std::ops::Deref for $ident {\n            type Target = $ty;\n\n            #[inline]\n            fn deref(&self) -> &Self::Target {\n                &self.0\n            }\n        }\n\n        impl std::ops::DerefMut for $ident {\n            #[inline]\n            fn deref_mut(&mut self) -> &mut Self::Target {\n                &mut self.0\n            }\n        }\n    };\n}\n\n#[cfg(test)]\nmod composite_rejection_tests {\n    use self::defs::*;\n    use crate::Error;\n    use std::error::Error as _;\n\n    #[allow(dead_code, unreachable_pub)]\n    mod defs {\n        __define_rejection! {\n            #[status = BAD_REQUEST]\n            #[body = \"error message 1\"]\n            pub struct Inner1;\n        }\n        __define_rejection! {\n            #[status = BAD_REQUEST]\n            #[body = \"error message 2\"]\n            pub struct Inner2(Error);\n        }\n        __composite_rejection! {\n            pub enum Outer { Inner1, Inner2 }\n        }\n    }\n\n    /// The implementation of `.source()` on `Outer` should defer straight to the implementation\n    /// on its inner type instead of returning the inner type itself, because the `Display`\n    /// implementation on `Outer` already forwards to the inner type and so it would result in two\n    /// errors in the chain `Display`ing the same thing.\n    #[test]\n    fn source_gives_inner_source() {\n        let rejection = Outer::Inner1(Inner1);\n        assert!(rejection.source().is_none());\n\n        let msg = \"hello world\";\n        let rejection = Outer::Inner2(Inner2(Error::new(msg)));\n        assert_eq!(rejection.source().unwrap().to_string(), msg);\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "dcca2b0da6cb822e18a2d386fae8fb6c9ec9d404",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/axum/examples/parse-body-based-on-content-type/src/main.rs",
    "func": "//! Provides a RESTful web server managing some Todos.\n//!\n//! Run with\n//!\n//! ```not_rust\n//! cargo run -p example-parse-body-based-on-content-type\n//! ```\n\nuse axum::{\n    extract::{FromRequest, Request},\n    http::{header::CONTENT_TYPE, StatusCode},\n    response::{IntoResponse, Response},\n    routing::post,\n    Form, Json, RequestExt, Router,\n};\nuse serde::{Deserialize, Serialize};\nuse tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt};\n\n#[tokio::main]\nasync fn main() {\n    tracing_subscriber::registry()\n        .with(\n            tracing_subscriber::EnvFilter::try_from_default_env().unwrap_or_else(|_| {\n                format!(\"{}=debug,tower_http=debug\", env!(\"CARGO_CRATE_NAME\")).into()\n            }),\n        )\n        .with(tracing_subscriber::fmt::layer())\n        .init();\n\n    let app = Router::new().route(\"/\", post(handler));\n\n    let listener = tokio::net::TcpListener::bind(\"127.0.0.1:3000\")\n        .await\n        .unwrap();\n    tracing::debug!(\"listening on {}\", listener.local_addr().unwrap());\n    axum::serve(listener, app).await.unwrap();\n}\n\n#[derive(Debug, Serialize, Deserialize)]\nstruct Payload {\n    foo: String,\n}\n\nasync fn handler(JsonOrForm(payload): JsonOrForm<Payload>) {\n    dbg!(payload);\n}\n\nstruct JsonOrForm<T>(T);\n\nimpl<S, T> FromRequest<S> for JsonOrForm<T>\nwhere\n    S: Send + Sync,\n    Json<T>: FromRequest<()>,\n    Form<T>: FromRequest<()>,\n    T: 'static,\n{\n    type Rejection = Response;\n\n    async fn from_request(req: Request, _state: &S) -> Result<Self, Self::Rejection> {\n        let content_type_header = req.headers().get(CONTENT_TYPE);\n        let content_type = content_type_header.and_then(|value| value.to_str().ok());\n\n        if let Some(content_type) = content_type {\n            if content_type.starts_with(\"application/json\") {\n                let Json(payload) = req.extract().await.map_err(IntoResponse::into_response)?;\n                return Ok(Self(payload));\n            }\n\n            if content_type.starts_with(\"application/x-www-form-urlencoded\") {\n                let Form(payload) = req.extract().await.map_err(IntoResponse::into_response)?;\n                return Ok(Self(payload));\n            }\n        }\n\n        Err(StatusCode::UNSUPPORTED_MEDIA_TYPE.into_response())\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "b03ba3aef50420aaec3952043e42c77a6c10f087",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/axum/examples/diesel-async-postgres/src/main.rs",
    "func": "//! Run with\n//!\n//! ```sh\n//! export DATABASE_URL=postgres://localhost/your_db\n//! diesel migration run\n//! cargo run -p example-diesel-async-postgres\n//! ```\n//!\n//! Checkout the [diesel webpage](https://diesel.rs) for\n//! longer guides about diesel\n//!\n//! Checkout the [crates.io source code](https://github.com/rust-lang/crates.io/)\n//! for a real world application using axum and diesel\n\nuse axum::{\n    extract::{FromRef, FromRequestParts, State},\n    http::{request::Parts, StatusCode},\n    response::Json,\n    routing::{get, post},\n    Router,\n};\nuse diesel::prelude::*;\nuse diesel_async::{\n    pooled_connection::AsyncDieselConnectionManager, AsyncPgConnection, RunQueryDsl,\n};\nuse std::net::SocketAddr;\nuse tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt};\n\n// normally part of your generated schema.rs file\ntable! {\n    users (id) {\n        id -> Integer,\n        name -> Text,\n        hair_color -> Nullable<Text>,\n    }\n}\n\n#[derive(serde::Serialize, Selectable, Queryable)]\nstruct User {\n    id: i32,\n    name: String,\n    hair_color: Option<String>,\n}\n\n#[derive(serde::Deserialize, Insertable)]\n#[diesel(table_name = users)]\nstruct NewUser {\n    name: String,\n    hair_color: Option<String>,\n}\n\ntype Pool = bb8::Pool<AsyncDieselConnectionManager<AsyncPgConnection>>;\n\n#[tokio::main]\nasync fn main() {\n    tracing_subscriber::registry()\n        .with(\n            tracing_subscriber::EnvFilter::try_from_default_env()\n                .unwrap_or_else(|_| format!(\"{}=debug\", env!(\"CARGO_CRATE_NAME\")).into()),\n        )\n        .with(tracing_subscriber::fmt::layer())\n        .init();\n\n    let db_url = std::env::var(\"DATABASE_URL\").unwrap();\n\n    // set up connection pool\n    let config = AsyncDieselConnectionManager::<diesel_async::AsyncPgConnection>::new(db_url);\n    let pool = bb8::Pool::builder().build(config).await.unwrap();\n\n    // build our application with some routes\n    let app = Router::new()\n        .route(\"/user/list\", get(list_users))\n        .route(\"/user/create\", post(create_user))\n        .with_state(pool);\n\n    // run it with hyper\n    let addr = SocketAddr::from(([127, 0, 0, 1], 3000));\n    tracing::debug!(\"listening on {addr}\");\n    let listener = tokio::net::TcpListener::bind(addr).await.unwrap();\n    axum::serve(listener, app).await.unwrap();\n}\n\nasync fn create_user(\n    State(pool): State<Pool>,\n    Json(new_user): Json<NewUser>,\n) -> Result<Json<User>, (StatusCode, String)> {\n    let mut conn = pool.get().await.map_err(internal_error)?;\n\n    let res = diesel::insert_into(users::table)\n        .values(new_user)\n        .returning(User::as_returning())\n        .get_result(&mut conn)\n        .await\n        .map_err(internal_error)?;\n    Ok(Json(res))\n}\n\n// we can also write a custom extractor that grabs a connection from the pool\n// which setup is appropriate depends on your application\nstruct DatabaseConnection(\n    bb8::PooledConnection<'static, AsyncDieselConnectionManager<AsyncPgConnection>>,\n);\n\nimpl<S> FromRequestParts<S> for DatabaseConnection\nwhere\n    S: Send + Sync,\n    Pool: FromRef<S>,\n{\n    type Rejection = (StatusCode, String);\n\n    async fn from_request_parts(_parts: &mut Parts, state: &S) -> Result<Self, Self::Rejection> {\n        let pool = Pool::from_ref(state);\n\n        let conn = pool.get_owned().await.map_err(internal_error)?;\n\n        Ok(Self(conn))\n    }\n}\n\nasync fn list_users(\n    DatabaseConnection(mut conn): DatabaseConnection,\n) -> Result<Json<Vec<User>>, (StatusCode, String)> {\n    let res = users::table\n        .select(User::as_select())\n        .load(&mut conn)\n        .await\n        .map_err(internal_error)?;\n    Ok(Json(res))\n}\n\n/// Utility function for mapping any error into a `500 Internal Server Error`\n/// response.\nfn internal_error<E>(err: E) -> (StatusCode, String)\nwhere\n    E: std::error::Error,\n{\n    (StatusCode::INTERNAL_SERVER_ERROR, err.to_string())\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "624d0f1e4a579275b2540438470a1f5a3804f428",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/axum/examples/diesel-postgres/src/main.rs",
    "func": "//! Run with\n//!\n//! ```not_rust\n//! cargo run -p example-diesel-postgres\n//! ```\n//!\n//! Checkout the [diesel webpage](https://diesel.rs) for\n//! longer guides about diesel\n//!\n//! Checkout the [crates.io source code](https://github.com/rust-lang/crates.io/)\n//! for a real world application using axum and diesel\n\nuse axum::{\n    extract::State,\n    http::StatusCode,\n    response::Json,\n    routing::{get, post},\n    Router,\n};\nuse diesel::prelude::*;\nuse diesel_migrations::{embed_migrations, EmbeddedMigrations, MigrationHarness};\nuse std::net::SocketAddr;\nuse tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt};\n\n// this embeds the migrations into the application binary\n// the migration path is relative to the `CARGO_MANIFEST_DIR`\npub const MIGRATIONS: EmbeddedMigrations = embed_migrations!(\"migrations/\");\n\n// normally part of your generated schema.rs file\ntable! {\n    users (id) {\n        id -> Integer,\n        name -> Text,\n        hair_color -> Nullable<Text>,\n    }\n}\n\n#[derive(serde::Serialize, Selectable, Queryable)]\nstruct User {\n    id: i32,\n    name: String,\n    hair_color: Option<String>,\n}\n\n#[derive(serde::Deserialize, Insertable)]\n#[diesel(table_name = users)]\nstruct NewUser {\n    name: String,\n    hair_color: Option<String>,\n}\n\n#[tokio::main]\nasync fn main() {\n    tracing_subscriber::registry()\n        .with(\n            tracing_subscriber::EnvFilter::try_from_default_env()\n                .unwrap_or_else(|_| format!(\"{}=debug\", env!(\"CARGO_CRATE_NAME\")).into()),\n        )\n        .with(tracing_subscriber::fmt::layer())\n        .init();\n\n    let db_url = std::env::var(\"DATABASE_URL\").unwrap();\n\n    // set up connection pool\n    let manager = deadpool_diesel::postgres::Manager::new(db_url, deadpool_diesel::Runtime::Tokio1);\n    let pool = deadpool_diesel::postgres::Pool::builder(manager)\n        .build()\n        .unwrap();\n\n    // run the migrations on server startup\n    {\n        let conn = pool.get().await.unwrap();\n        conn.interact(|conn| conn.run_pending_migrations(MIGRATIONS).map(|_| ()))\n            .await\n            .unwrap()\n            .unwrap();\n    }\n\n    // build our application with some routes\n    let app = Router::new()\n        .route(\"/user/list\", get(list_users))\n        .route(\"/user/create\", post(create_user))\n        .with_state(pool);\n\n    // run it with hyper\n    let addr = SocketAddr::from(([127, 0, 0, 1], 3000));\n    tracing::debug!(\"listening on {addr}\");\n    let listener = tokio::net::TcpListener::bind(addr).await.unwrap();\n    axum::serve(listener, app).await.unwrap();\n}\n\nasync fn create_user(\n    State(pool): State<deadpool_diesel::postgres::Pool>,\n    Json(new_user): Json<NewUser>,\n) -> Result<Json<User>, (StatusCode, String)> {\n    let conn = pool.get().await.map_err(internal_error)?;\n    let res = conn\n        .interact(|conn| {\n            diesel::insert_into(users::table)\n                .values(new_user)\n                .returning(User::as_returning())\n                .get_result(conn)\n        })\n        .await\n        .map_err(internal_error)?\n        .map_err(internal_error)?;\n    Ok(Json(res))\n}\n\nasync fn list_users(\n    State(pool): State<deadpool_diesel::postgres::Pool>,\n) -> Result<Json<Vec<User>>, (StatusCode, String)> {\n    let conn = pool.get().await.map_err(internal_error)?;\n    let res = conn\n        .interact(|conn| users::table.select(User::as_select()).load(conn))\n        .await\n        .map_err(internal_error)?\n        .map_err(internal_error)?;\n    Ok(Json(res))\n}\n\n/// Utility function for mapping any error into a `500 Internal Server Error`\n/// response.\nfn internal_error<E>(err: E) -> (StatusCode, String)\nwhere\n    E: std::error::Error,\n{\n    (StatusCode::INTERNAL_SERVER_ERROR, err.to_string())\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "00798e7201aa4b5c47eeb708817c2817246a6164",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/axum/axum-macros/tests/from_request/fail/unknown_attr_container.rs",
    "func": "use axum_macros::FromRequest;\n\n#[derive(FromRequest)]\n#[from_request(foo)]\nstruct Extractor;\n\nfn main() {}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "01fa3513156c92727669a1f15c971e06a46a7265",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/axum/axum-macros/tests/from_request/pass/state_with_rejection.rs",
    "func": "use axum::{\n    extract::State,\n    response::{IntoResponse, Response},\n    routing::get,\n    Router,\n};\nuse axum_macros::FromRequest;\nuse std::convert::Infallible;\n\nfn main() {\n    let _: axum::Router = Router::new()\n        .route(\"/a\", get(|_: Extractor| async {}))\n        .with_state(AppState::default());\n}\n\n#[derive(Clone, Default, FromRequest)]\n#[from_request(rejection(MyRejection))]\nstruct Extractor {\n    state: State<AppState>,\n}\n\n#[derive(Clone, Default)]\nstruct AppState {}\n\nstruct MyRejection {}\n\nimpl From<Infallible> for MyRejection {\n    fn from(err: Infallible) -> Self {\n        match err {}\n    }\n}\n\nimpl IntoResponse for MyRejection {\n    fn into_response(self) -> Response {\n        ().into_response()\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "2a117e65f64a6cdf5e945c8ae0ef77a6ba714f9f",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/axum/axum-macros/tests/debug_handler/fail/wrong_order.rs",
    "func": "use axum::{http::Uri, Json};\nuse axum_macros::debug_handler;\n\n#[debug_handler]\nasync fn one(_: Json<()>, _: Uri) {}\n\n#[debug_handler]\nasync fn two(_: String, _: Uri) {}\n\nfn main() {}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "62508a1dae7670ee9745cc0ad9f162f3b51e3a85",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/axum/axum-macros/tests/debug_handler/pass/deny_unreachable_code.rs",
    "func": "#![deny(unreachable_code)]\n\nuse axum::extract::Path;\n\n#[axum_macros::debug_handler]\nasync fn handler(Path(_): Path<String>) {}\n\nfn main() {}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "64a60420abae17893d9f7c4357736f2471226fba",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/axum/axum-macros/tests/debug_handler/pass/mut_extractor.rs",
    "func": "use axum_macros::debug_handler;\n\n#[debug_handler]\nasync fn handler(mut foo: String) -> String {\n    foo += \"bar\";\n    foo\n}\n\nfn main() {}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "debdeacbeaae3a4d76f6b7aab03b547a743f47b9",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/axum/axum-macros/tests/debug_handler/pass/returns_self.rs",
    "func": "use axum::response::{IntoResponse, Response};\nuse axum_macros::debug_handler;\n\nstruct A;\n\nimpl A {\n    #[debug_handler]\n    async fn handler() -> Self {\n        A\n    }\n}\n\nimpl IntoResponse for A {\n    fn into_response(self) -> Response {\n        todo!()\n    }\n}\n\nfn main() {}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "86e93af46f6b327cd0e21f29e387fca6f3d0f6c4",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/axum/axum-macros/tests/typed_path/fail/route_not_starting_with_slash_non_empty.rs",
    "func": "use axum_extra::routing::TypedPath;\n\n#[derive(TypedPath)]\n#[typed_path(\"{foo}\")]\nstruct MyPath;\n\nfn main() {}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "87b38755328edec7cd12c5012134807f7a284c9f",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/axum/axum-macros/tests/typed_path/fail/missing_capture.rs",
    "func": "use axum_macros::TypedPath;\nuse serde::Deserialize;\n\n#[derive(TypedPath, Deserialize)]\n#[typed_path(\"/users\")]\nstruct MyPath {\n    id: u32,\n}\n\nfn main() {}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "e052bfa387875f46f37749480c1a2496e8ea1642",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/axum/axum-macros/tests/debug_middleware/fail/takes_next_twice.rs",
    "func": "use axum::{debug_middleware, extract::Request, middleware::Next, response::Response};\n\n#[debug_middleware]\nasync fn my_middleware(request: Request, next: Next, next2: Next) -> Response {\n    let _ = next2;\n    next.run(request).await\n}\n\nfn main() {}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "d4ae10485525077796e5c50451185013fa619bc7",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/axum/axum/benches/benches.rs",
    "func": "#![allow(missing_docs)]\n\nuse axum::{\n    extract::State,\n    routing::{get, post},\n    Extension, Json, Router,\n};\nuse serde::{Deserialize, Serialize};\nuse std::{\n    future::IntoFuture,\n    io::BufRead,\n    process::{Command, Stdio},\n};\n\nfn main() {\n    if on_ci() {\n        install_rewrk();\n    } else {\n        ensure_rewrk_is_installed();\n    }\n\n    benchmark(\"minimal\").run(Router::new);\n\n    benchmark(\"basic\")\n        .path(\"/a/b/c\")\n        .run(|| Router::new().route(\"/a/b/c\", get(|| async { \"Hello, World!\" })));\n\n    benchmark(\"basic-merge\").path(\"/a/b/c\").run(|| {\n        let inner = Router::new().route(\"/a/b/c\", get(|| async { \"Hello, World!\" }));\n        Router::new().merge(inner)\n    });\n\n    benchmark(\"basic-nest\").path(\"/a/b/c\").run(|| {\n        let c = Router::new().route(\"/c\", get(|| async { \"Hello, World!\" }));\n        let b = Router::new().nest(\"/b\", c);\n        Router::new().nest(\"/a\", b)\n    });\n\n    benchmark(\"routing\").path(\"/foo/bar/baz\").run(|| {\n        let mut app = Router::new();\n        for a in 0..10 {\n            for b in 0..10 {\n                for c in 0..10 {\n                    app = app.route(&format!(\"/foo-{a}/bar-{b}/baz-{c}\"), get(|| async {}));\n                }\n            }\n        }\n        app.route(\"/foo/bar/baz\", get(|| async {}))\n    });\n\n    benchmark(\"receive-json\")\n        .method(\"post\")\n        .headers(&[(\"content-type\", \"application/json\")])\n        .body(r#\"{\"n\": 123, \"s\": \"hi there\", \"b\": false}\"#)\n        .run(|| Router::new().route(\"/\", post(|_: Json<Payload>| async {})));\n\n    benchmark(\"send-json\").run(|| {\n        Router::new().route(\n            \"/\",\n            get(|| async {\n                Json(Payload {\n                    n: 123,\n                    s: \"hi there\".to_owned(),\n                    b: false,\n                })\n            }),\n        )\n    });\n\n    let state = AppState {\n        _string: \"aaaaaaaaaaaaaaaaaa\".to_owned(),\n        _vec: Vec::from([\n            \"aaaaaaaaaaaaaaaaaa\".to_owned(),\n            \"bbbbbbbbbbbbbbbbbb\".to_owned(),\n            \"cccccccccccccccccc\".to_owned(),\n        ]),\n    };\n\n    benchmark(\"extension\").run(|| {\n        Router::new()\n            .route(\"/\", get(|_: Extension<AppState>| async {}))\n            .layer(Extension(state.clone()))\n    });\n\n    benchmark(\"state\").run(|| {\n        Router::new()\n            .route(\"/\", get(|_: State<AppState>| async {}))\n            .with_state(state.clone())\n    });\n}\n\n#[derive(Clone)]\nstruct AppState {\n    _string: String,\n    _vec: Vec<String>,\n}\n\n#[derive(Deserialize, Serialize)]\nstruct Payload {\n    n: u32,\n    s: String,\n    b: bool,\n}\n\nfn benchmark(name: &'static str) -> BenchmarkBuilder {\n    BenchmarkBuilder {\n        name,\n        path: None,\n        method: None,\n        headers: None,\n        body: None,\n    }\n}\n\nstruct BenchmarkBuilder {\n    name: &'static str,\n    path: Option<&'static str>,\n    method: Option<&'static str>,\n    headers: Option<&'static [(&'static str, &'static str)]>,\n    body: Option<&'static str>,\n}\n\nmacro_rules! config_method {\n    ($name:ident, $ty:ty) => {\n        fn $name(mut self, $name: $ty) -> Self {\n            self.$name = Some($name);\n            self\n        }\n    };\n}\n\nimpl BenchmarkBuilder {\n    config_method!(path, &'static str);\n    config_method!(method, &'static str);\n    config_method!(headers, &'static [(&'static str, &'static str)]);\n    config_method!(body, &'static str);\n\n    fn run<F>(self, f: F)\n    where\n        F: FnOnce() -> Router<()>,\n    {\n        // support only running some benchmarks with\n        // ```\n        // cargo bench -- routing send-json\n        // ```\n        let args = std::env::args().collect::<Vec<_>>();\n        if args.len() != 1 {\n            let names = &args[1..args.len() - 1];\n            if !names.is_empty() && !names.contains(&self.name.to_owned()) {\n                return;\n            }\n        }\n\n        let app = f();\n\n        let rt = tokio::runtime::Builder::new_multi_thread()\n            .enable_all()\n            .build()\n            .unwrap();\n\n        let listener = rt\n            .block_on(tokio::net::TcpListener::bind(\"0.0.0.0:0\"))\n            .unwrap();\n        let addr = listener.local_addr().unwrap();\n\n        std::thread::spawn(move || {\n            rt.block_on(axum::serve(listener, app).into_future())\n                .unwrap();\n        });\n\n        let mut cmd = Command::new(\"rewrk\");\n        cmd.stdout(Stdio::piped());\n\n        cmd.arg(\"--host\");\n        cmd.arg(format!(\"http://{addr}{}\", self.path.unwrap_or(\"\")));\n\n        cmd.args([\"--connections\", \"10\"]);\n        cmd.args([\"--threads\", \"10\"]);\n\n        if on_ci() {\n            // don't slow down CI by running the benchmarks for too long\n            // but do run them for a bit\n            cmd.args([\"--duration\", \"1s\"]);\n        } else {\n            cmd.args([\"--duration\", \"10s\"]);\n        }\n\n        if let Some(method) = self.method {\n            cmd.args([\"--method\", method]);\n        }\n\n        for (key, value) in self.headers.into_iter().flatten() {\n            cmd.arg(\"--header\");\n            cmd.arg(format!(\"{key}: {value}\"));\n        }\n\n        if let Some(body) = self.body {\n            cmd.args([\"--body\", body]);\n        }\n\n        eprintln!(\"Running {:?} benchmark\", self.name);\n\n        // indent output from `rewrk` so it's easier to read when running multiple benchmarks\n        let mut child = cmd.spawn().unwrap();\n        let stdout = child.stdout.take().unwrap();\n        let stdout = std::io::BufReader::new(stdout);\n        for line in stdout.lines() {\n            let line = line.unwrap();\n            println!(\"  {line}\");\n        }\n\n        let status = child.wait().unwrap();\n\n        if !status.success() {\n            eprintln!(\"`rewrk` command failed\");\n            std::process::exit(status.code().unwrap());\n        }\n    }\n}\n\nfn install_rewrk() {\n    println!(\"installing rewrk\");\n    let mut cmd = Command::new(\"cargo\");\n    cmd.args([\n        \"install\",\n        \"rewrk\",\n        \"--git\",\n        \"https://github.com/ChillFish8/rewrk.git\",\n    ]);\n    let status = cmd\n        .status()\n        .unwrap_or_else(|_| panic!(\"failed to install rewrk\"));\n    if !status.success() {\n        panic!(\"failed to install rewrk\");\n    }\n}\n\nfn ensure_rewrk_is_installed() {\n    let mut cmd = Command::new(\"rewrk\");\n    cmd.arg(\"--help\");\n    cmd.stdout(Stdio::null());\n    cmd.stderr(Stdio::null());\n    cmd.status().unwrap_or_else(|_| {\n        panic!(\"rewrk is not installed. See https://github.com/lnx-search/rewrk\")\n    });\n}\n\nfn on_ci() -> bool {\n    std::env::var(\"GITHUB_ACTIONS\").is_ok()\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "246f36f5e6c78f15e50303fdb52485dc38b109e1",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/axum/axum/src/test_helpers/counting_cloneable_state.rs",
    "func": "use std::sync::{\n    atomic::{AtomicBool, AtomicUsize, Ordering},\n    Arc,\n};\n\npub(crate) struct CountingCloneableState {\n    state: Arc<InnerState>,\n}\n\nstruct InnerState {\n    setup_done: AtomicBool,\n    count: AtomicUsize,\n}\n\nimpl CountingCloneableState {\n    pub(crate) fn new() -> Self {\n        let inner_state = InnerState {\n            setup_done: AtomicBool::new(false),\n            count: AtomicUsize::new(0),\n        };\n        CountingCloneableState {\n            state: Arc::new(inner_state),\n        }\n    }\n\n    pub(crate) fn setup_done(&self) {\n        self.state.setup_done.store(true, Ordering::SeqCst);\n    }\n\n    pub(crate) fn count(&self) -> usize {\n        self.state.count.load(Ordering::SeqCst)\n    }\n}\n\nimpl Clone for CountingCloneableState {\n    fn clone(&self) -> Self {\n        let state = self.state.clone();\n        if state.setup_done.load(Ordering::SeqCst) {\n            let bt = std::backtrace::Backtrace::force_capture();\n            let bt = bt\n                .to_string()\n                .lines()\n                .filter(|line| line.contains(\"axum\") || line.contains(\"./src\"))\n                .collect::<Vec<_>>()\n                .join(\"\\n\");\n            println!(\"AppState::Clone:\\n===============\\n{bt}\\n\");\n            state.count.fetch_add(1, Ordering::SeqCst);\n        }\n\n        CountingCloneableState { state }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "ab56a1cc92d90d7d78a3e6d859f77bac561ce300",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/axum/axum/src/body/mod.rs",
    "func": "//! HTTP body utilities.\n\n#[doc(no_inline)]\npub use http_body::Body as HttpBody;\n\n#[doc(no_inline)]\npub use bytes::Bytes;\n\n#[doc(inline)]\npub use axum_core::body::{Body, BodyDataStream};\n\nuse http_body_util::{BodyExt, Limited};\n\n/// Converts [`Body`] into [`Bytes`] and limits the maximum size of the body.\n///\n/// # Example\n///\n/// ```rust\n/// use axum::body::{to_bytes, Body};\n///\n/// # async fn foo() -> Result<(), axum_core::Error> {\n/// let body = Body::from(vec![1, 2, 3]);\n/// // Use `usize::MAX` if you don't care about the maximum size.\n/// let bytes = to_bytes(body, usize::MAX).await?;\n/// assert_eq!(&bytes[..], &[1, 2, 3]);\n/// # Ok(())\n/// # }\n/// ```\n///\n/// You can detect if the limit was hit by checking the source of the error:\n///\n/// ```rust\n/// use axum::body::{to_bytes, Body};\n/// use http_body_util::LengthLimitError;\n///\n/// # #[tokio::main]\n/// # async fn main() {\n/// let body = Body::from(vec![1, 2, 3]);\n/// match to_bytes(body, 1).await {\n///     Ok(_bytes) => panic!(\"should have hit the limit\"),\n///     Err(err) => {\n///         let source = std::error::Error::source(&err).unwrap();\n///         assert!(source.is::<LengthLimitError>());\n///     }\n/// }\n/// # }\n/// ```\npub async fn to_bytes(body: Body, limit: usize) -> Result<Bytes, axum_core::Error> {\n    Limited::new(body, limit)\n        .collect()\n        .await\n        .map(|col| col.to_bytes())\n        .map_err(axum_core::Error::new)\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "9457973ac80c982f9f9f5052c50cc4d849b76210",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/axum/axum/src/extract/ws.rs",
    "func": "//! Handle WebSocket connections.\n//!\n//! # Example\n//!\n//! ```\n//! use axum::{\n//!     extract::ws::{WebSocketUpgrade, WebSocket},\n//!     routing::any,\n//!     response::{IntoResponse, Response},\n//!     Router,\n//! };\n//!\n//! let app = Router::new().route(\"/ws\", any(handler));\n//!\n//! async fn handler(ws: WebSocketUpgrade) -> Response {\n//!     ws.on_upgrade(handle_socket)\n//! }\n//!\n//! async fn handle_socket(mut socket: WebSocket) {\n//!     while let Some(msg) = socket.recv().await {\n//!         let msg = if let Ok(msg) = msg {\n//!             msg\n//!         } else {\n//!             // client disconnected\n//!             return;\n//!         };\n//!\n//!         if socket.send(msg).await.is_err() {\n//!             // client disconnected\n//!             return;\n//!         }\n//!     }\n//! }\n//! # let _: Router = app;\n//! ```\n//!\n//! # Passing data and/or state to an `on_upgrade` callback\n//!\n//! ```\n//! use axum::{\n//!     extract::{ws::{WebSocketUpgrade, WebSocket}, State},\n//!     response::Response,\n//!     routing::any,\n//!     Router,\n//! };\n//!\n//! #[derive(Clone)]\n//! struct AppState {\n//!     // ...\n//! }\n//!\n//! async fn handler(ws: WebSocketUpgrade, State(state): State<AppState>) -> Response {\n//!     ws.on_upgrade(|socket| handle_socket(socket, state))\n//! }\n//!\n//! async fn handle_socket(socket: WebSocket, state: AppState) {\n//!     // ...\n//! }\n//!\n//! let app = Router::new()\n//!     .route(\"/ws\", any(handler))\n//!     .with_state(AppState { /* ... */ });\n//! # let _: Router = app;\n//! ```\n//!\n//! # Read and write concurrently\n//!\n//! If you need to read and write concurrently from a [`WebSocket`] you can use\n//! [`StreamExt::split`]:\n//!\n//! ```rust,no_run\n//! use axum::{Error, extract::ws::{WebSocket, Message}};\n//! use futures_util::{sink::SinkExt, stream::{StreamExt, SplitSink, SplitStream}};\n//!\n//! async fn handle_socket(mut socket: WebSocket) {\n//!     let (mut sender, mut receiver) = socket.split();\n//!\n//!     tokio::spawn(write(sender));\n//!     tokio::spawn(read(receiver));\n//! }\n//!\n//! async fn read(receiver: SplitStream<WebSocket>) {\n//!     // ...\n//! }\n//!\n//! async fn write(sender: SplitSink<WebSocket, Message>) {\n//!     // ...\n//! }\n//! ```\n//!\n//! [`StreamExt::split`]: https://docs.rs/futures/0.3.17/futures/stream/trait.StreamExt.html#method.split\n\nuse self::rejection::*;\nuse super::FromRequestParts;\nuse crate::{body::Bytes, response::Response, Error};\nuse axum_core::body::Body;\nuse futures_util::{\n    sink::{Sink, SinkExt},\n    stream::{Stream, StreamExt},\n};\nuse http::{\n    header::{self, HeaderMap, HeaderName, HeaderValue},\n    request::Parts,\n    Method, StatusCode, Version,\n};\nuse hyper_util::rt::TokioIo;\nuse sha1::{Digest, Sha1};\nuse std::{\n    borrow::Cow,\n    future::Future,\n    pin::Pin,\n    task::{Context, Poll},\n};\nuse tokio_tungstenite::{\n    tungstenite::{\n        self as ts,\n        protocol::{self, WebSocketConfig},\n    },\n    WebSocketStream,\n};\n\n/// Extractor for establishing WebSocket connections.\n///\n/// For HTTP/1.1 requests, this extractor requires the request method to be `GET`;\n/// in later versions, `CONNECT` is used instead.\n/// To support both, it should be used with [`any`](crate::routing::any).\n///\n/// See the [module docs](self) for an example.\n///\n/// [`MethodFilter`]: crate::routing::MethodFilter\n#[cfg_attr(docsrs, doc(cfg(feature = \"ws\")))]\npub struct WebSocketUpgrade<F = DefaultOnFailedUpgrade> {\n    config: WebSocketConfig,\n    /// The chosen protocol sent in the `Sec-WebSocket-Protocol` header of the response.\n    protocol: Option<HeaderValue>,\n    /// `None` if HTTP/2+ WebSockets are used.\n    sec_websocket_key: Option<HeaderValue>,\n    on_upgrade: hyper::upgrade::OnUpgrade,\n    on_failed_upgrade: F,\n    sec_websocket_protocol: Option<HeaderValue>,\n}\n\nimpl<F> std::fmt::Debug for WebSocketUpgrade<F> {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        f.debug_struct(\"WebSocketUpgrade\")\n            .field(\"config\", &self.config)\n            .field(\"protocol\", &self.protocol)\n            .field(\"sec_websocket_key\", &self.sec_websocket_key)\n            .field(\"sec_websocket_protocol\", &self.sec_websocket_protocol)\n            .finish_non_exhaustive()\n    }\n}\n\nimpl<F> WebSocketUpgrade<F> {\n    /// The target minimum size of the write buffer to reach before writing the data\n    /// to the underlying stream.\n    ///\n    /// The default value is 128 KiB.\n    ///\n    /// If set to `0` each message will be eagerly written to the underlying stream.\n    /// It is often more optimal to allow them to buffer a little, hence the default value.\n    ///\n    /// Note: [`flush`](SinkExt::flush) will always fully write the buffer regardless.\n    pub fn write_buffer_size(mut self, size: usize) -> Self {\n        self.config.write_buffer_size = size;\n        self\n    }\n\n    /// The max size of the write buffer in bytes. Setting this can provide backpressure\n    /// in the case the write buffer is filling up due to write errors.\n    ///\n    /// The default value is unlimited.\n    ///\n    /// Note: The write buffer only builds up past [`write_buffer_size`](Self::write_buffer_size)\n    /// when writes to the underlying stream are failing. So the **write buffer can not\n    /// fill up if you are not observing write errors even if not flushing**.\n    ///\n    /// Note: Should always be at least [`write_buffer_size + 1 message`](Self::write_buffer_size)\n    /// and probably a little more depending on error handling strategy.\n    pub fn max_write_buffer_size(mut self, max: usize) -> Self {\n        self.config.max_write_buffer_size = max;\n        self\n    }\n\n    /// Set the maximum message size (defaults to 64 megabytes)\n    pub fn max_message_size(mut self, max: usize) -> Self {\n        self.config.max_message_size = Some(max);\n        self\n    }\n\n    /// Set the maximum frame size (defaults to 16 megabytes)\n    pub fn max_frame_size(mut self, max: usize) -> Self {\n        self.config.max_frame_size = Some(max);\n        self\n    }\n\n    /// Allow server to accept unmasked frames (defaults to false)\n    pub fn accept_unmasked_frames(mut self, accept: bool) -> Self {\n        self.config.accept_unmasked_frames = accept;\n        self\n    }\n\n    /// Set the known protocols.\n    ///\n    /// If the protocol name specified by `Sec-WebSocket-Protocol` header\n    /// to match any of them, the upgrade response will include `Sec-WebSocket-Protocol` header and\n    /// return the protocol name.\n    ///\n    /// The protocols should be listed in decreasing order of preference: if the client offers\n    /// multiple protocols that the server could support, the server will pick the first one in\n    /// this list.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use axum::{\n    ///     extract::ws::{WebSocketUpgrade, WebSocket},\n    ///     routing::any,\n    ///     response::{IntoResponse, Response},\n    ///     Router,\n    /// };\n    ///\n    /// let app = Router::new().route(\"/ws\", any(handler));\n    ///\n    /// async fn handler(ws: WebSocketUpgrade) -> Response {\n    ///     ws.protocols([\"graphql-ws\", \"graphql-transport-ws\"])\n    ///         .on_upgrade(|socket| async {\n    ///             // ...\n    ///         })\n    /// }\n    /// # let _: Router = app;\n    /// ```\n    pub fn protocols<I>(mut self, protocols: I) -> Self\n    where\n        I: IntoIterator,\n        I::Item: Into<Cow<'static, str>>,\n    {\n        if let Some(req_protocols) = self\n            .sec_websocket_protocol\n            .as_ref()\n            .and_then(|p| p.to_str().ok())\n        {\n            self.protocol = protocols\n                .into_iter()\n                // FIXME: This will often allocate a new `String` and so is less efficient than it\n                // could be. But that can't be fixed without breaking changes to the public API.\n                .map(Into::into)\n                .find(|protocol| {\n                    req_protocols\n                        .split(',')\n                        .any(|req_protocol| req_protocol.trim() == protocol)\n                })\n                .map(|protocol| match protocol {\n                    Cow::Owned(s) => HeaderValue::from_str(&s).unwrap(),\n                    Cow::Borrowed(s) => HeaderValue::from_static(s),\n                });\n        }\n\n        self\n    }\n\n    /// Provide a callback to call if upgrading the connection fails.\n    ///\n    /// The connection upgrade is performed in a background task. If that fails this callback\n    /// will be called.\n    ///\n    /// By default any errors will be silently ignored.\n    ///\n    /// # Example\n    ///\n    /// ```\n    /// use axum::{\n    ///     extract::{WebSocketUpgrade},\n    ///     response::Response,\n    /// };\n    ///\n    /// async fn handler(ws: WebSocketUpgrade) -> Response {\n    ///     ws.on_failed_upgrade(|error| {\n    ///         report_error(error);\n    ///     })\n    ///     .on_upgrade(|socket| async { /* ... */ })\n    /// }\n    /// #\n    /// # fn report_error(_: axum::Error) {}\n    /// ```\n    pub fn on_failed_upgrade<C>(self, callback: C) -> WebSocketUpgrade<C>\n    where\n        C: OnFailedUpgrade,\n    {\n        WebSocketUpgrade {\n            config: self.config,\n            protocol: self.protocol,\n            sec_websocket_key: self.sec_websocket_key,\n            on_upgrade: self.on_upgrade,\n            on_failed_upgrade: callback,\n            sec_websocket_protocol: self.sec_websocket_protocol,\n        }\n    }\n\n    /// Finalize upgrading the connection and call the provided callback with\n    /// the stream.\n    #[must_use = \"to set up the WebSocket connection, this response must be returned\"]\n    pub fn on_upgrade<C, Fut>(self, callback: C) -> Response\n    where\n        C: FnOnce(WebSocket) -> Fut + Send + 'static,\n        Fut: Future<Output = ()> + Send + 'static,\n        F: OnFailedUpgrade,\n    {\n        let on_upgrade = self.on_upgrade;\n        let config = self.config;\n        let on_failed_upgrade = self.on_failed_upgrade;\n\n        let protocol = self.protocol.clone();\n\n        tokio::spawn(async move {\n            let upgraded = match on_upgrade.await {\n                Ok(upgraded) => upgraded,\n                Err(err) => {\n                    on_failed_upgrade.call(Error::new(err));\n                    return;\n                }\n            };\n            let upgraded = TokioIo::new(upgraded);\n\n            let socket =\n                WebSocketStream::from_raw_socket(upgraded, protocol::Role::Server, Some(config))\n                    .await;\n            let socket = WebSocket {\n                inner: socket,\n                protocol,\n            };\n            callback(socket).await;\n        });\n\n        if let Some(sec_websocket_key) = &self.sec_websocket_key {\n            // If `sec_websocket_key` was `Some`, we are using HTTP/1.1.\n\n            #[allow(clippy::declare_interior_mutable_const)]\n            const UPGRADE: HeaderValue = HeaderValue::from_static(\"upgrade\");\n            #[allow(clippy::declare_interior_mutable_const)]\n            const WEBSOCKET: HeaderValue = HeaderValue::from_static(\"websocket\");\n\n            let mut builder = Response::builder()\n                .status(StatusCode::SWITCHING_PROTOCOLS)\n                .header(header::CONNECTION, UPGRADE)\n                .header(header::UPGRADE, WEBSOCKET)\n                .header(\n                    header::SEC_WEBSOCKET_ACCEPT,\n                    sign(sec_websocket_key.as_bytes()),\n                );\n\n            if let Some(protocol) = self.protocol {\n                builder = builder.header(header::SEC_WEBSOCKET_PROTOCOL, protocol);\n            }\n\n            builder.body(Body::empty()).unwrap()\n        } else {\n            // Otherwise, we are HTTP/2+. As established in RFC 9113 section 8.5, we just respond\n            // with a 2XX with an empty body:\n            // <https://datatracker.ietf.org/doc/html/rfc9113#name-the-connect-method>.\n            Response::new(Body::empty())\n        }\n    }\n}\n\n/// What to do when a connection upgrade fails.\n///\n/// See [`WebSocketUpgrade::on_failed_upgrade`] for more details.\npub trait OnFailedUpgrade: Send + 'static {\n    /// Call the callback.\n    fn call(self, error: Error);\n}\n\nimpl<F> OnFailedUpgrade for F\nwhere\n    F: FnOnce(Error) + Send + 'static,\n{\n    fn call(self, error: Error) {\n        self(error)\n    }\n}\n\n/// The default `OnFailedUpgrade` used by `WebSocketUpgrade`.\n///\n/// It simply ignores the error.\n#[non_exhaustive]\n#[derive(Debug)]\npub struct DefaultOnFailedUpgrade;\n\nimpl OnFailedUpgrade for DefaultOnFailedUpgrade {\n    #[inline]\n    fn call(self, _error: Error) {}\n}\n\nimpl<S> FromRequestParts<S> for WebSocketUpgrade<DefaultOnFailedUpgrade>\nwhere\n    S: Send + Sync,\n{\n    type Rejection = WebSocketUpgradeRejection;\n\n    async fn from_request_parts(parts: &mut Parts, _state: &S) -> Result<Self, Self::Rejection> {\n        let sec_websocket_key = if parts.version <= Version::HTTP_11 {\n            if parts.method != Method::GET {\n                return Err(MethodNotGet.into());\n            }\n\n            if !header_contains(&parts.headers, header::CONNECTION, \"upgrade\") {\n                return Err(InvalidConnectionHeader.into());\n            }\n\n            if !header_eq(&parts.headers, header::UPGRADE, \"websocket\") {\n                return Err(InvalidUpgradeHeader.into());\n            }\n\n            Some(\n                parts\n                    .headers\n                    .get(header::SEC_WEBSOCKET_KEY)\n                    .ok_or(WebSocketKeyHeaderMissing)?\n                    .clone(),\n            )\n        } else {\n            if parts.method != Method::CONNECT {\n                return Err(MethodNotConnect.into());\n            }\n\n            // if this feature flag is disabled, we won\u2019t be receiving an HTTP/2 request to begin\n            // with.\n            #[cfg(feature = \"http2\")]\n            if parts\n                .extensions\n                .get::<hyper::ext::Protocol>()\n                .map_or(true, |p| p.as_str() != \"websocket\")\n            {\n                return Err(InvalidProtocolPseudoheader.into());\n            }\n\n            None\n        };\n\n        if !header_eq(&parts.headers, header::SEC_WEBSOCKET_VERSION, \"13\") {\n            return Err(InvalidWebSocketVersionHeader.into());\n        }\n\n        let on_upgrade = parts\n            .extensions\n            .remove::<hyper::upgrade::OnUpgrade>()\n            .ok_or(ConnectionNotUpgradable)?;\n\n        let sec_websocket_protocol = parts.headers.get(header::SEC_WEBSOCKET_PROTOCOL).cloned();\n\n        Ok(Self {\n            config: Default::default(),\n            protocol: None,\n            sec_websocket_key,\n            on_upgrade,\n            sec_websocket_protocol,\n            on_failed_upgrade: DefaultOnFailedUpgrade,\n        })\n    }\n}\n\nfn header_eq(headers: &HeaderMap, key: HeaderName, value: &'static str) -> bool {\n    if let Some(header) = headers.get(&key) {\n        header.as_bytes().eq_ignore_ascii_case(value.as_bytes())\n    } else {\n        false\n    }\n}\n\nfn header_contains(headers: &HeaderMap, key: HeaderName, value: &'static str) -> bool {\n    let header = if let Some(header) = headers.get(&key) {\n        header\n    } else {\n        return false;\n    };\n\n    if let Ok(header) = std::str::from_utf8(header.as_bytes()) {\n        header.to_ascii_lowercase().contains(value)\n    } else {\n        false\n    }\n}\n\n/// A stream of WebSocket messages.\n///\n/// See [the module level documentation](self) for more details.\n#[derive(Debug)]\npub struct WebSocket {\n    inner: WebSocketStream<TokioIo<hyper::upgrade::Upgraded>>,\n    protocol: Option<HeaderValue>,\n}\n\nimpl WebSocket {\n    /// Receive another message.\n    ///\n    /// Returns `None` if the stream has closed.\n    pub async fn recv(&mut self) -> Option<Result<Message, Error>> {\n        self.next().await\n    }\n\n    /// Send a message.\n    pub async fn send(&mut self, msg: Message) -> Result<(), Error> {\n        self.inner\n            .send(msg.into_tungstenite())\n            .await\n            .map_err(Error::new)\n    }\n\n    /// Return the selected WebSocket subprotocol, if one has been chosen.\n    pub fn protocol(&self) -> Option<&HeaderValue> {\n        self.protocol.as_ref()\n    }\n}\n\nimpl Stream for WebSocket {\n    type Item = Result<Message, Error>;\n\n    fn poll_next(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Option<Self::Item>> {\n        loop {\n            match futures_util::ready!(self.inner.poll_next_unpin(cx)) {\n                Some(Ok(msg)) => {\n                    if let Some(msg) = Message::from_tungstenite(msg) {\n                        return Poll::Ready(Some(Ok(msg)));\n                    }\n                }\n                Some(Err(err)) => return Poll::Ready(Some(Err(Error::new(err)))),\n                None => return Poll::Ready(None),\n            }\n        }\n    }\n}\n\nimpl Sink<Message> for WebSocket {\n    type Error = Error;\n\n    fn poll_ready(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Result<(), Self::Error>> {\n        Pin::new(&mut self.inner).poll_ready(cx).map_err(Error::new)\n    }\n\n    fn start_send(mut self: Pin<&mut Self>, item: Message) -> Result<(), Self::Error> {\n        Pin::new(&mut self.inner)\n            .start_send(item.into_tungstenite())\n            .map_err(Error::new)\n    }\n\n    fn poll_flush(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Result<(), Self::Error>> {\n        Pin::new(&mut self.inner).poll_flush(cx).map_err(Error::new)\n    }\n\n    fn poll_close(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Result<(), Self::Error>> {\n        Pin::new(&mut self.inner).poll_close(cx).map_err(Error::new)\n    }\n}\n\n/// Status code used to indicate why an endpoint is closing the WebSocket connection.\npub type CloseCode = u16;\n\n/// A struct representing the close command.\n#[derive(Debug, Clone, Eq, PartialEq)]\npub struct CloseFrame<'t> {\n    /// The reason as a code.\n    pub code: CloseCode,\n    /// The reason as text string.\n    pub reason: Cow<'t, str>,\n}\n\n/// A WebSocket message.\n//\n// This code comes from https://github.com/snapview/tungstenite-rs/blob/master/src/protocol/message.rs and is under following license:\n// Copyright (c) 2017 Alexey Galakhov\n// Copyright (c) 2016 Jason Housley\n//\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation the rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in\n// all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n// THE SOFTWARE.\n#[derive(Debug, Eq, PartialEq, Clone)]\npub enum Message {\n    /// A text WebSocket message\n    Text(String),\n    /// A binary WebSocket message\n    Binary(Vec<u8>),\n    /// A ping message with the specified payload\n    ///\n    /// The payload here must have a length less than 125 bytes.\n    ///\n    /// Ping messages will be automatically responded to by the server, so you do not have to worry\n    /// about dealing with them yourself.\n    Ping(Vec<u8>),\n    /// A pong message with the specified payload\n    ///\n    /// The payload here must have a length less than 125 bytes.\n    ///\n    /// Pong messages will be automatically sent to the client if a ping message is received, so\n    /// you do not have to worry about constructing them yourself unless you want to implement a\n    /// [unidirectional heartbeat](https://tools.ietf.org/html/rfc6455#section-5.5.3).\n    Pong(Vec<u8>),\n    /// A close message with the optional close frame.\n    ///\n    /// You may \"uncleanly\" close a WebSocket connection at any time\n    /// by simply dropping the [`WebSocket`].\n    /// However, you may also use the graceful closing protocol, in which\n    /// 1. peer A sends a close frame, and does not send any further messages;\n    /// 2. peer B responds with a close frame, and does not send any further messages;\n    /// 3. peer A processes the remaining messages sent by peer B, before finally\n    /// 4. both peers close the connection.\n    ///\n    /// After sending a close frame,\n    /// you may still read messages,\n    /// but attempts to send another message will error.\n    /// After receiving a close frame,\n    /// axum will automatically respond with a close frame if necessary\n    /// (you do not have to deal with this yourself).\n    /// Since no further messages will be received,\n    /// you may either do nothing\n    /// or explicitly drop the connection.\n    Close(Option<CloseFrame<'static>>),\n}\n\nimpl Message {\n    fn into_tungstenite(self) -> ts::Message {\n        match self {\n            Self::Text(text) => ts::Message::Text(text),\n            Self::Binary(binary) => ts::Message::Binary(binary),\n            Self::Ping(ping) => ts::Message::Ping(ping),\n            Self::Pong(pong) => ts::Message::Pong(pong),\n            Self::Close(Some(close)) => ts::Message::Close(Some(ts::protocol::CloseFrame {\n                code: ts::protocol::frame::coding::CloseCode::from(close.code),\n                reason: close.reason,\n            })),\n            Self::Close(None) => ts::Message::Close(None),\n        }\n    }\n\n    fn from_tungstenite(message: ts::Message) -> Option<Self> {\n        match message {\n            ts::Message::Text(text) => Some(Self::Text(text)),\n            ts::Message::Binary(binary) => Some(Self::Binary(binary)),\n            ts::Message::Ping(ping) => Some(Self::Ping(ping)),\n            ts::Message::Pong(pong) => Some(Self::Pong(pong)),\n            ts::Message::Close(Some(close)) => Some(Self::Close(Some(CloseFrame {\n                code: close.code.into(),\n                reason: close.reason,\n            }))),\n            ts::Message::Close(None) => Some(Self::Close(None)),\n            // we can ignore `Frame` frames as recommended by the tungstenite maintainers\n            // https://github.com/snapview/tungstenite-rs/issues/268\n            ts::Message::Frame(_) => None,\n        }\n    }\n\n    /// Consume the WebSocket and return it as binary data.\n    pub fn into_data(self) -> Vec<u8> {\n        match self {\n            Self::Text(string) => string.into_bytes(),\n            Self::Binary(data) | Self::Ping(data) | Self::Pong(data) => data,\n            Self::Close(None) => Vec::new(),\n            Self::Close(Some(frame)) => frame.reason.into_owned().into_bytes(),\n        }\n    }\n\n    /// Attempt to consume the WebSocket message and convert it to a String.\n    pub fn into_text(self) -> Result<String, Error> {\n        match self {\n            Self::Text(string) => Ok(string),\n            Self::Binary(data) | Self::Ping(data) | Self::Pong(data) => Ok(String::from_utf8(data)\n                .map_err(|err| err.utf8_error())\n                .map_err(Error::new)?),\n            Self::Close(None) => Ok(String::new()),\n            Self::Close(Some(frame)) => Ok(frame.reason.into_owned()),\n        }\n    }\n\n    /// Attempt to get a &str from the WebSocket message,\n    /// this will try to convert binary data to utf8.\n    pub fn to_text(&self) -> Result<&str, Error> {\n        match *self {\n            Self::Text(ref string) => Ok(string),\n            Self::Binary(ref data) | Self::Ping(ref data) | Self::Pong(ref data) => {\n                Ok(std::str::from_utf8(data).map_err(Error::new)?)\n            }\n            Self::Close(None) => Ok(\"\"),\n            Self::Close(Some(ref frame)) => Ok(&frame.reason),\n        }\n    }\n}\n\nimpl From<String> for Message {\n    fn from(string: String) -> Self {\n        Message::Text(string)\n    }\n}\n\nimpl<'s> From<&'s str> for Message {\n    fn from(string: &'s str) -> Self {\n        Message::Text(string.into())\n    }\n}\n\nimpl<'b> From<&'b [u8]> for Message {\n    fn from(data: &'b [u8]) -> Self {\n        Message::Binary(data.into())\n    }\n}\n\nimpl From<Vec<u8>> for Message {\n    fn from(data: Vec<u8>) -> Self {\n        Message::Binary(data)\n    }\n}\n\nimpl From<Message> for Vec<u8> {\n    fn from(msg: Message) -> Self {\n        msg.into_data()\n    }\n}\n\nfn sign(key: &[u8]) -> HeaderValue {\n    use base64::engine::Engine as _;\n\n    let mut sha1 = Sha1::default();\n    sha1.update(key);\n    sha1.update(&b\"258EAFA5-E914-47DA-95CA-C5AB0DC85B11\"[..]);\n    let b64 = Bytes::from(base64::engine::general_purpose::STANDARD.encode(sha1.finalize()));\n    HeaderValue::from_maybe_shared(b64).expect(\"base64 is a valid value\")\n}\n\npub mod rejection {\n    //! WebSocket specific rejections.\n\n    use axum_core::__composite_rejection as composite_rejection;\n    use axum_core::__define_rejection as define_rejection;\n\n    define_rejection! {\n        #[status = METHOD_NOT_ALLOWED]\n        #[body = \"Request method must be `GET`\"]\n        /// Rejection type for [`WebSocketUpgrade`](super::WebSocketUpgrade).\n        pub struct MethodNotGet;\n    }\n\n    define_rejection! {\n        #[status = METHOD_NOT_ALLOWED]\n        #[body = \"Request method must be `CONNECT`\"]\n        /// Rejection type for [`WebSocketUpgrade`](super::WebSocketUpgrade).\n        pub struct MethodNotConnect;\n    }\n\n    define_rejection! {\n        #[status = BAD_REQUEST]\n        #[body = \"Connection header did not include 'upgrade'\"]\n        /// Rejection type for [`WebSocketUpgrade`](super::WebSocketUpgrade).\n        pub struct InvalidConnectionHeader;\n    }\n\n    define_rejection! {\n        #[status = BAD_REQUEST]\n        #[body = \"`Upgrade` header did not include 'websocket'\"]\n        /// Rejection type for [`WebSocketUpgrade`](super::WebSocketUpgrade).\n        pub struct InvalidUpgradeHeader;\n    }\n\n    define_rejection! {\n        #[status = BAD_REQUEST]\n        #[body = \"`:protocol` pseudo-header did not include 'websocket'\"]\n        /// Rejection type for [`WebSocketUpgrade`](super::WebSocketUpgrade).\n        pub struct InvalidProtocolPseudoheader;\n    }\n\n    define_rejection! {\n        #[status = BAD_REQUEST]\n        #[body = \"`Sec-WebSocket-Version` header did not include '13'\"]\n        /// Rejection type for [`WebSocketUpgrade`](super::WebSocketUpgrade).\n        pub struct InvalidWebSocketVersionHeader;\n    }\n\n    define_rejection! {\n        #[status = BAD_REQUEST]\n        #[body = \"`Sec-WebSocket-Key` header missing\"]\n        /// Rejection type for [`WebSocketUpgrade`](super::WebSocketUpgrade).\n        pub struct WebSocketKeyHeaderMissing;\n    }\n\n    define_rejection! {\n        #[status = UPGRADE_REQUIRED]\n        #[body = \"WebSocket request couldn't be upgraded since no upgrade state was present\"]\n        /// Rejection type for [`WebSocketUpgrade`](super::WebSocketUpgrade).\n        ///\n        /// This rejection is returned if the connection cannot be upgraded for example if the\n        /// request is HTTP/1.0.\n        ///\n        /// See [MDN] for more details about connection upgrades.\n        ///\n        /// [MDN]: https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Upgrade\n        pub struct ConnectionNotUpgradable;\n    }\n\n    composite_rejection! {\n        /// Rejection used for [`WebSocketUpgrade`](super::WebSocketUpgrade).\n        ///\n        /// Contains one variant for each way the [`WebSocketUpgrade`](super::WebSocketUpgrade)\n        /// extractor can fail.\n        pub enum WebSocketUpgradeRejection {\n            MethodNotGet,\n            MethodNotConnect,\n            InvalidConnectionHeader,\n            InvalidUpgradeHeader,\n            InvalidProtocolPseudoheader,\n            InvalidWebSocketVersionHeader,\n            WebSocketKeyHeaderMissing,\n            ConnectionNotUpgradable,\n        }\n    }\n}\n\npub mod close_code {\n    //! Constants for [`CloseCode`]s.\n    //!\n    //! [`CloseCode`]: super::CloseCode\n\n    /// Indicates a normal closure, meaning that the purpose for which the connection was\n    /// established has been fulfilled.\n    pub const NORMAL: u16 = 1000;\n\n    /// Indicates that an endpoint is \"going away\", such as a server going down or a browser having\n    /// navigated away from a page.\n    pub const AWAY: u16 = 1001;\n\n    /// Indicates that an endpoint is terminating the connection due to a protocol error.\n    pub const PROTOCOL: u16 = 1002;\n\n    /// Indicates that an endpoint is terminating the connection because it has received a type of\n    /// data that it cannot accept.\n    ///\n    /// For example, an endpoint MAY send this if it understands only text data, but receives a binary message.\n    pub const UNSUPPORTED: u16 = 1003;\n\n    /// Indicates that no status code was included in a closing frame.\n    pub const STATUS: u16 = 1005;\n\n    /// Indicates an abnormal closure.\n    pub const ABNORMAL: u16 = 1006;\n\n    /// Indicates that an endpoint is terminating the connection because it has received data\n    /// within a message that was not consistent with the type of the message.\n    ///\n    /// For example, an endpoint received non-UTF-8 RFC3629 data within a text message.\n    pub const INVALID: u16 = 1007;\n\n    /// Indicates that an endpoint is terminating the connection because it has received a message\n    /// that violates its policy.\n    ///\n    /// This is a generic status code that can be returned when there is\n    /// no other more suitable status code (e.g., `UNSUPPORTED` or `SIZE`) or if there is a need to\n    /// hide specific details about the policy.\n    pub const POLICY: u16 = 1008;\n\n    /// Indicates that an endpoint is terminating the connection because it has received a message\n    /// that is too big for it to process.\n    pub const SIZE: u16 = 1009;\n\n    /// Indicates that an endpoint (client) is terminating the connection because the server\n    /// did not respond to extension negotiation correctly.\n    ///\n    /// Specifically, the client has expected the server to negotiate one or more extension(s),\n    /// but the server didn't return them in the response message of the WebSocket handshake.\n    /// The list of extensions that are needed should be given as the reason for closing.\n    /// Note that this status code is not used by the server,\n    /// because it can fail the WebSocket handshake instead.\n    pub const EXTENSION: u16 = 1010;\n\n    /// Indicates that a server is terminating the connection because it encountered an unexpected\n    /// condition that prevented it from fulfilling the request.\n    pub const ERROR: u16 = 1011;\n\n    /// Indicates that the server is restarting.\n    pub const RESTART: u16 = 1012;\n\n    /// Indicates that the server is overloaded and the client should either connect to a different\n    /// IP (when multiple targets exist), or reconnect to the same IP when a user has performed an\n    /// action.\n    pub const AGAIN: u16 = 1013;\n}\n\n#[cfg(test)]\nmod tests {\n    use std::future::ready;\n\n    use super::*;\n    use crate::{routing::any, test_helpers::spawn_service, Router};\n    use http::{Request, Version};\n    use http_body_util::BodyExt as _;\n    use hyper_util::rt::TokioExecutor;\n    use tokio::io::{AsyncRead, AsyncWrite};\n    use tokio::net::TcpStream;\n    use tokio_tungstenite::tungstenite;\n    use tower::ServiceExt;\n\n    #[crate::test]\n    async fn rejects_http_1_0_requests() {\n        let svc = any(|ws: Result<WebSocketUpgrade, WebSocketUpgradeRejection>| {\n            let rejection = ws.unwrap_err();\n            assert!(matches!(\n                rejection,\n                WebSocketUpgradeRejection::ConnectionNotUpgradable(_)\n            ));\n            std::future::ready(())\n        });\n\n        let req = Request::builder()\n            .version(Version::HTTP_10)\n            .method(Method::GET)\n            .header(\"upgrade\", \"websocket\")\n            .header(\"connection\", \"Upgrade\")\n            .header(\"sec-websocket-key\", \"6D69KGBOr4Re+Nj6zx9aQA==\")\n            .header(\"sec-websocket-version\", \"13\")\n            .body(Body::empty())\n            .unwrap();\n\n        let res = svc.oneshot(req).await.unwrap();\n\n        assert_eq!(res.status(), StatusCode::OK);\n    }\n\n    #[allow(dead_code)]\n    fn default_on_failed_upgrade() {\n        async fn handler(ws: WebSocketUpgrade) -> Response {\n            ws.on_upgrade(|_| async {})\n        }\n        let _: Router = Router::new().route(\"/\", any(handler));\n    }\n\n    #[allow(dead_code)]\n    fn on_failed_upgrade() {\n        async fn handler(ws: WebSocketUpgrade) -> Response {\n            ws.on_failed_upgrade(|_error: Error| println!(\"oops!\"))\n                .on_upgrade(|_| async {})\n        }\n        let _: Router = Router::new().route(\"/\", any(handler));\n    }\n\n    #[crate::test]\n    async fn integration_test() {\n        let addr = spawn_service(echo_app());\n        let (socket, _response) = tokio_tungstenite::connect_async(format!(\"ws://{addr}/echo\"))\n            .await\n            .unwrap();\n        test_echo_app(socket).await;\n    }\n\n    #[crate::test]\n    #[cfg(feature = \"http2\")]\n    async fn http2() {\n        let addr = spawn_service(echo_app());\n        let io = TokioIo::new(TcpStream::connect(addr).await.unwrap());\n        let (mut send_request, conn) =\n            hyper::client::conn::http2::Builder::new(TokioExecutor::new())\n                .handshake(io)\n                .await\n                .unwrap();\n\n        // Wait a little for the SETTINGS frame to go through\u2026\n        for _ in 0..10 {\n            tokio::task::yield_now().await;\n        }\n        assert!(conn.is_extended_connect_protocol_enabled());\n        tokio::spawn(async {\n            conn.await.unwrap();\n        });\n\n        let req = Request::builder()\n            .method(Method::CONNECT)\n            .extension(hyper::ext::Protocol::from_static(\"websocket\"))\n            .uri(\"/echo\")\n            .header(\"sec-websocket-version\", \"13\")\n            .header(\"Host\", \"server.example.com\")\n            .body(Body::empty())\n            .unwrap();\n\n        let response = send_request.send_request(req).await.unwrap();\n        let status = response.status();\n        if status != 200 {\n            let body = response.into_body().collect().await.unwrap().to_bytes();\n            let body = std::str::from_utf8(&body).unwrap();\n            panic!(\"response status was {status}: {body}\");\n        }\n        let upgraded = hyper::upgrade::on(response).await.unwrap();\n        let upgraded = TokioIo::new(upgraded);\n        let socket = WebSocketStream::from_raw_socket(upgraded, protocol::Role::Client, None).await;\n        test_echo_app(socket).await;\n    }\n\n    fn echo_app() -> Router {\n        async fn handle_socket(mut socket: WebSocket) {\n            while let Some(Ok(msg)) = socket.recv().await {\n                match msg {\n                    Message::Text(_) | Message::Binary(_) | Message::Close(_) => {\n                        if socket.send(msg).await.is_err() {\n                            break;\n                        }\n                    }\n                    Message::Ping(_) | Message::Pong(_) => {\n                        // tungstenite will respond to pings automatically\n                    }\n                }\n            }\n        }\n\n        Router::new().route(\n            \"/echo\",\n            any(|ws: WebSocketUpgrade| ready(ws.on_upgrade(handle_socket))),\n        )\n    }\n\n    async fn test_echo_app<S: AsyncRead + AsyncWrite + Unpin>(mut socket: WebSocketStream<S>) {\n        let input = tungstenite::Message::Text(\"foobar\".to_owned());\n        socket.send(input.clone()).await.unwrap();\n        let output = socket.next().await.unwrap().unwrap();\n        assert_eq!(input, output);\n\n        socket\n            .send(tungstenite::Message::Ping(\"ping\".to_owned().into_bytes()))\n            .await\n            .unwrap();\n        let output = socket.next().await.unwrap().unwrap();\n        assert_eq!(\n            output,\n            tungstenite::Message::Pong(\"ping\".to_owned().into_bytes())\n        );\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "f116dfb5cc5b2fa36aae322cf0d358b51d0a209b",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/axum/axum/src/extract/path/de.rs",
    "func": "use super::{ErrorKind, PathDeserializationError};\nuse crate::util::PercentDecodedStr;\nuse serde::{\n    de::{self, DeserializeSeed, EnumAccess, Error, MapAccess, SeqAccess, VariantAccess, Visitor},\n    forward_to_deserialize_any, Deserializer,\n};\nuse std::{any::type_name, sync::Arc};\n\nmacro_rules! unsupported_type {\n    ($trait_fn:ident) => {\n        fn $trait_fn<V>(self, _: V) -> Result<V::Value, Self::Error>\n        where\n            V: Visitor<'de>,\n        {\n            Err(PathDeserializationError::unsupported_type(type_name::<\n                V::Value,\n            >()))\n        }\n    };\n}\n\nmacro_rules! parse_single_value {\n    ($trait_fn:ident, $visit_fn:ident, $ty:literal) => {\n        fn $trait_fn<V>(self, visitor: V) -> Result<V::Value, Self::Error>\n        where\n            V: Visitor<'de>,\n        {\n            if self.url_params.len() != 1 {\n                return Err(PathDeserializationError::wrong_number_of_parameters()\n                    .got(self.url_params.len())\n                    .expected(1));\n            }\n\n            let value = self.url_params[0].1.parse().map_err(|_| {\n                PathDeserializationError::new(ErrorKind::ParseError {\n                    value: self.url_params[0].1.as_str().to_owned(),\n                    expected_type: $ty,\n                })\n            })?;\n            visitor.$visit_fn(value)\n        }\n    };\n}\n\npub(crate) struct PathDeserializer<'de> {\n    url_params: &'de [(Arc<str>, PercentDecodedStr)],\n}\n\nimpl<'de> PathDeserializer<'de> {\n    #[inline]\n    pub(crate) fn new(url_params: &'de [(Arc<str>, PercentDecodedStr)]) -> Self {\n        PathDeserializer { url_params }\n    }\n}\n\nimpl<'de> Deserializer<'de> for PathDeserializer<'de> {\n    type Error = PathDeserializationError;\n\n    unsupported_type!(deserialize_bytes);\n    unsupported_type!(deserialize_option);\n    unsupported_type!(deserialize_identifier);\n    unsupported_type!(deserialize_ignored_any);\n\n    parse_single_value!(deserialize_bool, visit_bool, \"bool\");\n    parse_single_value!(deserialize_i8, visit_i8, \"i8\");\n    parse_single_value!(deserialize_i16, visit_i16, \"i16\");\n    parse_single_value!(deserialize_i32, visit_i32, \"i32\");\n    parse_single_value!(deserialize_i64, visit_i64, \"i64\");\n    parse_single_value!(deserialize_i128, visit_i128, \"i128\");\n    parse_single_value!(deserialize_u8, visit_u8, \"u8\");\n    parse_single_value!(deserialize_u16, visit_u16, \"u16\");\n    parse_single_value!(deserialize_u32, visit_u32, \"u32\");\n    parse_single_value!(deserialize_u64, visit_u64, \"u64\");\n    parse_single_value!(deserialize_u128, visit_u128, \"u128\");\n    parse_single_value!(deserialize_f32, visit_f32, \"f32\");\n    parse_single_value!(deserialize_f64, visit_f64, \"f64\");\n    parse_single_value!(deserialize_string, visit_string, \"String\");\n    parse_single_value!(deserialize_byte_buf, visit_string, \"String\");\n    parse_single_value!(deserialize_char, visit_char, \"char\");\n\n    fn deserialize_any<V>(self, v: V) -> Result<V::Value, Self::Error>\n    where\n        V: Visitor<'de>,\n    {\n        self.deserialize_str(v)\n    }\n\n    fn deserialize_str<V>(self, visitor: V) -> Result<V::Value, Self::Error>\n    where\n        V: Visitor<'de>,\n    {\n        if self.url_params.len() != 1 {\n            return Err(PathDeserializationError::wrong_number_of_parameters()\n                .got(self.url_params.len())\n                .expected(1));\n        }\n        let key = &self.url_params[0].0;\n        let value = &self.url_params[0].1;\n        visitor\n            .visit_borrowed_str(value)\n            .map_err(|e: PathDeserializationError| {\n                if let ErrorKind::Message(message) = &e.kind {\n                    PathDeserializationError::new(ErrorKind::DeserializeError {\n                        key: key.to_string(),\n                        value: value.as_str().to_owned(),\n                        message: message.to_owned(),\n                    })\n                } else {\n                    e\n                }\n            })\n    }\n\n    fn deserialize_unit<V>(self, visitor: V) -> Result<V::Value, Self::Error>\n    where\n        V: Visitor<'de>,\n    {\n        visitor.visit_unit()\n    }\n\n    fn deserialize_unit_struct<V>(\n        self,\n        _name: &'static str,\n        visitor: V,\n    ) -> Result<V::Value, Self::Error>\n    where\n        V: Visitor<'de>,\n    {\n        visitor.visit_unit()\n    }\n\n    fn deserialize_newtype_struct<V>(\n        self,\n        _name: &'static str,\n        visitor: V,\n    ) -> Result<V::Value, Self::Error>\n    where\n        V: Visitor<'de>,\n    {\n        visitor.visit_newtype_struct(self)\n    }\n\n    fn deserialize_seq<V>(self, visitor: V) -> Result<V::Value, Self::Error>\n    where\n        V: Visitor<'de>,\n    {\n        visitor.visit_seq(SeqDeserializer {\n            params: self.url_params,\n            idx: 0,\n        })\n    }\n\n    fn deserialize_tuple<V>(self, len: usize, visitor: V) -> Result<V::Value, Self::Error>\n    where\n        V: Visitor<'de>,\n    {\n        if self.url_params.len() != len {\n            return Err(PathDeserializationError::wrong_number_of_parameters()\n                .got(self.url_params.len())\n                .expected(len));\n        }\n        visitor.visit_seq(SeqDeserializer {\n            params: self.url_params,\n            idx: 0,\n        })\n    }\n\n    fn deserialize_tuple_struct<V>(\n        self,\n        _name: &'static str,\n        len: usize,\n        visitor: V,\n    ) -> Result<V::Value, Self::Error>\n    where\n        V: Visitor<'de>,\n    {\n        if self.url_params.len() != len {\n            return Err(PathDeserializationError::wrong_number_of_parameters()\n                .got(self.url_params.len())\n                .expected(len));\n        }\n        visitor.visit_seq(SeqDeserializer {\n            params: self.url_params,\n            idx: 0,\n        })\n    }\n\n    fn deserialize_map<V>(self, visitor: V) -> Result<V::Value, Self::Error>\n    where\n        V: Visitor<'de>,\n    {\n        visitor.visit_map(MapDeserializer {\n            params: self.url_params,\n            value: None,\n            key: None,\n        })\n    }\n\n    fn deserialize_struct<V>(\n        self,\n        _name: &'static str,\n        _fields: &'static [&'static str],\n        visitor: V,\n    ) -> Result<V::Value, Self::Error>\n    where\n        V: Visitor<'de>,\n    {\n        self.deserialize_map(visitor)\n    }\n\n    fn deserialize_enum<V>(\n        self,\n        _name: &'static str,\n        _variants: &'static [&'static str],\n        visitor: V,\n    ) -> Result<V::Value, Self::Error>\n    where\n        V: Visitor<'de>,\n    {\n        if self.url_params.len() != 1 {\n            return Err(PathDeserializationError::wrong_number_of_parameters()\n                .got(self.url_params.len())\n                .expected(1));\n        }\n\n        visitor.visit_enum(EnumDeserializer {\n            value: &self.url_params[0].1,\n        })\n    }\n}\n\nstruct MapDeserializer<'de> {\n    params: &'de [(Arc<str>, PercentDecodedStr)],\n    key: Option<KeyOrIdx<'de>>,\n    value: Option<&'de PercentDecodedStr>,\n}\n\nimpl<'de> MapAccess<'de> for MapDeserializer<'de> {\n    type Error = PathDeserializationError;\n\n    fn next_key_seed<K>(&mut self, seed: K) -> Result<Option<K::Value>, Self::Error>\n    where\n        K: DeserializeSeed<'de>,\n    {\n        match self.params.split_first() {\n            Some(((key, value), tail)) => {\n                self.value = Some(value);\n                self.params = tail;\n                self.key = Some(KeyOrIdx::Key(key));\n                seed.deserialize(KeyDeserializer { key }).map(Some)\n            }\n            None => Ok(None),\n        }\n    }\n\n    fn next_value_seed<V>(&mut self, seed: V) -> Result<V::Value, Self::Error>\n    where\n        V: DeserializeSeed<'de>,\n    {\n        match self.value.take() {\n            Some(value) => seed.deserialize(ValueDeserializer {\n                key: self.key.take(),\n                value,\n            }),\n            None => Err(PathDeserializationError::custom(\"value is missing\")),\n        }\n    }\n}\n\nstruct KeyDeserializer<'de> {\n    key: &'de str,\n}\n\nmacro_rules! parse_key {\n    ($trait_fn:ident) => {\n        fn $trait_fn<V>(self, visitor: V) -> Result<V::Value, Self::Error>\n        where\n            V: Visitor<'de>,\n        {\n            visitor.visit_str(&self.key)\n        }\n    };\n}\n\nimpl<'de> Deserializer<'de> for KeyDeserializer<'de> {\n    type Error = PathDeserializationError;\n\n    parse_key!(deserialize_identifier);\n    parse_key!(deserialize_str);\n    parse_key!(deserialize_string);\n\n    fn deserialize_any<V>(self, _visitor: V) -> Result<V::Value, Self::Error>\n    where\n        V: Visitor<'de>,\n    {\n        Err(PathDeserializationError::custom(\"Unexpected key type\"))\n    }\n\n    forward_to_deserialize_any! {\n        bool i8 i16 i32 i64 i128 u8 u16 u32 u64 u128 f32 f64 char bytes\n        byte_buf option unit unit_struct seq tuple\n        tuple_struct map newtype_struct struct enum ignored_any\n    }\n}\n\nmacro_rules! parse_value {\n    ($trait_fn:ident, $visit_fn:ident, $ty:literal) => {\n        fn $trait_fn<V>(mut self, visitor: V) -> Result<V::Value, Self::Error>\n        where\n            V: Visitor<'de>,\n        {\n            let v = self.value.parse().map_err(|_| {\n                if let Some(key) = self.key.take() {\n                    let kind = match key {\n                        KeyOrIdx::Key(key) => ErrorKind::ParseErrorAtKey {\n                            key: key.to_owned(),\n                            value: self.value.as_str().to_owned(),\n                            expected_type: $ty,\n                        },\n                        KeyOrIdx::Idx { idx: index, key: _ } => ErrorKind::ParseErrorAtIndex {\n                            index,\n                            value: self.value.as_str().to_owned(),\n                            expected_type: $ty,\n                        },\n                    };\n                    PathDeserializationError::new(kind)\n                } else {\n                    PathDeserializationError::new(ErrorKind::ParseError {\n                        value: self.value.as_str().to_owned(),\n                        expected_type: $ty,\n                    })\n                }\n            })?;\n            visitor.$visit_fn(v)\n        }\n    };\n}\n\n#[derive(Debug)]\nstruct ValueDeserializer<'de> {\n    key: Option<KeyOrIdx<'de>>,\n    value: &'de PercentDecodedStr,\n}\n\nimpl<'de> Deserializer<'de> for ValueDeserializer<'de> {\n    type Error = PathDeserializationError;\n\n    unsupported_type!(deserialize_map);\n    unsupported_type!(deserialize_identifier);\n\n    parse_value!(deserialize_bool, visit_bool, \"bool\");\n    parse_value!(deserialize_i8, visit_i8, \"i8\");\n    parse_value!(deserialize_i16, visit_i16, \"i16\");\n    parse_value!(deserialize_i32, visit_i32, \"i32\");\n    parse_value!(deserialize_i64, visit_i64, \"i64\");\n    parse_value!(deserialize_i128, visit_i128, \"i128\");\n    parse_value!(deserialize_u8, visit_u8, \"u8\");\n    parse_value!(deserialize_u16, visit_u16, \"u16\");\n    parse_value!(deserialize_u32, visit_u32, \"u32\");\n    parse_value!(deserialize_u64, visit_u64, \"u64\");\n    parse_value!(deserialize_u128, visit_u128, \"u128\");\n    parse_value!(deserialize_f32, visit_f32, \"f32\");\n    parse_value!(deserialize_f64, visit_f64, \"f64\");\n    parse_value!(deserialize_string, visit_string, \"String\");\n    parse_value!(deserialize_byte_buf, visit_string, \"String\");\n    parse_value!(deserialize_char, visit_char, \"char\");\n\n    fn deserialize_any<V>(self, v: V) -> Result<V::Value, Self::Error>\n    where\n        V: Visitor<'de>,\n    {\n        self.deserialize_str(v)\n    }\n\n    fn deserialize_str<V>(self, visitor: V) -> Result<V::Value, Self::Error>\n    where\n        V: Visitor<'de>,\n    {\n        visitor\n            .visit_borrowed_str(self.value)\n            .map_err(|e: PathDeserializationError| {\n                if let (ErrorKind::Message(message), Some(key)) = (&e.kind, self.key.as_ref()) {\n                    PathDeserializationError::new(ErrorKind::DeserializeError {\n                        key: key.key().to_owned(),\n                        value: self.value.as_str().to_owned(),\n                        message: message.to_owned(),\n                    })\n                } else {\n                    e\n                }\n            })\n    }\n\n    fn deserialize_bytes<V>(self, visitor: V) -> Result<V::Value, Self::Error>\n    where\n        V: Visitor<'de>,\n    {\n        visitor.visit_borrowed_bytes(self.value.as_bytes())\n    }\n\n    fn deserialize_option<V>(self, visitor: V) -> Result<V::Value, Self::Error>\n    where\n        V: Visitor<'de>,\n    {\n        visitor.visit_some(self)\n    }\n\n    fn deserialize_unit<V>(self, visitor: V) -> Result<V::Value, Self::Error>\n    where\n        V: Visitor<'de>,\n    {\n        visitor.visit_unit()\n    }\n\n    fn deserialize_unit_struct<V>(\n        self,\n        _name: &'static str,\n        visitor: V,\n    ) -> Result<V::Value, Self::Error>\n    where\n        V: Visitor<'de>,\n    {\n        visitor.visit_unit()\n    }\n\n    fn deserialize_newtype_struct<V>(\n        self,\n        _name: &'static str,\n        visitor: V,\n    ) -> Result<V::Value, Self::Error>\n    where\n        V: Visitor<'de>,\n    {\n        visitor.visit_newtype_struct(self)\n    }\n\n    fn deserialize_tuple<V>(self, len: usize, visitor: V) -> Result<V::Value, Self::Error>\n    where\n        V: Visitor<'de>,\n    {\n        struct PairDeserializer<'de> {\n            key: Option<KeyOrIdx<'de>>,\n            value: Option<&'de PercentDecodedStr>,\n        }\n\n        impl<'de> SeqAccess<'de> for PairDeserializer<'de> {\n            type Error = PathDeserializationError;\n\n            fn next_element_seed<T>(&mut self, seed: T) -> Result<Option<T::Value>, Self::Error>\n            where\n                T: DeserializeSeed<'de>,\n            {\n                match self.key.take() {\n                    Some(KeyOrIdx::Idx { idx: _, key }) => {\n                        return seed.deserialize(KeyDeserializer { key }).map(Some);\n                    }\n                    Some(KeyOrIdx::Key(_)) => {\n                        return Err(PathDeserializationError::custom(\n                            \"array types are not supported\",\n                        ));\n                    }\n                    None => {}\n                };\n\n                self.value\n                    .take()\n                    .map(|value| seed.deserialize(ValueDeserializer { key: None, value }))\n                    .transpose()\n            }\n        }\n\n        if len == 2 {\n            match self.key {\n                Some(key) => visitor.visit_seq(PairDeserializer {\n                    key: Some(key),\n                    value: Some(self.value),\n                }),\n                // `self.key` is only `None` when deserializing maps so `deserialize_seq`\n                // wouldn't be called for that\n                None => unreachable!(),\n            }\n        } else {\n            Err(PathDeserializationError::unsupported_type(type_name::<\n                V::Value,\n            >()))\n        }\n    }\n\n    fn deserialize_seq<V>(self, _visitor: V) -> Result<V::Value, Self::Error>\n    where\n        V: Visitor<'de>,\n    {\n        Err(PathDeserializationError::unsupported_type(type_name::<\n            V::Value,\n        >()))\n    }\n\n    fn deserialize_tuple_struct<V>(\n        self,\n        _name: &'static str,\n        _len: usize,\n        _visitor: V,\n    ) -> Result<V::Value, Self::Error>\n    where\n        V: Visitor<'de>,\n    {\n        Err(PathDeserializationError::unsupported_type(type_name::<\n            V::Value,\n        >()))\n    }\n\n    fn deserialize_struct<V>(\n        self,\n        _name: &'static str,\n        _fields: &'static [&'static str],\n        _visitor: V,\n    ) -> Result<V::Value, Self::Error>\n    where\n        V: Visitor<'de>,\n    {\n        Err(PathDeserializationError::unsupported_type(type_name::<\n            V::Value,\n        >()))\n    }\n\n    fn deserialize_enum<V>(\n        self,\n        _name: &'static str,\n        _variants: &'static [&'static str],\n        visitor: V,\n    ) -> Result<V::Value, Self::Error>\n    where\n        V: Visitor<'de>,\n    {\n        visitor.visit_enum(EnumDeserializer { value: self.value })\n    }\n\n    fn deserialize_ignored_any<V>(self, visitor: V) -> Result<V::Value, Self::Error>\n    where\n        V: Visitor<'de>,\n    {\n        visitor.visit_unit()\n    }\n}\n\nstruct EnumDeserializer<'de> {\n    value: &'de str,\n}\n\nimpl<'de> EnumAccess<'de> for EnumDeserializer<'de> {\n    type Error = PathDeserializationError;\n    type Variant = UnitVariant;\n\n    fn variant_seed<V>(self, seed: V) -> Result<(V::Value, Self::Variant), Self::Error>\n    where\n        V: de::DeserializeSeed<'de>,\n    {\n        Ok((\n            seed.deserialize(KeyDeserializer { key: self.value })?,\n            UnitVariant,\n        ))\n    }\n}\n\nstruct UnitVariant;\n\nimpl<'de> VariantAccess<'de> for UnitVariant {\n    type Error = PathDeserializationError;\n\n    fn unit_variant(self) -> Result<(), Self::Error> {\n        Ok(())\n    }\n\n    fn newtype_variant_seed<T>(self, _seed: T) -> Result<T::Value, Self::Error>\n    where\n        T: DeserializeSeed<'de>,\n    {\n        Err(PathDeserializationError::unsupported_type(\n            \"newtype enum variant\",\n        ))\n    }\n\n    fn tuple_variant<V>(self, _len: usize, _visitor: V) -> Result<V::Value, Self::Error>\n    where\n        V: Visitor<'de>,\n    {\n        Err(PathDeserializationError::unsupported_type(\n            \"tuple enum variant\",\n        ))\n    }\n\n    fn struct_variant<V>(\n        self,\n        _fields: &'static [&'static str],\n        _visitor: V,\n    ) -> Result<V::Value, Self::Error>\n    where\n        V: Visitor<'de>,\n    {\n        Err(PathDeserializationError::unsupported_type(\n            \"struct enum variant\",\n        ))\n    }\n}\n\nstruct SeqDeserializer<'de> {\n    params: &'de [(Arc<str>, PercentDecodedStr)],\n    idx: usize,\n}\n\nimpl<'de> SeqAccess<'de> for SeqDeserializer<'de> {\n    type Error = PathDeserializationError;\n\n    fn next_element_seed<T>(&mut self, seed: T) -> Result<Option<T::Value>, Self::Error>\n    where\n        T: DeserializeSeed<'de>,\n    {\n        match self.params.split_first() {\n            Some(((key, value), tail)) => {\n                self.params = tail;\n                let idx = self.idx;\n                self.idx += 1;\n                Ok(Some(seed.deserialize(ValueDeserializer {\n                    key: Some(KeyOrIdx::Idx { idx, key }),\n                    value,\n                })?))\n            }\n            None => Ok(None),\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\nenum KeyOrIdx<'de> {\n    Key(&'de str),\n    Idx { idx: usize, key: &'de str },\n}\n\nimpl<'de> KeyOrIdx<'de> {\n    fn key(&self) -> &'de str {\n        match &self {\n            Self::Key(key) => key,\n            Self::Idx { key, .. } => key,\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use serde::Deserialize;\n    use std::collections::HashMap;\n\n    #[derive(Debug, Deserialize, Eq, PartialEq)]\n    enum MyEnum {\n        A,\n        B,\n        #[serde(rename = \"c\")]\n        C,\n    }\n\n    #[derive(Debug, Deserialize, Eq, PartialEq)]\n    struct Struct {\n        c: String,\n        b: bool,\n        a: i32,\n    }\n\n    fn create_url_params<I, K, V>(values: I) -> Vec<(Arc<str>, PercentDecodedStr)>\n    where\n        I: IntoIterator<Item = (K, V)>,\n        K: AsRef<str>,\n        V: AsRef<str>,\n    {\n        values\n            .into_iter()\n            .map(|(k, v)| (Arc::from(k.as_ref()), PercentDecodedStr::new(v).unwrap()))\n            .collect()\n    }\n\n    macro_rules! check_single_value {\n        ($ty:ty, $value_str:literal, $value:expr) => {\n            #[allow(clippy::bool_assert_comparison)]\n            {\n                let url_params = create_url_params(vec![(\"value\", $value_str)]);\n                let deserializer = PathDeserializer::new(&url_params);\n                assert_eq!(<$ty>::deserialize(deserializer).unwrap(), $value);\n            }\n        };\n    }\n\n    #[test]\n    fn test_parse_single_value() {\n        check_single_value!(bool, \"true\", true);\n        check_single_value!(bool, \"false\", false);\n        check_single_value!(i8, \"-123\", -123);\n        check_single_value!(i16, \"-123\", -123);\n        check_single_value!(i32, \"-123\", -123);\n        check_single_value!(i64, \"-123\", -123);\n        check_single_value!(i128, \"123\", 123);\n        check_single_value!(u8, \"123\", 123);\n        check_single_value!(u16, \"123\", 123);\n        check_single_value!(u32, \"123\", 123);\n        check_single_value!(u64, \"123\", 123);\n        check_single_value!(u128, \"123\", 123);\n        check_single_value!(f32, \"123\", 123.0);\n        check_single_value!(f64, \"123\", 123.0);\n        check_single_value!(String, \"abc\", \"abc\");\n        check_single_value!(String, \"one%20two\", \"one two\");\n        check_single_value!(&str, \"abc\", \"abc\");\n        check_single_value!(&str, \"one%20two\", \"one two\");\n        check_single_value!(char, \"a\", 'a');\n\n        let url_params = create_url_params(vec![(\"a\", \"B\")]);\n        assert_eq!(\n            MyEnum::deserialize(PathDeserializer::new(&url_params)).unwrap(),\n            MyEnum::B\n        );\n\n        let url_params = create_url_params(vec![(\"a\", \"1\"), (\"b\", \"2\")]);\n        let error_kind = i32::deserialize(PathDeserializer::new(&url_params))\n            .unwrap_err()\n            .kind;\n        assert!(matches!(\n            error_kind,\n            ErrorKind::WrongNumberOfParameters {\n                expected: 1,\n                got: 2\n            }\n        ));\n    }\n\n    #[test]\n    fn test_parse_seq() {\n        let url_params = create_url_params(vec![(\"a\", \"1\"), (\"b\", \"true\"), (\"c\", \"abc\")]);\n        assert_eq!(\n            <(i32, bool, String)>::deserialize(PathDeserializer::new(&url_params)).unwrap(),\n            (1, true, \"abc\".to_owned())\n        );\n\n        #[derive(Debug, Deserialize, Eq, PartialEq)]\n        struct TupleStruct(i32, bool, String);\n        assert_eq!(\n            TupleStruct::deserialize(PathDeserializer::new(&url_params)).unwrap(),\n            TupleStruct(1, true, \"abc\".to_owned())\n        );\n\n        let url_params = create_url_params(vec![(\"a\", \"1\"), (\"b\", \"2\"), (\"c\", \"3\")]);\n        assert_eq!(\n            <Vec<i32>>::deserialize(PathDeserializer::new(&url_params)).unwrap(),\n            vec![1, 2, 3]\n        );\n\n        let url_params = create_url_params(vec![(\"a\", \"c\"), (\"a\", \"B\")]);\n        assert_eq!(\n            <Vec<MyEnum>>::deserialize(PathDeserializer::new(&url_params)).unwrap(),\n            vec![MyEnum::C, MyEnum::B]\n        );\n    }\n\n    #[test]\n    fn test_parse_seq_tuple_string_string() {\n        let url_params = create_url_params(vec![(\"a\", \"foo\"), (\"b\", \"bar\")]);\n        assert_eq!(\n            <Vec<(String, String)>>::deserialize(PathDeserializer::new(&url_params)).unwrap(),\n            vec![\n                (\"a\".to_owned(), \"foo\".to_owned()),\n                (\"b\".to_owned(), \"bar\".to_owned())\n            ]\n        );\n    }\n\n    #[test]\n    fn test_parse_seq_tuple_string_parse() {\n        let url_params = create_url_params(vec![(\"a\", \"1\"), (\"b\", \"2\")]);\n        assert_eq!(\n            <Vec<(String, u32)>>::deserialize(PathDeserializer::new(&url_params)).unwrap(),\n            vec![(\"a\".to_owned(), 1), (\"b\".to_owned(), 2)]\n        );\n    }\n\n    #[test]\n    fn test_parse_struct() {\n        let url_params = create_url_params(vec![(\"a\", \"1\"), (\"b\", \"true\"), (\"c\", \"abc\")]);\n        assert_eq!(\n            Struct::deserialize(PathDeserializer::new(&url_params)).unwrap(),\n            Struct {\n                c: \"abc\".to_owned(),\n                b: true,\n                a: 1,\n            }\n        );\n    }\n\n    #[test]\n    fn test_parse_struct_ignoring_additional_fields() {\n        let url_params = create_url_params(vec![\n            (\"a\", \"1\"),\n            (\"b\", \"true\"),\n            (\"c\", \"abc\"),\n            (\"d\", \"false\"),\n        ]);\n        assert_eq!(\n            Struct::deserialize(PathDeserializer::new(&url_params)).unwrap(),\n            Struct {\n                c: \"abc\".to_owned(),\n                b: true,\n                a: 1,\n            }\n        );\n    }\n\n    #[test]\n    fn test_parse_map() {\n        let url_params = create_url_params(vec![(\"a\", \"1\"), (\"b\", \"true\"), (\"c\", \"abc\")]);\n        assert_eq!(\n            <HashMap<String, String>>::deserialize(PathDeserializer::new(&url_params)).unwrap(),\n            [(\"a\", \"1\"), (\"b\", \"true\"), (\"c\", \"abc\")]\n                .iter()\n                .map(|(key, value)| ((*key).to_owned(), (*value).to_owned()))\n                .collect()\n        );\n    }\n\n    macro_rules! test_parse_error {\n        (\n            $params:expr,\n            $ty:ty,\n            $expected_error_kind:expr $(,)?\n        ) => {\n            let url_params = create_url_params($params);\n            let actual_error_kind = <$ty>::deserialize(PathDeserializer::new(&url_params))\n                .unwrap_err()\n                .kind;\n            assert_eq!(actual_error_kind, $expected_error_kind);\n        };\n    }\n\n    #[test]\n    fn test_parse_tuple_too_many_fields() {\n        test_parse_error!(\n            vec![(\"a\", \"abc\"), (\"b\", \"true\"), (\"c\", \"1\"), (\"d\", \"false\"),],\n            (&str, bool, u32),\n            ErrorKind::WrongNumberOfParameters {\n                got: 4,\n                expected: 3,\n            }\n        );\n    }\n\n    #[test]\n    fn test_wrong_number_of_parameters_error() {\n        test_parse_error!(\n            vec![(\"a\", \"1\")],\n            (u32, u32),\n            ErrorKind::WrongNumberOfParameters {\n                got: 1,\n                expected: 2,\n            }\n        );\n    }\n\n    #[test]\n    fn test_parse_error_at_key_error() {\n        #[derive(Debug, Deserialize)]\n        #[allow(dead_code)]\n        struct Params {\n            a: u32,\n        }\n        test_parse_error!(\n            vec![(\"a\", \"false\")],\n            Params,\n            ErrorKind::ParseErrorAtKey {\n                key: \"a\".to_owned(),\n                value: \"false\".to_owned(),\n                expected_type: \"u32\",\n            }\n        );\n    }\n\n    #[test]\n    fn test_parse_error_at_key_error_multiple() {\n        #[derive(Debug, Deserialize)]\n        #[allow(dead_code)]\n        struct Params {\n            a: u32,\n            b: u32,\n        }\n        test_parse_error!(\n            vec![(\"a\", \"false\")],\n            Params,\n            ErrorKind::ParseErrorAtKey {\n                key: \"a\".to_owned(),\n                value: \"false\".to_owned(),\n                expected_type: \"u32\",\n            }\n        );\n    }\n\n    #[test]\n    fn test_parse_error_at_index_error() {\n        test_parse_error!(\n            vec![(\"a\", \"false\"), (\"b\", \"true\")],\n            (bool, u32),\n            ErrorKind::ParseErrorAtIndex {\n                index: 1,\n                value: \"true\".to_owned(),\n                expected_type: \"u32\",\n            }\n        );\n    }\n\n    #[test]\n    fn test_parse_error_error() {\n        test_parse_error!(\n            vec![(\"a\", \"false\")],\n            u32,\n            ErrorKind::ParseError {\n                value: \"false\".to_owned(),\n                expected_type: \"u32\",\n            }\n        );\n    }\n\n    #[test]\n    fn test_unsupported_type_error_nested_data_structure() {\n        test_parse_error!(\n            vec![(\"a\", \"false\")],\n            Vec<Vec<u32>>,\n            ErrorKind::UnsupportedType {\n                name: \"alloc::vec::Vec<u32>\",\n            }\n        );\n    }\n\n    #[test]\n    fn test_parse_seq_tuple_unsupported_key_type() {\n        test_parse_error!(\n            vec![(\"a\", \"false\")],\n            Vec<(u32, String)>,\n            ErrorKind::Message(\"Unexpected key type\".to_owned())\n        );\n    }\n\n    #[test]\n    fn test_parse_seq_wrong_tuple_length() {\n        test_parse_error!(\n            vec![(\"a\", \"false\")],\n            Vec<(String, String, String)>,\n            ErrorKind::UnsupportedType {\n                name: \"(alloc::string::String, alloc::string::String, alloc::string::String)\",\n            }\n        );\n    }\n\n    #[test]\n    fn test_parse_seq_seq() {\n        test_parse_error!(\n            vec![(\"a\", \"false\")],\n            Vec<Vec<String>>,\n            ErrorKind::UnsupportedType {\n                name: \"alloc::vec::Vec<alloc::string::String>\",\n            }\n        );\n    }\n\n    #[test]\n    fn test_deserialize_key_value() {\n        test_parse_error!(\n            vec![(\"id\", \"123123-123-123123\")],\n            uuid::Uuid,\n            ErrorKind::DeserializeError {\n                key: \"id\".to_owned(),\n                value: \"123123-123-123123\".to_owned(),\n                message: \"UUID parsing failed: invalid group count: expected 5, found 3\".to_owned(),\n            }\n        );\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "a3212c7ce353b8385e6cf04a7260e5440c5f8e1d",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/axum/axum/src/routing/method_routing.rs",
    "func": "//! Route to services and handlers based on HTTP methods.\n\nuse super::{future::InfallibleRouteFuture, IntoMakeService};\n#[cfg(feature = \"tokio\")]\nuse crate::extract::connect_info::IntoMakeServiceWithConnectInfo;\nuse crate::{\n    body::{Body, Bytes, HttpBody},\n    boxed::BoxedIntoRoute,\n    error_handling::{HandleError, HandleErrorLayer},\n    handler::Handler,\n    http::{Method, StatusCode},\n    response::Response,\n    routing::{future::RouteFuture, Fallback, MethodFilter, Route},\n};\nuse axum_core::{extract::Request, response::IntoResponse, BoxError};\nuse bytes::BytesMut;\nuse std::{\n    convert::Infallible,\n    fmt,\n    task::{Context, Poll},\n};\nuse tower::{service_fn, util::MapResponseLayer};\nuse tower_layer::Layer;\nuse tower_service::Service;\n\nmacro_rules! top_level_service_fn {\n    (\n        $name:ident, GET\n    ) => {\n        top_level_service_fn!(\n            /// Route `GET` requests to the given service.\n            ///\n            /// # Example\n            ///\n            /// ```rust\n            /// use axum::{\n            ///     extract::Request,\n            ///     Router,\n            ///     routing::get_service,\n            ///     body::Body,\n            /// };\n            /// use http::Response;\n            /// use std::convert::Infallible;\n            ///\n            /// let service = tower::service_fn(|request: Request| async {\n            ///     Ok::<_, Infallible>(Response::new(Body::empty()))\n            /// });\n            ///\n            /// // Requests to `GET /` will go to `service`.\n            /// let app = Router::new().route(\"/\", get_service(service));\n            /// # let _: Router = app;\n            /// ```\n            ///\n            /// Note that `get` routes will also be called for `HEAD` requests but will have\n            /// the response body removed. Make sure to add explicit `HEAD` routes\n            /// afterwards.\n            $name,\n            GET\n        );\n    };\n\n    (\n        $name:ident, CONNECT\n    ) => {\n        top_level_service_fn!(\n            /// Route `CONNECT` requests to the given service.\n            ///\n            /// See [`MethodFilter::CONNECT`] for when you'd want to use this,\n            /// and [`get_service`] for an example.\n            $name,\n            CONNECT\n        );\n    };\n\n    (\n        $name:ident, $method:ident\n    ) => {\n        top_level_service_fn!(\n            #[doc = concat!(\"Route `\", stringify!($method) ,\"` requests to the given service.\")]\n            ///\n            /// See [`get_service`] for an example.\n            $name,\n            $method\n        );\n    };\n\n    (\n        $(#[$m:meta])+\n        $name:ident, $method:ident\n    ) => {\n        $(#[$m])+\n        pub fn $name<T, S>(svc: T) -> MethodRouter<S, T::Error>\n        where\n            T: Service<Request> + Clone + Send + Sync + 'static,\n            T::Response: IntoResponse + 'static,\n            T::Future: Send + 'static,\n            S: Clone,\n        {\n            on_service(MethodFilter::$method, svc)\n        }\n    };\n}\n\nmacro_rules! top_level_handler_fn {\n    (\n        $name:ident, GET\n    ) => {\n        top_level_handler_fn!(\n            /// Route `GET` requests to the given handler.\n            ///\n            /// # Example\n            ///\n            /// ```rust\n            /// use axum::{\n            ///     routing::get,\n            ///     Router,\n            /// };\n            ///\n            /// async fn handler() {}\n            ///\n            /// // Requests to `GET /` will go to `handler`.\n            /// let app = Router::new().route(\"/\", get(handler));\n            /// # let _: Router = app;\n            /// ```\n            ///\n            /// Note that `get` routes will also be called for `HEAD` requests but will have\n            /// the response body removed. Make sure to add explicit `HEAD` routes\n            /// afterwards.\n            $name,\n            GET\n        );\n    };\n\n    (\n        $name:ident, CONNECT\n    ) => {\n        top_level_handler_fn!(\n            /// Route `CONNECT` requests to the given handler.\n            ///\n            /// See [`MethodFilter::CONNECT`] for when you'd want to use this,\n            /// and [`get`] for an example.\n            $name,\n            CONNECT\n        );\n    };\n\n    (\n        $name:ident, $method:ident\n    ) => {\n        top_level_handler_fn!(\n            #[doc = concat!(\"Route `\", stringify!($method) ,\"` requests to the given handler.\")]\n            ///\n            /// See [`get`] for an example.\n            $name,\n            $method\n        );\n    };\n\n    (\n        $(#[$m:meta])+\n        $name:ident, $method:ident\n    ) => {\n        $(#[$m])+\n        pub fn $name<H, T, S>(handler: H) -> MethodRouter<S, Infallible>\n        where\n            H: Handler<T, S>,\n            T: 'static,\n            S: Clone + Send + Sync + 'static,\n        {\n            on(MethodFilter::$method, handler)\n        }\n    };\n}\n\nmacro_rules! chained_service_fn {\n    (\n        $name:ident, GET\n    ) => {\n        chained_service_fn!(\n            /// Chain an additional service that will only accept `GET` requests.\n            ///\n            /// # Example\n            ///\n            /// ```rust\n            /// use axum::{\n            ///     extract::Request,\n            ///     Router,\n            ///     routing::post_service,\n            ///     body::Body,\n            /// };\n            /// use http::Response;\n            /// use std::convert::Infallible;\n            ///\n            /// let service = tower::service_fn(|request: Request| async {\n            ///     Ok::<_, Infallible>(Response::new(Body::empty()))\n            /// });\n            ///\n            /// let other_service = tower::service_fn(|request: Request| async {\n            ///     Ok::<_, Infallible>(Response::new(Body::empty()))\n            /// });\n            ///\n            /// // Requests to `POST /` will go to `service` and `GET /` will go to\n            /// // `other_service`.\n            /// let app = Router::new().route(\"/\", post_service(service).get_service(other_service));\n            /// # let _: Router = app;\n            /// ```\n            ///\n            /// Note that `get` routes will also be called for `HEAD` requests but will have\n            /// the response body removed. Make sure to add explicit `HEAD` routes\n            /// afterwards.\n            $name,\n            GET\n        );\n    };\n\n    (\n        $name:ident, CONNECT\n    ) => {\n        chained_service_fn!(\n            /// Chain an additional service that will only accept `CONNECT` requests.\n            ///\n            /// See [`MethodFilter::CONNECT`] for when you'd want to use this,\n            /// and [`MethodRouter::get_service`] for an example.\n            $name,\n            CONNECT\n        );\n    };\n\n    (\n        $name:ident, $method:ident\n    ) => {\n        chained_service_fn!(\n            #[doc = concat!(\"Chain an additional service that will only accept `\", stringify!($method),\"` requests.\")]\n            ///\n            /// See [`MethodRouter::get_service`] for an example.\n            $name,\n            $method\n        );\n    };\n\n    (\n        $(#[$m:meta])+\n        $name:ident, $method:ident\n    ) => {\n        $(#[$m])+\n        #[track_caller]\n        pub fn $name<T>(self, svc: T) -> Self\n        where\n            T: Service<Request, Error = E>\n                + Clone\n                + Send\n                + Sync\n                + 'static,\n            T::Response: IntoResponse + 'static,\n            T::Future: Send + 'static,\n        {\n            self.on_service(MethodFilter::$method, svc)\n        }\n    };\n}\n\nmacro_rules! chained_handler_fn {\n    (\n        $name:ident, GET\n    ) => {\n        chained_handler_fn!(\n            /// Chain an additional handler that will only accept `GET` requests.\n            ///\n            /// # Example\n            ///\n            /// ```rust\n            /// use axum::{routing::post, Router};\n            ///\n            /// async fn handler() {}\n            ///\n            /// async fn other_handler() {}\n            ///\n            /// // Requests to `POST /` will go to `handler` and `GET /` will go to\n            /// // `other_handler`.\n            /// let app = Router::new().route(\"/\", post(handler).get(other_handler));\n            /// # let _: Router = app;\n            /// ```\n            ///\n            /// Note that `get` routes will also be called for `HEAD` requests but will have\n            /// the response body removed. Make sure to add explicit `HEAD` routes\n            /// afterwards.\n            $name,\n            GET\n        );\n    };\n\n    (\n        $name:ident, CONNECT\n    ) => {\n        chained_handler_fn!(\n            /// Chain an additional handler that will only accept `CONNECT` requests.\n            ///\n            /// See [`MethodFilter::CONNECT`] for when you'd want to use this,\n            /// and [`MethodRouter::get`] for an example.\n            $name,\n            CONNECT\n        );\n    };\n\n    (\n        $name:ident, $method:ident\n    ) => {\n        chained_handler_fn!(\n            #[doc = concat!(\"Chain an additional handler that will only accept `\", stringify!($method),\"` requests.\")]\n            ///\n            /// See [`MethodRouter::get`] for an example.\n            $name,\n            $method\n        );\n    };\n\n    (\n        $(#[$m:meta])+\n        $name:ident, $method:ident\n    ) => {\n        $(#[$m])+\n        #[track_caller]\n        pub fn $name<H, T>(self, handler: H) -> Self\n        where\n            H: Handler<T, S>,\n            T: 'static,\n            S: Send + Sync + 'static,\n        {\n            self.on(MethodFilter::$method, handler)\n        }\n    };\n}\n\ntop_level_service_fn!(connect_service, CONNECT);\ntop_level_service_fn!(delete_service, DELETE);\ntop_level_service_fn!(get_service, GET);\ntop_level_service_fn!(head_service, HEAD);\ntop_level_service_fn!(options_service, OPTIONS);\ntop_level_service_fn!(patch_service, PATCH);\ntop_level_service_fn!(post_service, POST);\ntop_level_service_fn!(put_service, PUT);\ntop_level_service_fn!(trace_service, TRACE);\n\n/// Route requests with the given method to the service.\n///\n/// # Example\n///\n/// ```rust\n/// use axum::{\n///     extract::Request,\n///     routing::on,\n///     Router,\n///     body::Body,\n///     routing::{MethodFilter, on_service},\n/// };\n/// use http::Response;\n/// use std::convert::Infallible;\n///\n/// let service = tower::service_fn(|request: Request| async {\n///     Ok::<_, Infallible>(Response::new(Body::empty()))\n/// });\n///\n/// // Requests to `POST /` will go to `service`.\n/// let app = Router::new().route(\"/\", on_service(MethodFilter::POST, service));\n/// # let _: Router = app;\n/// ```\npub fn on_service<T, S>(filter: MethodFilter, svc: T) -> MethodRouter<S, T::Error>\nwhere\n    T: Service<Request> + Clone + Send + Sync + 'static,\n    T::Response: IntoResponse + 'static,\n    T::Future: Send + 'static,\n    S: Clone,\n{\n    MethodRouter::new().on_service(filter, svc)\n}\n\n/// Route requests to the given service regardless of its method.\n///\n/// # Example\n///\n/// ```rust\n/// use axum::{\n///     extract::Request,\n///     Router,\n///     routing::any_service,\n///     body::Body,\n/// };\n/// use http::Response;\n/// use std::convert::Infallible;\n///\n/// let service = tower::service_fn(|request: Request| async {\n///     Ok::<_, Infallible>(Response::new(Body::empty()))\n/// });\n///\n/// // All requests to `/` will go to `service`.\n/// let app = Router::new().route(\"/\", any_service(service));\n/// # let _: Router = app;\n/// ```\n///\n/// Additional methods can still be chained:\n///\n/// ```rust\n/// use axum::{\n///     extract::Request,\n///     Router,\n///     routing::any_service,\n///     body::Body,\n/// };\n/// use http::Response;\n/// use std::convert::Infallible;\n///\n/// let service = tower::service_fn(|request: Request| async {\n///     # Ok::<_, Infallible>(Response::new(Body::empty()))\n///     // ...\n/// });\n///\n/// let other_service = tower::service_fn(|request: Request| async {\n///     # Ok::<_, Infallible>(Response::new(Body::empty()))\n///     // ...\n/// });\n///\n/// // `POST /` goes to `other_service`. All other requests go to `service`\n/// let app = Router::new().route(\"/\", any_service(service).post_service(other_service));\n/// # let _: Router = app;\n/// ```\npub fn any_service<T, S>(svc: T) -> MethodRouter<S, T::Error>\nwhere\n    T: Service<Request> + Clone + Send + Sync + 'static,\n    T::Response: IntoResponse + 'static,\n    T::Future: Send + 'static,\n    S: Clone,\n{\n    MethodRouter::new()\n        .fallback_service(svc)\n        .skip_allow_header()\n}\n\ntop_level_handler_fn!(connect, CONNECT);\ntop_level_handler_fn!(delete, DELETE);\ntop_level_handler_fn!(get, GET);\ntop_level_handler_fn!(head, HEAD);\ntop_level_handler_fn!(options, OPTIONS);\ntop_level_handler_fn!(patch, PATCH);\ntop_level_handler_fn!(post, POST);\ntop_level_handler_fn!(put, PUT);\ntop_level_handler_fn!(trace, TRACE);\n\n/// Route requests with the given method to the handler.\n///\n/// # Example\n///\n/// ```rust\n/// use axum::{\n///     routing::on,\n///     Router,\n///     routing::MethodFilter,\n/// };\n///\n/// async fn handler() {}\n///\n/// // Requests to `POST /` will go to `handler`.\n/// let app = Router::new().route(\"/\", on(MethodFilter::POST, handler));\n/// # let _: Router = app;\n/// ```\npub fn on<H, T, S>(filter: MethodFilter, handler: H) -> MethodRouter<S, Infallible>\nwhere\n    H: Handler<T, S>,\n    T: 'static,\n    S: Clone + Send + Sync + 'static,\n{\n    MethodRouter::new().on(filter, handler)\n}\n\n/// Route requests with the given handler regardless of the method.\n///\n/// # Example\n///\n/// ```rust\n/// use axum::{\n///     routing::any,\n///     Router,\n/// };\n///\n/// async fn handler() {}\n///\n/// // All requests to `/` will go to `handler`.\n/// let app = Router::new().route(\"/\", any(handler));\n/// # let _: Router = app;\n/// ```\n///\n/// Additional methods can still be chained:\n///\n/// ```rust\n/// use axum::{\n///     routing::any,\n///     Router,\n/// };\n///\n/// async fn handler() {}\n///\n/// async fn other_handler() {}\n///\n/// // `POST /` goes to `other_handler`. All other requests go to `handler`\n/// let app = Router::new().route(\"/\", any(handler).post(other_handler));\n/// # let _: Router = app;\n/// ```\npub fn any<H, T, S>(handler: H) -> MethodRouter<S, Infallible>\nwhere\n    H: Handler<T, S>,\n    T: 'static,\n    S: Clone + Send + Sync + 'static,\n{\n    MethodRouter::new().fallback(handler).skip_allow_header()\n}\n\n/// A [`Service`] that accepts requests based on a [`MethodFilter`] and\n/// allows chaining additional handlers and services.\n///\n/// # When does `MethodRouter` implement [`Service`]?\n///\n/// Whether or not `MethodRouter` implements [`Service`] depends on the state type it requires.\n///\n/// ```\n/// use tower::Service;\n/// use axum::{routing::get, extract::{State, Request}, body::Body};\n///\n/// // this `MethodRouter` doesn't require any state, i.e. the state is `()`,\n/// let method_router = get(|| async {});\n/// // and thus it implements `Service`\n/// assert_service(method_router);\n///\n/// // this requires a `String` and doesn't implement `Service`\n/// let method_router = get(|_: State<String>| async {});\n/// // until you provide the `String` with `.with_state(...)`\n/// let method_router_with_state = method_router.with_state(String::new());\n/// // and then it implements `Service`\n/// assert_service(method_router_with_state);\n///\n/// // helper to check that a value implements `Service`\n/// fn assert_service<S>(service: S)\n/// where\n///     S: Service<Request>,\n/// {}\n/// ```\n#[must_use]\npub struct MethodRouter<S = (), E = Infallible> {\n    get: MethodEndpoint<S, E>,\n    head: MethodEndpoint<S, E>,\n    delete: MethodEndpoint<S, E>,\n    options: MethodEndpoint<S, E>,\n    patch: MethodEndpoint<S, E>,\n    post: MethodEndpoint<S, E>,\n    put: MethodEndpoint<S, E>,\n    trace: MethodEndpoint<S, E>,\n    connect: MethodEndpoint<S, E>,\n    fallback: Fallback<S, E>,\n    allow_header: AllowHeader,\n}\n\n#[derive(Clone, Debug)]\nenum AllowHeader {\n    /// No `Allow` header value has been built-up yet. This is the default state\n    None,\n    /// Don't set an `Allow` header. This is used when `any` or `any_service` are called.\n    Skip,\n    /// The current value of the `Allow` header.\n    Bytes(BytesMut),\n}\n\nimpl AllowHeader {\n    fn merge(self, other: Self) -> Self {\n        match (self, other) {\n            (AllowHeader::Skip, _) | (_, AllowHeader::Skip) => AllowHeader::Skip,\n            (AllowHeader::None, AllowHeader::None) => AllowHeader::None,\n            (AllowHeader::None, AllowHeader::Bytes(pick)) => AllowHeader::Bytes(pick),\n            (AllowHeader::Bytes(pick), AllowHeader::None) => AllowHeader::Bytes(pick),\n            (AllowHeader::Bytes(mut a), AllowHeader::Bytes(b)) => {\n                a.extend_from_slice(b\",\");\n                a.extend_from_slice(&b);\n                AllowHeader::Bytes(a)\n            }\n        }\n    }\n}\n\nimpl<S, E> fmt::Debug for MethodRouter<S, E> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"MethodRouter\")\n            .field(\"get\", &self.get)\n            .field(\"head\", &self.head)\n            .field(\"delete\", &self.delete)\n            .field(\"options\", &self.options)\n            .field(\"patch\", &self.patch)\n            .field(\"post\", &self.post)\n            .field(\"put\", &self.put)\n            .field(\"trace\", &self.trace)\n            .field(\"connect\", &self.connect)\n            .field(\"fallback\", &self.fallback)\n            .field(\"allow_header\", &self.allow_header)\n            .finish()\n    }\n}\n\nimpl<S> MethodRouter<S, Infallible>\nwhere\n    S: Clone,\n{\n    /// Chain an additional handler that will accept requests matching the given\n    /// `MethodFilter`.\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// use axum::{\n    ///     routing::get,\n    ///     Router,\n    ///     routing::MethodFilter\n    /// };\n    ///\n    /// async fn handler() {}\n    ///\n    /// async fn other_handler() {}\n    ///\n    /// // Requests to `GET /` will go to `handler` and `DELETE /` will go to\n    /// // `other_handler`\n    /// let app = Router::new().route(\"/\", get(handler).on(MethodFilter::DELETE, other_handler));\n    /// # let _: Router = app;\n    /// ```\n    #[track_caller]\n    pub fn on<H, T>(self, filter: MethodFilter, handler: H) -> Self\n    where\n        H: Handler<T, S>,\n        T: 'static,\n        S: Send + Sync + 'static,\n    {\n        self.on_endpoint(\n            filter,\n            MethodEndpoint::BoxedHandler(BoxedIntoRoute::from_handler(handler)),\n        )\n    }\n\n    chained_handler_fn!(connect, CONNECT);\n    chained_handler_fn!(delete, DELETE);\n    chained_handler_fn!(get, GET);\n    chained_handler_fn!(head, HEAD);\n    chained_handler_fn!(options, OPTIONS);\n    chained_handler_fn!(patch, PATCH);\n    chained_handler_fn!(post, POST);\n    chained_handler_fn!(put, PUT);\n    chained_handler_fn!(trace, TRACE);\n\n    /// Add a fallback [`Handler`] to the router.\n    pub fn fallback<H, T>(mut self, handler: H) -> Self\n    where\n        H: Handler<T, S>,\n        T: 'static,\n        S: Send + Sync + 'static,\n    {\n        self.fallback = Fallback::BoxedHandler(BoxedIntoRoute::from_handler(handler));\n        self\n    }\n\n    /// Add a fallback [`Handler`] if no custom one has been provided.\n    pub(crate) fn default_fallback<H, T>(self, handler: H) -> Self\n    where\n        H: Handler<T, S>,\n        T: 'static,\n        S: Send + Sync + 'static,\n    {\n        match self.fallback {\n            Fallback::Default(_) => self.fallback(handler),\n            _ => self,\n        }\n    }\n}\n\nimpl MethodRouter<(), Infallible> {\n    /// Convert the router into a [`MakeService`].\n    ///\n    /// This allows you to serve a single `MethodRouter` if you don't need any\n    /// routing based on the path:\n    ///\n    /// ```rust\n    /// use axum::{\n    ///     handler::Handler,\n    ///     http::{Uri, Method},\n    ///     response::IntoResponse,\n    ///     routing::get,\n    /// };\n    /// use std::net::SocketAddr;\n    ///\n    /// async fn handler(method: Method, uri: Uri, body: String) -> String {\n    ///     format!(\"received `{method} {uri}` with body `{body:?}`\")\n    /// }\n    ///\n    /// let router = get(handler).post(handler);\n    ///\n    /// # async {\n    /// let listener = tokio::net::TcpListener::bind(\"0.0.0.0:3000\").await.unwrap();\n    /// axum::serve(listener, router.into_make_service()).await.unwrap();\n    /// # };\n    /// ```\n    ///\n    /// [`MakeService`]: tower::make::MakeService\n    pub fn into_make_service(self) -> IntoMakeService<Self> {\n        IntoMakeService::new(self.with_state(()))\n    }\n\n    /// Convert the router into a [`MakeService`] which stores information\n    /// about the incoming connection.\n    ///\n    /// See [`Router::into_make_service_with_connect_info`] for more details.\n    ///\n    /// ```rust\n    /// use axum::{\n    ///     handler::Handler,\n    ///     response::IntoResponse,\n    ///     extract::ConnectInfo,\n    ///     routing::get,\n    /// };\n    /// use std::net::SocketAddr;\n    ///\n    /// async fn handler(ConnectInfo(addr): ConnectInfo<SocketAddr>) -> String {\n    ///     format!(\"Hello {addr}\")\n    /// }\n    ///\n    /// let router = get(handler).post(handler);\n    ///\n    /// # async {\n    /// let listener = tokio::net::TcpListener::bind(\"0.0.0.0:3000\").await.unwrap();\n    /// axum::serve(listener, router.into_make_service()).await.unwrap();\n    /// # };\n    /// ```\n    ///\n    /// [`MakeService`]: tower::make::MakeService\n    /// [`Router::into_make_service_with_connect_info`]: crate::routing::Router::into_make_service_with_connect_info\n    #[cfg(feature = \"tokio\")]\n    pub fn into_make_service_with_connect_info<C>(self) -> IntoMakeServiceWithConnectInfo<Self, C> {\n        IntoMakeServiceWithConnectInfo::new(self.with_state(()))\n    }\n}\n\nimpl<S, E> MethodRouter<S, E>\nwhere\n    S: Clone,\n{\n    /// Create a default `MethodRouter` that will respond with `405 Method Not Allowed` to all\n    /// requests.\n    pub fn new() -> Self {\n        let fallback = Route::new(service_fn(|_: Request| async {\n            Ok(StatusCode::METHOD_NOT_ALLOWED.into_response())\n        }));\n\n        Self {\n            get: MethodEndpoint::None,\n            head: MethodEndpoint::None,\n            delete: MethodEndpoint::None,\n            options: MethodEndpoint::None,\n            patch: MethodEndpoint::None,\n            post: MethodEndpoint::None,\n            put: MethodEndpoint::None,\n            trace: MethodEndpoint::None,\n            connect: MethodEndpoint::None,\n            allow_header: AllowHeader::None,\n            fallback: Fallback::Default(fallback),\n        }\n    }\n\n    /// Provide the state for the router.\n    pub fn with_state<S2>(self, state: S) -> MethodRouter<S2, E> {\n        MethodRouter {\n            get: self.get.with_state(&state),\n            head: self.head.with_state(&state),\n            delete: self.delete.with_state(&state),\n            options: self.options.with_state(&state),\n            patch: self.patch.with_state(&state),\n            post: self.post.with_state(&state),\n            put: self.put.with_state(&state),\n            trace: self.trace.with_state(&state),\n            connect: self.connect.with_state(&state),\n            allow_header: self.allow_header,\n            fallback: self.fallback.with_state(state),\n        }\n    }\n\n    /// Chain an additional service that will accept requests matching the given\n    /// `MethodFilter`.\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// use axum::{\n    ///     extract::Request,\n    ///     Router,\n    ///     routing::{MethodFilter, on_service},\n    ///     body::Body,\n    /// };\n    /// use http::Response;\n    /// use std::convert::Infallible;\n    ///\n    /// let service = tower::service_fn(|request: Request| async {\n    ///     Ok::<_, Infallible>(Response::new(Body::empty()))\n    /// });\n    ///\n    /// // Requests to `DELETE /` will go to `service`\n    /// let app = Router::new().route(\"/\", on_service(MethodFilter::DELETE, service));\n    /// # let _: Router = app;\n    /// ```\n    #[track_caller]\n    pub fn on_service<T>(self, filter: MethodFilter, svc: T) -> Self\n    where\n        T: Service<Request, Error = E> + Clone + Send + Sync + 'static,\n        T::Response: IntoResponse + 'static,\n        T::Future: Send + 'static,\n    {\n        self.on_endpoint(filter, MethodEndpoint::Route(Route::new(svc)))\n    }\n\n    #[track_caller]\n    fn on_endpoint(mut self, filter: MethodFilter, endpoint: MethodEndpoint<S, E>) -> Self {\n        // written as a separate function to generate less IR\n        #[track_caller]\n        fn set_endpoint<S, E>(\n            method_name: &str,\n            out: &mut MethodEndpoint<S, E>,\n            endpoint: &MethodEndpoint<S, E>,\n            endpoint_filter: MethodFilter,\n            filter: MethodFilter,\n            allow_header: &mut AllowHeader,\n            methods: &[&'static str],\n        ) where\n            MethodEndpoint<S, E>: Clone,\n            S: Clone,\n        {\n            if endpoint_filter.contains(filter) {\n                if out.is_some() {\n                    panic!(\n                        \"Overlapping method route. Cannot add two method routes that both handle \\\n                         `{method_name}`\",\n                    )\n                }\n                *out = endpoint.clone();\n                for method in methods {\n                    append_allow_header(allow_header, method);\n                }\n            }\n        }\n\n        set_endpoint(\n            \"GET\",\n            &mut self.get,\n            &endpoint,\n            filter,\n            MethodFilter::GET,\n            &mut self.allow_header,\n            &[\"GET\", \"HEAD\"],\n        );\n\n        set_endpoint(\n            \"HEAD\",\n            &mut self.head,\n            &endpoint,\n            filter,\n            MethodFilter::HEAD,\n            &mut self.allow_header,\n            &[\"HEAD\"],\n        );\n\n        set_endpoint(\n            \"TRACE\",\n            &mut self.trace,\n            &endpoint,\n            filter,\n            MethodFilter::TRACE,\n            &mut self.allow_header,\n            &[\"TRACE\"],\n        );\n\n        set_endpoint(\n            \"PUT\",\n            &mut self.put,\n            &endpoint,\n            filter,\n            MethodFilter::PUT,\n            &mut self.allow_header,\n            &[\"PUT\"],\n        );\n\n        set_endpoint(\n            \"POST\",\n            &mut self.post,\n            &endpoint,\n            filter,\n            MethodFilter::POST,\n            &mut self.allow_header,\n            &[\"POST\"],\n        );\n\n        set_endpoint(\n            \"PATCH\",\n            &mut self.patch,\n            &endpoint,\n            filter,\n            MethodFilter::PATCH,\n            &mut self.allow_header,\n            &[\"PATCH\"],\n        );\n\n        set_endpoint(\n            \"OPTIONS\",\n            &mut self.options,\n            &endpoint,\n            filter,\n            MethodFilter::OPTIONS,\n            &mut self.allow_header,\n            &[\"OPTIONS\"],\n        );\n\n        set_endpoint(\n            \"DELETE\",\n            &mut self.delete,\n            &endpoint,\n            filter,\n            MethodFilter::DELETE,\n            &mut self.allow_header,\n            &[\"DELETE\"],\n        );\n\n        set_endpoint(\n            \"CONNECT\",\n            &mut self.options,\n            &endpoint,\n            filter,\n            MethodFilter::CONNECT,\n            &mut self.allow_header,\n            &[\"CONNECT\"],\n        );\n\n        self\n    }\n\n    chained_service_fn!(connect_service, CONNECT);\n    chained_service_fn!(delete_service, DELETE);\n    chained_service_fn!(get_service, GET);\n    chained_service_fn!(head_service, HEAD);\n    chained_service_fn!(options_service, OPTIONS);\n    chained_service_fn!(patch_service, PATCH);\n    chained_service_fn!(post_service, POST);\n    chained_service_fn!(put_service, PUT);\n    chained_service_fn!(trace_service, TRACE);\n\n    #[doc = include_str!(\"../docs/method_routing/fallback.md\")]\n    pub fn fallback_service<T>(mut self, svc: T) -> Self\n    where\n        T: Service<Request, Error = E> + Clone + Send + Sync + 'static,\n        T::Response: IntoResponse + 'static,\n        T::Future: Send + 'static,\n    {\n        self.fallback = Fallback::Service(Route::new(svc));\n        self\n    }\n\n    #[doc = include_str!(\"../docs/method_routing/layer.md\")]\n    pub fn layer<L, NewError>(self, layer: L) -> MethodRouter<S, NewError>\n    where\n        L: Layer<Route<E>> + Clone + Send + Sync + 'static,\n        L::Service: Service<Request> + Clone + Send + Sync + 'static,\n        <L::Service as Service<Request>>::Response: IntoResponse + 'static,\n        <L::Service as Service<Request>>::Error: Into<NewError> + 'static,\n        <L::Service as Service<Request>>::Future: Send + 'static,\n        E: 'static,\n        S: 'static,\n        NewError: 'static,\n    {\n        let layer_fn = move |route: Route<E>| route.layer(layer.clone());\n\n        MethodRouter {\n            get: self.get.map(layer_fn.clone()),\n            head: self.head.map(layer_fn.clone()),\n            delete: self.delete.map(layer_fn.clone()),\n            options: self.options.map(layer_fn.clone()),\n            patch: self.patch.map(layer_fn.clone()),\n            post: self.post.map(layer_fn.clone()),\n            put: self.put.map(layer_fn.clone()),\n            trace: self.trace.map(layer_fn.clone()),\n            connect: self.connect.map(layer_fn.clone()),\n            fallback: self.fallback.map(layer_fn),\n            allow_header: self.allow_header,\n        }\n    }\n\n    #[doc = include_str!(\"../docs/method_routing/route_layer.md\")]\n    #[track_caller]\n    pub fn route_layer<L>(mut self, layer: L) -> MethodRouter<S, E>\n    where\n        L: Layer<Route<E>> + Clone + Send + Sync + 'static,\n        L::Service: Service<Request, Error = E> + Clone + Send + Sync + 'static,\n        <L::Service as Service<Request>>::Response: IntoResponse + 'static,\n        <L::Service as Service<Request>>::Future: Send + 'static,\n        E: 'static,\n        S: 'static,\n    {\n        if self.get.is_none()\n            && self.head.is_none()\n            && self.delete.is_none()\n            && self.options.is_none()\n            && self.patch.is_none()\n            && self.post.is_none()\n            && self.put.is_none()\n            && self.trace.is_none()\n            && self.connect.is_none()\n        {\n            panic!(\n                \"Adding a route_layer before any routes is a no-op. \\\n                 Add the routes you want the layer to apply to first.\"\n            );\n        }\n\n        let layer_fn = move |svc| {\n            let svc = layer.layer(svc);\n            let svc = MapResponseLayer::new(IntoResponse::into_response).layer(svc);\n            Route::new(svc)\n        };\n\n        self.get = self.get.map(layer_fn.clone());\n        self.head = self.head.map(layer_fn.clone());\n        self.delete = self.delete.map(layer_fn.clone());\n        self.options = self.options.map(layer_fn.clone());\n        self.patch = self.patch.map(layer_fn.clone());\n        self.post = self.post.map(layer_fn.clone());\n        self.put = self.put.map(layer_fn.clone());\n        self.trace = self.trace.map(layer_fn.clone());\n        self.connect = self.connect.map(layer_fn);\n\n        self\n    }\n\n    #[track_caller]\n    pub(crate) fn merge_for_path(mut self, path: Option<&str>, other: MethodRouter<S, E>) -> Self {\n        // written using inner functions to generate less IR\n        #[track_caller]\n        fn merge_inner<S, E>(\n            path: Option<&str>,\n            name: &str,\n            first: MethodEndpoint<S, E>,\n            second: MethodEndpoint<S, E>,\n        ) -> MethodEndpoint<S, E> {\n            match (first, second) {\n                (MethodEndpoint::None, MethodEndpoint::None) => MethodEndpoint::None,\n                (pick, MethodEndpoint::None) | (MethodEndpoint::None, pick) => pick,\n                _ => {\n                    if let Some(path) = path {\n                        panic!(\n                            \"Overlapping method route. Handler for `{name} {path}` already exists\"\n                        );\n                    } else {\n                        panic!(\n                            \"Overlapping method route. Cannot merge two method routes that both \\\n                             define `{name}`\"\n                        );\n                    }\n                }\n            }\n        }\n\n        self.get = merge_inner(path, \"GET\", self.get, other.get);\n        self.head = merge_inner(path, \"HEAD\", self.head, other.head);\n        self.delete = merge_inner(path, \"DELETE\", self.delete, other.delete);\n        self.options = merge_inner(path, \"OPTIONS\", self.options, other.options);\n        self.patch = merge_inner(path, \"PATCH\", self.patch, other.patch);\n        self.post = merge_inner(path, \"POST\", self.post, other.post);\n        self.put = merge_inner(path, \"PUT\", self.put, other.put);\n        self.trace = merge_inner(path, \"TRACE\", self.trace, other.trace);\n        self.connect = merge_inner(path, \"CONNECT\", self.connect, other.connect);\n\n        self.fallback = self\n            .fallback\n            .merge(other.fallback)\n            .expect(\"Cannot merge two `MethodRouter`s that both have a fallback\");\n\n        self.allow_header = self.allow_header.merge(other.allow_header);\n\n        self\n    }\n\n    #[doc = include_str!(\"../docs/method_routing/merge.md\")]\n    #[track_caller]\n    pub fn merge(self, other: MethodRouter<S, E>) -> Self {\n        self.merge_for_path(None, other)\n    }\n\n    /// Apply a [`HandleErrorLayer`].\n    ///\n    /// This is a convenience method for doing `self.layer(HandleErrorLayer::new(f))`.\n    pub fn handle_error<F, T>(self, f: F) -> MethodRouter<S, Infallible>\n    where\n        F: Clone + Send + Sync + 'static,\n        HandleError<Route<E>, F, T>: Service<Request, Error = Infallible>,\n        <HandleError<Route<E>, F, T> as Service<Request>>::Future: Send,\n        <HandleError<Route<E>, F, T> as Service<Request>>::Response: IntoResponse + Send,\n        T: 'static,\n        E: 'static,\n        S: 'static,\n    {\n        self.layer(HandleErrorLayer::new(f))\n    }\n\n    fn skip_allow_header(mut self) -> Self {\n        self.allow_header = AllowHeader::Skip;\n        self\n    }\n\n    pub(crate) fn call_with_state(&self, req: Request, state: S) -> RouteFuture<E> {\n        macro_rules! call {\n            (\n                $req:expr,\n                $method_variant:ident,\n                $svc:expr\n            ) => {\n                if *req.method() == Method::$method_variant {\n                    match $svc {\n                        MethodEndpoint::None => {}\n                        MethodEndpoint::Route(route) => {\n                            return route.clone().oneshot_inner_owned($req);\n                        }\n                        MethodEndpoint::BoxedHandler(handler) => {\n                            let route = handler.clone().into_route(state);\n                            return route.oneshot_inner_owned($req);\n                        }\n                    }\n                }\n            };\n        }\n\n        // written with a pattern match like this to ensure we call all routes\n        let Self {\n            get,\n            head,\n            delete,\n            options,\n            patch,\n            post,\n            put,\n            trace,\n            connect,\n            fallback,\n            allow_header,\n        } = self;\n\n        call!(req, HEAD, head);\n        call!(req, HEAD, get);\n        call!(req, GET, get);\n        call!(req, POST, post);\n        call!(req, OPTIONS, options);\n        call!(req, PATCH, patch);\n        call!(req, PUT, put);\n        call!(req, DELETE, delete);\n        call!(req, TRACE, trace);\n        call!(req, CONNECT, connect);\n\n        let future = fallback.clone().call_with_state(req, state);\n\n        match allow_header {\n            AllowHeader::None => future.allow_header(Bytes::new()),\n            AllowHeader::Skip => future,\n            AllowHeader::Bytes(allow_header) => future.allow_header(allow_header.clone().freeze()),\n        }\n    }\n}\n\nfn append_allow_header(allow_header: &mut AllowHeader, method: &'static str) {\n    match allow_header {\n        AllowHeader::None => {\n            *allow_header = AllowHeader::Bytes(BytesMut::from(method));\n        }\n        AllowHeader::Skip => {}\n        AllowHeader::Bytes(allow_header) => {\n            if let Ok(s) = std::str::from_utf8(allow_header) {\n                if !s.contains(method) {\n                    allow_header.extend_from_slice(b\",\");\n                    allow_header.extend_from_slice(method.as_bytes());\n                }\n            } else {\n                #[cfg(debug_assertions)]\n                panic!(\"`allow_header` contained invalid uft-8. This should never happen\")\n            }\n        }\n    }\n}\n\nimpl<S, E> Clone for MethodRouter<S, E> {\n    fn clone(&self) -> Self {\n        Self {\n            get: self.get.clone(),\n            head: self.head.clone(),\n            delete: self.delete.clone(),\n            options: self.options.clone(),\n            patch: self.patch.clone(),\n            post: self.post.clone(),\n            put: self.put.clone(),\n            trace: self.trace.clone(),\n            connect: self.connect.clone(),\n            fallback: self.fallback.clone(),\n            allow_header: self.allow_header.clone(),\n        }\n    }\n}\n\nimpl<S, E> Default for MethodRouter<S, E>\nwhere\n    S: Clone,\n{\n    fn default() -> Self {\n        Self::new()\n    }\n}\n\nenum MethodEndpoint<S, E> {\n    None,\n    Route(Route<E>),\n    BoxedHandler(BoxedIntoRoute<S, E>),\n}\n\nimpl<S, E> MethodEndpoint<S, E>\nwhere\n    S: Clone,\n{\n    fn is_some(&self) -> bool {\n        matches!(self, Self::Route(_) | Self::BoxedHandler(_))\n    }\n\n    fn is_none(&self) -> bool {\n        matches!(self, Self::None)\n    }\n\n    fn map<F, E2>(self, f: F) -> MethodEndpoint<S, E2>\n    where\n        S: 'static,\n        E: 'static,\n        F: FnOnce(Route<E>) -> Route<E2> + Clone + Send + Sync + 'static,\n        E2: 'static,\n    {\n        match self {\n            Self::None => MethodEndpoint::None,\n            Self::Route(route) => MethodEndpoint::Route(f(route)),\n            Self::BoxedHandler(handler) => MethodEndpoint::BoxedHandler(handler.map(f)),\n        }\n    }\n\n    fn with_state<S2>(self, state: &S) -> MethodEndpoint<S2, E> {\n        match self {\n            MethodEndpoint::None => MethodEndpoint::None,\n            MethodEndpoint::Route(route) => MethodEndpoint::Route(route),\n            MethodEndpoint::BoxedHandler(handler) => {\n                MethodEndpoint::Route(handler.into_route(state.clone()))\n            }\n        }\n    }\n}\n\nimpl<S, E> Clone for MethodEndpoint<S, E> {\n    fn clone(&self) -> Self {\n        match self {\n            Self::None => Self::None,\n            Self::Route(inner) => Self::Route(inner.clone()),\n            Self::BoxedHandler(inner) => Self::BoxedHandler(inner.clone()),\n        }\n    }\n}\n\nimpl<S, E> fmt::Debug for MethodEndpoint<S, E> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match self {\n            Self::None => f.debug_tuple(\"None\").finish(),\n            Self::Route(inner) => inner.fmt(f),\n            Self::BoxedHandler(_) => f.debug_tuple(\"BoxedHandler\").finish(),\n        }\n    }\n}\n\nimpl<B, E> Service<Request<B>> for MethodRouter<(), E>\nwhere\n    B: HttpBody<Data = Bytes> + Send + 'static,\n    B::Error: Into<BoxError>,\n{\n    type Response = Response;\n    type Error = E;\n    type Future = RouteFuture<E>;\n\n    #[inline]\n    fn poll_ready(&mut self, _cx: &mut Context<'_>) -> Poll<Result<(), Self::Error>> {\n        Poll::Ready(Ok(()))\n    }\n\n    #[inline]\n    fn call(&mut self, req: Request<B>) -> Self::Future {\n        let req = req.map(Body::new);\n        self.call_with_state(req, ())\n    }\n}\n\nimpl<S> Handler<(), S> for MethodRouter<S>\nwhere\n    S: Clone + 'static,\n{\n    type Future = InfallibleRouteFuture;\n\n    fn call(self, req: Request, state: S) -> Self::Future {\n        InfallibleRouteFuture::new(self.call_with_state(req, state))\n    }\n}\n\n// for `axum::serve(listener, router)`\n#[cfg(all(feature = \"tokio\", any(feature = \"http1\", feature = \"http2\")))]\nconst _: () = {\n    use crate::serve;\n\n    impl<L> Service<serve::IncomingStream<'_, L>> for MethodRouter<()>\n    where\n        L: serve::Listener,\n    {\n        type Response = Self;\n        type Error = Infallible;\n        type Future = std::future::Ready<Result<Self::Response, Self::Error>>;\n\n        fn poll_ready(&mut self, _cx: &mut Context<'_>) -> Poll<Result<(), Self::Error>> {\n            Poll::Ready(Ok(()))\n        }\n\n        fn call(&mut self, _req: serve::IncomingStream<'_, L>) -> Self::Future {\n            std::future::ready(Ok(self.clone().with_state(())))\n        }\n    }\n};\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::{extract::State, handler::HandlerWithoutStateExt};\n    use http::{header::ALLOW, HeaderMap};\n    use http_body_util::BodyExt;\n    use std::time::Duration;\n    use tower::ServiceExt;\n    use tower_http::{\n        services::fs::ServeDir, timeout::TimeoutLayer, validate_request::ValidateRequestHeaderLayer,\n    };\n\n    #[crate::test]\n    async fn method_not_allowed_by_default() {\n        let mut svc = MethodRouter::new();\n        let (status, _, body) = call(Method::GET, &mut svc).await;\n        assert_eq!(status, StatusCode::METHOD_NOT_ALLOWED);\n        assert!(body.is_empty());\n    }\n\n    #[crate::test]\n    async fn get_service_fn() {\n        async fn handle(_req: Request) -> Result<Response<Body>, Infallible> {\n            Ok(Response::new(Body::from(\"ok\")))\n        }\n\n        let mut svc = get_service(service_fn(handle));\n\n        let (status, _, body) = call(Method::GET, &mut svc).await;\n        assert_eq!(status, StatusCode::OK);\n        assert_eq!(body, \"ok\");\n    }\n\n    #[crate::test]\n    async fn get_handler() {\n        let mut svc = MethodRouter::new().get(ok);\n        let (status, _, body) = call(Method::GET, &mut svc).await;\n        assert_eq!(status, StatusCode::OK);\n        assert_eq!(body, \"ok\");\n    }\n\n    #[crate::test]\n    async fn get_accepts_head() {\n        let mut svc = MethodRouter::new().get(ok);\n        let (status, _, body) = call(Method::HEAD, &mut svc).await;\n        assert_eq!(status, StatusCode::OK);\n        assert!(body.is_empty());\n    }\n\n    #[crate::test]\n    async fn head_takes_precedence_over_get() {\n        let mut svc = MethodRouter::new().head(created).get(ok);\n        let (status, _, body) = call(Method::HEAD, &mut svc).await;\n        assert_eq!(status, StatusCode::CREATED);\n        assert!(body.is_empty());\n    }\n\n    #[crate::test]\n    async fn merge() {\n        let mut svc = get(ok).merge(post(ok));\n\n        let (status, _, _) = call(Method::GET, &mut svc).await;\n        assert_eq!(status, StatusCode::OK);\n\n        let (status, _, _) = call(Method::POST, &mut svc).await;\n        assert_eq!(status, StatusCode::OK);\n    }\n\n    #[crate::test]\n    async fn layer() {\n        let mut svc = MethodRouter::new()\n            .get(|| async { std::future::pending::<()>().await })\n            .layer(ValidateRequestHeaderLayer::bearer(\"password\"));\n\n        // method with route\n        let (status, _, _) = call(Method::GET, &mut svc).await;\n        assert_eq!(status, StatusCode::UNAUTHORIZED);\n\n        // method without route\n        let (status, _, _) = call(Method::DELETE, &mut svc).await;\n        assert_eq!(status, StatusCode::UNAUTHORIZED);\n    }\n\n    #[crate::test]\n    async fn route_layer() {\n        let mut svc = MethodRouter::new()\n            .get(|| async { std::future::pending::<()>().await })\n            .route_layer(ValidateRequestHeaderLayer::bearer(\"password\"));\n\n        // method with route\n        let (status, _, _) = call(Method::GET, &mut svc).await;\n        assert_eq!(status, StatusCode::UNAUTHORIZED);\n\n        // method without route\n        let (status, _, _) = call(Method::DELETE, &mut svc).await;\n        assert_eq!(status, StatusCode::METHOD_NOT_ALLOWED);\n    }\n\n    #[allow(dead_code)]\n    async fn building_complex_router() {\n        let app = crate::Router::new().route(\n            \"/\",\n            // use the all the things \ud83d\udca3\ufe0f\n            get(ok)\n                .post(ok)\n                .route_layer(ValidateRequestHeaderLayer::bearer(\"password\"))\n                .merge(delete_service(ServeDir::new(\".\")))\n                .fallback(|| async { StatusCode::NOT_FOUND })\n                .put(ok)\n                .layer(TimeoutLayer::new(Duration::from_secs(10))),\n        );\n\n        let listener = tokio::net::TcpListener::bind(\"0.0.0.0:0\").await.unwrap();\n        crate::serve(listener, app).await.unwrap();\n    }\n\n    #[crate::test]\n    async fn sets_allow_header() {\n        let mut svc = MethodRouter::new().put(ok).patch(ok);\n        let (status, headers, _) = call(Method::GET, &mut svc).await;\n        assert_eq!(status, StatusCode::METHOD_NOT_ALLOWED);\n        assert_eq!(headers[ALLOW], \"PUT,PATCH\");\n    }\n\n    #[crate::test]\n    async fn sets_allow_header_get_head() {\n        let mut svc = MethodRouter::new().get(ok).head(ok);\n        let (status, headers, _) = call(Method::PUT, &mut svc).await;\n        assert_eq!(status, StatusCode::METHOD_NOT_ALLOWED);\n        assert_eq!(headers[ALLOW], \"GET,HEAD\");\n    }\n\n    #[crate::test]\n    async fn empty_allow_header_by_default() {\n        let mut svc = MethodRouter::new();\n        let (status, headers, _) = call(Method::PATCH, &mut svc).await;\n        assert_eq!(status, StatusCode::METHOD_NOT_ALLOWED);\n        assert_eq!(headers[ALLOW], \"\");\n    }\n\n    #[crate::test]\n    async fn allow_header_when_merging() {\n        let a = put(ok).patch(ok);\n        let b = get(ok).head(ok);\n        let mut svc = a.merge(b);\n\n        let (status, headers, _) = call(Method::DELETE, &mut svc).await;\n        assert_eq!(status, StatusCode::METHOD_NOT_ALLOWED);\n        assert_eq!(headers[ALLOW], \"PUT,PATCH,GET,HEAD\");\n    }\n\n    #[crate::test]\n    async fn allow_header_any() {\n        let mut svc = any(ok);\n\n        let (status, headers, _) = call(Method::GET, &mut svc).await;\n        assert_eq!(status, StatusCode::OK);\n        assert!(!headers.contains_key(ALLOW));\n    }\n\n    #[crate::test]\n    async fn allow_header_with_fallback() {\n        let mut svc = MethodRouter::new()\n            .get(ok)\n            .fallback(|| async { (StatusCode::METHOD_NOT_ALLOWED, \"Method not allowed\") });\n\n        let (status, headers, _) = call(Method::DELETE, &mut svc).await;\n        assert_eq!(status, StatusCode::METHOD_NOT_ALLOWED);\n        assert_eq!(headers[ALLOW], \"GET,HEAD\");\n    }\n\n    #[crate::test]\n    async fn allow_header_with_fallback_that_sets_allow() {\n        async fn fallback(method: Method) -> Response {\n            if method == Method::POST {\n                \"OK\".into_response()\n            } else {\n                (\n                    StatusCode::METHOD_NOT_ALLOWED,\n                    [(ALLOW, \"GET,POST\")],\n                    \"Method not allowed\",\n                )\n                    .into_response()\n            }\n        }\n\n        let mut svc = MethodRouter::new().get(ok).fallback(fallback);\n\n        let (status, _, _) = call(Method::GET, &mut svc).await;\n        assert_eq!(status, StatusCode::OK);\n\n        let (status, _, _) = call(Method::POST, &mut svc).await;\n        assert_eq!(status, StatusCode::OK);\n\n        let (status, headers, _) = call(Method::DELETE, &mut svc).await;\n        assert_eq!(status, StatusCode::METHOD_NOT_ALLOWED);\n        assert_eq!(headers[ALLOW], \"GET,POST\");\n    }\n\n    #[crate::test]\n    async fn allow_header_noop_middleware() {\n        let mut svc = MethodRouter::new()\n            .get(ok)\n            .layer(tower::layer::util::Identity::new());\n\n        let (status, headers, _) = call(Method::DELETE, &mut svc).await;\n        assert_eq!(status, StatusCode::METHOD_NOT_ALLOWED);\n        assert_eq!(headers[ALLOW], \"GET,HEAD\");\n    }\n\n    #[crate::test]\n    #[should_panic(\n        expected = \"Overlapping method route. Cannot add two method routes that both handle `GET`\"\n    )]\n    async fn handler_overlaps() {\n        let _: MethodRouter<()> = get(ok).get(ok);\n    }\n\n    #[crate::test]\n    #[should_panic(\n        expected = \"Overlapping method route. Cannot add two method routes that both handle `POST`\"\n    )]\n    async fn service_overlaps() {\n        let _: MethodRouter<()> = post_service(ok.into_service()).post_service(ok.into_service());\n    }\n\n    #[crate::test]\n    async fn get_head_does_not_overlap() {\n        let _: MethodRouter<()> = get(ok).head(ok);\n    }\n\n    #[crate::test]\n    async fn head_get_does_not_overlap() {\n        let _: MethodRouter<()> = head(ok).get(ok);\n    }\n\n    #[crate::test]\n    async fn accessing_state() {\n        let mut svc = MethodRouter::new()\n            .get(|State(state): State<&'static str>| async move { state })\n            .with_state(\"state\");\n\n        let (status, _, text) = call(Method::GET, &mut svc).await;\n\n        assert_eq!(status, StatusCode::OK);\n        assert_eq!(text, \"state\");\n    }\n\n    #[crate::test]\n    async fn fallback_accessing_state() {\n        let mut svc = MethodRouter::new()\n            .fallback(|State(state): State<&'static str>| async move { state })\n            .with_state(\"state\");\n\n        let (status, _, text) = call(Method::GET, &mut svc).await;\n\n        assert_eq!(status, StatusCode::OK);\n        assert_eq!(text, \"state\");\n    }\n\n    #[crate::test]\n    async fn merge_accessing_state() {\n        let one = get(|State(state): State<&'static str>| async move { state });\n        let two = post(|State(state): State<&'static str>| async move { state });\n\n        let mut svc = one.merge(two).with_state(\"state\");\n\n        let (status, _, text) = call(Method::GET, &mut svc).await;\n        assert_eq!(status, StatusCode::OK);\n        assert_eq!(text, \"state\");\n\n        let (status, _, _) = call(Method::POST, &mut svc).await;\n        assert_eq!(status, StatusCode::OK);\n        assert_eq!(text, \"state\");\n    }\n\n    async fn call<S>(method: Method, svc: &mut S) -> (StatusCode, HeaderMap, String)\n    where\n        S: Service<Request, Error = Infallible>,\n        S::Response: IntoResponse,\n    {\n        let request = Request::builder()\n            .uri(\"/\")\n            .method(method)\n            .body(Body::empty())\n            .unwrap();\n        let response = svc\n            .ready()\n            .await\n            .unwrap()\n            .call(request)\n            .await\n            .unwrap()\n            .into_response();\n        let (parts, body) = response.into_parts();\n        let body =\n            String::from_utf8(BodyExt::collect(body).await.unwrap().to_bytes().to_vec()).unwrap();\n        (parts.status, parts.headers, body)\n    }\n\n    async fn ok() -> (StatusCode, &'static str) {\n        (StatusCode::OK, \"ok\")\n    }\n\n    async fn created() -> (StatusCode, &'static str) {\n        (StatusCode::CREATED, \"created\")\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "f8bf1ea7509ad8f923bb90033668984b4020920c",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/axum/axum/src/routing/method_filter.rs",
    "func": "use http::Method;\nuse std::{\n    fmt,\n    fmt::{Debug, Formatter},\n};\n\n/// A filter that matches one or more HTTP methods.\n#[derive(Debug, Copy, Clone, PartialEq)]\npub struct MethodFilter(u16);\n\nimpl MethodFilter {\n    /// Match `CONNECT` requests.\n    ///\n    /// This is useful for implementing HTTP/2's [extended CONNECT method],\n    /// in which the `:protocol` pseudoheader is read\n    /// (using [`hyper::ext::Protocol`])\n    /// and the connection upgraded to a bidirectional byte stream\n    /// (using [`hyper::upgrade::on`]).\n    ///\n    /// As seen in the [HTTP Upgrade Token Registry],\n    /// common uses include WebSockets and proxying UDP or IP \u2013\n    /// though note that when using [`WebSocketUpgrade`]\n    /// it's more useful to use [`any`](crate::routing::any)\n    /// as HTTP/1.1 WebSockets need to support `GET`.\n    ///\n    /// [extended CONNECT]: https://www.rfc-editor.org/rfc/rfc8441.html#section-4\n    /// [HTTP Upgrade Token Registry]: https://www.iana.org/assignments/http-upgrade-tokens/http-upgrade-tokens.xhtml\n    /// [`WebSocketUpgrade`]: crate::extract::WebSocketUpgrade\n    pub const CONNECT: Self = Self::from_bits(0b0_0000_0001);\n    /// Match `DELETE` requests.\n    pub const DELETE: Self = Self::from_bits(0b0_0000_0010);\n    /// Match `GET` requests.\n    pub const GET: Self = Self::from_bits(0b0_0000_0100);\n    /// Match `HEAD` requests.\n    pub const HEAD: Self = Self::from_bits(0b0_0000_1000);\n    /// Match `OPTIONS` requests.\n    pub const OPTIONS: Self = Self::from_bits(0b0_0001_0000);\n    /// Match `PATCH` requests.\n    pub const PATCH: Self = Self::from_bits(0b0_0010_0000);\n    /// Match `POST` requests.\n    pub const POST: Self = Self::from_bits(0b0_0100_0000);\n    /// Match `PUT` requests.\n    pub const PUT: Self = Self::from_bits(0b0_1000_0000);\n    /// Match `TRACE` requests.\n    pub const TRACE: Self = Self::from_bits(0b1_0000_0000);\n\n    const fn bits(&self) -> u16 {\n        let bits = self;\n        bits.0\n    }\n\n    const fn from_bits(bits: u16) -> Self {\n        Self(bits)\n    }\n\n    pub(crate) const fn contains(&self, other: Self) -> bool {\n        self.bits() & other.bits() == other.bits()\n    }\n\n    /// Performs the OR operation between the [`MethodFilter`] in `self` with `other`.\n    pub const fn or(self, other: Self) -> Self {\n        Self(self.0 | other.0)\n    }\n}\n\n/// Error type used when converting a [`Method`] to a [`MethodFilter`] fails.\n#[derive(Debug)]\npub struct NoMatchingMethodFilter {\n    method: Method,\n}\n\nimpl NoMatchingMethodFilter {\n    /// Get the [`Method`] that couldn't be converted to a [`MethodFilter`].\n    pub fn method(&self) -> &Method {\n        &self.method\n    }\n}\n\nimpl fmt::Display for NoMatchingMethodFilter {\n    fn fmt(&self, f: &mut Formatter<'_>) -> fmt::Result {\n        write!(f, \"no `MethodFilter` for `{}`\", self.method.as_str())\n    }\n}\n\nimpl std::error::Error for NoMatchingMethodFilter {}\n\nimpl TryFrom<Method> for MethodFilter {\n    type Error = NoMatchingMethodFilter;\n\n    fn try_from(m: Method) -> Result<Self, NoMatchingMethodFilter> {\n        match m {\n            Method::CONNECT => Ok(MethodFilter::CONNECT),\n            Method::DELETE => Ok(MethodFilter::DELETE),\n            Method::GET => Ok(MethodFilter::GET),\n            Method::HEAD => Ok(MethodFilter::HEAD),\n            Method::OPTIONS => Ok(MethodFilter::OPTIONS),\n            Method::PATCH => Ok(MethodFilter::PATCH),\n            Method::POST => Ok(MethodFilter::POST),\n            Method::PUT => Ok(MethodFilter::PUT),\n            Method::TRACE => Ok(MethodFilter::TRACE),\n            other => Err(NoMatchingMethodFilter { method: other }),\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn from_http_method() {\n        assert_eq!(\n            MethodFilter::try_from(Method::CONNECT).unwrap(),\n            MethodFilter::CONNECT\n        );\n\n        assert_eq!(\n            MethodFilter::try_from(Method::DELETE).unwrap(),\n            MethodFilter::DELETE\n        );\n\n        assert_eq!(\n            MethodFilter::try_from(Method::GET).unwrap(),\n            MethodFilter::GET\n        );\n\n        assert_eq!(\n            MethodFilter::try_from(Method::HEAD).unwrap(),\n            MethodFilter::HEAD\n        );\n\n        assert_eq!(\n            MethodFilter::try_from(Method::OPTIONS).unwrap(),\n            MethodFilter::OPTIONS\n        );\n\n        assert_eq!(\n            MethodFilter::try_from(Method::PATCH).unwrap(),\n            MethodFilter::PATCH\n        );\n\n        assert_eq!(\n            MethodFilter::try_from(Method::POST).unwrap(),\n            MethodFilter::POST\n        );\n\n        assert_eq!(\n            MethodFilter::try_from(Method::PUT).unwrap(),\n            MethodFilter::PUT\n        );\n\n        assert_eq!(\n            MethodFilter::try_from(Method::TRACE).unwrap(),\n            MethodFilter::TRACE\n        );\n\n        assert!(\n            MethodFilter::try_from(http::Method::from_bytes(b\"CUSTOM\").unwrap())\n                .unwrap_err()\n                .to_string()\n                .contains(\"CUSTOM\")\n        );\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "ebe1958e234bfd8b79ef8e9a54e39db307e9a9c7",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/axum/axum/src/serve/listener.rs",
    "func": "use std::{fmt, future::Future, time::Duration};\n\nuse tokio::{\n    io::{self, AsyncRead, AsyncWrite},\n    net::{TcpListener, TcpStream},\n};\n\n/// Types that can listen for connections.\npub trait Listener: Send + 'static {\n    /// The listener's IO type.\n    type Io: AsyncRead + AsyncWrite + Unpin + Send + 'static;\n\n    /// The listener's address type.\n    type Addr: Send;\n\n    /// Accept a new incoming connection to this listener.\n    ///\n    /// If the underlying accept call can return an error, this function must\n    /// take care of logging and retrying.\n    fn accept(&mut self) -> impl Future<Output = (Self::Io, Self::Addr)> + Send;\n\n    /// Returns the local address that this listener is bound to.\n    fn local_addr(&self) -> io::Result<Self::Addr>;\n}\n\nimpl Listener for TcpListener {\n    type Io = TcpStream;\n    type Addr = std::net::SocketAddr;\n\n    async fn accept(&mut self) -> (Self::Io, Self::Addr) {\n        loop {\n            match Self::accept(self).await {\n                Ok(tup) => return tup,\n                Err(e) => handle_accept_error(e).await,\n            }\n        }\n    }\n\n    #[inline]\n    fn local_addr(&self) -> io::Result<Self::Addr> {\n        Self::local_addr(self)\n    }\n}\n\n#[cfg(unix)]\nimpl Listener for tokio::net::UnixListener {\n    type Io = tokio::net::UnixStream;\n    type Addr = tokio::net::unix::SocketAddr;\n\n    async fn accept(&mut self) -> (Self::Io, Self::Addr) {\n        loop {\n            match Self::accept(self).await {\n                Ok(tup) => return tup,\n                Err(e) => handle_accept_error(e).await,\n            }\n        }\n    }\n\n    #[inline]\n    fn local_addr(&self) -> io::Result<Self::Addr> {\n        Self::local_addr(self)\n    }\n}\n\n/// Extensions to [`Listener`].\npub trait ListenerExt: Listener + Sized {\n    /// Run a mutable closure on every accepted `Io`.\n    ///\n    /// # Example\n    ///\n    /// ```\n    /// use axum::{Router, routing::get, serve::ListenerExt};\n    /// use tracing::trace;\n    ///\n    /// # async {\n    /// let router = Router::new().route(\"/\", get(|| async { \"Hello, World!\" }));\n    ///\n    /// let listener = tokio::net::TcpListener::bind(\"0.0.0.0:3000\")\n    ///     .await\n    ///     .unwrap()\n    ///     .tap_io(|tcp_stream| {\n    ///         if let Err(err) = tcp_stream.set_nodelay(true) {\n    ///             trace!(\"failed to set TCP_NODELAY on incoming connection: {err:#}\");\n    ///         }\n    ///     });\n    /// axum::serve(listener, router).await.unwrap();\n    /// # };\n    /// ```\n    fn tap_io<F>(self, tap_fn: F) -> TapIo<Self, F>\n    where\n        F: FnMut(&mut Self::Io) + Send + 'static,\n    {\n        TapIo {\n            listener: self,\n            tap_fn,\n        }\n    }\n}\n\nimpl<L: Listener> ListenerExt for L {}\n\n/// Return type of [`ListenerExt::tap_io`].\n///\n/// See that method for details.\npub struct TapIo<L, F> {\n    listener: L,\n    tap_fn: F,\n}\n\nimpl<L, F> fmt::Debug for TapIo<L, F>\nwhere\n    L: Listener + fmt::Debug,\n{\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"TapIo\")\n            .field(\"listener\", &self.listener)\n            .finish_non_exhaustive()\n    }\n}\n\nimpl<L, F> Listener for TapIo<L, F>\nwhere\n    L: Listener,\n    F: FnMut(&mut L::Io) + Send + 'static,\n{\n    type Io = L::Io;\n    type Addr = L::Addr;\n\n    async fn accept(&mut self) -> (Self::Io, Self::Addr) {\n        let (mut io, addr) = self.listener.accept().await;\n        (self.tap_fn)(&mut io);\n        (io, addr)\n    }\n\n    fn local_addr(&self) -> io::Result<Self::Addr> {\n        self.listener.local_addr()\n    }\n}\n\nasync fn handle_accept_error(e: io::Error) {\n    if is_connection_error(&e) {\n        return;\n    }\n\n    // [From `hyper::Server` in 0.14](https://github.com/hyperium/hyper/blob/v0.14.27/src/server/tcp.rs#L186)\n    //\n    // > A possible scenario is that the process has hit the max open files\n    // > allowed, and so trying to accept a new connection will fail with\n    // > `EMFILE`. In some cases, it's preferable to just wait for some time, if\n    // > the application will likely close some files (or connections), and try\n    // > to accept the connection again. If this option is `true`, the error\n    // > will be logged at the `error` level, since it is still a big deal,\n    // > and then the listener will sleep for 1 second.\n    //\n    // hyper allowed customizing this but axum does not.\n    error!(\"accept error: {e}\");\n    tokio::time::sleep(Duration::from_secs(1)).await;\n}\n\nfn is_connection_error(e: &io::Error) -> bool {\n    matches!(\n        e.kind(),\n        io::ErrorKind::ConnectionRefused\n            | io::ErrorKind::ConnectionAborted\n            | io::ErrorKind::ConnectionReset\n    )\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "a189ac6f4196b3fa7ec94be8d1a70980eb7565dc",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/axum/axum-extra/src/extract/host.rs",
    "func": "use super::rejection::{FailedToResolveHost, HostRejection};\nuse axum::extract::FromRequestParts;\nuse http::{\n    header::{HeaderMap, FORWARDED},\n    request::Parts,\n    uri::Authority,\n};\n\nconst X_FORWARDED_HOST_HEADER_KEY: &str = \"X-Forwarded-Host\";\n\n/// Extractor that resolves the host of the request.\n///\n/// Host is resolved through the following, in order:\n/// - `Forwarded` header\n/// - `X-Forwarded-Host` header\n/// - `Host` header\n/// - Authority of the request URI\n///\n/// See <https://www.rfc-editor.org/rfc/rfc9110.html#name-host-and-authority> for the definition of\n/// host.\n///\n/// Note that user agents can set `X-Forwarded-Host` and `Host` headers to arbitrary values so make\n/// sure to validate them to avoid security issues.\n#[derive(Debug, Clone)]\npub struct Host(pub String);\n\nimpl<S> FromRequestParts<S> for Host\nwhere\n    S: Send + Sync,\n{\n    type Rejection = HostRejection;\n\n    async fn from_request_parts(parts: &mut Parts, _state: &S) -> Result<Self, Self::Rejection> {\n        if let Some(host) = parse_forwarded(&parts.headers) {\n            return Ok(Host(host.to_owned()));\n        }\n\n        if let Some(host) = parts\n            .headers\n            .get(X_FORWARDED_HOST_HEADER_KEY)\n            .and_then(|host| host.to_str().ok())\n        {\n            return Ok(Host(host.to_owned()));\n        }\n\n        if let Some(host) = parts\n            .headers\n            .get(http::header::HOST)\n            .and_then(|host| host.to_str().ok())\n        {\n            return Ok(Host(host.to_owned()));\n        }\n\n        if let Some(authority) = parts.uri.authority() {\n            return Ok(Host(parse_authority(authority).to_owned()));\n        }\n\n        Err(HostRejection::FailedToResolveHost(FailedToResolveHost))\n    }\n}\n\n#[allow(warnings)]\nfn parse_forwarded(headers: &HeaderMap) -> Option<&str> {\n    // if there are multiple `Forwarded` `HeaderMap::get` will return the first one\n    let forwarded_values = headers.get(FORWARDED)?.to_str().ok()?;\n\n    // get the first set of values\n    let first_value = forwarded_values.split(',').nth(0)?;\n\n    // find the value of the `host` field\n    first_value.split(';').find_map(|pair| {\n        let (key, value) = pair.split_once('=')?;\n        key.trim()\n            .eq_ignore_ascii_case(\"host\")\n            .then(|| value.trim().trim_matches('\"'))\n    })\n}\n\nfn parse_authority(auth: &Authority) -> &str {\n    auth.as_str()\n        .rsplit('@')\n        .next()\n        .expect(\"split always has at least 1 item\")\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::test_helpers::TestClient;\n    use axum::{routing::get, Router};\n    use http::{header::HeaderName, Request};\n\n    fn test_client() -> TestClient {\n        async fn host_as_body(Host(host): Host) -> String {\n            host\n        }\n\n        TestClient::new(Router::new().route(\"/\", get(host_as_body)))\n    }\n\n    #[crate::test]\n    async fn host_header() {\n        let original_host = \"some-domain:123\";\n        let host = test_client()\n            .get(\"/\")\n            .header(http::header::HOST, original_host)\n            .await\n            .text()\n            .await;\n        assert_eq!(host, original_host);\n    }\n\n    #[crate::test]\n    async fn x_forwarded_host_header() {\n        let original_host = \"some-domain:456\";\n        let host = test_client()\n            .get(\"/\")\n            .header(X_FORWARDED_HOST_HEADER_KEY, original_host)\n            .await\n            .text()\n            .await;\n        assert_eq!(host, original_host);\n    }\n\n    #[crate::test]\n    async fn x_forwarded_host_precedence_over_host_header() {\n        let x_forwarded_host_header = \"some-domain:456\";\n        let host_header = \"some-domain:123\";\n        let host = test_client()\n            .get(\"/\")\n            .header(X_FORWARDED_HOST_HEADER_KEY, x_forwarded_host_header)\n            .header(http::header::HOST, host_header)\n            .await\n            .text()\n            .await;\n        assert_eq!(host, x_forwarded_host_header);\n    }\n\n    #[crate::test]\n    async fn uri_host() {\n        let client = test_client();\n        let port = client.server_port();\n        let host = client.get(\"/\").await.text().await;\n        assert_eq!(host, format!(\"127.0.0.1:{port}\"));\n    }\n\n    #[crate::test]\n    async fn ip4_uri_host() {\n        let mut parts = Request::new(()).into_parts().0;\n        parts.uri = \"https://127.0.0.1:1234/image.jpg\".parse().unwrap();\n        let host = Host::from_request_parts(&mut parts, &()).await.unwrap();\n        assert_eq!(host.0, \"127.0.0.1:1234\");\n    }\n\n    #[crate::test]\n    async fn ip6_uri_host() {\n        let mut parts = Request::new(()).into_parts().0;\n        parts.uri = \"http://cool:user@[::1]:456/file.txt\".parse().unwrap();\n        let host = Host::from_request_parts(&mut parts, &()).await.unwrap();\n        assert_eq!(host.0, \"[::1]:456\");\n    }\n\n    #[test]\n    fn forwarded_parsing() {\n        // the basic case\n        let headers = header_map(&[(FORWARDED, \"host=192.0.2.60;proto=http;by=203.0.113.43\")]);\n        let value = parse_forwarded(&headers).unwrap();\n        assert_eq!(value, \"192.0.2.60\");\n\n        // is case insensitive\n        let headers = header_map(&[(FORWARDED, \"host=192.0.2.60;proto=http;by=203.0.113.43\")]);\n        let value = parse_forwarded(&headers).unwrap();\n        assert_eq!(value, \"192.0.2.60\");\n\n        // ipv6\n        let headers = header_map(&[(FORWARDED, \"host=\\\"[2001:db8:cafe::17]:4711\\\"\")]);\n        let value = parse_forwarded(&headers).unwrap();\n        assert_eq!(value, \"[2001:db8:cafe::17]:4711\");\n\n        // multiple values in one header\n        let headers = header_map(&[(FORWARDED, \"host=192.0.2.60, host=127.0.0.1\")]);\n        let value = parse_forwarded(&headers).unwrap();\n        assert_eq!(value, \"192.0.2.60\");\n\n        // multiple header values\n        let headers = header_map(&[\n            (FORWARDED, \"host=192.0.2.60\"),\n            (FORWARDED, \"host=127.0.0.1\"),\n        ]);\n        let value = parse_forwarded(&headers).unwrap();\n        assert_eq!(value, \"192.0.2.60\");\n    }\n\n    fn header_map(values: &[(HeaderName, &str)]) -> HeaderMap {\n        let mut headers = HeaderMap::new();\n        for (key, value) in values {\n            headers.append(key, value.parse().unwrap());\n        }\n        headers\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "b57f992829e244c3f0a99b51dfe3a6799dd633ea",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/axum/axum-extra/src/extract/query.rs",
    "func": "use axum::{\n    extract::FromRequestParts,\n    response::{IntoResponse, Response},\n    Error,\n};\nuse http::{request::Parts, StatusCode};\nuse serde::de::DeserializeOwned;\nuse std::fmt;\n\n/// Extractor that deserializes query strings into some type.\n///\n/// `T` is expected to implement [`serde::Deserialize`].\n///\n/// # Differences from `axum::extract::Query`\n///\n/// This extractor uses [`serde_html_form`] under-the-hood which supports multi-value items. These\n/// are sent by multiple `<input>` attributes of the same name (e.g. checkboxes) and `<select>`s\n/// with the `multiple` attribute. Those values can be collected into a `Vec` or other sequential\n/// container.\n///\n/// # Example\n///\n/// ```rust,no_run\n/// use axum::{routing::get, Router};\n/// use axum_extra::extract::Query;\n/// use serde::Deserialize;\n///\n/// #[derive(Deserialize)]\n/// struct Pagination {\n///     page: usize,\n///     per_page: usize,\n/// }\n///\n/// // This will parse query strings like `?page=2&per_page=30` into `Pagination`\n/// // structs.\n/// async fn list_things(pagination: Query<Pagination>) {\n///     let pagination: Pagination = pagination.0;\n///\n///     // ...\n/// }\n///\n/// let app = Router::new().route(\"/list_things\", get(list_things));\n/// # let _: Router = app;\n/// ```\n///\n/// If the query string cannot be parsed it will reject the request with a `400\n/// Bad Request` response.\n///\n/// For handling values being empty vs missing see the [query-params-with-empty-strings][example]\n/// example.\n///\n/// [example]: https://github.com/tokio-rs/axum/blob/main/examples/query-params-with-empty-strings/src/main.rs\n///\n/// While `Option<T>` will handle empty parameters (e.g. `param=`), beware when using this with a\n/// `Vec<T>`. If your list is optional, use `Vec<T>` in combination with `#[serde(default)]`\n/// instead of `Option<Vec<T>>`. `Option<Vec<T>>` will handle 0, 2, or more arguments, but not one\n/// argument.\n///\n/// # Example\n///\n/// ```rust,no_run\n/// use axum::{routing::get, Router};\n/// use axum_extra::extract::Query;\n/// use serde::Deserialize;\n///\n/// #[derive(Deserialize)]\n/// struct Params {\n///     #[serde(default)]\n///     items: Vec<usize>,\n/// }\n///\n/// // This will parse 0 occurrences of `items` as an empty `Vec`.\n/// async fn process_items(Query(params): Query<Params>) {\n///     // ...\n/// }\n///\n/// let app = Router::new().route(\"/process_items\", get(process_items));\n/// # let _: Router = app;\n/// ```\n#[cfg_attr(docsrs, doc(cfg(feature = \"query\")))]\n#[derive(Debug, Clone, Copy, Default)]\npub struct Query<T>(pub T);\n\nimpl<T, S> FromRequestParts<S> for Query<T>\nwhere\n    T: DeserializeOwned,\n    S: Send + Sync,\n{\n    type Rejection = QueryRejection;\n\n    async fn from_request_parts(parts: &mut Parts, _state: &S) -> Result<Self, Self::Rejection> {\n        let query = parts.uri.query().unwrap_or_default();\n        let value = serde_html_form::from_str(query)\n            .map_err(|err| QueryRejection::FailedToDeserializeQueryString(Error::new(err)))?;\n        Ok(Query(value))\n    }\n}\n\naxum_core::__impl_deref!(Query);\n\n/// Rejection used for [`Query`].\n///\n/// Contains one variant for each way the [`Query`] extractor can fail.\n#[derive(Debug)]\n#[non_exhaustive]\n#[cfg(feature = \"query\")]\npub enum QueryRejection {\n    #[allow(missing_docs)]\n    FailedToDeserializeQueryString(Error),\n}\n\nimpl IntoResponse for QueryRejection {\n    fn into_response(self) -> Response {\n        match self {\n            Self::FailedToDeserializeQueryString(inner) => {\n                let body = format!(\"Failed to deserialize query string: {inner}\");\n                let status = StatusCode::BAD_REQUEST;\n                axum_core::__log_rejection!(\n                    rejection_type = Self,\n                    body_text = body,\n                    status = status,\n                );\n                (status, body).into_response()\n            }\n        }\n    }\n}\n\nimpl fmt::Display for QueryRejection {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match self {\n            Self::FailedToDeserializeQueryString(inner) => inner.fmt(f),\n        }\n    }\n}\n\nimpl std::error::Error for QueryRejection {\n    fn source(&self) -> Option<&(dyn std::error::Error + 'static)> {\n        match self {\n            Self::FailedToDeserializeQueryString(inner) => Some(inner),\n        }\n    }\n}\n\n/// Extractor that deserializes query strings into `None` if no query parameters are present.\n/// Otherwise behaviour is identical to [`Query`]\n///\n/// `T` is expected to implement [`serde::Deserialize`].\n///\n/// # Example\n///\n/// ```rust,no_run\n/// use axum::{routing::get, Router};\n/// use axum_extra::extract::OptionalQuery;\n/// use serde::Deserialize;\n///\n/// #[derive(Deserialize)]\n/// struct Pagination {\n///     page: usize,\n///     per_page: usize,\n/// }\n///\n/// // This will parse query strings like `?page=2&per_page=30` into `Some(Pagination)` and\n/// // empty query string into `None`\n/// async fn list_things(OptionalQuery(pagination): OptionalQuery<Pagination>) {\n///     match pagination {\n///         Some(Pagination{ page, per_page }) => { /* return specified page */ },\n///         None => { /* return fist page */ }\n///     }\n///     // ...\n/// }\n///\n/// let app = Router::new().route(\"/list_things\", get(list_things));\n/// # let _: Router = app;\n/// ```\n///\n/// If the query string cannot be parsed it will reject the request with a `400\n/// Bad Request` response.\n///\n/// For handling values being empty vs missing see the [query-params-with-empty-strings][example]\n/// example.\n///\n/// [example]: https://github.com/tokio-rs/axum/blob/main/examples/query-params-with-empty-strings/src/main.rs\n#[cfg_attr(docsrs, doc(cfg(feature = \"query\")))]\n#[derive(Debug, Clone, Copy, Default)]\npub struct OptionalQuery<T>(pub Option<T>);\n\nimpl<T, S> FromRequestParts<S> for OptionalQuery<T>\nwhere\n    T: DeserializeOwned,\n    S: Send + Sync,\n{\n    type Rejection = OptionalQueryRejection;\n\n    async fn from_request_parts(parts: &mut Parts, _state: &S) -> Result<Self, Self::Rejection> {\n        if let Some(query) = parts.uri.query() {\n            let value = serde_html_form::from_str(query).map_err(|err| {\n                OptionalQueryRejection::FailedToDeserializeQueryString(Error::new(err))\n            })?;\n            Ok(OptionalQuery(Some(value)))\n        } else {\n            Ok(OptionalQuery(None))\n        }\n    }\n}\n\nimpl<T> std::ops::Deref for OptionalQuery<T> {\n    type Target = Option<T>;\n\n    #[inline]\n    fn deref(&self) -> &Self::Target {\n        &self.0\n    }\n}\n\nimpl<T> std::ops::DerefMut for OptionalQuery<T> {\n    #[inline]\n    fn deref_mut(&mut self) -> &mut Self::Target {\n        &mut self.0\n    }\n}\n\n/// Rejection used for [`OptionalQuery`].\n///\n/// Contains one variant for each way the [`OptionalQuery`] extractor can fail.\n#[derive(Debug)]\n#[non_exhaustive]\n#[cfg(feature = \"query\")]\npub enum OptionalQueryRejection {\n    #[allow(missing_docs)]\n    FailedToDeserializeQueryString(Error),\n}\n\nimpl IntoResponse for OptionalQueryRejection {\n    fn into_response(self) -> Response {\n        match self {\n            Self::FailedToDeserializeQueryString(inner) => (\n                StatusCode::BAD_REQUEST,\n                format!(\"Failed to deserialize query string: {inner}\"),\n            )\n                .into_response(),\n        }\n    }\n}\n\nimpl fmt::Display for OptionalQueryRejection {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match self {\n            Self::FailedToDeserializeQueryString(inner) => inner.fmt(f),\n        }\n    }\n}\n\nimpl std::error::Error for OptionalQueryRejection {\n    fn source(&self) -> Option<&(dyn std::error::Error + 'static)> {\n        match self {\n            Self::FailedToDeserializeQueryString(inner) => Some(inner),\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::test_helpers::*;\n    use axum::{routing::post, Router};\n    use http::header::CONTENT_TYPE;\n    use serde::Deserialize;\n\n    #[tokio::test]\n    async fn query_supports_multiple_values() {\n        #[derive(Deserialize)]\n        struct Data {\n            #[serde(rename = \"value\")]\n            values: Vec<String>,\n        }\n\n        let app = Router::new().route(\n            \"/\",\n            post(|Query(data): Query<Data>| async move { data.values.join(\",\") }),\n        );\n\n        let client = TestClient::new(app);\n\n        let res = client\n            .post(\"/?value=one&value=two\")\n            .header(CONTENT_TYPE, \"application/x-www-form-urlencoded\")\n            .body(\"\")\n            .await;\n\n        assert_eq!(res.status(), StatusCode::OK);\n        assert_eq!(res.text().await, \"one,two\");\n    }\n\n    #[tokio::test]\n    async fn optional_query_supports_multiple_values() {\n        #[derive(Deserialize)]\n        struct Data {\n            #[serde(rename = \"value\")]\n            values: Vec<String>,\n        }\n\n        let app = Router::new().route(\n            \"/\",\n            post(|OptionalQuery(data): OptionalQuery<Data>| async move {\n                data.map(|Data { values }| values.join(\",\"))\n                    .unwrap_or(\"None\".to_owned())\n            }),\n        );\n\n        let client = TestClient::new(app);\n\n        let res = client\n            .post(\"/?value=one&value=two\")\n            .header(CONTENT_TYPE, \"application/x-www-form-urlencoded\")\n            .body(\"\")\n            .await;\n\n        assert_eq!(res.status(), StatusCode::OK);\n        assert_eq!(res.text().await, \"one,two\");\n    }\n\n    #[tokio::test]\n    async fn optional_query_deserializes_no_parameters_into_none() {\n        #[derive(Deserialize)]\n        struct Data {\n            value: String,\n        }\n\n        let app = Router::new().route(\n            \"/\",\n            post(|OptionalQuery(data): OptionalQuery<Data>| async move {\n                match data {\n                    None => \"None\".into(),\n                    Some(data) => data.value,\n                }\n            }),\n        );\n\n        let client = TestClient::new(app);\n\n        let res = client.post(\"/\").body(\"\").await;\n\n        assert_eq!(res.status(), StatusCode::OK);\n        assert_eq!(res.text().await, \"None\");\n    }\n\n    #[tokio::test]\n    async fn optional_query_preserves_parsing_errors() {\n        #[derive(Deserialize)]\n        struct Data {\n            value: String,\n        }\n\n        let app = Router::new().route(\n            \"/\",\n            post(|OptionalQuery(data): OptionalQuery<Data>| async move {\n                match data {\n                    None => \"None\".into(),\n                    Some(data) => data.value,\n                }\n            }),\n        );\n\n        let client = TestClient::new(app);\n\n        let res = client\n            .post(\"/?other=something\")\n            .header(CONTENT_TYPE, \"application/x-www-form-urlencoded\")\n            .body(\"\")\n            .await;\n\n        assert_eq!(res.status(), StatusCode::BAD_REQUEST);\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "5aa87238b67e674cac77ff15665cdbf09438942d",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/Rocket/core/lib/tests/multipart-limit.rs",
    "func": "#[macro_use] extern crate rocket;\n\nuse rocket::{Config, Build, Rocket};\nuse rocket::{data::Limits, form::Form};\nuse rocket::http::{ContentType, Status};\nuse ubyte::{ToByteUnit, ByteUnit};\n\n#[derive(FromForm)]\nstruct Data<'r> {\n    foo: Option<&'r str>,\n}\n\n#[rocket::post(\"/\", data = \"<form>\")]\nfn form<'r>(form: Form<Data<'r>>) -> &'r str {\n    form.foo.unwrap_or(\"missing\")\n}\n\nfn rocket_with_form_data_limit(limit: ByteUnit) -> Rocket<Build> {\n    rocket::custom(Config {\n        limits: Limits::default().limit(\"data-form\", limit),\n        ..Config::debug_default()\n    }).mount(\"/\", routes![form])\n}\n\n#[test]\nfn test_multipart_limit() {\n    use rocket::local::blocking::Client;\n\n    let body = &[\n        \"--X-BOUNDARY\",\n        r#\"Content-Disposition: form-data; name=\"foo\"; filename=\"foo.txt\"\"#,\n        \"Content-Type: text/plain\",\n        \"\",\n        \"hi\",\n        \"--X-BOUNDARY--\",\n        \"\",\n    ].join(\"\\r\\n\");\n\n    let client = Client::debug(rocket_with_form_data_limit(body.len().bytes())).unwrap();\n    let response = client.post(\"/\")\n        .header(\"multipart/form-data; boundary=X-BOUNDARY\".parse::<ContentType>().unwrap())\n        .body(body)\n        .dispatch();\n\n    assert_eq!(response.into_string().unwrap(), \"hi\");\n\n    let client = Client::debug(rocket_with_form_data_limit(body.len().bytes() - 1)).unwrap();\n    let response = client.post(\"/\")\n        .header(\"multipart/form-data; boundary=X-BOUNDARY\".parse::<ContentType>().unwrap())\n        .body(body)\n        .dispatch();\n\n    assert_eq!(response.status(), Status::PayloadTooLarge);\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "b632fd8ecd88cbbbe555dd7151b6c51c0ab7d3f9",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/Rocket/core/lib/tests/on_launch_fairing_can_inspect_port.rs",
    "func": "use std::net::{SocketAddr, Ipv4Addr};\n\nuse rocket::config::Config;\nuse rocket::fairing::AdHoc;\nuse rocket::futures::channel::oneshot;\nuse rocket::listener::tcp::TcpListener;\n\n#[rocket::async_test]\nasync fn on_ignite_fairing_can_inspect_port() {\n    let (tx, rx) = oneshot::channel();\n    let rocket = rocket::custom(Config::debug_default())\n        .attach(AdHoc::on_liftoff(\"Send Port -> Channel\", move |rocket| {\n            Box::pin(async move {\n                let tcp = rocket.endpoints().find_map(|v| v.tcp());\n                tx.send(tcp.unwrap().port()).expect(\"send okay\");\n            })\n        }));\n\n    let addr = SocketAddr::from((Ipv4Addr::LOCALHOST, 0));\n    rocket::tokio::spawn(rocket.try_launch_on(TcpListener::bind(addr)));\n    assert_ne!(rx.await.unwrap(), 0);\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "49a92840d07a29c562be3f6dee34416df10e8004",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/Rocket/core/lib/tests/local_request_private_cookie-issue-368.rs",
    "func": "#![cfg(feature = \"secrets\")]\n\nuse rocket::http::CookieJar;\n\n#[rocket::get(\"/\")]\nfn return_private_cookie(cookies: &CookieJar<'_>) -> Option<String> {\n    match cookies.get_private(\"cookie_name\") {\n        Some(cookie) => Some(cookie.value().into()),\n        None => None,\n    }\n}\n\nmod tests {\n    use super::*;\n    use rocket::routes;\n    use rocket::local::blocking::Client;\n    use rocket::http::Status;\n\n    #[test]\n    fn private_cookie_is_returned() {\n        let rocket = rocket::build().mount(\"/\", routes![return_private_cookie]);\n\n        let client = Client::debug(rocket).unwrap();\n        let req = client.get(\"/\").private_cookie((\"cookie_name\", \"cookie_value\"));\n        let response = req.dispatch();\n\n        assert_eq!(response.headers().get_one(\"Set-Cookie\"), None);\n        assert_eq!(response.into_string(), Some(\"cookie_value\".into()));\n    }\n\n    #[test]\n    fn regular_cookie_is_not_returned() {\n        let rocket = rocket::build().mount(\"/\", routes![return_private_cookie]);\n\n        let client = Client::debug(rocket).unwrap();\n        let req = client.get(\"/\").cookie((\"cookie_name\", \"cookie_value\"));\n        let response = req.dispatch();\n\n        assert_eq!(response.status(), Status::NotFound);\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "e548ecbcf6442e6dca1e760216516a21593c1f73",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/Rocket/core/lib/fuzz/targets/uri-normalization.rs",
    "func": "#![no_main]\n\nuse rocket::http::uri::*;\nuse libfuzzer_sys::fuzz_target;\n\nfn fuzz(data: &str) {\n    if let Ok(uri) = Uri::parse_any(data) {\n        match uri {\n            Uri::Origin(uri) if uri.is_normalized() => {\n                assert_eq!(uri.clone(), uri.into_normalized());\n            }\n            Uri::Absolute(uri) if uri.is_normalized() => {\n                assert_eq!(uri.clone(), uri.into_normalized());\n            }\n            Uri::Reference(uri) if uri.is_normalized() => {\n                assert_eq!(uri.clone(), uri.into_normalized());\n            }\n            _ => { /* not normalizable */ },\n        }\n    }\n}\n\nfuzz_target!(|data: &str| fuzz(data));\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "53be5e4b1a093083f7f24fc658ece5e1b4b9b1f1",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/Rocket/core/lib/fuzz/targets/uri-roundtrip.rs",
    "func": "#![no_main]\n\nuse rocket::http::uri::*;\nuse libfuzzer_sys::fuzz_target;\n\nfn fuzz(data: &str) {\n    if let Ok(uri) = Uri::parse_any(data) {\n        let string = uri.to_string();\n        let _ = match uri {\n            Uri::Asterisk(_) => Asterisk::parse_owned(string).expect(\"Asterisk\").to_string(),\n            Uri::Origin(_) => Origin::parse_owned(string).expect(\"Origin\").to_string(),\n            Uri::Authority(_) => Authority::parse_owned(string).expect(\"Authority\").to_string(),\n            Uri::Absolute(_) => Absolute::parse_owned(string).expect(\"Absolute\").to_string(),\n            Uri::Reference(_) => Reference::parse_owned(string).expect(\"Reference\").to_string(),\n        };\n    }\n}\n\nfuzz_target!(|data: &[u8]| {\n    let _ = std::str::from_utf8(data).map(fuzz);\n});\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "09ec9e5ff56f28abfdef61ba1e7d5f5eefd75723",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/Rocket/core/lib/src/data/io_stream.rs",
    "func": "use std::io;\nuse std::task::{Context, Poll};\nuse std::pin::Pin;\n\nuse tokio::io::{AsyncRead, AsyncWrite, ReadBuf};\nuse hyper::upgrade::Upgraded;\nuse hyper_util::rt::TokioIo;\n\n/// A bidirectional, raw stream to the client.\n///\n/// An instance of `IoStream` is passed to an [`IoHandler`] in response to a\n/// successful upgrade request initiated by responders via\n/// [`Response::add_upgrade()`] or the equivalent builder method\n/// [`Builder::upgrade()`]. For details on upgrade connections, see\n/// [`Response`#upgrading].\n///\n/// An `IoStream` is guaranteed to be [`AsyncRead`], [`AsyncWrite`], and\n/// `Unpin`. Bytes written to the stream are sent directly to the client. Bytes\n/// read from the stream are those sent directly _by_ the client. See\n/// [`IoHandler`] for one example of how values of this type are used.\n///\n/// [`Response::add_upgrade()`]: crate::Response::add_upgrade()\n/// [`Builder::upgrade()`]: crate::response::Builder::upgrade()\n/// [`Response`#upgrading]: crate::response::Response#upgrading\npub struct IoStream {\n    kind: IoStreamKind,\n}\n\n/// Just in case we want to add stream kinds in the future.\nenum IoStreamKind {\n    Upgraded(TokioIo<Upgraded>)\n}\n\n/// An upgraded connection I/O handler.\n///\n/// An I/O handler performs raw I/O via the passed in [`IoStream`], which is\n/// [`AsyncRead`], [`AsyncWrite`], and `Unpin`.\n///\n/// # Example\n///\n/// The example below implements an `EchoHandler` that echos the raw bytes back\n/// to the client.\n///\n/// ```rust\n/// use std::pin::Pin;\n///\n/// use rocket::tokio::io;\n/// use rocket::data::{IoHandler, IoStream};\n///\n/// struct EchoHandler;\n///\n/// #[rocket::async_trait]\n/// impl IoHandler for EchoHandler {\n///     async fn io(self: Box<Self>, io: IoStream) -> io::Result<()> {\n///         let (mut reader, mut writer) = io::split(io);\n///         io::copy(&mut reader, &mut writer).await?;\n///         Ok(())\n///     }\n/// }\n///\n/// # use rocket::Response;\n/// # rocket::async_test(async {\n/// # let mut response = Response::new();\n/// # response.add_upgrade(\"raw-echo\", EchoHandler);\n/// # assert!(response.upgrade(\"raw-echo\").is_some());\n/// # })\n/// ```\n#[crate::async_trait]\npub trait IoHandler: Send {\n    /// Performs the raw I/O.\n    async fn io(self: Box<Self>, io: IoStream) -> io::Result<()>;\n}\n\n#[crate::async_trait]\nimpl IoHandler for () {\n    async fn io(self: Box<Self>, _: IoStream) -> io::Result<()> {\n        Ok(())\n    }\n}\n\n#[doc(hidden)]\nimpl From<Upgraded> for IoStream {\n    fn from(io: Upgraded) -> Self {\n        IoStream { kind: IoStreamKind::Upgraded(TokioIo::new(io)) }\n    }\n}\n\n/// A \"trait alias\" of sorts so we can use `AsyncRead + AsyncWrite + Unpin` in `dyn`.\npub trait AsyncReadWrite: AsyncRead + AsyncWrite + Unpin { }\n\n/// Implemented for all `AsyncRead + AsyncWrite + Unpin`, of course.\nimpl<T: AsyncRead + AsyncWrite + Unpin> AsyncReadWrite for T {  }\n\nimpl IoStream {\n    /// Returns the internal I/O stream.\n    fn inner_mut(&mut self) -> Pin<&mut dyn AsyncReadWrite> {\n        match self.kind {\n            IoStreamKind::Upgraded(ref mut io) => Pin::new(io),\n        }\n    }\n\n    /// Returns `true` if the inner I/O stream is write vectored.\n    fn inner_is_write_vectored(&self) -> bool {\n        match self.kind {\n            IoStreamKind::Upgraded(ref io) => io.is_write_vectored(),\n        }\n    }\n}\n\nimpl AsyncRead for IoStream {\n    fn poll_read(\n        self: Pin<&mut Self>,\n        cx: &mut Context<'_>,\n        buf: &mut ReadBuf<'_>,\n    ) -> Poll<io::Result<()>> {\n        self.get_mut().inner_mut().poll_read(cx, buf)\n    }\n}\n\nimpl AsyncWrite for IoStream {\n    fn poll_write(\n        self: Pin<&mut Self>,\n        cx: &mut Context<'_>,\n        buf: &[u8],\n    ) -> Poll<io::Result<usize>> {\n        self.get_mut().inner_mut().poll_write(cx, buf)\n    }\n\n    fn poll_flush(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<io::Result<()>> {\n        self.get_mut().inner_mut().poll_flush(cx)\n    }\n\n    fn poll_shutdown(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<io::Result<()>> {\n        self.get_mut().inner_mut().poll_shutdown(cx)\n    }\n\n    fn poll_write_vectored(\n        self: Pin<&mut Self>,\n        cx: &mut Context<'_>,\n        bufs: &[io::IoSlice<'_>],\n    ) -> Poll<io::Result<usize>> {\n        self.get_mut().inner_mut().poll_write_vectored(cx, bufs)\n    }\n\n    fn is_write_vectored(&self) -> bool {\n        self.inner_is_write_vectored()\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn is_unpin() {\n        fn check_traits<T: AsyncRead + AsyncWrite + Unpin + Send>() {}\n        check_traits::<IoStream>();\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "cbb4dc4ac03230358263b45f655393452f04788b",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/Rocket/core/lib/src/data/from_data.rs",
    "func": "use crate::http::{RawStr, Status};\nuse crate::request::{Request, local_cache};\nuse crate::data::{Data, Limits};\nuse crate::outcome::{self, IntoOutcome, try_outcome, Outcome::*};\n\n/// Type alias for the `Outcome` of [`FromData`].\n///\n/// [`FromData`]: crate::data::FromData\npub type Outcome<'r, T, E = <T as FromData<'r>>::Error>\n    = outcome::Outcome<T, (Status, E), (Data<'r>, Status)>;\n\n/// Trait implemented by data guards to derive a value from request body data.\n///\n/// # Data Guards\n///\n/// A data guard is a guard that operates on a request's body data. Data guards\n/// validate and parse request body data via implementations of `FromData`. In\n/// other words, a type is a data guard _iff_ it implements `FromData`.\n///\n/// Data guards are the target of the `data` route attribute parameter:\n///\n/// ```rust\n/// # #[macro_use] extern crate rocket;\n/// # type DataGuard = String;\n/// #[post(\"/submit\", data = \"<var>\")]\n/// fn submit(var: DataGuard) { /* ... */ }\n/// ```\n///\n/// A route can have at most one data guard. Above, `var` is used as the\n/// argument name for the data guard type `DataGuard`. When the `submit` route\n/// matches, Rocket will call the `FromData` implementation for the type `T`.\n/// The handler will only be called if the guard returns successfully.\n///\n/// ## Build-In Guards\n///\n/// Rocket provides implementations for `FromData` for many types. Their\n/// behavior is documented here:\n///\n///   * `Data`: Returns the untouched `Data`.\n///\n///     - **Fails:** Never.\n///\n///     - **Succeeds:** Always.\n///\n///     - **Forwards:** Never.\n///\n///   * Strings: `Cow<str>`, `&str`, `&RawStr`, `String`\n///\n///     _Limited by the `string` [data limit]._\n///\n///     Reads the body data into a string via [`DataStream::into_string()`].\n///\n///     - **Fails:** If the body data is not valid UTF-8 or on I/O errors while\n///     reading. The error type is [`io::Error`].\n///\n///     - **Succeeds:** If the body data _is_ valid UTF-8. If the limit is\n///     exceeded, the string is truncated to the limit.\n///\n///     - **Forwards:** Never.\n///\n///   * Bytes: `&[u8]`, `Vec<u8>`\n///\n///     _Limited by the `bytes` [data limit]._\n///\n///     Reads the body data into a byte vector via [`DataStream::into_bytes()`].\n///\n///     - **Fails:** On I/O errors while reading. The error type is\n///     [`io::Error`].\n///\n///     - **Succeeds:** As long as no I/O error occurs. If the limit is\n///     exceeded, the slice is truncated to the limit.\n///\n///     - **Forwards:** Never.\n///\n///   * [`TempFile`](crate::fs::TempFile)\n///\n///     _Limited by the `file` and/or `file/$ext` [data limit]._\n///\n///     Streams the body data directly into a temporary file. The data is never\n///     buffered in memory.\n///\n///     - **Fails:** On I/O errors while reading data or creating the temporary\n///     file. The error type is [`io::Error`].\n///\n///     - **Succeeds:** As long as no I/O error occurs and the temporary file\n///     could be created. If the limit is exceeded, only data up to the limit is\n///     read and subsequently written.\n///\n///     - **Forwards:** Never.\n///\n///   * Deserializers: [`Json<T>`], [`MsgPack<T>`]\n///\n///     _Limited by the `json`, `msgpack` [data limit], respectively._\n///\n///     Reads up to the configured limit and deserializes the read data into `T`\n///     using the respective format's parser.\n///\n///     - **Fails:** On I/O errors while reading the data, or if the data fails\n///     to parse as a `T` according to the deserializer. The error type for\n///     `Json` is [`json::Error`](crate::serde::json::Error) and the error type\n///     for `MsgPack` is [`msgpack::Error`](crate::serde::msgpack::Error).\n///\n///     - **Succeeds:** As long as no I/O error occurs and the (limited) body\n///     data was successfully deserialized as a `T`.\n///\n///     - **Forwards:** Never.\n///\n///   * Forms: [`Form<T>`]\n///\n///     _Limited by the `form` or `data-form` [data limit]._\n///\n///     Parses the incoming data stream into fields according to Rocket's [field\n///     wire format], pushes each field to `T`'s [`FromForm`] [push parser], and\n///     finalizes the form. Parsing is done on the stream without reading the\n///     data into memory. If the request has as a [`ContentType::Form`], the\n///     `form` limit is applied, otherwise if the request has a\n///     [`ContentType::FormData`], the `data-form` limit is applied.\n///\n///     - **Fails:** On I/O errors while reading the data, or if the data fails\n///     to parse as a `T` according to its `FromForm` implementation. The errors\n///     are collected into an [`Errors`](crate::form::Errors), the error type.\n///\n///     - **Succeeds:** As long as no I/O error occurs and the (limited) body\n///     data was successfully parsed as a `T`.\n///\n///     - **Forwards:** If the request's `Content-Type` is neither\n///     [`ContentType::Form`] nor [`ContentType::FormData`].\n///\n///   * `Option<T>`\n///\n///     Forwards to `T`'s `FromData` implementation, capturing the outcome.\n///\n///     - **Fails:** Never.\n///\n///     - **Succeeds:** Always. If `T`'s `FromData` implementation succeeds, the\n///     parsed value is returned in `Some`. If its implementation forwards or\n///     fails, `None` is returned.\n///\n///     - **Forwards:** Never.\n///\n///   * `Result<T, T::Error>`\n///\n///     Forwards to `T`'s `FromData` implementation, capturing the outcome.\n///\n///     - **Fails:** Never.\n///\n///     - **Succeeds:** If `T`'s `FromData` implementation succeeds or fails. If\n///     it succeeds, the value is returned in `Ok`. If it fails, the error value\n///     is returned in `Err`.\n///\n///     - **Forwards:** If `T`'s implementation forwards.\n///\n///   * [`Capped<T>`]\n///\n///     Forwards to `T`'s `FromData` implementation, recording whether the data\n///     was truncated (a.k.a. capped) due to `T`'s limit being exceeded.\n///\n///     - **Fails:** If `T`'s implementation fails.\n///     - **Succeeds:** If `T`'s implementation succeeds.\n///     - **Forwards:** If `T`'s implementation forwards.\n///\n/// [data limit]: crate::data::Limits#built-in-limits\n/// [`DataStream::into_string()`]: crate::data::DataStream::into_string()\n/// [`DataStream::into_bytes()`]: crate::data::DataStream::into_bytes()\n/// [`io::Error`]: std::io::Error\n/// [`Json<T>`]: crate::serde::json::Json\n/// [`MsgPack<T>`]: crate::serde::msgpack::MsgPack\n/// [`Form<T>`]: crate::form::Form\n/// [field wire format]: crate::form#field-wire-format\n/// [`FromForm`]: crate::form::FromForm\n/// [push parser]: crate::form::FromForm#push-parsing\n/// [`ContentType::Form`]: crate::http::ContentType::Form\n/// [`ContentType::FormData`]: crate::http::ContentType::FormData\n///\n/// ## Async Trait\n///\n/// [`FromData`] is an _async_ trait. Implementations of `FromData` must be\n/// decorated with an attribute of `#[rocket::async_trait]`:\n///\n/// ```rust\n/// use rocket::request::Request;\n/// use rocket::data::{self, Data, FromData};\n/// # struct MyType;\n/// # type MyError = String;\n///\n/// #[rocket::async_trait]\n/// impl<'r> FromData<'r> for MyType {\n///     type Error = MyError;\n///\n///     async fn from_data(req: &'r Request<'_>, data: Data<'r>) -> data::Outcome<'r, Self> {\n///         /* .. */\n///         # unimplemented!()\n///     }\n/// }\n/// ```\n///\n/// # Example\n///\n/// Say that you have a custom type, `Person`:\n///\n/// ```rust\n/// struct Person<'r> {\n///     name: &'r str,\n///     age: u16\n/// }\n/// ```\n///\n/// `Person` has a custom serialization format, so the built-in `Json` type\n/// doesn't suffice. The format is `<name>:<age>` with `Content-Type:\n/// application/x-person`. You'd like to use `Person` as a data guard, so that\n/// you can retrieve it directly from a client's request body:\n///\n/// ```rust\n/// # use rocket::post;\n/// # type Person<'r> = &'r rocket::http::RawStr;\n/// #[post(\"/person\", data = \"<person>\")]\n/// fn person(person: Person<'_>) -> &'static str {\n///     \"Saved the new person to the database!\"\n/// }\n/// ```\n///\n/// A `FromData` implementation for such a type might look like:\n///\n/// ```rust\n/// # #[macro_use] extern crate rocket;\n/// #\n/// # #[derive(Debug)]\n/// # struct Person<'r> { name: &'r str, age: u16 }\n/// #\n/// use rocket::request::{self, Request};\n/// use rocket::data::{self, Data, FromData, ToByteUnit};\n/// use rocket::http::{Status, ContentType};\n/// use rocket::outcome::Outcome;\n///\n/// #[derive(Debug)]\n/// enum Error {\n///     TooLarge,\n///     NoColon,\n///     InvalidAge,\n///     Io(std::io::Error),\n/// }\n///\n/// #[rocket::async_trait]\n/// impl<'r> FromData<'r> for Person<'r> {\n///     type Error = Error;\n///\n///     async fn from_data(req: &'r Request<'_>, data: Data<'r>) -> data::Outcome<'r, Self> {\n///         use Error::*;\n///\n///         // Ensure the content type is correct before opening the data.\n///         let person_ct = ContentType::new(\"application\", \"x-person\");\n///         if req.content_type() != Some(&person_ct) {\n///             return Outcome::Forward((data, Status::UnsupportedMediaType));\n///         }\n///\n///         // Use a configured limit with name 'person' or fallback to default.\n///         let limit = req.limits().get(\"person\").unwrap_or(256.bytes());\n///\n///         // Read the data into a string.\n///         let string = match data.open(limit).into_string().await {\n///             Ok(string) if string.is_complete() => string.into_inner(),\n///             Ok(_) => return Outcome::Error((Status::PayloadTooLarge, TooLarge)),\n///             Err(e) => return Outcome::Error((Status::InternalServerError, Io(e))),\n///         };\n///\n///         // We store `string` in request-local cache for long-lived borrows.\n///         let string = request::local_cache!(req, string);\n///\n///         // Split the string into two pieces at ':'.\n///         let (name, age) = match string.find(':') {\n///             Some(i) => (&string[..i], &string[(i + 1)..]),\n///             None => return Outcome::Error((Status::UnprocessableEntity, NoColon)),\n///         };\n///\n///         // Parse the age.\n///         let age: u16 = match age.parse() {\n///             Ok(age) => age,\n///             Err(_) => return Outcome::Error((Status::UnprocessableEntity, InvalidAge)),\n///         };\n///\n///         Outcome::Success(Person { name, age })\n///     }\n/// }\n///\n/// // The following routes now typecheck...\n///\n/// #[post(\"/person\", data = \"<person>\")]\n/// fn person(person: Person<'_>) { /* .. */ }\n///\n/// #[post(\"/person\", data = \"<person>\")]\n/// fn person2(person: Result<Person<'_>, Error>) { /* .. */ }\n///\n/// #[post(\"/person\", data = \"<person>\")]\n/// fn person3(person: Option<Person<'_>>) { /* .. */ }\n///\n/// #[post(\"/person\", data = \"<person>\")]\n/// fn person4(person: Person<'_>) -> &str {\n///     // Note that this is only possible because the data in `person` live\n///     // as long as the request through request-local cache.\n///     person.name\n/// }\n/// ```\n#[crate::async_trait]\npub trait FromData<'r>: Sized {\n    /// The associated error to be returned when the guard fails.\n    type Error: Send + std::fmt::Debug;\n\n    /// Asynchronously validates, parses, and converts an instance of `Self`\n    /// from the incoming request body data.\n    ///\n    /// If validation and parsing succeeds, an outcome of `Success` is returned.\n    /// If the data is not appropriate given the type of `Self`, `Forward` is\n    /// returned. If parsing fails, `Error` is returned.\n    async fn from_data(req: &'r Request<'_>, data: Data<'r>) -> Outcome<'r, Self>;\n}\n\nuse crate::data::Capped;\n\n#[crate::async_trait]\nimpl<'r> FromData<'r> for Capped<String> {\n    type Error = std::io::Error;\n\n    async fn from_data(req: &'r Request<'_>, data: Data<'r>) -> Outcome<'r, Self> {\n        let limit = req.limits().get(\"string\").unwrap_or(Limits::STRING);\n        data.open(limit).into_string().await.or_error(Status::BadRequest)\n    }\n}\n\nimpl_strict_from_data_from_capped!(String);\n\n#[crate::async_trait]\nimpl<'r> FromData<'r> for Capped<&'r str> {\n    type Error = std::io::Error;\n\n    async fn from_data(req: &'r Request<'_>, data: Data<'r>) -> Outcome<'r, Self> {\n        let capped = try_outcome!(<Capped<String>>::from_data(req, data).await);\n        let string = capped.map(|s| local_cache!(req, s));\n        Success(string)\n    }\n}\n\nimpl_strict_from_data_from_capped!(&'r str);\n\n#[crate::async_trait]\nimpl<'r> FromData<'r> for Capped<&'r RawStr> {\n    type Error = std::io::Error;\n\n    async fn from_data(req: &'r Request<'_>, data: Data<'r>) -> Outcome<'r, Self> {\n        let capped = try_outcome!(<Capped<String>>::from_data(req, data).await);\n        let raw = capped.map(|s| RawStr::new(local_cache!(req, s)));\n        Success(raw)\n    }\n}\n\nimpl_strict_from_data_from_capped!(&'r RawStr);\n\n#[crate::async_trait]\nimpl<'r> FromData<'r> for Capped<std::borrow::Cow<'_, str>> {\n    type Error = std::io::Error;\n\n    async fn from_data(req: &'r Request<'_>, data: Data<'r>) -> Outcome<'r, Self> {\n        let capped = try_outcome!(<Capped<String>>::from_data(req, data).await);\n        Success(capped.map(|s| s.into()))\n    }\n}\n\nimpl_strict_from_data_from_capped!(std::borrow::Cow<'_, str>);\n\n#[crate::async_trait]\nimpl<'r> FromData<'r> for Capped<&'r [u8]> {\n    type Error = std::io::Error;\n\n    async fn from_data(req: &'r Request<'_>, data: Data<'r>) -> Outcome<'r, Self> {\n        let capped = try_outcome!(<Capped<Vec<u8>>>::from_data(req, data).await);\n        let raw = capped.map(|b| local_cache!(req, b));\n        Success(raw)\n    }\n}\n\nimpl_strict_from_data_from_capped!(&'r [u8]);\n\n#[crate::async_trait]\nimpl<'r> FromData<'r> for Capped<Vec<u8>> {\n    type Error = std::io::Error;\n\n    async fn from_data(req: &'r Request<'_>, data: Data<'r>) -> Outcome<'r, Self> {\n        let limit = req.limits().get(\"bytes\").unwrap_or(Limits::BYTES);\n        data.open(limit).into_bytes().await.or_error(Status::BadRequest)\n    }\n}\n\nimpl_strict_from_data_from_capped!(Vec<u8>);\n\n#[crate::async_trait]\nimpl<'r> FromData<'r> for Data<'r> {\n    type Error = std::convert::Infallible;\n\n    async fn from_data(_: &'r Request<'_>, data: Data<'r>) -> Outcome<'r, Self> {\n        Success(data)\n    }\n}\n\n#[crate::async_trait]\nimpl<'r, T: FromData<'r> + 'r> FromData<'r> for Result<T, T::Error> {\n    type Error = std::convert::Infallible;\n\n    async fn from_data(req: &'r Request<'_>, data: Data<'r>) -> Outcome<'r, Self> {\n        match T::from_data(req, data).await {\n            Success(v) => Success(Ok(v)),\n            Error((_, e)) => Success(Err(e)),\n            Forward(d) => Forward(d),\n        }\n    }\n}\n\n#[crate::async_trait]\nimpl<'r, T: FromData<'r>> FromData<'r> for Option<T> {\n    type Error = std::convert::Infallible;\n\n    async fn from_data(req: &'r Request<'_>, data: Data<'r>) -> Outcome<'r, Self> {\n        match T::from_data(req, data).await {\n            Success(v) => Success(Some(v)),\n            Error(..) | Forward(..) => Success(None),\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "39318afd0560cbd7ef00f36dfb5168d6a15b1e33",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/Rocket/core/lib/src/local/mod.rs",
    "func": "//! Structures for local dispatching of requests, primarily for testing.\n//!\n//! This module allows for simple request dispatching against a local,\n//! non-networked instance of Rocket. The primary use of this module is to unit\n//! and integration test Rocket applications by crafting requests, dispatching\n//! them, and verifying the response.\n//!\n//! # Async. vs. Blocking\n//!\n//! This module contains two variants, in its two submodules, of the same local\n//! API: [`asynchronous`], and [`blocking`]. As their names imply, the\n//! `asynchronous` API is `async`, returning a `Future` for operations that\n//! would otherwise block, while `blocking` blocks for the same operations.\n//!\n//! Unless your request handling requires concurrency to make progress, or\n//! you're making use of a `Client` in an environment that necessitates or would\n//! benefit from concurrency, you should use the `blocking` set of APIs due\n//! their ease-of-use. If your request handling _does_ require concurrency to\n//! make progress, for instance by having one handler `await` a response\n//! generated from a request to another handler, use the `asynchronous` set of\n//! APIs.\n//!\n//! Both APIs include a `Client` structure that is used to create `LocalRequest`\n//! structures that can be dispatched against a given [`Rocket`](crate::Rocket)\n//! instance to yield a `LocalResponse` structure. The APIs are identical except\n//! in that the `asynchronous` APIs return `Future`s for otherwise blocking\n//! operations.\n//!\n//! # Unit/Integration Testing\n//!\n//! This module is primarily intended to be used to test a Rocket application by\n//! constructing requests via `Client`, dispatching them, and validating the\n//! resulting response. As a complete example, consider the following \"Hello,\n//! world!\" application, with testing.\n//!\n//! ```rust\n//! #[macro_use] extern crate rocket;\n//!\n//! #[get(\"/\")]\n//! fn hello() -> &'static str {\n//!     \"Hello, world!\"\n//! }\n//!\n//! #[launch]\n//! fn rocket() -> _ {\n//!     rocket::build().mount(\"/\", routes![hello])\n//! }\n//!\n//! #[cfg(test)]\n//! mod test {\n//!     // Using the preferred `blocking` API.\n//!     #[test]\n//!     fn test_hello_world_blocking() {\n//!         use rocket::local::blocking::Client;\n//!\n//!         // Construct a client to use for dispatching requests.\n//!         let client = Client::tracked(super::rocket())\n//!             .expect(\"valid `Rocket`\");\n//!\n//!         // Dispatch a request to 'GET /' and validate the response.\n//!         let response = client.get(\"/\").dispatch();\n//!         assert_eq!(response.into_string().unwrap(), \"Hello, world!\");\n//!     }\n//!\n//!     // Using the `asynchronous` API.\n//!     #[rocket::async_test]\n//!     async fn test_hello_world_async() {\n//!         use rocket::local::asynchronous::Client;\n//!\n//!         // Construct a client to use for dispatching requests.\n//!         let client = Client::tracked(super::rocket()).await\n//!             .expect(\"valid `Rocket`\");\n//!\n//!         // Dispatch a request to 'GET /' and validate the response.\n//!         let response = client.get(\"/\").dispatch().await;\n//!         assert_eq!(response.into_string().await.unwrap(), \"Hello, world!\");\n//!     }\n//! }\n//! ```\n//!\n//! For more details on testing, see the [testing guide].\n//!\n//! [testing guide]: https://rocket.rs/master/guide/testing/\n//! [`Client`]: crate::local::asynchronous::Client\n//!\n//! # `Client`\n//!\n//! A `Client`, either [`blocking::Client`] or [`asynchronous::Client`],\n//! referred to as simply [`Client`] and [`async` `Client`], respectively,\n//! constructs requests for local dispatching.\n//!\n//! **Usage**\n//!\n//! A `Client` is constructed via the [`tracked()`] ([`async` `tracked()`]) or\n//! [`untracked()`] ([`async` `untracked()`]) methods from an already\n//! constructed `Rocket` instance. Once a value of `Client` has been\n//! constructed, [`get()`], [`put()`], [`post()`], and so on ([`async` `get()`],\n//! [`async` `put()`], [`async` `post()`]) can be called to create a\n//! [`LocalRequest`] ([`async` `LocalRequest`]) for dispatching.\n//!\n//! **Cookie Tracking**\n//!\n//! A `Client` constructed using `tracked()` propagates cookie changes made by\n//! responses to previously dispatched requests. In other words, if a previously\n//! dispatched request resulted in a response that adds a cookie, any future\n//! requests will contain that cookie. Similarly, cookies removed by a response\n//! won't be propagated further.\n//!\n//! This is typically the desired mode of operation for a `Client` as it removes\n//! the burden of manually tracking cookies. Under some circumstances, however,\n//! disabling this tracking may be desired. In these cases, use the\n//! `untracked()` constructor to create a `Client` that _will not_ track\n//! cookies.\n//!\n//! [`Client`]: blocking::Client\n//! [`async` `Client`]: asynchronous::Client\n//! [`LocalRequest`]: blocking::LocalRequest\n//! [`async` `LocalRequest`]: asynchronous::LocalRequest\n//!\n//! [`tracked()`]: blocking::Client::tracked()\n//! [`untracked()`]: blocking::Client::untracked()\n//! [`async` `tracked()`]: asynchronous::Client::tracked()\n//! [`async` `untracked()`]: asynchronous::Client::untracked()\n//!\n//! [`get()`]: blocking::Client::get()\n//! [`put()`]: blocking::Client::put()\n//! [`post()`]: blocking::Client::post()\n//! [`async` `get()`]: asynchronous::Client::get()\n//! [`async` `put()`]: asynchronous::Client::put()\n//! [`async` `post()`]: asynchronous::Client::post()\n//!\n//! **Example**\n//!\n//! For a usage example, see [`Client`] or [`async` `Client`].\n//!\n//! # `LocalRequest`\n//!\n//! A [`LocalRequest`] ([`async` `LocalRequest`]) is constructed via a `Client`.\n//! Once obtained, headers, cookies, including private cookies, the remote IP\n//! address, and the request body can all be set via methods on the\n//! `LocalRequest` structure.\n//!\n//! **Dispatching**\n//!\n//! A `LocalRequest` is dispatched by calling [`dispatch()`] ([`async`\n//! `dispatch()`]). The `LocalRequest` is consumed and a [`LocalResponse`]\n//! ([`async` `LocalResponse`]) is returned.\n//!\n//! Note that `LocalRequest` implements [`Clone`]. As such, if the same request\n//! needs to be dispatched multiple times, the request can first be cloned and\n//! then dispatched: `request.clone().dispatch()`.\n//!\n//! **Example**\n//!\n//! For a usage example, see [`LocalRequest`] or [`async` `LocalRequest`].\n//!\n//! [`LocalResponse`]: blocking::LocalResponse\n//! [`async` `LocalResponse`]: asynchronous::LocalResponse\n//! [`dispatch()`]: blocking::LocalRequest::dispatch()\n//! [`async` `dispatch()`]: asynchronous::LocalRequest::dispatch()\n//!\n//! # `LocalResponse`\n//!\n//! The result of `dispatch()`ing a `LocalRequest` is a [`LocalResponse`]\n//! ([`async` `LocalResponse`]). A `LocalResponse` can be queried for response\n//! metadata, including the HTTP status, headers, and cookies, via its getter\n//! methods. Additionally, the body of the response can be read into a string\n//! ([`into_string()`] or [`async` `into_string()`]) or a vector\n//! ([`into_bytes()`] or [`async` `into_bytes()`]).\n//!\n//! The response body must also be read directly using standard I/O mechanisms:\n//! the `blocking` `LocalResponse` implements `Read` while the `async`\n//! `LocalResponse` implements `AsyncRead`.\n//!\n//! For a usage example, see [`LocalResponse`] or [`async` `LocalResponse`].\n//!\n//! [`into_string()`]: blocking::LocalResponse::into_string()\n//! [`async` `into_string()`]: asynchronous::LocalResponse::into_string()\n//! [`into_bytes()`]: blocking::LocalResponse::into_bytes()\n//! [`async` `into_bytes()`]: asynchronous::LocalResponse::into_bytes()\n\n#[macro_use] mod client;\n#[macro_use] mod request;\n#[macro_use] mod response;\n\npub mod asynchronous;\npub mod blocking;\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "e83ff9e1b25e56df3f88b42716299e109f1efe31",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/Rocket/core/lib/src/form/name/buf.rs",
    "func": "use std::borrow::Cow;\n\nuse crate::form::name::*;\n\n/// A potentially owned [`Name`].\n///\n/// Constructible from a [`NameView`], [`Name`], `&str`, or `String`, a\n/// `NameBuf` acts much like a [`Name`] but can be converted into an owned\n/// version via [`IntoOwned`](crate::http::ext::IntoOwned).\n///\n/// ```rust\n/// use rocket::form::name::NameBuf;\n/// use rocket::http::ext::IntoOwned;\n///\n/// let alloc = String::from(\"a.b.c\");\n/// let name = NameBuf::from(alloc.as_str());\n/// let owned: NameBuf<'static> = name.into_owned();\n/// ```\n#[derive(Clone)]\npub struct NameBuf<'v> {\n    left: &'v Name,\n    right: Cow<'v, str>,\n}\n\nimpl<'v> NameBuf<'v> {\n    #[inline]\n    fn split(&self) -> (&Name, &Name) {\n        (self.left, Name::new(&self.right))\n    }\n\n    /// Returns an iterator over the keys of `self`, including empty keys.\n    ///\n    /// See [`Name`] for a description of \"keys\".\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// use rocket::form::name::NameBuf;\n    ///\n    /// let name = NameBuf::from(\"apple.b[foo:bar]zoo.[barb].bat\");\n    /// let keys: Vec<_> = name.keys().map(|k| k.as_str()).collect();\n    /// assert_eq!(keys, &[\"apple\", \"b\", \"foo:bar\", \"zoo\", \"\", \"barb\", \"bat\"]);\n    /// ```\n    #[inline]\n    pub fn keys(&self) -> impl Iterator<Item = &Key> {\n        let (left, right) = self.split();\n        left.keys().chain(right.keys())\n    }\n\n    /// Returns `true` if `self` is empty.\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// use rocket::form::name::NameBuf;\n    ///\n    /// let name = NameBuf::from(\"apple.b[foo:bar]zoo.[barb].bat\");\n    /// assert!(!name.is_empty());\n    ///\n    /// let name = NameBuf::from(\"\");\n    /// assert!(name.is_empty());\n    /// ```\n    #[inline]\n    pub fn is_empty(&self) -> bool {\n        let (left, right) = self.split();\n        left.is_empty() && right.is_empty()\n    }\n}\n\nimpl crate::http::ext::IntoOwned for NameBuf<'_> {\n    type Owned = NameBuf<'static>;\n\n    fn into_owned(self) -> Self::Owned {\n        let right = match (self.left, self.right) {\n            (l, Cow::Owned(r)) if l.is_empty() => Cow::Owned(r),\n            (l, r) if l.is_empty() => r.to_string().into(),\n            (l, r) if r.is_empty() => l.to_string().into(),\n            (l, r) => format!(\"{}.{}\", l, r).into(),\n        };\n\n        NameBuf { left: \"\".into(), right }\n    }\n}\n\nimpl serde::Serialize for NameBuf<'_> {\n    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>\n        where S: serde::Serializer\n    {\n        serializer.serialize_str(&self.to_string())\n    }\n}\n\nimpl<'v> From<NameView<'v>> for NameBuf<'v> {\n    fn from(nv: NameView<'v>) -> Self {\n        NameBuf { left: nv.as_name(), right: Cow::Borrowed(\"\") }\n    }\n}\n\nimpl<'v> From<&'v Name> for NameBuf<'v> {\n    fn from(name: &'v Name) -> Self {\n        NameBuf { left: name, right: Cow::Borrowed(\"\") }\n    }\n}\n\nimpl<'v> From<&'v str> for NameBuf<'v> {\n    fn from(name: &'v str) -> Self {\n        NameBuf::from((None, Cow::Borrowed(name)))\n    }\n}\n\nimpl<'v> From<String> for NameBuf<'v> {\n    fn from(name: String) -> Self {\n        NameBuf::from((None, Cow::Owned(name)))\n    }\n}\n\n#[doc(hidden)]\nimpl<'v> From<(Option<&'v Name>, Cow<'v, str>)> for NameBuf<'v> {\n    fn from((prefix, right): (Option<&'v Name>, Cow<'v, str>)) -> Self {\n        match prefix {\n            Some(left) => NameBuf { left, right },\n            None => NameBuf { left: \"\".into(), right }\n        }\n    }\n}\n\n#[doc(hidden)]\nimpl<'v> From<(Option<&'v Name>, String)> for NameBuf<'v> {\n    fn from((prefix, right): (Option<&'v Name>, String)) -> Self {\n        match prefix {\n            Some(left) => NameBuf { left, right: right.into() },\n            None => NameBuf { left: \"\".into(), right: right.into() }\n        }\n    }\n}\n\n#[doc(hidden)]\nimpl<'v> From<(Option<&'v Name>, &'v str)> for NameBuf<'v> {\n    fn from((prefix, suffix): (Option<&'v Name>, &'v str)) -> Self {\n        NameBuf::from((prefix, Cow::Borrowed(suffix)))\n    }\n}\n\n#[doc(hidden)]\nimpl<'v> From<(&'v Name, &'v str)> for NameBuf<'v> {\n    fn from((prefix, suffix): (&'v Name, &'v str)) -> Self {\n        NameBuf::from((Some(prefix), Cow::Borrowed(suffix)))\n    }\n}\n\nimpl std::fmt::Debug for NameBuf<'_> {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        write!(f, \"\\\"\")?;\n\n        let (left, right) = self.split();\n        if !left.is_empty() { write!(f, \"{}\", left.escape_debug())? }\n        if !right.is_empty() {\n            if !left.is_empty() { f.write_str(\".\")?; }\n            write!(f, \"{}\", right.escape_debug())?;\n        }\n\n        write!(f, \"\\\"\")\n    }\n}\n\nimpl std::fmt::Display for NameBuf<'_> {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        let (left, right) = self.split();\n        if !left.is_empty() { left.fmt(f)?; }\n        if !right.is_empty() {\n            if !left.is_empty() { f.write_str(\".\")?; }\n            right.fmt(f)?;\n        }\n\n        Ok(())\n    }\n}\n\nimpl PartialEq for NameBuf<'_> {\n    fn eq(&self, other: &Self) -> bool {\n        self.keys().eq(other.keys())\n    }\n}\n\nimpl<N: AsRef<Name> + ?Sized> PartialEq<N> for NameBuf<'_> {\n    fn eq(&self, other: &N) -> bool {\n        self.keys().eq(other.as_ref().keys())\n    }\n}\n\nimpl PartialEq<NameBuf<'_>> for Name {\n    fn eq(&self, other: &NameBuf<'_>) -> bool {\n        self.keys().eq(other.keys())\n    }\n}\n\nimpl PartialEq<NameBuf<'_>> for str {\n    fn eq(&self, other: &NameBuf<'_>) -> bool {\n        Name::new(self) == other\n    }\n}\n\nimpl PartialEq<NameBuf<'_>> for &str {\n    fn eq(&self, other: &NameBuf<'_>) -> bool {\n        Name::new(self) == other\n    }\n}\n\nimpl Eq for NameBuf<'_> { }\n\nimpl std::hash::Hash for NameBuf<'_> {\n    fn hash<H: std::hash::Hasher>(&self, state: &mut H) {\n        self.keys().for_each(|k| k.hash(state))\n    }\n}\n\nimpl indexmap::Equivalent<Name> for NameBuf<'_> {\n    fn equivalent(&self, key: &Name) -> bool {\n        self.keys().eq(key.keys())\n    }\n}\n\nimpl indexmap::Equivalent<NameBuf<'_>> for Name {\n    fn equivalent(&self, key: &NameBuf<'_>) -> bool {\n        self.keys().eq(key.keys())\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "9dc1b8b73cccbea7ab3f3e57c0cf86cad759c99e",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/Rocket/core/lib/src/util/unix.rs",
    "func": "use std::io;\nuse std::os::fd::AsRawFd;\n\npub fn lock_exclusive_nonblocking<T: AsRawFd>(file: &T) -> io::Result<()> {\n    let raw_fd = file.as_raw_fd();\n    let res = unsafe {\n        libc::flock(raw_fd, libc::LOCK_EX | libc::LOCK_NB)\n    };\n\n    match res {\n        0 => Ok(()),\n        _ => Err(io::Error::last_os_error()),\n    }\n}\n\npub fn unlock_nonblocking<T: AsRawFd>(file: &T) -> io::Result<()> {\n    let res = unsafe {\n        libc::flock(file.as_raw_fd(), libc::LOCK_UN | libc::LOCK_NB)\n    };\n\n    match res {\n        0 => Ok(()),\n        _ => Err(io::Error::last_os_error()),\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "6513c0fd18f7197cf04acb532f95960490707d52",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/Rocket/core/codegen/tests/ui-fail-stable/typed-uris-invalid-syntax.rs",
    "func": "#[macro_use] extern crate rocket;\n\n#[get(\"/\")]\nfn index() {  }\n\n#[post(\"/<_id>/<_name>\")]\nfn simple(_id: i32, _name: String) -> &'static str { \"\" }\n\nfn main() {\n    uri!(simple: id = 100, \"Hello\");\n    uri!(simple(id = 100, \"Hello\"));\n    uri!(simple(\"Hello\", id = 100));\n    uri!(simple,);\n    uri!(simple:);\n    uri!(\"/mount\",);\n    uri!(\"mount\", simple);\n    uri!(\"mount\", simple, \"http://\");\n    uri!(\"/mount\", simple, \"http://\");\n    uri!(\"/mount\", simple, \"#foo\", \"?foo\");\n    uri!(\"mount\", simple(10, \"hi\"), \"http://\");\n    uri!(\"/mount\", simple(10, \"hi\"), \"http://\");\n    uri!(\"/mount?foo\", simple(10, \"hi\"), \"foo/bar?foo#bar\");\n    uri!(\"/mount\", simple(10, \"hi\"), \"a/b\");\n    uri!(\"/mount\", simple(10, \"hi\"), \"#foo\", \"?foo\");\n    uri!(\"/mount/<id>\", simple);\n    uri!();\n    uri!(simple: id = );\n    uri!(simple(id = ));\n    uri!(\"*\", simple(10), \"hi\");\n    uri!(\"some.host:8088\", simple(10), \"hi\");\n    uri!(\"?foo\");\n    uri!(\"\");\n    uri!(\"/foo\", \"bar\");\n    uri!(\"/foo\" (\"bar\"));\n    uri!(\"ftp:?\", index);\n    uri!(\"ftp:\", index, \"foo#bar\");\n    uri!(\"ftp:\", index, \"foo?bar\");\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "7ebbc01cef36a0028939b3f321d8d862c094d0d9",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/Rocket/core/codegen/tests/ui-fail-stable/routes.rs",
    "func": "#[macro_use] extern crate rocket;\n\nfn main() {\n    let _ = routes![a b];\n    let _ = routes![];\n    let _ = routes![a::, ];\n    let _ = routes![a::];\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "3f55890e081589b74106acf4ca04eaa0004f13e2",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/Rocket/core/codegen/tests/ui-fail-stable/route-path-bad-syntax.rs",
    "func": "#[macro_use] extern crate rocket;\n\n// Check that route paths are absolute and normalized.\n\n#[get(\"a\")]\nfn f0() {}\n\n#[get(\"\")]\nfn f1() {}\n\n#[get(\"a/b/c\")]\nfn f2() {}\n\n#[get(\"/a///b\")]\nfn f3() {}\n\n#[get(\"/?bat&&\")]\nfn f4() {}\n\n#[get(\"/?bat&&\")]\nfn f5() {}\n\n#[get(\"/a/b//\")]\nfn f6() {}\n\n// Check that paths contain only valid URI characters\n\n#[get(\"/!@#$%^&*()\")]\nfn g1() {}\n\n#[get(\"/a%20b\")]\nfn g2() {}\n\n#[get(\"/a?a%20b\")]\nfn g3() {}\n\n#[get(\"/a?a+b\")]\nfn g4() {}\n\n// Check that all declared parameters are accounted for\n\n#[get(\"/<name>\")]\nfn h0(_name: usize) {}\n\n#[get(\"/a?<r>\")]\nfn h1() {}\n\n#[post(\"/a\", data = \"<test>\")]\nfn h2() {}\n\n#[get(\"/<_r>\")]\nfn h3() {}\n\n#[get(\"/<_r>/<b>\")]\nfn h4() {}\n\n//\n// Check dynamic parameters are valid idents\n\n#[get(\"/<foo_.>\")]\nfn i0() {}\n\n#[get(\"/<foo*>\")]\nfn i1() {}\n\n#[get(\"/<!>\")]\nfn i2() {}\n\n#[get(\"/<name>:<id>\")]\nfn i3() {}\n\n// Check that a data parameter is exactly `<param>`\n\n#[get(\"/\", data = \"foo\")]\nfn j0() {}\n\n#[get(\"/\", data = \"<foo..>\")]\nfn j1() {}\n\n#[get(\"/\", data = \"<foo\")]\nfn j2() {}\n\n#[get(\"/\", data = \"<test >\")]\nfn j3() {}\n\n// Check that all identifiers are named\n\n#[get(\"/<_>\")]\nfn k0(_: usize) {}\n\n// Check that strange dynamic syntax is caught.\n\n#[get(\"/<>\")]\nfn m0() {}\n\n#[get(\"/<id><\")]\nfn m1() {}\n\n#[get(\"/<<<<id><\")]\nfn m2() {}\n\n#[get(\"/<>name><\")]\nfn m3() {}\n\n// New additions for trailing paths, which we artificially disallow.\n\n#[get(\"/a/\")]\nfn n1() {}\n\n#[get(\"/a/b/\")]\nfn n2() {}\n\n#[get(\"/a/b/c/\")]\nfn n3() {}\n\nfn main() {  }\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "7ec529ed5b8b51b78937d56c17f82623357455f6",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/Rocket/core/codegen/tests/ui-fail-stable/typed-uri-bad-type.rs",
    "func": "#![allow(unused_variables)]\n\n#[macro_use] extern crate rocket;\n\nuse rocket::request::FromParam;\n\nstruct S;\n\nimpl<'a> FromParam<'a> for S {\n    type Error = ();\n    fn from_param(param: &'a str) -> Result<Self, Self::Error> { Ok(S) }\n}\n\n#[post(\"/<id>\")]\nfn simple(id: usize) {  }\n\n#[post(\"/<id>/<name>\")]\nfn not_uri_display(id: i32, name: S) {  }\n\n#[post(\"/<id>/<name>\")]\nfn not_uri_display_but_unused(id: i32, name: S) {  }\n\n#[post(\"/<id>/<name>\")]\nfn optionals(id: Option<i32>, name: Result<String, &str>) {  }\n\nuse rocket::form::{FromFormField, Errors, ValueField, DataField};\n\n#[rocket::async_trait]\nimpl<'v> FromFormField<'v> for S {\n    fn default() -> Option<Self> { None }\n\n    fn from_value(_: ValueField<'v>) -> Result<Self, Errors<'v>> { Ok(S) }\n\n    async fn from_data(_: DataField<'v, '_>) -> Result<Self, Errors<'v>> { Ok(S) }\n}\n\n#[post(\"/?<id>\")]\nfn simple_q(id: isize) {  }\n\n#[post(\"/?<id>&<rest..>\")]\nfn other_q(id: usize, rest: S) {  }\n\n#[post(\"/?<id>&<name>\")]\nfn optionals_q(id: Option<i32>, name: Result<String, Errors<'_>>) {  }\n\nfn main() {\n    uri!(simple(id = \"hi\"));\n\n    uri!(simple(\"hello\"));\n\n    uri!(simple(id = 239239i64));\n\n    uri!(not_uri_display(10, S));\n\n    // This one is okay. In paths, a value _must_ be supplied.\n    uri!(optionals(id = 10, name = \"bob\".to_string()));\n\n    uri!(optionals(id = Some(10), name = Ok(\"bob\".into())));\n\n    uri!(simple_q(\"hi\"));\n\n    uri!(simple_q(id = \"hi\"));\n\n    uri!(other_q(100, S));\n\n    uri!(other_q(rest = S, id = 100));\n\n    uri!(other_q(rest = _, id = 100));\n\n    uri!(other_q(rest = S, id = _));\n\n    // These are all okay.\n    uri!(optionals_q(_, _));\n    uri!(optionals_q(id = Some(10), name = Some(\"Bob\".to_string())));\n    uri!(optionals_q(_, Some(\"Bob\".into())));\n    uri!(optionals_q(id = _, name = _));\n\n    // Invalid prefixes.\n    uri!(uri!(\"?foo#bar\"), simple(id = \"hi\"));\n    uri!(uri!(\"*\"), simple(id = \"hi\"));\n\n    // Invalid suffix.\n    uri!(_, simple(id = \"hi\"), uri!(\"*\"));\n    uri!(_, simple(id = \"hi\"), uri!(\"/foo/bar\"));\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "54bc636b8b54ce036f9b3475b52b95d0d10d5c53",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/Rocket/core/codegen/tests/ui-fail-nightly/catch.rs",
    "func": "#[macro_use] extern crate rocket;\n\nuse rocket::Request;\n\n#[catch(404)]\nstruct Catcher(String);\n\n#[catch(404)]\nconst CATCH: &str = \"Catcher\";\n\n#[catch(\"404\")]\nfn e1(_request: &Request) { }\n\n#[catch(code = \"404\")]\nfn e2(_request: &Request) { }\n\n#[catch(code = 404)]\nfn e3(_request: &Request) { }\n\n#[catch(99)]\nfn e4(_request: &Request) { }\n\n#[catch(600)]\nfn e5(_request: &Request) { }\n\n#[catch(400, message = \"foo\")]\nfn e5(_request: &Request) { }\n\n#[catch(404)]\nfn f3(_request: &Request, _other: bool) { }\n\nfn main() { }\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "8183e619e46149c14a4a4c11a9d80a0e2c1590fb",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/Rocket/core/codegen/tests/ui-fail-nightly/catchers.rs",
    "func": "#[macro_use] extern crate rocket;\n\nfn main() {\n    let _ = catchers![a b];\n    let _ = catchers![];\n    let _ = catchers![a::, ];\n    let _ = catchers![a::];\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "fc5840f0208c700cfb379ea5fa5b2259205fb9c7",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/Rocket/core/codegen/tests/ui-fail-nightly/from_form.rs",
    "func": "use rocket::form::FromForm;\n\n#[derive(FromForm)]\nenum Thing { }\n\n#[derive(FromForm)]\nstruct Foo1;\n\n#[derive(FromForm)]\nstruct Foo2 {  }\n\n#[derive(FromForm)]\nstruct Foo3(usize);\n\n#[derive(FromForm)]\nstruct Foo4(usize, usize, usize);\n\n#[derive(FromForm)]\nstruct NextTodoTask<'f, 'a> {\n    description: String,\n    raw_description: &'f str,\n    other: &'a str,\n    completed: bool,\n}\n\n#[derive(FromForm)]\nstruct BadName1 {\n    #[field(name = \"isindex\")]\n    field: String,\n}\n\n#[derive(FromForm)]\nstruct Demo2 {\n    #[field(name = \"foo\")]\n    field: String,\n    foo: usize,\n}\n\n#[derive(FromForm)]\nstruct MyForm9 {\n    #[field(name = \"hello\")]\n    first: String,\n    #[field(name = \"hello\")]\n    other: String,\n}\n\n#[derive(FromForm)]\nstruct MyForm10 {\n    first: String,\n    #[field(name = \"first\")]\n    other: String,\n}\n\n#[derive(FromForm)]\nstruct MyForm {\n    #[field(name = \"blah\", field = \"bloo\")]\n    my_field: String,\n}\n\n#[derive(FromForm)]\nstruct MyForm1 {\n    #[field]\n    my_field: String,\n}\n\n#[derive(FromForm)]\nstruct MyForm2 {\n    #[field(\"blah\")]\n    my_field: String,\n}\n\n#[derive(FromForm)]\nstruct MyForm3 {\n    #[field(123)]\n    my_field: String,\n}\n\n#[derive(FromForm)]\nstruct MyForm4 {\n    #[field(beep = \"bop\")]\n    my_field: String,\n}\n\n#[derive(FromForm)]\nstruct MyForm5 {\n    #[field(name = \"blah\")]\n    #[field(name = \"blah\")]\n    my_field: String,\n}\n\n#[derive(FromForm)]\nstruct MyForm6 {\n    #[field(name = true)]\n    my_field: String,\n}\n\n#[derive(FromForm)]\nstruct MyForm7 {\n    #[field(name)]\n    my_field: String,\n}\n\n#[derive(FromForm)]\nstruct MyForm8 {\n    #[field(name = 123)]\n    my_field: String,\n}\n\n#[derive(FromForm)]\nstruct MyForm11 {\n    #[field(name = \"hello&world\")]\n    first: String,\n}\n\n#[derive(FromForm)]\nstruct MyForm12 {\n    #[field(name = \"!@#$%^&*()_\")]\n    first: String,\n}\n\n#[derive(FromForm)]\nstruct MyForm13 {\n    #[field(name = \"?\")]\n    first: String,\n}\n\n#[derive(FromForm)]\nstruct MyForm14 {\n    #[field(name = \"\")]\n    first: String,\n}\n\n#[derive(FromForm)]\nstruct BadName2 {\n    #[field(name = \"a&b\")]\n    field: String,\n}\n\n#[derive(FromForm)]\nstruct BadName3 {\n    #[field(name = \"a=\")]\n    field: String,\n}\n\n#[derive(FromForm)]\nstruct Validate0 {\n    #[field(validate = 123)]\n    first: String,\n}\n\n#[derive(FromForm)]\nstruct Validate1 {\n    #[field(validate = unknown())]\n    first: String,\n}\n\n#[derive(FromForm)]\nstruct Validate2 {\n    #[field(validate = ext(rocket::http::ContentType::HTML))]\n    first: String,\n}\n\n#[derive(FromForm)]\nstruct Validate3 {\n    #[field(validate = ext(\"hello\"))]\n    first: String,\n}\n\n#[derive(FromForm)]\nstruct Default0 {\n    #[field(default = 123)]\n    first: String,\n}\n\n#[derive(FromForm)]\nstruct Default1 {\n    #[field(default = 1, default = 2)]\n    double_default: usize,\n}\n\n#[derive(FromForm)]\nstruct Default2 {\n    #[field(default = 1)]\n    #[field(default = 2)]\n    double_default: usize,\n}\n\n#[derive(FromForm)]\nstruct Default3 {\n    #[field(default = 1, default_with = None)]\n    double_default: usize,\n}\n\n#[derive(FromForm)]\nstruct Default4 {\n    #[field(default_with = None)]\n    #[field(default = 1)]\n    double_default: usize,\n}\n\n#[derive(FromForm)]\nstruct Default5 {\n    #[field(default_with = Some(\"hi\"))]\n    no_conversion_from_with: String,\n}\n\n#[derive(FromForm)]\nstruct Default6 {\n    #[field(default = \"no conversion\")]\n    first: bool,\n}\n\n#[derive(FromForm)] // NO ERROR\nstruct Another<T> {\n    _foo: T,\n    _bar: T,\n}\n\n#[derive(FromForm)] // NO ERROR\nstruct AnotherOne<T> { // NO ERROR\n    _foo: T,\n    _bar: T,\n}\n\nfn main() { }\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "fb7096ac888786cd3b6ca552675da5dba31f4d94",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/Rocket/core/codegen/src/derive/responder.rs",
    "func": "use quote::ToTokens;\nuse devise::{*, ext::{TypeExt, SpanDiagnosticExt}};\nuse proc_macro2::TokenStream;\n\nuse crate::exports::*;\nuse crate::syn_ext::{TypeExt as _, GenericsExt as _};\nuse crate::http_codegen::{ContentType, Status};\n\n#[derive(Debug, Default, FromMeta)]\nstruct ItemAttr {\n    content_type: Option<SpanWrapped<ContentType>>,\n    status: Option<SpanWrapped<Status>>,\n}\n\n#[derive(Default, FromMeta)]\nstruct FieldAttr {\n    ignore: bool,\n}\n\npub fn derive_responder(input: proc_macro::TokenStream) -> TokenStream {\n    let impl_tokens = quote!(impl<'r, 'o: 'r> #_response::Responder<'r, 'o>);\n    DeriveGenerator::build_for(input, impl_tokens)\n        .support(Support::Struct | Support::Enum | Support::Lifetime | Support::Type)\n        .replace_generic(1, 0)\n        .type_bound_mapper(MapperBuild::new()\n            .try_enum_map(|m, e| mapper::enum_null(m, e))\n            .try_fields_map(|_, fields| {\n                let generic_idents = fields.parent.input().generics().type_idents();\n                let lifetime = |ty: &syn::Type| syn::Lifetime::new(\"'o\", ty.span());\n                let mut types = fields.iter()\n                    .map(|f| (f, &f.field.inner.ty))\n                    .map(|(f, ty)| (f, ty.with_replaced_lifetimes(lifetime(ty))));\n\n                let mut bounds = vec![];\n                if let Some((_, ty)) = types.next() {\n                    if !ty.is_concrete(&generic_idents) {\n                        let span = ty.span();\n                        bounds.push(quote_spanned!(span => #ty: #_response::Responder<'r, 'o>));\n                    }\n                }\n\n                for (f, ty) in types {\n                    let attr = FieldAttr::one_from_attrs(\"response\", &f.attrs)?.unwrap_or_default();\n                    if ty.is_concrete(&generic_idents) || attr.ignore {\n                        continue;\n                    }\n\n                    bounds.push(quote_spanned! { ty.span() =>\n                        #ty: ::std::convert::Into<#_http::Header<'o>>\n                    });\n                }\n\n                Ok(quote!(#(#bounds,)*))\n            })\n        )\n        .validator(ValidatorBuild::new()\n            .input_validate(|_, i| match i.generics().lifetimes().count() > 1 {\n                true => Err(i.generics().span().error(\"only one lifetime is supported\")),\n                false => Ok(())\n            })\n            .fields_validate(|_, fields| match fields.is_empty() {\n                true => Err(fields.span().error(\"need at least one field\")),\n                false => Ok(())\n            })\n        )\n        .inner_mapper(MapperBuild::new()\n            .with_output(|_, output| quote! {\n                fn respond_to(self, __req: &'r #Request<'_>) -> #_response::Result<'o> {\n                    #output\n                }\n            })\n            .try_fields_map(|_, fields| {\n                fn set_header_tokens<T: ToTokens + Spanned>(item: T) -> TokenStream {\n                    quote_spanned!(item.span() => __res.set_header(#item);)\n                }\n\n                let attr = ItemAttr::one_from_attrs(\"response\", fields.parent.attrs())?\n                    .unwrap_or_default();\n\n                let responder = fields.iter().next().map(|f| {\n                    let (accessor, ty) = (f.accessor(), f.ty.with_stripped_lifetimes());\n                    quote_spanned! { f.span() =>\n                        let mut __res = <#ty as #_response::Responder>::respond_to(\n                            #accessor, __req\n                        )?;\n                    }\n                }).expect(\"have at least one field\");\n\n                let mut headers = vec![];\n                for field in fields.iter().skip(1) {\n                    let attr = FieldAttr::one_from_attrs(\"response\", &field.attrs)?\n                        .unwrap_or_default();\n\n                    if !attr.ignore {\n                        headers.push(set_header_tokens(field.accessor()));\n                    }\n                }\n\n                let content_type = attr.content_type.map(set_header_tokens);\n                let status = attr.status.map(|status| {\n                    quote_spanned!(status.span() => __res.set_status(#status);)\n                });\n\n                Ok(quote! {\n                    #responder\n                    #(#headers)*\n                    #content_type\n                    #status\n                    #_Ok(__res)\n                })\n            })\n        )\n        .to_tokens()\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "20061785cef2443dbff8f21b2d70207564d57c51",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/Rocket/core/codegen/src/derive/from_param.rs",
    "func": "use devise::*;\nuse devise::ext::SpanDiagnosticExt;\n\nuse quote::quote;\nuse proc_macro2::TokenStream;\nuse syn::ext::IdentExt;\n\nuse crate::exports::*;\n\npub fn derive_from_param(input: proc_macro::TokenStream) -> TokenStream {\n    DeriveGenerator::build_for(input, quote!(impl<'a> #_request::FromParam<'a>))\n        .support(Support::Enum)\n        .validator(ValidatorBuild::new().fields_validate(|_, fields| {\n            if !fields.is_empty() {\n                return Err(fields.span().error(\"variants with data fields are not supported\"));\n            }\n\n            Ok(())\n        }))\n        .inner_mapper(MapperBuild::new().enum_map(|_, data| {\n            let matches = data.variants().map(|field| {\n                let field_name = field.ident.unraw();\n                quote!(stringify!(#field_name) => Ok(Self::#field))\n            });\n\n            let names = data.variants().map(|field| {\n                let field_name = field.ident.unraw();\n                quote!(stringify!(#field_name))\n            });\n\n            quote! {\n                type Error = #_error::InvalidOption<'a>;\n\n                fn from_param(param: &'a str) -> Result<Self, Self::Error> {\n                    match param {\n                        #(#matches,)*\n                        _ => Err(#_error::InvalidOption::new(param, &[#(#names),*])),\n                    }\n                }\n            }\n        }))\n        .to_tokens()\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "8b3fe406346886c76981d3cc374422c95f92cf69",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/Rocket/core/codegen/src/bang/mod.rs",
    "func": "mod uri;\nmod uri_parsing;\nmod test_guide;\nmod export;\n\npub mod typed_stream;\n\nuse devise::Result;\nuse syn::{Path, punctuated::Punctuated, parse::Parser, Token};\nuse syn::spanned::Spanned;\nuse proc_macro2::TokenStream;\n\nfn struct_maker_vec(\n    input: proc_macro::TokenStream,\n    ty: TokenStream,\n    map: impl Fn(TokenStream) -> TokenStream,\n) -> Result<TokenStream> {\n    use crate::exports::_Vec;\n\n    // Parse a comma-separated list of paths.\n    let paths = <Punctuated<Path, Token![,]>>::parse_terminated.parse(input)?;\n    let exprs = paths.iter().map(|path| {\n        let expr = map(quote_spanned!(path.span() => ___struct));\n        quote_spanned!(path.span() => {\n            let ___struct = #path {};\n            let ___item: #ty = #expr;\n            ___item\n        })\n    });\n\n    Ok(quote!({\n        let ___vec: #_Vec<#ty> = vec![#(#exprs),*];\n        ___vec\n    }))\n}\n\npub fn routes_macro(input: proc_macro::TokenStream) -> TokenStream {\n    struct_maker_vec(input, quote!(::rocket::Route), |e| quote!(#e.into_route()))\n        .unwrap_or_else(|diag| diag.emit_as_expr_tokens())\n}\n\npub fn catchers_macro(input: proc_macro::TokenStream) -> TokenStream {\n    struct_maker_vec(input, quote!(::rocket::Catcher), |e| quote!(#e.into_catcher()))\n        .unwrap_or_else(|diag| diag.emit_as_expr_tokens())\n}\n\npub fn uri_macro(input: proc_macro::TokenStream) -> TokenStream {\n    uri::_uri_macro(input.into())\n        .unwrap_or_else(|diag| diag.emit_as_expr_tokens_or(quote! {\n            rocket::http::uri::Origin::root()\n        }))\n}\n\npub fn uri_internal_macro(input: proc_macro::TokenStream) -> TokenStream {\n    // TODO: Ideally we would generate a perfect `Origin::root()` so that we don't\n    // assist in propagating further errors. Alas, we can't set the span to the\n    // invocation of `uri!` without access to `span.parent()`, and\n    // `Span::call_site()` here points to the `#[route]`, immediate caller,\n    // generating a rather confusing error message when there's a type-mismatch.\n    uri::_uri_internal_macro(input.into())\n        .unwrap_or_else(|diag| diag.emit_as_expr_tokens_or(quote! {\n            rocket::http::uri::Origin::root()\n        }))\n}\n\npub fn guide_tests_internal(input: proc_macro::TokenStream) -> TokenStream {\n    test_guide::_macro(input)\n        .unwrap_or_else(|diag| diag.emit_as_item_tokens())\n}\n\npub fn export_internal(input: proc_macro::TokenStream) -> TokenStream {\n    export::_macro(input)\n        .unwrap_or_else(|diag| diag.emit_as_item_tokens())\n}\n\npub fn typed_stream(input: proc_macro::TokenStream) -> TokenStream {\n    typed_stream::_macro(input)\n        .unwrap_or_else(|diag| diag.emit_as_item_tokens())\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "7d3753d4920a7dff12df5ef4ca8245987094163d",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/Rocket/core/http/src/uri/host.rs",
    "func": "use std::fmt::{self, Display};\n\nuse crate::uncased::UncasedStr;\nuse crate::uri::error::Error;\nuse crate::uri::{Absolute, Authority};\n\n/// A domain and port identified by a client as the server being messaged.\n///\n/// For requests made via HTTP/1.1, a host is identified via the `HOST` header.\n/// In HTTP/2 and HTTP/3, this information is instead communicated via the\n/// `:authority` and `:port` pseudo-header request fields. It is a\n/// client-controlled value via which the client communicates to the server the\n/// domain name and port it is attempting to communicate with. The following\n/// diagram illustrates the syntactic structure of a `Host`:\n///\n/// ```text\n/// some.domain.foo:8088\n/// |-------------| |--|\n///      domain     port\n/// ```\n///\n/// Only the domain part is required. Its value is case-insensitive.\n///\n/// # URI Construction\n///\n/// A `Host` is _not_ a [`Uri`](crate::uri::Uri), and none of Rocket's APIs will\n/// accept a `Host` value as such. This is because doing so would facilitate the\n/// construction of URIs to internal routes in a manner controllable by an\n/// attacker, inevitably leading to \"HTTP Host header attacks\".\n///\n/// Instead, a `Host` must be checked before being converted to a [`Uri`]\n/// value. The [`Host::to_authority`] and [`Host::to_absolute`] methods provide\n/// these mechanisms:\n///\n/// ```rust\n/// # #[macro_use] extern crate rocket;\n/// # type Token = String;\n/// use rocket::http::uri::Host;\n///\n/// // A sensitive URI we want to prefix with safe hosts.\n/// #[get(\"/token?<secret>\")]\n/// fn token(secret: Token) { /* .. */ }\n///\n/// // Whitelist of known hosts. In a real setting, you might retrieve this\n/// // list from config at ignite-time using tools like `AdHoc::config()`.\n/// const WHITELIST: [Host<'static>; 4] = [\n///     Host::new(uri!(\"rocket.rs\")),\n///     Host::new(uri!(\"rocket.rs:443\")),\n///     Host::new(uri!(\"guide.rocket.rs\")),\n///     Host::new(uri!(\"guide.rocket.rs:443\")),\n/// ];\n///\n/// // Use `Host::to_absolute()` to case-insensitively check a host against a\n/// // whitelist, returning an `Absolute` usable as a `uri!()` prefix.\n/// let host = Host::new(uri!(\"guide.ROCKET.rs\"));\n/// let prefix = host.to_absolute(\"https\", &WHITELIST);\n///\n/// // Since `guide.rocket.rs` is in the whitelist, `prefix` is `Some`.\n/// assert!(prefix.is_some());\n/// if let Some(prefix) = prefix {\n///     // We can use this prefix to safely construct URIs.\n///     let uri = uri!(prefix, token(\"some-secret-token\"));\n///     assert_eq!(uri, \"https://guide.ROCKET.rs/token?secret=some-secret-token\");\n/// }\n/// ```\n///\n/// # (De)serialization\n///\n/// `Host` is both `Serialize` and `Deserialize`:\n///\n/// ```rust\n/// # #[cfg(feature = \"serde\")] mod serde_impl {\n/// # use serde as serde;\n/// use serde::{Serialize, Deserialize};\n/// use rocket::http::uri::Host;\n///\n/// #[derive(Deserialize, Serialize)]\n/// # #[serde(crate = \"serde\")]\n/// struct UriOwned {\n///     uri: Host<'static>,\n/// }\n///\n/// #[derive(Deserialize, Serialize)]\n/// # #[serde(crate = \"serde\")]\n/// struct UriBorrowed<'a> {\n///     uri: Host<'a>,\n/// }\n/// # }\n/// ```\n#[derive(Debug, Clone)]\npub struct Host<'a>(Authority<'a>);\n\nimpl<'a> Host<'a> {\n    /// Create a new `Host` from an `Authority`. Only the `host` and `port`\n    /// parts are preserved.\n    ///\n    /// ```rust\n    /// # #[macro_use] extern crate rocket;\n    /// use rocket::http::uri::Host;\n    ///\n    /// let host = Host::new(uri!(\"developer.mozilla.org\"));\n    /// assert_eq!(host.to_string(), \"developer.mozilla.org\");\n    ///\n    /// let host = Host::new(uri!(\"foo:bar@developer.mozilla.org:1234\"));\n    /// assert_eq!(host.to_string(), \"developer.mozilla.org:1234\");\n    ///\n    /// let host = Host::new(uri!(\"rocket.rs:443\"));\n    /// assert_eq!(host.to_string(), \"rocket.rs:443\");\n    /// ```\n    pub const fn new(authority: Authority<'a>) -> Self {\n        Host(authority)\n    }\n\n    /// Parses the string `string` into a `Host`. Parsing will never allocate.\n    /// Returns an `Error` if `string` is not a valid authority URI, meaning\n    /// that this parser accepts a `user_info` part for compatibility but\n    /// discards it.\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// # #[macro_use] extern crate rocket;\n    /// use rocket::http::uri::Host;\n    ///\n    /// // Parse from a valid authority URI.\n    /// let host = Host::parse(\"user:pass@domain\").expect(\"valid host\");\n    /// assert_eq!(host.domain(), \"domain\");\n    /// assert_eq!(host.port(), None);\n    ///\n    /// // Parse from a valid host.\n    /// let host = Host::parse(\"domain:311\").expect(\"valid host\");\n    /// assert_eq!(host.domain(), \"doMaIN\");\n    /// assert_eq!(host.port(), Some(311));\n    ///\n    /// // Invalid hosts fail to parse.\n    /// Host::parse(\"https://rocket.rs\").expect_err(\"invalid host\");\n    ///\n    /// // Prefer to use `uri!()` when the input is statically known:\n    /// let host = Host::new(uri!(\"domain\"));\n    /// assert_eq!(host.domain(), \"domain\");\n    /// assert_eq!(host.port(), None);\n    /// ```\n    pub fn parse(string: &'a str) -> Result<Host<'a>, Error<'a>> {\n        Host::parse_bytes(string.as_bytes())\n    }\n\n    /// PRIVATE: Used by core.\n    #[doc(hidden)]\n    pub fn parse_bytes(bytes: &'a [u8]) -> Result<Host<'a>, Error<'a>> {\n        crate::parse::uri::authority_from_bytes(bytes).map(Host::new)\n    }\n\n    /// Parses the string `string` into an `Host`. Parsing never allocates\n    /// on success. May allocate on error.\n    ///\n    /// This method should be used instead of [`Host::parse()`] when the source\n    /// is already a `String`. Returns an `Error` if `string` is not a valid\n    /// authority URI, meaning that this parser accepts a `user_info` part for\n    /// compatibility but discards it.\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// # extern crate rocket;\n    /// use rocket::http::uri::Host;\n    ///\n    /// let source = format!(\"rocket.rs:8000\");\n    /// let host = Host::parse_owned(source).expect(\"valid host\");\n    /// assert_eq!(host.domain(), \"rocket.rs\");\n    /// assert_eq!(host.port(), Some(8000));\n    /// ```\n    pub fn parse_owned(string: String) -> Result<Host<'static>, Error<'static>> {\n        Authority::parse_owned(string).map(Host::new)\n    }\n\n    /// Returns the case-insensitive domain part of the host.\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// # #[macro_use] extern crate rocket;\n    /// use rocket::http::uri::Host;\n    ///\n    /// let host = Host::new(uri!(\"domain.com:123\"));\n    /// assert_eq!(host.domain(), \"domain.com\");\n    ///\n    /// let host = Host::new(uri!(\"username:password@domain:123\"));\n    /// assert_eq!(host.domain(), \"domain\");\n    ///\n    /// let host = Host::new(uri!(\"[1::2]:123\"));\n    /// assert_eq!(host.domain(), \"[1::2]\");\n    /// ```\n    #[inline]\n    pub fn domain(&self) -> &UncasedStr {\n        self.0.host().into()\n    }\n\n    /// Returns the port part of the host, if there is one.\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// # #[macro_use] extern crate rocket;\n    /// use rocket::http::uri::Host;\n    ///\n    /// // With a port.\n    /// let host = Host::new(uri!(\"domain:123\"));\n    /// assert_eq!(host.port(), Some(123));\n    ///\n    /// let host = Host::new(uri!(\"domain.com:8181\"));\n    /// assert_eq!(host.port(), Some(8181));\n    ///\n    /// // Without a port.\n    /// let host = Host::new(uri!(\"domain.foo.bar.tld\"));\n    /// assert_eq!(host.port(), None);\n    /// ```\n    #[inline(always)]\n    pub fn port(&self) -> Option<u16> {\n        self.0.port()\n    }\n\n    /// Checks `self` against `whitelist`. If `self` is in `whitelist`, returns\n    /// an [`Authority`] URI representing self. Otherwise, returns `None`.\n    /// Domain comparison is case-insensitive.\n    ///\n    /// See [URI construction](Self#uri-construction) for more.\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// # #[macro_use] extern crate rocket;\n    /// use rocket::http::uri::Host;\n    ///\n    /// let whitelist = &[Host::new(uri!(\"domain.tld\"))];\n    ///\n    /// // A host in the whitelist returns `Some`.\n    /// let host = Host::new(uri!(\"domain.tld\"));\n    /// let uri = host.to_authority(whitelist);\n    /// assert!(uri.is_some());\n    /// assert_eq!(uri.unwrap().to_string(), \"domain.tld\");\n    ///\n    /// let host = Host::new(uri!(\"foo:bar@doMaIN.tLd\"));\n    /// let uri = host.to_authority(whitelist);\n    /// assert!(uri.is_some());\n    /// assert_eq!(uri.unwrap().to_string(), \"doMaIN.tLd\");\n    ///\n    /// // A host _not_ in the whitelist returns `None`.\n    /// let host = Host::new(uri!(\"domain.tld:1234\"));\n    /// let uri = host.to_authority(whitelist);\n    /// assert!(uri.is_none());\n    /// ```\n    pub fn to_authority<'h, W>(&self, whitelist: W) -> Option<Authority<'a>>\n        where W: IntoIterator<Item = &'h Host<'h>>\n    {\n        let mut auth = whitelist.into_iter().any(|h| h == self).then(|| self.0.clone())?;\n        auth.user_info = None;\n        Some(auth)\n    }\n\n    /// Checks `self` against `whitelist`. If `self` is in `whitelist`, returns\n    /// an [`Absolute`] URI representing `self` with scheme `scheme`. Otherwise,\n    /// returns `None`. Domain comparison is case-insensitive.\n    ///\n    /// See [URI construction](Self#uri-construction) for more.\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// # #[macro_use] extern crate rocket;\n    /// use rocket::http::uri::Host;\n    ///\n    /// let whitelist = &[Host::new(uri!(\"domain.tld:443\"))];\n    ///\n    /// // A host in the whitelist returns `Some`.\n    /// let host = Host::new(uri!(\"user@domain.tld:443\"));\n    /// let uri = host.to_absolute(\"http\", whitelist);\n    /// assert!(uri.is_some());\n    /// assert_eq!(uri.unwrap().to_string(), \"http://domain.tld:443\");\n    ///\n    /// let host = Host::new(uri!(\"domain.TLD:443\"));\n    /// let uri = host.to_absolute(\"https\", whitelist);\n    /// assert!(uri.is_some());\n    /// assert_eq!(uri.unwrap().to_string(), \"https://domain.TLD:443\");\n    ///\n    /// // A host _not_ in the whitelist returns `None`.\n    /// let host = Host::new(uri!(\"domain.tld\"));\n    /// let uri = host.to_absolute(\"http\", whitelist);\n    /// assert!(uri.is_none());\n    /// ```\n    pub fn to_absolute<'h, W>(&self, scheme: &'a str, whitelist: W) -> Option<Absolute<'a>>\n        where W: IntoIterator<Item = &'h Host<'h>>\n    {\n        let scheme = crate::parse::uri::scheme_from_str(scheme).ok()?;\n        let authority = self.to_authority(whitelist)?;\n        Some(Absolute::const_new(scheme, Some(authority), \"\", None))\n    }\n}\n\nimpl_serde!(Host<'a>, \"an HTTP host\");\n\nimpl_base_traits!(Host, domain, port);\n\nimpl crate::ext::IntoOwned for Host<'_> {\n    type Owned = Host<'static>;\n\n    fn into_owned(self) -> Host<'static> {\n        Host(self.0.into_owned())\n    }\n}\n\nimpl<'a> From<Authority<'a>> for Host<'a> {\n    fn from(auth: Authority<'a>) -> Self {\n        Host::new(auth)\n    }\n}\n\nimpl Display for Host<'_> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        self.domain().fmt(f)?;\n        if let Some(port) = self.port() {\n            write!(f, \":{}\", port)?;\n        }\n\n        Ok(())\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "14d5d33f346c7619bc33de205e3eda178d77e630",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/Rocket/core/http/src/uri/uri.rs",
    "func": "use std::fmt::{self, Display};\nuse std::borrow::Cow;\n\nuse crate::ext::IntoOwned;\nuse crate::uri::{Origin, Authority, Absolute, Reference, Asterisk};\nuse crate::uri::error::{Error, TryFromUriError};\n\n/// An `enum` encapsulating any of the possible URI variants.\n///\n/// # Usage\n///\n/// In Rocket, this type will rarely be used directly. Instead, you will\n/// typically encounter URIs via the [`Origin`] type. This is because all\n/// incoming requests accepted by Rocket contain URIs in origin-form.\n///\n/// ## Parsing\n///\n/// The `Uri` type implements a full, zero-allocation, zero-copy [RFC 7230]\n/// compliant \"request target\" parser with limited liberties for real-world\n/// deviations. In particular, the parser deviates as follows:\n///\n///   * It accepts `%` characters without two trailing hex-digits.\n///\n///   * It accepts the following additional unencoded characters in query parts,\n///     to match real-world browser behavior:\n///\n///     `{`, `}`, `[`,  `]`, `\\`,  `^`,  <code>&#96;</code>, `|`\n///\n/// To parse an `&str` into a `Uri`, use [`Uri::parse()`]. Alternatively, you\n/// may also use the `TryFrom<&str>` and `TryFrom<String>` trait implementation.\n/// To inspect the parsed type, match on the resulting `enum` and use the\n/// methods of the internal structure.\n///\n/// [RFC 7230]: https://tools.ietf.org/html/rfc7230\n#[derive(Debug, PartialEq, Clone)]\npub enum Uri<'a> {\n    /// An asterisk: exactly `*`.\n    Asterisk(Asterisk),\n    /// An origin URI.\n    Origin(Origin<'a>),\n    /// An authority URI.\n    Authority(Authority<'a>),\n    /// An absolute URI.\n    Absolute(Absolute<'a>),\n    /// A URI reference.\n    Reference(Reference<'a>),\n}\n\nimpl<'a> Uri<'a> {\n    /// Parses the string `string` into a `Uri` of kind `T`.\n    ///\n    /// This is identical to `T::parse(string).map(Uri::from)`.\n    ///\n    /// `T` is typically one of [`Asterisk`], [`Origin`], [`Authority`],\n    /// [`Absolute`], or [`Reference`]. Parsing never allocates. Returns an\n    /// `Error` if `string` is not a valid URI of kind `T`.\n    ///\n    /// To perform an ambiguous parse into _any_ valid URI type, use\n    /// [`Uri::parse_any()`].\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// # #[macro_use] extern crate rocket;\n    /// use rocket::http::uri::{Uri, Origin};\n    ///\n    /// // Parse a valid origin URI (note: in practice, use `Origin::parse()`).\n    /// let uri = Uri::parse::<Origin>(\"/a/b/c?query\").expect(\"valid URI\");\n    /// let origin = uri.origin().expect(\"origin URI\");\n    /// assert_eq!(origin.path(), \"/a/b/c\");\n    /// assert_eq!(origin.query().unwrap(), \"query\");\n    ///\n    /// // Prefer to use the `uri!()` macro for static inputs. The return value\n    /// // is of the specific type, not `Uri`.\n    /// let origin = uri!(\"/a/b/c?query\");\n    /// assert_eq!(origin.path(), \"/a/b/c\");\n    /// assert_eq!(origin.query().unwrap(), \"query\");\n    ///\n    /// // Invalid URIs fail to parse.\n    /// Uri::parse::<Origin>(\"foo bar\").expect_err(\"invalid URI\");\n    /// ```\n    pub fn parse<T>(string: &'a str) -> Result<Uri<'a>, Error<'_>>\n        where T: Into<Uri<'a>> + TryFrom<&'a str, Error = Error<'a>>\n    {\n        T::try_from(string).map(|v| v.into())\n    }\n\n    /// Parse `string` into a the \"best fit\" URI type.\n    ///\n    /// Always prefer to use `uri!()` for statically known inputs.\n    ///\n    /// Because URI parsing is ambiguous (that is, there isn't a one-to-one\n    /// mapping between strings and a URI type), the internal type returned by\n    /// this method _may_ not be the desired type. This method chooses the \"best\n    /// fit\" type for a given string by preferring to parse in the following\n    /// order:\n    ///\n    ///   * `Asterisk`\n    ///   * `Origin`\n    ///   * `Authority`\n    ///   * `Absolute`\n    ///   * `Reference`\n    ///\n    /// Thus, even though `*` is a valid `Asterisk` _and_ `Reference` URI, it\n    /// will parse as an `Asterisk`.\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// # #[macro_use] extern crate rocket;\n    /// use rocket::http::uri::{Uri, Origin, Reference};\n    ///\n    /// // An absolute path is an origin _unless_ it contains a fragment.\n    /// let uri = Uri::parse_any(\"/a/b/c?query\").expect(\"valid URI\");\n    /// let origin = uri.origin().expect(\"origin URI\");\n    /// assert_eq!(origin.path(), \"/a/b/c\");\n    /// assert_eq!(origin.query().unwrap(), \"query\");\n    ///\n    /// let uri = Uri::parse_any(\"/a/b/c?query#fragment\").expect(\"valid URI\");\n    /// let reference = uri.reference().expect(\"reference URI\");\n    /// assert_eq!(reference.path(), \"/a/b/c\");\n    /// assert_eq!(reference.query().unwrap(), \"query\");\n    /// assert_eq!(reference.fragment().unwrap(), \"fragment\");\n    ///\n    /// // Prefer to use the `uri!()` macro for static inputs. The return type\n    /// // is the internal type, not `Uri`. The explicit type is not required.\n    /// let uri: Origin = uri!(\"/a/b/c?query\");\n    /// let uri: Reference = uri!(\"/a/b/c?query#fragment\");\n    /// ```\n    pub fn parse_any(string: &'a str) -> Result<Uri<'a>, Error<'_>> {\n        crate::parse::uri::from_str(string)\n    }\n\n    /// Returns the internal instance of `Origin` if `self` is a `Uri::Origin`.\n    /// Otherwise, returns `None`.\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// # #[macro_use] extern crate rocket;\n    /// use rocket::http::uri::{Uri, Absolute, Origin};\n    ///\n    /// let uri = Uri::parse::<Origin>(\"/a/b/c?query\").expect(\"valid URI\");\n    /// assert!(uri.origin().is_some());\n    ///\n    /// let uri = Uri::from(uri!(\"/a/b/c?query\"));\n    /// assert!(uri.origin().is_some());\n    ///\n    /// let uri = Uri::parse::<Absolute>(\"https://rocket.rs\").expect(\"valid URI\");\n    /// assert!(uri.origin().is_none());\n    ///\n    /// let uri = Uri::from(uri!(\"https://rocket.rs\"));\n    /// assert!(uri.origin().is_none());\n    /// ```\n    pub fn origin(&self) -> Option<&Origin<'a>> {\n        match self {\n            Uri::Origin(ref inner) => Some(inner),\n            _ => None\n        }\n    }\n\n    /// Returns the internal instance of `Authority` if `self` is a\n    /// `Uri::Authority`. Otherwise, returns `None`.\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// # #[macro_use] extern crate rocket;\n    /// use rocket::http::uri::{Uri, Absolute, Authority};\n    ///\n    /// let uri = Uri::parse::<Authority>(\"user:pass@domain.com\").expect(\"valid URI\");\n    /// assert!(uri.authority().is_some());\n    ///\n    /// let uri = Uri::from(uri!(\"user:pass@domain.com\"));\n    /// assert!(uri.authority().is_some());\n    ///\n    /// let uri = Uri::parse::<Absolute>(\"https://rocket.rs\").expect(\"valid URI\");\n    /// assert!(uri.authority().is_none());\n    ///\n    /// let uri = Uri::from(uri!(\"https://rocket.rs\"));\n    /// assert!(uri.authority().is_none());\n    /// ```\n    pub fn authority(&self) -> Option<&Authority<'a>> {\n        match self {\n            Uri::Authority(ref inner) => Some(inner),\n            _ => None\n        }\n    }\n\n    /// Returns the internal instance of `Absolute` if `self` is a\n    /// `Uri::Absolute`. Otherwise, returns `None`.\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// # #[macro_use] extern crate rocket;\n    /// use rocket::http::uri::{Uri, Absolute, Origin};\n    ///\n    /// let uri = Uri::parse::<Absolute>(\"http://rocket.rs\").expect(\"valid URI\");\n    /// assert!(uri.absolute().is_some());\n    ///\n    /// let uri = Uri::from(uri!(\"http://rocket.rs\"));\n    /// assert!(uri.absolute().is_some());\n    ///\n    /// let uri = Uri::parse::<Origin>(\"/path\").expect(\"valid URI\");\n    /// assert!(uri.absolute().is_none());\n    ///\n    /// let uri = Uri::from(uri!(\"/path\"));\n    /// assert!(uri.absolute().is_none());\n    /// ```\n    pub fn absolute(&self) -> Option<&Absolute<'a>> {\n        match self {\n            Uri::Absolute(ref inner) => Some(inner),\n            _ => None\n        }\n    }\n\n    /// Returns the internal instance of `Reference` if `self` is a\n    /// `Uri::Reference`. Otherwise, returns `None`.\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// # #[macro_use] extern crate rocket;\n    /// use rocket::http::uri::{Uri, Absolute, Reference};\n    ///\n    /// let uri = Uri::parse::<Reference>(\"foo/bar\").expect(\"valid URI\");\n    /// assert!(uri.reference().is_some());\n    ///\n    /// let uri = Uri::from(uri!(\"foo/bar\"));\n    /// assert!(uri.reference().is_some());\n    ///\n    /// let uri = Uri::parse::<Absolute>(\"https://rocket.rs\").expect(\"valid URI\");\n    /// assert!(uri.reference().is_none());\n    ///\n    /// let uri = Uri::from(uri!(\"https://rocket.rs\"));\n    /// assert!(uri.reference().is_none());\n    /// ```\n    pub fn reference(&self) -> Option<&Reference<'a>> {\n        match self {\n            Uri::Reference(ref inner) => Some(inner),\n            _ => None\n        }\n    }\n}\n\npub(crate) unsafe fn as_utf8_unchecked(input: Cow<'_, [u8]>) -> Cow<'_, str> {\n    match input {\n        Cow::Borrowed(bytes) => Cow::Borrowed(std::str::from_utf8_unchecked(bytes)),\n        Cow::Owned(bytes) => Cow::Owned(String::from_utf8_unchecked(bytes))\n    }\n}\n\n// impl<'a> TryFrom<&'a str> for Uri<'a> {\n//     type Error = Error<'a>;\n//\n//     #[inline]\n//     fn try_from(string: &'a str) -> Result<Uri<'a>, Self::Error> {\n//         Uri::parse(string)\n//     }\n// }\n//\n// impl TryFrom<String> for Uri<'static> {\n//     type Error = Error<'static>;\n//\n//     #[inline]\n//     fn try_from(string: String) -> Result<Uri<'static>, Self::Error> {\n//         // TODO: Potentially optimize this like `Origin::parse_owned`.\n//         Uri::parse(&string)\n//             .map(|u| u.into_owned())\n//             .map_err(|e| e.into_owned())\n//     }\n// }\n\nimpl IntoOwned for Uri<'_> {\n    type Owned = Uri<'static>;\n\n    fn into_owned(self) -> Uri<'static> {\n        match self {\n            Uri::Origin(origin) => Uri::Origin(origin.into_owned()),\n            Uri::Authority(authority) => Uri::Authority(authority.into_owned()),\n            Uri::Absolute(absolute) => Uri::Absolute(absolute.into_owned()),\n            Uri::Reference(reference) => Uri::Reference(reference.into_owned()),\n            Uri::Asterisk(asterisk) => Uri::Asterisk(asterisk)\n        }\n    }\n}\n\nimpl Display for Uri<'_> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match *self {\n            Uri::Origin(ref origin) => write!(f, \"{}\", origin),\n            Uri::Authority(ref authority) => write!(f, \"{}\", authority),\n            Uri::Absolute(ref absolute) => write!(f, \"{}\", absolute),\n            Uri::Reference(ref reference) => write!(f, \"{}\", reference),\n            Uri::Asterisk(ref asterisk) => write!(f, \"{}\", asterisk)\n        }\n    }\n}\n\nmacro_rules! impl_uri_from {\n    ($T:ident $(<$lt:lifetime>)?) => (\n        impl<'a> From<$T $(<$lt>)?> for Uri<'a> {\n            fn from(other: $T $(<$lt>)?) -> Uri<'a> {\n                Uri::$T(other)\n            }\n        }\n\n        impl<'a> TryFrom<Uri<'a>> for $T $(<$lt>)? {\n            type Error = TryFromUriError;\n\n            fn try_from(uri: Uri<'a>) -> Result<Self, Self::Error> {\n                match uri {\n                    Uri::$T(inner) => Ok(inner),\n                    _ => Err(TryFromUriError(()))\n                }\n            }\n        }\n\n        impl<'b, $($lt)?> PartialEq<$T $(<$lt>)?> for Uri<'b> {\n            fn eq(&self, other: &$T $(<$lt>)?) -> bool {\n                match self {\n                    Uri::$T(inner) => inner == other,\n                    _ => false\n                }\n            }\n        }\n\n        impl<'b, $($lt)?> PartialEq<Uri<'b>> for $T $(<$lt>)? {\n            fn eq(&self, other: &Uri<'b>) -> bool {\n                match other {\n                    Uri::$T(inner) => inner == self,\n                    _ => false\n                }\n            }\n        }\n\n        impl<'b, $($lt)?> PartialEq<&$T $(<$lt>)?> for Uri<'b> {\n            fn eq(&self, other: &&$T $(<$lt>)?) -> bool {\n                match self {\n                    Uri::$T(inner) => inner == *other,\n                    _ => false\n                }\n            }\n        }\n\n        impl<'b, $($lt)?> PartialEq<Uri<'b>> for &$T $(<$lt>)? {\n            fn eq(&self, other: &Uri<'b>) -> bool {\n                match other {\n                    Uri::$T(inner) => inner == *self,\n                    _ => false\n                }\n            }\n        }\n    )\n}\n\nimpl_uri_from!(Origin<'a>);\nimpl_uri_from!(Authority<'a>);\nimpl_uri_from!(Absolute<'a>);\nimpl_uri_from!(Reference<'a>);\nimpl_uri_from!(Asterisk);\n\n/// Implements Serialize and Deserialize for any 'URI' looking type.\nmacro_rules! impl_serde {\n    ($T:ty, $expected:literal) => {\n        #[cfg(feature = \"serde\")]\n        mod serde_impl {\n            use std::fmt;\n            use std::marker::PhantomData;\n            use super::*;\n\n            use serde::ser::{Serialize, Serializer};\n            use serde::de::{Deserialize, Deserializer, Error, Visitor};\n\n            impl<'a> Serialize for $T {\n                fn serialize<S: Serializer>(&self, serializer: S) -> Result<S::Ok, S::Error> {\n                    serializer.serialize_str(&self.to_string())\n                }\n            }\n\n            struct DeVisitor<'a>(PhantomData<&'a $T>);\n\n            impl<'de, 'a> Visitor<'de> for DeVisitor<'a> {\n                type Value = $T;\n\n                fn expecting(&self, formatter: &mut fmt::Formatter<'_>) -> fmt::Result {\n                    write!(formatter, $expected)\n                }\n\n                fn visit_str<E: Error>(self, v: &str) -> Result<Self::Value, E> {\n                    <$T>::parse_owned(v.to_string()).map_err(Error::custom)\n                }\n\n                fn visit_string<E: Error>(self, v: String) -> Result<Self::Value, E> {\n                    <$T>::parse_owned(v).map_err(Error::custom)\n                }\n            }\n\n            impl<'a, 'de> Deserialize<'de> for $T {\n                fn deserialize<D: Deserializer<'de>>(deserializer: D) -> Result<Self, D::Error> {\n                    deserializer.deserialize_str(DeVisitor(PhantomData))\n                }\n            }\n        }\n    };\n}\n\n/// Implements traits from `impl_base_traits` and IntoOwned for a URI.\nmacro_rules! impl_traits {\n    ($T:ident, $($field:ident),* $(,)?) => {\n        impl_traits!($T [parse], $($field),*);\n    };\n    ($T:ident [$partial_eq_parse:ident], $($field:ident),* $(,)?) => {\n        impl_base_traits!($T [$partial_eq_parse], $($field),*);\n\n        impl crate::ext::IntoOwned for $T<'_> {\n            type Owned = $T<'static>;\n\n            fn into_owned(self) -> $T<'static> {\n                $T {\n                    source: self.source.into_owned(),\n                    $($field: self.$field.into_owned()),*\n                }\n            }\n        }\n    }\n}\n\n/// Implements PartialEq, Eq, Hash, and TryFrom.\nmacro_rules! impl_base_traits {\n    ($T:ident, $($field:ident),* $(,)?) => {\n        impl_base_traits!($T [parse], $($field),*);\n    };\n    ($T:ident [$partial_eq_parse:ident], $($field:ident),* $(,)?) => {\n        impl std::convert::TryFrom<String> for $T<'static> {\n            type Error = Error<'static>;\n\n            fn try_from(value: String) -> Result<Self, Self::Error> {\n                $T::parse_owned(value)\n            }\n        }\n\n        // Because inference doesn't take `&String` to `&str`.\n        impl<'a> std::convert::TryFrom<&'a String> for $T<'a> {\n            type Error = Error<'a>;\n\n            fn try_from(value: &'a String) -> Result<Self, Self::Error> {\n                $T::parse(value.as_str())\n            }\n        }\n\n        impl<'a> std::convert::TryFrom<&'a str> for $T<'a> {\n            type Error = Error<'a>;\n\n            fn try_from(value: &'a str) -> Result<Self, Self::Error> {\n                $T::parse(value)\n            }\n        }\n\n        impl<'a, 'b> PartialEq<$T<'b>> for $T<'a> {\n            fn eq(&self, other: &$T<'b>) -> bool {\n                true $(&& self.$field() == other.$field())*\n            }\n        }\n\n        impl PartialEq<str> for $T<'_> {\n            fn eq(&self, string: &str) -> bool {\n                $T::$partial_eq_parse(string).map_or(false, |v| &v == self)\n            }\n        }\n\n        impl PartialEq<&str> for $T<'_> {\n            fn eq(&self, other: &&str) -> bool {\n                self.eq(*other)\n            }\n        }\n\n        impl PartialEq<$T<'_>> for str {\n            fn eq(&self, other: &$T<'_>) -> bool {\n                other.eq(self)\n            }\n        }\n\n        impl Eq for $T<'_> { }\n\n        impl std::hash::Hash for $T<'_> {\n            fn hash<H: std::hash::Hasher>(&self, state: &mut H) {\n                $(self.$field().hash(state);)*\n            }\n        }\n    }\n}\n\nmod tests {\n    #[test]\n    fn normalization() {\n        fn normalize(uri: &str) -> String {\n            use crate::uri::Uri;\n\n            match Uri::parse_any(uri).unwrap() {\n                Uri::Origin(uri) => uri.into_normalized().to_string(),\n                Uri::Absolute(uri) => uri.into_normalized().to_string(),\n                Uri::Reference(uri) => uri.into_normalized().to_string(),\n                uri => uri.to_string(),\n            }\n        }\n\n        assert_eq!(normalize(\"/#\"), \"/#\");\n\n        assert_eq!(normalize(\"/\"), \"/\");\n        assert_eq!(normalize(\"//\"), \"/\");\n        assert_eq!(normalize(\"//////a/\"), \"/a/\");\n        assert_eq!(normalize(\"//ab\"), \"/ab\");\n        assert_eq!(normalize(\"//a\"), \"/a\");\n        assert_eq!(normalize(\"/a/b///c\"), \"/a/b/c\");\n        assert_eq!(normalize(\"/a/b///c/\"), \"/a/b/c/\");\n        assert_eq!(normalize(\"/a///b/c/d///\"), \"/a/b/c/d/\");\n\n        assert_eq!(normalize(\"/?\"), \"/?\");\n        assert_eq!(normalize(\"/?foo\"), \"/?foo\");\n        assert_eq!(normalize(\"/a/?\"), \"/a/?\");\n        assert_eq!(normalize(\"/a/?foo\"), \"/a/?foo\");\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "503f9483ad681fb44dd70c77574bdee468162d68",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/Rocket/core/http/src/uri/fmt/from_uri_param.rs",
    "func": "use std::path::{Path, PathBuf};\nuse std::collections::{BTreeMap, HashMap};\n\nuse either::Either;\n\nuse crate::uri::fmt::UriDisplay;\nuse crate::uri::fmt::{self, Part};\n\n/// Conversion trait for parameters used in [`uri!`] invocations.\n///\n/// # Overview\n///\n/// In addition to implementing [`UriDisplay`], to use a custom type in a `uri!`\n/// expression, the `FromUriParam` trait must be implemented. The `UriDisplay`\n/// derive automatically generates _identity_ implementations of `FromUriParam`,\n/// so in the majority of cases, as with `UriDisplay`, this trait is never\n/// implemented manually.\n///\n/// In the rare case that `UriDisplay` is implemented manually, this trait, too,\n/// must be implemented explicitly. In the majority of cases, implementation can\n/// be automated. Rocket provides [`impl_from_uri_param_identity!`] to generate\n/// the _identity_ implementations automatically. For a type `T`, these are:\n///\n///   * `impl<P: Part> FromUriParam<P, T> for T`\n///   * `impl<'x, P: Part> FromUriParam<P, &'x T> for T`\n///   * `impl<'x, P: Part> FromUriParam<P, &'x mut T> for T`\n///\n/// See [`impl_from_uri_param_identity!`] for usage details.\n///\n/// [`impl_from_uri_param_identity!`]: crate::impl_from_uri_param_identity!\n///\n/// # Code Generation\n///\n/// This trait is invoked once per expression passed into a [`uri!`] invocation.\n/// In particular, for a route URI parameter of type `T` and a user-supplied\n/// expression `e` of type `S`, `<T as FromUriParam<S>>::from_uri_param(e)` is\n/// invoked. The returned value of type `T::Target` is used in place of the\n/// user's value and rendered using its [`UriDisplay`] implementation.\n///\n/// This trait allows types that differ from the route URI parameter's types to\n/// be used in their place at no cost. For instance, the following\n/// implementation, provided by Rocket, allows an `&str` to be used in a `uri!`\n/// invocation for route URI parameters declared as `String`:\n///\n/// ```rust\n/// # extern crate rocket;\n/// # use rocket::http::uri::fmt::{FromUriParam, Part};\n/// # struct S;\n/// # type String = S;\n/// impl<'a, P: Part> FromUriParam<P, &'a str> for String {\n///     type Target = &'a str;\n/// #   fn from_uri_param(s: &'a str) -> Self::Target { \"hi\" }\n/// }\n/// ```\n///\n/// Because the [`FromUriParam::Target`] type is the same as the input type, the\n/// conversion is a no-op and free of cost, allowing an `&str` to be used in\n/// place of a `String` without penalty.\n///\n/// # Provided Implementations\n///\n/// The following types have _identity_ implementations:\n///\n///    * `String`, `i8`, `i16`, `i32`, `i64`, `i128`, `isize`, `u8`, `u16`,\n///      `u32`, `u64`, `u128`, `usize`, `f32`, `f64`, `bool`, `IpAddr`,\n///      `Ipv4Addr`, `Ipv6Addr`, `&str`, `Cow<str>`, `Either<A, B>`\n///\n/// The following types have _identity_ implementations _only in [`Path`]_:\n///\n///   * `&Path`, `PathBuf`\n///\n/// The following types have _identity_ implementations _only in [`Query`]_:\n///\n///   * `Option<T>`, `Result<T, E>`\n///\n/// The following conversions are implemented for both paths and queries,\n/// allowing a value of the type on the left to be used when a type on the right\n/// is expected by a route:\n///\n///   * `&str` to `String`\n///   * `String` to `&str`\n///   * `T` to `Form<T>`\n///\n/// The following conversions are implemented _only in [`Path`]_:\n///\n///   * `&str` to `&Path`\n///   * `&str` to `PathBuf`\n///   * `PathBuf` to `&Path`\n///   * `T` to `Option<T>`\n///   * `T` to `Result<T, E>`\n///\n/// The following conversions are implemented _only in [`Query`]_:\n///\n///   * `Option<T>` to `Result<T, E>` (for any `E`)\n///   * `Result<T, E>` to `Option<T>` (for any `E`)\n///\n/// See [Foreign Impls](#foreign-impls) for all provided implementations.\n///\n/// # Implementing\n///\n/// This trait should only be implemented when you'd like to allow a type\n/// different from the route's declared type to be used in its place in a `uri!`\n/// invocation. For instance, if the route has a type of `T` and you'd like to\n/// use a type of `S` in a `uri!` invocation, you'd implement `FromUriParam<P,\n/// T> for S` where `P` is `Path` for conversions valid in the path part of a\n/// URI, `Uri` for conversions valid in the query part of a URI, or `P: Part`\n/// when a conversion is valid in either case.\n///\n/// This is typically only warranted for owned-value types with corresponding\n/// reference types: `String` and `&str`, for instance. In this case, it's\n/// desirable to allow an `&str` to be used in place of a `String`.\n///\n/// When implementing `FromUriParam`, be aware that Rocket will use the\n/// [`UriDisplay`] implementation of [`FromUriParam::Target`], _not_ of the\n/// source type. Incorrect implementations can result in creating unsafe URIs.\n///\n/// # Example\n///\n/// The following example implements `FromUriParam<Query, (&str, &str)>` for a\n/// `User` type. The implementation allows an `(&str, &str)` type to be used in\n/// a `uri!` invocation where a `User` type is expected in the query part of the\n/// URI.\n///\n/// ```rust\n/// # #[macro_use] extern crate rocket;\n/// use std::fmt;\n///\n/// use rocket::http::uri::fmt::{Formatter, UriDisplay, FromUriParam, Query};\n///\n/// #[derive(FromForm)]\n/// struct User<'a> {\n///     name: &'a str,\n///     nickname: String,\n/// }\n///\n/// impl UriDisplay<Query> for User<'_> {\n///     fn fmt(&self, f: &mut Formatter<Query>) -> fmt::Result {\n///         f.write_named_value(\"name\", &self.name)?;\n///         f.write_named_value(\"nickname\", &self.nickname)\n///     }\n/// }\n///\n/// impl<'a, 'b> FromUriParam<Query, (&'a str, &'b str)> for User<'a> {\n///     type Target = User<'a>;\n///\n///     fn from_uri_param((name, nickname): (&'a str, &'b str)) -> User<'a> {\n///         User { name: name.into(), nickname: nickname.to_string() }\n///     }\n/// }\n/// ```\n///\n/// With these implementations, the following typechecks:\n///\n/// ```rust\n/// # #[macro_use] extern crate rocket;\n/// # use std::fmt;\n/// # use rocket::http::uri::fmt::{Formatter, UriDisplay, FromUriParam, Query};\n/// #\n/// # #[derive(FromForm)]\n/// # struct User<'a> { name: &'a str, nickname: String, }\n/// #\n/// # impl UriDisplay<Query> for User<'_> {\n/// #     fn fmt(&self, f: &mut Formatter<Query>) -> fmt::Result {\n/// #         f.write_named_value(\"name\", &self.name)?;\n/// #         f.write_named_value(\"nickname\", &self.nickname)\n/// #     }\n/// # }\n/// #\n/// # impl<'a, 'b> FromUriParam<Query, (&'a str, &'b str)> for User<'a> {\n/// #     type Target = User<'a>;\n/// #     fn from_uri_param((name, nickname): (&'a str, &'b str)) -> User<'a> {\n/// #         User { name: name.into(), nickname: nickname.to_string() }\n/// #     }\n/// # }\n/// #\n/// #[post(\"/<name>?<user..>\")]\n/// fn some_route(name: &str, user: User<'_>)  { /* .. */ }\n///\n/// let uri = uri!(some_route(name = \"hey\", user = (\"Robert Mike\", \"Bob\")));\n/// assert_eq!(uri.path(), \"/hey\");\n/// assert_eq!(uri.query().unwrap(), \"name=Robert%20Mike&nickname=Bob\");\n/// ```\n///\n/// [`uri!`]: ../../../../rocket/macro.uri.html\n/// [`FromUriParam::Target`]: crate::uri::fmt::FromUriParam::Target\n/// [`Path`]: crate::uri::fmt::Path\n/// [`Query`]: crate::uri::fmt::Query\npub trait FromUriParam<P: Part, T> {\n    /// The resulting type of this conversion.\n    type Target: UriDisplay<P>;\n\n    /// Converts a value of type `T` into a value of type `Self::Target`. The\n    /// resulting value of type `Self::Target` will be rendered into a URI using\n    /// its [`UriDisplay`] implementation.\n    fn from_uri_param(param: T) -> Self::Target;\n}\n\n#[doc(hidden)]\n#[macro_export(local_inner_macros)]\nmacro_rules! impl_conversion_ref {\n    ($(($($l:tt)+) $A:ty => $B:ty),* $(,)?) => (\n        impl_conversion_ref!(@_ $(($($l)+,) $A => $B),*);\n    );\n\n    ($($A:ty => $B:ty),* $(,)?) => (\n        impl_conversion_ref!(@_ $(() $A => $B),*);\n    );\n\n    (@_ $(($($l:tt)*) $A:ty => $B:ty),* $(,)?) => ($(\n        impl_conversion_ref!([P] ($($l)* P: $crate::uri::fmt::Part) $A => $B);\n    )*);\n\n    ($([$P:ty] ($($l:tt)*) $A:ty => $B:ty),* $(,)?) => ($(\n        impl_conversion_ref!(@_ [$P] ($($l)*) $A => $B);\n        impl_conversion_ref!(@_ [$P] ('x, $($l)*) &'x $A => $B);\n        impl_conversion_ref!(@_ [$P] ('x, $($l)*) &'x mut $A => $B);\n    )*);\n\n    ($([$P:ty] $A:ty => $B:ty),* $(,)?) => ( impl_conversion_ref!($([$P] () $A => $B),*););\n\n    (@_ [$P:ty] ($($l:tt)*) $A:ty => $B:ty) => (\n        impl<$($l)*> $crate::uri::fmt::FromUriParam<$P, $A> for $B {\n            type Target = $A;\n            #[inline(always)] fn from_uri_param(param: $A) -> $A { param }\n        }\n    );\n}\n\n/// Macro to automatically generate _identity_ [`FromUriParam`] trait\n/// implementations.\n///\n/// For a type `T`, the _identity_ implementations of `FromUriParam` are:\n///\n///   * `impl<P: Part> FromUriParam<P, T> for T`\n///   * `impl<'x> FromUriParam<P, &'x T> for T`\n///   * `impl<'x> FromUriParam<P, &'x mut T> for T`\n///\n/// where `P` is one of:\n///\n///   * `P: Part` (the generic `P`)\n///   * [`Path`]\n///   * [`Query`]\n///\n/// This macro can be invoked in four ways:\n///\n///   1. `impl_from_uri_param_identity!(Type);`\n///\n///      Generates the three _identity_ implementations for the generic `P`.\n///\n///      * Example: `impl_from_uri_param_identity!(MyType);`\n///      * Generates: `impl<P: Part> FromUriParam<P, _> for MyType { ... }`\n///\n///   2. `impl_from_uri_param_identity!((generics*) Type);`\n///\n///      Generates the three _identity_ implementations for the generic `P`,\n///      adding the tokens `generics` to the `impl` generics of the generated\n///      implementation.\n///\n///      * Example: `impl_from_uri_param_identity!(('a) MyType<'a>);`\n///      * Generates: `impl<'a, P: Part> FromUriParam<P, _> for MyType<'a> { ... }`\n///\n///   3. `impl_from_uri_param_identity!([Part] Type);`\n///\n///      Generates the three _identity_ implementations for the `Part`\n///      `Part`, where `Part` is a path to [`Path`] or [`Query`].\n///\n///      * Example: `impl_from_uri_param_identity!([Path] MyType);`\n///      * Generates: `impl FromUriParam<Path, _> for MyType { ... }`\n///\n///   4. `impl_from_uri_param_identity!([Part] (generics*) Type);`\n///\n///      See 2 and 3.\n///\n///      * Example: `impl_from_uri_param_identity!([Path] ('a) MyType<'a>);`\n///      * Generates: `impl<'a> FromUriParam<Path, _> for MyType<'a> { ... }`\n///\n/// [`FromUriParam`]: crate::uri::fmt::FromUriParam\n/// [`Path`]: crate::uri::fmt::Path\n/// [`Query`]: crate::uri::fmt::Query\n#[macro_export(local_inner_macros)]\nmacro_rules! impl_from_uri_param_identity {\n    ($(($($l:tt)*) $T:ty),* $(,)?) => ($( impl_conversion_ref!(($($l)*) $T => $T); )*);\n    ($([$P:ty] ($($l:tt)*) $T:ty),* $(,)?) => ($( impl_conversion_ref!([$P] ($($l)*) $T => $T); )*);\n    ($([$P:ty] $T:ty),* $(,)?) => ($( impl_conversion_ref!([$P] $T => $T); )*);\n    ($($T:ty),* $(,)?) => ($( impl_conversion_ref!($T => $T); )*);\n}\n\nuse std::borrow::Cow;\nuse std::net::{IpAddr, Ipv4Addr, Ipv6Addr, SocketAddr, SocketAddrV4, SocketAddrV6};\nuse std::num::{\n    NonZeroIsize, NonZeroI8, NonZeroI16, NonZeroI32, NonZeroI64, NonZeroI128,\n    NonZeroUsize, NonZeroU8, NonZeroU16, NonZeroU32, NonZeroU64, NonZeroU128,\n};\n\nimpl_from_uri_param_identity! {\n    String,\n    i8, i16, i32, i64, i128, isize,\n    u8, u16, u32, u64, u128, usize,\n    f32, f64, bool,\n    IpAddr, Ipv4Addr, Ipv6Addr, SocketAddr, SocketAddrV4, SocketAddrV6,\n    NonZeroIsize, NonZeroI8, NonZeroI16, NonZeroI32, NonZeroI64, NonZeroI128,\n    NonZeroUsize, NonZeroU8, NonZeroU16, NonZeroU32, NonZeroU64, NonZeroU128,\n    time::Date, time::Time, time::PrimitiveDateTime,\n}\n\nimpl_from_uri_param_identity! {\n    ('a) &'a str,\n    ('a) Cow<'a, str>\n}\n\nimpl_conversion_ref! {\n    ('a) &'a str => String,\n\n    ('a) String => &'a str\n}\n\nimpl_from_uri_param_identity!([fmt::Path] ('a) &'a Path);\nimpl_from_uri_param_identity!([fmt::Path] PathBuf);\n\nimpl_conversion_ref! {\n    [fmt::Path] ('a) &'a Path => PathBuf,\n    [fmt::Path] ('a) PathBuf => &'a Path,\n}\n\n// TODO: A specialized `RawBytes` instead of `&[u8]`. Then impl [T] => Vec<T>.\nimpl_from_uri_param_identity!([fmt::Query] ('a) &'a [u8]);\n\nimpl_conversion_ref! {\n    [fmt::Query] (T, A: FromUriParam<fmt::Query, T> + UriDisplay<fmt::Query>) Vec<A> => Vec<T>,\n    [fmt::Query] (\n            T,\n            A: FromUriParam<fmt::Query, T> + UriDisplay<fmt::Query>,\n            const N: usize\n        ) Vec<A> => [T; N],\n\n    [fmt::Query] (\n            T,\n            A: FromUriParam<fmt::Query, T> + UriDisplay<fmt::Query>,\n            const N: usize\n        ) [A; N] => Vec<T>,\n\n    [fmt::Query] (\n            T,\n            A: FromUriParam<fmt::Query, T> + UriDisplay<fmt::Query>,\n            const N: usize\n        ) [A; N] => [T; N],\n}\n\n/// A no cost conversion allowing an `&str` to be used in place of a `PathBuf`.\nimpl<'a> FromUriParam<fmt::Path, &'a str> for PathBuf {\n    type Target = &'a Path;\n\n    #[inline(always)]\n    fn from_uri_param(param: &'a str) -> &'a Path {\n        Path::new(param)\n    }\n}\n\n/// A no cost conversion allowing an `&&str` to be used in place of a `PathBuf`.\nimpl<'a, 'b> FromUriParam<fmt::Path, &'a &'b str> for PathBuf {\n    type Target = &'b Path;\n\n    #[inline(always)]\n    fn from_uri_param(param: &'a &'b str) -> &'b Path {\n        Path::new(*param)\n    }\n}\n\n/// A no cost conversion allowing any `T` to be used in place of an `Option<T>`.\nimpl<A, T: FromUriParam<fmt::Path, A>> FromUriParam<fmt::Path, A> for Option<T> {\n    type Target = T::Target;\n\n    #[inline(always)]\n    fn from_uri_param(param: A) -> Self::Target {\n        T::from_uri_param(param)\n    }\n}\n\n/// A no cost conversion allowing `T` to be used in place of an `Result<T, E>`.\nimpl<A, E, T> FromUriParam<fmt::Path, A> for Result<T, E>\n    where T: FromUriParam<fmt::Path, A>\n{\n    type Target = T::Target;\n\n    #[inline(always)]\n    fn from_uri_param(param: A) -> Self::Target {\n        T::from_uri_param(param)\n    }\n}\n\nimpl<P: Part, A, B, T, U> FromUriParam<P, Either<A, B>> for Either<T, U>\n    where T: FromUriParam<P, A>, U: FromUriParam<P, B>\n{\n    type Target = Either<T::Target, U::Target>;\n\n    fn from_uri_param(param: Either<A, B>) -> Self::Target {\n        match param {\n            Either::Left(a) => Either::Left(T::from_uri_param(a)),\n            Either::Right(b) => Either::Right(U::from_uri_param(b)),\n        }\n    }\n}\n\nimpl<A, T: FromUriParam<fmt::Query, A>> FromUriParam<fmt::Query, Option<A>> for Option<T> {\n    type Target = Option<T::Target>;\n\n    #[inline(always)]\n    fn from_uri_param(param: Option<A>) -> Self::Target {\n        param.map(T::from_uri_param)\n    }\n}\n\nimpl<A, E, T: FromUriParam<fmt::Query, A>> FromUriParam<fmt::Query, Option<A>> for Result<T, E> {\n    type Target = Option<T::Target>;\n\n    #[inline(always)]\n    fn from_uri_param(param: Option<A>) -> Self::Target {\n        param.map(T::from_uri_param)\n    }\n}\n\nimpl<A, E, T: FromUriParam<fmt::Query, A>> FromUriParam<fmt::Query, Result<A, E>> for Result<T, E> {\n    type Target = Result<T::Target, E>;\n\n    #[inline(always)]\n    fn from_uri_param(param: Result<A, E>) -> Self::Target {\n        param.map(T::from_uri_param)\n    }\n}\n\nimpl<A, E, T: FromUriParam<fmt::Query, A>> FromUriParam<fmt::Query, Result<A, E>> for Option<T> {\n    type Target = Result<T::Target, E>;\n\n    #[inline(always)]\n    fn from_uri_param(param: Result<A, E>) -> Self::Target {\n        param.map(T::from_uri_param)\n    }\n}\n\nmacro_rules! impl_map_conversion {\n    ($From:ident => $To:ident) => (\n        impl<K, V, A, B> FromUriParam<fmt::Query, $From<A, B>> for $To<K, V>\n            where A: UriDisplay<fmt::Query>, K: FromUriParam<fmt::Query, A>,\n                  B: UriDisplay<fmt::Query>, V: FromUriParam<fmt::Query, B>\n        {\n            type Target = $From<A, B>;\n\n            #[inline(always)]\n            fn from_uri_param(param: $From<A, B>) -> Self::Target {\n                param\n            }\n        }\n    );\n\n    (& $([$mut:tt])? $From:ident => $To:ident) => (\n        impl<'a, K, V, A, B> FromUriParam<fmt::Query, &'a $($mut)? $From<A, B>> for $To<K, V>\n            where A: UriDisplay<fmt::Query>, K: FromUriParam<fmt::Query, A>,\n                  B: UriDisplay<fmt::Query>, V: FromUriParam<fmt::Query, B>\n        {\n            type Target = &'a $From<A, B>;\n\n            #[inline(always)]\n            fn from_uri_param(param: &'a $($mut)? $From<A, B>) -> Self::Target {\n                param\n            }\n        }\n    );\n}\n\nimpl_map_conversion!(HashMap => HashMap);\nimpl_map_conversion!(HashMap => BTreeMap);\nimpl_map_conversion!(BTreeMap => BTreeMap);\nimpl_map_conversion!(BTreeMap => HashMap);\n\nimpl_map_conversion!(&HashMap => HashMap);\nimpl_map_conversion!(&HashMap => BTreeMap);\nimpl_map_conversion!(&BTreeMap => BTreeMap);\nimpl_map_conversion!(&BTreeMap => HashMap);\n\nimpl_map_conversion!(&[mut] HashMap => HashMap);\nimpl_map_conversion!(&[mut] HashMap => BTreeMap);\nimpl_map_conversion!(&[mut] BTreeMap => BTreeMap);\nimpl_map_conversion!(&[mut] BTreeMap => HashMap);\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "49574939bf0ae705f45ddc8701639b117032ac1c",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/actix-web/actix-router/benches/router.rs",
    "func": "//! Based on https://github.com/ibraheemdev/matchit/blob/master/benches/bench.rs\n\nuse criterion::{black_box, criterion_group, criterion_main, Criterion};\n\nmacro_rules! register {\n    (colon) => {{\n        register!(finish => \":p1\", \":p2\", \":p3\", \":p4\")\n    }};\n    (brackets) => {{\n        register!(finish => \"{p1}\", \"{p2}\", \"{p3}\", \"{p4}\")\n    }};\n    (regex) => {{\n        register!(finish => \"(.*)\", \"(.*)\", \"(.*)\", \"(.*)\")\n    }};\n    (finish => $p1:literal, $p2:literal, $p3:literal, $p4:literal) => {{\n        let arr = [\n            concat!(\"/authorizations\"),\n            concat!(\"/authorizations/\", $p1),\n            concat!(\"/applications/\", $p1, \"/tokens/\", $p2),\n            concat!(\"/events\"),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/events\"),\n            concat!(\"/networks/\", $p1, \"/\", $p2, \"/events\"),\n            concat!(\"/orgs/\", $p1, \"/events\"),\n            concat!(\"/users/\", $p1, \"/received_events\"),\n            concat!(\"/users/\", $p1, \"/received_events/public\"),\n            concat!(\"/users/\", $p1, \"/events\"),\n            concat!(\"/users/\", $p1, \"/events/public\"),\n            concat!(\"/users/\", $p1, \"/events/orgs/\", $p2),\n            concat!(\"/feeds\"),\n            concat!(\"/notifications\"),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/notifications\"),\n            concat!(\"/notifications/threads/\", $p1),\n            concat!(\"/notifications/threads/\", $p1, \"/subscription\"),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/stargazers\"),\n            concat!(\"/users/\", $p1, \"/starred\"),\n            concat!(\"/user/starred\"),\n            concat!(\"/user/starred/\", $p1, \"/\", $p2),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/subscribers\"),\n            concat!(\"/users/\", $p1, \"/subscriptions\"),\n            concat!(\"/user/subscriptions\"),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/subscription\"),\n            concat!(\"/user/subscriptions/\", $p1, \"/\", $p2),\n            concat!(\"/users/\", $p1, \"/gists\"),\n            concat!(\"/gists\"),\n            concat!(\"/gists/\", $p1),\n            concat!(\"/gists/\", $p1, \"/star\"),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/git/blobs/\", $p3),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/git/commits/\", $p3),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/git/refs\"),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/git/tags/\", $p3),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/git/trees/\", $p3),\n            concat!(\"/issues\"),\n            concat!(\"/user/issues\"),\n            concat!(\"/orgs/\", $p1, \"/issues\"),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/issues\"),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/issues/\", $p3),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/assignees\"),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/assignees/\", $p3),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/issues/\", $p3, \"/comments\"),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/issues/\", $p3, \"/events\"),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/labels\"),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/labels/\", $p3),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/issues/\", $p3, \"/labels\"),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/milestones/\", $p3, \"/labels\"),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/milestones/\"),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/milestones/\", $p3),\n            concat!(\"/emojis\"),\n            concat!(\"/gitignore/templates\"),\n            concat!(\"/gitignore/templates/\", $p1),\n            concat!(\"/meta\"),\n            concat!(\"/rate_limit\"),\n            concat!(\"/users/\", $p1, \"/orgs\"),\n            concat!(\"/user/orgs\"),\n            concat!(\"/orgs/\", $p1),\n            concat!(\"/orgs/\", $p1, \"/members\"),\n            concat!(\"/orgs/\", $p1, \"/members\", $p2),\n            concat!(\"/orgs/\", $p1, \"/public_members\"),\n            concat!(\"/orgs/\", $p1, \"/public_members/\", $p2),\n            concat!(\"/orgs/\", $p1, \"/teams\"),\n            concat!(\"/teams/\", $p1),\n            concat!(\"/teams/\", $p1, \"/members\"),\n            concat!(\"/teams/\", $p1, \"/members\", $p2),\n            concat!(\"/teams/\", $p1, \"/repos\"),\n            concat!(\"/teams/\", $p1, \"/repos/\", $p2, \"/\", $p3),\n            concat!(\"/user/teams\"),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/pulls\"),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/pulls/\", $p3),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/pulls/\", $p3, \"/commits\"),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/pulls/\", $p3, \"/files\"),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/pulls/\", $p3, \"/merge\"),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/pulls/\", $p3, \"/comments\"),\n            concat!(\"/user/repos\"),\n            concat!(\"/users/\", $p1, \"/repos\"),\n            concat!(\"/orgs/\", $p1, \"/repos\"),\n            concat!(\"/repositories\"),\n            concat!(\"/repos/\", $p1, \"/\", $p2),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/contributors\"),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/languages\"),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/teams\"),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/tags\"),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/branches\"),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/branches/\", $p3),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/collaborators\"),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/collaborators/\", $p3),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/comments\"),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/commits/\", $p3, \"/comments\"),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/commits\"),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/commits/\", $p3),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/readme\"),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/keys\"),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/keys\", $p3),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/downloads\"),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/downloads\", $p3),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/forks\"),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/hooks\"),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/hooks\", $p3),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/releases\"),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/releases/\", $p3),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/releases/\", $p3, \"/assets\"),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/stats/contributors\"),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/stats/commit_activity\"),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/stats/code_frequency\"),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/stats/participation\"),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/stats/punch_card\"),\n            concat!(\"/repos/\", $p1, \"/\", $p2, \"/statuses/\", $p3),\n            concat!(\"/search/repositories\"),\n            concat!(\"/search/code\"),\n            concat!(\"/search/issues\"),\n            concat!(\"/search/users\"),\n            concat!(\"/legacy/issues/search/\", $p1, \"/\", $p2, \"/\", $p3, \"/\", $p4),\n            concat!(\"/legacy/repos/search/\", $p1),\n            concat!(\"/legacy/user/search/\", $p1),\n            concat!(\"/legacy/user/email/\", $p1),\n            concat!(\"/users/\", $p1),\n            concat!(\"/user\"),\n            concat!(\"/users\"),\n            concat!(\"/user/emails\"),\n            concat!(\"/users/\", $p1, \"/followers\"),\n            concat!(\"/user/followers\"),\n            concat!(\"/users/\", $p1, \"/following\"),\n            concat!(\"/user/following\"),\n            concat!(\"/user/following/\", $p1),\n            concat!(\"/users/\", $p1, \"/following\", $p2),\n            concat!(\"/users/\", $p1, \"/keys\"),\n            concat!(\"/user/keys\"),\n            concat!(\"/user/keys/\", $p1),\n        ];\n\n        IntoIterator::into_iter(arr)\n    }};\n}\n\nfn call() -> impl Iterator<Item = &'static str> {\n    let arr = [\n        \"/authorizations\",\n        \"/user/repos\",\n        \"/repos/rust-lang/rust/stargazers\",\n        \"/orgs/rust-lang/public_members/nikomatsakis\",\n        \"/repos/rust-lang/rust/releases/1.51.0\",\n    ];\n\n    IntoIterator::into_iter(arr)\n}\n\nfn compare_routers(c: &mut Criterion) {\n    let mut group = c.benchmark_group(\"Compare Routers\");\n\n    let mut actix = actix_router::Router::<bool>::build();\n    for route in register!(brackets) {\n        actix.path(route, true);\n    }\n    let actix = actix.finish();\n    group.bench_function(\"actix\", |b| {\n        b.iter(|| {\n            for route in call() {\n                let mut path = actix_router::Path::new(route);\n                black_box(actix.recognize(&mut path).unwrap());\n            }\n        });\n    });\n\n    let regex_set = regex::RegexSet::new(register!(regex)).unwrap();\n    group.bench_function(\"regex\", |b| {\n        b.iter(|| {\n            for route in call() {\n                black_box(regex_set.matches(route));\n            }\n        });\n    });\n\n    group.finish();\n}\n\ncriterion_group!(benches, compare_routers);\ncriterion_main!(benches);\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "46b39de61fc6ce4435cc59aef0260b186abc17b7",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/actix-web/actix-files/src/error.rs",
    "func": "use actix_web::{http::StatusCode, ResponseError};\nuse derive_more::derive::Display;\n\n/// Errors which can occur when serving static files.\n#[derive(Debug, PartialEq, Eq, Display)]\npub enum FilesError {\n    /// Path is not a directory.\n    #[allow(dead_code)]\n    #[display(\"path is not a directory. Unable to serve static files\")]\n    IsNotDirectory,\n\n    /// Cannot render directory.\n    #[display(\"unable to render directory without index file\")]\n    IsDirectory,\n}\n\nimpl ResponseError for FilesError {\n    /// Returns `404 Not Found`.\n    fn status_code(&self) -> StatusCode {\n        StatusCode::NOT_FOUND\n    }\n}\n\n#[derive(Debug, PartialEq, Eq, Display)]\n#[non_exhaustive]\npub enum UriSegmentError {\n    /// Segment started with the wrapped invalid character.\n    #[display(\"segment started with invalid character: ('{_0}')\")]\n    BadStart(char),\n\n    /// Segment contained the wrapped invalid character.\n    #[display(\"segment contained invalid character ('{_0}')\")]\n    BadChar(char),\n\n    /// Segment ended with the wrapped invalid character.\n    #[display(\"segment ended with invalid character: ('{_0}')\")]\n    BadEnd(char),\n\n    /// Path is not a valid UTF-8 string after percent-decoding.\n    #[display(\"path is not a valid UTF-8 string after percent-decoding\")]\n    NotValidUtf8,\n}\n\nimpl ResponseError for UriSegmentError {\n    /// Returns `400 Bad Request`.\n    fn status_code(&self) -> StatusCode {\n        StatusCode::BAD_REQUEST\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "67bfa17cd33155b8d660d3c193aedfb8635a2e6e",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/actix-web/actix-files/src/files.rs",
    "func": "use std::{\n    cell::RefCell,\n    fmt, io,\n    path::{Path, PathBuf},\n    rc::Rc,\n};\n\nuse actix_service::{boxed, IntoServiceFactory, ServiceFactory, ServiceFactoryExt};\nuse actix_web::{\n    dev::{\n        AppService, HttpServiceFactory, RequestHead, ResourceDef, ServiceRequest, ServiceResponse,\n    },\n    error::Error,\n    guard::Guard,\n    http::header::DispositionType,\n    HttpRequest,\n};\nuse futures_core::future::LocalBoxFuture;\n\nuse crate::{\n    directory_listing, named,\n    service::{FilesService, FilesServiceInner},\n    Directory, DirectoryRenderer, HttpNewService, MimeOverride, PathFilter,\n};\n\n/// Static files handling service.\n///\n/// `Files` service must be registered with `App::service()` method.\n///\n/// # Examples\n/// ```\n/// use actix_web::App;\n/// use actix_files::Files;\n///\n/// let app = App::new()\n///     .service(Files::new(\"/static\", \".\"));\n/// ```\npub struct Files {\n    mount_path: String,\n    directory: PathBuf,\n    index: Option<String>,\n    show_index: bool,\n    redirect_to_slash: bool,\n    default: Rc<RefCell<Option<Rc<HttpNewService>>>>,\n    renderer: Rc<DirectoryRenderer>,\n    mime_override: Option<Rc<MimeOverride>>,\n    path_filter: Option<Rc<PathFilter>>,\n    file_flags: named::Flags,\n    use_guards: Option<Rc<dyn Guard>>,\n    guards: Vec<Rc<dyn Guard>>,\n    hidden_files: bool,\n}\n\nimpl fmt::Debug for Files {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.write_str(\"Files\")\n    }\n}\n\nimpl Clone for Files {\n    fn clone(&self) -> Self {\n        Self {\n            directory: self.directory.clone(),\n            index: self.index.clone(),\n            show_index: self.show_index,\n            redirect_to_slash: self.redirect_to_slash,\n            default: self.default.clone(),\n            renderer: self.renderer.clone(),\n            file_flags: self.file_flags,\n            mount_path: self.mount_path.clone(),\n            mime_override: self.mime_override.clone(),\n            path_filter: self.path_filter.clone(),\n            use_guards: self.use_guards.clone(),\n            guards: self.guards.clone(),\n            hidden_files: self.hidden_files,\n        }\n    }\n}\n\nimpl Files {\n    /// Create new `Files` instance for a specified base directory.\n    ///\n    /// # Argument Order\n    /// The first argument (`mount_path`) is the root URL at which the static files are served.\n    /// For example, `/assets` will serve files at `example.com/assets/...`.\n    ///\n    /// The second argument (`serve_from`) is the location on disk at which files are loaded.\n    /// This can be a relative path. For example, `./` would serve files from the current\n    /// working directory.\n    ///\n    /// # Implementation Notes\n    /// If the mount path is set as the root path `/`, services registered after this one will\n    /// be inaccessible. Register more specific handlers and services first.\n    ///\n    /// `Files` utilizes the existing Tokio thread-pool for blocking filesystem operations.\n    /// The number of running threads is adjusted over time as needed, up to a maximum of 512 times\n    /// the number of server [workers](actix_web::HttpServer::workers), by default.\n    pub fn new<T: Into<PathBuf>>(mount_path: &str, serve_from: T) -> Files {\n        let orig_dir = serve_from.into();\n        let dir = match orig_dir.canonicalize() {\n            Ok(canon_dir) => canon_dir,\n            Err(_) => {\n                log::error!(\"Specified path is not a directory: {:?}\", orig_dir);\n                PathBuf::new()\n            }\n        };\n\n        Files {\n            mount_path: mount_path.trim_end_matches('/').to_owned(),\n            directory: dir,\n            index: None,\n            show_index: false,\n            redirect_to_slash: false,\n            default: Rc::new(RefCell::new(None)),\n            renderer: Rc::new(directory_listing),\n            mime_override: None,\n            path_filter: None,\n            file_flags: named::Flags::default(),\n            use_guards: None,\n            guards: Vec::new(),\n            hidden_files: false,\n        }\n    }\n\n    /// Show files listing for directories.\n    ///\n    /// By default show files listing is disabled.\n    ///\n    /// When used with [`Files::index_file()`], files listing is shown as a fallback\n    /// when the index file is not found.\n    pub fn show_files_listing(mut self) -> Self {\n        self.show_index = true;\n        self\n    }\n\n    /// Redirects to a slash-ended path when browsing a directory.\n    ///\n    /// By default never redirect.\n    pub fn redirect_to_slash_directory(mut self) -> Self {\n        self.redirect_to_slash = true;\n        self\n    }\n\n    /// Set custom directory renderer.\n    pub fn files_listing_renderer<F>(mut self, f: F) -> Self\n    where\n        for<'r, 's> F:\n            Fn(&'r Directory, &'s HttpRequest) -> Result<ServiceResponse, io::Error> + 'static,\n    {\n        self.renderer = Rc::new(f);\n        self\n    }\n\n    /// Specifies MIME override callback.\n    pub fn mime_override<F>(mut self, f: F) -> Self\n    where\n        F: Fn(&mime::Name<'_>) -> DispositionType + 'static,\n    {\n        self.mime_override = Some(Rc::new(f));\n        self\n    }\n\n    /// Sets path filtering closure.\n    ///\n    /// The path provided to the closure is relative to `serve_from` path.\n    /// You can safely join this path with the `serve_from` path to get the real path.\n    /// However, the real path may not exist since the filter is called before checking path existence.\n    ///\n    /// When a path doesn't pass the filter, [`Files::default_handler`] is called if set, otherwise,\n    /// `404 Not Found` is returned.\n    ///\n    /// # Examples\n    /// ```\n    /// use std::path::Path;\n    /// use actix_files::Files;\n    ///\n    /// // prevent searching subdirectories and following symlinks\n    /// let files_service = Files::new(\"/\", \"./static\").path_filter(|path, _| {\n    ///     path.components().count() == 1\n    ///         && Path::new(\"./static\")\n    ///             .join(path)\n    ///             .symlink_metadata()\n    ///             .map(|m| !m.file_type().is_symlink())\n    ///             .unwrap_or(false)\n    /// });\n    /// ```\n    pub fn path_filter<F>(mut self, f: F) -> Self\n    where\n        F: Fn(&Path, &RequestHead) -> bool + 'static,\n    {\n        self.path_filter = Some(Rc::new(f));\n        self\n    }\n\n    /// Set index file\n    ///\n    /// Shows specific index file for directories instead of\n    /// showing files listing.\n    ///\n    /// If the index file is not found, files listing is shown as a fallback if\n    /// [`Files::show_files_listing()`] is set.\n    pub fn index_file<T: Into<String>>(mut self, index: T) -> Self {\n        self.index = Some(index.into());\n        self\n    }\n\n    /// Specifies whether to use ETag or not.\n    ///\n    /// Default is true.\n    pub fn use_etag(mut self, value: bool) -> Self {\n        self.file_flags.set(named::Flags::ETAG, value);\n        self\n    }\n\n    /// Specifies whether to use Last-Modified or not.\n    ///\n    /// Default is true.\n    pub fn use_last_modified(mut self, value: bool) -> Self {\n        self.file_flags.set(named::Flags::LAST_MD, value);\n        self\n    }\n\n    /// Specifies whether text responses should signal a UTF-8 encoding.\n    ///\n    /// Default is false (but will default to true in a future version).\n    pub fn prefer_utf8(mut self, value: bool) -> Self {\n        self.file_flags.set(named::Flags::PREFER_UTF8, value);\n        self\n    }\n\n    /// Adds a routing guard.\n    ///\n    /// Use this to allow multiple chained file services that respond to strictly different\n    /// properties of a request. Due to the way routing works, if a guard check returns true and the\n    /// request starts being handled by the file service, it will not be able to back-out and try\n    /// the next service, you will simply get a 404 (or 405) error response.\n    ///\n    /// To allow `POST` requests to retrieve files, see [`Files::method_guard()`].\n    ///\n    /// # Examples\n    /// ```\n    /// use actix_web::{guard::Header, App};\n    /// use actix_files::Files;\n    ///\n    /// App::new().service(\n    ///     Files::new(\"/\",\"/my/site/files\")\n    ///         .guard(Header(\"Host\", \"example.com\"))\n    /// );\n    /// ```\n    pub fn guard<G: Guard + 'static>(mut self, guard: G) -> Self {\n        self.guards.push(Rc::new(guard));\n        self\n    }\n\n    /// Specifies guard to check before fetching directory listings or files.\n    ///\n    /// Note that this guard has no effect on routing; it's main use is to guard on the request's\n    /// method just before serving the file, only allowing `GET` and `HEAD` requests by default.\n    /// See [`Files::guard`] for routing guards.\n    pub fn method_guard<G: Guard + 'static>(mut self, guard: G) -> Self {\n        self.use_guards = Some(Rc::new(guard));\n        self\n    }\n\n    /// See [`Files::method_guard`].\n    #[doc(hidden)]\n    #[deprecated(since = \"0.6.0\", note = \"Renamed to `method_guard`.\")]\n    pub fn use_guards<G: Guard + 'static>(self, guard: G) -> Self {\n        self.method_guard(guard)\n    }\n\n    /// Disable `Content-Disposition` header.\n    ///\n    /// By default Content-Disposition` header is enabled.\n    pub fn disable_content_disposition(mut self) -> Self {\n        self.file_flags.remove(named::Flags::CONTENT_DISPOSITION);\n        self\n    }\n\n    /// Sets default handler which is used when no matched file could be found.\n    ///\n    /// # Examples\n    /// Setting a fallback static file handler:\n    /// ```\n    /// use actix_files::{Files, NamedFile};\n    /// use actix_web::dev::{ServiceRequest, ServiceResponse, fn_service};\n    ///\n    /// # fn run() -> Result<(), actix_web::Error> {\n    /// let files = Files::new(\"/\", \"./static\")\n    ///     .index_file(\"index.html\")\n    ///     .default_handler(fn_service(|req: ServiceRequest| async {\n    ///         let (req, _) = req.into_parts();\n    ///         let file = NamedFile::open_async(\"./static/404.html\").await?;\n    ///         let res = file.into_response(&req);\n    ///         Ok(ServiceResponse::new(req, res))\n    ///     }));\n    /// # Ok(())\n    /// # }\n    /// ```\n    pub fn default_handler<F, U>(mut self, f: F) -> Self\n    where\n        F: IntoServiceFactory<U, ServiceRequest>,\n        U: ServiceFactory<ServiceRequest, Config = (), Response = ServiceResponse, Error = Error>\n            + 'static,\n    {\n        // create and configure default resource\n        self.default = Rc::new(RefCell::new(Some(Rc::new(boxed::factory(\n            f.into_factory().map_init_err(|_| ()),\n        )))));\n\n        self\n    }\n\n    /// Enables serving hidden files and directories, allowing a leading dots in url fragments.\n    pub fn use_hidden_files(mut self) -> Self {\n        self.hidden_files = true;\n        self\n    }\n}\n\nimpl HttpServiceFactory for Files {\n    fn register(mut self, config: &mut AppService) {\n        let guards = if self.guards.is_empty() {\n            None\n        } else {\n            let guards = std::mem::take(&mut self.guards);\n            Some(\n                guards\n                    .into_iter()\n                    .map(|guard| -> Box<dyn Guard> { Box::new(guard) })\n                    .collect::<Vec<_>>(),\n            )\n        };\n\n        if self.default.borrow().is_none() {\n            *self.default.borrow_mut() = Some(config.default_service());\n        }\n\n        let rdef = if config.is_root() {\n            ResourceDef::root_prefix(&self.mount_path)\n        } else {\n            ResourceDef::prefix(&self.mount_path)\n        };\n\n        config.register_service(rdef, guards, self, None)\n    }\n}\n\nimpl ServiceFactory<ServiceRequest> for Files {\n    type Response = ServiceResponse;\n    type Error = Error;\n    type Config = ();\n    type Service = FilesService;\n    type InitError = ();\n    type Future = LocalBoxFuture<'static, Result<Self::Service, Self::InitError>>;\n\n    fn new_service(&self, _: ()) -> Self::Future {\n        let mut inner = FilesServiceInner {\n            directory: self.directory.clone(),\n            index: self.index.clone(),\n            show_index: self.show_index,\n            redirect_to_slash: self.redirect_to_slash,\n            default: None,\n            renderer: self.renderer.clone(),\n            mime_override: self.mime_override.clone(),\n            path_filter: self.path_filter.clone(),\n            file_flags: self.file_flags,\n            guards: self.use_guards.clone(),\n            hidden_files: self.hidden_files,\n        };\n\n        if let Some(ref default) = *self.default.borrow() {\n            let fut = default.new_service(());\n            Box::pin(async {\n                match fut.await {\n                    Ok(default) => {\n                        inner.default = Some(default);\n                        Ok(FilesService(Rc::new(inner)))\n                    }\n                    Err(_) => Err(()),\n                }\n            })\n        } else {\n            Box::pin(async move { Ok(FilesService(Rc::new(inner))) })\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use actix_web::{\n        http::StatusCode,\n        test::{self, TestRequest},\n        App, HttpResponse,\n    };\n\n    use super::*;\n\n    #[actix_web::test]\n    async fn custom_files_listing_renderer() {\n        let srv = test::init_service(\n            App::new().service(\n                Files::new(\"/\", \"./tests\")\n                    .show_files_listing()\n                    .files_listing_renderer(|dir, req| {\n                        Ok(ServiceResponse::new(\n                            req.clone(),\n                            HttpResponse::Ok().body(dir.path.to_str().unwrap().to_owned()),\n                        ))\n                    }),\n            ),\n        )\n        .await;\n\n        let req = TestRequest::with_uri(\"/\").to_request();\n        let res = test::call_service(&srv, req).await;\n\n        assert_eq!(res.status(), StatusCode::OK);\n        let body = test::read_body(res).await;\n        let body_str = std::str::from_utf8(&body).unwrap();\n        let actual_path = Path::new(&body_str);\n        let expected_path = Path::new(\"actix-files/tests\");\n        assert!(\n            actual_path.ends_with(expected_path),\n            \"body {:?} does not end with {:?}\",\n            actual_path,\n            expected_path\n        );\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "7e6ca5cd6ba99e354118e875c9d1ceb9ff69248c",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/actix-web/actix-multipart-derive/tests/trybuild/deny-unknown.rs",
    "func": "use actix_web::{web, App, Responder};\n\nuse actix_multipart::form::MultipartForm;\n\n#[derive(MultipartForm)]\n#[multipart(deny_unknown_fields)]\nstruct Form {}\n\nasync fn handler(_form: MultipartForm<Form>) -> impl Responder {\n    \"Hello World!\"\n}\n\n#[actix_web::main]\nasync fn main() {\n    App::new().default_service(web::to(handler));\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "2963e43da3062c476cd05e9a04bad3501f4c2862",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/actix-web/actix-http/examples/actix-web.rs",
    "func": "use actix_http::HttpService;\nuse actix_server::Server;\nuse actix_service::map_config;\nuse actix_web::{dev::AppConfig, get, App, Responder};\n\n#[get(\"/\")]\nasync fn index() -> impl Responder {\n    \"Hello, world. From Actix Web!\"\n}\n\n#[tokio::main(flavor = \"current_thread\")]\nasync fn main() -> std::io::Result<()> {\n    Server::build()\n        .bind(\"hello-world\", \"127.0.0.1:8080\", || {\n            // construct actix-web app\n            let app = App::new().service(index);\n\n            HttpService::build()\n                // pass the app to service builder\n                // map_config is used to map App's configuration to ServiceBuilder\n                // h1 will configure server to only use HTTP/1.1\n                .h1(map_config(app, |_| AppConfig::default()))\n                .tcp()\n        })?\n        .run()\n        .await\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "1b3922a2b424259857ac83624e38ba976d9828c8",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/actix-web/actix-http/src/notify_on_drop.rs",
    "func": "/// Test Module for checking the drop state of certain async tasks that are spawned\n/// with `actix_rt::spawn`\n///\n/// The target task must explicitly generate `NotifyOnDrop` when spawn the task\nuse std::cell::RefCell;\n\nthread_local! {\n    static NOTIFY_DROPPED: RefCell<Option<bool>> = const { RefCell::new(None) };\n}\n\n/// Check if the spawned task is dropped.\n///\n/// # Panics\n/// Panics when there was no `NotifyOnDrop` instance on current thread.\npub(crate) fn is_dropped() -> bool {\n    NOTIFY_DROPPED.with(|bool| {\n        bool.borrow()\n            .expect(\"No NotifyOnDrop existed on current thread\")\n    })\n}\n\npub(crate) struct NotifyOnDrop;\n\nimpl NotifyOnDrop {\n    /// # Panics\n    /// Panics hen construct multiple instances on any given thread.\n    pub(crate) fn new() -> Self {\n        NOTIFY_DROPPED.with(|bool| {\n            let mut bool = bool.borrow_mut();\n            if bool.is_some() {\n                panic!(\"NotifyOnDrop existed on current thread\");\n            } else {\n                *bool = Some(false);\n            }\n        });\n\n        NotifyOnDrop\n    }\n}\n\nimpl Drop for NotifyOnDrop {\n    fn drop(&mut self) {\n        NOTIFY_DROPPED.with(|bool| {\n            if let Some(b) = bool.borrow_mut().as_mut() {\n                *b = true;\n            }\n        });\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "bcafa89458fe9fed5f82bb74d052fa6784dfaddc",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/actix-web/actix-http/src/ws/mask.rs",
    "func": "//! This is code from [Tungstenite project](https://github.com/snapview/tungstenite-rs)\n\n/// Mask/unmask a frame.\n#[inline]\npub fn apply_mask(buf: &mut [u8], mask: [u8; 4]) {\n    apply_mask_fast32(buf, mask)\n}\n\n/// A safe unoptimized mask application.\n#[inline]\nfn apply_mask_fallback(buf: &mut [u8], mask: [u8; 4]) {\n    for (i, byte) in buf.iter_mut().enumerate() {\n        *byte ^= mask[i & 3];\n    }\n}\n\n/// Faster version of `apply_mask()` which operates on 4-byte blocks.\n#[inline]\npub fn apply_mask_fast32(buf: &mut [u8], mask: [u8; 4]) {\n    let mask_u32 = u32::from_ne_bytes(mask);\n\n    // SAFETY:\n    //\n    // buf is a valid slice borrowed mutably from bytes::BytesMut.\n    //\n    // un aligned prefix and suffix would be mask/unmask per byte.\n    // proper aligned middle slice goes into fast path and operates on 4-byte blocks.\n    let (prefix, words, suffix) = unsafe { buf.align_to_mut::<u32>() };\n    apply_mask_fallback(prefix, mask);\n    let head = prefix.len() & 3;\n    let mask_u32 = if head > 0 {\n        if cfg!(target_endian = \"big\") {\n            mask_u32.rotate_left(8 * head as u32)\n        } else {\n            mask_u32.rotate_right(8 * head as u32)\n        }\n    } else {\n        mask_u32\n    };\n    for word in words.iter_mut() {\n        *word ^= mask_u32;\n    }\n    apply_mask_fallback(suffix, mask_u32.to_ne_bytes());\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_apply_mask() {\n        let mask = [0x6d, 0xb6, 0xb2, 0x80];\n        let unmasked = [\n            0xf3, 0x00, 0x01, 0x02, 0x03, 0x80, 0x81, 0x82, 0xff, 0xfe, 0x00, 0x17, 0x74, 0xf9,\n            0x12, 0x03,\n        ];\n\n        for data_len in 0..=unmasked.len() {\n            let unmasked = &unmasked[0..data_len];\n            // Check masking with different alignment.\n            for off in 0..=3 {\n                if unmasked.len() < off {\n                    continue;\n                }\n                let mut masked = unmasked.to_vec();\n                apply_mask_fallback(&mut masked[off..], mask);\n\n                let mut masked_fast = unmasked.to_vec();\n                apply_mask_fast32(&mut masked_fast[off..], mask);\n\n                assert_eq!(masked, masked_fast);\n            }\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "31c3263b137ad81b89b7b95ea7261b9b9e711e55",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/actix-web/actix-http/src/h2/service.rs",
    "func": "use std::{\n    future::Future,\n    marker::PhantomData,\n    mem, net,\n    pin::Pin,\n    rc::Rc,\n    task::{Context, Poll},\n};\n\nuse actix_codec::{AsyncRead, AsyncWrite};\nuse actix_rt::net::TcpStream;\nuse actix_service::{\n    fn_factory, fn_service, IntoServiceFactory, Service, ServiceFactory, ServiceFactoryExt as _,\n};\nuse actix_utils::future::ready;\nuse futures_core::{future::LocalBoxFuture, ready};\nuse tracing::{error, trace};\n\nuse super::{dispatcher::Dispatcher, handshake_with_timeout, HandshakeWithTimeout};\nuse crate::{\n    body::{BoxBody, MessageBody},\n    config::ServiceConfig,\n    error::DispatchError,\n    service::HttpFlow,\n    ConnectCallback, OnConnectData, Request, Response,\n};\n\n/// `ServiceFactory` implementation for HTTP/2 transport\npub struct H2Service<T, S, B> {\n    srv: S,\n    cfg: ServiceConfig,\n    on_connect_ext: Option<Rc<ConnectCallback<T>>>,\n    _phantom: PhantomData<(T, B)>,\n}\n\nimpl<T, S, B> H2Service<T, S, B>\nwhere\n    S: ServiceFactory<Request, Config = ()>,\n    S::Error: Into<Response<BoxBody>> + 'static,\n    S::Response: Into<Response<B>> + 'static,\n    <S::Service as Service<Request>>::Future: 'static,\n\n    B: MessageBody + 'static,\n{\n    /// Create new `H2Service` instance with config.\n    pub(crate) fn with_config<F: IntoServiceFactory<S, Request>>(\n        cfg: ServiceConfig,\n        service: F,\n    ) -> Self {\n        H2Service {\n            cfg,\n            on_connect_ext: None,\n            srv: service.into_factory(),\n            _phantom: PhantomData,\n        }\n    }\n\n    /// Set on connect callback.\n    pub(crate) fn on_connect_ext(mut self, f: Option<Rc<ConnectCallback<T>>>) -> Self {\n        self.on_connect_ext = f;\n        self\n    }\n}\n\nimpl<S, B> H2Service<TcpStream, S, B>\nwhere\n    S: ServiceFactory<Request, Config = ()>,\n    S::Future: 'static,\n    S::Error: Into<Response<BoxBody>> + 'static,\n    S::Response: Into<Response<B>> + 'static,\n    <S::Service as Service<Request>>::Future: 'static,\n\n    B: MessageBody + 'static,\n{\n    /// Create plain TCP based service\n    pub fn tcp(\n        self,\n    ) -> impl ServiceFactory<\n        TcpStream,\n        Config = (),\n        Response = (),\n        Error = DispatchError,\n        InitError = S::InitError,\n    > {\n        fn_factory(|| {\n            ready(Ok::<_, S::InitError>(fn_service(|io: TcpStream| {\n                let peer_addr = io.peer_addr().ok();\n                ready(Ok::<_, DispatchError>((io, peer_addr)))\n            })))\n        })\n        .and_then(self)\n    }\n}\n\n#[cfg(feature = \"openssl\")]\nmod openssl {\n    use actix_service::ServiceFactoryExt as _;\n    use actix_tls::accept::{\n        openssl::{\n            reexports::{Error as SslError, SslAcceptor},\n            Acceptor, TlsStream,\n        },\n        TlsError,\n    };\n\n    use super::*;\n\n    impl<S, B> H2Service<TlsStream<TcpStream>, S, B>\n    where\n        S: ServiceFactory<Request, Config = ()>,\n        S::Future: 'static,\n        S::Error: Into<Response<BoxBody>> + 'static,\n        S::Response: Into<Response<B>> + 'static,\n        <S::Service as Service<Request>>::Future: 'static,\n\n        B: MessageBody + 'static,\n    {\n        /// Create OpenSSL based service.\n        pub fn openssl(\n            self,\n            acceptor: SslAcceptor,\n        ) -> impl ServiceFactory<\n            TcpStream,\n            Config = (),\n            Response = (),\n            Error = TlsError<SslError, DispatchError>,\n            InitError = S::InitError,\n        > {\n            Acceptor::new(acceptor)\n                .map_init_err(|_| {\n                    unreachable!(\"TLS acceptor service factory does not error on init\")\n                })\n                .map_err(TlsError::into_service_error)\n                .map(|io: TlsStream<TcpStream>| {\n                    let peer_addr = io.get_ref().peer_addr().ok();\n                    (io, peer_addr)\n                })\n                .and_then(self.map_err(TlsError::Service))\n        }\n    }\n}\n\n#[cfg(feature = \"rustls-0_20\")]\nmod rustls_0_20 {\n    use std::io;\n\n    use actix_service::ServiceFactoryExt as _;\n    use actix_tls::accept::{\n        rustls::{reexports::ServerConfig, Acceptor, TlsStream},\n        TlsError,\n    };\n\n    use super::*;\n\n    impl<S, B> H2Service<TlsStream<TcpStream>, S, B>\n    where\n        S: ServiceFactory<Request, Config = ()>,\n        S::Future: 'static,\n        S::Error: Into<Response<BoxBody>> + 'static,\n        S::Response: Into<Response<B>> + 'static,\n        <S::Service as Service<Request>>::Future: 'static,\n\n        B: MessageBody + 'static,\n    {\n        /// Create Rustls v0.20 based service.\n        pub fn rustls(\n            self,\n            mut config: ServerConfig,\n        ) -> impl ServiceFactory<\n            TcpStream,\n            Config = (),\n            Response = (),\n            Error = TlsError<io::Error, DispatchError>,\n            InitError = S::InitError,\n        > {\n            let mut protos = vec![b\"h2\".to_vec()];\n            protos.extend_from_slice(&config.alpn_protocols);\n            config.alpn_protocols = protos;\n\n            Acceptor::new(config)\n                .map_init_err(|_| {\n                    unreachable!(\"TLS acceptor service factory does not error on init\")\n                })\n                .map_err(TlsError::into_service_error)\n                .map(|io: TlsStream<TcpStream>| {\n                    let peer_addr = io.get_ref().0.peer_addr().ok();\n                    (io, peer_addr)\n                })\n                .and_then(self.map_err(TlsError::Service))\n        }\n    }\n}\n\n#[cfg(feature = \"rustls-0_21\")]\nmod rustls_0_21 {\n    use std::io;\n\n    use actix_service::ServiceFactoryExt as _;\n    use actix_tls::accept::{\n        rustls_0_21::{reexports::ServerConfig, Acceptor, TlsStream},\n        TlsError,\n    };\n\n    use super::*;\n\n    impl<S, B> H2Service<TlsStream<TcpStream>, S, B>\n    where\n        S: ServiceFactory<Request, Config = ()>,\n        S::Future: 'static,\n        S::Error: Into<Response<BoxBody>> + 'static,\n        S::Response: Into<Response<B>> + 'static,\n        <S::Service as Service<Request>>::Future: 'static,\n\n        B: MessageBody + 'static,\n    {\n        /// Create Rustls v0.21 based service.\n        pub fn rustls_021(\n            self,\n            mut config: ServerConfig,\n        ) -> impl ServiceFactory<\n            TcpStream,\n            Config = (),\n            Response = (),\n            Error = TlsError<io::Error, DispatchError>,\n            InitError = S::InitError,\n        > {\n            let mut protos = vec![b\"h2\".to_vec()];\n            protos.extend_from_slice(&config.alpn_protocols);\n            config.alpn_protocols = protos;\n\n            Acceptor::new(config)\n                .map_init_err(|_| {\n                    unreachable!(\"TLS acceptor service factory does not error on init\")\n                })\n                .map_err(TlsError::into_service_error)\n                .map(|io: TlsStream<TcpStream>| {\n                    let peer_addr = io.get_ref().0.peer_addr().ok();\n                    (io, peer_addr)\n                })\n                .and_then(self.map_err(TlsError::Service))\n        }\n    }\n}\n\n#[cfg(feature = \"rustls-0_22\")]\nmod rustls_0_22 {\n    use std::io;\n\n    use actix_service::ServiceFactoryExt as _;\n    use actix_tls::accept::{\n        rustls_0_22::{reexports::ServerConfig, Acceptor, TlsStream},\n        TlsError,\n    };\n\n    use super::*;\n\n    impl<S, B> H2Service<TlsStream<TcpStream>, S, B>\n    where\n        S: ServiceFactory<Request, Config = ()>,\n        S::Future: 'static,\n        S::Error: Into<Response<BoxBody>> + 'static,\n        S::Response: Into<Response<B>> + 'static,\n        <S::Service as Service<Request>>::Future: 'static,\n\n        B: MessageBody + 'static,\n    {\n        /// Create Rustls v0.22 based service.\n        pub fn rustls_0_22(\n            self,\n            mut config: ServerConfig,\n        ) -> impl ServiceFactory<\n            TcpStream,\n            Config = (),\n            Response = (),\n            Error = TlsError<io::Error, DispatchError>,\n            InitError = S::InitError,\n        > {\n            let mut protos = vec![b\"h2\".to_vec()];\n            protos.extend_from_slice(&config.alpn_protocols);\n            config.alpn_protocols = protos;\n\n            Acceptor::new(config)\n                .map_init_err(|_| {\n                    unreachable!(\"TLS acceptor service factory does not error on init\")\n                })\n                .map_err(TlsError::into_service_error)\n                .map(|io: TlsStream<TcpStream>| {\n                    let peer_addr = io.get_ref().0.peer_addr().ok();\n                    (io, peer_addr)\n                })\n                .and_then(self.map_err(TlsError::Service))\n        }\n    }\n}\n\n#[cfg(feature = \"rustls-0_23\")]\nmod rustls_0_23 {\n    use std::io;\n\n    use actix_service::ServiceFactoryExt as _;\n    use actix_tls::accept::{\n        rustls_0_23::{reexports::ServerConfig, Acceptor, TlsStream},\n        TlsError,\n    };\n\n    use super::*;\n\n    impl<S, B> H2Service<TlsStream<TcpStream>, S, B>\n    where\n        S: ServiceFactory<Request, Config = ()>,\n        S::Future: 'static,\n        S::Error: Into<Response<BoxBody>> + 'static,\n        S::Response: Into<Response<B>> + 'static,\n        <S::Service as Service<Request>>::Future: 'static,\n\n        B: MessageBody + 'static,\n    {\n        /// Create Rustls v0.23 based service.\n        pub fn rustls_0_23(\n            self,\n            mut config: ServerConfig,\n        ) -> impl ServiceFactory<\n            TcpStream,\n            Config = (),\n            Response = (),\n            Error = TlsError<io::Error, DispatchError>,\n            InitError = S::InitError,\n        > {\n            let mut protos = vec![b\"h2\".to_vec()];\n            protos.extend_from_slice(&config.alpn_protocols);\n            config.alpn_protocols = protos;\n\n            Acceptor::new(config)\n                .map_init_err(|_| {\n                    unreachable!(\"TLS acceptor service factory does not error on init\")\n                })\n                .map_err(TlsError::into_service_error)\n                .map(|io: TlsStream<TcpStream>| {\n                    let peer_addr = io.get_ref().0.peer_addr().ok();\n                    (io, peer_addr)\n                })\n                .and_then(self.map_err(TlsError::Service))\n        }\n    }\n}\n\nimpl<T, S, B> ServiceFactory<(T, Option<net::SocketAddr>)> for H2Service<T, S, B>\nwhere\n    T: AsyncRead + AsyncWrite + Unpin + 'static,\n\n    S: ServiceFactory<Request, Config = ()>,\n    S::Future: 'static,\n    S::Error: Into<Response<BoxBody>> + 'static,\n    S::Response: Into<Response<B>> + 'static,\n    <S::Service as Service<Request>>::Future: 'static,\n\n    B: MessageBody + 'static,\n{\n    type Response = ();\n    type Error = DispatchError;\n    type Config = ();\n    type Service = H2ServiceHandler<T, S::Service, B>;\n    type InitError = S::InitError;\n    type Future = LocalBoxFuture<'static, Result<Self::Service, Self::InitError>>;\n\n    fn new_service(&self, _: ()) -> Self::Future {\n        let service = self.srv.new_service(());\n        let cfg = self.cfg.clone();\n        let on_connect_ext = self.on_connect_ext.clone();\n\n        Box::pin(async move {\n            let service = service.await?;\n            Ok(H2ServiceHandler::new(cfg, on_connect_ext, service))\n        })\n    }\n}\n\n/// `Service` implementation for HTTP/2 transport\npub struct H2ServiceHandler<T, S, B>\nwhere\n    S: Service<Request>,\n{\n    flow: Rc<HttpFlow<S, (), ()>>,\n    cfg: ServiceConfig,\n    on_connect_ext: Option<Rc<ConnectCallback<T>>>,\n    _phantom: PhantomData<B>,\n}\n\nimpl<T, S, B> H2ServiceHandler<T, S, B>\nwhere\n    S: Service<Request>,\n    S::Error: Into<Response<BoxBody>> + 'static,\n    S::Future: 'static,\n    S::Response: Into<Response<B>> + 'static,\n    B: MessageBody + 'static,\n{\n    fn new(\n        cfg: ServiceConfig,\n        on_connect_ext: Option<Rc<ConnectCallback<T>>>,\n        service: S,\n    ) -> H2ServiceHandler<T, S, B> {\n        H2ServiceHandler {\n            flow: HttpFlow::new(service, (), None),\n            cfg,\n            on_connect_ext,\n            _phantom: PhantomData,\n        }\n    }\n}\n\nimpl<T, S, B> Service<(T, Option<net::SocketAddr>)> for H2ServiceHandler<T, S, B>\nwhere\n    T: AsyncRead + AsyncWrite + Unpin,\n    S: Service<Request>,\n    S::Error: Into<Response<BoxBody>> + 'static,\n    S::Future: 'static,\n    S::Response: Into<Response<B>> + 'static,\n    B: MessageBody + 'static,\n{\n    type Response = ();\n    type Error = DispatchError;\n    type Future = H2ServiceHandlerResponse<T, S, B>;\n\n    fn poll_ready(&self, cx: &mut Context<'_>) -> Poll<Result<(), Self::Error>> {\n        self.flow.service.poll_ready(cx).map_err(|err| {\n            let err = err.into();\n            error!(\"Service readiness error: {:?}\", err);\n            DispatchError::Service(err)\n        })\n    }\n\n    fn call(&self, (io, addr): (T, Option<net::SocketAddr>)) -> Self::Future {\n        let on_connect_data = OnConnectData::from_io(&io, self.on_connect_ext.as_deref());\n\n        H2ServiceHandlerResponse {\n            state: State::Handshake(\n                Some(Rc::clone(&self.flow)),\n                Some(self.cfg.clone()),\n                addr,\n                on_connect_data,\n                handshake_with_timeout(io, &self.cfg),\n            ),\n        }\n    }\n}\n\nenum State<T, S: Service<Request>, B: MessageBody>\nwhere\n    T: AsyncRead + AsyncWrite + Unpin,\n    S::Future: 'static,\n{\n    Handshake(\n        Option<Rc<HttpFlow<S, (), ()>>>,\n        Option<ServiceConfig>,\n        Option<net::SocketAddr>,\n        OnConnectData,\n        HandshakeWithTimeout<T>,\n    ),\n    Established(Dispatcher<T, S, B, (), ()>),\n}\n\npub struct H2ServiceHandlerResponse<T, S, B>\nwhere\n    T: AsyncRead + AsyncWrite + Unpin,\n    S: Service<Request>,\n    S::Error: Into<Response<BoxBody>> + 'static,\n    S::Future: 'static,\n    S::Response: Into<Response<B>> + 'static,\n    B: MessageBody + 'static,\n{\n    state: State<T, S, B>,\n}\n\nimpl<T, S, B> Future for H2ServiceHandlerResponse<T, S, B>\nwhere\n    T: AsyncRead + AsyncWrite + Unpin,\n    S: Service<Request>,\n    S::Error: Into<Response<BoxBody>> + 'static,\n    S::Future: 'static,\n    S::Response: Into<Response<B>> + 'static,\n    B: MessageBody,\n{\n    type Output = Result<(), DispatchError>;\n\n    fn poll(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> {\n        match self.state {\n            State::Handshake(\n                ref mut srv,\n                ref mut config,\n                ref peer_addr,\n                ref mut conn_data,\n                ref mut handshake,\n            ) => match ready!(Pin::new(handshake).poll(cx)) {\n                Ok((conn, timer)) => {\n                    let on_connect_data = mem::take(conn_data);\n\n                    self.state = State::Established(Dispatcher::new(\n                        conn,\n                        srv.take().unwrap(),\n                        config.take().unwrap(),\n                        *peer_addr,\n                        on_connect_data,\n                        timer,\n                    ));\n\n                    self.poll(cx)\n                }\n\n                Err(err) => {\n                    trace!(\"H2 handshake error: {}\", err);\n                    Poll::Ready(Err(err))\n                }\n            },\n\n            State::Established(ref mut disp) => Pin::new(disp).poll(cx),\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "562752d9a460076bf437827d601eabbc5c7c10f5",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/actix-web/actix-http/src/body/body_stream.rs",
    "func": "use std::{\n    error::Error as StdError,\n    pin::Pin,\n    task::{Context, Poll},\n};\n\nuse bytes::Bytes;\nuse futures_core::{ready, Stream};\nuse pin_project_lite::pin_project;\n\nuse super::{BodySize, MessageBody};\n\npin_project! {\n    /// Streaming response wrapper.\n    ///\n    /// Response does not contain `Content-Length` header and appropriate transfer encoding is used.\n    pub struct BodyStream<S> {\n        #[pin]\n        stream: S,\n    }\n}\n\n// TODO: from_infallible method\n\nimpl<S, E> BodyStream<S>\nwhere\n    S: Stream<Item = Result<Bytes, E>>,\n    E: Into<Box<dyn StdError>> + 'static,\n{\n    #[inline]\n    pub fn new(stream: S) -> Self {\n        BodyStream { stream }\n    }\n}\n\nimpl<S, E> MessageBody for BodyStream<S>\nwhere\n    S: Stream<Item = Result<Bytes, E>>,\n    E: Into<Box<dyn StdError>> + 'static,\n{\n    type Error = E;\n\n    #[inline]\n    fn size(&self) -> BodySize {\n        BodySize::Stream\n    }\n\n    /// Attempts to pull out the next value of the underlying [`Stream`].\n    ///\n    /// Empty values are skipped to prevent [`BodyStream`]'s transmission being ended on a\n    /// zero-length chunk, but rather proceed until the underlying [`Stream`] ends.\n    fn poll_next(\n        mut self: Pin<&mut Self>,\n        cx: &mut Context<'_>,\n    ) -> Poll<Option<Result<Bytes, Self::Error>>> {\n        loop {\n            let stream = self.as_mut().project().stream;\n\n            let chunk = match ready!(stream.poll_next(cx)) {\n                Some(Ok(ref bytes)) if bytes.is_empty() => continue,\n                opt => opt,\n            };\n\n            return Poll::Ready(chunk);\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use std::{convert::Infallible, time::Duration};\n\n    use actix_rt::{\n        pin,\n        time::{sleep, Sleep},\n    };\n    use actix_utils::future::poll_fn;\n    use derive_more::derive::{Display, Error};\n    use futures_core::ready;\n    use futures_util::{stream, FutureExt as _};\n    use pin_project_lite::pin_project;\n    use static_assertions::{assert_impl_all, assert_not_impl_any};\n\n    use super::*;\n    use crate::body::to_bytes;\n\n    assert_impl_all!(BodyStream<stream::Empty<Result<Bytes, crate::Error>>>: MessageBody);\n    assert_impl_all!(BodyStream<stream::Empty<Result<Bytes, &'static str>>>: MessageBody);\n    assert_impl_all!(BodyStream<stream::Repeat<Result<Bytes, &'static str>>>: MessageBody);\n    assert_impl_all!(BodyStream<stream::Empty<Result<Bytes, Infallible>>>: MessageBody);\n    assert_impl_all!(BodyStream<stream::Repeat<Result<Bytes, Infallible>>>: MessageBody);\n\n    assert_not_impl_any!(BodyStream<stream::Empty<Bytes>>: MessageBody);\n    assert_not_impl_any!(BodyStream<stream::Repeat<Bytes>>: MessageBody);\n    // crate::Error is not Clone\n    assert_not_impl_any!(BodyStream<stream::Repeat<Result<Bytes, crate::Error>>>: MessageBody);\n\n    #[actix_rt::test]\n    async fn skips_empty_chunks() {\n        let body = BodyStream::new(stream::iter(\n            [\"1\", \"\", \"2\"]\n                .iter()\n                .map(|&v| Ok::<_, Infallible>(Bytes::from(v))),\n        ));\n        pin!(body);\n\n        assert_eq!(\n            poll_fn(|cx| body.as_mut().poll_next(cx))\n                .await\n                .unwrap()\n                .ok(),\n            Some(Bytes::from(\"1\")),\n        );\n        assert_eq!(\n            poll_fn(|cx| body.as_mut().poll_next(cx))\n                .await\n                .unwrap()\n                .ok(),\n            Some(Bytes::from(\"2\")),\n        );\n    }\n\n    #[actix_rt::test]\n    async fn read_to_bytes() {\n        let body = BodyStream::new(stream::iter(\n            [\"1\", \"\", \"2\"]\n                .iter()\n                .map(|&v| Ok::<_, Infallible>(Bytes::from(v))),\n        ));\n\n        assert_eq!(to_bytes(body).await.ok(), Some(Bytes::from(\"12\")));\n    }\n    #[derive(Debug, Display, Error)]\n    #[display(\"stream error\")]\n    struct StreamErr;\n\n    #[actix_rt::test]\n    async fn stream_immediate_error() {\n        let body = BodyStream::new(stream::once(async { Err(StreamErr) }));\n        assert!(matches!(to_bytes(body).await, Err(StreamErr)));\n    }\n\n    #[actix_rt::test]\n    async fn stream_string_error() {\n        // `&'static str` does not impl `Error`\n        // but it does impl `Into<Box<dyn Error>>`\n\n        let body = BodyStream::new(stream::once(async { Err(\"stringy error\") }));\n        assert!(matches!(to_bytes(body).await, Err(\"stringy error\")));\n    }\n\n    #[actix_rt::test]\n    async fn stream_boxed_error() {\n        // `Box<dyn Error>` does not impl `Error`\n        // but it does impl `Into<Box<dyn Error>>`\n\n        let body = BodyStream::new(stream::once(async {\n            Err(Box::<dyn StdError>::from(\"stringy error\"))\n        }));\n\n        assert_eq!(\n            to_bytes(body).await.unwrap_err().to_string(),\n            \"stringy error\"\n        );\n    }\n\n    #[actix_rt::test]\n    async fn stream_delayed_error() {\n        let body = BodyStream::new(stream::iter(vec![Ok(Bytes::from(\"1\")), Err(StreamErr)]));\n        assert!(matches!(to_bytes(body).await, Err(StreamErr)));\n\n        pin_project! {\n            #[derive(Debug)]\n            #[project = TimeDelayStreamProj]\n            enum TimeDelayStream {\n                Start,\n                Sleep { delay: Pin<Box<Sleep>> },\n                Done,\n            }\n        }\n\n        impl Stream for TimeDelayStream {\n            type Item = Result<Bytes, StreamErr>;\n\n            fn poll_next(\n                mut self: Pin<&mut Self>,\n                cx: &mut Context<'_>,\n            ) -> Poll<Option<Self::Item>> {\n                match self.as_mut().get_mut() {\n                    TimeDelayStream::Start => {\n                        let sleep = sleep(Duration::from_millis(1));\n                        self.as_mut().set(TimeDelayStream::Sleep {\n                            delay: Box::pin(sleep),\n                        });\n                        cx.waker().wake_by_ref();\n                        Poll::Pending\n                    }\n\n                    TimeDelayStream::Sleep { ref mut delay } => {\n                        ready!(delay.poll_unpin(cx));\n                        self.set(TimeDelayStream::Done);\n                        cx.waker().wake_by_ref();\n                        Poll::Pending\n                    }\n\n                    TimeDelayStream::Done => Poll::Ready(Some(Err(StreamErr))),\n                }\n            }\n        }\n\n        let body = BodyStream::new(TimeDelayStream::Start);\n        assert!(matches!(to_bytes(body).await, Err(StreamErr)));\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "a5cd340117c9811da55342510f94df3fefbc6806",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/actix-web/awc/src/responses/json_body.rs",
    "func": "use std::{\n    future::Future,\n    marker::PhantomData,\n    mem,\n    pin::Pin,\n    task::{Context, Poll},\n};\n\nuse actix_http::{error::PayloadError, header, HttpMessage};\nuse bytes::Bytes;\nuse futures_core::{ready, Stream};\nuse pin_project_lite::pin_project;\nuse serde::de::DeserializeOwned;\n\nuse super::{read_body::ReadBody, ResponseTimeout, DEFAULT_BODY_LIMIT};\nuse crate::{error::JsonPayloadError, ClientResponse};\n\npin_project! {\n    /// A `Future` that reads a body stream, parses JSON, resolving to a deserialized `T`.\n    ///\n    /// # Errors\n    /// `Future` implementation returns error if:\n    /// - content type is not `application/json`;\n    /// - content length is greater than [limit](JsonBody::limit) (default: 2 MiB).\n    pub struct JsonBody<S, T> {\n        #[pin]\n        body: Option<ReadBody<S>>,\n        length: Option<usize>,\n        timeout: ResponseTimeout,\n        err: Option<JsonPayloadError>,\n        _phantom: PhantomData<T>,\n    }\n}\n\nimpl<S, T> JsonBody<S, T>\nwhere\n    S: Stream<Item = Result<Bytes, PayloadError>>,\n    T: DeserializeOwned,\n{\n    /// Creates a JSON body stream reader from a response by taking its payload.\n    pub fn new(res: &mut ClientResponse<S>) -> Self {\n        // check content-type\n        let json = if let Ok(Some(mime)) = res.mime_type() {\n            mime.subtype() == mime::JSON || mime.suffix() == Some(mime::JSON)\n        } else {\n            false\n        };\n\n        if !json {\n            return JsonBody {\n                length: None,\n                body: None,\n                timeout: ResponseTimeout::default(),\n                err: Some(JsonPayloadError::ContentType),\n                _phantom: PhantomData,\n            };\n        }\n\n        let length = res\n            .headers()\n            .get(&header::CONTENT_LENGTH)\n            .and_then(|len_hdr| len_hdr.to_str().ok())\n            .and_then(|len_str| len_str.parse::<usize>().ok());\n\n        JsonBody {\n            body: Some(ReadBody::new(res.take_payload(), DEFAULT_BODY_LIMIT)),\n            length,\n            timeout: mem::take(&mut res.timeout),\n            err: None,\n            _phantom: PhantomData,\n        }\n    }\n\n    /// Change max size of payload. Default limit is 2 MiB.\n    pub fn limit(mut self, limit: usize) -> Self {\n        if let Some(ref mut fut) = self.body {\n            fut.limit = limit;\n        }\n\n        self\n    }\n}\n\nimpl<S, T> Future for JsonBody<S, T>\nwhere\n    S: Stream<Item = Result<Bytes, PayloadError>>,\n    T: DeserializeOwned,\n{\n    type Output = Result<T, JsonPayloadError>;\n\n    fn poll(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> {\n        let this = self.project();\n\n        if let Some(err) = this.err.take() {\n            return Poll::Ready(Err(err));\n        }\n\n        if let Some(len) = this.length.take() {\n            let body = Option::as_ref(&this.body).unwrap();\n            if len > body.limit {\n                return Poll::Ready(Err(JsonPayloadError::Payload(PayloadError::Overflow)));\n            }\n        }\n\n        this.timeout\n            .poll_timeout(cx)\n            .map_err(JsonPayloadError::Payload)?;\n\n        let body = ready!(this.body.as_pin_mut().unwrap().poll(cx))?;\n        Poll::Ready(serde_json::from_slice::<T>(&body).map_err(JsonPayloadError::from))\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use actix_http::BoxedPayloadStream;\n    use serde::{Deserialize, Serialize};\n    use static_assertions::assert_impl_all;\n\n    use super::*;\n    use crate::test::TestResponse;\n\n    assert_impl_all!(JsonBody<BoxedPayloadStream, String>: Unpin);\n\n    #[derive(Serialize, Deserialize, PartialEq, Debug)]\n    struct MyObject {\n        name: String,\n    }\n\n    fn json_eq(err: JsonPayloadError, other: JsonPayloadError) -> bool {\n        match err {\n            JsonPayloadError::Payload(PayloadError::Overflow) => {\n                matches!(other, JsonPayloadError::Payload(PayloadError::Overflow))\n            }\n            JsonPayloadError::ContentType => matches!(other, JsonPayloadError::ContentType),\n            _ => false,\n        }\n    }\n\n    #[actix_rt::test]\n    async fn read_json_body() {\n        let mut req = TestResponse::default().finish();\n        let json = JsonBody::<_, MyObject>::new(&mut req).await;\n        assert!(json_eq(json.err().unwrap(), JsonPayloadError::ContentType));\n\n        let mut req = TestResponse::default()\n            .insert_header((\n                header::CONTENT_TYPE,\n                header::HeaderValue::from_static(\"application/text\"),\n            ))\n            .finish();\n        let json = JsonBody::<_, MyObject>::new(&mut req).await;\n        assert!(json_eq(json.err().unwrap(), JsonPayloadError::ContentType));\n\n        let mut req = TestResponse::default()\n            .insert_header((\n                header::CONTENT_TYPE,\n                header::HeaderValue::from_static(\"application/json\"),\n            ))\n            .insert_header((\n                header::CONTENT_LENGTH,\n                header::HeaderValue::from_static(\"10000\"),\n            ))\n            .finish();\n\n        let json = JsonBody::<_, MyObject>::new(&mut req).limit(100).await;\n        assert!(json_eq(\n            json.err().unwrap(),\n            JsonPayloadError::Payload(PayloadError::Overflow)\n        ));\n\n        let mut req = TestResponse::default()\n            .insert_header((\n                header::CONTENT_TYPE,\n                header::HeaderValue::from_static(\"application/json\"),\n            ))\n            .insert_header((\n                header::CONTENT_LENGTH,\n                header::HeaderValue::from_static(\"16\"),\n            ))\n            .set_payload(Bytes::from_static(b\"{\\\"name\\\": \\\"test\\\"}\"))\n            .finish();\n\n        let json = JsonBody::<_, MyObject>::new(&mut req).await;\n        assert_eq!(\n            json.ok().unwrap(),\n            MyObject {\n                name: \"test\".to_owned()\n            }\n        );\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "b575bb48f2f68e19f5378230af1256c38687d5b0",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/actix-web/actix-web/examples/macroless.rs",
    "func": "use actix_web::{middleware, rt, web, App, HttpRequest, HttpServer};\n\nasync fn index(req: HttpRequest) -> &'static str {\n    println!(\"REQ: {:?}\", req);\n    \"Hello world!\\r\\n\"\n}\n\nfn main() -> std::io::Result<()> {\n    env_logger::init_from_env(env_logger::Env::new().default_filter_or(\"info\"));\n\n    rt::System::new().block_on(\n        HttpServer::new(|| {\n            App::new()\n                .wrap(middleware::Logger::default())\n                .service(web::resource(\"/\").route(web::get().to(index)))\n        })\n        .bind((\"127.0.0.1\", 8080))?\n        .workers(1)\n        .run(),\n    )\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "3521bb3595b78830806ccf38970ae40aff1ef52c",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/actix-web/actix-web/src/app.rs",
    "func": "use std::{cell::RefCell, fmt, future::Future, rc::Rc};\n\nuse actix_http::{body::MessageBody, Extensions, Request};\nuse actix_service::{\n    apply, apply_fn_factory, boxed, IntoServiceFactory, ServiceFactory, ServiceFactoryExt,\n    Transform,\n};\nuse futures_util::FutureExt as _;\n\nuse crate::{\n    app_service::{AppEntry, AppInit, AppRoutingFactory},\n    config::ServiceConfig,\n    data::{Data, DataFactory, FnDataFactory},\n    dev::ResourceDef,\n    error::Error,\n    resource::Resource,\n    route::Route,\n    service::{\n        AppServiceFactory, BoxedHttpServiceFactory, HttpServiceFactory, ServiceFactoryWrapper,\n        ServiceRequest, ServiceResponse,\n    },\n};\n\n/// The top-level builder for an Actix Web application.\npub struct App<T> {\n    endpoint: T,\n    services: Vec<Box<dyn AppServiceFactory>>,\n    default: Option<Rc<BoxedHttpServiceFactory>>,\n    factory_ref: Rc<RefCell<Option<AppRoutingFactory>>>,\n    data_factories: Vec<FnDataFactory>,\n    external: Vec<ResourceDef>,\n    extensions: Extensions,\n}\n\nimpl App<AppEntry> {\n    /// Create application builder. Application can be configured with a builder-like pattern.\n    #[allow(clippy::new_without_default)]\n    pub fn new() -> Self {\n        let factory_ref = Rc::new(RefCell::new(None));\n\n        App {\n            endpoint: AppEntry::new(Rc::clone(&factory_ref)),\n            data_factories: Vec::new(),\n            services: Vec::new(),\n            default: None,\n            factory_ref,\n            external: Vec::new(),\n            extensions: Extensions::new(),\n        }\n    }\n}\n\nimpl<T> App<T>\nwhere\n    T: ServiceFactory<ServiceRequest, Config = (), Error = Error, InitError = ()>,\n{\n    /// Set application (root level) data.\n    ///\n    /// Application data stored with `App::app_data()` method is available through the\n    /// [`HttpRequest::app_data`](crate::HttpRequest::app_data) method at runtime.\n    ///\n    /// # [`Data<T>`]\n    /// Any [`Data<T>`] type added here can utilize its extractor implementation in handlers.\n    /// Types not wrapped in `Data<T>` cannot use this extractor. See [its docs](Data<T>) for more\n    /// about its usage and patterns.\n    ///\n    /// ```\n    /// use std::cell::Cell;\n    /// use actix_web::{web, App, HttpRequest, HttpResponse, Responder};\n    ///\n    /// struct MyData {\n    ///     count: std::cell::Cell<usize>,\n    /// }\n    ///\n    /// async fn handler(req: HttpRequest, counter: web::Data<MyData>) -> impl Responder {\n    ///     // note this cannot use the Data<T> extractor because it was not added with it\n    ///     let incr = *req.app_data::<usize>().unwrap();\n    ///     assert_eq!(incr, 3);\n    ///\n    ///     // update counter using other value from app data\n    ///     counter.count.set(counter.count.get() + incr);\n    ///\n    ///     HttpResponse::Ok().body(counter.count.get().to_string())\n    /// }\n    ///\n    /// let app = App::new().service(\n    ///     web::resource(\"/\")\n    ///         .app_data(3usize)\n    ///         .app_data(web::Data::new(MyData { count: Default::default() }))\n    ///         .route(web::get().to(handler))\n    /// );\n    /// ```\n    ///\n    /// # Shared Mutable State\n    /// [`HttpServer::new`](crate::HttpServer::new) accepts an application factory rather than an\n    /// application instance; the factory closure is called on each worker thread independently.\n    /// Therefore, if you want to share a data object between different workers, a shareable object\n    /// needs to be created first, outside the `HttpServer::new` closure and cloned into it.\n    /// [`Data<T>`] is an example of such a sharable object.\n    ///\n    /// ```ignore\n    /// let counter = web::Data::new(AppStateWithCounter {\n    ///     counter: Mutex::new(0),\n    /// });\n    ///\n    /// HttpServer::new(move || {\n    ///     // move counter object into the closure and clone for each worker\n    ///\n    ///     App::new()\n    ///         .app_data(counter.clone())\n    ///         .route(\"/\", web::get().to(handler))\n    /// })\n    /// ```\n    #[doc(alias = \"manage\")]\n    pub fn app_data<U: 'static>(mut self, data: U) -> Self {\n        self.extensions.insert(data);\n        self\n    }\n\n    /// Add application (root) data after wrapping in `Data<T>`.\n    ///\n    /// Deprecated in favor of [`app_data`](Self::app_data).\n    #[deprecated(since = \"4.0.0\", note = \"Use `.app_data(Data::new(val))` instead.\")]\n    pub fn data<U: 'static>(self, data: U) -> Self {\n        self.app_data(Data::new(data))\n    }\n\n    /// Add application data factory that resolves asynchronously.\n    ///\n    /// Data items are constructed during application initialization, before the server starts\n    /// accepting requests.\n    ///\n    /// The returned data value `D` is wrapped as [`Data<D>`].\n    pub fn data_factory<F, Out, D, E>(mut self, data: F) -> Self\n    where\n        F: Fn() -> Out + 'static,\n        Out: Future<Output = Result<D, E>> + 'static,\n        D: 'static,\n        E: std::fmt::Debug,\n    {\n        self.data_factories.push(Box::new(move || {\n            {\n                let fut = data();\n                async move {\n                    match fut.await {\n                        Err(err) => {\n                            log::error!(\"Can not construct data instance: {err:?}\");\n                            Err(())\n                        }\n                        Ok(data) => {\n                            let data: Box<dyn DataFactory> = Box::new(Data::new(data));\n                            Ok(data)\n                        }\n                    }\n                }\n            }\n            .boxed_local()\n        }));\n\n        self\n    }\n\n    /// Run external configuration as part of the application building\n    /// process\n    ///\n    /// This function is useful for moving parts of configuration to a\n    /// different module or even library. For example,\n    /// some of the resource's configuration could be moved to different module.\n    ///\n    /// ```\n    /// use actix_web::{web, App, HttpResponse};\n    ///\n    /// // this function could be located in different module\n    /// fn config(cfg: &mut web::ServiceConfig) {\n    ///     cfg.service(web::resource(\"/test\")\n    ///         .route(web::get().to(|| HttpResponse::Ok()))\n    ///         .route(web::head().to(|| HttpResponse::MethodNotAllowed()))\n    ///     );\n    /// }\n    ///\n    /// App::new()\n    ///     .configure(config)  // <- register resources\n    ///     .route(\"/index.html\", web::get().to(|| HttpResponse::Ok()));\n    /// ```\n    pub fn configure<F>(mut self, f: F) -> Self\n    where\n        F: FnOnce(&mut ServiceConfig),\n    {\n        let mut cfg = ServiceConfig::new();\n\n        f(&mut cfg);\n\n        self.services.extend(cfg.services);\n        self.external.extend(cfg.external);\n        self.extensions.extend(cfg.app_data);\n\n        if let Some(default) = cfg.default {\n            self.default = Some(default);\n        }\n\n        self\n    }\n\n    /// Configure route for a specific path.\n    ///\n    /// This is a simplified version of the `App::service()` method.\n    /// This method can be used multiple times with same path, in that case\n    /// multiple resources with one route would be registered for same resource path.\n    ///\n    /// ```\n    /// use actix_web::{web, App, HttpResponse};\n    ///\n    /// async fn index(data: web::Path<(String, String)>) -> &'static str {\n    ///     \"Welcome!\"\n    /// }\n    ///\n    /// let app = App::new()\n    ///     .route(\"/test1\", web::get().to(index))\n    ///     .route(\"/test2\", web::post().to(|| HttpResponse::MethodNotAllowed()));\n    /// ```\n    pub fn route(self, path: &str, mut route: Route) -> Self {\n        self.service(\n            Resource::new(path)\n                .add_guards(route.take_guards())\n                .route(route),\n        )\n    }\n\n    /// Register HTTP service.\n    ///\n    /// Http service is any type that implements `HttpServiceFactory` trait.\n    ///\n    /// Actix Web provides several services implementations:\n    ///\n    /// * *Resource* is an entry in resource table which corresponds to requested URL.\n    /// * *Scope* is a set of resources with common root path.\n    pub fn service<F>(mut self, factory: F) -> Self\n    where\n        F: HttpServiceFactory + 'static,\n    {\n        self.services\n            .push(Box::new(ServiceFactoryWrapper::new(factory)));\n        self\n    }\n\n    /// Default service that is invoked when no matching resource could be found.\n    ///\n    /// You can use a [`Route`] as default service.\n    ///\n    /// If a default service is not registered, an empty `404 Not Found` response will be sent to\n    /// the client instead.\n    ///\n    /// # Examples\n    /// ```\n    /// use actix_web::{web, App, HttpResponse};\n    ///\n    /// async fn index() -> &'static str {\n    ///     \"Welcome!\"\n    /// }\n    ///\n    /// let app = App::new()\n    ///     .service(web::resource(\"/index.html\").route(web::get().to(index)))\n    ///     .default_service(web::to(|| HttpResponse::NotFound()));\n    /// ```\n    pub fn default_service<F, U>(mut self, svc: F) -> Self\n    where\n        F: IntoServiceFactory<U, ServiceRequest>,\n        U: ServiceFactory<ServiceRequest, Config = (), Response = ServiceResponse, Error = Error>\n            + 'static,\n        U::InitError: fmt::Debug,\n    {\n        let svc = svc.into_factory().map_init_err(|err| {\n            log::error!(\"Can not construct default service: {err:?}\");\n        });\n\n        self.default = Some(Rc::new(boxed::factory(svc)));\n\n        self\n    }\n\n    /// Register an external resource.\n    ///\n    /// External resources are useful for URL generation purposes only\n    /// and are never considered for matching at request time. Calls to\n    /// `HttpRequest::url_for()` will work as expected.\n    ///\n    /// ```\n    /// use actix_web::{web, App, HttpRequest, HttpResponse, Result};\n    ///\n    /// async fn index(req: HttpRequest) -> Result<HttpResponse> {\n    ///     let url = req.url_for(\"youtube\", &[\"asdlkjqme\"])?;\n    ///     assert_eq!(url.as_str(), \"https://youtube.com/watch/asdlkjqme\");\n    ///     Ok(HttpResponse::Ok().into())\n    /// }\n    ///\n    /// let app = App::new()\n    ///     .service(web::resource(\"/index.html\").route(\n    ///         web::get().to(index)))\n    ///     .external_resource(\"youtube\", \"https://youtube.com/watch/{video_id}\");\n    /// ```\n    pub fn external_resource<N, U>(mut self, name: N, url: U) -> Self\n    where\n        N: AsRef<str>,\n        U: AsRef<str>,\n    {\n        let mut rdef = ResourceDef::new(url.as_ref());\n        rdef.set_name(name.as_ref());\n        self.external.push(rdef);\n        self\n    }\n\n    /// Registers an app-wide middleware.\n    ///\n    /// Registers middleware, in the form of a middleware component (type), that runs during\n    /// inbound and/or outbound processing in the request life-cycle (request -> response),\n    /// modifying request/response as necessary, across all requests managed by the `App`.\n    ///\n    /// Use middleware when you need to read or modify *every* request or response in some way.\n    ///\n    /// Middleware can be applied similarly to individual `Scope`s and `Resource`s.\n    /// See [`Scope::wrap`](crate::Scope::wrap) and [`Resource::wrap`].\n    ///\n    /// For more info on middleware take a look at the [`middleware` module][crate::middleware].\n    ///\n    /// # Examples\n    /// ```\n    /// use actix_web::{middleware, web, App};\n    ///\n    /// async fn index() -> &'static str {\n    ///     \"Welcome!\"\n    /// }\n    ///\n    /// let app = App::new()\n    ///     .wrap(middleware::Logger::default())\n    ///     .route(\"/index.html\", web::get().to(index));\n    /// ```\n    #[doc(alias = \"middleware\")]\n    #[doc(alias = \"use\")] // nodejs terminology\n    pub fn wrap<M, B>(\n        self,\n        mw: M,\n    ) -> App<\n        impl ServiceFactory<\n            ServiceRequest,\n            Config = (),\n            Response = ServiceResponse<B>,\n            Error = Error,\n            InitError = (),\n        >,\n    >\n    where\n        M: Transform<\n                T::Service,\n                ServiceRequest,\n                Response = ServiceResponse<B>,\n                Error = Error,\n                InitError = (),\n            > + 'static,\n        B: MessageBody,\n    {\n        App {\n            endpoint: apply(mw, self.endpoint),\n            data_factories: self.data_factories,\n            services: self.services,\n            default: self.default,\n            factory_ref: self.factory_ref,\n            external: self.external,\n            extensions: self.extensions,\n        }\n    }\n\n    /// Registers an app-wide function middleware.\n    ///\n    /// `mw` is a closure that runs during inbound and/or outbound processing in the request\n    /// life-cycle (request -> response), modifying request/response as necessary, across all\n    /// requests handled by the `App`.\n    ///\n    /// Use middleware when you need to read or modify *every* request or response in some way.\n    ///\n    /// Middleware can also be applied to individual `Scope`s and `Resource`s.\n    ///\n    /// See [`App::wrap`] for details on how middlewares compose with each other.\n    ///\n    /// # Examples\n    /// ```\n    /// use actix_web::{dev::Service as _, middleware, web, App};\n    /// use actix_web::http::header::{CONTENT_TYPE, HeaderValue};\n    ///\n    /// async fn index() -> &'static str {\n    ///     \"Welcome!\"\n    /// }\n    ///\n    /// let app = App::new()\n    ///     .wrap_fn(|req, srv| {\n    ///         let fut = srv.call(req);\n    ///         async {\n    ///             let mut res = fut.await?;\n    ///             res.headers_mut()\n    ///                 .insert(CONTENT_TYPE, HeaderValue::from_static(\"text/plain\"));\n    ///             Ok(res)\n    ///         }\n    ///     })\n    ///     .route(\"/index.html\", web::get().to(index));\n    /// ```\n    #[doc(alias = \"middleware\")]\n    #[doc(alias = \"use\")] // nodejs terminology\n    pub fn wrap_fn<F, R, B>(\n        self,\n        mw: F,\n    ) -> App<\n        impl ServiceFactory<\n            ServiceRequest,\n            Config = (),\n            Response = ServiceResponse<B>,\n            Error = Error,\n            InitError = (),\n        >,\n    >\n    where\n        F: Fn(ServiceRequest, &T::Service) -> R + Clone + 'static,\n        R: Future<Output = Result<ServiceResponse<B>, Error>>,\n        B: MessageBody,\n    {\n        App {\n            endpoint: apply_fn_factory(self.endpoint, mw),\n            data_factories: self.data_factories,\n            services: self.services,\n            default: self.default,\n            factory_ref: self.factory_ref,\n            external: self.external,\n            extensions: self.extensions,\n        }\n    }\n}\n\nimpl<T, B> IntoServiceFactory<AppInit<T, B>, Request> for App<T>\nwhere\n    T: ServiceFactory<\n            ServiceRequest,\n            Config = (),\n            Response = ServiceResponse<B>,\n            Error = Error,\n            InitError = (),\n        > + 'static,\n    B: MessageBody,\n{\n    fn into_factory(self) -> AppInit<T, B> {\n        AppInit {\n            async_data_factories: self.data_factories.into_boxed_slice().into(),\n            endpoint: self.endpoint,\n            services: Rc::new(RefCell::new(self.services)),\n            external: RefCell::new(self.external),\n            default: self.default,\n            factory_ref: self.factory_ref,\n            extensions: RefCell::new(Some(self.extensions)),\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use actix_service::Service as _;\n    use actix_utils::future::{err, ok};\n    use bytes::Bytes;\n\n    use super::*;\n    use crate::{\n        http::{\n            header::{self, HeaderValue},\n            Method, StatusCode,\n        },\n        middleware::DefaultHeaders,\n        test::{call_service, init_service, read_body, try_init_service, TestRequest},\n        web, HttpRequest, HttpResponse,\n    };\n\n    #[actix_rt::test]\n    async fn test_default_resource() {\n        let srv =\n            init_service(App::new().service(web::resource(\"/test\").to(HttpResponse::Ok))).await;\n        let req = TestRequest::with_uri(\"/test\").to_request();\n        let resp = srv.call(req).await.unwrap();\n        assert_eq!(resp.status(), StatusCode::OK);\n\n        let req = TestRequest::with_uri(\"/blah\").to_request();\n        let resp = srv.call(req).await.unwrap();\n        assert_eq!(resp.status(), StatusCode::NOT_FOUND);\n\n        let srv = init_service(\n            App::new()\n                .service(web::resource(\"/test\").to(HttpResponse::Ok))\n                .service(\n                    web::resource(\"/test2\")\n                        .default_service(|r: ServiceRequest| {\n                            ok(r.into_response(HttpResponse::Created()))\n                        })\n                        .route(web::get().to(HttpResponse::Ok)),\n                )\n                .default_service(|r: ServiceRequest| {\n                    ok(r.into_response(HttpResponse::MethodNotAllowed()))\n                }),\n        )\n        .await;\n\n        let req = TestRequest::with_uri(\"/blah\").to_request();\n        let resp = srv.call(req).await.unwrap();\n        assert_eq!(resp.status(), StatusCode::METHOD_NOT_ALLOWED);\n\n        let req = TestRequest::with_uri(\"/test2\").to_request();\n        let resp = srv.call(req).await.unwrap();\n        assert_eq!(resp.status(), StatusCode::OK);\n\n        let req = TestRequest::with_uri(\"/test2\")\n            .method(Method::POST)\n            .to_request();\n        let resp = srv.call(req).await.unwrap();\n        assert_eq!(resp.status(), StatusCode::CREATED);\n    }\n\n    // allow deprecated App::data\n    #[allow(deprecated)]\n    #[actix_rt::test]\n    async fn test_data_factory() {\n        let srv = init_service(\n            App::new()\n                .data_factory(|| ok::<_, ()>(10usize))\n                .service(web::resource(\"/\").to(|_: web::Data<usize>| HttpResponse::Ok())),\n        )\n        .await;\n        let req = TestRequest::default().to_request();\n        let resp = srv.call(req).await.unwrap();\n        assert_eq!(resp.status(), StatusCode::OK);\n\n        let srv = init_service(\n            App::new()\n                .data_factory(|| ok::<_, ()>(10u32))\n                .service(web::resource(\"/\").to(|_: web::Data<usize>| HttpResponse::Ok())),\n        )\n        .await;\n        let req = TestRequest::default().to_request();\n        let resp = srv.call(req).await.unwrap();\n        assert_eq!(resp.status(), StatusCode::INTERNAL_SERVER_ERROR);\n    }\n\n    // allow deprecated App::data\n    #[allow(deprecated)]\n    #[actix_rt::test]\n    async fn test_data_factory_errors() {\n        let srv = try_init_service(\n            App::new()\n                .data_factory(|| err::<u32, _>(()))\n                .service(web::resource(\"/\").to(|_: web::Data<usize>| HttpResponse::Ok())),\n        )\n        .await;\n\n        assert!(srv.is_err());\n    }\n\n    #[actix_rt::test]\n    async fn test_extension() {\n        let srv = init_service(App::new().app_data(10usize).service(web::resource(\"/\").to(\n            |req: HttpRequest| {\n                assert_eq!(*req.app_data::<usize>().unwrap(), 10);\n                HttpResponse::Ok()\n            },\n        )))\n        .await;\n        let req = TestRequest::default().to_request();\n        let resp = srv.call(req).await.unwrap();\n        assert_eq!(resp.status(), StatusCode::OK);\n    }\n\n    #[actix_rt::test]\n    async fn test_wrap() {\n        let srv = init_service(\n            App::new()\n                .wrap(\n                    DefaultHeaders::new()\n                        .add((header::CONTENT_TYPE, HeaderValue::from_static(\"0001\"))),\n                )\n                .route(\"/test\", web::get().to(HttpResponse::Ok)),\n        )\n        .await;\n        let req = TestRequest::with_uri(\"/test\").to_request();\n        let resp = call_service(&srv, req).await;\n        assert_eq!(resp.status(), StatusCode::OK);\n        assert_eq!(\n            resp.headers().get(header::CONTENT_TYPE).unwrap(),\n            HeaderValue::from_static(\"0001\")\n        );\n    }\n\n    #[actix_rt::test]\n    async fn test_router_wrap() {\n        let srv = init_service(\n            App::new()\n                .route(\"/test\", web::get().to(HttpResponse::Ok))\n                .wrap(\n                    DefaultHeaders::new()\n                        .add((header::CONTENT_TYPE, HeaderValue::from_static(\"0001\"))),\n                ),\n        )\n        .await;\n        let req = TestRequest::with_uri(\"/test\").to_request();\n        let resp = call_service(&srv, req).await;\n        assert_eq!(resp.status(), StatusCode::OK);\n        assert_eq!(\n            resp.headers().get(header::CONTENT_TYPE).unwrap(),\n            HeaderValue::from_static(\"0001\")\n        );\n    }\n\n    #[actix_rt::test]\n    async fn test_wrap_fn() {\n        let srv = init_service(\n            App::new()\n                .wrap_fn(|req, srv| {\n                    let fut = srv.call(req);\n                    async move {\n                        let mut res = fut.await?;\n                        res.headers_mut()\n                            .insert(header::CONTENT_TYPE, HeaderValue::from_static(\"0001\"));\n                        Ok(res)\n                    }\n                })\n                .service(web::resource(\"/test\").to(HttpResponse::Ok)),\n        )\n        .await;\n        let req = TestRequest::with_uri(\"/test\").to_request();\n        let resp = call_service(&srv, req).await;\n        assert_eq!(resp.status(), StatusCode::OK);\n        assert_eq!(\n            resp.headers().get(header::CONTENT_TYPE).unwrap(),\n            HeaderValue::from_static(\"0001\")\n        );\n    }\n\n    #[actix_rt::test]\n    async fn test_router_wrap_fn() {\n        let srv = init_service(\n            App::new()\n                .route(\"/test\", web::get().to(HttpResponse::Ok))\n                .wrap_fn(|req, srv| {\n                    let fut = srv.call(req);\n                    async {\n                        let mut res = fut.await?;\n                        res.headers_mut()\n                            .insert(header::CONTENT_TYPE, HeaderValue::from_static(\"0001\"));\n                        Ok(res)\n                    }\n                }),\n        )\n        .await;\n        let req = TestRequest::with_uri(\"/test\").to_request();\n        let resp = call_service(&srv, req).await;\n        assert_eq!(resp.status(), StatusCode::OK);\n        assert_eq!(\n            resp.headers().get(header::CONTENT_TYPE).unwrap(),\n            HeaderValue::from_static(\"0001\")\n        );\n    }\n\n    #[actix_rt::test]\n    async fn test_external_resource() {\n        let srv = init_service(\n            App::new()\n                .external_resource(\"youtube\", \"https://youtube.com/watch/{video_id}\")\n                .route(\n                    \"/test\",\n                    web::get().to(|req: HttpRequest| {\n                        HttpResponse::Ok()\n                            .body(req.url_for(\"youtube\", [\"12345\"]).unwrap().to_string())\n                    }),\n                ),\n        )\n        .await;\n        let req = TestRequest::with_uri(\"/test\").to_request();\n        let resp = call_service(&srv, req).await;\n        assert_eq!(resp.status(), StatusCode::OK);\n        let body = read_body(resp).await;\n        assert_eq!(body, Bytes::from_static(b\"https://youtube.com/watch/12345\"));\n    }\n\n    #[test]\n    fn can_be_returned_from_fn() {\n        /// compile-only test for returning app type from function\n        pub fn my_app() -> App<\n            impl ServiceFactory<\n                ServiceRequest,\n                Response = ServiceResponse<impl MessageBody>,\n                Config = (),\n                InitError = (),\n                Error = Error,\n            >,\n        > {\n            App::new()\n                // logger can be removed without affecting the return type\n                .wrap(crate::middleware::Logger::default())\n                .route(\"/\", web::to(|| async { \"hello\" }))\n        }\n\n        #[allow(clippy::let_underscore_future)]\n        let _ = init_service(my_app());\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "261cc2c970743fbde7cf6966a38e1bcae4b286ba",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/actix-web/actix-web/src/helpers.rs",
    "func": "use std::io;\n\nuse bytes::BufMut;\n\n/// An `io::Write`r that only requires mutable reference and assumes that there is space available\n/// in the buffer for every write operation or that it can be extended implicitly (like\n/// `bytes::BytesMut`, for example).\n///\n/// This is slightly faster (~10%) than `bytes::buf::Writer` in such cases because it does not\n/// perform a remaining length check before writing.\npub(crate) struct MutWriter<'a, B>(pub(crate) &'a mut B);\n\nimpl<'a, B> io::Write for MutWriter<'a, B>\nwhere\n    B: BufMut,\n{\n    fn write(&mut self, buf: &[u8]) -> io::Result<usize> {\n        self.0.put_slice(buf);\n        Ok(buf.len())\n    }\n\n    fn flush(&mut self) -> io::Result<()> {\n        Ok(())\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "a913837fc084d97c34462b7e083963de3b5202de",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/actix-web/actix-web/src/error/response_error.rs",
    "func": "//! `ResponseError` trait and foreign impls.\n\nuse std::{\n    convert::Infallible,\n    error::Error as StdError,\n    fmt,\n    io::{self, Write as _},\n};\n\nuse actix_http::Response;\nuse bytes::BytesMut;\n\nuse crate::{\n    body::BoxBody,\n    error::{downcast_dyn, downcast_get_type_id},\n    helpers,\n    http::{\n        header::{self, TryIntoHeaderValue},\n        StatusCode,\n    },\n    HttpResponse,\n};\n\n/// Errors that can generate responses.\n// TODO: flesh out documentation\npub trait ResponseError: fmt::Debug + fmt::Display {\n    /// Returns appropriate status code for error.\n    ///\n    /// A 500 Internal Server Error is used by default. If [error_response](Self::error_response) is\n    /// also implemented and does not call `self.status_code()`, then this will not be used.\n    fn status_code(&self) -> StatusCode {\n        StatusCode::INTERNAL_SERVER_ERROR\n    }\n\n    /// Creates full response for error.\n    ///\n    /// By default, the generated response uses a 500 Internal Server Error status code, a\n    /// `Content-Type` of `text/plain`, and the body is set to `Self`'s `Display` impl.\n    fn error_response(&self) -> HttpResponse<BoxBody> {\n        let mut res = HttpResponse::new(self.status_code());\n\n        let mut buf = BytesMut::new();\n        let _ = write!(helpers::MutWriter(&mut buf), \"{}\", self);\n\n        let mime = mime::TEXT_PLAIN_UTF_8.try_into_value().unwrap();\n        res.headers_mut().insert(header::CONTENT_TYPE, mime);\n\n        res.set_body(BoxBody::new(buf))\n    }\n\n    downcast_get_type_id!();\n}\n\ndowncast_dyn!(ResponseError);\n\nimpl ResponseError for Box<dyn StdError + 'static> {}\n\nimpl ResponseError for Infallible {\n    fn status_code(&self) -> StatusCode {\n        match *self {}\n    }\n    fn error_response(&self) -> HttpResponse<BoxBody> {\n        match *self {}\n    }\n}\n\n#[cfg(feature = \"openssl\")]\nimpl ResponseError for actix_tls::accept::openssl::reexports::Error {}\n\nimpl ResponseError for serde::de::value::Error {\n    fn status_code(&self) -> StatusCode {\n        StatusCode::BAD_REQUEST\n    }\n}\n\nimpl ResponseError for serde_json::Error {}\n\nimpl ResponseError for serde_urlencoded::ser::Error {}\n\nimpl ResponseError for std::str::Utf8Error {\n    fn status_code(&self) -> StatusCode {\n        StatusCode::BAD_REQUEST\n    }\n}\n\nimpl ResponseError for std::io::Error {\n    fn status_code(&self) -> StatusCode {\n        match self.kind() {\n            io::ErrorKind::NotFound => StatusCode::NOT_FOUND,\n            io::ErrorKind::PermissionDenied => StatusCode::FORBIDDEN,\n            _ => StatusCode::INTERNAL_SERVER_ERROR,\n        }\n    }\n}\n\nimpl ResponseError for actix_http::error::HttpError {}\n\nimpl ResponseError for actix_http::Error {\n    fn status_code(&self) -> StatusCode {\n        StatusCode::INTERNAL_SERVER_ERROR\n    }\n\n    fn error_response(&self) -> HttpResponse<BoxBody> {\n        HttpResponse::with_body(self.status_code(), self.to_string()).map_into_boxed_body()\n    }\n}\n\nimpl ResponseError for actix_http::header::InvalidHeaderValue {\n    fn status_code(&self) -> StatusCode {\n        StatusCode::BAD_REQUEST\n    }\n}\n\nimpl ResponseError for actix_http::error::ParseError {\n    fn status_code(&self) -> StatusCode {\n        StatusCode::BAD_REQUEST\n    }\n}\n\nimpl ResponseError for actix_http::error::PayloadError {\n    fn status_code(&self) -> StatusCode {\n        match *self {\n            actix_http::error::PayloadError::Overflow => StatusCode::PAYLOAD_TOO_LARGE,\n            _ => StatusCode::BAD_REQUEST,\n        }\n    }\n}\n\nimpl ResponseError for actix_http::ws::ProtocolError {}\n\nimpl ResponseError for actix_http::error::ContentTypeError {\n    fn status_code(&self) -> StatusCode {\n        StatusCode::BAD_REQUEST\n    }\n}\n\nimpl ResponseError for actix_http::ws::HandshakeError {\n    fn error_response(&self) -> HttpResponse<BoxBody> {\n        Response::from(self).map_into_boxed_body().into()\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_error_casting() {\n        use actix_http::error::{ContentTypeError, PayloadError};\n\n        let err = PayloadError::Overflow;\n        let resp_err: &dyn ResponseError = &err;\n\n        let err = resp_err.downcast_ref::<PayloadError>().unwrap();\n        assert_eq!(err.to_string(), \"payload reached size limit\");\n\n        let not_err = resp_err.downcast_ref::<ContentTypeError>();\n        assert!(not_err.is_none());\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "eca64ae56c711a58e44f9500c71e35fe07aae757",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/actix-web/actix-web/src/types/either.rs",
    "func": "//! For either helper, see [`Either`].\n\nuse std::{\n    future::Future,\n    mem,\n    pin::Pin,\n    task::{Context, Poll},\n};\n\nuse bytes::Bytes;\nuse futures_core::ready;\nuse pin_project_lite::pin_project;\n\nuse crate::{\n    body::EitherBody,\n    dev,\n    web::{Form, Json},\n    Error, FromRequest, HttpRequest, HttpResponse, Responder,\n};\n\n/// Combines two extractor or responder types into a single type.\n///\n/// # Extractor\n/// Provides a mechanism for trying two extractors, a primary and a fallback. Useful for\n/// \"polymorphic payloads\" where, for example, a form might be JSON or URL encoded.\n///\n/// It is important to note that this extractor, by necessity, buffers the entire request payload\n/// as part of its implementation. Though, it does respect any `PayloadConfig` maximum size limits.\n///\n/// ```\n/// use actix_web::{post, web, Either};\n/// use serde::Deserialize;\n///\n/// #[derive(Deserialize)]\n/// struct Info {\n///     name: String,\n/// }\n///\n/// // handler that accepts form as JSON or form-urlencoded.\n/// #[post(\"/\")]\n/// async fn index(form: Either<web::Json<Info>, web::Form<Info>>) -> String {\n///     let name: String = match form {\n///         Either::Left(json) => json.name.to_owned(),\n///         Either::Right(form) => form.name.to_owned(),\n///     };\n///\n///     format!(\"Welcome {}!\", name)\n/// }\n/// ```\n///\n/// # Responder\n/// It may be desirable to use a concrete type for a response with multiple branches. As long as\n/// both types implement `Responder`, so will the `Either` type, enabling it to be used as a\n/// handler's return type.\n///\n/// All properties of a response are determined by the Responder branch returned.\n///\n/// ```\n/// use actix_web::{get, Either, Error, HttpResponse};\n///\n/// #[get(\"/\")]\n/// async fn index() -> Either<&'static str, Result<HttpResponse, Error>> {\n///     if 1 == 2 {\n///         // respond with Left variant\n///         Either::Left(\"Bad data\")\n///     } else {\n///         // respond with Right variant\n///         Either::Right(\n///             Ok(HttpResponse::Ok()\n///                 .content_type(mime::TEXT_HTML)\n///                 .body(\"<p>Hello!</p>\"))\n///         )\n///     }\n/// }\n/// ```\n#[derive(Debug, PartialEq, Eq)]\npub enum Either<L, R> {\n    /// A value of type `L`.\n    Left(L),\n\n    /// A value of type `R`.\n    Right(R),\n}\n\nimpl<T> Either<Form<T>, Json<T>> {\n    pub fn into_inner(self) -> T {\n        match self {\n            Either::Left(form) => form.into_inner(),\n            Either::Right(form) => form.into_inner(),\n        }\n    }\n}\n\nimpl<T> Either<Json<T>, Form<T>> {\n    pub fn into_inner(self) -> T {\n        match self {\n            Either::Left(form) => form.into_inner(),\n            Either::Right(form) => form.into_inner(),\n        }\n    }\n}\n\n#[cfg(test)]\nimpl<L, R> Either<L, R> {\n    pub(self) fn unwrap_left(self) -> L {\n        match self {\n            Either::Left(data) => data,\n            Either::Right(_) => {\n                panic!(\"Cannot unwrap Left branch. Either contains an `R` type.\")\n            }\n        }\n    }\n\n    pub(self) fn unwrap_right(self) -> R {\n        match self {\n            Either::Left(_) => {\n                panic!(\"Cannot unwrap Right branch. Either contains an `L` type.\")\n            }\n            Either::Right(data) => data,\n        }\n    }\n}\n\n/// See [here](#responder) for example of usage as a handler return type.\nimpl<L, R> Responder for Either<L, R>\nwhere\n    L: Responder,\n    R: Responder,\n{\n    type Body = EitherBody<L::Body, R::Body>;\n\n    fn respond_to(self, req: &HttpRequest) -> HttpResponse<Self::Body> {\n        match self {\n            Either::Left(a) => a.respond_to(req).map_into_left_body(),\n            Either::Right(b) => b.respond_to(req).map_into_right_body(),\n        }\n    }\n}\n\n/// A composite error resulting from failure to extract an `Either<L, R>`.\n///\n/// The implementation of `Into<actix_web::Error>` will return the payload buffering error or the\n/// error from the primary extractor. To access the fallback error, use a match clause.\n#[derive(Debug)]\npub enum EitherExtractError<L, R> {\n    /// Error from payload buffering, such as exceeding payload max size limit.\n    Bytes(Error),\n\n    /// Error from primary and fallback extractors.\n    Extract(L, R),\n}\n\nimpl<L, R> From<EitherExtractError<L, R>> for Error\nwhere\n    L: Into<Error>,\n    R: Into<Error>,\n{\n    fn from(err: EitherExtractError<L, R>) -> Error {\n        match err {\n            EitherExtractError::Bytes(err) => err,\n            EitherExtractError::Extract(a_err, _b_err) => a_err.into(),\n        }\n    }\n}\n\n/// See [here](#extractor) for example of usage as an extractor.\nimpl<L, R> FromRequest for Either<L, R>\nwhere\n    L: FromRequest + 'static,\n    R: FromRequest + 'static,\n{\n    type Error = EitherExtractError<L::Error, R::Error>;\n    type Future = EitherExtractFut<L, R>;\n\n    fn from_request(req: &HttpRequest, payload: &mut dev::Payload) -> Self::Future {\n        EitherExtractFut {\n            req: req.clone(),\n            state: EitherExtractState::Bytes {\n                bytes: Bytes::from_request(req, payload),\n            },\n        }\n    }\n}\n\npin_project! {\n    pub struct EitherExtractFut<L, R>\n    where\n        R: FromRequest,\n        L: FromRequest,\n    {\n        req: HttpRequest,\n        #[pin]\n        state: EitherExtractState<L, R>,\n    }\n}\n\npin_project! {\n    #[project = EitherExtractProj]\n    pub enum EitherExtractState<L, R>\n    where\n        L: FromRequest,\n        R: FromRequest,\n    {\n        Bytes {\n            #[pin]\n            bytes: <Bytes as FromRequest>::Future,\n        },\n        Left {\n            #[pin]\n            left: L::Future,\n            fallback: Bytes,\n        },\n        Right {\n            #[pin]\n            right: R::Future,\n            left_err: Option<L::Error>,\n        },\n    }\n}\n\nimpl<R, RF, RE, L, LF, LE> Future for EitherExtractFut<L, R>\nwhere\n    L: FromRequest<Future = LF, Error = LE>,\n    R: FromRequest<Future = RF, Error = RE>,\n    LF: Future<Output = Result<L, LE>> + 'static,\n    RF: Future<Output = Result<R, RE>> + 'static,\n    LE: Into<Error>,\n    RE: Into<Error>,\n{\n    type Output = Result<Either<L, R>, EitherExtractError<LE, RE>>;\n\n    fn poll(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> {\n        let mut this = self.project();\n        let ready = loop {\n            let next = match this.state.as_mut().project() {\n                EitherExtractProj::Bytes { bytes } => {\n                    let res = ready!(bytes.poll(cx));\n                    match res {\n                        Ok(bytes) => {\n                            let fallback = bytes.clone();\n                            let left = L::from_request(this.req, &mut payload_from_bytes(bytes));\n                            EitherExtractState::Left { left, fallback }\n                        }\n                        Err(err) => break Err(EitherExtractError::Bytes(err)),\n                    }\n                }\n                EitherExtractProj::Left { left, fallback } => {\n                    let res = ready!(left.poll(cx));\n                    match res {\n                        Ok(extracted) => break Ok(Either::Left(extracted)),\n                        Err(left_err) => {\n                            let right = R::from_request(\n                                this.req,\n                                &mut payload_from_bytes(mem::take(fallback)),\n                            );\n                            EitherExtractState::Right {\n                                left_err: Some(left_err),\n                                right,\n                            }\n                        }\n                    }\n                }\n                EitherExtractProj::Right { right, left_err } => {\n                    let res = ready!(right.poll(cx));\n                    match res {\n                        Ok(data) => break Ok(Either::Right(data)),\n                        Err(err) => {\n                            break Err(EitherExtractError::Extract(left_err.take().unwrap(), err));\n                        }\n                    }\n                }\n            };\n            this.state.set(next);\n        };\n        Poll::Ready(ready)\n    }\n}\n\nfn payload_from_bytes(bytes: Bytes) -> dev::Payload {\n    let (_, mut h1_payload) = actix_http::h1::Payload::create(true);\n    h1_payload.unread_data(bytes);\n    dev::Payload::from(h1_payload)\n}\n\n#[cfg(test)]\nmod tests {\n    use serde::{Deserialize, Serialize};\n\n    use super::*;\n    use crate::test::TestRequest;\n\n    #[derive(Debug, Clone, Serialize, Deserialize)]\n    struct TestForm {\n        hello: String,\n    }\n\n    #[actix_rt::test]\n    async fn test_either_extract_first_try() {\n        let (req, mut pl) = TestRequest::default()\n            .set_form(TestForm {\n                hello: \"world\".to_owned(),\n            })\n            .to_http_parts();\n\n        let form = Either::<Form<TestForm>, Json<TestForm>>::from_request(&req, &mut pl)\n            .await\n            .unwrap()\n            .unwrap_left()\n            .into_inner();\n        assert_eq!(&form.hello, \"world\");\n    }\n\n    #[actix_rt::test]\n    async fn test_either_extract_fallback() {\n        let (req, mut pl) = TestRequest::default()\n            .set_json(TestForm {\n                hello: \"world\".to_owned(),\n            })\n            .to_http_parts();\n\n        let form = Either::<Form<TestForm>, Json<TestForm>>::from_request(&req, &mut pl)\n            .await\n            .unwrap()\n            .unwrap_right()\n            .into_inner();\n        assert_eq!(&form.hello, \"world\");\n    }\n\n    #[actix_rt::test]\n    async fn test_either_extract_recursive_fallback() {\n        let (req, mut pl) = TestRequest::default()\n            .set_payload(Bytes::from_static(b\"!@$%^&*()\"))\n            .to_http_parts();\n\n        let payload =\n            Either::<Either<Form<TestForm>, Json<TestForm>>, Bytes>::from_request(&req, &mut pl)\n                .await\n                .unwrap()\n                .unwrap_right();\n        assert_eq!(&payload.as_ref(), &b\"!@$%^&*()\");\n    }\n\n    #[actix_rt::test]\n    async fn test_either_extract_recursive_fallback_inner() {\n        let (req, mut pl) = TestRequest::default()\n            .set_json(TestForm {\n                hello: \"world\".to_owned(),\n            })\n            .to_http_parts();\n\n        let form =\n            Either::<Either<Form<TestForm>, Json<TestForm>>, Bytes>::from_request(&req, &mut pl)\n                .await\n                .unwrap()\n                .unwrap_left()\n                .unwrap_right()\n                .into_inner();\n        assert_eq!(&form.hello, \"world\");\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "74d0b6f87ea07eed9ef7f6a31bc35e9910b65cf9",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/actix-web/actix-web/src/http/header/accept.rs",
    "func": "use std::cmp::Ordering;\n\nuse mime::Mime;\n\nuse super::{common_header, QualityItem};\nuse crate::http::header;\n\ncommon_header! {\n    /// `Accept` header, defined in [RFC 7231 \u00a75.3.2].\n    ///\n    /// The `Accept` header field can be used by user agents to specify\n    /// response media types that are acceptable. Accept header fields can\n    /// be used to indicate that the request is specifically limited to a\n    /// small set of desired types, as in the case of a request for an\n    /// in-line image\n    ///\n    /// # ABNF\n    /// ```plain\n    /// Accept = #( media-range [ accept-params ] )\n    ///\n    /// media-range    = ( \"*/*\"\n    ///                  / ( type \"/\" \"*\" )\n    ///                  / ( type \"/\" subtype )\n    ///                  ) *( OWS \";\" OWS parameter )\n    /// accept-params  = weight *( accept-ext )\n    /// accept-ext = OWS \";\" OWS token [ \"=\" ( token / quoted-string ) ]\n    /// ```\n    ///\n    /// # Example Values\n    /// * `audio/*; q=0.2, audio/basic`\n    /// * `text/plain; q=0.5, text/html, text/x-dvi; q=0.8, text/x-c`\n    ///\n    /// # Examples\n    /// ```\n    /// use actix_web::HttpResponse;\n    /// use actix_web::http::header::{Accept, QualityItem};\n    ///\n    /// let mut builder = HttpResponse::Ok();\n    /// builder.insert_header(\n    ///     Accept(vec![\n    ///         QualityItem::max(mime::TEXT_HTML),\n    ///     ])\n    /// );\n    /// ```\n    ///\n    /// ```\n    /// use actix_web::HttpResponse;\n    /// use actix_web::http::header::{Accept, QualityItem};\n    ///\n    /// let mut builder = HttpResponse::Ok();\n    /// builder.insert_header(\n    ///     Accept(vec![\n    ///         QualityItem::max(mime::APPLICATION_JSON),\n    ///     ])\n    /// );\n    /// ```\n    ///\n    /// ```\n    /// use actix_web::HttpResponse;\n    /// use actix_web::http::header::{Accept, QualityItem, q};\n    ///\n    /// let mut builder = HttpResponse::Ok();\n    /// builder.insert_header(\n    ///     Accept(vec![\n    ///         QualityItem::max(mime::TEXT_HTML),\n    ///         QualityItem::max(\"application/xhtml+xml\".parse().unwrap()),\n    ///         QualityItem::new(mime::TEXT_XML, q(0.9)),\n    ///         QualityItem::max(\"image/webp\".parse().unwrap()),\n    ///         QualityItem::new(mime::STAR_STAR, q(0.8)),\n    ///     ])\n    /// );\n    /// ```\n    ///\n    /// [RFC 7231 \u00a75.3.2]: https://datatracker.ietf.org/doc/html/rfc7231#section-5.3.2\n    (Accept, header::ACCEPT) => (QualityItem<Mime>)*\n\n    test_parse_and_format {\n        // Tests from the RFC\n         crate::http::header::common_header_test!(\n            test1,\n            [b\"audio/*; q=0.2, audio/basic\"],\n            Some(Accept(vec![\n                QualityItem::new(\"audio/*\".parse().unwrap(), q(0.2)),\n                QualityItem::max(\"audio/basic\".parse().unwrap()),\n                ])));\n\n        crate::http::header::common_header_test!(\n            test2,\n            [b\"text/plain; q=0.5, text/html, text/x-dvi; q=0.8, text/x-c\"],\n            Some(Accept(vec![\n                QualityItem::new(mime::TEXT_PLAIN, q(0.5)),\n                QualityItem::max(mime::TEXT_HTML),\n                QualityItem::new(\n                    \"text/x-dvi\".parse().unwrap(),\n                    q(0.8)),\n                QualityItem::max(\"text/x-c\".parse().unwrap()),\n                ])));\n\n        // Custom tests\n        crate::http::header::common_header_test!(\n            test3,\n            [b\"text/plain; charset=utf-8\"],\n            Some(Accept(vec![\n                QualityItem::max(mime::TEXT_PLAIN_UTF_8),\n            ])));\n        crate::http::header::common_header_test!(\n            test4,\n            [b\"text/plain; charset=utf-8; q=0.5\"],\n            Some(Accept(vec![\n                QualityItem::new(mime::TEXT_PLAIN_UTF_8, q(0.5)),\n            ])));\n\n        #[test]\n        fn test_fuzzing1() {\n            let req = test::TestRequest::default()\n                .insert_header((header::ACCEPT, \"chunk#;e\"))\n                .finish();\n            let header = Accept::parse(&req);\n            assert!(header.is_ok());\n        }\n    }\n}\n\nimpl Accept {\n    /// Construct `Accept: */*`.\n    pub fn star() -> Accept {\n        Accept(vec![QualityItem::max(mime::STAR_STAR)])\n    }\n\n    /// Construct `Accept: application/json`.\n    pub fn json() -> Accept {\n        Accept(vec![QualityItem::max(mime::APPLICATION_JSON)])\n    }\n\n    /// Construct `Accept: text/*`.\n    pub fn text() -> Accept {\n        Accept(vec![QualityItem::max(mime::TEXT_STAR)])\n    }\n\n    /// Construct `Accept: image/*`.\n    pub fn image() -> Accept {\n        Accept(vec![QualityItem::max(mime::IMAGE_STAR)])\n    }\n\n    /// Construct `Accept: text/html`.\n    pub fn html() -> Accept {\n        Accept(vec![QualityItem::max(mime::TEXT_HTML)])\n    }\n\n    // TODO: method for getting best content encoding based on q-factors, available from server side\n    // and if none are acceptable return None\n\n    /// Extracts the most preferable mime type, accounting for [q-factor weighting].\n    ///\n    /// If no q-factors are provided, the first mime type is chosen. Note that items without\n    /// q-factors are given the maximum preference value.\n    ///\n    /// As per the spec, will return [`mime::STAR_STAR`] (indicating no preference) if the contained\n    /// list is empty.\n    ///\n    /// [q-factor weighting]: https://datatracker.ietf.org/doc/html/rfc7231#section-5.3.2\n    pub fn preference(&self) -> Mime {\n        use actix_http::header::Quality;\n\n        let mut max_item = None;\n        let mut max_pref = Quality::ZERO;\n\n        // uses manual max lookup loop since we want the first occurrence in the case of same\n        // preference but `Iterator::max_by_key` would give us the last occurrence\n\n        for pref in &self.0 {\n            // only change if strictly greater\n            // equal items, even while unsorted, still have higher preference if they appear first\n            if pref.quality > max_pref {\n                max_pref = pref.quality;\n                max_item = Some(pref.item.clone());\n            }\n        }\n\n        max_item.unwrap_or(mime::STAR_STAR)\n    }\n\n    /// Returns a sorted list of mime types from highest to lowest preference, accounting for\n    /// [q-factor weighting] and specificity.\n    ///\n    /// [q-factor weighting]: https://datatracker.ietf.org/doc/html/rfc7231#section-5.3.2\n    pub fn ranked(&self) -> Vec<Mime> {\n        if self.is_empty() {\n            return vec![];\n        }\n\n        let mut types = self.0.clone();\n\n        // use stable sort so items with equal q-factor and specificity retain listed order\n        types.sort_by(|a, b| {\n            // sort by q-factor descending\n            b.quality.cmp(&a.quality).then_with(|| {\n                // use specificity rules on mime types with\n                // same q-factor (eg. text/html > text/* > */*)\n\n                // subtypes are not comparable if main type is star, so return\n                match (a.item.type_(), b.item.type_()) {\n                    (mime::STAR, mime::STAR) => return Ordering::Equal,\n\n                    // a is sorted after b\n                    (mime::STAR, _) => return Ordering::Greater,\n\n                    // a is sorted before b\n                    (_, mime::STAR) => return Ordering::Less,\n\n                    _ => {}\n                }\n\n                // in both these match expressions, the returned ordering appears\n                // inverted because sort is high-to-low (\"descending\") precedence\n                match (a.item.subtype(), b.item.subtype()) {\n                    (mime::STAR, mime::STAR) => Ordering::Equal,\n\n                    // a is sorted after b\n                    (mime::STAR, _) => Ordering::Greater,\n\n                    // a is sorted before b\n                    (_, mime::STAR) => Ordering::Less,\n\n                    _ => Ordering::Equal,\n                }\n            })\n        });\n\n        types.into_iter().map(|qitem| qitem.item).collect()\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::http::header::q;\n\n    #[test]\n    fn ranking_precedence() {\n        let test = Accept(vec![]);\n        assert!(test.ranked().is_empty());\n\n        let test = Accept(vec![QualityItem::max(mime::APPLICATION_JSON)]);\n        assert_eq!(test.ranked(), vec![mime::APPLICATION_JSON]);\n\n        let test = Accept(vec![\n            QualityItem::max(mime::TEXT_HTML),\n            \"application/xhtml+xml\".parse().unwrap(),\n            QualityItem::new(\"application/xml\".parse().unwrap(), q(0.9)),\n            QualityItem::new(mime::STAR_STAR, q(0.8)),\n        ]);\n        assert_eq!(\n            test.ranked(),\n            vec![\n                mime::TEXT_HTML,\n                \"application/xhtml+xml\".parse().unwrap(),\n                \"application/xml\".parse().unwrap(),\n                mime::STAR_STAR,\n            ]\n        );\n\n        let test = Accept(vec![\n            QualityItem::max(mime::STAR_STAR),\n            QualityItem::max(mime::IMAGE_STAR),\n            QualityItem::max(mime::IMAGE_PNG),\n        ]);\n        assert_eq!(\n            test.ranked(),\n            vec![mime::IMAGE_PNG, mime::IMAGE_STAR, mime::STAR_STAR]\n        );\n    }\n\n    #[test]\n    fn preference_selection() {\n        let test = Accept(vec![\n            QualityItem::max(mime::TEXT_HTML),\n            \"application/xhtml+xml\".parse().unwrap(),\n            QualityItem::new(\"application/xml\".parse().unwrap(), q(0.9)),\n            QualityItem::new(mime::STAR_STAR, q(0.8)),\n        ]);\n        assert_eq!(test.preference(), mime::TEXT_HTML);\n\n        let test = Accept(vec![\n            QualityItem::new(\"video/*\".parse().unwrap(), q(0.8)),\n            QualityItem::max(mime::IMAGE_PNG),\n            QualityItem::new(mime::STAR_STAR, q(0.5)),\n            QualityItem::max(mime::IMAGE_SVG),\n            QualityItem::new(mime::IMAGE_STAR, q(0.8)),\n        ]);\n        assert_eq!(test.preference(), mime::IMAGE_PNG);\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "28a9e9dbd69a1139cf87b69d4b63a380d976b4ff",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/actix-web/actix-web/src/http/header/cache_control.rs",
    "func": "use std::{fmt, str};\n\nuse super::common_header;\nuse crate::http::header;\n\ncommon_header! {\n    /// `Cache-Control` header, defined\n    /// in [RFC 7234 \u00a75.2](https://datatracker.ietf.org/doc/html/rfc7234#section-5.2).\n    ///\n    /// The `Cache-Control` header field is used to specify directives for\n    /// caches along the request/response chain.  Such cache directives are\n    /// unidirectional in that the presence of a directive in a request does\n    /// not imply that the same directive is to be given in the response.\n    ///\n    /// # ABNF\n    /// ```text\n    /// Cache-Control   = 1#cache-directive\n    /// cache-directive = token [ \"=\" ( token / quoted-string ) ]\n    /// ```\n    ///\n    /// # Example Values\n    /// * `no-cache`\n    /// * `private, community=\"UCI\"`\n    /// * `max-age=30`\n    ///\n    /// # Examples\n    /// ```\n    /// use actix_web::HttpResponse;\n    /// use actix_web::http::header::{CacheControl, CacheDirective};\n    ///\n    /// let mut builder = HttpResponse::Ok();\n    /// builder.insert_header(CacheControl(vec![CacheDirective::MaxAge(86400u32)]));\n    /// ```\n    ///\n    /// ```\n    /// use actix_web::HttpResponse;\n    /// use actix_web::http::header::{CacheControl, CacheDirective};\n    ///\n    /// let mut builder = HttpResponse::Ok();\n    /// builder.insert_header(CacheControl(vec![\n    ///     CacheDirective::NoCache,\n    ///     CacheDirective::Private,\n    ///     CacheDirective::MaxAge(360u32),\n    ///     CacheDirective::Extension(\"foo\".to_owned(), Some(\"bar\".to_owned())),\n    /// ]));\n    /// ```\n    (CacheControl, header::CACHE_CONTROL) => (CacheDirective)+\n\n    test_parse_and_format {\n        common_header_test!(no_headers, [b\"\"; 0], None);\n        common_header_test!(empty_header, [b\"\"; 1], None);\n        common_header_test!(bad_syntax, [b\"foo=\"], None);\n\n        common_header_test!(\n            multiple_headers,\n            [&b\"no-cache\"[..], &b\"private\"[..]],\n            Some(CacheControl(vec![\n                CacheDirective::NoCache,\n                CacheDirective::Private,\n            ]))\n        );\n\n        common_header_test!(\n            argument,\n            [b\"max-age=100, private\"],\n            Some(CacheControl(vec![\n                CacheDirective::MaxAge(100),\n                CacheDirective::Private,\n            ]))\n        );\n\n        common_header_test!(\n            extension,\n            [b\"foo, bar=baz\"],\n            Some(CacheControl(vec![\n                CacheDirective::Extension(\"foo\".to_owned(), None),\n                CacheDirective::Extension(\"bar\".to_owned(), Some(\"baz\".to_owned())),\n            ]))\n        );\n\n        #[test]\n        fn parse_quote_form() {\n            let req = test::TestRequest::default()\n                .insert_header((header::CACHE_CONTROL, \"max-age=\\\"200\\\"\"))\n                .finish();\n\n            assert_eq!(\n                Header::parse(&req).ok(),\n                Some(CacheControl(vec![CacheDirective::MaxAge(200)]))\n            )\n        }\n    }\n}\n\n/// `CacheControl` contains a list of these directives.\n#[derive(Debug, Clone, PartialEq, Eq)]\npub enum CacheDirective {\n    /// \"no-cache\"\n    NoCache,\n    /// \"no-store\"\n    NoStore,\n    /// \"no-transform\"\n    NoTransform,\n    /// \"only-if-cached\"\n    OnlyIfCached,\n\n    // request directives\n    /// \"max-age=delta\"\n    MaxAge(u32),\n    /// \"max-stale=delta\"\n    MaxStale(u32),\n    /// \"min-fresh=delta\"\n    MinFresh(u32),\n\n    // response directives\n    /// \"must-revalidate\"\n    MustRevalidate,\n    /// \"public\"\n    Public,\n    /// \"private\"\n    Private,\n    /// \"proxy-revalidate\"\n    ProxyRevalidate,\n    /// \"s-maxage=delta\"\n    SMaxAge(u32),\n\n    /// Extension directives. Optionally include an argument.\n    Extension(String, Option<String>),\n}\n\nimpl fmt::Display for CacheDirective {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        use self::CacheDirective::*;\n\n        let dir_str = match self {\n            NoCache => \"no-cache\",\n            NoStore => \"no-store\",\n            NoTransform => \"no-transform\",\n            OnlyIfCached => \"only-if-cached\",\n\n            MaxAge(secs) => return write!(f, \"max-age={}\", secs),\n            MaxStale(secs) => return write!(f, \"max-stale={}\", secs),\n            MinFresh(secs) => return write!(f, \"min-fresh={}\", secs),\n\n            MustRevalidate => \"must-revalidate\",\n            Public => \"public\",\n            Private => \"private\",\n            ProxyRevalidate => \"proxy-revalidate\",\n            SMaxAge(secs) => return write!(f, \"s-maxage={}\", secs),\n\n            Extension(name, None) => name.as_str(),\n            Extension(name, Some(arg)) => return write!(f, \"{}={}\", name, arg),\n        };\n\n        f.write_str(dir_str)\n    }\n}\n\nimpl str::FromStr for CacheDirective {\n    type Err = Option<<u32 as str::FromStr>::Err>;\n\n    fn from_str(s: &str) -> Result<Self, Self::Err> {\n        use self::CacheDirective::*;\n\n        match s {\n            \"\" => Err(None),\n\n            \"no-cache\" => Ok(NoCache),\n            \"no-store\" => Ok(NoStore),\n            \"no-transform\" => Ok(NoTransform),\n            \"only-if-cached\" => Ok(OnlyIfCached),\n            \"must-revalidate\" => Ok(MustRevalidate),\n            \"public\" => Ok(Public),\n            \"private\" => Ok(Private),\n            \"proxy-revalidate\" => Ok(ProxyRevalidate),\n\n            _ => match s.find('=') {\n                Some(idx) if idx + 1 < s.len() => {\n                    match (&s[..idx], s[idx + 1..].trim_matches('\"')) {\n                        (\"max-age\", secs) => secs.parse().map(MaxAge).map_err(Some),\n                        (\"max-stale\", secs) => secs.parse().map(MaxStale).map_err(Some),\n                        (\"min-fresh\", secs) => secs.parse().map(MinFresh).map_err(Some),\n                        (\"s-maxage\", secs) => secs.parse().map(SMaxAge).map_err(Some),\n                        (left, right) => Ok(Extension(left.to_owned(), Some(right.to_owned()))),\n                    }\n                }\n                Some(_) => Err(None),\n                None => Ok(Extension(s.to_owned(), None)),\n            },\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "5ffa2610af675a4055c4a2353e9f670ceac73d4a",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/actix-web/actix-web/src/middleware/compress.rs",
    "func": "//! For middleware documentation, see [`Compress`].\n\nuse std::{\n    future::Future,\n    marker::PhantomData,\n    pin::Pin,\n    task::{Context, Poll},\n};\n\nuse actix_http::encoding::Encoder;\nuse actix_service::{Service, Transform};\nuse actix_utils::future::{ok, Either, Ready};\nuse futures_core::ready;\nuse mime::Mime;\nuse once_cell::sync::Lazy;\nuse pin_project_lite::pin_project;\n\nuse crate::{\n    body::{EitherBody, MessageBody},\n    http::{\n        header::{self, AcceptEncoding, ContentEncoding, Encoding, HeaderValue},\n        StatusCode,\n    },\n    service::{ServiceRequest, ServiceResponse},\n    Error, HttpMessage, HttpResponse,\n};\n\n/// Middleware for compressing response payloads.\n///\n/// # Encoding Negotiation\n/// `Compress` will read the `Accept-Encoding` header to negotiate which compression codec to use.\n/// Payloads are not compressed if the header is not sent. The `compress-*` [feature flags] are also\n/// considered in this selection process.\n///\n/// # Pre-compressed Payload\n/// If you are serving some data that is already using a compressed representation (e.g., a gzip\n/// compressed HTML file from disk) you can signal this to `Compress` by setting an appropriate\n/// `Content-Encoding` header. In addition to preventing double compressing the payload, this header\n/// is required by the spec when using compressed representations and will inform the client that\n/// the content should be uncompressed.\n///\n/// However, it is not advised to unconditionally serve encoded representations of content because\n/// the client may not support it. The [`AcceptEncoding`] typed header has some utilities to help\n/// perform manual encoding negotiation, if required. When negotiating content encoding, it is also\n/// required by the spec to send a `Vary: Accept-Encoding` header.\n///\n/// A (na\u00efve) example serving an pre-compressed Gzip file is included below.\n///\n/// # Examples\n/// To enable automatic payload compression just include `Compress` as a top-level middleware:\n/// ```\n/// use actix_web::{middleware, web, App, HttpResponse};\n///\n/// let app = App::new()\n///     .wrap(middleware::Compress::default())\n///     .default_service(web::to(|| async { HttpResponse::Ok().body(\"hello world\") }));\n/// ```\n///\n/// Pre-compressed Gzip file being served from disk with correct headers added to bypass middleware:\n/// ```no_run\n/// use actix_web::{middleware, http::header, web, App, HttpResponse, Responder};\n///\n/// async fn index_handler() -> actix_web::Result<impl Responder> {\n///     Ok(actix_files::NamedFile::open_async(\"./assets/index.html.gz\").await?\n///         .customize()\n///         .insert_header(header::ContentEncoding::Gzip))\n/// }\n///\n/// let app = App::new()\n///     .wrap(middleware::Compress::default())\n///     .default_service(web::to(index_handler));\n/// ```\n///\n/// [feature flags]: ../index.html#crate-features\n#[derive(Debug, Clone, Default)]\n#[non_exhaustive]\npub struct Compress;\n\nimpl<S, B> Transform<S, ServiceRequest> for Compress\nwhere\n    B: MessageBody,\n    S: Service<ServiceRequest, Response = ServiceResponse<B>, Error = Error>,\n{\n    type Response = ServiceResponse<EitherBody<Encoder<B>>>;\n    type Error = Error;\n    type Transform = CompressMiddleware<S>;\n    type InitError = ();\n    type Future = Ready<Result<Self::Transform, Self::InitError>>;\n\n    fn new_transform(&self, service: S) -> Self::Future {\n        ok(CompressMiddleware { service })\n    }\n}\n\npub struct CompressMiddleware<S> {\n    service: S,\n}\n\nimpl<S, B> Service<ServiceRequest> for CompressMiddleware<S>\nwhere\n    S: Service<ServiceRequest, Response = ServiceResponse<B>, Error = Error>,\n    B: MessageBody,\n{\n    type Response = ServiceResponse<EitherBody<Encoder<B>>>;\n    type Error = Error;\n    #[allow(clippy::type_complexity)]\n    type Future = Either<CompressResponse<S, B>, Ready<Result<Self::Response, Self::Error>>>;\n\n    actix_service::forward_ready!(service);\n\n    #[allow(clippy::borrow_interior_mutable_const)]\n    fn call(&self, req: ServiceRequest) -> Self::Future {\n        // negotiate content-encoding\n        let accept_encoding = req.get_header::<AcceptEncoding>();\n\n        let accept_encoding = match accept_encoding {\n            // missing header; fallback to identity\n            None => {\n                return Either::left(CompressResponse {\n                    encoding: Encoding::identity(),\n                    fut: self.service.call(req),\n                    _phantom: PhantomData,\n                })\n            }\n\n            // valid accept-encoding header\n            Some(accept_encoding) => accept_encoding,\n        };\n\n        match accept_encoding.negotiate(SUPPORTED_ENCODINGS.iter()) {\n            None => {\n                let mut res = HttpResponse::with_body(\n                    StatusCode::NOT_ACCEPTABLE,\n                    SUPPORTED_ENCODINGS_STRING.as_str(),\n                );\n\n                res.headers_mut()\n                    .insert(header::VARY, HeaderValue::from_static(\"Accept-Encoding\"));\n\n                Either::right(ok(req\n                    .into_response(res)\n                    .map_into_boxed_body()\n                    .map_into_right_body()))\n            }\n\n            Some(encoding) => Either::left(CompressResponse {\n                fut: self.service.call(req),\n                encoding,\n                _phantom: PhantomData,\n            }),\n        }\n    }\n}\n\npin_project! {\n    pub struct CompressResponse<S, B>\n    where\n        S: Service<ServiceRequest>,\n    {\n        #[pin]\n        fut: S::Future,\n        encoding: Encoding,\n        _phantom: PhantomData<B>,\n    }\n}\n\nimpl<S, B> Future for CompressResponse<S, B>\nwhere\n    B: MessageBody,\n    S: Service<ServiceRequest, Response = ServiceResponse<B>, Error = Error>,\n{\n    type Output = Result<ServiceResponse<EitherBody<Encoder<B>>>, Error>;\n\n    fn poll(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> {\n        let this = self.as_mut().project();\n\n        match ready!(this.fut.poll(cx)) {\n            Ok(resp) => {\n                let enc = match this.encoding {\n                    Encoding::Known(enc) => *enc,\n                    Encoding::Unknown(enc) => {\n                        unimplemented!(\"encoding '{enc}' should not be here\");\n                    }\n                };\n\n                Poll::Ready(Ok(resp.map_body(move |head, body| {\n                    let content_type = head.headers.get(header::CONTENT_TYPE);\n\n                    fn default_compress_predicate(content_type: Option<&HeaderValue>) -> bool {\n                        match content_type {\n                            None => true,\n                            Some(hdr) => {\n                                match hdr.to_str().ok().and_then(|hdr| hdr.parse::<Mime>().ok()) {\n                                    Some(mime) if mime.type_().as_str() == \"image\" => false,\n                                    Some(mime) if mime.type_().as_str() == \"video\" => false,\n                                    _ => true,\n                                }\n                            }\n                        }\n                    }\n\n                    let enc = if default_compress_predicate(content_type) {\n                        enc\n                    } else {\n                        ContentEncoding::Identity\n                    };\n\n                    EitherBody::left(Encoder::response(enc, head, body))\n                })))\n            }\n\n            Err(err) => Poll::Ready(Err(err)),\n        }\n    }\n}\n\nstatic SUPPORTED_ENCODINGS_STRING: Lazy<String> = Lazy::new(|| {\n    #[allow(unused_mut)] // only unused when no compress features enabled\n    let mut encoding: Vec<&str> = vec![];\n\n    #[cfg(feature = \"compress-brotli\")]\n    {\n        encoding.push(\"br\");\n    }\n\n    #[cfg(feature = \"compress-gzip\")]\n    {\n        encoding.push(\"gzip\");\n        encoding.push(\"deflate\");\n    }\n\n    #[cfg(feature = \"compress-zstd\")]\n    {\n        encoding.push(\"zstd\");\n    }\n\n    assert!(\n        !encoding.is_empty(),\n        \"encoding can not be empty unless __compress feature has been explicitly enabled by itself\"\n    );\n\n    encoding.join(\", \")\n});\n\nstatic SUPPORTED_ENCODINGS: &[Encoding] = &[\n    Encoding::identity(),\n    #[cfg(feature = \"compress-brotli\")]\n    {\n        Encoding::brotli()\n    },\n    #[cfg(feature = \"compress-gzip\")]\n    {\n        Encoding::gzip()\n    },\n    #[cfg(feature = \"compress-gzip\")]\n    {\n        Encoding::deflate()\n    },\n    #[cfg(feature = \"compress-zstd\")]\n    {\n        Encoding::zstd()\n    },\n];\n\n// move cfg(feature) to prevents_double_compressing if more tests are added\n#[cfg(feature = \"compress-gzip\")]\n#[cfg(test)]\nmod tests {\n    use std::collections::HashSet;\n\n    use static_assertions::assert_impl_all;\n\n    use super::*;\n    use crate::{http::header::ContentType, middleware::DefaultHeaders, test, web, App};\n\n    const HTML_DATA_PART: &str = \"<html><h1>hello world</h1></html\";\n    const HTML_DATA: &str = const_str::repeat!(HTML_DATA_PART, 100);\n\n    const TEXT_DATA_PART: &str = \"hello world \";\n    const TEXT_DATA: &str = const_str::repeat!(TEXT_DATA_PART, 100);\n\n    assert_impl_all!(Compress: Send, Sync);\n\n    pub fn gzip_decode(bytes: impl AsRef<[u8]>) -> Vec<u8> {\n        use std::io::Read as _;\n        let mut decoder = flate2::read::GzDecoder::new(bytes.as_ref());\n        let mut buf = Vec::new();\n        decoder.read_to_end(&mut buf).unwrap();\n        buf\n    }\n\n    #[track_caller]\n    fn assert_successful_res_with_content_type<B>(res: &ServiceResponse<B>, ct: &str) {\n        assert!(res.status().is_success());\n        assert!(\n            res.headers()\n                .get(header::CONTENT_TYPE)\n                .expect(\"content-type header should be present\")\n                .to_str()\n                .expect(\"content-type header should be utf-8\")\n                .contains(ct),\n            \"response's content-type did not match {}\",\n            ct\n        );\n    }\n\n    #[track_caller]\n    fn assert_successful_gzip_res_with_content_type<B>(res: &ServiceResponse<B>, ct: &str) {\n        assert_successful_res_with_content_type(res, ct);\n        assert_eq!(\n            res.headers()\n                .get(header::CONTENT_ENCODING)\n                .expect(\"response should be gzip compressed\"),\n            \"gzip\",\n        );\n    }\n\n    #[track_caller]\n    fn assert_successful_identity_res_with_content_type<B>(res: &ServiceResponse<B>, ct: &str) {\n        assert_successful_res_with_content_type(res, ct);\n        assert!(\n            res.headers().get(header::CONTENT_ENCODING).is_none(),\n            \"response should not be compressed\",\n        );\n    }\n\n    #[actix_rt::test]\n    async fn prevents_double_compressing() {\n        let app = test::init_service({\n            App::new()\n                .wrap(Compress::default())\n                .route(\n                    \"/single\",\n                    web::get().to(move || HttpResponse::Ok().body(TEXT_DATA)),\n                )\n                .service(\n                    web::resource(\"/double\")\n                        .wrap(Compress::default())\n                        .wrap(DefaultHeaders::new().add((\"x-double\", \"true\")))\n                        .route(web::get().to(move || HttpResponse::Ok().body(TEXT_DATA))),\n                )\n        })\n        .await;\n\n        let req = test::TestRequest::default()\n            .uri(\"/single\")\n            .insert_header((header::ACCEPT_ENCODING, \"gzip\"))\n            .to_request();\n        let res = test::call_service(&app, req).await;\n        assert_eq!(res.status(), StatusCode::OK);\n        assert_eq!(res.headers().get(\"x-double\"), None);\n        assert_eq!(res.headers().get(header::CONTENT_ENCODING).unwrap(), \"gzip\");\n        let bytes = test::read_body(res).await;\n        assert_eq!(gzip_decode(bytes), TEXT_DATA.as_bytes());\n\n        let req = test::TestRequest::default()\n            .uri(\"/double\")\n            .insert_header((header::ACCEPT_ENCODING, \"gzip\"))\n            .to_request();\n        let res = test::call_service(&app, req).await;\n        assert_eq!(res.status(), StatusCode::OK);\n        assert_eq!(res.headers().get(\"x-double\").unwrap(), \"true\");\n        assert_eq!(res.headers().get(header::CONTENT_ENCODING).unwrap(), \"gzip\");\n        let bytes = test::read_body(res).await;\n        assert_eq!(gzip_decode(bytes), TEXT_DATA.as_bytes());\n    }\n\n    #[actix_rt::test]\n    async fn retains_previously_set_vary_header() {\n        let app = test::init_service({\n            App::new()\n                .wrap(Compress::default())\n                .default_service(web::to(move || {\n                    HttpResponse::Ok()\n                        .insert_header((header::VARY, \"x-test\"))\n                        .body(TEXT_DATA)\n                }))\n        })\n        .await;\n\n        let req = test::TestRequest::default()\n            .insert_header((header::ACCEPT_ENCODING, \"gzip\"))\n            .to_request();\n        let res = test::call_service(&app, req).await;\n        assert_eq!(res.status(), StatusCode::OK);\n        #[allow(clippy::mutable_key_type)]\n        let vary_headers = res.headers().get_all(header::VARY).collect::<HashSet<_>>();\n        assert!(vary_headers.contains(&HeaderValue::from_static(\"x-test\")));\n        assert!(vary_headers.contains(&HeaderValue::from_static(\"accept-encoding\")));\n    }\n\n    fn configure_predicate_test(cfg: &mut web::ServiceConfig) {\n        cfg.route(\n            \"/html\",\n            web::get().to(|| {\n                HttpResponse::Ok()\n                    .content_type(ContentType::html())\n                    .body(HTML_DATA)\n            }),\n        )\n        .route(\n            \"/image\",\n            web::get().to(|| {\n                HttpResponse::Ok()\n                    .content_type(ContentType::jpeg())\n                    .body(TEXT_DATA)\n            }),\n        );\n    }\n\n    #[actix_rt::test]\n    async fn prevents_compression_jpeg() {\n        let app = test::init_service(\n            App::new()\n                .wrap(Compress::default())\n                .configure(configure_predicate_test),\n        )\n        .await;\n\n        let req =\n            test::TestRequest::with_uri(\"/html\").insert_header((header::ACCEPT_ENCODING, \"gzip\"));\n        let res = test::call_service(&app, req.to_request()).await;\n        assert_successful_gzip_res_with_content_type(&res, \"text/html\");\n        assert_ne!(test::read_body(res).await, HTML_DATA.as_bytes());\n\n        let req =\n            test::TestRequest::with_uri(\"/image\").insert_header((header::ACCEPT_ENCODING, \"gzip\"));\n        let res = test::call_service(&app, req.to_request()).await;\n        assert_successful_identity_res_with_content_type(&res, \"image/jpeg\");\n        assert_eq!(test::read_body(res).await, TEXT_DATA.as_bytes());\n    }\n\n    #[actix_rt::test]\n    async fn prevents_compression_empty() {\n        let app = test::init_service({\n            App::new()\n                .wrap(Compress::default())\n                .default_service(web::to(move || HttpResponse::Ok().finish()))\n        })\n        .await;\n\n        let req = test::TestRequest::default()\n            .insert_header((header::ACCEPT_ENCODING, \"gzip\"))\n            .to_request();\n        let res = test::call_service(&app, req).await;\n        assert_eq!(res.status(), StatusCode::OK);\n        assert!(!res.headers().contains_key(header::CONTENT_ENCODING));\n        assert!(test::read_body(res).await.is_empty());\n    }\n}\n\n#[cfg(feature = \"compress-brotli\")]\n#[cfg(test)]\nmod tests_brotli {\n    use super::*;\n    use crate::{test, web, App};\n\n    #[actix_rt::test]\n    async fn prevents_compression_empty() {\n        let app = test::init_service({\n            App::new()\n                .wrap(Compress::default())\n                .default_service(web::to(move || HttpResponse::Ok().finish()))\n        })\n        .await;\n\n        let req = test::TestRequest::default()\n            .insert_header((header::ACCEPT_ENCODING, \"br\"))\n            .to_request();\n        let res = test::call_service(&app, req).await;\n        assert_eq!(res.status(), StatusCode::OK);\n        assert!(!res.headers().contains_key(header::CONTENT_ENCODING));\n        assert!(test::read_body(res).await.is_empty());\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "ac97deccb26b0244299dff96a04b67d212d5d0ef",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/actix-web/actix-web-actors/src/context.rs",
    "func": "use std::{\n    collections::VecDeque,\n    future::Future,\n    pin::Pin,\n    task::{Context, Poll},\n};\n\nuse actix::{\n    dev::{AsyncContextParts, ContextFut, ContextParts, Envelope, Mailbox, ToEnvelope},\n    fut::ActorFuture,\n    Actor, ActorContext, ActorState, Addr, AsyncContext, Handler, Message, SpawnHandle,\n};\nuse actix_web::error::Error;\nuse bytes::Bytes;\nuse futures_core::Stream;\nuse tokio::sync::oneshot::Sender;\n\n/// Execution context for HTTP actors\n///\n/// # Example\n///\n/// A demonstration of [server-sent events](https://developer.mozilla.org/docs/Web/API/Server-sent_events) using actors:\n///\n/// ```no_run\n/// use std::time::Duration;\n///\n/// use actix::{Actor, AsyncContext};\n/// use actix_web::{get, http::header, App, HttpResponse, HttpServer};\n/// use actix_web_actors::HttpContext;\n/// use bytes::Bytes;\n///\n/// struct MyActor {\n///     count: usize,\n/// }\n///\n/// impl Actor for MyActor {\n///     type Context = HttpContext<Self>;\n///\n///     fn started(&mut self, ctx: &mut Self::Context) {\n///         ctx.run_later(Duration::from_millis(100), Self::write);\n///     }\n/// }\n///\n/// impl MyActor {\n///     fn write(&mut self, ctx: &mut HttpContext<Self>) {\n///         self.count += 1;\n///         if self.count > 3 {\n///             ctx.write_eof()\n///         } else {\n///             ctx.write(Bytes::from(format!(\"event: count\\ndata: {}\\n\\n\", self.count)));\n///             ctx.run_later(Duration::from_millis(100), Self::write);\n///         }\n///     }\n/// }\n///\n/// #[get(\"/\")]\n/// async fn index() -> HttpResponse {\n///     HttpResponse::Ok()\n///         .insert_header(header::ContentType(mime::TEXT_EVENT_STREAM))\n///         .streaming(HttpContext::create(MyActor { count: 0 }))\n/// }\n///\n/// #[actix_web::main]\n/// async fn main() -> std::io::Result<()> {\n///     HttpServer::new(|| App::new().service(index))\n///         .bind((\"127.0.0.1\", 8080))?\n///         .run()\n///         .await\n/// }\n/// ```\npub struct HttpContext<A>\nwhere\n    A: Actor<Context = HttpContext<A>>,\n{\n    inner: ContextParts<A>,\n    stream: VecDeque<Option<Bytes>>,\n}\n\nimpl<A> ActorContext for HttpContext<A>\nwhere\n    A: Actor<Context = Self>,\n{\n    fn stop(&mut self) {\n        self.inner.stop();\n    }\n    fn terminate(&mut self) {\n        self.inner.terminate()\n    }\n    fn state(&self) -> ActorState {\n        self.inner.state()\n    }\n}\n\nimpl<A> AsyncContext<A> for HttpContext<A>\nwhere\n    A: Actor<Context = Self>,\n{\n    #[inline]\n    fn spawn<F>(&mut self, fut: F) -> SpawnHandle\n    where\n        F: ActorFuture<A, Output = ()> + 'static,\n    {\n        self.inner.spawn(fut)\n    }\n\n    #[inline]\n    fn wait<F>(&mut self, fut: F)\n    where\n        F: ActorFuture<A, Output = ()> + 'static,\n    {\n        self.inner.wait(fut)\n    }\n\n    #[doc(hidden)]\n    #[inline]\n    fn waiting(&self) -> bool {\n        self.inner.waiting()\n            || self.inner.state() == ActorState::Stopping\n            || self.inner.state() == ActorState::Stopped\n    }\n\n    #[inline]\n    fn cancel_future(&mut self, handle: SpawnHandle) -> bool {\n        self.inner.cancel_future(handle)\n    }\n\n    #[inline]\n    fn address(&self) -> Addr<A> {\n        self.inner.address()\n    }\n}\n\nimpl<A> HttpContext<A>\nwhere\n    A: Actor<Context = Self>,\n{\n    #[inline]\n    /// Create a new HTTP Context from a request and an actor\n    pub fn create(actor: A) -> impl Stream<Item = Result<Bytes, Error>> {\n        let mb = Mailbox::default();\n        let ctx = HttpContext {\n            inner: ContextParts::new(mb.sender_producer()),\n            stream: VecDeque::new(),\n        };\n        HttpContextFut::new(ctx, actor, mb)\n    }\n\n    /// Create a new HTTP Context\n    pub fn with_factory<F>(f: F) -> impl Stream<Item = Result<Bytes, Error>>\n    where\n        F: FnOnce(&mut Self) -> A + 'static,\n    {\n        let mb = Mailbox::default();\n        let mut ctx = HttpContext {\n            inner: ContextParts::new(mb.sender_producer()),\n            stream: VecDeque::new(),\n        };\n\n        let act = f(&mut ctx);\n        HttpContextFut::new(ctx, act, mb)\n    }\n}\n\nimpl<A> HttpContext<A>\nwhere\n    A: Actor<Context = Self>,\n{\n    /// Write payload\n    #[inline]\n    pub fn write(&mut self, data: Bytes) {\n        self.stream.push_back(Some(data));\n    }\n\n    /// Indicate end of streaming payload. Also this method calls `Self::close`.\n    #[inline]\n    pub fn write_eof(&mut self) {\n        self.stream.push_back(None);\n    }\n\n    /// Handle of the running future\n    ///\n    /// SpawnHandle is the handle returned by `AsyncContext::spawn()` method.\n    pub fn handle(&self) -> SpawnHandle {\n        self.inner.curr_handle()\n    }\n}\n\nimpl<A> AsyncContextParts<A> for HttpContext<A>\nwhere\n    A: Actor<Context = Self>,\n{\n    fn parts(&mut self) -> &mut ContextParts<A> {\n        &mut self.inner\n    }\n}\n\nstruct HttpContextFut<A>\nwhere\n    A: Actor<Context = HttpContext<A>>,\n{\n    fut: ContextFut<A, HttpContext<A>>,\n}\n\nimpl<A> HttpContextFut<A>\nwhere\n    A: Actor<Context = HttpContext<A>>,\n{\n    fn new(ctx: HttpContext<A>, act: A, mailbox: Mailbox<A>) -> Self {\n        let fut = ContextFut::new(ctx, act, mailbox);\n        HttpContextFut { fut }\n    }\n}\n\nimpl<A> Stream for HttpContextFut<A>\nwhere\n    A: Actor<Context = HttpContext<A>>,\n{\n    type Item = Result<Bytes, Error>;\n\n    fn poll_next(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Option<Self::Item>> {\n        if self.fut.alive() {\n            let _ = Pin::new(&mut self.fut).poll(cx);\n        }\n\n        // frames\n        if let Some(data) = self.fut.ctx().stream.pop_front() {\n            Poll::Ready(data.map(Ok))\n        } else if self.fut.alive() {\n            Poll::Pending\n        } else {\n            Poll::Ready(None)\n        }\n    }\n}\n\nimpl<A, M> ToEnvelope<A, M> for HttpContext<A>\nwhere\n    A: Actor<Context = HttpContext<A>> + Handler<M>,\n    M: Message + Send + 'static,\n    M::Result: Send,\n{\n    fn pack(msg: M, tx: Option<Sender<M::Result>>) -> Envelope<A> {\n        Envelope::new(msg, tx)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use std::time::Duration;\n\n    use actix_web::{\n        http::StatusCode,\n        test::{call_service, init_service, read_body, TestRequest},\n        web, App, HttpResponse,\n    };\n\n    use super::*;\n\n    struct MyActor {\n        count: usize,\n    }\n\n    impl Actor for MyActor {\n        type Context = HttpContext<Self>;\n\n        fn started(&mut self, ctx: &mut Self::Context) {\n            ctx.run_later(Duration::from_millis(100), Self::write);\n        }\n    }\n\n    impl MyActor {\n        fn write(&mut self, ctx: &mut HttpContext<Self>) {\n            self.count += 1;\n            if self.count > 3 {\n                ctx.write_eof()\n            } else {\n                ctx.write(Bytes::from(format!(\"LINE-{}\", self.count)));\n                ctx.run_later(Duration::from_millis(100), Self::write);\n            }\n        }\n    }\n\n    #[actix_rt::test]\n    async fn test_default_resource() {\n        let srv = init_service(App::new().service(web::resource(\"/test\").to(|| async {\n            HttpResponse::Ok().streaming(HttpContext::create(MyActor { count: 0 }))\n        })))\n        .await;\n\n        let req = TestRequest::with_uri(\"/test\").to_request();\n        let resp = call_service(&srv, req).await;\n        assert_eq!(resp.status(), StatusCode::OK);\n\n        let body = read_body(resp).await;\n        assert_eq!(body, Bytes::from_static(b\"LINE-1LINE-2LINE-3\"));\n    }\n}\n"
  }
]