[
  {
    "project": "",
    "target": 0,
    "commit_id": "40de2bdae2fcd9e152564fab2bdab9ecaaec9489",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-query/src/extension/mysql/column.rs",
    "func": "use crate::Iden;\n\n#[derive(Debug, Copy, Clone)]\npub enum MySqlType {\n    TinyBlob,\n    MediumBlob,\n    LongBlob,\n}\n\nimpl Iden for MySqlType {\n    fn unquoted(&self, s: &mut dyn std::fmt::Write) {\n        let ty = match self {\n            Self::TinyBlob => \"tinyblob\",\n            Self::MediumBlob => \"mediumblob\",\n            Self::LongBlob => \"longblob\",\n        };\n        write!(s, \"{ty}\").unwrap();\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "715fb75e2ecd2292f2b25531471461d37f7a6bcb",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-query/sea-query-derive/tests/compile-fail/wrong_literal_type.rs",
    "func": "use sea_query::Iden;\n\n#[derive(Iden)]\nenum User {\n    Table,\n    #[iden = 123]\n    Id,\n    FirstName,\n    LastName,\n    Email,\n}\n\nfn main() {}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "afd099d8884523e12eff4453fc4bc11183404fd1",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-query/src/backend/mysql/table.rs",
    "func": "use super::*;\n\nimpl TableBuilder for MysqlQueryBuilder {\n    fn prepare_table_opt(&self, create: &TableCreateStatement, sql: &mut dyn SqlWriter) {\n        // comment\n        if let Some(comment) = &create.comment {\n            let comment = self.escape_string(comment);\n            write!(sql, \" COMMENT '{comment}'\").unwrap();\n        }\n        self.prepare_table_opt_def(create, sql)\n    }\n\n    fn prepare_column_def(&self, column_def: &ColumnDef, sql: &mut dyn SqlWriter) {\n        column_def.name.prepare(sql.as_writer(), self.quote());\n\n        if let Some(column_type) = &column_def.types {\n            write!(sql, \" \").unwrap();\n            self.prepare_column_type(column_type, sql);\n        }\n\n        for column_spec in column_def.spec.iter() {\n            write!(sql, \" \").unwrap();\n            self.prepare_column_spec(column_spec, sql);\n        }\n    }\n\n    fn prepare_column_type(&self, column_type: &ColumnType, sql: &mut dyn SqlWriter) {\n        write!(\n            sql,\n            \"{}\",\n            match column_type {\n                ColumnType::Char(length) => match length {\n                    Some(length) => format!(\"char({length})\"),\n                    None => \"char\".into(),\n                },\n                ColumnType::String(length) => match length {\n                    StringLen::N(length) => format!(\"varchar({length})\"),\n                    StringLen::None => \"varchar(255)\".into(),\n                    StringLen::Max => \"varchar(65535)\".into(),\n                },\n                ColumnType::Text => \"text\".into(),\n                ColumnType::TinyInteger | ColumnType::TinyUnsigned => \"tinyint\".into(),\n                ColumnType::SmallInteger | ColumnType::SmallUnsigned => \"smallint\".into(),\n                ColumnType::Integer | ColumnType::Unsigned => \"int\".into(),\n                ColumnType::BigInteger | ColumnType::BigUnsigned => \"bigint\".into(),\n                ColumnType::Float => \"float\".into(),\n                ColumnType::Double => \"double\".into(),\n                ColumnType::Decimal(precision) => match precision {\n                    Some((precision, scale)) => format!(\"decimal({precision}, {scale})\"),\n                    None => \"decimal\".into(),\n                },\n                ColumnType::DateTime => \"datetime\".into(),\n                ColumnType::Timestamp => \"timestamp\".into(),\n                ColumnType::TimestampWithTimeZone => \"timestamp\".into(),\n                ColumnType::Time => \"time\".into(),\n                ColumnType::Date => \"date\".into(),\n                ColumnType::Year => \"year\".into(),\n                ColumnType::Interval(_, _) => \"unsupported\".into(),\n                ColumnType::Binary(length) => format!(\"binary({length})\"),\n                ColumnType::VarBinary(length) => match length {\n                    StringLen::N(length) => format!(\"varbinary({length})\"),\n                    StringLen::None => \"varbinary(255)\".into(),\n                    StringLen::Max => \"varbinary(65535)\".into(),\n                },\n                ColumnType::Blob => \"blob\".into(),\n                ColumnType::Bit(length) => {\n                    match length {\n                        Some(length) => format!(\"bit({length})\"),\n                        None => \"bit\".into(),\n                    }\n                }\n                ColumnType::VarBit(length) => {\n                    format!(\"bit({length})\")\n                }\n                ColumnType::Boolean => \"bool\".into(),\n                ColumnType::Money(precision) => match precision {\n                    Some((precision, scale)) => format!(\"decimal({precision}, {scale})\"),\n                    None => \"decimal\".into(),\n                },\n                ColumnType::Json => \"json\".into(),\n                ColumnType::JsonBinary => \"json\".into(),\n                ColumnType::Uuid => \"binary(16)\".into(),\n                ColumnType::Custom(iden) => iden.to_string(),\n                ColumnType::Enum { variants, .. } => format!(\n                    \"ENUM('{}')\",\n                    variants\n                        .iter()\n                        .map(|v| v.to_string())\n                        .collect::<Vec<_>>()\n                        .join(\"', '\")\n                ),\n                ColumnType::Array(_) => unimplemented!(\"Array is not available in MySQL.\"),\n                ColumnType::Vector(_) => unimplemented!(\"Vector is not available in MySQL.\"),\n                ColumnType::Cidr => unimplemented!(\"Cidr is not available in MySQL.\"),\n                ColumnType::Inet => unimplemented!(\"Inet is not available in MySQL.\"),\n                ColumnType::MacAddr => unimplemented!(\"MacAddr is not available in MySQL.\"),\n                ColumnType::LTree => unimplemented!(\"LTree is not available in MySQL.\"),\n            }\n        )\n        .unwrap();\n        if matches!(\n            column_type,\n            ColumnType::TinyUnsigned\n                | ColumnType::SmallUnsigned\n                | ColumnType::Unsigned\n                | ColumnType::BigUnsigned\n        ) {\n            write!(sql, \" \").unwrap();\n            write!(sql, \"UNSIGNED\").unwrap();\n        }\n    }\n\n    fn column_spec_auto_increment_keyword(&self) -> &str {\n        \"AUTO_INCREMENT\"\n    }\n\n    fn prepare_table_alter_statement(&self, alter: &TableAlterStatement, sql: &mut dyn SqlWriter) {\n        if alter.options.is_empty() {\n            panic!(\"No alter option found\")\n        };\n        write!(sql, \"ALTER TABLE \").unwrap();\n        if let Some(table) = &alter.table {\n            self.prepare_table_ref_table_stmt(table, sql);\n            write!(sql, \" \").unwrap();\n        }\n        alter.options.iter().fold(true, |first, option| {\n            if !first {\n                write!(sql, \", \").unwrap();\n            };\n            match option {\n                TableAlterOption::AddColumn(AddColumnOption {\n                    column,\n                    if_not_exists,\n                }) => {\n                    write!(sql, \"ADD COLUMN \").unwrap();\n                    if *if_not_exists {\n                        write!(sql, \"IF NOT EXISTS \").unwrap();\n                    }\n                    self.prepare_column_def(column, sql);\n                }\n                TableAlterOption::ModifyColumn(column_def) => {\n                    write!(sql, \"MODIFY COLUMN \").unwrap();\n                    self.prepare_column_def(column_def, sql);\n                }\n                TableAlterOption::RenameColumn(from_name, to_name) => {\n                    write!(sql, \"RENAME COLUMN \").unwrap();\n                    from_name.prepare(sql.as_writer(), self.quote());\n                    write!(sql, \" TO \").unwrap();\n                    to_name.prepare(sql.as_writer(), self.quote());\n                }\n                TableAlterOption::DropColumn(column_name) => {\n                    write!(sql, \"DROP COLUMN \").unwrap();\n                    column_name.prepare(sql.as_writer(), self.quote());\n                }\n                TableAlterOption::DropForeignKey(name) => {\n                    let mut foreign_key = TableForeignKey::new();\n                    foreign_key.name(name.to_string());\n                    let drop = ForeignKeyDropStatement {\n                        foreign_key,\n                        table: None,\n                    };\n                    self.prepare_foreign_key_drop_statement_internal(&drop, sql, Mode::TableAlter);\n                }\n                TableAlterOption::AddForeignKey(foreign_key) => {\n                    let create = ForeignKeyCreateStatement {\n                        foreign_key: foreign_key.to_owned(),\n                    };\n                    self.prepare_foreign_key_create_statement_internal(\n                        &create,\n                        sql,\n                        Mode::TableAlter,\n                    );\n                }\n            };\n            false\n        });\n    }\n\n    fn prepare_table_rename_statement(\n        &self,\n        rename: &TableRenameStatement,\n        sql: &mut dyn SqlWriter,\n    ) {\n        write!(sql, \"RENAME TABLE \").unwrap();\n        if let Some(from_name) = &rename.from_name {\n            self.prepare_table_ref_table_stmt(from_name, sql);\n        }\n        write!(sql, \" TO \").unwrap();\n        if let Some(to_name) = &rename.to_name {\n            self.prepare_table_ref_table_stmt(to_name, sql);\n        }\n    }\n\n    /// column comment\n    fn column_comment(&self, comment: &str, sql: &mut dyn SqlWriter) {\n        let comment = self.escape_string(comment);\n        write!(sql, \"COMMENT '{comment}'\").unwrap()\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "c8dfae833ef7b235b0de4f4ba058beba8c763839",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/ratatui/examples/apps/demo2/src/destroy.rs",
    "func": "use rand::Rng;\nuse rand_chacha::rand_core::SeedableRng;\nuse ratatui::{\n    buffer::Buffer,\n    layout::{Flex, Layout, Rect},\n    style::{Color, Style},\n    text::Text,\n    widgets::Widget,\n    Frame,\n};\n\n/// delay the start of the animation so it doesn't start immediately\nconst DELAY: usize = 120;\n/// higher means more pixels per frame are modified in the animation\nconst DRIP_SPEED: usize = 500;\n/// delay the start of the text animation so it doesn't start immediately after the initial delay\nconst TEXT_DELAY: usize = 180;\n\n/// Destroy mode activated by pressing `d`\npub fn destroy(frame: &mut Frame<'_>) {\n    let frame_count = frame.count().saturating_sub(DELAY);\n    if frame_count == 0 {\n        return;\n    }\n\n    let area = frame.area();\n    let buf = frame.buffer_mut();\n\n    drip(frame_count, area, buf);\n    text(frame_count, area, buf);\n}\n\n/// Move a bunch of random pixels down one row.\n///\n/// Each pick some random pixels and move them each down one row. This is a very inefficient way to\n/// do this, but it works well enough for this demo.\n#[allow(\n    clippy::cast_possible_truncation,\n    clippy::cast_precision_loss,\n    clippy::cast_sign_loss\n)]\nfn drip(frame_count: usize, area: Rect, buf: &mut Buffer) {\n    // a seeded rng as we have to move the same random pixels each frame\n    let mut rng = rand_chacha::ChaCha8Rng::seed_from_u64(10);\n    let ramp_frames = 450;\n    let fractional_speed = frame_count as f64 / f64::from(ramp_frames);\n    let variable_speed = DRIP_SPEED as f64 * fractional_speed * fractional_speed * fractional_speed;\n    let pixel_count = (frame_count as f64 * variable_speed).floor() as usize;\n    for _ in 0..pixel_count {\n        let src_x = rng.gen_range(0..area.width);\n        let src_y = rng.gen_range(1..area.height - 2);\n        let src = buf[(src_x, src_y)].clone();\n        // 1% of the time, move a blank or pixel (10:1) to the top line of the screen\n        if rng.gen_ratio(1, 100) {\n            let dest_x = rng\n                .gen_range(src_x.saturating_sub(5)..src_x.saturating_add(5))\n                .clamp(area.left(), area.right() - 1);\n            let dest_y = area.top() + 1;\n\n            let dest = &mut buf[(dest_x, dest_y)];\n            // copy the cell to the new location about 1/10 of the time blank out the cell the rest\n            // of the time. This has the effect of gradually removing the pixels from the screen.\n            if rng.gen_ratio(1, 10) {\n                *dest = src;\n            } else {\n                dest.reset();\n            }\n        } else {\n            // move the pixel down one row\n            let dest_x = src_x;\n            let dest_y = src_y.saturating_add(1).min(area.bottom() - 2);\n            // copy the cell to the new location\n            buf[(dest_x, dest_y)] = src;\n        }\n    }\n}\n\n/// draw some text fading in and out from black to red and back\n#[allow(clippy::cast_possible_truncation, clippy::cast_precision_loss)]\nfn text(frame_count: usize, area: Rect, buf: &mut Buffer) {\n    let sub_frame = frame_count.saturating_sub(TEXT_DELAY);\n    if sub_frame == 0 {\n        return;\n    }\n\n    let logo = indoc::indoc! {\"\n        \u2588\u2588\u2588\u2588\u2588\u2588      \u2588\u2588\u2588\u2588    \u2588\u2588\u2588\u2588\u2588\u2588    \u2588\u2588\u2588\u2588    \u2588\u2588\u2588\u2588\u2588\u2588  \u2588\u2588    \u2588\u2588  \u2588\u2588\n        \u2588\u2588    \u2588\u2588  \u2588\u2588    \u2588\u2588    \u2588\u2588    \u2588\u2588    \u2588\u2588    \u2588\u2588    \u2588\u2588    \u2588\u2588  \u2588\u2588\n        \u2588\u2588\u2588\u2588\u2588\u2588    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588    \u2588\u2588    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588    \u2588\u2588    \u2588\u2588    \u2588\u2588  \u2588\u2588\n        \u2588\u2588  \u2588\u2588    \u2588\u2588    \u2588\u2588    \u2588\u2588    \u2588\u2588    \u2588\u2588    \u2588\u2588    \u2588\u2588    \u2588\u2588  \u2588\u2588\n        \u2588\u2588    \u2588\u2588  \u2588\u2588    \u2588\u2588    \u2588\u2588    \u2588\u2588    \u2588\u2588    \u2588\u2588      \u2588\u2588\u2588\u2588    \u2588\u2588\n    \"};\n    let logo_text = Text::styled(logo, Color::Rgb(255, 255, 255));\n    let area = centered_rect(area, logo_text.width() as u16, logo_text.height() as u16);\n\n    let mask_buf = &mut Buffer::empty(area);\n    logo_text.render(area, mask_buf);\n\n    let percentage = (sub_frame as f64 / 480.0).clamp(0.0, 1.0);\n\n    for row in area.rows() {\n        for col in row.columns() {\n            let cell = &mut buf[(col.x, col.y)];\n            let mask_cell = &mut mask_buf[(col.x, col.y)];\n            cell.set_symbol(mask_cell.symbol());\n\n            // blend the mask cell color with the cell color\n            let cell_color = cell.style().bg.unwrap_or(Color::Rgb(0, 0, 0));\n            let mask_color = mask_cell.style().fg.unwrap_or(Color::Rgb(255, 0, 0));\n\n            let color = blend(mask_color, cell_color, percentage);\n            cell.set_style(Style::new().fg(color));\n        }\n    }\n}\n\nfn blend(mask_color: Color, cell_color: Color, percentage: f64) -> Color {\n    let Color::Rgb(mask_red, mask_green, mask_blue) = mask_color else {\n        return mask_color;\n    };\n    let Color::Rgb(cell_red, cell_green, cell_blue) = cell_color else {\n        return mask_color;\n    };\n\n    let remain = 1.0 - percentage;\n\n    let red = f64::from(mask_red).mul_add(percentage, f64::from(cell_red) * remain);\n    let green = f64::from(mask_green).mul_add(percentage, f64::from(cell_green) * remain);\n    let blue = f64::from(mask_blue).mul_add(percentage, f64::from(cell_blue) * remain);\n\n    #[allow(clippy::cast_possible_truncation, clippy::cast_sign_loss)]\n    Color::Rgb(red as u8, green as u8, blue as u8)\n}\n\n/// a centered rect of the given size\nfn centered_rect(area: Rect, width: u16, height: u16) -> Rect {\n    let horizontal = Layout::horizontal([width]).flex(Flex::Center);\n    let vertical = Layout::vertical([height]).flex(Flex::Center);\n    let [area] = vertical.areas(area);\n    let [area] = horizontal.areas(area);\n    area\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "e53eaad25cf03729bc0ba03c40541bc3e990eac9",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/ratatui/ratatui-termion/src/lib.rs",
    "func": "// show the feature flags in the generated documentation\n#![cfg_attr(docsrs, feature(doc_cfg))]\n#![cfg_attr(docsrs, feature(doc_auto_cfg))]\n#![doc(\n    html_logo_url = \"https://raw.githubusercontent.com/ratatui/ratatui/main/assets/logo.png\",\n    html_favicon_url = \"https://raw.githubusercontent.com/ratatui/ratatui/main/assets/favicon.ico\"\n)]\n#![warn(missing_docs)]\n//! This module provides the [`TermionBackend`] implementation for the [`Backend`] trait. It uses\n//! the [Termion] crate to interact with the terminal.\n//!\n//! [`Backend`]: ratatui_core::backend::Backend\n//! [Termion]: https://docs.rs/termion\n#![cfg_attr(feature = \"document-features\", doc = \"\\n## Features\")]\n#![cfg_attr(feature = \"document-features\", doc = document_features::document_features!())]\n\nuse std::{\n    fmt,\n    io::{self, Write},\n};\n\nuse ratatui_core::{\n    backend::{Backend, ClearType, WindowSize},\n    buffer::Cell,\n    layout::{Position, Size},\n    style::{Color, Modifier, Style},\n};\npub use termion;\nuse termion::{color as tcolor, color::Color as _, style as tstyle};\n\n/// A [`Backend`] implementation that uses [Termion] to render to the terminal.\n///\n/// The `TermionBackend` struct is a wrapper around a writer implementing [`Write`], which is used\n/// to send commands to the terminal. It provides methods for drawing content, manipulating the\n/// cursor, and clearing the terminal screen.\n///\n/// Most applications should not call the methods on `TermionBackend` directly, but will instead\n/// use the [`Terminal`] struct, which provides a more ergonomic interface.\n///\n/// Usually applications will enable raw mode and switch to alternate screen mode when starting.\n/// This is done by calling [`IntoRawMode::into_raw_mode()`] and\n/// [`IntoAlternateScreen::into_alternate_screen()`] on the writer before creating the backend.\n/// This is not done automatically by the backend because it is possible that the application may\n/// want to use the terminal for other purposes (like showing help text) before entering alternate\n/// screen mode. This backend automatically disable raw mode and switches back to the primary\n/// screen when the writer is dropped.\n///\n/// # Example\n///\n/// ```rust,no_run\n/// use std::io::{stderr, stdout};\n///\n/// use ratatui::{\n///     backend::TermionBackend,\n///     termion::{raw::IntoRawMode, screen::IntoAlternateScreen},\n///     Terminal,\n/// };\n///\n/// let writer = stdout().into_raw_mode()?.into_alternate_screen()?;\n/// let mut backend = TermionBackend::new(writer);\n/// // or\n/// let writer = stderr().into_raw_mode()?.into_alternate_screen()?;\n/// let backend = TermionBackend::new(stderr());\n/// let mut terminal = Terminal::new(backend)?;\n///\n/// terminal.clear()?;\n/// terminal.draw(|frame| {\n///     // -- snip --\n/// })?;\n/// # std::io::Result::Ok(())\n/// ```\n///\n/// [`IntoRawMode::into_raw_mode()`]: termion::raw::IntoRawMode\n/// [`IntoAlternateScreen::into_alternate_screen()`]: termion::screen::IntoAlternateScreen\n/// [`Terminal`]: ratatui_core::terminal::Terminal\n/// [Termion]: https://docs.rs/termion\n#[derive(Debug, Default, Clone, Eq, PartialEq, Hash)]\npub struct TermionBackend<W>\nwhere\n    W: Write,\n{\n    writer: W,\n}\n\nimpl<W> TermionBackend<W>\nwhere\n    W: Write,\n{\n    /// Creates a new Termion backend with the given writer.\n    ///\n    /// Most applications will use either [`stdout`](std::io::stdout) or\n    /// [`stderr`](std::io::stderr) as writer. See the [FAQ] to determine which one to use.\n    ///\n    /// [FAQ]: https://ratatui.rs/faq/#should-i-use-stdout-or-stderr\n    ///\n    /// # Example\n    ///\n    /// ```rust,no_run\n    /// use std::io::stdout;\n    ///\n    /// use ratatui::backend::TermionBackend;\n    ///\n    /// let backend = TermionBackend::new(stdout());\n    /// ```\n    pub const fn new(writer: W) -> Self {\n        Self { writer }\n    }\n\n    /// Gets the writer.\n    #[instability::unstable(\n        feature = \"backend-writer\",\n        issue = \"https://github.com/ratatui/ratatui/pull/991\"\n    )]\n    pub const fn writer(&self) -> &W {\n        &self.writer\n    }\n\n    /// Gets the writer as a mutable reference.\n    /// Note: writing to the writer may cause incorrect output after the write. This is due to the\n    /// way that the Terminal implements diffing Buffers.\n    #[instability::unstable(\n        feature = \"backend-writer\",\n        issue = \"https://github.com/ratatui/ratatui/pull/991\"\n    )]\n    pub fn writer_mut(&mut self) -> &mut W {\n        &mut self.writer\n    }\n}\n\nimpl<W> Write for TermionBackend<W>\nwhere\n    W: Write,\n{\n    fn write(&mut self, buf: &[u8]) -> io::Result<usize> {\n        self.writer.write(buf)\n    }\n\n    fn flush(&mut self) -> io::Result<()> {\n        self.writer.flush()\n    }\n}\n\nimpl<W> Backend for TermionBackend<W>\nwhere\n    W: Write,\n{\n    fn clear(&mut self) -> io::Result<()> {\n        self.clear_region(ClearType::All)\n    }\n\n    fn clear_region(&mut self, clear_type: ClearType) -> io::Result<()> {\n        match clear_type {\n            ClearType::All => write!(self.writer, \"{}\", termion::clear::All)?,\n            ClearType::AfterCursor => write!(self.writer, \"{}\", termion::clear::AfterCursor)?,\n            ClearType::BeforeCursor => write!(self.writer, \"{}\", termion::clear::BeforeCursor)?,\n            ClearType::CurrentLine => write!(self.writer, \"{}\", termion::clear::CurrentLine)?,\n            ClearType::UntilNewLine => write!(self.writer, \"{}\", termion::clear::UntilNewline)?,\n        };\n        self.writer.flush()\n    }\n\n    fn append_lines(&mut self, n: u16) -> io::Result<()> {\n        for _ in 0..n {\n            writeln!(self.writer)?;\n        }\n        self.writer.flush()\n    }\n\n    fn hide_cursor(&mut self) -> io::Result<()> {\n        write!(self.writer, \"{}\", termion::cursor::Hide)?;\n        self.writer.flush()\n    }\n\n    fn show_cursor(&mut self) -> io::Result<()> {\n        write!(self.writer, \"{}\", termion::cursor::Show)?;\n        self.writer.flush()\n    }\n\n    fn get_cursor_position(&mut self) -> io::Result<Position> {\n        termion::cursor::DetectCursorPos::cursor_pos(&mut self.writer)\n            .map(|(x, y)| Position { x: x - 1, y: y - 1 })\n    }\n\n    fn set_cursor_position<P: Into<Position>>(&mut self, position: P) -> io::Result<()> {\n        let Position { x, y } = position.into();\n        write!(self.writer, \"{}\", termion::cursor::Goto(x + 1, y + 1))?;\n        self.writer.flush()\n    }\n\n    fn draw<'a, I>(&mut self, content: I) -> io::Result<()>\n    where\n        I: Iterator<Item = (u16, u16, &'a Cell)>,\n    {\n        use std::fmt::Write;\n\n        let mut string = String::with_capacity(content.size_hint().0 * 3);\n        let mut fg = Color::Reset;\n        let mut bg = Color::Reset;\n        let mut modifier = Modifier::empty();\n        let mut last_pos: Option<Position> = None;\n        for (x, y, cell) in content {\n            // Move the cursor if the previous location was not (x - 1, y)\n            if !matches!(last_pos, Some(p) if x == p.x + 1 && y == p.y) {\n                write!(string, \"{}\", termion::cursor::Goto(x + 1, y + 1)).unwrap();\n            }\n            last_pos = Some(Position { x, y });\n            if cell.modifier != modifier {\n                write!(\n                    string,\n                    \"{}\",\n                    ModifierDiff {\n                        from: modifier,\n                        to: cell.modifier\n                    }\n                )\n                .unwrap();\n                modifier = cell.modifier;\n            }\n            if cell.fg != fg {\n                write!(string, \"{}\", Fg(cell.fg)).unwrap();\n                fg = cell.fg;\n            }\n            if cell.bg != bg {\n                write!(string, \"{}\", Bg(cell.bg)).unwrap();\n                bg = cell.bg;\n            }\n            string.push_str(cell.symbol());\n        }\n        write!(\n            self.writer,\n            \"{string}{}{}{}\",\n            Fg(Color::Reset),\n            Bg(Color::Reset),\n            termion::style::Reset,\n        )\n    }\n\n    fn size(&self) -> io::Result<Size> {\n        let terminal = termion::terminal_size()?;\n        Ok(Size::new(terminal.0, terminal.1))\n    }\n\n    fn window_size(&mut self) -> io::Result<WindowSize> {\n        Ok(WindowSize {\n            columns_rows: termion::terminal_size()?.into(),\n            pixels: termion::terminal_size_pixels()?.into(),\n        })\n    }\n\n    fn flush(&mut self) -> io::Result<()> {\n        self.writer.flush()\n    }\n\n    #[cfg(feature = \"scrolling-regions\")]\n    fn scroll_region_up(&mut self, region: std::ops::Range<u16>, amount: u16) -> io::Result<()> {\n        write!(\n            self.writer,\n            \"{}{}{}\",\n            SetRegion(region.start.saturating_add(1), region.end),\n            termion::scroll::Up(amount),\n            ResetRegion,\n        )?;\n        self.writer.flush()\n    }\n\n    #[cfg(feature = \"scrolling-regions\")]\n    fn scroll_region_down(&mut self, region: std::ops::Range<u16>, amount: u16) -> io::Result<()> {\n        write!(\n            self.writer,\n            \"{}{}{}\",\n            SetRegion(region.start.saturating_add(1), region.end),\n            termion::scroll::Down(amount),\n            ResetRegion,\n        )?;\n        self.writer.flush()\n    }\n}\nstruct Fg(Color);\n\nstruct Bg(Color);\n\n/// The `ModifierDiff` struct is used to calculate the difference between two `Modifier`\n/// values. This is useful when updating the terminal display, as it allows for more\n/// efficient updates by only sending the necessary changes.\nstruct ModifierDiff {\n    from: Modifier,\n    to: Modifier,\n}\n\nimpl fmt::Display for Fg {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        match self.0 {\n            Color::Reset => termion::color::Reset.write_fg(f),\n            Color::Black => termion::color::Black.write_fg(f),\n            Color::Red => termion::color::Red.write_fg(f),\n            Color::Green => termion::color::Green.write_fg(f),\n            Color::Yellow => termion::color::Yellow.write_fg(f),\n            Color::Blue => termion::color::Blue.write_fg(f),\n            Color::Magenta => termion::color::Magenta.write_fg(f),\n            Color::Cyan => termion::color::Cyan.write_fg(f),\n            Color::Gray => termion::color::White.write_fg(f),\n            Color::DarkGray => termion::color::LightBlack.write_fg(f),\n            Color::LightRed => termion::color::LightRed.write_fg(f),\n            Color::LightGreen => termion::color::LightGreen.write_fg(f),\n            Color::LightBlue => termion::color::LightBlue.write_fg(f),\n            Color::LightYellow => termion::color::LightYellow.write_fg(f),\n            Color::LightMagenta => termion::color::LightMagenta.write_fg(f),\n            Color::LightCyan => termion::color::LightCyan.write_fg(f),\n            Color::White => termion::color::LightWhite.write_fg(f),\n            Color::Indexed(i) => termion::color::AnsiValue(i).write_fg(f),\n            Color::Rgb(r, g, b) => termion::color::Rgb(r, g, b).write_fg(f),\n        }\n    }\n}\nimpl fmt::Display for Bg {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        match self.0 {\n            Color::Reset => termion::color::Reset.write_bg(f),\n            Color::Black => termion::color::Black.write_bg(f),\n            Color::Red => termion::color::Red.write_bg(f),\n            Color::Green => termion::color::Green.write_bg(f),\n            Color::Yellow => termion::color::Yellow.write_bg(f),\n            Color::Blue => termion::color::Blue.write_bg(f),\n            Color::Magenta => termion::color::Magenta.write_bg(f),\n            Color::Cyan => termion::color::Cyan.write_bg(f),\n            Color::Gray => termion::color::White.write_bg(f),\n            Color::DarkGray => termion::color::LightBlack.write_bg(f),\n            Color::LightRed => termion::color::LightRed.write_bg(f),\n            Color::LightGreen => termion::color::LightGreen.write_bg(f),\n            Color::LightBlue => termion::color::LightBlue.write_bg(f),\n            Color::LightYellow => termion::color::LightYellow.write_bg(f),\n            Color::LightMagenta => termion::color::LightMagenta.write_bg(f),\n            Color::LightCyan => termion::color::LightCyan.write_bg(f),\n            Color::White => termion::color::LightWhite.write_bg(f),\n            Color::Indexed(i) => termion::color::AnsiValue(i).write_bg(f),\n            Color::Rgb(r, g, b) => termion::color::Rgb(r, g, b).write_bg(f),\n        }\n    }\n}\n\n/// A trait for converting a Termion type to a Ratatui type.\n///\n/// This trait is necessary to avoid the orphan rule, as we cannot implement a trait for a type\n/// defined in another crate.\npub trait FromTermion<T> {\n    /// Convert the Termion type to the Ratatui type.\n    fn from_termion(termion: T) -> Self;\n}\n\n/// A trait for converting a Ratatui type to a Termion type.\n///\n/// This trait is necessary to avoid the orphan rule, as we cannot implement a trait for a type\n/// defined in another crate.\npub trait IntoTermion<T> {\n    /// Convert the Ratatui type to the Termion type.\n    fn into_termion(self) -> T;\n}\n\nmacro_rules! from_termion_for_color {\n    ($termion_color:ident, $color:ident) => {\n        impl FromTermion<tcolor::$termion_color> for Color {\n            fn from_termion(_: tcolor::$termion_color) -> Self {\n                Color::$color\n            }\n        }\n\n        impl FromTermion<tcolor::Bg<tcolor::$termion_color>> for Style {\n            fn from_termion(_: tcolor::Bg<tcolor::$termion_color>) -> Self {\n                Style::default().bg(Color::$color)\n            }\n        }\n\n        impl FromTermion<tcolor::Fg<tcolor::$termion_color>> for Style {\n            fn from_termion(_: tcolor::Fg<tcolor::$termion_color>) -> Self {\n                Style::default().fg(Color::$color)\n            }\n        }\n    };\n}\n\nfrom_termion_for_color!(Reset, Reset);\nfrom_termion_for_color!(Black, Black);\nfrom_termion_for_color!(Red, Red);\nfrom_termion_for_color!(Green, Green);\nfrom_termion_for_color!(Yellow, Yellow);\nfrom_termion_for_color!(Blue, Blue);\nfrom_termion_for_color!(Magenta, Magenta);\nfrom_termion_for_color!(Cyan, Cyan);\nfrom_termion_for_color!(White, Gray);\nfrom_termion_for_color!(LightBlack, DarkGray);\nfrom_termion_for_color!(LightRed, LightRed);\nfrom_termion_for_color!(LightGreen, LightGreen);\nfrom_termion_for_color!(LightBlue, LightBlue);\nfrom_termion_for_color!(LightYellow, LightYellow);\nfrom_termion_for_color!(LightMagenta, LightMagenta);\nfrom_termion_for_color!(LightCyan, LightCyan);\nfrom_termion_for_color!(LightWhite, White);\n\nimpl FromTermion<tcolor::AnsiValue> for Color {\n    fn from_termion(value: tcolor::AnsiValue) -> Self {\n        Self::Indexed(value.0)\n    }\n}\n\nimpl FromTermion<tcolor::Bg<tcolor::AnsiValue>> for Style {\n    fn from_termion(value: tcolor::Bg<tcolor::AnsiValue>) -> Self {\n        Self::default().bg(Color::Indexed(value.0 .0))\n    }\n}\n\nimpl FromTermion<tcolor::Fg<tcolor::AnsiValue>> for Style {\n    fn from_termion(value: tcolor::Fg<tcolor::AnsiValue>) -> Self {\n        Self::default().fg(Color::Indexed(value.0 .0))\n    }\n}\n\nimpl FromTermion<tcolor::Rgb> for Color {\n    fn from_termion(value: tcolor::Rgb) -> Self {\n        Self::Rgb(value.0, value.1, value.2)\n    }\n}\n\nimpl FromTermion<tcolor::Bg<tcolor::Rgb>> for Style {\n    fn from_termion(value: tcolor::Bg<tcolor::Rgb>) -> Self {\n        Self::default().bg(Color::Rgb(value.0 .0, value.0 .1, value.0 .2))\n    }\n}\n\nimpl FromTermion<tcolor::Fg<tcolor::Rgb>> for Style {\n    fn from_termion(value: tcolor::Fg<tcolor::Rgb>) -> Self {\n        Self::default().fg(Color::Rgb(value.0 .0, value.0 .1, value.0 .2))\n    }\n}\n\nimpl fmt::Display for ModifierDiff {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        let remove = self.from - self.to;\n        if remove.contains(Modifier::REVERSED) {\n            write!(f, \"{}\", termion::style::NoInvert)?;\n        }\n        if remove.contains(Modifier::BOLD) {\n            // XXX: the termion NoBold flag actually enables double-underline on ECMA-48 compliant\n            // terminals, and NoFaint additionally disables bold... so we use this trick to get\n            // the right semantics.\n            write!(f, \"{}\", termion::style::NoFaint)?;\n\n            if self.to.contains(Modifier::DIM) {\n                write!(f, \"{}\", termion::style::Faint)?;\n            }\n        }\n        if remove.contains(Modifier::ITALIC) {\n            write!(f, \"{}\", termion::style::NoItalic)?;\n        }\n        if remove.contains(Modifier::UNDERLINED) {\n            write!(f, \"{}\", termion::style::NoUnderline)?;\n        }\n        if remove.contains(Modifier::DIM) {\n            write!(f, \"{}\", termion::style::NoFaint)?;\n\n            // XXX: the NoFaint flag additionally disables bold as well, so we need to re-enable it\n            // here if we want it.\n            if self.to.contains(Modifier::BOLD) {\n                write!(f, \"{}\", termion::style::Bold)?;\n            }\n        }\n        if remove.contains(Modifier::CROSSED_OUT) {\n            write!(f, \"{}\", termion::style::NoCrossedOut)?;\n        }\n        if remove.contains(Modifier::SLOW_BLINK) || remove.contains(Modifier::RAPID_BLINK) {\n            write!(f, \"{}\", termion::style::NoBlink)?;\n        }\n\n        let add = self.to - self.from;\n        if add.contains(Modifier::REVERSED) {\n            write!(f, \"{}\", termion::style::Invert)?;\n        }\n        if add.contains(Modifier::BOLD) {\n            write!(f, \"{}\", termion::style::Bold)?;\n        }\n        if add.contains(Modifier::ITALIC) {\n            write!(f, \"{}\", termion::style::Italic)?;\n        }\n        if add.contains(Modifier::UNDERLINED) {\n            write!(f, \"{}\", termion::style::Underline)?;\n        }\n        if add.contains(Modifier::DIM) {\n            write!(f, \"{}\", termion::style::Faint)?;\n        }\n        if add.contains(Modifier::CROSSED_OUT) {\n            write!(f, \"{}\", termion::style::CrossedOut)?;\n        }\n        if add.contains(Modifier::SLOW_BLINK) || add.contains(Modifier::RAPID_BLINK) {\n            write!(f, \"{}\", termion::style::Blink)?;\n        }\n\n        Ok(())\n    }\n}\n\nmacro_rules! from_termion_for_modifier {\n    ($termion_modifier:ident, $modifier:ident) => {\n        impl FromTermion<tstyle::$termion_modifier> for Modifier {\n            fn from_termion(_: tstyle::$termion_modifier) -> Self {\n                Modifier::$modifier\n            }\n        }\n    };\n}\n\nfrom_termion_for_modifier!(Invert, REVERSED);\nfrom_termion_for_modifier!(Bold, BOLD);\nfrom_termion_for_modifier!(Italic, ITALIC);\nfrom_termion_for_modifier!(Underline, UNDERLINED);\nfrom_termion_for_modifier!(Faint, DIM);\nfrom_termion_for_modifier!(CrossedOut, CROSSED_OUT);\nfrom_termion_for_modifier!(Blink, SLOW_BLINK);\n\nimpl FromTermion<termion::style::Reset> for Modifier {\n    fn from_termion(_: termion::style::Reset) -> Self {\n        Self::empty()\n    }\n}\n\n/// Set scrolling region.\n#[derive(Copy, Clone, PartialEq, Eq)]\npub struct SetRegion(pub u16, pub u16);\n\nimpl fmt::Display for SetRegion {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        write!(f, \"\\x1B[{};{}r\", self.0, self.1)\n    }\n}\n\n/// Reset scrolling region.\n#[derive(Copy, Clone, PartialEq, Eq)]\npub struct ResetRegion;\n\nimpl fmt::Display for ResetRegion {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        write!(f, \"\\x1B[r\")\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use ratatui_core::style::Stylize;\n\n    use super::*;\n\n    #[test]\n    fn from_termion_color() {\n        assert_eq!(Color::from_termion(tcolor::Reset), Color::Reset);\n        assert_eq!(Color::from_termion(tcolor::Black), Color::Black);\n        assert_eq!(Color::from_termion(tcolor::Red), Color::Red);\n        assert_eq!(Color::from_termion(tcolor::Green), Color::Green);\n        assert_eq!(Color::from_termion(tcolor::Yellow), Color::Yellow);\n        assert_eq!(Color::from_termion(tcolor::Blue), Color::Blue);\n        assert_eq!(Color::from_termion(tcolor::Magenta), Color::Magenta);\n        assert_eq!(Color::from_termion(tcolor::Cyan), Color::Cyan);\n        assert_eq!(Color::from_termion(tcolor::White), Color::Gray);\n        assert_eq!(Color::from_termion(tcolor::LightBlack), Color::DarkGray);\n        assert_eq!(Color::from_termion(tcolor::LightRed), Color::LightRed);\n        assert_eq!(Color::from_termion(tcolor::LightGreen), Color::LightGreen);\n        assert_eq!(Color::from_termion(tcolor::LightBlue), Color::LightBlue);\n        assert_eq!(Color::from_termion(tcolor::LightYellow), Color::LightYellow);\n        assert_eq!(\n            Color::from_termion(tcolor::LightMagenta),\n            Color::LightMagenta\n        );\n        assert_eq!(Color::from_termion(tcolor::LightCyan), Color::LightCyan);\n        assert_eq!(Color::from_termion(tcolor::LightWhite), Color::White);\n        assert_eq!(\n            Color::from_termion(tcolor::AnsiValue(31)),\n            Color::Indexed(31)\n        );\n        assert_eq!(\n            Color::from_termion(tcolor::Rgb(1, 2, 3)),\n            Color::Rgb(1, 2, 3)\n        );\n    }\n\n    #[test]\n    fn from_termion_bg() {\n        use tc::Bg;\n        use tcolor as tc;\n\n        assert_eq!(\n            Style::from_termion(Bg(tc::Reset)),\n            Style::new().bg(Color::Reset)\n        );\n        assert_eq!(Style::from_termion(Bg(tc::Black)), Style::new().on_black());\n        assert_eq!(Style::from_termion(Bg(tc::Red)), Style::new().on_red());\n        assert_eq!(Style::from_termion(Bg(tc::Green)), Style::new().on_green());\n        assert_eq!(\n            Style::from_termion(Bg(tc::Yellow)),\n            Style::new().on_yellow()\n        );\n        assert_eq!(Style::from_termion(Bg(tc::Blue)), Style::new().on_blue());\n        assert_eq!(\n            Style::from_termion(Bg(tc::Magenta)),\n            Style::new().on_magenta()\n        );\n        assert_eq!(Style::from_termion(Bg(tc::Cyan)), Style::new().on_cyan());\n        assert_eq!(Style::from_termion(Bg(tc::White)), Style::new().on_gray());\n        assert_eq!(\n            Style::from_termion(Bg(tc::LightBlack)),\n            Style::new().on_dark_gray()\n        );\n        assert_eq!(\n            Style::from_termion(Bg(tc::LightRed)),\n            Style::new().on_light_red()\n        );\n        assert_eq!(\n            Style::from_termion(Bg(tc::LightGreen)),\n            Style::new().on_light_green()\n        );\n        assert_eq!(\n            Style::from_termion(Bg(tc::LightBlue)),\n            Style::new().on_light_blue()\n        );\n        assert_eq!(\n            Style::from_termion(Bg(tc::LightYellow)),\n            Style::new().on_light_yellow()\n        );\n        assert_eq!(\n            Style::from_termion(Bg(tc::LightMagenta)),\n            Style::new().on_light_magenta()\n        );\n        assert_eq!(\n            Style::from_termion(Bg(tc::LightCyan)),\n            Style::new().on_light_cyan()\n        );\n        assert_eq!(\n            Style::from_termion(Bg(tc::LightWhite)),\n            Style::new().on_white()\n        );\n        assert_eq!(\n            Style::from_termion(Bg(tc::AnsiValue(31))),\n            Style::new().bg(Color::Indexed(31))\n        );\n        assert_eq!(\n            Style::from_termion(Bg(tc::Rgb(1, 2, 3))),\n            Style::new().bg(Color::Rgb(1, 2, 3))\n        );\n    }\n\n    #[test]\n    fn from_termion_fg() {\n        use tc::Fg;\n        use tcolor as tc;\n\n        assert_eq!(\n            Style::from_termion(Fg(tc::Reset)),\n            Style::new().fg(Color::Reset)\n        );\n        assert_eq!(Style::from_termion(Fg(tc::Black)), Style::new().black());\n        assert_eq!(Style::from_termion(Fg(tc::Red)), Style::new().red());\n        assert_eq!(Style::from_termion(Fg(tc::Green)), Style::new().green());\n        assert_eq!(Style::from_termion(Fg(tc::Yellow)), Style::new().yellow());\n        assert_eq!(Style::from_termion(Fg(tc::Blue)), Style::default().blue());\n        assert_eq!(\n            Style::from_termion(Fg(tc::Magenta)),\n            Style::default().magenta()\n        );\n        assert_eq!(Style::from_termion(Fg(tc::Cyan)), Style::default().cyan());\n        assert_eq!(Style::from_termion(Fg(tc::White)), Style::default().gray());\n        assert_eq!(\n            Style::from_termion(Fg(tc::LightBlack)),\n            Style::new().dark_gray()\n        );\n        assert_eq!(\n            Style::from_termion(Fg(tc::LightRed)),\n            Style::new().light_red()\n        );\n        assert_eq!(\n            Style::from_termion(Fg(tc::LightGreen)),\n            Style::new().light_green()\n        );\n        assert_eq!(\n            Style::from_termion(Fg(tc::LightBlue)),\n            Style::new().light_blue()\n        );\n        assert_eq!(\n            Style::from_termion(Fg(tc::LightYellow)),\n            Style::new().light_yellow()\n        );\n        assert_eq!(\n            Style::from_termion(Fg(tc::LightMagenta)),\n            Style::new().light_magenta()\n        );\n        assert_eq!(\n            Style::from_termion(Fg(tc::LightCyan)),\n            Style::new().light_cyan()\n        );\n        assert_eq!(\n            Style::from_termion(Fg(tc::LightWhite)),\n            Style::new().white()\n        );\n        assert_eq!(\n            Style::from_termion(Fg(tc::AnsiValue(31))),\n            Style::default().fg(Color::Indexed(31))\n        );\n        assert_eq!(\n            Style::from_termion(Fg(tc::Rgb(1, 2, 3))),\n            Style::default().fg(Color::Rgb(1, 2, 3))\n        );\n    }\n\n    #[test]\n    fn from_termion_style() {\n        assert_eq!(Modifier::from_termion(tstyle::Invert), Modifier::REVERSED);\n        assert_eq!(Modifier::from_termion(tstyle::Bold), Modifier::BOLD);\n        assert_eq!(Modifier::from_termion(tstyle::Italic), Modifier::ITALIC);\n        assert_eq!(\n            Modifier::from_termion(tstyle::Underline),\n            Modifier::UNDERLINED\n        );\n        assert_eq!(Modifier::from_termion(tstyle::Faint), Modifier::DIM);\n        assert_eq!(\n            Modifier::from_termion(tstyle::CrossedOut),\n            Modifier::CROSSED_OUT\n        );\n        assert_eq!(Modifier::from_termion(tstyle::Blink), Modifier::SLOW_BLINK);\n        assert_eq!(Modifier::from_termion(tstyle::Reset), Modifier::empty());\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "2cb68607a3a72e79e7d4716f182c9a38df81e313",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/ratatui/ratatui-widgets/examples/logo.rs",
    "func": "//! # [Ratatui] `RatatuiLogo` example\n//!\n//! The latest version of this example is available in the [widget examples] folder in the\n//! repository.\n//!\n//! Please note that the examples are designed to be run against the `main` branch of the Github\n//! repository. This means that you may not be able to compile with the latest release version on\n//! crates.io, or the one that you have installed locally.\n//!\n//! See the [examples readme] for more information on finding examples that match the version of the\n//! library you are using.\n//!\n//! [Ratatui]: https://github.com/ratatui/ratatui\n//! [widget examples]: https://github.com/ratatui/ratatui/blob/main/ratatui-widgets/examples\n//! [examples readme]: https://github.com/ratatui/ratatui/blob/main/examples/README.md\n\nuse std::env::args;\n\nuse color_eyre::Result;\nuse ratatui::{\n    crossterm::event::{self, Event},\n    layout::{Constraint, Layout},\n    widgets::{RatatuiLogo, RatatuiLogoSize},\n    DefaultTerminal, Frame, TerminalOptions, Viewport,\n};\n\nfn main() -> Result<()> {\n    color_eyre::install()?;\n    let terminal = ratatui::init_with_options(TerminalOptions {\n        viewport: Viewport::Inline(3),\n    });\n    let size = match args().nth(1).as_deref() {\n        Some(\"small\") => RatatuiLogoSize::Small,\n        Some(\"tiny\") => RatatuiLogoSize::Tiny,\n        _ => RatatuiLogoSize::default(),\n    };\n    let result = run(terminal, size);\n    ratatui::restore();\n    println!();\n    result\n}\n\n/// Run the application.\nfn run(mut terminal: DefaultTerminal, size: RatatuiLogoSize) -> Result<()> {\n    loop {\n        terminal.draw(|frame| draw(frame, size))?;\n        if matches!(event::read()?, Event::Key(_)) {\n            break Ok(());\n        }\n    }\n}\n\n/// Draw the UI with a logo.\nfn draw(frame: &mut Frame, size: RatatuiLogoSize) {\n    let [top, bottom] =\n        Layout::vertical([Constraint::Length(1), Constraint::Fill(1)]).areas(frame.area());\n\n    frame.render_widget(\"Powered by\", top);\n    frame.render_widget(RatatuiLogo::new(size), bottom);\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "01293783d8f15effc04b464594cefdd53ece9f06",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/ratatui/ratatui-core/src/backend.rs",
    "func": "#![warn(missing_docs)]\n//! This module provides the backend implementations for different terminal libraries.\n//!\n//! It defines the [`Backend`] trait which is used to abstract over the specific terminal library\n//! being used.\n//!\n//! Supported terminal backends:\n//! - [Crossterm]: enable the `crossterm` feature (enabled by default) and use [`CrosstermBackend`]\n//! - [Termion]: enable the `termion` feature and use [`TermionBackend`]\n//! - [Termwiz]: enable the `termwiz` feature and use [`TermwizBackend`]\n//!\n//! Additionally, a [`TestBackend`] is provided for testing purposes.\n//!\n//! See the [Backend Comparison] section of the [Ratatui Website] for more details on the different\n//! backends.\n//!\n//! Each backend supports a number of features, such as [raw mode](#raw-mode), [alternate\n//! screen](#alternate-screen), and [mouse capture](#mouse-capture). These features are generally\n//! not enabled by default, and must be enabled by the application before they can be used. See the\n//! documentation for each backend for more details.\n//!\n//! Note: most applications should use the [`Terminal`] struct instead of directly calling methods\n//! on the backend.\n//!\n//! # Example\n//!\n//! ```rust,no_run\n//! use std::io::stdout;\n//!\n//! use ratatui::{backend::CrosstermBackend, Terminal};\n//!\n//! let backend = CrosstermBackend::new(stdout());\n//! let mut terminal = Terminal::new(backend)?;\n//! terminal.clear()?;\n//! terminal.draw(|frame| {\n//!     // -- snip --\n//! })?;\n//! # std::io::Result::Ok(())\n//! ```\n//!\n//! See the the [Examples] directory for more examples.\n//!\n//! # Raw Mode\n//!\n//! Raw mode is a mode where the terminal does not perform any processing or handling of the input\n//! and output. This means that features such as echoing input characters, line buffering, and\n//! special character processing (e.g., CTRL-C for SIGINT) are disabled. This is useful for\n//! applications that want to have complete control over the terminal input and output, processing\n//! each keystroke themselves.\n//!\n//! For example, in raw mode, the terminal will not perform line buffering on the input, so the\n//! application will receive each key press as it is typed, instead of waiting for the user to\n//! press enter. This makes it suitable for real-time applications like text editors,\n//! terminal-based games, and more.\n//!\n//! Each backend handles raw mode differently, so the behavior may vary depending on the backend\n//! being used. Be sure to consult the backend's specific documentation for exact details on how it\n//! implements raw mode.\n//!\n//! # Alternate Screen\n//!\n//! The alternate screen is a separate buffer that some terminals provide, distinct from the main\n//! screen. When activated, the terminal will display the alternate screen, hiding the current\n//! content of the main screen. Applications can write to this screen as if it were the regular\n//! terminal display, but when the application exits, the terminal will switch back to the main\n//! screen, and the contents of the alternate screen will be cleared. This is useful for\n//! applications like text editors or terminal games that want to use the full terminal window\n//! without disrupting the command line or other terminal content.\n//!\n//! This creates a seamless transition between the application and the regular terminal session, as\n//! the content displayed before launching the application will reappear after the application\n//! exits.\n//!\n//! Note that not all terminal emulators support the alternate screen, and even those that do may\n//! handle it differently. As a result, the behavior may vary depending on the backend being used.\n//! Always consult the specific backend's documentation to understand how it implements the\n//! alternate screen.\n//!\n//! # Mouse Capture\n//!\n//! Mouse capture is a mode where the terminal captures mouse events such as clicks, scrolls, and\n//! movement, and sends them to the application as special sequences or events. This enables the\n//! application to handle and respond to mouse actions, providing a more interactive and graphical\n//! user experience within the terminal. It's particularly useful for applications like\n//! terminal-based games, text editors, or other programs that require more direct interaction from\n//! the user.\n//!\n//! Each backend handles mouse capture differently, with variations in the types of events that can\n//! be captured and how they are represented. As such, the behavior may vary depending on the\n//! backend being used, and developers should consult the specific backend's documentation to\n//! understand how it implements mouse capture.\n//!\n//! [`CrosstermBackend`]: https://docs.rs/ratatui/latest/ratatui/backend/struct.CrosstermBackend.html\n//! [`TermionBackend`]: https://docs.rs/ratatui/latest/ratatui/backend/struct.TermionBackend.html\n//! [`TermwizBackend`]: https://docs.rs/ratatui/latest/ratatui/backend/struct.TermwizBackend.html\n//! [`Terminal`]: https://docs.rs/ratatui/latest/ratatui/struct.Terminal.html\n//! [Crossterm]: https://crates.io/crates/crossterm\n//! [Termion]: https://crates.io/crates/termion\n//! [Termwiz]: https://crates.io/crates/termwiz\n//! [Examples]: https://github.com/ratatui/ratatui/tree/main/ratatui/examples/README.md\n//! [Backend Comparison]: https://ratatui.rs/concepts/backends/comparison/\n//! [Ratatui Website]: https://ratatui.rs\nuse std::io;\n\nuse strum::{Display, EnumString};\n\nuse crate::{\n    buffer::Cell,\n    layout::{Position, Size},\n};\n\nmod test;\npub use self::test::TestBackend;\n\n/// Enum representing the different types of clearing operations that can be performed\n/// on the terminal screen.\n#[derive(Debug, Display, EnumString, Clone, Copy, Eq, PartialEq, Hash)]\npub enum ClearType {\n    /// Clear the entire screen.\n    All,\n    /// Clear everything after the cursor.\n    AfterCursor,\n    /// Clear everything before the cursor.\n    BeforeCursor,\n    /// Clear the current line.\n    CurrentLine,\n    /// Clear everything from the cursor until the next newline.\n    UntilNewLine,\n}\n\n/// The window size in characters (columns / rows) as well as pixels.\n#[derive(Debug, Clone, Copy, Eq, PartialEq, Hash)]\npub struct WindowSize {\n    /// Size of the window in characters (columns / rows).\n    pub columns_rows: Size,\n    /// Size of the window in pixels.\n    ///\n    /// The `pixels` fields may not be implemented by all terminals and return `0,0`. See\n    /// <https://man7.org/linux/man-pages/man4/tty_ioctl.4.html> under section \"Get and set window\n    /// size\" / TIOCGWINSZ where the fields are commented as \"unused\".\n    pub pixels: Size,\n}\n\n/// The `Backend` trait provides an abstraction over different terminal libraries. It defines the\n/// methods required to draw content, manipulate the cursor, and clear the terminal screen.\n///\n/// Most applications should not need to interact with the `Backend` trait directly as the\n/// [`Terminal`] struct provides a higher level interface for interacting with the terminal.\n///\n/// [`Terminal`]: https://docs.rs/ratatui/latest/ratatui/struct.Terminal.html\npub trait Backend {\n    /// Draw the given content to the terminal screen.\n    ///\n    /// The content is provided as an iterator over `(u16, u16, &Cell)` tuples, where the first two\n    /// elements represent the x and y coordinates, and the third element is a reference to the\n    /// [`Cell`] to be drawn.\n    fn draw<'a, I>(&mut self, content: I) -> io::Result<()>\n    where\n        I: Iterator<Item = (u16, u16, &'a Cell)>;\n\n    /// Insert `n` line breaks to the terminal screen.\n    ///\n    /// This method is optional and may not be implemented by all backends.\n    fn append_lines(&mut self, _n: u16) -> io::Result<()> {\n        Ok(())\n    }\n\n    /// Hide the cursor on the terminal screen.\n    ///\n    ///\n    /// See also [`show_cursor`].\n    /// # Example\n    ///\n    /// ```rust\n    /// # use ratatui::backend::{TestBackend};\n    /// # let mut backend = TestBackend::new(80, 25);\n    /// use ratatui::backend::Backend;\n    ///\n    /// backend.hide_cursor()?;\n    /// // do something with hidden cursor\n    /// backend.show_cursor()?;\n    /// # std::io::Result::Ok(())\n    /// ```\n    ///\n    /// [`show_cursor`]: Self::show_cursor\n    fn hide_cursor(&mut self) -> io::Result<()>;\n\n    /// Show the cursor on the terminal screen.\n    ///\n    /// See [`hide_cursor`] for an example.\n    ///\n    /// [`hide_cursor`]: Self::hide_cursor\n    fn show_cursor(&mut self) -> io::Result<()>;\n\n    /// Get the current cursor position on the terminal screen.\n    ///\n    /// The returned tuple contains the x and y coordinates of the cursor.\n    /// The origin (0, 0) is at the top left corner of the screen.\n    ///\n    /// See [`set_cursor_position`] for an example.\n    ///\n    /// [`set_cursor_position`]: Self::set_cursor_position\n    fn get_cursor_position(&mut self) -> io::Result<Position>;\n\n    /// Set the cursor position on the terminal screen to the given x and y coordinates.\n    ///\n    /// The origin (0, 0) is at the top left corner of the screen.\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// # use ratatui::backend::{TestBackend};\n    /// # let mut backend = TestBackend::new(80, 25);\n    /// use ratatui::{backend::Backend, layout::Position};\n    ///\n    /// backend.set_cursor_position(Position { x: 10, y: 20 })?;\n    /// assert_eq!(backend.get_cursor_position()?, Position { x: 10, y: 20 });\n    /// # std::io::Result::Ok(())\n    /// ```\n    fn set_cursor_position<P: Into<Position>>(&mut self, position: P) -> io::Result<()>;\n\n    /// Get the current cursor position on the terminal screen.\n    ///\n    /// The returned tuple contains the x and y coordinates of the cursor. The origin\n    /// (0, 0) is at the top left corner of the screen.\n    #[deprecated = \"the method get_cursor_position indicates more clearly what about the cursor to get\"]\n    fn get_cursor(&mut self) -> io::Result<(u16, u16)> {\n        let Position { x, y } = self.get_cursor_position()?;\n        Ok((x, y))\n    }\n\n    /// Set the cursor position on the terminal screen to the given x and y coordinates.\n    ///\n    /// The origin (0, 0) is at the top left corner of the screen.\n    #[deprecated = \"the method set_cursor_position indicates more clearly what about the cursor to set\"]\n    fn set_cursor(&mut self, x: u16, y: u16) -> io::Result<()> {\n        self.set_cursor_position(Position { x, y })\n    }\n\n    /// Clears the whole terminal screen\n    ///\n    /// # Example\n    ///\n    /// ```rust,no_run\n    /// # use ratatui::backend::{TestBackend};\n    /// # let mut backend = TestBackend::new(80, 25);\n    /// use ratatui::backend::Backend;\n    ///\n    /// backend.clear()?;\n    /// # std::io::Result::Ok(())\n    /// ```\n    fn clear(&mut self) -> io::Result<()>;\n\n    /// Clears a specific region of the terminal specified by the [`ClearType`] parameter\n    ///\n    /// This method is optional and may not be implemented by all backends. The default\n    /// implementation calls [`clear`] if the `clear_type` is [`ClearType::All`] and returns an\n    /// error otherwise.\n    ///\n    /// # Example\n    ///\n    /// ```rust,no_run\n    /// # use ratatui::{backend::{TestBackend}};\n    /// # let mut backend = TestBackend::new(80, 25);\n    /// use ratatui::backend::{Backend, ClearType};\n    ///\n    /// backend.clear_region(ClearType::All)?;\n    /// # std::io::Result::Ok(())\n    /// ```\n    ///\n    /// # Errors\n    ///\n    /// This method will return an error if the terminal screen could not be cleared. It will also\n    /// return an error if the `clear_type` is not supported by the backend.\n    ///\n    /// [`clear`]: Self::clear\n    fn clear_region(&mut self, clear_type: ClearType) -> io::Result<()> {\n        match clear_type {\n            ClearType::All => self.clear(),\n            ClearType::AfterCursor\n            | ClearType::BeforeCursor\n            | ClearType::CurrentLine\n            | ClearType::UntilNewLine => Err(io::Error::new(\n                io::ErrorKind::Other,\n                format!(\"clear_type [{clear_type:?}] not supported with this backend\"),\n            )),\n        }\n    }\n\n    /// Get the size of the terminal screen in columns/rows as a [`Size`].\n    ///\n    /// The returned [`Size`] contains the width and height of the terminal screen.\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// # use ratatui::{backend::{TestBackend}};\n    /// # let backend = TestBackend::new(80, 25);\n    /// use ratatui::{backend::Backend, layout::Size};\n    ///\n    /// assert_eq!(backend.size()?, Size::new(80, 25));\n    /// # std::io::Result::Ok(())\n    /// ```\n    fn size(&self) -> io::Result<Size>;\n\n    /// Get the size of the terminal screen in columns/rows and pixels as a [`WindowSize`].\n    ///\n    /// The reason for this not returning only the pixel size, given the redundancy with the\n    /// `size()` method, is that the underlying backends most likely get both values with one\n    /// syscall, and the user is also most likely to need columns and rows along with pixel size.\n    fn window_size(&mut self) -> io::Result<WindowSize>;\n\n    /// Flush any buffered content to the terminal screen.\n    fn flush(&mut self) -> io::Result<()>;\n\n    /// Scroll a region of the screen upwards, where a region is specified by a (half-open) range\n    /// of rows.\n    ///\n    /// Each row in the region is replaced by the row `line_count` rows below it, except the bottom\n    /// `line_count` rows, which are replaced by empty rows. If `line_count` is equal to or larger\n    /// than the number of rows in the region, then all rows are replaced with empty rows.\n    ///\n    /// If the region includes row 0, then `line_count` rows are copied into the bottom of the\n    /// scrollback buffer. These rows are first taken from the old contents of the region, starting\n    /// from the top. If there aren't sufficient rows in the region, then the remainder are empty\n    /// rows.\n    ///\n    /// The position of the cursor afterwards is undefined.\n    ///\n    /// The behavior is designed to match what ANSI terminals do when scrolling regions are\n    /// established. With ANSI terminals, a scrolling region can be established with the \"^[[X;Yr\"\n    /// sequence, where X and Y define the lines of the region. The scrolling region can be reset\n    /// to be the whole screen with the \"^[[r\" sequence.\n    ///\n    /// When a scrolling region is established in an ANSI terminal, various operations' behaviors\n    /// are changed in such a way that the scrolling region acts like a \"virtual screen\". In\n    /// particular, the scrolling sequence \"^[[NS\", which scrolls lines up by a count of N.\n    ///\n    /// On an ANSI terminal, this method will probably translate to something like:\n    /// \"^[[X;Yr^[[NS^[[r\". That is, set the scrolling region, scroll up, then reset the scrolling\n    /// region.\n    ///\n    /// For examples of how this function is expected to work, refer to the tests for\n    /// [`TestBackend::scroll_region_up`].\n    #[cfg(feature = \"scrolling-regions\")]\n    fn scroll_region_up(&mut self, region: std::ops::Range<u16>, line_count: u16)\n        -> io::Result<()>;\n\n    /// Scroll a region of the screen downwards, where a region is specified by a (half-open) range\n    /// of rows.\n    ///\n    /// Each row in the region is replaced by the row `line_count` rows above it, except the top\n    /// `line_count` rows, which are replaced by empty rows. If `line_count` is equal to or larger\n    /// than the number of rows in the region, then all rows are replaced with empty rows.\n    ///\n    /// The position of the cursor afterwards is undefined.\n    ///\n    /// See the documentation for [`Self::scroll_region_down`] for more information about how this\n    /// is expected to be implemented for ANSI terminals. All of that applies, except the ANSI\n    /// sequence to scroll down is \"^[[NT\".\n    ///\n    /// This function is asymmetrical with regards to the scrollback buffer. The reason is that\n    /// this how terminals seem to implement things.\n    ///\n    /// For examples of how this function is expected to work, refer to the tests for\n    /// [`TestBackend::scroll_region_down`].\n    #[cfg(feature = \"scrolling-regions\")]\n    fn scroll_region_down(\n        &mut self,\n        region: std::ops::Range<u16>,\n        line_count: u16,\n    ) -> io::Result<()>;\n}\n\n#[cfg(test)]\nmod tests {\n    use strum::ParseError;\n\n    use super::*;\n\n    #[test]\n    fn clear_type_tostring() {\n        assert_eq!(ClearType::All.to_string(), \"All\");\n        assert_eq!(ClearType::AfterCursor.to_string(), \"AfterCursor\");\n        assert_eq!(ClearType::BeforeCursor.to_string(), \"BeforeCursor\");\n        assert_eq!(ClearType::CurrentLine.to_string(), \"CurrentLine\");\n        assert_eq!(ClearType::UntilNewLine.to_string(), \"UntilNewLine\");\n    }\n\n    #[test]\n    fn clear_type_from_str() {\n        assert_eq!(\"All\".parse::<ClearType>(), Ok(ClearType::All));\n        assert_eq!(\n            \"AfterCursor\".parse::<ClearType>(),\n            Ok(ClearType::AfterCursor)\n        );\n        assert_eq!(\n            \"BeforeCursor\".parse::<ClearType>(),\n            Ok(ClearType::BeforeCursor)\n        );\n        assert_eq!(\n            \"CurrentLine\".parse::<ClearType>(),\n            Ok(ClearType::CurrentLine)\n        );\n        assert_eq!(\n            \"UntilNewLine\".parse::<ClearType>(),\n            Ok(ClearType::UntilNewLine)\n        );\n        assert_eq!(\"\".parse::<ClearType>(), Err(ParseError::VariantNotFound));\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "778df9f1df474d74c8f713443e0746013a3b6bfb",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/fd/build.rs",
    "func": "fn main() {\n    let min_version = \"1.64\";\n\n    match version_check::is_min_version(min_version) {\n        Some(true) => {}\n        // rustc version too small or can't figure it out\n        _ => {\n            eprintln!(\"'fd' requires rustc >= {min_version}\");\n            std::process::exit(1);\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "1f6c42d7052c1adbe28686c6063a178e312df447",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/packages/rsx/src/ifmt.rs",
    "func": "use proc_macro2::{Span, TokenStream};\nuse quote::{quote, quote_spanned, ToTokens, TokenStreamExt};\nuse std::collections::HashMap;\nuse syn::{\n    parse::{Parse, ParseStream},\n    *,\n};\n\n/// A hot-reloadable formatted string, boolean, number or other literal\n///\n/// This wraps LitStr with some extra goodies like inline expressions and hot-reloading.\n/// Originally this was intended to provide named inline string interpolation but eventually Rust\n/// actually shipped this!\n#[derive(Debug, PartialEq, Eq, Clone, Hash)]\npub struct IfmtInput {\n    pub source: LitStr,\n    pub segments: Vec<Segment>,\n}\n\nimpl IfmtInput {\n    pub fn new(span: Span) -> Self {\n        Self {\n            source: LitStr::new(\"\", span),\n            segments: Vec::new(),\n        }\n    }\n\n    pub fn new_litstr(source: LitStr) -> Result<Self> {\n        let segments = IfmtInput::from_raw(&source.value())?;\n        Ok(Self { segments, source })\n    }\n\n    pub fn span(&self) -> Span {\n        self.source.span()\n    }\n\n    pub fn push_raw_str(&mut self, other: String) {\n        self.segments.push(Segment::Literal(other.to_string()))\n    }\n\n    pub fn push_ifmt(&mut self, other: IfmtInput) {\n        self.segments.extend(other.segments);\n    }\n\n    pub fn push_expr(&mut self, expr: Expr) {\n        self.segments.push(Segment::Formatted(FormattedSegment {\n            format_args: String::new(),\n            segment: FormattedSegmentType::Expr(Box::new(expr)),\n        }));\n    }\n\n    pub fn is_static(&self) -> bool {\n        self.segments\n            .iter()\n            .all(|seg| matches!(seg, Segment::Literal(_)))\n    }\n\n    pub fn to_static(&self) -> Option<String> {\n        self.segments\n            .iter()\n            .try_fold(String::new(), |acc, segment| {\n                if let Segment::Literal(seg) = segment {\n                    Some(acc + seg)\n                } else {\n                    None\n                }\n            })\n    }\n\n    pub fn dynamic_segments(&self) -> Vec<&FormattedSegment> {\n        self.segments\n            .iter()\n            .filter_map(|seg| match seg {\n                Segment::Formatted(seg) => Some(seg),\n                _ => None,\n            })\n            .collect::<Vec<_>>()\n    }\n\n    pub fn dynamic_seg_frequency_map(&self) -> HashMap<&FormattedSegment, usize> {\n        let mut map = HashMap::new();\n        for seg in self.dynamic_segments() {\n            *map.entry(seg).or_insert(0) += 1;\n        }\n        map\n    }\n\n    fn is_simple_expr(&self) -> bool {\n        self.segments.iter().all(|seg| match seg {\n            Segment::Literal(_) => true,\n            Segment::Formatted(FormattedSegment { segment, .. }) => {\n                matches!(segment, FormattedSegmentType::Ident(_))\n            }\n        })\n    }\n\n    /// Try to convert this into a single _.to_string() call if possible\n    ///\n    /// Using \"{single_expression}\" is pretty common, but you don't need to go through the whole format! machinery for that, so we optimize it here.\n    fn try_to_string(&self) -> Option<TokenStream> {\n        let mut single_dynamic = None;\n        for segment in &self.segments {\n            match segment {\n                Segment::Literal(literal) => {\n                    if !literal.is_empty() {\n                        return None;\n                    }\n                }\n                Segment::Formatted(FormattedSegment {\n                    segment,\n                    format_args,\n                }) => {\n                    if format_args.is_empty() {\n                        match single_dynamic {\n                            Some(current_string) => {\n                                single_dynamic =\n                                    Some(quote!(#current_string + &(#segment).to_string()));\n                            }\n                            None => {\n                                single_dynamic = Some(quote!((#segment).to_string()));\n                            }\n                        }\n                    } else {\n                        return None;\n                    }\n                }\n            }\n        }\n        single_dynamic\n    }\n\n    /// print the original source string - this handles escapes and stuff for us\n    pub fn to_string_with_quotes(&self) -> String {\n        self.source.to_token_stream().to_string()\n    }\n\n    /// Parse the source into segments\n    fn from_raw(input: &str) -> Result<Vec<Segment>> {\n        let mut chars = input.chars().peekable();\n        let mut segments = Vec::new();\n        let mut current_literal = String::new();\n        while let Some(c) = chars.next() {\n            if c == '{' {\n                if let Some(c) = chars.next_if(|c| *c == '{') {\n                    current_literal.push(c);\n                    continue;\n                }\n                if !current_literal.is_empty() {\n                    segments.push(Segment::Literal(current_literal));\n                }\n                current_literal = String::new();\n                let mut current_captured = String::new();\n                while let Some(c) = chars.next() {\n                    if c == ':' {\n                        // two :s in a row is a path, not a format arg\n                        if chars.next_if(|c| *c == ':').is_some() {\n                            current_captured.push_str(\"::\");\n                            continue;\n                        }\n                        let mut current_format_args = String::new();\n                        for c in chars.by_ref() {\n                            if c == '}' {\n                                segments.push(Segment::Formatted(FormattedSegment {\n                                    format_args: current_format_args,\n                                    segment: FormattedSegmentType::parse(&current_captured)?,\n                                }));\n                                break;\n                            }\n                            current_format_args.push(c);\n                        }\n                        break;\n                    }\n                    if c == '}' {\n                        segments.push(Segment::Formatted(FormattedSegment {\n                            format_args: String::new(),\n                            segment: FormattedSegmentType::parse(&current_captured)?,\n                        }));\n                        break;\n                    }\n                    current_captured.push(c);\n                }\n            } else {\n                if '}' == c {\n                    if let Some(c) = chars.next_if(|c| *c == '}') {\n                        current_literal.push(c);\n                        continue;\n                    } else {\n                        return Err(Error::new(\n                            Span::call_site(),\n                            \"unmatched closing '}' in format string\",\n                        ));\n                    }\n                }\n                current_literal.push(c);\n            }\n        }\n\n        if !current_literal.is_empty() {\n            segments.push(Segment::Literal(current_literal));\n        }\n\n        Ok(segments)\n    }\n}\n\nimpl ToTokens for IfmtInput {\n    fn to_tokens(&self, tokens: &mut TokenStream) {\n        // If the input is a string literal, we can just return it\n        if let Some(static_str) = self.to_static() {\n            return quote_spanned! { self.span() => #static_str }.to_tokens(tokens);\n        }\n\n        // Try to turn it into a single _.to_string() call\n        if !cfg!(debug_assertions) {\n            if let Some(single_dynamic) = self.try_to_string() {\n                tokens.extend(single_dynamic);\n                return;\n            }\n        }\n\n        // If the segments are not complex exprs, we can just use format! directly to take advantage of RA rename/expansion\n        if self.is_simple_expr() {\n            let raw = &self.source;\n            tokens.extend(quote! {\n                ::std::format!(#raw)\n            });\n            return;\n        }\n\n        // build format_literal\n        let mut format_literal = String::new();\n        let mut expr_counter = 0;\n        for segment in self.segments.iter() {\n            match segment {\n                Segment::Literal(s) => format_literal += &s.replace('{', \"{{\").replace('}', \"}}\"),\n                Segment::Formatted(FormattedSegment { format_args, .. }) => {\n                    format_literal += \"{\";\n                    format_literal += &expr_counter.to_string();\n                    expr_counter += 1;\n                    format_literal += \":\";\n                    format_literal += format_args;\n                    format_literal += \"}\";\n                }\n            }\n        }\n\n        let span = self.span();\n\n        let positional_args = self.segments.iter().filter_map(|seg| {\n            if let Segment::Formatted(FormattedSegment { segment, .. }) = seg {\n                let mut segment = segment.clone();\n                // We set the span of the ident here, so that we can use it in diagnostics\n                if let FormattedSegmentType::Ident(ident) = &mut segment {\n                    ident.set_span(span);\n                }\n                Some(segment)\n            } else {\n                None\n            }\n        });\n\n        quote_spanned! {\n            span =>\n            ::std::format!(\n                #format_literal\n                #(, #positional_args)*\n            )\n        }\n        .to_tokens(tokens)\n    }\n}\n\n#[derive(Debug, PartialEq, Eq, Clone, Hash)]\npub enum Segment {\n    Literal(String),\n    Formatted(FormattedSegment),\n}\n\nimpl Segment {\n    pub fn is_literal(&self) -> bool {\n        matches!(self, Segment::Literal(_))\n    }\n\n    pub fn is_formatted(&self) -> bool {\n        matches!(self, Segment::Formatted(_))\n    }\n}\n\n#[derive(Debug, PartialEq, Eq, Clone, Hash)]\npub struct FormattedSegment {\n    pub format_args: String,\n    pub segment: FormattedSegmentType,\n}\n\nimpl ToTokens for FormattedSegment {\n    fn to_tokens(&self, tokens: &mut TokenStream) {\n        let (fmt, seg) = (&self.format_args, &self.segment);\n        let fmt = format!(\"{{0:{fmt}}}\");\n        tokens.append_all(quote! {\n            format!(#fmt, #seg)\n        });\n    }\n}\n\n#[derive(Debug, PartialEq, Eq, Clone, Hash)]\npub enum FormattedSegmentType {\n    Expr(Box<Expr>),\n    Ident(Ident),\n}\n\nimpl FormattedSegmentType {\n    fn parse(input: &str) -> Result<Self> {\n        if let Ok(ident) = parse_str::<Ident>(input) {\n            if ident == input {\n                return Ok(Self::Ident(ident));\n            }\n        }\n        if let Ok(expr) = parse_str(input) {\n            Ok(Self::Expr(Box::new(expr)))\n        } else {\n            Err(Error::new(\n                Span::call_site(),\n                \"Expected Ident or Expression\",\n            ))\n        }\n    }\n}\n\nimpl ToTokens for FormattedSegmentType {\n    fn to_tokens(&self, tokens: &mut TokenStream) {\n        match self {\n            Self::Expr(expr) => expr.to_tokens(tokens),\n            Self::Ident(ident) => ident.to_tokens(tokens),\n        }\n    }\n}\n\nimpl Parse for IfmtInput {\n    fn parse(input: ParseStream) -> Result<Self> {\n        let source: LitStr = input.parse()?;\n        Self::new_litstr(source)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use prettier_please::PrettyUnparse;\n\n    #[test]\n    fn raw_tokens() {\n        let input = syn::parse2::<IfmtInput>(quote! { r#\"hello world\"# }).unwrap();\n        println!(\"{}\", input.to_token_stream().pretty_unparse());\n        assert_eq!(input.source.value(), \"hello world\");\n        assert_eq!(input.to_string_with_quotes(), \"r#\\\"hello world\\\"#\");\n    }\n\n    #[test]\n    fn segments_parse() {\n        let input: IfmtInput = parse_quote! { \"blah {abc} {def}\" };\n        assert_eq!(\n            input.segments,\n            vec![\n                Segment::Literal(\"blah \".to_string()),\n                Segment::Formatted(FormattedSegment {\n                    format_args: String::new(),\n                    segment: FormattedSegmentType::Ident(Ident::new(\"abc\", Span::call_site()))\n                }),\n                Segment::Literal(\" \".to_string()),\n                Segment::Formatted(FormattedSegment {\n                    format_args: String::new(),\n                    segment: FormattedSegmentType::Ident(Ident::new(\"def\", Span::call_site()))\n                }),\n            ]\n        );\n    }\n\n    #[test]\n    fn printing_raw() {\n        let input = syn::parse2::<IfmtInput>(quote! { \"hello {world}\" }).unwrap();\n        println!(\"{}\", input.to_string_with_quotes());\n\n        let input = syn::parse2::<IfmtInput>(quote! { \"hello {world} {world} {world}\" }).unwrap();\n        println!(\"{}\", input.to_string_with_quotes());\n\n        let input = syn::parse2::<IfmtInput>(quote! { \"hello {world} {world} {world()}\" }).unwrap();\n        println!(\"{}\", input.to_string_with_quotes());\n\n        let input =\n            syn::parse2::<IfmtInput>(quote! { r#\"hello {world} {world} {world()}\"# }).unwrap();\n        println!(\"{}\", input.to_string_with_quotes());\n        assert!(!input.is_static());\n\n        let input = syn::parse2::<IfmtInput>(quote! { r#\"hello\"# }).unwrap();\n        println!(\"{}\", input.to_string_with_quotes());\n        assert!(input.is_static());\n    }\n\n    #[test]\n    fn to_static() {\n        let input = syn::parse2::<IfmtInput>(quote! { \"body {{ background: red; }}\" }).unwrap();\n        assert_eq!(\n            input.to_static(),\n            Some(\"body { background: red; }\".to_string())\n        );\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "ae1583639ed7b58437974a46eff5baff439a8dfe",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/packages/fullstack/src/document/mod.rs",
    "func": "//! This module contains the document providers for the fullstack platform.\n\n#[cfg(feature = \"server\")]\npub mod server;\n#[cfg(feature = \"server\")]\npub use server::ServerDocument;\n#[cfg(all(feature = \"web\", feature = \"document\"))]\npub mod web;\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "afc568b1790d122bfcc14d616ad573a220046b0f",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/packages/fullstack/src/document/server.rs",
    "func": "//! On the server, we collect any elements that should be rendered into the head in the first frame of SSR.\n//! After the first frame, we have already sent down the head, so we can't modify it in place. The web client\n//! will hydrate the head with the correct contents once it loads.\n\nuse std::cell::RefCell;\n\nuse dioxus_lib::{document::*, prelude::*};\nuse dioxus_ssr::Renderer;\nuse once_cell::sync::Lazy;\nuse parking_lot::RwLock;\n\nstatic RENDERER: Lazy<RwLock<Renderer>> = Lazy::new(|| RwLock::new(Renderer::new()));\n\n#[derive(Default)]\nstruct ServerDocumentInner {\n    streaming: bool,\n    title: Option<String>,\n    meta: Vec<Element>,\n    link: Vec<Element>,\n    script: Vec<Element>,\n}\n\n/// A Document provider that collects all contents injected into the head for SSR rendering.\n#[derive(Default)]\npub struct ServerDocument(RefCell<ServerDocumentInner>);\n\nimpl ServerDocument {\n    pub(crate) fn title(&self) -> Option<String> {\n        let myself = self.0.borrow();\n        myself.title.as_ref().map(|title| {\n            RENDERER\n                .write()\n                .render_element(rsx! { title { \"{title}\" } })\n        })\n    }\n\n    pub(crate) fn render(&self, to: &mut impl std::fmt::Write) -> std::fmt::Result {\n        let myself = self.0.borrow();\n        let element = rsx! {\n            {myself.meta.iter().map(|m| rsx! { {m} })}\n            {myself.link.iter().map(|l| rsx! { {l} })}\n            {myself.script.iter().map(|s| rsx! { {s} })}\n        };\n\n        RENDERER.write().render_element_to(to, element)?;\n\n        Ok(())\n    }\n\n    pub(crate) fn start_streaming(&self) {\n        self.0.borrow_mut().streaming = true;\n    }\n\n    pub(crate) fn warn_if_streaming(&self) {\n        if self.0.borrow().streaming {\n            tracing::warn!(\"Attempted to insert content into the head after the initial streaming frame. Inserting content into the head only works during the initial render of SSR outside before resolving any suspense boundaries.\");\n        }\n    }\n\n    /// Write the head element into the serialized context for hydration\n    /// We write true if the head element was written to the DOM during server side rendering\n    pub(crate) fn serialize_for_hydration(&self) {\n        // We only serialize the head elements if the web document feature is enabled\n        #[cfg(feature = \"document\")]\n        {\n            let serialize = crate::html_storage::serialize_context();\n            serialize.push(&!self.0.borrow().streaming);\n        }\n    }\n}\n\nimpl Document for ServerDocument {\n    fn eval(&self, js: String) -> Eval {\n        NoOpDocument.eval(js)\n    }\n\n    fn set_title(&self, title: String) {\n        self.warn_if_streaming();\n        self.serialize_for_hydration();\n        self.0.borrow_mut().title = Some(title);\n    }\n\n    fn create_meta(&self, props: MetaProps) {\n        self.warn_if_streaming();\n        self.serialize_for_hydration();\n        self.0.borrow_mut().meta.push(rsx! {\n            meta {\n                name: props.name,\n                charset: props.charset,\n                http_equiv: props.http_equiv,\n                content: props.content,\n                property: props.property,\n                ..props.additional_attributes\n            }\n        });\n    }\n\n    fn create_script(&self, props: ScriptProps) {\n        self.warn_if_streaming();\n        self.serialize_for_hydration();\n        let children = props.script_contents().ok();\n        self.0.borrow_mut().script.push(rsx! {\n            script {\n                src: props.src,\n                defer: props.defer,\n                crossorigin: props.crossorigin,\n                fetchpriority: props.fetchpriority,\n                integrity: props.integrity,\n                nomodule: props.nomodule,\n                nonce: props.nonce,\n                referrerpolicy: props.referrerpolicy,\n                r#type: props.r#type,\n                ..props.additional_attributes,\n                {children}\n            }\n        });\n    }\n\n    fn create_style(&self, props: StyleProps) {\n        self.warn_if_streaming();\n        self.serialize_for_hydration();\n        match (&props.href, props.style_contents()) {\n            // The style has inline contents, render it as a style tag\n            (_, Ok(contents)) => self.0.borrow_mut().script.push(rsx! {\n                style {\n                    media: props.media,\n                    nonce: props.nonce,\n                    title: props.title,\n                    ..props.additional_attributes,\n                    {contents}\n                }\n            }),\n            // The style has a href, render it as a link tag\n            (Some(_), _) => {\n                self.0.borrow_mut().script.push(rsx! {\n                    link {\n                        rel: \"stylesheet\",\n                        href: props.href,\n                        media: props.media,\n                        nonce: props.nonce,\n                        title: props.title,\n                        ..props.additional_attributes,\n                    }\n                });\n            }\n            // The style has neither contents nor src, log an error\n            (None, Err(err)) => {\n                err.log(\"Style\");\n            }\n        }\n    }\n\n    fn create_link(&self, props: LinkProps) {\n        self.warn_if_streaming();\n        self.serialize_for_hydration();\n        self.0.borrow_mut().link.push(rsx! {\n            link {\n                rel: props.rel,\n                media: props.media,\n                title: props.title,\n                disabled: props.disabled,\n                r#as: props.r#as,\n                sizes: props.sizes,\n                href: props.href,\n                crossorigin: props.crossorigin,\n                referrerpolicy: props.referrerpolicy,\n                fetchpriority: props.fetchpriority,\n                hreflang: props.hreflang,\n                integrity: props.integrity,\n                r#type: props.r#type,\n                blocking: props.blocking,\n            }\n        })\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "e70ac1d924a8a4f2f33fc0de19825ef08e4295f8",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/packages/router/src/hooks/use_navigator.rs",
    "func": "use dioxus_lib::prelude::{try_consume_context, use_hook};\n\nuse crate::prelude::{Navigator, RouterContext};\n\n/// A hook that provides access to the navigator to change the router history.\n///\n/// > The Routable macro will define a version of this hook with an explicit type.\n///\n/// ```rust\n/// # use dioxus::prelude::*;\n/// # use dioxus_router::prelude::*;\n/// #[derive(Clone, Routable)]\n/// enum Route {\n///     #[route(\"/\")]\n///     Index {},\n///     #[route(\"/:id\")]\n///     Dynamic { id: usize },\n/// }\n///\n/// #[component]\n/// fn App() -> Element {\n///     rsx! {\n///         Router::<Route> {}\n///     }\n/// }\n///\n/// #[component]\n/// fn Index() -> Element {\n///     let navigator = use_navigator();\n///\n///     rsx! {\n///         button {\n///             onclick: move |_| { navigator.push(Route::Dynamic { id: 1234 }); },\n///             \"Go to /1234\"\n///         }\n///     }\n/// }\n///\n/// #[component]\n/// fn Dynamic(id: usize) -> Element {\n///     rsx! {\n///         p {\n///             \"Current ID: {id}\"\n///         }\n///     }\n/// }\n///\n/// # let mut vdom = VirtualDom::new(App);\n/// # vdom.rebuild_in_place();\n/// ```\n#[must_use]\npub fn use_navigator() -> Navigator {\n    use_hook(|| {\n        let router = try_consume_context::<RouterContext>()\n            .expect(\"Must be called in a descendant of a Router component\");\n\n        Navigator(router)\n    })\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "14a77792fdb80200c73ae536642cf71c2a208759",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/packages/manganis/manganis-core/src/options.rs",
    "func": "use const_serialize::SerializeConst;\n\nuse crate::{CssAssetOptions, FolderAssetOptions, ImageAssetOptions, JsAssetOptions};\n\n/// Settings for a generic asset\n#[derive(\n    Debug,\n    PartialEq,\n    PartialOrd,\n    Clone,\n    Copy,\n    Hash,\n    SerializeConst,\n    serde::Serialize,\n    serde::Deserialize,\n)]\n#[repr(C, u8)]\n#[non_exhaustive]\npub enum AssetOptions {\n    /// An image asset\n    Image(ImageAssetOptions),\n    /// A folder asset\n    Folder(FolderAssetOptions),\n    /// A css asset\n    Css(CssAssetOptions),\n    /// A javascript asset\n    Js(JsAssetOptions),\n    /// An unknown asset\n    Unknown,\n}\n\nimpl AssetOptions {\n    /// Try to get the extension for the asset. If the asset options don't define an extension, this will return None\n    pub const fn extension(&self) -> Option<&'static str> {\n        match self {\n            AssetOptions::Image(image) => image.extension(),\n            AssetOptions::Css(_) => Some(\"css\"),\n            AssetOptions::Js(_) => Some(\"js\"),\n            AssetOptions::Folder(_) => None,\n            AssetOptions::Unknown => None,\n        }\n    }\n\n    /// Convert the options into options for a generic asset\n    pub const fn into_asset_options(self) -> Self {\n        self\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "d8b1281c4e954823c7dbadc7680cbcf73f794b0f",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/packages/history/src/lib.rs",
    "func": "use dioxus_core::prelude::{provide_context, provide_root_context};\nuse std::{rc::Rc, sync::Arc};\n\nmod memory;\npub use memory::*;\n\n/// Get the history provider for the current platform if the platform doesn't implement a history functionality.\npub fn history() -> Rc<dyn History> {\n    match dioxus_core::prelude::try_consume_context::<Rc<dyn History>>() {\n        Some(history) => history,\n        None => {\n            tracing::error!(\"Unable to find a history provider in the renderer. Make sure your renderer supports the Router. Falling back to the in-memory history provider.\");\n            provide_root_context(Rc::new(MemoryHistory::default()))\n        }\n    }\n}\n\n/// Provide a history context to the current component.\npub fn provide_history_context(history: Rc<dyn History>) {\n    provide_context(history);\n}\n\npub trait History {\n    /// Get the path of the current URL.\n    ///\n    /// **Must start** with `/`. **Must _not_ contain** the prefix.\n    ///\n    /// ```rust\n    /// # use dioxus::prelude::*;\n    /// # #[component]\n    /// # fn Index() -> Element { VNode::empty() }\n    /// # #[component]\n    /// # fn OtherPage() -> Element { VNode::empty() }\n    /// #[derive(Clone, Routable, Debug, PartialEq)]\n    /// enum Route {\n    ///     #[route(\"/\")]\n    ///     Index {},\n    ///     #[route(\"/some-other-page\")]\n    ///     OtherPage {},\n    /// }\n    /// let mut history = dioxus::history::MemoryHistory::default();\n    /// assert_eq!(history.current_route(), \"/\");\n    ///\n    /// history.push(Route::OtherPage {}.to_string());\n    /// assert_eq!(history.current_route(), \"/some-other-page\");\n    /// ```\n    #[must_use]\n    fn current_route(&self) -> String;\n\n    /// Get the current path prefix of the URL.\n    ///\n    /// Not all [`HistoryProvider`]s need a prefix feature. It is meant for environments where a\n    /// dioxus-router-core-routed application is not running on `/`. The [`HistoryProvider`] is responsible\n    /// for removing the prefix from the dioxus-router-core-internal path, and also for adding it back in\n    /// during navigation. This functions value is only used for creating `href`s (e.g. for SSR or\n    /// display (but not navigation) in a web app).\n    fn current_prefix(&self) -> Option<String> {\n        None\n    }\n\n    /// Check whether there is a previous page to navigate back to.\n    ///\n    /// If a [`HistoryProvider`] cannot know this, it should return [`true`].\n    ///\n    /// ```rust\n    /// # use dioxus::prelude::*;\n    /// # #[component]\n    /// # fn Index() -> Element { VNode::empty() }\n    /// # fn Other() -> Element { VNode::empty() }\n    /// #[derive(Clone, Routable, Debug, PartialEq)]\n    /// enum Route {\n    ///     #[route(\"/\")]\n    ///     Index {},\n    ///     #[route(\"/other\")]\n    ///     Other {},\n    /// }\n    /// let mut history = dioxus::history::MemoryHistory::default();\n    /// assert_eq!(history.can_go_back(), false);\n    ///\n    /// history.push(Route::Other {}.to_string());\n    /// assert_eq!(history.can_go_back(), true);\n    /// ```\n    #[must_use]\n    fn can_go_back(&self) -> bool {\n        true\n    }\n\n    /// Go back to a previous page.\n    ///\n    /// If a [`HistoryProvider`] cannot go to a previous page, it should do nothing. This method\n    /// might be called, even if `can_go_back` returns [`false`].\n    ///\n    /// ```rust\n    /// # use dioxus::prelude::*;\n    /// # #[component]\n    /// # fn Index() -> Element { VNode::empty() }\n    /// # #[component]\n    /// # fn OtherPage() -> Element { VNode::empty() }\n    /// #[derive(Clone, Routable, Debug, PartialEq)]\n    /// enum Route {\n    ///     #[route(\"/\")]\n    ///     Index {},\n    ///     #[route(\"/some-other-page\")]\n    ///     OtherPage {},\n    /// }\n    /// let mut history = dioxus::history::MemoryHistory::default();\n    /// assert_eq!(history.current_route(), \"/\");\n    ///\n    /// history.go_back();\n    /// assert_eq!(history.current_route(), \"/\");\n    ///\n    /// history.push(Route::OtherPage {}.to_string());\n    /// assert_eq!(history.current_route(), \"/some-other-page\");\n    ///\n    /// history.go_back();\n    /// assert_eq!(history.current_route(), \"/\");\n    /// ```\n    fn go_back(&self);\n\n    /// Check whether there is a future page to navigate forward to.\n    ///\n    /// If a [`HistoryProvider`] cannot know this, it should return [`true`].\n    ///\n    /// ```rust\n    /// # use dioxus::prelude::*;\n    /// # #[component]\n    /// # fn Index() -> Element { VNode::empty() }\n    /// # #[component]\n    /// # fn OtherPage() -> Element { VNode::empty() }\n    /// #[derive(Clone, Routable, Debug, PartialEq)]\n    /// enum Route {\n    ///     #[route(\"/\")]\n    ///     Index {},\n    ///     #[route(\"/some-other-page\")]\n    ///     OtherPage {},\n    /// }\n    /// let mut history = dioxus::history::MemoryHistory::default();\n    /// assert_eq!(history.can_go_forward(), false);\n    ///\n    /// history.push(Route::OtherPage {}.to_string());\n    /// assert_eq!(history.can_go_forward(), false);\n    ///\n    /// history.go_back();\n    /// assert_eq!(history.can_go_forward(), true);\n    /// ```\n    #[must_use]\n    fn can_go_forward(&self) -> bool {\n        true\n    }\n\n    /// Go forward to a future page.\n    ///\n    /// If a [`HistoryProvider`] cannot go to a previous page, it should do nothing. This method\n    /// might be called, even if `can_go_forward` returns [`false`].\n    ///\n    /// ```rust\n    /// # use dioxus::prelude::*;\n    /// # #[component]\n    /// # fn Index() -> Element { VNode::empty() }\n    /// # #[component]\n    /// # fn OtherPage() -> Element { VNode::empty() }\n    /// #[derive(Clone, Routable, Debug, PartialEq)]\n    /// enum Route {\n    ///     #[route(\"/\")]\n    ///     Index {},\n    ///     #[route(\"/some-other-page\")]\n    ///     OtherPage {},\n    /// }\n    /// let mut history = dioxus::history::MemoryHistory::default();\n    /// history.push(Route::OtherPage {}.to_string());\n    /// assert_eq!(history.current_route(), Route::OtherPage {}.to_string());\n    ///\n    /// history.go_back();\n    /// assert_eq!(history.current_route(), Route::Index {}.to_string());\n    ///\n    /// history.go_forward();\n    /// assert_eq!(history.current_route(), Route::OtherPage {}.to_string());\n    /// ```\n    fn go_forward(&self);\n\n    /// Go to another page.\n    ///\n    /// This should do three things:\n    /// 1. Merge the current URL with the `path` parameter (which may also include a query part).\n    /// 2. Remove the previous URL to the navigation history.\n    /// 3. Clear the navigation future.\n    ///\n    /// ```rust\n    /// # use dioxus::prelude::*;\n    /// # #[component]\n    /// # fn Index() -> Element { VNode::empty() }\n    /// # #[component]\n    /// # fn OtherPage() -> Element { VNode::empty() }\n    /// #[derive(Clone, Routable, Debug, PartialEq)]\n    /// enum Route {\n    ///     #[route(\"/\")]\n    ///     Index {},\n    ///     #[route(\"/some-other-page\")]\n    ///     OtherPage {},\n    /// }\n    /// let mut history = dioxus::history::MemoryHistory::default();\n    /// assert_eq!(history.current_route(), Route::Index {}.to_string());\n    ///\n    /// history.push(Route::OtherPage {}.to_string());\n    /// assert_eq!(history.current_route(), Route::OtherPage {}.to_string());\n    /// assert!(history.can_go_back());\n    /// ```\n    fn push(&self, route: String);\n\n    /// Replace the current page with another one.\n    ///\n    /// This should merge the current URL with the `path` parameter (which may also include a query\n    /// part). In contrast to the `push` function, the navigation history and future should stay\n    /// untouched.\n    ///\n    /// ```rust\n    /// # use dioxus::prelude::*;\n    /// # #[component]\n    /// # fn Index() -> Element { VNode::empty() }\n    /// # #[component]\n    /// # fn OtherPage() -> Element { VNode::empty() }\n    /// #[derive(Clone, Routable, Debug, PartialEq)]\n    /// enum Route {\n    ///     #[route(\"/\")]\n    ///     Index {},\n    ///     #[route(\"/some-other-page\")]\n    ///     OtherPage {},\n    /// }\n    /// let mut history = dioxus::history::MemoryHistory::default();\n    /// assert_eq!(history.current_route(), Route::Index {}.to_string());\n    ///\n    /// history.replace(Route::OtherPage {}.to_string());\n    /// assert_eq!(history.current_route(), Route::OtherPage {}.to_string());\n    /// assert!(!history.can_go_back());\n    /// ```\n    fn replace(&self, path: String);\n\n    /// Navigate to an external URL.\n    ///\n    /// This should navigate to an external URL, which isn't controlled by the router. If a\n    /// [`HistoryProvider`] cannot do that, it should return [`false`], otherwise [`true`].\n    ///\n    /// Returning [`false`] will cause the router to handle the external navigation failure.\n    #[allow(unused_variables)]\n    fn external(&self, url: String) -> bool {\n        false\n    }\n\n    /// Provide the [`HistoryProvider`] with an update callback.\n    ///\n    /// Some [`HistoryProvider`]s may receive URL updates from outside the router. When such\n    /// updates are received, they should call `callback`, which will cause the router to update.\n    #[allow(unused_variables)]\n    fn updater(&self, callback: Arc<dyn Fn() + Send + Sync>) {}\n\n    /// Whether the router should include the legacy prevent default attribute instead of the new\n    /// prevent default method. This should only be used by liveview.\n    fn include_prevent_default(&self) -> bool {\n        false\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "188f6744d7c114240aea14cdd78066397b1e518e",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/packages/signals/src/read_only_signal.rs",
    "func": "use crate::{read::Readable, ReadableRef, Signal, SignalData};\nuse dioxus_core::IntoDynNode;\nuse std::ops::Deref;\n\nuse crate::{default_impl, read_impls};\nuse dioxus_core::{prelude::IntoAttributeValue, ScopeId};\nuse generational_box::{BorrowResult, Storage, UnsyncStorage};\n\n/// A signal that can only be read from.\npub struct ReadOnlySignal<T: 'static, S: Storage<SignalData<T>> = UnsyncStorage> {\n    inner: Signal<T, S>,\n}\n\n/// A signal that can only be read from.\npub type ReadSignal<T, S> = ReadOnlySignal<T, S>;\n\nimpl<T: 'static, S: Storage<SignalData<T>>> From<Signal<T, S>> for ReadOnlySignal<T, S> {\n    fn from(inner: Signal<T, S>) -> Self {\n        Self { inner }\n    }\n}\n\nimpl<T: 'static> ReadOnlySignal<T> {\n    /// Create a new read-only signal.\n    #[track_caller]\n    pub fn new(signal: Signal<T>) -> Self {\n        Self::new_maybe_sync(signal)\n    }\n}\n\nimpl<T: 'static, S: Storage<SignalData<T>>> ReadOnlySignal<T, S> {\n    /// Create a new read-only signal that is maybe sync.\n    #[track_caller]\n    pub fn new_maybe_sync(signal: Signal<T, S>) -> Self {\n        Self { inner: signal }\n    }\n\n    /// Get the scope that the signal was created in.\n    pub fn origin_scope(&self) -> ScopeId {\n        self.inner.origin_scope()\n    }\n\n    /// Get the id of the signal.\n    pub fn id(&self) -> generational_box::GenerationalBoxId {\n        self.inner.id()\n    }\n\n    /// Point to another signal\n    pub fn point_to(&self, other: Self) -> BorrowResult {\n        self.inner.point_to(other.inner)\n    }\n\n    #[doc(hidden)]\n    /// This is only used by the `props` macro.\n    /// Mark any readers of the signal as dirty\n    pub fn mark_dirty(&mut self) {\n        use crate::write::Writable;\n        use warnings::Warning;\n        // We diff props while rendering, but we only write to the signal if it has\n        // changed so it is safe to ignore the warning\n        crate::warnings::signal_write_in_component_body::allow(|| {\n            _ = self.inner.try_write();\n        });\n    }\n}\n\nimpl<T, S: Storage<SignalData<T>>> Readable for ReadOnlySignal<T, S> {\n    type Target = T;\n    type Storage = S;\n\n    #[track_caller]\n    fn try_read_unchecked(\n        &self,\n    ) -> Result<ReadableRef<'static, Self>, generational_box::BorrowError> {\n        self.inner.try_read_unchecked()\n    }\n\n    /// Get the current value of the signal. **Unlike read, this will not subscribe the current scope to the signal which can cause parts of your UI to not update.**\n    ///\n    /// If the signal has been dropped, this will panic.\n    #[track_caller]\n    fn try_peek_unchecked(&self) -> BorrowResult<S::Ref<'static, T>> {\n        self.inner.try_peek_unchecked()\n    }\n}\n\n#[cfg(feature = \"serialize\")]\nimpl<T: serde::Serialize + 'static, Store: Storage<SignalData<T>>> serde::Serialize\n    for ReadOnlySignal<T, Store>\n{\n    fn serialize<S: serde::Serializer>(&self, serializer: S) -> Result<S::Ok, S::Error> {\n        self.read().serialize(serializer)\n    }\n}\n\n#[cfg(feature = \"serialize\")]\nimpl<'de, T: serde::Deserialize<'de> + 'static, Store: Storage<SignalData<T>>>\n    serde::Deserialize<'de> for ReadOnlySignal<T, Store>\n{\n    fn deserialize<D: serde::Deserializer<'de>>(deserializer: D) -> Result<Self, D::Error> {\n        Ok(Self::new_maybe_sync(Signal::new_maybe_sync(\n            T::deserialize(deserializer)?,\n        )))\n    }\n}\n\nimpl<T> IntoAttributeValue for ReadOnlySignal<T>\nwhere\n    T: Clone + IntoAttributeValue,\n{\n    fn into_value(self) -> dioxus_core::AttributeValue {\n        self.with(|f| f.clone().into_value())\n    }\n}\n\nimpl<T> IntoDynNode for ReadOnlySignal<T>\nwhere\n    T: Clone + IntoDynNode,\n{\n    fn into_dyn_node(self) -> dioxus_core::DynamicNode {\n        self().into_dyn_node()\n    }\n}\n\nimpl<T: 'static, S: Storage<SignalData<T>>> PartialEq for ReadOnlySignal<T, S> {\n    fn eq(&self, other: &Self) -> bool {\n        self.inner == other.inner\n    }\n}\n\nimpl<T: Clone, S: Storage<SignalData<T>> + 'static> Deref for ReadOnlySignal<T, S> {\n    type Target = dyn Fn() -> T;\n\n    fn deref(&self) -> &Self::Target {\n        unsafe { Readable::deref_impl(self) }\n    }\n}\n\nread_impls!(\n    ReadOnlySignal<T, S> where\n        S: Storage<SignalData<T>>\n);\ndefault_impl!(\n    ReadOnlySignal<T, S> where\n    S: Storage<SignalData<T>>\n);\n\nimpl<T: 'static, S: Storage<SignalData<T>>> Clone for ReadOnlySignal<T, S> {\n    fn clone(&self) -> Self {\n        *self\n    }\n}\n\nimpl<T: 'static, S: Storage<SignalData<T>>> Copy for ReadOnlySignal<T, S> {}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "58b94adee12c4092d7054a1f1eef0b315c027c47",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/packages/web/src/launch.rs",
    "func": "//! This module contains the `launch` function, which is the main entry point for dioxus web\n\npub use crate::Config;\nuse dioxus_core::prelude::*;\nuse std::any::Any;\n\n/// Launch the web application with the given root component, context and config\n///\n/// For a builder API, see `LaunchBuilder` defined in the `dioxus` crate.\npub fn launch(\n    root: fn() -> Element,\n    contexts: Vec<Box<dyn Fn() -> Box<dyn Any> + Send + Sync>>,\n    platform_config: Vec<Box<dyn Any>>,\n) {\n    let mut vdom = VirtualDom::new(root);\n    for context in contexts {\n        vdom.insert_any_root_context(context());\n    }\n\n    let platform_config = *platform_config\n        .into_iter()\n        .find_map(|cfg| cfg.downcast::<Config>().ok())\n        .unwrap_or_default();\n    launch_virtual_dom(vdom, platform_config)\n}\n\n/// Launch the web application with a prebuild virtual dom\n///\n/// For a builder API, see `LaunchBuilder` defined in the `dioxus` crate.\npub fn launch_virtual_dom(vdom: VirtualDom, platform_config: Config) {\n    wasm_bindgen_futures::spawn_local(async move {\n        crate::run(vdom, platform_config).await;\n    });\n}\n\n/// Launch the web application with the given root component and config\npub fn launch_cfg(root: fn() -> Element, platform_config: Config) {\n    launch(root, Vec::new(), vec![Box::new(platform_config)])\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "f35b9bcce422398b47aeb3ac84aa10b24b4dbed8",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/packages/core/src/hotreload_utils.rs",
    "func": "use std::{\n    any::{Any, TypeId},\n    hash::{Hash, Hasher},\n};\n\n#[cfg(feature = \"serialize\")]\nuse crate::nodes::deserialize_string_leaky;\nuse crate::{\n    Attribute, AttributeValue, DynamicNode, Template, TemplateAttribute, TemplateNode, VNode, VText,\n};\n\n#[cfg_attr(feature = \"serialize\", derive(serde::Serialize, serde::Deserialize))]\n#[doc(hidden)]\n#[derive(Debug, PartialEq, Clone)]\npub struct HotreloadedLiteral {\n    pub name: String,\n    pub value: HotReloadLiteral,\n}\n\n#[cfg_attr(feature = \"serialize\", derive(serde::Serialize, serde::Deserialize))]\n#[doc(hidden)]\n#[derive(Debug, PartialEq, Clone)]\npub enum HotReloadLiteral {\n    Fmted(FmtedSegments),\n    Float(f64),\n    Int(i64),\n    Bool(bool),\n}\n\nimpl HotReloadLiteral {\n    pub fn as_fmted(&self) -> Option<&FmtedSegments> {\n        match self {\n            Self::Fmted(segments) => Some(segments),\n            _ => None,\n        }\n    }\n\n    pub fn as_float(&self) -> Option<f64> {\n        match self {\n            Self::Float(f) => Some(*f),\n            _ => None,\n        }\n    }\n\n    pub fn as_int(&self) -> Option<i64> {\n        match self {\n            Self::Int(i) => Some(*i),\n            _ => None,\n        }\n    }\n\n    pub fn as_bool(&self) -> Option<bool> {\n        match self {\n            Self::Bool(b) => Some(*b),\n            _ => None,\n        }\n    }\n}\n\nimpl Hash for HotReloadLiteral {\n    fn hash<H: Hasher>(&self, state: &mut H) {\n        match self {\n            Self::Fmted(segments) => segments.hash(state),\n            Self::Float(f) => f.to_bits().hash(state),\n            Self::Int(i) => i.hash(state),\n            Self::Bool(b) => b.hash(state),\n        }\n    }\n}\n\n#[cfg_attr(feature = \"serialize\", derive(serde::Serialize, serde::Deserialize))]\n#[doc(hidden)]\n#[derive(Debug, PartialEq, Eq, Clone, Hash)]\npub struct FmtedSegments {\n    pub(crate) segments: Vec<FmtSegment>,\n}\n\nimpl FmtedSegments {\n    pub fn new(segments: Vec<FmtSegment>) -> Self {\n        Self { segments }\n    }\n\n    /// Render the formatted string by stitching together the segments\n    pub(crate) fn render_with(&self, dynamic_text: &[String]) -> String {\n        let mut out = String::new();\n\n        for segment in &self.segments {\n            match segment {\n                FmtSegment::Literal { value } => out.push_str(value),\n                FmtSegment::Dynamic { id } => out.push_str(&dynamic_text[*id]),\n            }\n        }\n\n        out\n    }\n}\n\ntype StaticStr = &'static str;\n\n#[cfg_attr(feature = \"serialize\", derive(serde::Serialize, serde::Deserialize))]\n#[doc(hidden)]\n#[derive(Debug, PartialEq, Eq, Clone, Hash)]\npub enum FmtSegment {\n    Literal {\n        #[cfg_attr(\n            feature = \"serialize\",\n            serde(deserialize_with = \"deserialize_string_leaky\")\n        )]\n        value: StaticStr,\n    },\n    Dynamic {\n        id: usize,\n    },\n}\n\n// let __pool = DynamicValuePool::new(\n//     vec![...],\n//     vec![...],\n//     vec![...],\n// );\n// VNode::new(\n//     None,\n//     Template {\n//         name: \"...\",\n//         roots: &[...],\n//         node_paths: &[..],\n//         attr_paths: &[...],\n//     },\n//     Box::new([...]),\n//     Box::new([...]),\n// )\n\n// Open questions:\n// - How do we handle type coercion for different sized component property integers?\n// - Should non-string hot literals go through the centralized pool?\n// - Should formatted strings be a runtime concept?\n\n#[doc(hidden)]\npub struct DynamicLiteralPool {\n    dynamic_text: Box<[String]>,\n}\n\nimpl DynamicLiteralPool {\n    pub fn new(dynamic_text: Vec<String>) -> Self {\n        Self {\n            dynamic_text: dynamic_text.into_boxed_slice(),\n        }\n    }\n\n    pub fn get_component_property<'a, T>(\n        &self,\n        id: usize,\n        hot_reload: &'a HotReloadedTemplate,\n        f: impl FnOnce(&'a HotReloadLiteral) -> Option<T>,\n    ) -> Option<T> {\n        f(hot_reload.component_values.get(id)?)\n    }\n\n    /// Get a component property of a specific type at the component property index\n    pub fn component_property<T: 'static>(\n        &mut self,\n        id: usize,\n        hot_reload: &HotReloadedTemplate,\n        // We pass in the original value for better type inference\n        // For example, if the original literal is `0i128`, we know the output must be the type `i128`\n        _coherse_type: T,\n    ) -> T {\n        fn assert_type<T: 'static, T2: 'static>(t: T) -> T2 {\n            *(Box::new(t) as Box<dyn Any>).downcast::<T2>().unwrap()\n        }\n        let grab_float = || {\n            self.get_component_property(id, hot_reload, HotReloadLiteral::as_float).unwrap_or_else(|| {\n                tracing::error!(\"Expected a float component property, because the type was {}. The CLI gave the hot reloading engine a type of {:?}. This is probably caused by a bug in dioxus hot reloading. Please report this issue.\", std::any::type_name::<T>(), hot_reload.component_values.get(id));\n                Default::default()\n\n        })\n        };\n        let grab_int = || {\n            self.get_component_property(id, hot_reload, HotReloadLiteral::as_int).unwrap_or_else(|| {\n                tracing::error!(\"Expected a integer component property, because the type was {}. The CLI gave the hot reloading engine a type of {:?}. This is probably caused by a bug in dioxus hot reloading. Please report this issue.\", std::any::type_name::<T>(), hot_reload.component_values.get(id));\n                Default::default()\n            })\n        };\n        let grab_bool = || {\n            self.get_component_property(id, hot_reload, HotReloadLiteral::as_bool).unwrap_or_else(|| {\n                tracing::error!(\"Expected a bool component property, because the type was {}. The CLI gave the hot reloading engine a type of {:?}. This is probably caused by a bug in dioxus hot reloading. Please report this issue.\", std::any::type_name::<T>(), hot_reload.component_values.get(id));\n                Default::default()\n            })\n        };\n        let grab_fmted = || {\n            self.get_component_property(id, hot_reload, |fmted| HotReloadLiteral::as_fmted(fmted).map(|segments| self.render_formatted(segments))).unwrap_or_else(|| {\n                tracing::error!(\"Expected a string component property, because the type was {}. The CLI gave the hot reloading engine a type of {:?}. This is probably caused by a bug in dioxus hot reloading. Please report this issue.\", std::any::type_name::<T>(), hot_reload.component_values.get(id));\n                Default::default()\n            })\n        };\n        match TypeId::of::<T>() {\n            // Any string types that accept a literal\n            _ if TypeId::of::<String>() == TypeId::of::<T>() => assert_type(grab_fmted()),\n            _ if TypeId::of::<&str>() == TypeId::of::<T>() => {\n                assert_type(Box::leak(grab_fmted().into_boxed_str()) as &'static str)\n            }\n            // Any integer types that accept a literal\n            _ if TypeId::of::<i128>() == TypeId::of::<T>() => assert_type(grab_int() as i128),\n            _ if TypeId::of::<i64>() == TypeId::of::<T>() => assert_type(grab_int()),\n            _ if TypeId::of::<i32>() == TypeId::of::<T>() => assert_type(grab_int() as i32),\n            _ if TypeId::of::<i16>() == TypeId::of::<T>() => assert_type(grab_int() as i16),\n            _ if TypeId::of::<i8>() == TypeId::of::<T>() => assert_type(grab_int() as i8),\n            _ if TypeId::of::<isize>() == TypeId::of::<T>() => assert_type(grab_int() as isize),\n            _ if TypeId::of::<u128>() == TypeId::of::<T>() => assert_type(grab_int() as u128),\n            _ if TypeId::of::<u64>() == TypeId::of::<T>() => assert_type(grab_int() as u64),\n            _ if TypeId::of::<u32>() == TypeId::of::<T>() => assert_type(grab_int() as u32),\n            _ if TypeId::of::<u16>() == TypeId::of::<T>() => assert_type(grab_int() as u16),\n            _ if TypeId::of::<u8>() == TypeId::of::<T>() => assert_type(grab_int() as u8),\n            _ if TypeId::of::<usize>() == TypeId::of::<T>() => assert_type(grab_int() as usize),\n            // Any float types that accept a literal\n            _ if TypeId::of::<f64>() == TypeId::of::<T>() => assert_type(grab_float()),\n            _ if TypeId::of::<f32>() == TypeId::of::<T>() => assert_type(grab_float() as f32),\n            // Any bool types that accept a literal\n            _ if TypeId::of::<bool>() == TypeId::of::<T>() => assert_type(grab_bool()),\n            _ => panic!(\"Unsupported component property type\"),\n        }\n    }\n\n    pub fn render_formatted(&self, segments: &FmtedSegments) -> String {\n        segments.render_with(&self.dynamic_text)\n    }\n}\n#[doc(hidden)]\npub struct DynamicValuePool {\n    dynamic_attributes: Box<[Box<[Attribute]>]>,\n    dynamic_nodes: Box<[DynamicNode]>,\n    literal_pool: DynamicLiteralPool,\n}\n\nimpl DynamicValuePool {\n    pub fn new(\n        dynamic_nodes: Vec<DynamicNode>,\n        dynamic_attributes: Vec<Box<[Attribute]>>,\n        literal_pool: DynamicLiteralPool,\n    ) -> Self {\n        Self {\n            dynamic_attributes: dynamic_attributes.into_boxed_slice(),\n            dynamic_nodes: dynamic_nodes.into_boxed_slice(),\n            literal_pool,\n        }\n    }\n\n    pub fn render_with(&mut self, hot_reload: &HotReloadedTemplate) -> VNode {\n        // Get the node_paths from a depth first traversal of the template\n        let key = hot_reload\n            .key\n            .as_ref()\n            .map(|key| self.literal_pool.render_formatted(key));\n        let dynamic_nodes = hot_reload\n            .dynamic_nodes\n            .iter()\n            .map(|node| self.render_dynamic_node(node))\n            .collect();\n        let dynamic_attrs = hot_reload\n            .dynamic_attributes\n            .iter()\n            .map(|attr| self.render_attribute(attr))\n            .collect();\n\n        VNode::new(key, hot_reload.template, dynamic_nodes, dynamic_attrs)\n    }\n\n    fn render_dynamic_node(&mut self, node: &HotReloadDynamicNode) -> DynamicNode {\n        match node {\n            // If the node is dynamic, take it from the pool and return it\n            HotReloadDynamicNode::Dynamic(id) => self.dynamic_nodes[*id].clone(),\n            // Otherwise, format the text node and return it\n            HotReloadDynamicNode::Formatted(segments) => DynamicNode::Text(VText {\n                value: self.literal_pool.render_formatted(segments),\n            }),\n        }\n    }\n\n    fn render_attribute(&mut self, attr: &HotReloadDynamicAttribute) -> Box<[Attribute]> {\n        match attr {\n            HotReloadDynamicAttribute::Dynamic(id) => self.dynamic_attributes[*id].clone(),\n            HotReloadDynamicAttribute::Named(NamedAttribute {\n                name,\n                namespace,\n                value,\n            }) => Box::new([Attribute {\n                name,\n                namespace: *namespace,\n                value: match value {\n                    HotReloadAttributeValue::Literal(HotReloadLiteral::Fmted(segments)) => {\n                        AttributeValue::Text(self.literal_pool.render_formatted(segments))\n                    }\n                    HotReloadAttributeValue::Literal(HotReloadLiteral::Float(f)) => {\n                        AttributeValue::Float(*f)\n                    }\n                    HotReloadAttributeValue::Literal(HotReloadLiteral::Int(i)) => {\n                        AttributeValue::Int(*i)\n                    }\n                    HotReloadAttributeValue::Literal(HotReloadLiteral::Bool(b)) => {\n                        AttributeValue::Bool(*b)\n                    }\n                    HotReloadAttributeValue::Dynamic(id) => {\n                        self.dynamic_attributes[*id][0].value.clone()\n                    }\n                },\n                volatile: false,\n            }]),\n        }\n    }\n}\n\n#[doc(hidden)]\n#[derive(Debug, Clone, PartialEq)]\n#[cfg_attr(feature = \"serialize\", derive(serde::Serialize, serde::Deserialize))]\npub struct HotReloadTemplateWithLocation {\n    pub key: TemplateGlobalKey,\n    pub template: HotReloadedTemplate,\n}\n\n#[doc(hidden)]\n#[derive(Debug, Clone, PartialEq, Hash, PartialOrd, Eq, Ord)]\n#[cfg_attr(feature = \"serialize\", derive(serde::Serialize, serde::Deserialize))]\npub struct TemplateGlobalKey {\n    pub file: String,\n    pub line: usize,\n    pub column: usize,\n    pub index: usize,\n}\n\ntype StaticTemplateArray = &'static [TemplateNode];\n\n#[doc(hidden)]\n#[derive(Debug, PartialEq, Clone)]\n#[cfg_attr(feature = \"serialize\", derive(serde::Serialize, serde::Deserialize))]\npub struct HotReloadedTemplate {\n    pub key: Option<FmtedSegments>,\n    pub dynamic_nodes: Vec<HotReloadDynamicNode>,\n    pub dynamic_attributes: Vec<HotReloadDynamicAttribute>,\n    pub component_values: Vec<HotReloadLiteral>,\n    #[cfg_attr(\n        feature = \"serialize\",\n        serde(deserialize_with = \"crate::nodes::deserialize_leaky\")\n    )]\n    pub roots: StaticTemplateArray,\n    /// The template that is computed from the hot reload roots\n    template: Template,\n}\n\nimpl HotReloadedTemplate {\n    pub fn new(\n        key: Option<FmtedSegments>,\n        dynamic_nodes: Vec<HotReloadDynamicNode>,\n        dynamic_attributes: Vec<HotReloadDynamicAttribute>,\n        component_values: Vec<HotReloadLiteral>,\n        roots: &'static [TemplateNode],\n    ) -> Self {\n        let node_paths = Self::node_paths(roots);\n        let attr_paths = Self::attr_paths(roots);\n\n        let template = Template {\n            roots,\n            node_paths,\n            attr_paths,\n        };\n        Self {\n            key,\n            dynamic_nodes,\n            dynamic_attributes,\n            component_values,\n            roots,\n            template,\n        }\n    }\n\n    fn node_paths(roots: &'static [TemplateNode]) -> &'static [&'static [u8]] {\n        fn add_node_paths(\n            roots: &[TemplateNode],\n            node_paths: &mut Vec<&'static [u8]>,\n            current_path: Vec<u8>,\n        ) {\n            for (idx, node) in roots.iter().enumerate() {\n                let mut path = current_path.clone();\n                path.push(idx as u8);\n                match node {\n                    TemplateNode::Element { children, .. } => {\n                        add_node_paths(children, node_paths, path);\n                    }\n                    TemplateNode::Text { .. } => {}\n                    TemplateNode::Dynamic { id } => {\n                        debug_assert_eq!(node_paths.len(), *id);\n                        node_paths.push(Box::leak(path.into_boxed_slice()));\n                    }\n                }\n            }\n        }\n\n        let mut node_paths = Vec::new();\n        add_node_paths(roots, &mut node_paths, Vec::new());\n        let leaked: &'static [&'static [u8]] = Box::leak(node_paths.into_boxed_slice());\n        leaked\n    }\n\n    fn attr_paths(roots: &'static [TemplateNode]) -> &'static [&'static [u8]] {\n        fn add_attr_paths(\n            roots: &[TemplateNode],\n            attr_paths: &mut Vec<&'static [u8]>,\n            current_path: Vec<u8>,\n        ) {\n            for (idx, node) in roots.iter().enumerate() {\n                let mut path = current_path.clone();\n                path.push(idx as u8);\n                if let TemplateNode::Element {\n                    children, attrs, ..\n                } = node\n                {\n                    for attr in *attrs {\n                        if let TemplateAttribute::Dynamic { id } = attr {\n                            debug_assert_eq!(attr_paths.len(), *id);\n                            attr_paths.push(Box::leak(path.clone().into_boxed_slice()));\n                        }\n                    }\n                    add_attr_paths(children, attr_paths, path);\n                }\n            }\n        }\n\n        let mut attr_paths = Vec::new();\n        add_attr_paths(roots, &mut attr_paths, Vec::new());\n        let leaked: &'static [&'static [u8]] = Box::leak(attr_paths.into_boxed_slice());\n        leaked\n    }\n}\n\n#[doc(hidden)]\n#[derive(Debug, PartialEq, Clone, Hash)]\n#[cfg_attr(feature = \"serialize\", derive(serde::Serialize, serde::Deserialize))]\npub enum HotReloadDynamicNode {\n    Dynamic(usize),\n    Formatted(FmtedSegments),\n}\n\n#[doc(hidden)]\n#[derive(Debug, PartialEq, Clone, Hash)]\n#[cfg_attr(feature = \"serialize\", derive(serde::Serialize, serde::Deserialize))]\npub enum HotReloadDynamicAttribute {\n    Dynamic(usize),\n    Named(NamedAttribute),\n}\n\n#[doc(hidden)]\n#[derive(Debug, PartialEq, Clone, Hash)]\n#[cfg_attr(feature = \"serialize\", derive(serde::Serialize, serde::Deserialize))]\npub struct NamedAttribute {\n    /// The name of this attribute.\n    #[cfg_attr(\n        feature = \"serialize\",\n        serde(deserialize_with = \"crate::nodes::deserialize_string_leaky\")\n    )]\n    name: StaticStr,\n    /// The namespace of this attribute. Does not exist in the HTML spec\n    #[cfg_attr(\n        feature = \"serialize\",\n        serde(deserialize_with = \"crate::nodes::deserialize_option_leaky\")\n    )]\n    namespace: Option<StaticStr>,\n\n    value: HotReloadAttributeValue,\n}\n\nimpl NamedAttribute {\n    pub fn new(\n        name: &'static str,\n        namespace: Option<&'static str>,\n        value: HotReloadAttributeValue,\n    ) -> Self {\n        Self {\n            name,\n            namespace,\n            value,\n        }\n    }\n}\n\n#[doc(hidden)]\n#[derive(Debug, PartialEq, Clone, Hash)]\n#[cfg_attr(feature = \"serialize\", derive(serde::Serialize, serde::Deserialize))]\npub enum HotReloadAttributeValue {\n    Literal(HotReloadLiteral),\n    Dynamic(usize),\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "3bba5da386855685d6e2a14c3ad214332b761eea",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/packages/mobile/src/lib.rs",
    "func": "#![doc = include_str!(\"../README.md\")]\n#![doc(html_logo_url = \"https://avatars.githubusercontent.com/u/79236386\")]\n#![doc(html_favicon_url = \"https://avatars.githubusercontent.com/u/79236386\")]\n\npub use dioxus_desktop::*;\nuse dioxus_lib::prelude::*;\nuse std::sync::Mutex;\n\npub mod launch_bindings {\n    use std::any::Any;\n\n    use super::*;\n    pub fn launch(\n        root: fn() -> Element,\n        _contexts: Vec<Box<dyn Fn() -> Box<dyn Any> + Send + Sync>>,\n        _platform_config: Vec<Box<dyn Any>>,\n    ) {\n        super::launch(root);\n    }\n\n    pub fn launch_virtual_dom(_virtual_dom: VirtualDom, _desktop_config: Config) -> ! {\n        todo!()\n    }\n}\n\n/// Launch via the binding API\npub fn launch(incoming: fn() -> Element) {\n    #[cfg(target_os = \"android\")]\n    {\n        *APP_FN_PTR.lock().unwrap() = Some(incoming);\n    }\n\n    #[cfg(not(target_os = \"android\"))]\n    {\n        dioxus_desktop::launch::launch(incoming, vec![], Default::default());\n    }\n}\n\nstatic APP_FN_PTR: Mutex<Option<fn() -> Element>> = Mutex::new(None);\n\npub fn root() {\n    let app = APP_FN_PTR\n        .lock()\n        .expect(\"APP_FN_PTR lock failed\")\n        .expect(\"Android to have set the app trampoline\");\n\n    dioxus_desktop::launch::launch(app, vec![], Default::default());\n}\n\n/// Expose the `Java_dev_dioxus_main_WryActivity_create` function to the JNI layer.\n/// We hardcode these to have a single trampoline for host Java code to call into.\n///\n/// This saves us from having to plumb the top-level package name all the way down into\n/// this file. This is better for modularity (ie just call dioxus' main to run the app) as\n/// well as cache thrashing since this crate doesn't rely on external env vars.\n///\n/// The CLI is expecting to find `dev.dioxus.main` in the final library. If you find a need to\n/// change this, you'll need to change the CLI as well.\n#[cfg(target_os = \"android\")]\n#[no_mangle]\n#[inline(never)]\npub extern \"C\" fn start_app() {\n    tao::android_binding!(dev_dioxus, main, WryActivity, wry::android_setup, root, tao);\n    wry::android_binding!(dev_dioxus, main, wry);\n}\n\n/// Call our `main` function to initialize the rust runtime and set the launch binding trampoline\n#[cfg(target_os = \"android\")]\n#[no_mangle]\n#[inline(never)]\npub extern \"C\" fn JNI_OnLoad(\n    _vm: *mut libc::c_void,\n    _reserved: *mut libc::c_void,\n) -> jni::sys::jint {\n    // we're going to find the `main` symbol using dlsym directly and call it\n    unsafe {\n        let mut main_fn_ptr = libc::dlsym(libc::RTLD_DEFAULT, b\"main\\0\".as_ptr() as _);\n\n        if main_fn_ptr.is_null() {\n            main_fn_ptr = libc::dlsym(libc::RTLD_DEFAULT, b\"_main\\0\".as_ptr() as _);\n        }\n\n        if main_fn_ptr.is_null() {\n            panic!(\"Failed to find main symbol\");\n        }\n\n        let main_fn: extern \"C\" fn() = std::mem::transmute(main_fn_ptr);\n        main_fn();\n    };\n\n    jni::sys::JNI_VERSION_1_6\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "7ea9cfe88ea1936d0bb8b2d2036768347486623a",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/examples/hash_fragment_state.rs",
    "func": "//! This example shows how to use the hash segment to store state in the url.\n//!\n//! You can set up two way data binding between the url hash and signals.\n//!\n//! Run this example on desktop with  \n//! ```sh\n//! dx serve --example hash_fragment_state --features=ciborium,base64\n//! ```\n//! Or on web with\n//! ```sh\n//! dx serve --platform web --features web --example hash_fragment_state --features=ciborium,base64 -- --no-default-features\n//! ```\n\nuse std::{fmt::Display, str::FromStr};\n\nuse base64::engine::general_purpose::STANDARD;\nuse base64::Engine;\nuse dioxus::prelude::*;\nuse serde::{Deserialize, Serialize};\n\nfn main() {\n    dioxus::launch(|| {\n        rsx! {\n            Router::<Route> {}\n        }\n    });\n}\n\n#[derive(Routable, Clone, Debug, PartialEq)]\n#[rustfmt::skip]\nenum Route {\n    #[route(\"/#:url_hash\")]\n    Home {\n        url_hash: State,\n    },\n}\n\n// You can use a custom type with the hash segment as long as it implements Display, FromStr and Default\n#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]\nstruct State {\n    counters: Vec<usize>,\n}\n\n// Display the state in a way that can be parsed by FromStr\nimpl Display for State {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        let mut serialized = Vec::new();\n        if ciborium::into_writer(self, &mut serialized).is_ok() {\n            write!(f, \"{}\", STANDARD.encode(serialized))?;\n        }\n        Ok(())\n    }\n}\n\nenum StateParseError {\n    DecodeError(base64::DecodeError),\n    CiboriumError(ciborium::de::Error<std::io::Error>),\n}\n\nimpl std::fmt::Display for StateParseError {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            Self::DecodeError(err) => write!(f, \"Failed to decode base64: {}\", err),\n            Self::CiboriumError(err) => write!(f, \"Failed to deserialize: {}\", err),\n        }\n    }\n}\n\n// Parse the state from a string that was created by Display\nimpl FromStr for State {\n    type Err = StateParseError;\n\n    fn from_str(s: &str) -> Result<Self, Self::Err> {\n        let decompressed = STANDARD\n            .decode(s.as_bytes())\n            .map_err(StateParseError::DecodeError)?;\n        let parsed = ciborium::from_reader(std::io::Cursor::new(decompressed))\n            .map_err(StateParseError::CiboriumError)?;\n        Ok(parsed)\n    }\n}\n\n#[component]\nfn Home(url_hash: ReadOnlySignal<State>) -> Element {\n    // The initial state of the state comes from the url hash\n    let mut state = use_signal(&*url_hash);\n\n    // Change the state signal when the url hash changes\n    use_memo(move || {\n        if *state.peek() != *url_hash.read() {\n            state.set(url_hash());\n        }\n    });\n\n    // Change the url hash when the state changes\n    use_memo(move || {\n        if *state.read() != *url_hash.peek() {\n            navigator().replace(Route::Home { url_hash: state() });\n        }\n    });\n\n    rsx! {\n        button {\n            onclick: move |_| state.write().counters.clear(),\n            \"Reset\"\n        }\n        button {\n            onclick: move |_| {\n                state.write().counters.push(0);\n            },\n            \"Add Counter\"\n        }\n        for counter in 0..state.read().counters.len() {\n            div {\n                button {\n                    onclick: move |_| {\n                        state.write().counters.remove(counter);\n                    },\n                    \"Remove\"\n                }\n                button {\n                    onclick: move |_| {\n                        state.write().counters[counter] += 1;\n                    },\n                    \"Count: {state.read().counters[counter]}\"\n                }\n            }\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "147193117ba72ffaff029ad02e45b65fe91824c1",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/examples/simple_list.rs",
    "func": "//! A few ways of mapping elements into rsx! syntax\n//!\n//! Rsx allows anything that's an iterator where the output type implements Into<Element>, so you can use any of the following:\n\nuse dioxus::prelude::*;\n\nfn main() {\n    dioxus::launch(app);\n}\n\nfn app() -> Element {\n    rsx!(\n        div {\n            // Use Map directly to lazily pull elements\n            {(0..10).map(|f| rsx! { \"{f}\" })}\n\n            // Collect into an intermediate collection if necessary, and call into_iter\n            {[\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"]\n                .into_iter()\n                .map(|f| rsx! { \"{f}\" })\n                .collect::<Vec<_>>()\n                .into_iter()}\n\n            // Use optionals\n            {Some(rsx! { \"Some\" })}\n\n            // use a for loop where the body itself is RSX\n            for name in 0..10 {\n                div { \"{name}\" }\n            }\n\n            // Or even use an unterminated conditional\n            if true {\n                \"hello world!\"\n            }\n        }\n    )\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "7af3e83455873b7e08f67afde9b8e5f78d41d0c9",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/dioxus/examples/fullstack-desktop/src/main.rs",
    "func": "#![allow(non_snake_case)]\nuse dioxus::prelude::*;\n\nfn main() {\n    // Set the url of the server where server functions are hosted.\n    #[cfg(not(feature = \"server\"))]\n    dioxus::fullstack::prelude::server_fn::client::set_server_url(\"http://127.0.0.1:8080\");\n    dioxus::launch(app);\n}\n\npub fn app() -> Element {\n    let mut count = use_signal(|| 0);\n    let mut text = use_signal(|| \"...\".to_string());\n\n    rsx! {\n        h1 { \"High-Five counter: {count}\" }\n        button { onclick: move |_| count += 1, \"Up high!\" }\n        button { onclick: move |_| count -= 1, \"Down low!\" }\n        button {\n            onclick: move |_| async move {\n                if let Ok(data) = get_server_data().await {\n                    println!(\"Client received: {}\", data);\n                    text.set(data.clone());\n                    post_server_data(data).await.unwrap();\n                }\n            },\n            \"Run a server function\"\n        }\n        \"Server said: {text}\"\n    }\n}\n\n#[server(PostServerData)]\nasync fn post_server_data(data: String) -> Result<(), ServerFnError> {\n    println!(\"Server received: {}\", data);\n\n    Ok(())\n}\n\n#[server(GetServerData)]\nasync fn get_server_data() -> Result<String, ServerFnError> {\n    Ok(\"Hello from the server!\".to_string())\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "b974288901a7663c99759b5bb26bf6721cb85cd9",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/json/tests/regression/issue795.rs",
    "func": "#![allow(clippy::assertions_on_result_states)]\n\nuse serde::de::{\n    Deserialize, Deserializer, EnumAccess, IgnoredAny, MapAccess, VariantAccess, Visitor,\n};\nuse serde_json::json;\nuse std::fmt;\n\n#[derive(Debug)]\npub enum Enum {\n    Variant {\n        #[allow(dead_code)]\n        x: u8,\n    },\n}\n\nimpl<'de> Deserialize<'de> for Enum {\n    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>\n    where\n        D: Deserializer<'de>,\n    {\n        struct EnumVisitor;\n\n        impl<'de> Visitor<'de> for EnumVisitor {\n            type Value = Enum;\n\n            fn expecting(&self, formatter: &mut fmt::Formatter) -> fmt::Result {\n                formatter.write_str(\"enum Enum\")\n            }\n\n            fn visit_enum<A>(self, data: A) -> Result<Self::Value, A::Error>\n            where\n                A: EnumAccess<'de>,\n            {\n                let (IgnoredAny, variant) = data.variant()?;\n                variant.struct_variant(&[\"x\"], self)\n            }\n\n            fn visit_map<A>(self, mut data: A) -> Result<Self::Value, A::Error>\n            where\n                A: MapAccess<'de>,\n            {\n                let mut x = 0;\n                if let Some((IgnoredAny, value)) = data.next_entry()? {\n                    x = value;\n                }\n                Ok(Enum::Variant { x })\n            }\n        }\n\n        deserializer.deserialize_enum(\"Enum\", &[\"Variant\"], EnumVisitor)\n    }\n}\n\n#[test]\nfn test() {\n    let s = r#\" {\"Variant\":{\"x\":0,\"y\":0}} \"#;\n    assert!(serde_json::from_str::<Enum>(s).is_err());\n\n    let j = json!({\"Variant\":{\"x\":0,\"y\":0}});\n    assert!(serde_json::from_value::<Enum>(j).is_err());\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "4d5722d5ae162d60a963f8041d08552c53e17e6e",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/json/src/lexical/shift.rs",
    "func": "// Adapted from https://github.com/Alexhuszagh/rust-lexical.\n\n//! Bit-shift helpers.\n\nuse super::float::ExtendedFloat;\nuse core::mem;\n\n// Shift extended-precision float right `shift` bytes.\n#[inline]\npub(crate) fn shr(fp: &mut ExtendedFloat, shift: i32) {\n    let bits: u64 = mem::size_of::<u64>() as u64 * 8;\n    debug_assert!((shift as u64) < bits, \"shr() overflow in shift right.\");\n\n    fp.mant >>= shift;\n    fp.exp += shift;\n}\n\n// Shift extended-precision float right `shift` bytes.\n//\n// Accepts when the shift is the same as the type size, and\n// sets the value to 0.\n#[inline]\npub(crate) fn overflowing_shr(fp: &mut ExtendedFloat, shift: i32) {\n    let bits: u64 = mem::size_of::<u64>() as u64 * 8;\n    debug_assert!(\n        (shift as u64) <= bits,\n        \"overflowing_shr() overflow in shift right.\"\n    );\n\n    fp.mant = if shift as u64 == bits {\n        0\n    } else {\n        fp.mant >> shift\n    };\n    fp.exp += shift;\n}\n\n// Shift extended-precision float left `shift` bytes.\n#[inline]\npub(crate) fn shl(fp: &mut ExtendedFloat, shift: i32) {\n    let bits: u64 = mem::size_of::<u64>() as u64 * 8;\n    debug_assert!((shift as u64) < bits, \"shl() overflow in shift left.\");\n\n    fp.mant <<= shift;\n    fp.exp -= shift;\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "fc2ac21d3e31c694825d912662e00ac5861d4e7c",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tauri/crates/tauri-macros/src/command/handler.rs",
    "func": "// Copyright 2019-2024 Tauri Programme within The Commons Conservancy\n// SPDX-License-Identifier: Apache-2.0\n// SPDX-License-Identifier: MIT\n\nuse quote::format_ident;\nuse syn::{\n  parse::{Parse, ParseBuffer, ParseStream},\n  Attribute, Ident, Path, Token,\n};\n\nstruct CommandDef {\n  path: Path,\n  attrs: Vec<Attribute>,\n}\n\nimpl Parse for CommandDef {\n  fn parse(input: ParseStream) -> syn::Result<Self> {\n    let attrs = input.call(Attribute::parse_outer)?;\n    let path = input.parse()?;\n\n    Ok(CommandDef { path, attrs })\n  }\n}\n\n/// The items parsed from [`generate_handle!`](crate::generate_handle).\npub struct Handler {\n  command_defs: Vec<CommandDef>,\n  commands: Vec<Ident>,\n  wrappers: Vec<Path>,\n}\n\nimpl Parse for Handler {\n  fn parse(input: &ParseBuffer<'_>) -> syn::Result<Self> {\n    let command_defs = input.parse_terminated(CommandDef::parse, Token![,])?;\n\n    // parse the command names and wrappers from the passed paths\n    let (commands, wrappers) = command_defs\n      .iter()\n      .map(|command_def| {\n        let mut wrapper = command_def.path.clone();\n        let last = super::path_to_command(&mut wrapper);\n\n        // the name of the actual command function\n        let command = last.ident.clone();\n\n        // set the path to the command function wrapper\n        last.ident = super::format_command_wrapper(&command);\n\n        (command, wrapper)\n      })\n      .unzip();\n\n    Ok(Self {\n      command_defs: command_defs.into_iter().collect(), // remove punctuation separators\n      commands,\n      wrappers,\n    })\n  }\n}\n\nimpl From<Handler> for proc_macro::TokenStream {\n  fn from(\n    Handler {\n      command_defs,\n      commands,\n      wrappers,\n    }: Handler,\n  ) -> Self {\n    let cmd = format_ident!(\"__tauri_cmd__\");\n    let invoke = format_ident!(\"__tauri_invoke__\");\n    let (paths, attrs): (Vec<Path>, Vec<Vec<Attribute>>) = command_defs\n      .into_iter()\n      .map(|def| (def.path, def.attrs))\n      .unzip();\n    quote::quote!(move |#invoke| {\n      let #cmd = #invoke.message.command();\n      match #cmd {\n        #(#(#attrs)* stringify!(#commands) => #wrappers!(#paths, #invoke),)*\n        _ => {\n          return false;\n        },\n      }\n    })\n    .into()\n  }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "a5a9e86e67ab8939d0b89d6c958df1aebeb0fb5d",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tauri/crates/tauri/src/menu/icon.rs",
    "func": "// Copyright 2019-2024 Tauri Programme within The Commons Conservancy\n// SPDX-License-Identifier: Apache-2.0\n// SPDX-License-Identifier: MIT\n\nuse std::sync::Arc;\n\nuse super::run_item_main_thread;\nuse super::{IconMenuItem, NativeIcon};\nuse crate::menu::IconMenuItemInner;\nuse crate::run_main_thread;\nuse crate::{image::Image, menu::MenuId, AppHandle, Manager, Runtime};\n\nimpl<R: Runtime> IconMenuItem<R> {\n  /// Create a new menu item.\n  ///\n  /// - `text` could optionally contain an `&` before a character to assign this character as the mnemonic\n  ///   for this menu item. To display a `&` without assigning a mnemenonic, use `&&`.\n  pub fn new<M, T, A>(\n    manager: &M,\n    text: T,\n    enabled: bool,\n    icon: Option<Image<'_>>,\n    accelerator: Option<A>,\n  ) -> crate::Result<Self>\n  where\n    M: Manager<R>,\n    T: AsRef<str>,\n    A: AsRef<str>,\n  {\n    let handle = manager.app_handle();\n    let app_handle = handle.clone();\n\n    let text = text.as_ref().to_owned();\n    let accelerator = accelerator.and_then(|s| s.as_ref().parse().ok());\n    let icon = match icon {\n      Some(i) => Some(i.try_into()?),\n      None => None,\n    };\n\n    let item = run_main_thread!(handle, || {\n      let item = muda::IconMenuItem::new(text, enabled, icon, accelerator);\n      IconMenuItemInner {\n        id: item.id().clone(),\n        inner: Some(item),\n        app_handle,\n      }\n    })?;\n\n    Ok(Self(Arc::new(item)))\n  }\n\n  /// Create a new menu item with the specified id.\n  ///\n  /// - `text` could optionally contain an `&` before a character to assign this character as the mnemonic\n  ///   for this menu item. To display a `&` without assigning a mnemenonic, use `&&`.\n  pub fn with_id<M, I, T, A>(\n    manager: &M,\n    id: I,\n    text: T,\n    enabled: bool,\n    icon: Option<Image<'_>>,\n    accelerator: Option<A>,\n  ) -> crate::Result<Self>\n  where\n    M: Manager<R>,\n    I: Into<MenuId>,\n    T: AsRef<str>,\n    A: AsRef<str>,\n  {\n    let handle = manager.app_handle();\n    let app_handle = handle.clone();\n\n    let id = id.into();\n    let text = text.as_ref().to_owned();\n    let accelerator = accelerator.and_then(|s| s.as_ref().parse().ok());\n    let icon = match icon {\n      Some(i) => Some(i.try_into()?),\n      None => None,\n    };\n\n    let item = run_main_thread!(handle, || {\n      let item = muda::IconMenuItem::with_id(id.clone(), text, enabled, icon, accelerator);\n      IconMenuItemInner {\n        id,\n        inner: Some(item),\n        app_handle,\n      }\n    })?;\n\n    Ok(Self(Arc::new(item)))\n  }\n\n  /// Create a new icon menu item but with a native icon.\n  ///\n  /// See [`IconMenuItem::new`] for more info.\n  ///\n  /// ## Platform-specific:\n  ///\n  /// - **Windows / Linux**: Unsupported.\n  pub fn with_native_icon<M, T, A>(\n    manager: &M,\n    text: T,\n    enabled: bool,\n    native_icon: Option<NativeIcon>,\n    accelerator: Option<A>,\n  ) -> crate::Result<Self>\n  where\n    M: Manager<R>,\n    T: AsRef<str>,\n    A: AsRef<str>,\n  {\n    let handle = manager.app_handle();\n    let app_handle = handle.clone();\n\n    let text = text.as_ref().to_owned();\n    let icon = native_icon.map(Into::into);\n    let accelerator = accelerator.and_then(|s| s.as_ref().parse().ok());\n\n    let item = run_main_thread!(handle, || {\n      let item = muda::IconMenuItem::with_native_icon(text, enabled, icon, accelerator);\n      IconMenuItemInner {\n        id: item.id().clone(),\n        inner: Some(item),\n        app_handle,\n      }\n    })?;\n\n    Ok(Self(Arc::new(item)))\n  }\n\n  /// Create a new icon menu item with the specified id but with a native icon.\n  ///\n  /// See [`IconMenuItem::new`] for more info.\n  ///\n  /// ## Platform-specific:\n  ///\n  /// - **Windows / Linux**: Unsupported.\n  pub fn with_id_and_native_icon<M, I, T, A>(\n    manager: &M,\n    id: I,\n    text: T,\n    enabled: bool,\n    native_icon: Option<NativeIcon>,\n    accelerator: Option<A>,\n  ) -> crate::Result<Self>\n  where\n    M: Manager<R>,\n    I: Into<MenuId>,\n    T: AsRef<str>,\n    A: AsRef<str>,\n  {\n    let handle = manager.app_handle();\n    let app_handle = handle.clone();\n\n    let id = id.into();\n    let text = text.as_ref().to_owned();\n    let icon = native_icon.map(Into::into);\n    let accelerator = accelerator.and_then(|s| s.as_ref().parse().ok());\n\n    let item = run_main_thread!(handle, || {\n      let item =\n        muda::IconMenuItem::with_id_and_native_icon(id.clone(), text, enabled, icon, accelerator);\n      IconMenuItemInner {\n        id,\n        inner: Some(item),\n        app_handle,\n      }\n    })?;\n\n    Ok(Self(Arc::new(item)))\n  }\n\n  /// The application handle associated with this type.\n  pub fn app_handle(&self) -> &AppHandle<R> {\n    &self.0.app_handle\n  }\n\n  /// Returns a unique identifier associated with this menu item.\n  pub fn id(&self) -> &MenuId {\n    &self.0.id\n  }\n\n  /// Get the text for this menu item.\n  pub fn text(&self) -> crate::Result<String> {\n    run_item_main_thread!(self, |self_: Self| (*self_.0).as_ref().text())\n  }\n\n  /// Set the text for this menu item. `text` could optionally contain\n  /// an `&` before a character to assign this character as the mnemonic\n  /// for this menu item. To display a `&` without assigning a mnemenonic, use `&&`.\n  pub fn set_text<S: AsRef<str>>(&self, text: S) -> crate::Result<()> {\n    let text = text.as_ref().to_string();\n    run_item_main_thread!(self, |self_: Self| (*self_.0).as_ref().set_text(text))\n  }\n\n  /// Get whether this menu item is enabled or not.\n  pub fn is_enabled(&self) -> crate::Result<bool> {\n    run_item_main_thread!(self, |self_: Self| (*self_.0).as_ref().is_enabled())\n  }\n\n  /// Enable or disable this menu item.\n  pub fn set_enabled(&self, enabled: bool) -> crate::Result<()> {\n    run_item_main_thread!(self, |self_: Self| (*self_.0).as_ref().set_enabled(enabled))\n  }\n\n  /// Set this menu item accelerator.\n  pub fn set_accelerator<S: AsRef<str>>(&self, accelerator: Option<S>) -> crate::Result<()> {\n    let accel = accelerator.and_then(|s| s.as_ref().parse().ok());\n    run_item_main_thread!(self, |self_: Self| {\n      (*self_.0).as_ref().set_accelerator(accel)\n    })?\n    .map_err(Into::into)\n  }\n\n  /// Change this menu item icon or remove it.\n  pub fn set_icon(&self, icon: Option<Image<'_>>) -> crate::Result<()> {\n    let icon = match icon {\n      Some(i) => Some(i.try_into()?),\n      None => None,\n    };\n    run_item_main_thread!(self, |self_: Self| (*self_.0).as_ref().set_icon(icon))\n  }\n\n  /// Change this menu item icon to a native image or remove it.\n  ///\n  /// ## Platform-specific:\n  ///\n  /// - **Windows / Linux**: Unsupported.\n  pub fn set_native_icon(&self, _icon: Option<NativeIcon>) -> crate::Result<()> {\n    #[cfg(target_os = \"macos\")]\n    return run_item_main_thread!(self, |self_: Self| {\n      (*self_.0).as_ref().set_native_icon(_icon.map(Into::into))\n    });\n    #[allow(unreachable_code)]\n    Ok(())\n  }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "cd56ceaf15072845a656ad1bb805d5738af49a39",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tauri/crates/tauri-runtime-wry/src/window/macos.rs",
    "func": "// Copyright 2019-2024 Tauri Programme within The Commons Conservancy\n// SPDX-License-Identifier: Apache-2.0\n// SPDX-License-Identifier: MIT\n\nuse objc2_app_kit::{NSBackingStoreType, NSWindow, NSWindowStyleMask};\nuse objc2_foundation::MainThreadMarker;\nuse tao::platform::macos::WindowExtMacOS;\n\nimpl super::WindowExt for tao::window::Window {\n  // based on electron implementation\n  // https://github.com/electron/electron/blob/15db63e26df3e3d59ce6281f030624f746518511/shell/browser/native_window_mac.mm#L474\n  fn set_enabled(&self, enabled: bool) {\n    let ns_window: &NSWindow = unsafe { &*self.ns_window().cast() };\n    if !enabled {\n      let frame = ns_window.frame();\n      let mtm = MainThreadMarker::new()\n        .expect(\"`Window::set_enabled` can only be called on the main thread\");\n      let sheet = unsafe {\n        NSWindow::initWithContentRect_styleMask_backing_defer(\n          mtm.alloc(),\n          frame,\n          NSWindowStyleMask::Titled,\n          NSBackingStoreType::NSBackingStoreBuffered,\n          false,\n        )\n      };\n      unsafe { sheet.setAlphaValue(0.5) };\n      unsafe { ns_window.beginSheet_completionHandler(&sheet, None) };\n    } else if let Some(attached) = unsafe { ns_window.attachedSheet() } {\n      unsafe { ns_window.endSheet(&attached) };\n    }\n  }\n\n  fn is_enabled(&self) -> bool {\n    let ns_window: &NSWindow = unsafe { &*self.ns_window().cast() };\n    unsafe { ns_window.attachedSheet() }.is_none()\n  }\n\n  fn center(&self) {\n    let ns_window: &NSWindow = unsafe { &*self.ns_window().cast() };\n    ns_window.center();\n  }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "6c9d42484043b2efd6a6332b86ec0fc416b7f3fd",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tauri/crates/tauri-runtime/src/lib.rs",
    "func": "// Copyright 2019-2024 Tauri Programme within The Commons Conservancy\n// SPDX-License-Identifier: Apache-2.0\n// SPDX-License-Identifier: MIT\n\n//! Internal runtime between Tauri and the underlying webview runtime.\n//!\n//! None of the exposed API of this crate is stable, and it may break semver\n//! compatibility in the future. The major version only signifies the intended Tauri version.\n\n#![doc(\n  html_logo_url = \"https://github.com/tauri-apps/tauri/raw/dev/.github/icon.png\",\n  html_favicon_url = \"https://github.com/tauri-apps/tauri/raw/dev/.github/icon.png\"\n)]\n#![cfg_attr(docsrs, feature(doc_cfg))]\n\nuse raw_window_handle::DisplayHandle;\nuse serde::{Deserialize, Serialize};\nuse std::{borrow::Cow, fmt::Debug, sync::mpsc::Sender};\nuse tauri_utils::config::Color;\nuse tauri_utils::Theme;\nuse url::Url;\nuse webview::{DetachedWebview, PendingWebview};\n\n/// Types useful for interacting with a user's monitors.\npub mod monitor;\npub mod webview;\npub mod window;\n\nuse dpi::{PhysicalPosition, PhysicalSize, Position, Size};\nuse monitor::Monitor;\nuse window::{\n  CursorIcon, DetachedWindow, PendingWindow, RawWindow, WebviewEvent, WindowEvent,\n  WindowSizeConstraints,\n};\nuse window::{WindowBuilder, WindowId};\n\nuse http::{\n  header::{InvalidHeaderName, InvalidHeaderValue},\n  method::InvalidMethod,\n  status::InvalidStatusCode,\n};\n\n/// UI scaling utilities.\npub use dpi;\n\npub type WindowEventId = u32;\npub type WebviewEventId = u32;\n\n/// A rectangular region.\n#[derive(Clone, Copy, Debug, Serialize)]\npub struct Rect {\n  /// Rect position.\n  pub position: dpi::Position,\n  /// Rect size.\n  pub size: dpi::Size,\n}\n\nimpl Default for Rect {\n  fn default() -> Self {\n    Self {\n      position: Position::Logical((0, 0).into()),\n      size: Size::Logical((0, 0).into()),\n    }\n  }\n}\n\n/// Progress bar status.\n#[derive(Debug, Clone, Copy, Deserialize)]\n#[serde(rename_all = \"camelCase\")]\npub enum ProgressBarStatus {\n  /// Hide progress bar.\n  None,\n  /// Normal state.\n  Normal,\n  /// Indeterminate state. **Treated as Normal on Linux and macOS**\n  Indeterminate,\n  /// Paused state. **Treated as Normal on Linux**\n  Paused,\n  /// Error state. **Treated as Normal on Linux**\n  Error,\n}\n\n/// Progress Bar State\n#[derive(Debug, Deserialize)]\n#[serde(rename_all = \"camelCase\")]\npub struct ProgressBarState {\n  /// The progress bar status.\n  pub status: Option<ProgressBarStatus>,\n  /// The progress bar progress. This can be a value ranging from `0` to `100`\n  pub progress: Option<u64>,\n  /// The `.desktop` filename with the Unity desktop window manager, for example `myapp.desktop` **Linux Only**\n  pub desktop_filename: Option<String>,\n}\n\n/// Type of user attention requested on a window.\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Deserialize)]\n#[serde(tag = \"type\")]\npub enum UserAttentionType {\n  /// ## Platform-specific\n  /// - **macOS:** Bounces the dock icon until the application is in focus.\n  /// - **Windows:** Flashes both the window and the taskbar button until the application is in focus.\n  Critical,\n  /// ## Platform-specific\n  /// - **macOS:** Bounces the dock icon once.\n  /// - **Windows:** Flashes the taskbar button until the application is in focus.\n  Informational,\n}\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Deserialize)]\n#[serde(tag = \"type\")]\npub enum DeviceEventFilter {\n  /// Always filter out device events.\n  Always,\n  /// Filter out device events while the window is not focused.\n  Unfocused,\n  /// Report all device events regardless of window focus.\n  Never,\n}\n\nimpl Default for DeviceEventFilter {\n  fn default() -> Self {\n    Self::Unfocused\n  }\n}\n\n/// Defines the orientation that a window resize will be performed.\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Deserialize)]\npub enum ResizeDirection {\n  East,\n  North,\n  NorthEast,\n  NorthWest,\n  South,\n  SouthEast,\n  SouthWest,\n  West,\n}\n\n#[derive(Debug, thiserror::Error)]\n#[non_exhaustive]\npub enum Error {\n  /// Failed to create webview.\n  #[error(\"failed to create webview: {0}\")]\n  CreateWebview(Box<dyn std::error::Error + Send + Sync>),\n  /// Failed to create window.\n  #[error(\"failed to create window\")]\n  CreateWindow,\n  /// The given window label is invalid.\n  #[error(\"Window labels must only include alphanumeric characters, `-`, `/`, `:` and `_`.\")]\n  InvalidWindowLabel,\n  /// Failed to send message to webview.\n  #[error(\"failed to send message to the webview\")]\n  FailedToSendMessage,\n  /// Failed to receive message from webview.\n  #[error(\"failed to receive message from webview\")]\n  FailedToReceiveMessage,\n  /// Failed to serialize/deserialize.\n  #[error(\"JSON error: {0}\")]\n  Json(#[from] serde_json::Error),\n  /// Failed to load window icon.\n  #[error(\"invalid icon: {0}\")]\n  InvalidIcon(Box<dyn std::error::Error + Send + Sync>),\n  /// Failed to get monitor on window operation.\n  #[error(\"failed to get monitor\")]\n  FailedToGetMonitor,\n  /// Failed to get cursor position.\n  #[error(\"failed to get cursor position\")]\n  FailedToGetCursorPosition,\n  #[error(\"Invalid header name: {0}\")]\n  InvalidHeaderName(#[from] InvalidHeaderName),\n  #[error(\"Invalid header value: {0}\")]\n  InvalidHeaderValue(#[from] InvalidHeaderValue),\n  #[error(\"Invalid status code: {0}\")]\n  InvalidStatusCode(#[from] InvalidStatusCode),\n  #[error(\"Invalid method: {0}\")]\n  InvalidMethod(#[from] InvalidMethod),\n  #[error(\"Infallible error, something went really wrong: {0}\")]\n  Infallible(#[from] std::convert::Infallible),\n  #[error(\"the event loop has been closed\")]\n  EventLoopClosed,\n  #[error(\"Invalid proxy url\")]\n  InvalidProxyUrl,\n  #[error(\"window not found\")]\n  WindowNotFound,\n}\n\n/// Result type.\npub type Result<T> = std::result::Result<T, Error>;\n\n/// Window icon.\n#[derive(Debug, Clone)]\npub struct Icon<'a> {\n  /// RGBA bytes of the icon.\n  pub rgba: Cow<'a, [u8]>,\n  /// Icon width.\n  pub width: u32,\n  /// Icon height.\n  pub height: u32,\n}\n\n/// A type that can be used as an user event.\npub trait UserEvent: Debug + Clone + Send + 'static {}\n\nimpl<T: Debug + Clone + Send + 'static> UserEvent for T {}\n\n/// Event triggered on the event loop run.\n#[derive(Debug)]\n#[non_exhaustive]\npub enum RunEvent<T: UserEvent> {\n  /// Event loop is exiting.\n  Exit,\n  /// Event loop is about to exit\n  ExitRequested {\n    /// The exit code.\n    code: Option<i32>,\n    tx: Sender<ExitRequestedEventAction>,\n  },\n  /// An event associated with a window.\n  WindowEvent {\n    /// The window label.\n    label: String,\n    /// The detailed event.\n    event: WindowEvent,\n  },\n  /// An event associated with a webview.\n  WebviewEvent {\n    /// The webview label.\n    label: String,\n    /// The detailed event.\n    event: WebviewEvent,\n  },\n  /// Application ready.\n  Ready,\n  /// Sent if the event loop is being resumed.\n  Resumed,\n  /// Emitted when all of the event loop's input events have been processed and redraw processing is about to begin.\n  ///\n  /// This event is useful as a place to put your code that should be run after all state-changing events have been handled and you want to do stuff (updating state, performing calculations, etc) that happens as the \u201cmain body\u201d of your event loop.\n  MainEventsCleared,\n  /// Emitted when the user wants to open the specified resource with the app.\n  #[cfg(any(target_os = \"macos\", target_os = \"ios\"))]\n  Opened { urls: Vec<url::Url> },\n  /// Emitted when the NSApplicationDelegate's applicationShouldHandleReopen gets called\n  #[cfg(target_os = \"macos\")]\n  Reopen {\n    /// Indicates whether the NSApplication object found any visible windows in your application.\n    has_visible_windows: bool,\n  },\n  /// A custom event defined by the user.\n  UserEvent(T),\n}\n\n/// Action to take when the event loop is about to exit\n#[derive(Debug)]\npub enum ExitRequestedEventAction {\n  /// Prevent the event loop from exiting\n  Prevent,\n}\n\n/// Application's activation policy. Corresponds to NSApplicationActivationPolicy.\n#[cfg(target_os = \"macos\")]\n#[cfg_attr(docsrs, doc(cfg(target_os = \"macos\")))]\n#[non_exhaustive]\npub enum ActivationPolicy {\n  /// Corresponds to NSApplicationActivationPolicyRegular.\n  Regular,\n  /// Corresponds to NSApplicationActivationPolicyAccessory.\n  Accessory,\n  /// Corresponds to NSApplicationActivationPolicyProhibited.\n  Prohibited,\n}\n\n/// A [`Send`] handle to the runtime.\npub trait RuntimeHandle<T: UserEvent>: Debug + Clone + Send + Sync + Sized + 'static {\n  type Runtime: Runtime<T, Handle = Self>;\n\n  /// Creates an `EventLoopProxy` that can be used to dispatch user events to the main event loop.\n  fn create_proxy(&self) -> <Self::Runtime as Runtime<T>>::EventLoopProxy;\n\n  /// Sets the activation policy for the application.\n  #[cfg(target_os = \"macos\")]\n  #[cfg_attr(docsrs, doc(cfg(target_os = \"macos\")))]\n  fn set_activation_policy(&self, activation_policy: ActivationPolicy) -> Result<()>;\n\n  /// Requests an exit of the event loop.\n  fn request_exit(&self, code: i32) -> Result<()>;\n\n  /// Create a new window.\n  fn create_window<F: Fn(RawWindow) + Send + 'static>(\n    &self,\n    pending: PendingWindow<T, Self::Runtime>,\n    before_window_creation: Option<F>,\n  ) -> Result<DetachedWindow<T, Self::Runtime>>;\n\n  /// Create a new webview.\n  fn create_webview(\n    &self,\n    window_id: WindowId,\n    pending: PendingWebview<T, Self::Runtime>,\n  ) -> Result<DetachedWebview<T, Self::Runtime>>;\n\n  /// Run a task on the main thread.\n  fn run_on_main_thread<F: FnOnce() + Send + 'static>(&self, f: F) -> Result<()>;\n\n  fn display_handle(&self) -> std::result::Result<DisplayHandle, raw_window_handle::HandleError>;\n\n  fn primary_monitor(&self) -> Option<Monitor>;\n  fn monitor_from_point(&self, x: f64, y: f64) -> Option<Monitor>;\n  fn available_monitors(&self) -> Vec<Monitor>;\n\n  fn cursor_position(&self) -> Result<PhysicalPosition<f64>>;\n\n  fn set_theme(&self, theme: Option<Theme>);\n\n  /// Shows the application, but does not automatically focus it.\n  #[cfg(target_os = \"macos\")]\n  #[cfg_attr(docsrs, doc(cfg(target_os = \"macos\")))]\n  fn show(&self) -> Result<()>;\n\n  /// Hides the application.\n  #[cfg(target_os = \"macos\")]\n  #[cfg_attr(docsrs, doc(cfg(target_os = \"macos\")))]\n  fn hide(&self) -> Result<()>;\n\n  /// Finds an Android class in the project scope.\n  #[cfg(target_os = \"android\")]\n  fn find_class<'a>(\n    &self,\n    env: &mut jni::JNIEnv<'a>,\n    activity: &jni::objects::JObject<'_>,\n    name: impl Into<String>,\n  ) -> std::result::Result<jni::objects::JClass<'a>, jni::errors::Error>;\n\n  /// Dispatch a closure to run on the Android context.\n  ///\n  /// The closure takes the JNI env, the Android activity instance and the possibly null webview.\n  #[cfg(target_os = \"android\")]\n  fn run_on_android_context<F>(&self, f: F)\n  where\n    F: FnOnce(&mut jni::JNIEnv, &jni::objects::JObject, &jni::objects::JObject) + Send + 'static;\n}\n\npub trait EventLoopProxy<T: UserEvent>: Debug + Clone + Send + Sync {\n  fn send_event(&self, event: T) -> Result<()>;\n}\n\n#[derive(Default)]\npub struct RuntimeInitArgs {\n  #[cfg(any(\n    target_os = \"linux\",\n    target_os = \"dragonfly\",\n    target_os = \"freebsd\",\n    target_os = \"netbsd\",\n    target_os = \"openbsd\"\n  ))]\n  pub app_id: Option<String>,\n  #[cfg(windows)]\n  pub msg_hook: Option<Box<dyn FnMut(*const std::ffi::c_void) -> bool + 'static>>,\n}\n\n/// The webview runtime interface.\npub trait Runtime<T: UserEvent>: Debug + Sized + 'static {\n  /// The window message dispatcher.\n  type WindowDispatcher: WindowDispatch<T, Runtime = Self>;\n  /// The webview message dispatcher.\n  type WebviewDispatcher: WebviewDispatch<T, Runtime = Self>;\n  /// The runtime handle type.\n  type Handle: RuntimeHandle<T, Runtime = Self>;\n  /// The proxy type.\n  type EventLoopProxy: EventLoopProxy<T>;\n\n  /// Creates a new webview runtime. Must be used on the main thread.\n  fn new(args: RuntimeInitArgs) -> Result<Self>;\n\n  /// Creates a new webview runtime on any thread.\n  #[cfg(any(windows, target_os = \"linux\"))]\n  #[cfg_attr(docsrs, doc(cfg(any(windows, target_os = \"linux\"))))]\n  fn new_any_thread(args: RuntimeInitArgs) -> Result<Self>;\n\n  /// Creates an `EventLoopProxy` that can be used to dispatch user events to the main event loop.\n  fn create_proxy(&self) -> Self::EventLoopProxy;\n\n  /// Gets a runtime handle.\n  fn handle(&self) -> Self::Handle;\n\n  /// Create a new window.\n  fn create_window<F: Fn(RawWindow) + Send + 'static>(\n    &self,\n    pending: PendingWindow<T, Self>,\n    after_window_creation: Option<F>,\n  ) -> Result<DetachedWindow<T, Self>>;\n\n  /// Create a new webview.\n  fn create_webview(\n    &self,\n    window_id: WindowId,\n    pending: PendingWebview<T, Self>,\n  ) -> Result<DetachedWebview<T, Self>>;\n\n  fn primary_monitor(&self) -> Option<Monitor>;\n  fn monitor_from_point(&self, x: f64, y: f64) -> Option<Monitor>;\n  fn available_monitors(&self) -> Vec<Monitor>;\n\n  fn cursor_position(&self) -> Result<PhysicalPosition<f64>>;\n\n  fn set_theme(&self, theme: Option<Theme>);\n\n  /// Sets the activation policy for the application.\n  #[cfg(target_os = \"macos\")]\n  #[cfg_attr(docsrs, doc(cfg(target_os = \"macos\")))]\n  fn set_activation_policy(&mut self, activation_policy: ActivationPolicy);\n\n  /// Shows the application, but does not automatically focus it.\n  #[cfg(target_os = \"macos\")]\n  #[cfg_attr(docsrs, doc(cfg(target_os = \"macos\")))]\n  fn show(&self);\n\n  /// Hides the application.\n  #[cfg(target_os = \"macos\")]\n  #[cfg_attr(docsrs, doc(cfg(target_os = \"macos\")))]\n  fn hide(&self);\n\n  /// Change the device event filter mode.\n  ///\n  /// Since the DeviceEvent capture can lead to high CPU usage for unfocused windows, [`tao`]\n  /// will ignore them by default for unfocused windows on Windows. This method allows changing\n  /// the filter to explicitly capture them again.\n  ///\n  /// ## Platform-specific\n  ///\n  /// - ** Linux / macOS / iOS / Android**: Unsupported.\n  ///\n  /// [`tao`]: https://crates.io/crates/tao\n  fn set_device_event_filter(&mut self, filter: DeviceEventFilter);\n\n  /// Runs an iteration of the runtime event loop and returns control flow to the caller.\n  #[cfg(desktop)]\n  fn run_iteration<F: FnMut(RunEvent<T>) + 'static>(&mut self, callback: F);\n\n  /// Run the webview runtime.\n  fn run<F: FnMut(RunEvent<T>) + 'static>(self, callback: F);\n}\n\n/// Webview dispatcher. A thread-safe handle to the webview APIs.\npub trait WebviewDispatch<T: UserEvent>: Debug + Clone + Send + Sync + Sized + 'static {\n  /// The runtime this [`WebviewDispatch`] runs under.\n  type Runtime: Runtime<T>;\n\n  /// Run a task on the main thread.\n  fn run_on_main_thread<F: FnOnce() + Send + 'static>(&self, f: F) -> Result<()>;\n\n  /// Registers a webview event handler.\n  fn on_webview_event<F: Fn(&WebviewEvent) + Send + 'static>(&self, f: F) -> WebviewEventId;\n\n  /// Runs a closure with the platform webview object as argument.\n  fn with_webview<F: FnOnce(Box<dyn std::any::Any>) + Send + 'static>(&self, f: F) -> Result<()>;\n\n  /// Open the web inspector which is usually called devtools.\n  #[cfg(any(debug_assertions, feature = \"devtools\"))]\n  fn open_devtools(&self);\n\n  /// Close the web inspector which is usually called devtools.\n  #[cfg(any(debug_assertions, feature = \"devtools\"))]\n  fn close_devtools(&self);\n\n  /// Gets the devtools window's current open state.\n  #[cfg(any(debug_assertions, feature = \"devtools\"))]\n  fn is_devtools_open(&self) -> Result<bool>;\n\n  // GETTERS\n\n  /// Returns the webview's current URL.\n  fn url(&self) -> Result<String>;\n\n  /// Returns the webview's bounds.\n  fn bounds(&self) -> Result<Rect>;\n\n  /// Returns the position of the top-left hand corner of the webviews's client area relative to the top-left hand corner of the window.\n  fn position(&self) -> Result<PhysicalPosition<i32>>;\n\n  /// Returns the physical size of the webviews's client area.\n  fn size(&self) -> Result<PhysicalSize<u32>>;\n\n  // SETTER\n\n  /// Navigate to the given URL.\n  fn navigate(&self, url: Url) -> Result<()>;\n\n  /// Opens the dialog to prints the contents of the webview.\n  fn print(&self) -> Result<()>;\n\n  /// Closes the webview.\n  fn close(&self) -> Result<()>;\n\n  /// Sets the webview's bounds.\n  fn set_bounds(&self, bounds: Rect) -> Result<()>;\n\n  /// Resizes the webview.\n  fn set_size(&self, size: Size) -> Result<()>;\n\n  /// Updates the webview position.\n  fn set_position(&self, position: Position) -> Result<()>;\n\n  /// Bring the window to front and focus the webview.\n  fn set_focus(&self) -> Result<()>;\n\n  /// Hide the webview\n  fn hide(&self) -> Result<()>;\n\n  /// Show the webview\n  fn show(&self) -> Result<()>;\n\n  /// Executes javascript on the window this [`WindowDispatch`] represents.\n  fn eval_script<S: Into<String>>(&self, script: S) -> Result<()>;\n\n  /// Moves the webview to the given window.\n  fn reparent(&self, window_id: WindowId) -> Result<()>;\n\n  /// Sets whether the webview should automatically grow and shrink its size and position when the parent window resizes.\n  fn set_auto_resize(&self, auto_resize: bool) -> Result<()>;\n\n  /// Set the webview zoom level\n  fn set_zoom(&self, scale_factor: f64) -> Result<()>;\n\n  /// Set the webview background.\n  fn set_background_color(&self, color: Option<Color>) -> Result<()>;\n\n  /// Clear all browsing data for this webview.\n  fn clear_all_browsing_data(&self) -> Result<()>;\n}\n\n/// Window dispatcher. A thread-safe handle to the window APIs.\npub trait WindowDispatch<T: UserEvent>: Debug + Clone + Send + Sync + Sized + 'static {\n  /// The runtime this [`WindowDispatch`] runs under.\n  type Runtime: Runtime<T>;\n\n  /// The window builder type.\n  type WindowBuilder: WindowBuilder;\n\n  /// Run a task on the main thread.\n  fn run_on_main_thread<F: FnOnce() + Send + 'static>(&self, f: F) -> Result<()>;\n\n  /// Registers a window event handler.\n  fn on_window_event<F: Fn(&WindowEvent) + Send + 'static>(&self, f: F) -> WindowEventId;\n\n  // GETTERS\n\n  /// Returns the scale factor that can be used to map logical pixels to physical pixels, and vice versa.\n  fn scale_factor(&self) -> Result<f64>;\n\n  /// Returns the position of the top-left hand corner of the window's client area relative to the top-left hand corner of the desktop.\n  fn inner_position(&self) -> Result<PhysicalPosition<i32>>;\n\n  /// Returns the position of the top-left hand corner of the window relative to the top-left hand corner of the desktop.\n  fn outer_position(&self) -> Result<PhysicalPosition<i32>>;\n\n  /// Returns the physical size of the window's client area.\n  ///\n  /// The client area is the content of the window, excluding the title bar and borders.\n  fn inner_size(&self) -> Result<PhysicalSize<u32>>;\n\n  /// Returns the physical size of the entire window.\n  ///\n  /// These dimensions include the title bar and borders. If you don't want that (and you usually don't), use inner_size instead.\n  fn outer_size(&self) -> Result<PhysicalSize<u32>>;\n\n  /// Gets the window's current fullscreen state.\n  fn is_fullscreen(&self) -> Result<bool>;\n\n  /// Gets the window's current minimized state.\n  fn is_minimized(&self) -> Result<bool>;\n\n  /// Gets the window's current maximized state.\n  fn is_maximized(&self) -> Result<bool>;\n\n  /// Gets the window's current focus state.\n  fn is_focused(&self) -> Result<bool>;\n\n  /// Gets the window's current decoration state.\n  fn is_decorated(&self) -> Result<bool>;\n\n  /// Gets the window's current resizable state.\n  fn is_resizable(&self) -> Result<bool>;\n\n  /// Gets the window's native maximize button state.\n  ///\n  /// ## Platform-specific\n  ///\n  /// - **Linux / iOS / Android:** Unsupported.\n  fn is_maximizable(&self) -> Result<bool>;\n\n  /// Gets the window's native minimize button state.\n  ///\n  /// ## Platform-specific\n  ///\n  /// - **Linux / iOS / Android:** Unsupported.\n  fn is_minimizable(&self) -> Result<bool>;\n\n  /// Gets the window's native close button state.\n  ///\n  /// ## Platform-specific\n  ///\n  /// - **iOS / Android:** Unsupported.\n  fn is_closable(&self) -> Result<bool>;\n\n  /// Gets the window's current visibility state.\n  fn is_visible(&self) -> Result<bool>;\n\n  /// Whether the window is enabled or disable.\n  fn is_enabled(&self) -> Result<bool>;\n\n  /// Gets the window's current title.\n  fn title(&self) -> Result<String>;\n\n  /// Returns the monitor on which the window currently resides.\n  ///\n  /// Returns None if current monitor can't be detected.\n  fn current_monitor(&self) -> Result<Option<Monitor>>;\n\n  /// Returns the primary monitor of the system.\n  ///\n  /// Returns None if it can't identify any monitor as a primary one.\n  fn primary_monitor(&self) -> Result<Option<Monitor>>;\n\n  /// Returns the monitor that contains the given point.\n  fn monitor_from_point(&self, x: f64, y: f64) -> Result<Option<Monitor>>;\n\n  /// Returns the list of all the monitors available on the system.\n  fn available_monitors(&self) -> Result<Vec<Monitor>>;\n\n  /// Returns the `ApplicationWindow` from gtk crate that is used by this window.\n  #[cfg(any(\n    target_os = \"linux\",\n    target_os = \"dragonfly\",\n    target_os = \"freebsd\",\n    target_os = \"netbsd\",\n    target_os = \"openbsd\"\n  ))]\n  fn gtk_window(&self) -> Result<gtk::ApplicationWindow>;\n\n  /// Returns the vertical [`gtk::Box`] that is added by default as the sole child of this window.\n  #[cfg(any(\n    target_os = \"linux\",\n    target_os = \"dragonfly\",\n    target_os = \"freebsd\",\n    target_os = \"netbsd\",\n    target_os = \"openbsd\"\n  ))]\n  fn default_vbox(&self) -> Result<gtk::Box>;\n\n  /// Raw window handle.\n  fn window_handle(\n    &self,\n  ) -> std::result::Result<raw_window_handle::WindowHandle<'_>, raw_window_handle::HandleError>;\n\n  /// Returns the current window theme.\n  fn theme(&self) -> Result<Theme>;\n\n  // SETTERS\n\n  /// Centers the window.\n  fn center(&self) -> Result<()>;\n\n  /// Requests user attention to the window.\n  ///\n  /// Providing `None` will unset the request for user attention.\n  fn request_user_attention(&self, request_type: Option<UserAttentionType>) -> Result<()>;\n\n  /// Create a new window.\n  fn create_window<F: Fn(RawWindow) + Send + 'static>(\n    &mut self,\n    pending: PendingWindow<T, Self::Runtime>,\n    after_window_creation: Option<F>,\n  ) -> Result<DetachedWindow<T, Self::Runtime>>;\n\n  /// Create a new webview.\n  fn create_webview(\n    &mut self,\n    pending: PendingWebview<T, Self::Runtime>,\n  ) -> Result<DetachedWebview<T, Self::Runtime>>;\n\n  /// Updates the window resizable flag.\n  fn set_resizable(&self, resizable: bool) -> Result<()>;\n\n  /// Enable or disable the window.\n  ///\n  /// ## Platform-specific\n  ///\n  /// - **Android / iOS**: Unsupported.\n  fn set_enabled(&self, enabled: bool) -> Result<()>;\n\n  /// Updates the window's native maximize button state.\n  ///\n  /// ## Platform-specific\n  ///\n  /// - **macOS:** Disables the \"zoom\" button in the window titlebar, which is also used to enter fullscreen mode.\n  /// - **Linux / iOS / Android:** Unsupported.\n  fn set_maximizable(&self, maximizable: bool) -> Result<()>;\n\n  /// Updates the window's native minimize button state.\n  ///\n  /// ## Platform-specific\n  ///\n  /// - **Linux / iOS / Android:** Unsupported.\n  fn set_minimizable(&self, minimizable: bool) -> Result<()>;\n\n  /// Updates the window's native close button state.\n  ///\n  /// ## Platform-specific\n  ///\n  /// - **Linux:** \"GTK+ will do its best to convince the window manager not to show a close button.\n  ///   Depending on the system, this function may not have any effect when called on a window that is already visible\"\n  /// - **iOS / Android:** Unsupported.\n  fn set_closable(&self, closable: bool) -> Result<()>;\n\n  /// Updates the window title.\n  fn set_title<S: Into<String>>(&self, title: S) -> Result<()>;\n\n  /// Maximizes the window.\n  fn maximize(&self) -> Result<()>;\n\n  /// Unmaximizes the window.\n  fn unmaximize(&self) -> Result<()>;\n\n  /// Minimizes the window.\n  fn minimize(&self) -> Result<()>;\n\n  /// Unminimizes the window.\n  fn unminimize(&self) -> Result<()>;\n\n  /// Shows the window.\n  fn show(&self) -> Result<()>;\n\n  /// Hides the window.\n  fn hide(&self) -> Result<()>;\n\n  /// Closes the window.\n  fn close(&self) -> Result<()>;\n\n  /// Destroys the window.\n  fn destroy(&self) -> Result<()>;\n\n  /// Updates the decorations flag.\n  fn set_decorations(&self, decorations: bool) -> Result<()>;\n\n  /// Updates the shadow flag.\n  fn set_shadow(&self, enable: bool) -> Result<()>;\n\n  /// Updates the window alwaysOnBottom flag.\n  fn set_always_on_bottom(&self, always_on_bottom: bool) -> Result<()>;\n\n  /// Updates the window alwaysOnTop flag.\n  fn set_always_on_top(&self, always_on_top: bool) -> Result<()>;\n\n  /// Updates the window visibleOnAllWorkspaces flag.\n  fn set_visible_on_all_workspaces(&self, visible_on_all_workspaces: bool) -> Result<()>;\n\n  /// Set the window background.\n  fn set_background_color(&self, color: Option<Color>) -> Result<()>;\n\n  /// Prevents the window contents from being captured by other apps.\n  fn set_content_protected(&self, protected: bool) -> Result<()>;\n\n  /// Resizes the window.\n  fn set_size(&self, size: Size) -> Result<()>;\n\n  /// Updates the window min inner size.\n  fn set_min_size(&self, size: Option<Size>) -> Result<()>;\n\n  /// Updates the window max inner size.\n  fn set_max_size(&self, size: Option<Size>) -> Result<()>;\n\n  /// Sets this window's minimum inner width.\n  fn set_size_constraints(&self, constraints: WindowSizeConstraints) -> Result<()>;\n\n  /// Updates the window position.\n  fn set_position(&self, position: Position) -> Result<()>;\n\n  /// Updates the window fullscreen state.\n  fn set_fullscreen(&self, fullscreen: bool) -> Result<()>;\n\n  /// Bring the window to front and focus.\n  fn set_focus(&self) -> Result<()>;\n\n  /// Updates the window icon.\n  fn set_icon(&self, icon: Icon) -> Result<()>;\n\n  /// Whether to hide the window icon from the taskbar or not.\n  fn set_skip_taskbar(&self, skip: bool) -> Result<()>;\n\n  /// Grabs the cursor, preventing it from leaving the window.\n  ///\n  /// There's no guarantee that the cursor will be hidden. You should\n  /// hide it by yourself if you want so.\n  fn set_cursor_grab(&self, grab: bool) -> Result<()>;\n\n  /// Modifies the cursor's visibility.\n  ///\n  /// If `false`, this will hide the cursor. If `true`, this will show the cursor.\n  fn set_cursor_visible(&self, visible: bool) -> Result<()>;\n\n  // Modifies the cursor icon of the window.\n  fn set_cursor_icon(&self, icon: CursorIcon) -> Result<()>;\n\n  /// Changes the position of the cursor in window coordinates.\n  fn set_cursor_position<Pos: Into<Position>>(&self, position: Pos) -> Result<()>;\n\n  /// Ignores the window cursor events.\n  fn set_ignore_cursor_events(&self, ignore: bool) -> Result<()>;\n\n  /// Starts dragging the window.\n  fn start_dragging(&self) -> Result<()>;\n\n  /// Starts resize-dragging the window.\n  fn start_resize_dragging(&self, direction: ResizeDirection) -> Result<()>;\n\n  /// Sets the badge count on the taskbar\n  /// The badge count appears as a whole for the application\n  /// Using `0` or using `None` will remove the badge\n  ///\n  /// ## Platform-specific\n  /// - **Windows:** Unsupported, use [`WindowDispatch::set_overlay_icon`] instead.\n  /// - **Android:** Unsupported.\n  /// - **iOS:** iOS expects i32, if the value is larger than i32::MAX, it will be clamped to i32::MAX.\n  fn set_badge_count(&self, count: Option<i64>, desktop_filename: Option<String>) -> Result<()>;\n\n  /// Sets the badge count on the taskbar **macOS only**. Using `None` will remove the badge\n  fn set_badge_label(&self, label: Option<String>) -> Result<()>;\n\n  /// Sets the overlay icon on the taskbar **Windows only**. Using `None` will remove the icon\n  ///\n  /// The overlay icon can be unique for each window.\n  fn set_overlay_icon(&self, icon: Option<Icon>) -> Result<()>;\n\n  /// Sets the taskbar progress state.\n  ///\n  /// ## Platform-specific\n  ///\n  /// - **Linux / macOS**: Progress bar is app-wide and not specific to this window. Only supported desktop environments with `libunity` (e.g. GNOME).\n  /// - **iOS / Android:** Unsupported.\n  fn set_progress_bar(&self, progress_state: ProgressBarState) -> Result<()>;\n\n  /// Sets the title bar style. Available on macOS only.\n  ///\n  /// ## Platform-specific\n  ///\n  /// - **Linux / Windows / iOS / Android:** Unsupported.\n  fn set_title_bar_style(&self, style: tauri_utils::TitleBarStyle) -> Result<()>;\n\n  /// Sets the theme for this window.\n  ///\n  /// ## Platform-specific\n  ///\n  /// - **Linux / macOS**: Theme is app-wide and not specific to this window.\n  /// - **iOS / Android:** Unsupported.\n  fn set_theme(&self, theme: Option<Theme>) -> Result<()>;\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "6111c6147fad0e0a64e089efc295197fd92103bc",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tauri/crates/tauri-cli/src/interface/rust/installation.rs",
    "func": "// Copyright 2019-2024 Tauri Programme within The Commons Conservancy\n// SPDX-License-Identifier: Apache-2.0\n// SPDX-License-Identifier: MIT\n\nuse crate::Result;\n\nuse std::{fs::read_dir, path::PathBuf, process::Command};\n\npub fn installed_targets() -> Result<Vec<String>> {\n  let output = Command::new(\"rustc\")\n    .args([\"--print\", \"sysroot\"])\n    .output()?;\n  let sysroot_path = PathBuf::from(String::from_utf8_lossy(&output.stdout).trim().to_string());\n\n  let mut targets = Vec::new();\n  for entry in read_dir(sysroot_path.join(\"lib\").join(\"rustlib\"))?.flatten() {\n    if entry.file_type().map(|t| t.is_dir()).unwrap_or_default() {\n      let name = entry.file_name();\n      if name != \"etc\" && name != \"src\" {\n        targets.push(name.to_string_lossy().into_owned());\n      }\n    }\n  }\n\n  Ok(targets)\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "971ff6166cf731a55d7bc01505a6507729ceec81",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tauri/crates/tauri-utils/src/pattern/mod.rs",
    "func": "// Copyright 2019-2024 Tauri Programme within The Commons Conservancy\n// SPDX-License-Identifier: Apache-2.0\n// SPDX-License-Identifier: MIT\n\n/// Handling the Tauri \"Isolation\" Pattern.\n#[cfg(feature = \"isolation\")]\npub mod isolation;\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "eb503100b0d8d35685ec4d79a5c7a15663f783e0",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tauri/examples/resources/src-tauri/src/main.rs",
    "func": "// Copyright 2019-2024 Tauri Programme within The Commons Conservancy\n// SPDX-License-Identifier: Apache-2.0\n// SPDX-License-Identifier: MIT\n\n#![cfg_attr(not(debug_assertions), windows_subsystem = \"windows\")]\n\nuse tauri::Manager;\n\n#[tauri::command]\nfn read_to_string(path: &str) -> String {\n  std::fs::read_to_string(path).unwrap_or_default()\n}\n\nfn main() {\n  tauri::Builder::default()\n    .setup(move |app| {\n      let path = app\n        .path()\n        .resolve(\"assets/index.js\", tauri::path::BaseDirectory::Resource)\n        .unwrap();\n\n      let content = std::fs::read_to_string(&path).unwrap();\n\n      println!(\"Resource `assets/index.js` path: {}\", path.display());\n      println!(\"Resource `assets/index.js` content:\\n{}\\n\", content);\n\n      Ok(())\n    })\n    .invoke_handler(tauri::generate_handler![read_to_string])\n    .run(tauri::generate_context!())\n    .expect(\"error while running tauri application\");\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "fdcbe498557dc68544285c79d86a24322746a3d6",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tauri/examples/api/src-tauri/src/lib.rs",
    "func": "// Copyright 2019-2024 Tauri Programme within The Commons Conservancy\n// SPDX-License-Identifier: Apache-2.0\n// SPDX-License-Identifier: MIT\n\nmod cmd;\n#[cfg(desktop)]\nmod menu_plugin;\n#[cfg(desktop)]\nmod tray;\n\nuse serde::Serialize;\nuse tauri::{\n  ipc::Channel,\n  webview::{PageLoadEvent, WebviewWindowBuilder},\n  App, Emitter, Listener, Runtime, WebviewUrl,\n};\n#[allow(unused)]\nuse tauri::{Manager, RunEvent};\nuse tauri_plugin_sample::{PingRequest, SampleExt};\n\n#[derive(Clone, Serialize)]\nstruct Reply {\n  data: String,\n}\n\n#[cfg(target_os = \"macos\")]\npub struct AppMenu<R: Runtime>(pub std::sync::Mutex<Option<tauri::menu::Menu<R>>>);\n\n#[cfg(all(desktop, not(test)))]\npub struct PopupMenu<R: Runtime>(tauri::menu::Menu<R>);\n\n#[cfg_attr(mobile, tauri::mobile_entry_point)]\npub fn run() {\n  run_app(tauri::Builder::default(), |_app| {})\n}\n\npub fn run_app<R: Runtime, F: FnOnce(&App<R>) + Send + 'static>(\n  builder: tauri::Builder<R>,\n  setup: F,\n) {\n  #[allow(unused_mut)]\n  let mut builder = builder\n    .plugin(\n      tauri_plugin_log::Builder::default()\n        .level(log::LevelFilter::Info)\n        .build(),\n    )\n    .plugin(tauri_plugin_sample::init())\n    .setup(move |app| {\n      #[cfg(all(desktop, not(test)))]\n      {\n        let handle = app.handle();\n        tray::create_tray(handle)?;\n        handle.plugin(menu_plugin::init())?;\n      }\n\n      #[cfg(target_os = \"macos\")]\n      app.manage(AppMenu::<R>(Default::default()));\n\n      #[cfg(all(desktop, not(test)))]\n      app.manage(PopupMenu(\n        tauri::menu::MenuBuilder::new(app)\n          .check(\"check\", \"Tauri is awesome!\")\n          .text(\"text\", \"Do something\")\n          .copy()\n          .build()?,\n      ));\n\n      let mut window_builder = WebviewWindowBuilder::new(app, \"main\", WebviewUrl::default());\n\n      #[cfg(all(desktop, not(test)))]\n      {\n        window_builder = window_builder\n          .title(\"Tauri API Validation\")\n          .inner_size(1000., 800.)\n          .min_inner_size(600., 400.)\n          .menu(tauri::menu::Menu::default(app.handle())?);\n      }\n\n      let webview = window_builder.build()?;\n\n      #[cfg(debug_assertions)]\n      webview.open_devtools();\n\n      let value = Some(\"test\".to_string());\n      let response = app.sample().ping(PingRequest {\n        value: value.clone(),\n        on_event: Channel::new(|event| {\n          println!(\"got channel event: {:?}\", event);\n          Ok(())\n        }),\n      });\n      log::info!(\"got response: {:?}\", response);\n      if let Ok(res) = response {\n        assert_eq!(res.value, value);\n      }\n\n      #[cfg(desktop)]\n      std::thread::spawn(|| {\n        let server = match tiny_http::Server::http(\"localhost:3003\") {\n          Ok(s) => s,\n          Err(e) => {\n            eprintln!(\"{}\", e);\n            std::process::exit(1);\n          }\n        };\n        loop {\n          if let Ok(mut request) = server.recv() {\n            let mut body = Vec::new();\n            let _ = request.as_reader().read_to_end(&mut body);\n            let response = tiny_http::Response::new(\n              tiny_http::StatusCode(200),\n              request.headers().to_vec(),\n              std::io::Cursor::new(body),\n              request.body_length(),\n              None,\n            );\n            let _ = request.respond(response);\n          }\n        }\n      });\n\n      setup(app);\n\n      Ok(())\n    })\n    .on_page_load(|webview, payload| {\n      if payload.event() == PageLoadEvent::Finished {\n        let webview_ = webview.clone();\n        webview.listen(\"js-event\", move |event| {\n          println!(\"got js-event with message '{:?}'\", event.payload());\n          let reply = Reply {\n            data: \"something else\".to_string(),\n          };\n\n          webview_\n            .emit(\"rust-event\", Some(reply))\n            .expect(\"failed to emit\");\n        });\n      }\n    });\n\n  #[allow(unused_mut)]\n  let mut app = builder\n    .invoke_handler(tauri::generate_handler![\n      cmd::log_operation,\n      cmd::perform_request,\n      cmd::echo\n    ])\n    .build(tauri::tauri_build_context!())\n    .expect(\"error while building tauri application\");\n\n  #[cfg(target_os = \"macos\")]\n  app.set_activation_policy(tauri::ActivationPolicy::Regular);\n\n  app.run(move |_app_handle, _event| {\n    #[cfg(all(desktop, not(test)))]\n    match &_event {\n      RunEvent::ExitRequested { api, code, .. } => {\n        // Keep the event loop running even if all windows are closed\n        // This allow us to catch tray icon events when there is no window\n        // if we manually requested an exit (code is Some(_)) we will let it go through\n        if code.is_none() {\n          api.prevent_exit();\n        }\n      }\n      RunEvent::WindowEvent {\n        event: tauri::WindowEvent::CloseRequested { api, .. },\n        label,\n        ..\n      } => {\n        println!(\"closing window...\");\n        // run the window destroy manually just for fun :)\n        // usually you'd show a dialog here to ask for confirmation or whatever\n        api.prevent_close();\n        _app_handle\n          .get_webview_window(label)\n          .unwrap()\n          .destroy()\n          .unwrap();\n      }\n      _ => (),\n    }\n  })\n}\n\n#[cfg(test)]\nmod tests {\n  use tauri::Manager;\n\n  #[test]\n  fn run_app() {\n    super::run_app(tauri::test::mock_builder(), |app| {\n      let window = app.get_webview_window(\"main\").unwrap();\n      std::thread::spawn(move || {\n        std::thread::sleep(std::time::Duration::from_secs(1));\n        window.close().unwrap();\n      });\n    })\n  }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "9572a99996cdace845c6298adef5f29f46a9ad76",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/benches/benches/bevy_render/torus.rs",
    "func": "use criterion::{black_box, criterion_group, criterion_main, Criterion};\n\nuse bevy_render::mesh::TorusMeshBuilder;\n\nfn torus(c: &mut Criterion) {\n    c.bench_function(\"build_torus\", |b| {\n        b.iter(|| black_box(TorusMeshBuilder::new(black_box(0.5), black_box(1.0))));\n    });\n}\n\ncriterion_group!(benches, torus,);\ncriterion_main!(benches);\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "ebf3fa475626a04198bea0f257ea760d16066857",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_ecs/src/event/iterators.rs",
    "func": "use crate as bevy_ecs;\n#[cfg(feature = \"multi_threaded\")]\nuse bevy_ecs::batching::BatchingStrategy;\nuse bevy_ecs::event::{Event, EventCursor, EventId, EventInstance, Events};\nuse bevy_utils::detailed_trace;\nuse core::{iter::Chain, slice::Iter};\n\n/// An iterator that yields any unread events from an [`EventReader`](super::EventReader) or [`EventCursor`].\n#[derive(Debug)]\npub struct EventIterator<'a, E: Event> {\n    iter: EventIteratorWithId<'a, E>,\n}\n\nimpl<'a, E: Event> Iterator for EventIterator<'a, E> {\n    type Item = &'a E;\n    fn next(&mut self) -> Option<Self::Item> {\n        self.iter.next().map(|(event, _)| event)\n    }\n\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.iter.size_hint()\n    }\n\n    fn count(self) -> usize {\n        self.iter.count()\n    }\n\n    fn last(self) -> Option<Self::Item>\n    where\n        Self: Sized,\n    {\n        self.iter.last().map(|(event, _)| event)\n    }\n\n    fn nth(&mut self, n: usize) -> Option<Self::Item> {\n        self.iter.nth(n).map(|(event, _)| event)\n    }\n}\n\nimpl<'a, E: Event> ExactSizeIterator for EventIterator<'a, E> {\n    fn len(&self) -> usize {\n        self.iter.len()\n    }\n}\n\n/// An iterator that yields any unread events (and their IDs) from an [`EventReader`](super::EventReader) or [`EventCursor`].\n#[derive(Debug)]\npub struct EventIteratorWithId<'a, E: Event> {\n    reader: &'a mut EventCursor<E>,\n    chain: Chain<Iter<'a, EventInstance<E>>, Iter<'a, EventInstance<E>>>,\n    unread: usize,\n}\n\nimpl<'a, E: Event> EventIteratorWithId<'a, E> {\n    /// Creates a new iterator that yields any `events` that have not yet been seen by `reader`.\n    pub fn new(reader: &'a mut EventCursor<E>, events: &'a Events<E>) -> Self {\n        let a_index = reader\n            .last_event_count\n            .saturating_sub(events.events_a.start_event_count);\n        let b_index = reader\n            .last_event_count\n            .saturating_sub(events.events_b.start_event_count);\n        let a = events.events_a.get(a_index..).unwrap_or_default();\n        let b = events.events_b.get(b_index..).unwrap_or_default();\n\n        let unread_count = a.len() + b.len();\n        // Ensure `len` is implemented correctly\n        debug_assert_eq!(unread_count, reader.len(events));\n        reader.last_event_count = events.event_count - unread_count;\n        // Iterate the oldest first, then the newer events\n        let chain = a.iter().chain(b.iter());\n\n        Self {\n            reader,\n            chain,\n            unread: unread_count,\n        }\n    }\n\n    /// Iterate over only the events.\n    pub fn without_id(self) -> EventIterator<'a, E> {\n        EventIterator { iter: self }\n    }\n}\n\nimpl<'a, E: Event> Iterator for EventIteratorWithId<'a, E> {\n    type Item = (&'a E, EventId<E>);\n    fn next(&mut self) -> Option<Self::Item> {\n        match self\n            .chain\n            .next()\n            .map(|instance| (&instance.event, instance.event_id))\n        {\n            Some(item) => {\n                detailed_trace!(\"EventReader::iter() -> {}\", item.1);\n                self.reader.last_event_count += 1;\n                self.unread -= 1;\n                Some(item)\n            }\n            None => None,\n        }\n    }\n\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.chain.size_hint()\n    }\n\n    fn count(self) -> usize {\n        self.reader.last_event_count += self.unread;\n        self.unread\n    }\n\n    fn last(self) -> Option<Self::Item>\n    where\n        Self: Sized,\n    {\n        let EventInstance { event_id, event } = self.chain.last()?;\n        self.reader.last_event_count += self.unread;\n        Some((event, *event_id))\n    }\n\n    fn nth(&mut self, n: usize) -> Option<Self::Item> {\n        if let Some(EventInstance { event_id, event }) = self.chain.nth(n) {\n            self.reader.last_event_count += n + 1;\n            self.unread -= n + 1;\n            Some((event, *event_id))\n        } else {\n            self.reader.last_event_count += self.unread;\n            self.unread = 0;\n            None\n        }\n    }\n}\n\nimpl<'a, E: Event> ExactSizeIterator for EventIteratorWithId<'a, E> {\n    fn len(&self) -> usize {\n        self.unread\n    }\n}\n\n/// A parallel iterator over `Event`s.\n#[cfg(feature = \"multi_threaded\")]\n#[derive(Debug)]\npub struct EventParIter<'a, E: Event> {\n    reader: &'a mut EventCursor<E>,\n    slices: [&'a [EventInstance<E>]; 2],\n    batching_strategy: BatchingStrategy,\n    unread: usize,\n}\n\n#[cfg(feature = \"multi_threaded\")]\nimpl<'a, E: Event> EventParIter<'a, E> {\n    /// Creates a new parallel iterator over `events` that have not yet been seen by `reader`.\n    pub fn new(reader: &'a mut EventCursor<E>, events: &'a Events<E>) -> Self {\n        let a_index = reader\n            .last_event_count\n            .saturating_sub(events.events_a.start_event_count);\n        let b_index = reader\n            .last_event_count\n            .saturating_sub(events.events_b.start_event_count);\n        let a = events.events_a.get(a_index..).unwrap_or_default();\n        let b = events.events_b.get(b_index..).unwrap_or_default();\n\n        let unread_count = a.len() + b.len();\n        // Ensure `len` is implemented correctly\n        debug_assert_eq!(unread_count, reader.len(events));\n        reader.last_event_count = events.event_count - unread_count;\n\n        Self {\n            reader,\n            slices: [a, b],\n            batching_strategy: BatchingStrategy::default(),\n            unread: unread_count,\n        }\n    }\n\n    /// Changes the batching strategy used when iterating.\n    ///\n    /// For more information on how this affects the resultant iteration, see\n    /// [`BatchingStrategy`].\n    pub fn batching_strategy(mut self, strategy: BatchingStrategy) -> Self {\n        self.batching_strategy = strategy;\n        self\n    }\n\n    /// Runs the provided closure for each unread event in parallel.\n    ///\n    /// Unlike normal iteration, the event order is not guaranteed in any form.\n    ///\n    /// # Panics\n    /// If the [`ComputeTaskPool`] is not initialized. If using this from an event reader that is being\n    /// initialized and run from the ECS scheduler, this should never panic.\n    ///\n    /// [`ComputeTaskPool`]: bevy_tasks::ComputeTaskPool\n    pub fn for_each<FN: Fn(&'a E) + Send + Sync + Clone>(self, func: FN) {\n        self.for_each_with_id(move |e, _| func(e));\n    }\n\n    /// Runs the provided closure for each unread event in parallel, like [`for_each`](Self::for_each),\n    /// but additionally provides the `EventId` to the closure.\n    ///\n    /// Note that the order of iteration is not guaranteed, but `EventId`s are ordered by send order.\n    ///\n    /// # Panics\n    /// If the [`ComputeTaskPool`] is not initialized. If using this from an event reader that is being\n    /// initialized and run from the ECS scheduler, this should never panic.\n    ///\n    /// [`ComputeTaskPool`]: bevy_tasks::ComputeTaskPool\n    pub fn for_each_with_id<FN: Fn(&'a E, EventId<E>) + Send + Sync + Clone>(mut self, func: FN) {\n        #[cfg(target_arch = \"wasm32\")]\n        {\n            self.into_iter().for_each(|(e, i)| func(e, i));\n        }\n\n        #[cfg(not(target_arch = \"wasm32\"))]\n        {\n            let pool = bevy_tasks::ComputeTaskPool::get();\n            let thread_count = pool.thread_num();\n            if thread_count <= 1 {\n                return self.into_iter().for_each(|(e, i)| func(e, i));\n            }\n\n            let batch_size = self\n                .batching_strategy\n                .calc_batch_size(|| self.len(), thread_count);\n            let chunks = self.slices.map(|s| s.chunks_exact(batch_size));\n            let remainders = chunks.each_ref().map(core::slice::ChunksExact::remainder);\n\n            pool.scope(|scope| {\n                for batch in chunks.into_iter().flatten().chain(remainders) {\n                    let func = func.clone();\n                    scope.spawn(async move {\n                        for event in batch {\n                            func(&event.event, event.event_id);\n                        }\n                    });\n                }\n            });\n\n            // Events are guaranteed to be read at this point.\n            self.reader.last_event_count += self.unread;\n            self.unread = 0;\n        }\n    }\n\n    /// Returns the number of [`Event`]s to be iterated.\n    pub fn len(&self) -> usize {\n        self.slices.iter().map(|s| s.len()).sum()\n    }\n\n    /// Returns [`true`]\u00a0if there are no events remaining in this iterator.\n    pub fn is_empty(&self) -> bool {\n        self.slices.iter().all(|x| x.is_empty())\n    }\n}\n\n#[cfg(feature = \"multi_threaded\")]\nimpl<'a, E: Event> IntoIterator for EventParIter<'a, E> {\n    type IntoIter = EventIteratorWithId<'a, E>;\n    type Item = <Self::IntoIter as Iterator>::Item;\n\n    fn into_iter(self) -> Self::IntoIter {\n        let EventParIter {\n            reader,\n            slices: [a, b],\n            ..\n        } = self;\n        let unread = a.len() + b.len();\n        let chain = a.iter().chain(b);\n        EventIteratorWithId {\n            reader,\n            chain,\n            unread,\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "0086df4715c621ff25b4cc1a67bf208b2333859d",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_ecs/src/event/mod.rs",
    "func": "//! Event handling types.\nmod base;\nmod collections;\nmod event_cursor;\nmod iterators;\nmod mut_iterators;\nmod mutator;\nmod reader;\nmod registry;\nmod send_event;\nmod update;\nmod writer;\n\npub(crate) use base::EventInstance;\npub use base::{Event, EventId};\npub use bevy_ecs_macros::Event;\npub use collections::{Events, SendBatchIds};\npub use event_cursor::EventCursor;\n#[cfg(feature = \"multi_threaded\")]\npub use iterators::EventParIter;\npub use iterators::{EventIterator, EventIteratorWithId};\n#[cfg(feature = \"multi_threaded\")]\npub use mut_iterators::EventMutParIter;\npub use mut_iterators::{EventMutIterator, EventMutIteratorWithId};\npub use mutator::EventMutator;\npub use reader::EventReader;\npub use registry::{EventRegistry, ShouldUpdateEvents};\npub use send_event::SendEvent;\npub use update::{\n    event_update_condition, event_update_system, signal_event_update_system, EventUpdates,\n};\npub use writer::EventWriter;\n\n#[cfg(test)]\nmod tests {\n    use crate as bevy_ecs;\n    use bevy_ecs::{event::*, system::assert_is_read_only_system};\n    use bevy_ecs_macros::Event;\n\n    #[derive(Event, Copy, Clone, PartialEq, Eq, Debug)]\n    struct TestEvent {\n        i: usize,\n    }\n\n    #[derive(Event, Clone, PartialEq, Debug, Default)]\n    struct EmptyTestEvent;\n\n    fn get_events<E: Event + Clone>(events: &Events<E>, cursor: &mut EventCursor<E>) -> Vec<E> {\n        cursor.read(events).cloned().collect::<Vec<E>>()\n    }\n\n    #[test]\n    fn test_events() {\n        let mut events = Events::<TestEvent>::default();\n        let event_0 = TestEvent { i: 0 };\n        let event_1 = TestEvent { i: 1 };\n        let event_2 = TestEvent { i: 2 };\n\n        // this reader will miss event_0 and event_1 because it wont read them over the course of\n        // two updates\n        let mut reader_missed: EventCursor<TestEvent> = events.get_cursor();\n\n        let mut reader_a: EventCursor<TestEvent> = events.get_cursor();\n\n        events.send(event_0);\n\n        assert_eq!(\n            get_events(&events, &mut reader_a),\n            vec![event_0],\n            \"reader_a created before event receives event\"\n        );\n        assert_eq!(\n            get_events(&events, &mut reader_a),\n            vec![],\n            \"second iteration of reader_a created before event results in zero events\"\n        );\n\n        let mut reader_b: EventCursor<TestEvent> = events.get_cursor();\n\n        assert_eq!(\n            get_events(&events, &mut reader_b),\n            vec![event_0],\n            \"reader_b created after event receives event\"\n        );\n        assert_eq!(\n            get_events(&events, &mut reader_b),\n            vec![],\n            \"second iteration of reader_b created after event results in zero events\"\n        );\n\n        events.send(event_1);\n\n        let mut reader_c = events.get_cursor();\n\n        assert_eq!(\n            get_events(&events, &mut reader_c),\n            vec![event_0, event_1],\n            \"reader_c created after two events receives both events\"\n        );\n        assert_eq!(\n            get_events(&events, &mut reader_c),\n            vec![],\n            \"second iteration of reader_c created after two event results in zero events\"\n        );\n\n        assert_eq!(\n            get_events(&events, &mut reader_a),\n            vec![event_1],\n            \"reader_a receives next unread event\"\n        );\n\n        events.update();\n\n        let mut reader_d = events.get_cursor();\n\n        events.send(event_2);\n\n        assert_eq!(\n            get_events(&events, &mut reader_a),\n            vec![event_2],\n            \"reader_a receives event created after update\"\n        );\n        assert_eq!(\n            get_events(&events, &mut reader_b),\n            vec![event_1, event_2],\n            \"reader_b receives events created before and after update\"\n        );\n        assert_eq!(\n            get_events(&events, &mut reader_d),\n            vec![event_0, event_1, event_2],\n            \"reader_d receives all events created before and after update\"\n        );\n\n        events.update();\n\n        assert_eq!(\n            get_events(&events, &mut reader_missed),\n            vec![event_2],\n            \"reader_missed missed events unread after two update() calls\"\n        );\n    }\n\n    // Events Collection\n    fn events_clear_and_read_impl(clear_func: impl FnOnce(&mut Events<TestEvent>)) {\n        let mut events = Events::<TestEvent>::default();\n        let mut reader = events.get_cursor();\n\n        assert!(reader.read(&events).next().is_none());\n\n        events.send(TestEvent { i: 0 });\n        assert_eq!(*reader.read(&events).next().unwrap(), TestEvent { i: 0 });\n        assert_eq!(reader.read(&events).next(), None);\n\n        events.send(TestEvent { i: 1 });\n        clear_func(&mut events);\n        assert!(reader.read(&events).next().is_none());\n\n        events.send(TestEvent { i: 2 });\n        events.update();\n        events.send(TestEvent { i: 3 });\n\n        assert!(reader\n            .read(&events)\n            .eq([TestEvent { i: 2 }, TestEvent { i: 3 }].iter()));\n    }\n\n    #[test]\n    fn test_events_clear_and_read() {\n        events_clear_and_read_impl(Events::clear);\n    }\n\n    #[test]\n    fn test_events_drain_and_read() {\n        events_clear_and_read_impl(|events| {\n            assert!(events\n                .drain()\n                .eq(vec![TestEvent { i: 0 }, TestEvent { i: 1 }].into_iter()));\n        });\n    }\n\n    #[test]\n    fn test_events_send_default() {\n        let mut events = Events::<EmptyTestEvent>::default();\n        events.send_default();\n\n        let mut reader = events.get_cursor();\n        assert_eq!(get_events(&events, &mut reader), vec![EmptyTestEvent]);\n    }\n\n    #[test]\n    fn test_send_events_ids() {\n        let mut events = Events::<TestEvent>::default();\n        let event_0 = TestEvent { i: 0 };\n        let event_1 = TestEvent { i: 1 };\n        let event_2 = TestEvent { i: 2 };\n\n        let event_0_id = events.send(event_0);\n\n        assert_eq!(\n            events.get_event(event_0_id.id),\n            Some((&event_0, event_0_id)),\n            \"Getting a sent event by ID should return the original event\"\n        );\n\n        let mut event_ids = events.send_batch([event_1, event_2]);\n\n        let event_id = event_ids.next().expect(\"Event 1 must have been sent\");\n\n        assert_eq!(\n            events.get_event(event_id.id),\n            Some((&event_1, event_id)),\n            \"Getting a sent event by ID should return the original event\"\n        );\n\n        let event_id = event_ids.next().expect(\"Event 2 must have been sent\");\n\n        assert_eq!(\n            events.get_event(event_id.id),\n            Some((&event_2, event_id)),\n            \"Getting a sent event by ID should return the original event\"\n        );\n\n        assert!(\n            event_ids.next().is_none(),\n            \"Only sent two events; got more than two IDs\"\n        );\n    }\n\n    #[test]\n    fn test_event_registry_can_add_and_remove_events_to_world() {\n        use bevy_ecs::prelude::*;\n\n        let mut world = World::new();\n        EventRegistry::register_event::<TestEvent>(&mut world);\n\n        let has_events = world.get_resource::<Events<TestEvent>>().is_some();\n        assert!(has_events, \"Should have the events resource\");\n\n        EventRegistry::deregister_events::<TestEvent>(&mut world);\n\n        let has_events = world.get_resource::<Events<TestEvent>>().is_some();\n        assert!(!has_events, \"Should not have the events resource\");\n    }\n\n    #[test]\n    fn test_events_update_drain() {\n        let mut events = Events::<TestEvent>::default();\n        let mut reader = events.get_cursor();\n\n        events.send(TestEvent { i: 0 });\n        events.send(TestEvent { i: 1 });\n        assert_eq!(reader.read(&events).count(), 2);\n\n        let mut old_events = Vec::from_iter(events.update_drain());\n        assert!(old_events.is_empty());\n\n        events.send(TestEvent { i: 2 });\n        assert_eq!(reader.read(&events).count(), 1);\n\n        old_events.extend(events.update_drain());\n        assert_eq!(old_events.len(), 2);\n\n        old_events.extend(events.update_drain());\n        assert_eq!(\n            old_events,\n            &[TestEvent { i: 0 }, TestEvent { i: 1 }, TestEvent { i: 2 }]\n        );\n    }\n\n    #[test]\n    fn test_events_empty() {\n        let mut events = Events::<TestEvent>::default();\n        assert!(events.is_empty());\n\n        events.send(TestEvent { i: 0 });\n        assert!(!events.is_empty());\n\n        events.update();\n        assert!(!events.is_empty());\n\n        // events are only empty after the second call to update\n        // due to double buffering.\n        events.update();\n        assert!(events.is_empty());\n    }\n\n    #[test]\n    fn test_events_extend_impl() {\n        let mut events = Events::<TestEvent>::default();\n        let mut reader = events.get_cursor();\n\n        events.extend(vec![TestEvent { i: 0 }, TestEvent { i: 1 }]);\n        assert!(reader\n            .read(&events)\n            .eq([TestEvent { i: 0 }, TestEvent { i: 1 }].iter()));\n    }\n\n    // Cursor\n    #[test]\n    fn test_event_cursor_read() {\n        let mut events = Events::<TestEvent>::default();\n        let mut cursor = events.get_cursor();\n        assert!(cursor.read(&events).next().is_none());\n\n        events.send(TestEvent { i: 0 });\n        let sent_event = cursor.read(&events).next().unwrap();\n        assert_eq!(sent_event, &TestEvent { i: 0 });\n        assert!(cursor.read(&events).next().is_none());\n\n        events.send(TestEvent { i: 2 });\n        let sent_event = cursor.read(&events).next().unwrap();\n        assert_eq!(sent_event, &TestEvent { i: 2 });\n        assert!(cursor.read(&events).next().is_none());\n\n        events.clear();\n        assert!(cursor.read(&events).next().is_none());\n    }\n\n    #[test]\n    fn test_event_cursor_read_mut() {\n        let mut events = Events::<TestEvent>::default();\n        let mut write_cursor = events.get_cursor();\n        let mut read_cursor = events.get_cursor();\n        assert!(write_cursor.read_mut(&mut events).next().is_none());\n        assert!(read_cursor.read(&events).next().is_none());\n\n        events.send(TestEvent { i: 0 });\n        let sent_event = write_cursor.read_mut(&mut events).next().unwrap();\n        assert_eq!(sent_event, &mut TestEvent { i: 0 });\n        *sent_event = TestEvent { i: 1 }; // Mutate whole event\n        assert_eq!(\n            read_cursor.read(&events).next().unwrap(),\n            &TestEvent { i: 1 }\n        );\n        assert!(read_cursor.read(&events).next().is_none());\n\n        events.send(TestEvent { i: 2 });\n        let sent_event = write_cursor.read_mut(&mut events).next().unwrap();\n        assert_eq!(sent_event, &mut TestEvent { i: 2 });\n        sent_event.i = 3; // Mutate sub value\n        assert_eq!(\n            read_cursor.read(&events).next().unwrap(),\n            &TestEvent { i: 3 }\n        );\n        assert!(read_cursor.read(&events).next().is_none());\n\n        events.clear();\n        assert!(write_cursor.read(&events).next().is_none());\n        assert!(read_cursor.read(&events).next().is_none());\n    }\n\n    #[test]\n    fn test_event_cursor_clear() {\n        let mut events = Events::<TestEvent>::default();\n        let mut reader = events.get_cursor();\n\n        events.send(TestEvent { i: 0 });\n        assert_eq!(reader.len(&events), 1);\n        reader.clear(&events);\n        assert_eq!(reader.len(&events), 0);\n    }\n\n    #[test]\n    fn test_event_cursor_len_update() {\n        let mut events = Events::<TestEvent>::default();\n        events.send(TestEvent { i: 0 });\n        events.send(TestEvent { i: 0 });\n        let reader = events.get_cursor();\n        assert_eq!(reader.len(&events), 2);\n        events.update();\n        events.send(TestEvent { i: 0 });\n        assert_eq!(reader.len(&events), 3);\n        events.update();\n        assert_eq!(reader.len(&events), 1);\n        events.update();\n        assert!(reader.is_empty(&events));\n    }\n\n    #[test]\n    fn test_event_cursor_len_current() {\n        let mut events = Events::<TestEvent>::default();\n        events.send(TestEvent { i: 0 });\n        let reader = events.get_cursor_current();\n        assert!(reader.is_empty(&events));\n        events.send(TestEvent { i: 0 });\n        assert_eq!(reader.len(&events), 1);\n        assert!(!reader.is_empty(&events));\n    }\n\n    #[test]\n    fn test_event_cursor_iter_len_updated() {\n        let mut events = Events::<TestEvent>::default();\n        events.send(TestEvent { i: 0 });\n        events.send(TestEvent { i: 1 });\n        events.send(TestEvent { i: 2 });\n        let mut reader = events.get_cursor();\n        let mut iter = reader.read(&events);\n        assert_eq!(iter.len(), 3);\n        iter.next();\n        assert_eq!(iter.len(), 2);\n        iter.next();\n        assert_eq!(iter.len(), 1);\n        iter.next();\n        assert_eq!(iter.len(), 0);\n    }\n\n    #[test]\n    fn test_event_cursor_len_empty() {\n        let events = Events::<TestEvent>::default();\n        assert_eq!(events.get_cursor().len(&events), 0);\n        assert!(events.get_cursor().is_empty(&events));\n    }\n\n    #[test]\n    fn test_event_cursor_len_filled() {\n        let mut events = Events::<TestEvent>::default();\n        events.send(TestEvent { i: 0 });\n        assert_eq!(events.get_cursor().len(&events), 1);\n        assert!(!events.get_cursor().is_empty(&events));\n    }\n\n    #[cfg(feature = \"multi_threaded\")]\n    #[test]\n    fn test_event_cursor_par_read() {\n        use crate::prelude::*;\n        use core::sync::atomic::{AtomicUsize, Ordering};\n\n        #[derive(Resource)]\n        struct Counter(AtomicUsize);\n\n        let mut world = World::new();\n        world.init_resource::<Events<TestEvent>>();\n        for _ in 0..100 {\n            world.send_event(TestEvent { i: 1 });\n        }\n\n        let mut schedule = Schedule::default();\n\n        schedule.add_systems(\n            |mut cursor: Local<EventCursor<TestEvent>>,\n             events: Res<Events<TestEvent>>,\n             counter: ResMut<Counter>| {\n                cursor.par_read(&events).for_each(|event| {\n                    counter.0.fetch_add(event.i, Ordering::Relaxed);\n                });\n            },\n        );\n\n        world.insert_resource(Counter(AtomicUsize::new(0)));\n        schedule.run(&mut world);\n        let counter = world.remove_resource::<Counter>().unwrap();\n        assert_eq!(counter.0.into_inner(), 100);\n\n        world.insert_resource(Counter(AtomicUsize::new(0)));\n        schedule.run(&mut world);\n        let counter = world.remove_resource::<Counter>().unwrap();\n        assert_eq!(\n            counter.0.into_inner(),\n            0,\n            \"par_read should have consumed events but didn't\"\n        );\n    }\n\n    #[cfg(feature = \"multi_threaded\")]\n    #[test]\n    fn test_event_cursor_par_read_mut() {\n        use crate::prelude::*;\n        use core::sync::atomic::{AtomicUsize, Ordering};\n\n        #[derive(Resource)]\n        struct Counter(AtomicUsize);\n\n        let mut world = World::new();\n        world.init_resource::<Events<TestEvent>>();\n        for _ in 0..100 {\n            world.send_event(TestEvent { i: 1 });\n        }\n        let mut schedule = Schedule::default();\n        schedule.add_systems(\n            |mut cursor: Local<EventCursor<TestEvent>>,\n             mut events: ResMut<Events<TestEvent>>,\n             counter: ResMut<Counter>| {\n                cursor.par_read_mut(&mut events).for_each(|event| {\n                    event.i += 1;\n                    counter.0.fetch_add(event.i, Ordering::Relaxed);\n                });\n            },\n        );\n        world.insert_resource(Counter(AtomicUsize::new(0)));\n        schedule.run(&mut world);\n        let counter = world.remove_resource::<Counter>().unwrap();\n        assert_eq!(counter.0.into_inner(), 200, \"Initial run failed\");\n\n        world.insert_resource(Counter(AtomicUsize::new(0)));\n        schedule.run(&mut world);\n        let counter = world.remove_resource::<Counter>().unwrap();\n        assert_eq!(\n            counter.0.into_inner(),\n            0,\n            \"par_read_mut should have consumed events but didn't\"\n        );\n    }\n\n    // Reader & Mutator\n    #[test]\n    fn ensure_reader_readonly() {\n        fn reader_system(_: EventReader<EmptyTestEvent>) {}\n\n        assert_is_read_only_system(reader_system);\n    }\n\n    #[test]\n    fn test_event_reader_iter_last() {\n        use bevy_ecs::prelude::*;\n\n        let mut world = World::new();\n        world.init_resource::<Events<TestEvent>>();\n\n        let mut reader =\n            IntoSystem::into_system(|mut events: EventReader<TestEvent>| -> Option<TestEvent> {\n                events.read().last().copied()\n            });\n        reader.initialize(&mut world);\n\n        let last = reader.run((), &mut world);\n        assert!(last.is_none(), \"EventReader should be empty\");\n\n        world.send_event(TestEvent { i: 0 });\n        let last = reader.run((), &mut world);\n        assert_eq!(last, Some(TestEvent { i: 0 }));\n\n        world.send_event(TestEvent { i: 1 });\n        world.send_event(TestEvent { i: 2 });\n        world.send_event(TestEvent { i: 3 });\n        let last = reader.run((), &mut world);\n        assert_eq!(last, Some(TestEvent { i: 3 }));\n\n        let last = reader.run((), &mut world);\n        assert!(last.is_none(), \"EventReader should be empty\");\n    }\n\n    #[test]\n    fn test_event_mutator_iter_last() {\n        use bevy_ecs::prelude::*;\n\n        let mut world = World::new();\n        world.init_resource::<Events<TestEvent>>();\n\n        let mut mutator =\n            IntoSystem::into_system(|mut events: EventMutator<TestEvent>| -> Option<TestEvent> {\n                events.read().last().copied()\n            });\n        mutator.initialize(&mut world);\n\n        let last = mutator.run((), &mut world);\n        assert!(last.is_none(), \"EventMutator should be empty\");\n\n        world.send_event(TestEvent { i: 0 });\n        let last = mutator.run((), &mut world);\n        assert_eq!(last, Some(TestEvent { i: 0 }));\n\n        world.send_event(TestEvent { i: 1 });\n        world.send_event(TestEvent { i: 2 });\n        world.send_event(TestEvent { i: 3 });\n        let last = mutator.run((), &mut world);\n        assert_eq!(last, Some(TestEvent { i: 3 }));\n\n        let last = mutator.run((), &mut world);\n        assert!(last.is_none(), \"EventMutator should be empty\");\n    }\n\n    #[allow(clippy::iter_nth_zero)]\n    #[test]\n    fn test_event_reader_iter_nth() {\n        use bevy_ecs::prelude::*;\n\n        let mut world = World::new();\n        world.init_resource::<Events<TestEvent>>();\n\n        world.send_event(TestEvent { i: 0 });\n        world.send_event(TestEvent { i: 1 });\n        world.send_event(TestEvent { i: 2 });\n        world.send_event(TestEvent { i: 3 });\n        world.send_event(TestEvent { i: 4 });\n\n        let mut schedule = Schedule::default();\n        schedule.add_systems(|mut events: EventReader<TestEvent>| {\n            let mut iter = events.read();\n\n            assert_eq!(iter.next(), Some(&TestEvent { i: 0 }));\n            assert_eq!(iter.nth(2), Some(&TestEvent { i: 3 }));\n            assert_eq!(iter.nth(1), None);\n\n            assert!(events.is_empty());\n        });\n        schedule.run(&mut world);\n    }\n\n    #[allow(clippy::iter_nth_zero)]\n    #[test]\n    fn test_event_mutator_iter_nth() {\n        use bevy_ecs::prelude::*;\n\n        let mut world = World::new();\n        world.init_resource::<Events<TestEvent>>();\n\n        world.send_event(TestEvent { i: 0 });\n        world.send_event(TestEvent { i: 1 });\n        world.send_event(TestEvent { i: 2 });\n        world.send_event(TestEvent { i: 3 });\n        world.send_event(TestEvent { i: 4 });\n\n        let mut schedule = Schedule::default();\n        schedule.add_systems(|mut events: EventReader<TestEvent>| {\n            let mut iter = events.read();\n\n            assert_eq!(iter.next(), Some(&TestEvent { i: 0 }));\n            assert_eq!(iter.nth(2), Some(&TestEvent { i: 3 }));\n            assert_eq!(iter.nth(1), None);\n\n            assert!(events.is_empty());\n        });\n        schedule.run(&mut world);\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "381c27616748f6a7ad3bd353f49e71dfaf11585c",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_ecs/src/system/system_registry.rs",
    "func": "#[cfg(feature = \"bevy_reflect\")]\nuse crate::reflect::ReflectComponent;\nuse crate::{\n    self as bevy_ecs,\n    bundle::Bundle,\n    change_detection::Mut,\n    entity::Entity,\n    system::{input::SystemInput, BoxedSystem, IntoSystem, System},\n    world::{Command, World},\n};\nuse bevy_ecs_macros::{Component, Resource};\n#[cfg(feature = \"bevy_reflect\")]\nuse bevy_reflect::Reflect;\nuse core::marker::PhantomData;\nuse thiserror::Error;\n\n/// A small wrapper for [`BoxedSystem`] that also keeps track whether or not the system has been initialized.\n#[derive(Component)]\nstruct RegisteredSystem<I, O> {\n    initialized: bool,\n    system: BoxedSystem<I, O>,\n}\n\n/// Marker [`Component`](bevy_ecs::component::Component) for identifying [`SystemId`] [`Entity`]s.\n#[derive(Component)]\n#[cfg_attr(feature = \"bevy_reflect\", derive(Reflect))]\n#[cfg_attr(feature = \"bevy_reflect\", reflect(Component))]\npub struct SystemIdMarker;\n\n/// A system that has been removed from the registry.\n/// It contains the system and whether or not it has been initialized.\n///\n/// This struct is returned by [`World::unregister_system`].\npub struct RemovedSystem<I = (), O = ()> {\n    initialized: bool,\n    system: BoxedSystem<I, O>,\n}\n\nimpl<I, O> RemovedSystem<I, O> {\n    /// Is the system initialized?\n    /// A system is initialized the first time it's ran.\n    pub fn initialized(&self) -> bool {\n        self.initialized\n    }\n\n    /// The system removed from the storage.\n    pub fn system(self) -> BoxedSystem<I, O> {\n        self.system\n    }\n}\n\n/// An identifier for a registered system.\n///\n/// These are opaque identifiers, keyed to a specific [`World`],\n/// and are created via [`World::register_system`].\npub struct SystemId<I: SystemInput = (), O = ()> {\n    pub(crate) entity: Entity,\n    pub(crate) marker: PhantomData<fn(I) -> O>,\n}\n\nimpl<I: SystemInput, O> SystemId<I, O> {\n    /// Transforms a [`SystemId`] into the [`Entity`] that holds the one-shot system's state.\n    ///\n    /// It's trivial to convert [`SystemId`] into an [`Entity`] since a one-shot system\n    /// is really an entity with associated handler function.\n    ///\n    /// For example, this is useful if you want to assign a name label to a system.\n    pub fn entity(self) -> Entity {\n        self.entity\n    }\n\n    /// Create [`SystemId`] from an [`Entity`]. Useful when you only have entity handles to avoid\n    /// adding extra components that have a [`SystemId`] everywhere. To run a system with this ID\n    ///  - The entity must be a system\n    ///  - The `I` + `O` types must be correct\n    pub fn from_entity(entity: Entity) -> Self {\n        Self {\n            entity,\n            marker: PhantomData,\n        }\n    }\n}\n\nimpl<I: SystemInput, O> Eq for SystemId<I, O> {}\n\n// A manual impl is used because the trait bounds should ignore the `I` and `O` phantom parameters.\nimpl<I: SystemInput, O> Copy for SystemId<I, O> {}\n\n// A manual impl is used because the trait bounds should ignore the `I` and `O` phantom parameters.\nimpl<I: SystemInput, O> Clone for SystemId<I, O> {\n    fn clone(&self) -> Self {\n        *self\n    }\n}\n\n// A manual impl is used because the trait bounds should ignore the `I` and `O` phantom parameters.\nimpl<I: SystemInput, O> PartialEq for SystemId<I, O> {\n    fn eq(&self, other: &Self) -> bool {\n        self.entity == other.entity && self.marker == other.marker\n    }\n}\n\n// A manual impl is used because the trait bounds should ignore the `I` and `O` phantom parameters.\nimpl<I: SystemInput, O> core::hash::Hash for SystemId<I, O> {\n    fn hash<H: core::hash::Hasher>(&self, state: &mut H) {\n        self.entity.hash(state);\n    }\n}\n\nimpl<I: SystemInput, O> core::fmt::Debug for SystemId<I, O> {\n    fn fmt(&self, f: &mut core::fmt::Formatter<'_>) -> core::fmt::Result {\n        f.debug_tuple(\"SystemId\").field(&self.entity).finish()\n    }\n}\n\n/// A cached [`SystemId`] distinguished by the unique function type of its system.\n///\n/// This resource is inserted by [`World::register_system_cached`].\n#[derive(Resource)]\npub struct CachedSystemId<S: System>(pub SystemId<S::In, S::Out>);\n\n/// Creates a [`Bundle`] for a one-shot system entity.\nfn system_bundle<I: 'static, O: 'static>(system: BoxedSystem<I, O>) -> impl Bundle {\n    (\n        RegisteredSystem {\n            initialized: false,\n            system,\n        },\n        SystemIdMarker,\n    )\n}\n\nimpl World {\n    /// Registers a system and returns a [`SystemId`] so it can later be called by [`World::run_system`].\n    ///\n    /// It's possible to register multiple copies of the same system by calling this function\n    /// multiple times. If that's not what you want, consider using [`World::register_system_cached`]\n    /// instead.\n    ///\n    /// This is different from adding systems to a [`Schedule`](crate::schedule::Schedule),\n    /// because the [`SystemId`] that is returned can be used anywhere in the [`World`] to run the associated system.\n    /// This allows for running systems in a pushed-based fashion.\n    /// Using a [`Schedule`](crate::schedule::Schedule) is still preferred for most cases\n    /// due to its better performance and ability to run non-conflicting systems simultaneously.\n    pub fn register_system<I, O, M>(\n        &mut self,\n        system: impl IntoSystem<I, O, M> + 'static,\n    ) -> SystemId<I, O>\n    where\n        I: SystemInput + 'static,\n        O: 'static,\n    {\n        self.register_boxed_system(Box::new(IntoSystem::into_system(system)))\n    }\n\n    /// Similar to [`Self::register_system`], but allows passing in a [`BoxedSystem`].\n    ///\n    ///  This is useful if the [`IntoSystem`] implementor has already been turned into a\n    /// [`System`] trait object and put in a [`Box`].\n    pub fn register_boxed_system<I, O>(&mut self, system: BoxedSystem<I, O>) -> SystemId<I, O>\n    where\n        I: SystemInput + 'static,\n        O: 'static,\n    {\n        let entity = self.spawn(system_bundle(system)).id();\n        SystemId::from_entity(entity)\n    }\n\n    /// Removes a registered system and returns the system, if it exists.\n    /// After removing a system, the [`SystemId`] becomes invalid and attempting to use it afterwards will result in errors.\n    /// Re-adding the removed system will register it on a new [`SystemId`].\n    ///\n    /// If no system corresponds to the given [`SystemId`], this method returns an error.\n    /// Systems are also not allowed to remove themselves, this returns an error too.\n    pub fn unregister_system<I, O>(\n        &mut self,\n        id: SystemId<I, O>,\n    ) -> Result<RemovedSystem<I, O>, RegisteredSystemError<I, O>>\n    where\n        I: SystemInput + 'static,\n        O: 'static,\n    {\n        match self.get_entity_mut(id.entity) {\n            Ok(mut entity) => {\n                let registered_system = entity\n                    .take::<RegisteredSystem<I, O>>()\n                    .ok_or(RegisteredSystemError::SelfRemove(id))?;\n                entity.despawn();\n                Ok(RemovedSystem {\n                    initialized: registered_system.initialized,\n                    system: registered_system.system,\n                })\n            }\n            Err(_) => Err(RegisteredSystemError::SystemIdNotRegistered(id)),\n        }\n    }\n\n    /// Run stored systems by their [`SystemId`].\n    /// Before running a system, it must first be registered.\n    /// The method [`World::register_system`] stores a given system and returns a [`SystemId`].\n    /// This is different from [`RunSystemOnce::run_system_once`](crate::system::RunSystemOnce::run_system_once),\n    /// because it keeps local state between calls and change detection works correctly.\n    ///\n    /// In order to run a chained system with an input, use [`World::run_system_with_input`] instead.\n    ///\n    /// # Limitations\n    ///\n    ///  - Stored systems cannot be recursive, they cannot call themselves through [`Commands::run_system`](crate::system::Commands).\n    ///\n    /// # Examples\n    ///\n    /// ## Running a system\n    ///\n    /// ```\n    /// # use bevy_ecs::prelude::*;\n    /// fn increment(mut counter: Local<u8>) {\n    ///    *counter += 1;\n    ///    println!(\"{}\", *counter);\n    /// }\n    ///\n    /// let mut world = World::default();\n    /// let counter_one = world.register_system(increment);\n    /// let counter_two = world.register_system(increment);\n    /// world.run_system(counter_one); // -> 1\n    /// world.run_system(counter_one); // -> 2\n    /// world.run_system(counter_two); // -> 1\n    /// ```\n    ///\n    /// ## Change detection\n    ///\n    /// ```\n    /// # use bevy_ecs::prelude::*;\n    /// #[derive(Resource, Default)]\n    /// struct ChangeDetector;\n    ///\n    /// let mut world = World::default();\n    /// world.init_resource::<ChangeDetector>();\n    /// let detector = world.register_system(|change_detector: ResMut<ChangeDetector>| {\n    ///     if change_detector.is_changed() {\n    ///         println!(\"Something happened!\");\n    ///     } else {\n    ///         println!(\"Nothing happened.\");\n    ///     }\n    /// });\n    ///\n    /// // Resources are changed when they are first added\n    /// let _ = world.run_system(detector); // -> Something happened!\n    /// let _ = world.run_system(detector); // -> Nothing happened.\n    /// world.resource_mut::<ChangeDetector>().set_changed();\n    /// let _ = world.run_system(detector); // -> Something happened!\n    /// ```\n    ///\n    /// ## Getting system output\n    ///\n    /// ```\n    /// # use bevy_ecs::prelude::*;\n    ///\n    /// #[derive(Resource)]\n    /// struct PlayerScore(i32);\n    ///\n    /// #[derive(Resource)]\n    /// struct OpponentScore(i32);\n    ///\n    /// fn get_player_score(player_score: Res<PlayerScore>) -> i32 {\n    ///   player_score.0\n    /// }\n    ///\n    /// fn get_opponent_score(opponent_score: Res<OpponentScore>) -> i32 {\n    ///   opponent_score.0\n    /// }\n    ///\n    /// let mut world = World::default();\n    /// world.insert_resource(PlayerScore(3));\n    /// world.insert_resource(OpponentScore(2));\n    ///\n    /// let scoring_systems = [\n    ///   (\"player\", world.register_system(get_player_score)),\n    ///   (\"opponent\", world.register_system(get_opponent_score)),\n    /// ];\n    ///\n    /// for (label, scoring_system) in scoring_systems {\n    ///   println!(\"{label} has score {}\", world.run_system(scoring_system).expect(\"system succeeded\"));\n    /// }\n    /// ```\n    pub fn run_system<O: 'static>(\n        &mut self,\n        id: SystemId<(), O>,\n    ) -> Result<O, RegisteredSystemError<(), O>> {\n        self.run_system_with_input(id, ())\n    }\n\n    /// Run a stored chained system by its [`SystemId`], providing an input value.\n    /// Before running a system, it must first be registered.\n    /// The method [`World::register_system`] stores a given system and returns a [`SystemId`].\n    ///\n    /// # Limitations\n    ///\n    ///  - Stored systems cannot be recursive, they cannot call themselves through [`Commands::run_system`](crate::system::Commands).\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # use bevy_ecs::prelude::*;\n    /// fn increment(In(increment_by): In<u8>, mut counter: Local<u8>) -> u8 {\n    ///   *counter += increment_by;\n    ///   *counter\n    /// }\n    ///\n    /// let mut world = World::default();\n    /// let counter_one = world.register_system(increment);\n    /// let counter_two = world.register_system(increment);\n    /// assert_eq!(world.run_system_with_input(counter_one, 1).unwrap(), 1);\n    /// assert_eq!(world.run_system_with_input(counter_one, 20).unwrap(), 21);\n    /// assert_eq!(world.run_system_with_input(counter_two, 30).unwrap(), 30);\n    /// ```\n    ///\n    /// See [`World::run_system`] for more examples.\n    pub fn run_system_with_input<I, O>(\n        &mut self,\n        id: SystemId<I, O>,\n        input: I::Inner<'_>,\n    ) -> Result<O, RegisteredSystemError<I, O>>\n    where\n        I: SystemInput + 'static,\n        O: 'static,\n    {\n        // lookup\n        let mut entity = self\n            .get_entity_mut(id.entity)\n            .map_err(|_| RegisteredSystemError::SystemIdNotRegistered(id))?;\n\n        // take ownership of system trait object\n        let RegisteredSystem {\n            mut initialized,\n            mut system,\n        } = entity\n            .take::<RegisteredSystem<I, O>>()\n            .ok_or(RegisteredSystemError::Recursive(id))?;\n\n        // run the system\n        if !initialized {\n            system.initialize(self);\n            initialized = true;\n        }\n\n        let result = if system.validate_param(self) {\n            Ok(system.run(input, self))\n        } else {\n            Err(RegisteredSystemError::InvalidParams(id))\n        };\n\n        // return ownership of system trait object (if entity still exists)\n        if let Ok(mut entity) = self.get_entity_mut(id.entity) {\n            entity.insert::<RegisteredSystem<I, O>>(RegisteredSystem {\n                initialized,\n                system,\n            });\n        }\n        result\n    }\n\n    /// Registers a system or returns its cached [`SystemId`].\n    ///\n    /// If you want to run the system immediately and you don't need its `SystemId`, see\n    /// [`World::run_system_cached`].\n    ///\n    /// The first time this function is called for a particular system, it will register it and\n    /// store its [`SystemId`] in a [`CachedSystemId`] resource for later. If you would rather\n    /// manage the `SystemId` yourself, or register multiple copies of the same system, use\n    /// [`World::register_system`] instead.\n    ///\n    /// # Limitations\n    ///\n    /// This function only accepts ZST (zero-sized) systems to guarantee that any two systems of\n    /// the same type must be equal. This means that closures that capture the environment, and\n    /// function pointers, are not accepted.\n    ///\n    /// If you want to access values from the environment within a system, consider passing them in\n    /// as inputs via [`World::run_system_cached_with`]. If that's not an option, consider\n    /// [`World::register_system`] instead.\n    pub fn register_system_cached<I, O, M, S>(&mut self, system: S) -> SystemId<I, O>\n    where\n        I: SystemInput + 'static,\n        O: 'static,\n        S: IntoSystem<I, O, M> + 'static,\n    {\n        const {\n            assert!(\n                size_of::<S>() == 0,\n                \"Non-ZST systems (e.g. capturing closures, function pointers) cannot be cached.\",\n            );\n        }\n\n        if !self.contains_resource::<CachedSystemId<S::System>>() {\n            let id = self.register_system(system);\n            self.insert_resource(CachedSystemId::<S::System>(id));\n            return id;\n        }\n\n        self.resource_scope(|world, mut id: Mut<CachedSystemId<S::System>>| {\n            if let Ok(mut entity) = world.get_entity_mut(id.0.entity()) {\n                if !entity.contains::<RegisteredSystem<I, O>>() {\n                    entity.insert(system_bundle(Box::new(IntoSystem::into_system(system))));\n                }\n            } else {\n                id.0 = world.register_system(system);\n            }\n            id.0\n        })\n    }\n\n    /// Removes a cached system and its [`CachedSystemId`] resource.\n    ///\n    /// See [`World::register_system_cached`] for more information.\n    pub fn unregister_system_cached<I, O, M, S>(\n        &mut self,\n        _system: S,\n    ) -> Result<RemovedSystem<I, O>, RegisteredSystemError<I, O>>\n    where\n        I: SystemInput + 'static,\n        O: 'static,\n        S: IntoSystem<I, O, M> + 'static,\n    {\n        let id = self\n            .remove_resource::<CachedSystemId<S::System>>()\n            .ok_or(RegisteredSystemError::SystemNotCached)?;\n        self.unregister_system(id.0)\n    }\n\n    /// Runs a cached system, registering it if necessary.\n    ///\n    /// See [`World::register_system_cached`] for more information.\n    pub fn run_system_cached<O: 'static, M, S: IntoSystem<(), O, M> + 'static>(\n        &mut self,\n        system: S,\n    ) -> Result<O, RegisteredSystemError<(), O>> {\n        self.run_system_cached_with(system, ())\n    }\n\n    /// Runs a cached system with an input, registering it if necessary.\n    ///\n    /// See [`World::register_system_cached`] for more information.\n    pub fn run_system_cached_with<I, O, M, S>(\n        &mut self,\n        system: S,\n        input: I::Inner<'_>,\n    ) -> Result<O, RegisteredSystemError<I, O>>\n    where\n        I: SystemInput + 'static,\n        O: 'static,\n        S: IntoSystem<I, O, M> + 'static,\n    {\n        let id = self.register_system_cached(system);\n        self.run_system_with_input(id, input)\n    }\n}\n\n/// The [`Command`] type for [`World::run_system`] or [`World::run_system_with_input`].\n///\n/// This command runs systems in an exclusive and single threaded way.\n/// Running slow systems can become a bottleneck.\n///\n/// If the system needs an [`In<_>`](crate::system::In) input value to run, it must\n/// be provided as part of the command.\n///\n/// There is no way to get the output of a system when run as a command, because the\n/// execution of the system happens later. To get the output of a system, use\n/// [`World::run_system`] or [`World::run_system_with_input`] instead of running the system as a command.\n#[derive(Debug, Clone)]\npub struct RunSystemWithInput<I: SystemInput + 'static> {\n    system_id: SystemId<I>,\n    input: I::Inner<'static>,\n}\n\n/// The [`Command`] type for [`World::run_system`].\n///\n/// This command runs systems in an exclusive and single threaded way.\n/// Running slow systems can become a bottleneck.\n///\n/// If the system needs an [`In<_>`](crate::system::In) input value to run, use the\n/// [`RunSystemWithInput`] type instead.\n///\n/// There is no way to get the output of a system when run as a command, because the\n/// execution of the system happens later. To get the output of a system, use\n/// [`World::run_system`] or [`World::run_system_with_input`] instead of running the system as a command.\npub type RunSystem = RunSystemWithInput<()>;\n\nimpl RunSystem {\n    /// Creates a new [`Command`] struct, which can be added to [`Commands`](crate::system::Commands).\n    pub fn new(system_id: SystemId) -> Self {\n        Self::new_with_input(system_id, ())\n    }\n}\n\nimpl<I: SystemInput + 'static> RunSystemWithInput<I> {\n    /// Creates a new [`Command`] struct, which can be added to [`Commands`](crate::system::Commands)\n    /// in order to run the specified system with the provided [`In<_>`](crate::system::In) input value.\n    pub fn new_with_input(system_id: SystemId<I>, input: I::Inner<'static>) -> Self {\n        Self { system_id, input }\n    }\n}\n\nimpl<I> Command for RunSystemWithInput<I>\nwhere\n    I: SystemInput<Inner<'static>: Send> + 'static,\n{\n    #[inline]\n    fn apply(self, world: &mut World) {\n        _ = world.run_system_with_input(self.system_id, self.input);\n    }\n}\n\n/// The [`Command`] type for registering one shot systems from [`Commands`](crate::system::Commands).\n///\n/// This command needs an already boxed system to register, and an already spawned entity.\npub struct RegisterSystem<I: SystemInput + 'static, O: 'static> {\n    system: BoxedSystem<I, O>,\n    entity: Entity,\n}\n\nimpl<I, O> RegisterSystem<I, O>\nwhere\n    I: SystemInput + 'static,\n    O: 'static,\n{\n    /// Creates a new [`Command`] struct, which can be added to [`Commands`](crate::system::Commands).\n    pub fn new<M, S: IntoSystem<I, O, M> + 'static>(system: S, entity: Entity) -> Self {\n        Self {\n            system: Box::new(IntoSystem::into_system(system)),\n            entity,\n        }\n    }\n}\n\nimpl<I, O> Command for RegisterSystem<I, O>\nwhere\n    I: SystemInput + Send + 'static,\n    O: Send + 'static,\n{\n    fn apply(self, world: &mut World) {\n        if let Ok(mut entity) = world.get_entity_mut(self.entity) {\n            entity.insert(system_bundle(self.system));\n        }\n    }\n}\n\n/// The [`Command`] type for unregistering one-shot systems from [`Commands`](crate::system::Commands).\npub struct UnregisterSystem<I: SystemInput + 'static, O: 'static> {\n    system_id: SystemId<I, O>,\n}\n\nimpl<I, O> UnregisterSystem<I, O>\nwhere\n    I: SystemInput + 'static,\n    O: 'static,\n{\n    /// Creates a new [`Command`] struct, which can be added to [`Commands`](crate::system::Commands).\n    pub fn new(system_id: SystemId<I, O>) -> Self {\n        Self { system_id }\n    }\n}\n\nimpl<I, O> Command for UnregisterSystem<I, O>\nwhere\n    I: SystemInput + 'static,\n    O: 'static,\n{\n    fn apply(self, world: &mut World) {\n        let _ = world.unregister_system(self.system_id);\n    }\n}\n\n/// The [`Command`] type for running a cached one-shot system from\n/// [`Commands`](crate::system::Commands).\n///\n/// See [`World::register_system_cached`] for more information.\npub struct RunSystemCachedWith<S, I, O, M>\nwhere\n    I: SystemInput,\n    S: IntoSystem<I, O, M>,\n{\n    system: S,\n    input: I::Inner<'static>,\n    _phantom: PhantomData<(fn() -> O, fn() -> M)>,\n}\n\nimpl<S, I, O, M> RunSystemCachedWith<S, I, O, M>\nwhere\n    I: SystemInput,\n    S: IntoSystem<I, O, M>,\n{\n    /// Creates a new [`Command`] struct, which can be added to\n    /// [`Commands`](crate::system::Commands).\n    pub fn new(system: S, input: I::Inner<'static>) -> Self {\n        Self {\n            system,\n            input,\n            _phantom: PhantomData,\n        }\n    }\n}\n\nimpl<S, I, O, M> Command for RunSystemCachedWith<S, I, O, M>\nwhere\n    I: SystemInput<Inner<'static>: Send> + Send + 'static,\n    O: Send + 'static,\n    S: IntoSystem<I, O, M> + Send + 'static,\n    M: 'static,\n{\n    fn apply(self, world: &mut World) {\n        let _ = world.run_system_cached_with(self.system, self.input);\n    }\n}\n\n/// An operation with stored systems failed.\n#[derive(Error)]\npub enum RegisteredSystemError<I: SystemInput = (), O = ()> {\n    /// A system was run by id, but no system with that id was found.\n    ///\n    /// Did you forget to register it?\n    #[error(\"System {0:?} was not registered\")]\n    SystemIdNotRegistered(SystemId<I, O>),\n    /// A cached system was removed by value, but no system with its type was found.\n    ///\n    /// Did you forget to register it?\n    #[error(\"Cached system was not found\")]\n    SystemNotCached,\n    /// A system tried to run itself recursively.\n    #[error(\"System {0:?} tried to run itself recursively\")]\n    Recursive(SystemId<I, O>),\n    /// A system tried to remove itself.\n    #[error(\"System {0:?} tried to remove itself\")]\n    SelfRemove(SystemId<I, O>),\n    /// System could not be run due to parameters that failed validation.\n    ///\n    /// This can occur because the data required by the system was not present in the world.\n    #[error(\"The data required by the system {0:?} was not found in the world and the system did not run due to failed parameter validation.\")]\n    InvalidParams(SystemId<I, O>),\n}\n\nimpl<I: SystemInput, O> core::fmt::Debug for RegisteredSystemError<I, O> {\n    fn fmt(&self, f: &mut core::fmt::Formatter<'_>) -> core::fmt::Result {\n        match self {\n            Self::SystemIdNotRegistered(arg0) => {\n                f.debug_tuple(\"SystemIdNotRegistered\").field(arg0).finish()\n            }\n            Self::SystemNotCached => write!(f, \"SystemNotCached\"),\n            Self::Recursive(arg0) => f.debug_tuple(\"Recursive\").field(arg0).finish(),\n            Self::SelfRemove(arg0) => f.debug_tuple(\"SelfRemove\").field(arg0).finish(),\n            Self::InvalidParams(arg0) => f.debug_tuple(\"InvalidParams\").field(arg0).finish(),\n        }\n    }\n}\n\nmod tests {\n    use crate::prelude::*;\n    use crate::{self as bevy_ecs};\n\n    #[derive(Resource, Default, PartialEq, Debug)]\n    struct Counter(u8);\n\n    #[test]\n    fn change_detection() {\n        #[derive(Resource, Default)]\n        struct ChangeDetector;\n\n        fn count_up_iff_changed(\n            mut counter: ResMut<Counter>,\n            change_detector: ResMut<ChangeDetector>,\n        ) {\n            if change_detector.is_changed() {\n                counter.0 += 1;\n            }\n        }\n\n        let mut world = World::new();\n        world.init_resource::<ChangeDetector>();\n        world.init_resource::<Counter>();\n        assert_eq!(*world.resource::<Counter>(), Counter(0));\n        // Resources are changed when they are first added.\n        let id = world.register_system(count_up_iff_changed);\n        world.run_system(id).expect(\"system runs successfully\");\n        assert_eq!(*world.resource::<Counter>(), Counter(1));\n        // Nothing changed\n        world.run_system(id).expect(\"system runs successfully\");\n        assert_eq!(*world.resource::<Counter>(), Counter(1));\n        // Making a change\n        world.resource_mut::<ChangeDetector>().set_changed();\n        world.run_system(id).expect(\"system runs successfully\");\n        assert_eq!(*world.resource::<Counter>(), Counter(2));\n    }\n\n    #[test]\n    fn local_variables() {\n        // The `Local` begins at the default value of 0\n        fn doubling(last_counter: Local<Counter>, mut counter: ResMut<Counter>) {\n            counter.0 += last_counter.0 .0;\n            last_counter.0 .0 = counter.0;\n        }\n\n        let mut world = World::new();\n        world.insert_resource(Counter(1));\n        assert_eq!(*world.resource::<Counter>(), Counter(1));\n        let id = world.register_system(doubling);\n        world.run_system(id).expect(\"system runs successfully\");\n        assert_eq!(*world.resource::<Counter>(), Counter(1));\n        world.run_system(id).expect(\"system runs successfully\");\n        assert_eq!(*world.resource::<Counter>(), Counter(2));\n        world.run_system(id).expect(\"system runs successfully\");\n        assert_eq!(*world.resource::<Counter>(), Counter(4));\n        world.run_system(id).expect(\"system runs successfully\");\n        assert_eq!(*world.resource::<Counter>(), Counter(8));\n    }\n\n    #[test]\n    fn input_values() {\n        // Verify that a non-Copy, non-Clone type can be passed in.\n        struct NonCopy(u8);\n\n        fn increment_sys(In(NonCopy(increment_by)): In<NonCopy>, mut counter: ResMut<Counter>) {\n            counter.0 += increment_by;\n        }\n\n        let mut world = World::new();\n\n        let id = world.register_system(increment_sys);\n\n        // Insert the resource after registering the system.\n        world.insert_resource(Counter(1));\n        assert_eq!(*world.resource::<Counter>(), Counter(1));\n\n        world\n            .run_system_with_input(id, NonCopy(1))\n            .expect(\"system runs successfully\");\n        assert_eq!(*world.resource::<Counter>(), Counter(2));\n\n        world\n            .run_system_with_input(id, NonCopy(1))\n            .expect(\"system runs successfully\");\n        assert_eq!(*world.resource::<Counter>(), Counter(3));\n\n        world\n            .run_system_with_input(id, NonCopy(20))\n            .expect(\"system runs successfully\");\n        assert_eq!(*world.resource::<Counter>(), Counter(23));\n\n        world\n            .run_system_with_input(id, NonCopy(1))\n            .expect(\"system runs successfully\");\n        assert_eq!(*world.resource::<Counter>(), Counter(24));\n    }\n\n    #[test]\n    fn output_values() {\n        // Verify that a non-Copy, non-Clone type can be returned.\n        #[derive(Eq, PartialEq, Debug)]\n        struct NonCopy(u8);\n\n        fn increment_sys(mut counter: ResMut<Counter>) -> NonCopy {\n            counter.0 += 1;\n            NonCopy(counter.0)\n        }\n\n        let mut world = World::new();\n\n        let id = world.register_system(increment_sys);\n\n        // Insert the resource after registering the system.\n        world.insert_resource(Counter(1));\n        assert_eq!(*world.resource::<Counter>(), Counter(1));\n\n        let output = world.run_system(id).expect(\"system runs successfully\");\n        assert_eq!(*world.resource::<Counter>(), Counter(2));\n        assert_eq!(output, NonCopy(2));\n\n        let output = world.run_system(id).expect(\"system runs successfully\");\n        assert_eq!(*world.resource::<Counter>(), Counter(3));\n        assert_eq!(output, NonCopy(3));\n    }\n\n    #[test]\n    fn exclusive_system() {\n        let mut world = World::new();\n        let exclusive_system_id = world.register_system(|world: &mut World| {\n            world.spawn_empty();\n        });\n        let entity_count = world.entities.len();\n        let _ = world.run_system(exclusive_system_id);\n        assert_eq!(world.entities.len(), entity_count + 1);\n    }\n\n    #[test]\n    fn nested_systems() {\n        use crate::system::SystemId;\n\n        #[derive(Component)]\n        struct Callback(SystemId);\n\n        fn nested(query: Query<&Callback>, mut commands: Commands) {\n            for callback in query.iter() {\n                commands.run_system(callback.0);\n            }\n        }\n\n        let mut world = World::new();\n        world.insert_resource(Counter(0));\n\n        let increment_two = world.register_system(|mut counter: ResMut<Counter>| {\n            counter.0 += 2;\n        });\n        let increment_three = world.register_system(|mut counter: ResMut<Counter>| {\n            counter.0 += 3;\n        });\n        let nested_id = world.register_system(nested);\n\n        world.spawn(Callback(increment_two));\n        world.spawn(Callback(increment_three));\n        let _ = world.run_system(nested_id);\n        assert_eq!(*world.resource::<Counter>(), Counter(5));\n    }\n\n    #[test]\n    fn nested_systems_with_inputs() {\n        use crate::system::SystemId;\n\n        #[derive(Component)]\n        struct Callback(SystemId<In<u8>>, u8);\n\n        fn nested(query: Query<&Callback>, mut commands: Commands) {\n            for callback in query.iter() {\n                commands.run_system_with_input(callback.0, callback.1);\n            }\n        }\n\n        let mut world = World::new();\n        world.insert_resource(Counter(0));\n\n        let increment_by =\n            world.register_system(|In(amt): In<u8>, mut counter: ResMut<Counter>| {\n                counter.0 += amt;\n            });\n        let nested_id = world.register_system(nested);\n\n        world.spawn(Callback(increment_by, 2));\n        world.spawn(Callback(increment_by, 3));\n        let _ = world.run_system(nested_id);\n        assert_eq!(*world.resource::<Counter>(), Counter(5));\n    }\n\n    #[test]\n    fn cached_system() {\n        use crate::system::RegisteredSystemError;\n\n        fn four() -> i32 {\n            4\n        }\n\n        let mut world = World::new();\n        let old = world.register_system_cached(four);\n        let new = world.register_system_cached(four);\n        assert_eq!(old, new);\n\n        let result = world.unregister_system_cached(four);\n        assert!(result.is_ok());\n        let new = world.register_system_cached(four);\n        assert_ne!(old, new);\n\n        let output = world.run_system(old);\n        assert!(matches!(\n            output,\n            Err(RegisteredSystemError::SystemIdNotRegistered(x)) if x == old,\n        ));\n        let output = world.run_system(new);\n        assert!(matches!(output, Ok(x) if x == four()));\n        let output = world.run_system_cached(four);\n        assert!(matches!(output, Ok(x) if x == four()));\n        let output = world.run_system_cached_with(four, ());\n        assert!(matches!(output, Ok(x) if x == four()));\n    }\n\n    #[test]\n    fn cached_system_commands() {\n        fn sys(mut counter: ResMut<Counter>) {\n            counter.0 = 1;\n        }\n\n        let mut world = World::new();\n        world.insert_resource(Counter(0));\n\n        world.commands().run_system_cached(sys);\n        world.flush_commands();\n\n        assert_eq!(world.resource::<Counter>().0, 1);\n    }\n\n    #[test]\n    fn cached_system_adapters() {\n        fn four() -> i32 {\n            4\n        }\n\n        fn double(In(i): In<i32>) -> i32 {\n            i * 2\n        }\n\n        let mut world = World::new();\n\n        let output = world.run_system_cached(four.pipe(double));\n        assert!(matches!(output, Ok(8)));\n\n        let output = world.run_system_cached(four.map(|i| i * 2));\n        assert!(matches!(output, Ok(8)));\n    }\n\n    #[test]\n    fn system_with_input_ref() {\n        fn with_ref(InRef(input): InRef<u8>, mut counter: ResMut<Counter>) {\n            counter.0 += *input;\n        }\n\n        let mut world = World::new();\n        world.insert_resource(Counter(0));\n\n        let id = world.register_system(with_ref);\n        world.run_system_with_input(id, &2).unwrap();\n        assert_eq!(*world.resource::<Counter>(), Counter(2));\n    }\n\n    #[test]\n    fn system_with_input_mut() {\n        #[derive(Event)]\n        struct MyEvent {\n            cancelled: bool,\n        }\n\n        fn post(InMut(event): InMut<MyEvent>, counter: ResMut<Counter>) {\n            if counter.0 > 0 {\n                event.cancelled = true;\n            }\n        }\n\n        let mut world = World::new();\n        world.insert_resource(Counter(0));\n        let post_system = world.register_system(post);\n\n        let mut event = MyEvent { cancelled: false };\n        world\n            .run_system_with_input(post_system, &mut event)\n            .unwrap();\n        assert!(!event.cancelled);\n\n        world.resource_mut::<Counter>().0 = 1;\n        world\n            .run_system_with_input(post_system, &mut event)\n            .unwrap();\n        assert!(event.cancelled);\n    }\n\n    #[test]\n    fn run_system_invalid_params() {\n        use crate::system::RegisteredSystemError;\n\n        struct T;\n        impl Resource for T {}\n        fn system(_: Res<T>) {}\n\n        let mut world = World::new();\n        let id = world.register_system_cached(system);\n        // This fails because `T` has not been added to the world yet.\n        let result = world.run_system(id);\n\n        assert!(matches!(\n            result,\n            Err(RegisteredSystemError::InvalidParams(_))\n        ));\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "418ae10ec087272f023659a9b1f6d505ef4fa588",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_ecs/src/query/builder.rs",
    "func": "use core::marker::PhantomData;\n\nuse crate::{\n    component::{ComponentId, StorageType},\n    prelude::*,\n};\n\nuse super::{FilteredAccess, QueryData, QueryFilter};\n\n/// Builder struct to create [`QueryState`] instances at runtime.\n///\n/// ```\n/// # use bevy_ecs::prelude::*;\n/// #\n/// # #[derive(Component)]\n/// # struct A;\n/// #\n/// # #[derive(Component)]\n/// # struct B;\n/// #\n/// # #[derive(Component)]\n/// # struct C;\n/// #\n/// let mut world = World::new();\n/// let entity_a = world.spawn((A, B)).id();\n/// let entity_b = world.spawn((A, C)).id();\n///\n/// // Instantiate the builder using the type signature of the iterator you will consume\n/// let mut query = QueryBuilder::<(Entity, &B)>::new(&mut world)\n/// // Add additional terms through builder methods\n///     .with::<A>()\n///     .without::<C>()\n///     .build();\n///\n/// // Consume the QueryState\n/// let (entity, b) = query.single(&world);\n/// ```\npub struct QueryBuilder<'w, D: QueryData = (), F: QueryFilter = ()> {\n    access: FilteredAccess<ComponentId>,\n    world: &'w mut World,\n    or: bool,\n    first: bool,\n    _marker: PhantomData<(D, F)>,\n}\n\nimpl<'w, D: QueryData, F: QueryFilter> QueryBuilder<'w, D, F> {\n    /// Creates a new builder with the accesses required for `Q` and `F`\n    pub fn new(world: &'w mut World) -> Self {\n        let fetch_state = D::init_state(world);\n        let filter_state = F::init_state(world);\n\n        let mut access = FilteredAccess::default();\n        D::update_component_access(&fetch_state, &mut access);\n\n        // Use a temporary empty FilteredAccess for filters. This prevents them from conflicting with the\n        // main Query's `fetch_state` access. Filters are allowed to conflict with the main query fetch\n        // because they are evaluated *before* a specific reference is constructed.\n        let mut filter_access = FilteredAccess::default();\n        F::update_component_access(&filter_state, &mut filter_access);\n\n        // Merge the temporary filter access with the main access. This ensures that filter access is\n        // properly considered in a global \"cross-query\" context (both within systems and across systems).\n        access.extend(&filter_access);\n\n        Self {\n            access,\n            world,\n            or: false,\n            first: false,\n            _marker: PhantomData,\n        }\n    }\n\n    pub(super) fn is_dense(&self) -> bool {\n        // Note: `component_id` comes from the user in safe code, so we cannot trust it to\n        // exist. If it doesn't exist we pessimistically assume it's sparse.\n        let is_dense = |component_id| {\n            self.world()\n                .components()\n                .get_info(component_id)\n                .map_or(false, |info| info.storage_type() == StorageType::Table)\n        };\n\n        #[allow(deprecated)]\n        let (mut component_reads_and_writes, component_reads_and_writes_inverted) =\n            self.access.access().component_reads_and_writes();\n        if component_reads_and_writes_inverted {\n            return false;\n        }\n\n        component_reads_and_writes.all(is_dense)\n            && self.access.access().archetypal().all(is_dense)\n            && !self.access.access().has_read_all_components()\n            && self.access.with_filters().all(is_dense)\n            && self.access.without_filters().all(is_dense)\n    }\n\n    /// Returns a reference to the world passed to [`Self::new`].\n    pub fn world(&self) -> &World {\n        self.world\n    }\n\n    /// Returns a mutable reference to the world passed to [`Self::new`].\n    pub fn world_mut(&mut self) -> &mut World {\n        self.world\n    }\n\n    /// Adds access to self's underlying [`FilteredAccess`] respecting [`Self::or`] and [`Self::and`]\n    pub fn extend_access(&mut self, mut access: FilteredAccess<ComponentId>) {\n        if self.or {\n            if self.first {\n                access.required.clear();\n                self.access.extend(&access);\n                self.first = false;\n            } else {\n                self.access.append_or(&access);\n            }\n        } else {\n            self.access.extend(&access);\n        }\n    }\n\n    /// Adds accesses required for `T` to self.\n    pub fn data<T: QueryData>(&mut self) -> &mut Self {\n        let state = T::init_state(self.world);\n        let mut access = FilteredAccess::default();\n        T::update_component_access(&state, &mut access);\n        self.extend_access(access);\n        self\n    }\n\n    /// Adds filter from `T` to self.\n    pub fn filter<T: QueryFilter>(&mut self) -> &mut Self {\n        let state = T::init_state(self.world);\n        let mut access = FilteredAccess::default();\n        T::update_component_access(&state, &mut access);\n        self.extend_access(access);\n        self\n    }\n\n    /// Adds [`With<T>`] to the [`FilteredAccess`] of self.\n    pub fn with<T: Component>(&mut self) -> &mut Self {\n        self.filter::<With<T>>();\n        self\n    }\n\n    /// Adds [`With<T>`] to the [`FilteredAccess`] of self from a runtime [`ComponentId`].\n    pub fn with_id(&mut self, id: ComponentId) -> &mut Self {\n        let mut access = FilteredAccess::default();\n        access.and_with(id);\n        self.extend_access(access);\n        self\n    }\n\n    /// Adds [`Without<T>`] to the [`FilteredAccess`] of self.\n    pub fn without<T: Component>(&mut self) -> &mut Self {\n        self.filter::<Without<T>>();\n        self\n    }\n\n    /// Adds [`Without<T>`] to the [`FilteredAccess`] of self from a runtime [`ComponentId`].\n    pub fn without_id(&mut self, id: ComponentId) -> &mut Self {\n        let mut access = FilteredAccess::default();\n        access.and_without(id);\n        self.extend_access(access);\n        self\n    }\n\n    /// Adds `&T` to the [`FilteredAccess`] of self.\n    pub fn ref_id(&mut self, id: ComponentId) -> &mut Self {\n        self.with_id(id);\n        self.access.add_component_read(id);\n        self\n    }\n\n    /// Adds `&mut T` to the [`FilteredAccess`] of self.\n    pub fn mut_id(&mut self, id: ComponentId) -> &mut Self {\n        self.with_id(id);\n        self.access.add_component_write(id);\n        self\n    }\n\n    /// Takes a function over mutable access to a [`QueryBuilder`], calls that function\n    /// on an empty builder and then adds all accesses from that builder to self as optional.\n    pub fn optional(&mut self, f: impl Fn(&mut QueryBuilder)) -> &mut Self {\n        let mut builder = QueryBuilder::new(self.world);\n        f(&mut builder);\n        self.access.extend_access(builder.access());\n        self\n    }\n\n    /// Takes a function over mutable access to a [`QueryBuilder`], calls that function\n    /// on an empty builder and then adds all accesses from that builder to self.\n    ///\n    /// Primarily used when inside a [`Self::or`] closure to group several terms.\n    pub fn and(&mut self, f: impl Fn(&mut QueryBuilder)) -> &mut Self {\n        let mut builder = QueryBuilder::new(self.world);\n        f(&mut builder);\n        let access = builder.access().clone();\n        self.extend_access(access);\n        self\n    }\n\n    /// Takes a function over mutable access to a [`QueryBuilder`], calls that function\n    /// on an empty builder, all accesses added to that builder will become terms in an or expression.\n    ///\n    /// ```\n    /// # use bevy_ecs::prelude::*;\n    /// #\n    /// # #[derive(Component)]\n    /// # struct A;\n    /// #\n    /// # #[derive(Component)]\n    /// # struct B;\n    /// #\n    /// # let mut world = World::new();\n    /// #\n    /// QueryBuilder::<Entity>::new(&mut world).or(|builder| {\n    ///     builder.with::<A>();\n    ///     builder.with::<B>();\n    /// });\n    /// // is equivalent to\n    /// QueryBuilder::<Entity>::new(&mut world).filter::<Or<(With<A>, With<B>)>>();\n    /// ```\n    pub fn or(&mut self, f: impl Fn(&mut QueryBuilder)) -> &mut Self {\n        let mut builder = QueryBuilder::new(self.world);\n        builder.or = true;\n        builder.first = true;\n        f(&mut builder);\n        self.access.extend(builder.access());\n        self\n    }\n\n    /// Returns a reference to the [`FilteredAccess`] that will be provided to the built [`Query`].\n    pub fn access(&self) -> &FilteredAccess<ComponentId> {\n        &self.access\n    }\n\n    /// Transmute the existing builder adding required accesses.\n    /// This will maintain all existing accesses.\n    ///\n    /// If including a filter type see [`Self::transmute_filtered`]\n    pub fn transmute<NewD: QueryData>(&mut self) -> &mut QueryBuilder<'w, NewD> {\n        self.transmute_filtered::<NewD, ()>()\n    }\n\n    /// Transmute the existing builder adding required accesses.\n    /// This will maintain all existing accesses.\n    pub fn transmute_filtered<NewD: QueryData, NewF: QueryFilter>(\n        &mut self,\n    ) -> &mut QueryBuilder<'w, NewD, NewF> {\n        let mut fetch_state = NewD::init_state(self.world);\n        let filter_state = NewF::init_state(self.world);\n\n        NewD::set_access(&mut fetch_state, &self.access);\n\n        let mut access = FilteredAccess::default();\n        NewD::update_component_access(&fetch_state, &mut access);\n        NewF::update_component_access(&filter_state, &mut access);\n\n        self.extend_access(access);\n        // SAFETY:\n        // - We have included all required accesses for NewQ and NewF\n        // - The layout of all QueryBuilder instances is the same\n        unsafe { core::mem::transmute(self) }\n    }\n\n    /// Create a [`QueryState`] with the accesses of the builder.\n    ///\n    /// Takes `&mut self` to access the inner world reference while initializing\n    /// state for the new [`QueryState`]\n    pub fn build(&mut self) -> QueryState<D, F> {\n        QueryState::<D, F>::from_builder(self)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use crate as bevy_ecs;\n    use crate::{prelude::*, world::FilteredEntityRef};\n\n    #[derive(Component, PartialEq, Debug)]\n    struct A(usize);\n\n    #[derive(Component, PartialEq, Debug)]\n    struct B(usize);\n\n    #[derive(Component, PartialEq, Debug)]\n    struct C(usize);\n\n    #[test]\n    fn builder_with_without_static() {\n        let mut world = World::new();\n        let entity_a = world.spawn((A(0), B(0))).id();\n        let entity_b = world.spawn((A(0), C(0))).id();\n\n        let mut query_a = QueryBuilder::<Entity>::new(&mut world)\n            .with::<A>()\n            .without::<C>()\n            .build();\n        assert_eq!(entity_a, query_a.single(&world));\n\n        let mut query_b = QueryBuilder::<Entity>::new(&mut world)\n            .with::<A>()\n            .without::<B>()\n            .build();\n        assert_eq!(entity_b, query_b.single(&world));\n    }\n\n    #[test]\n    fn builder_with_without_dynamic() {\n        let mut world = World::new();\n        let entity_a = world.spawn((A(0), B(0))).id();\n        let entity_b = world.spawn((A(0), C(0))).id();\n        let component_id_a = world.register_component::<A>();\n        let component_id_b = world.register_component::<B>();\n        let component_id_c = world.register_component::<C>();\n\n        let mut query_a = QueryBuilder::<Entity>::new(&mut world)\n            .with_id(component_id_a)\n            .without_id(component_id_c)\n            .build();\n        assert_eq!(entity_a, query_a.single(&world));\n\n        let mut query_b = QueryBuilder::<Entity>::new(&mut world)\n            .with_id(component_id_a)\n            .without_id(component_id_b)\n            .build();\n        assert_eq!(entity_b, query_b.single(&world));\n    }\n\n    #[test]\n    fn builder_or() {\n        let mut world = World::new();\n        world.spawn((A(0), B(0)));\n        world.spawn(B(0));\n        world.spawn(C(0));\n\n        let mut query_a = QueryBuilder::<Entity>::new(&mut world)\n            .or(|builder| {\n                builder.with::<A>();\n                builder.with::<B>();\n            })\n            .build();\n        assert_eq!(2, query_a.iter(&world).count());\n\n        let mut query_b = QueryBuilder::<Entity>::new(&mut world)\n            .or(|builder| {\n                builder.with::<A>();\n                builder.without::<B>();\n            })\n            .build();\n        dbg!(&query_b.component_access);\n        assert_eq!(2, query_b.iter(&world).count());\n\n        let mut query_c = QueryBuilder::<Entity>::new(&mut world)\n            .or(|builder| {\n                builder.with::<A>();\n                builder.with::<B>();\n                builder.with::<C>();\n            })\n            .build();\n        assert_eq!(3, query_c.iter(&world).count());\n    }\n\n    #[test]\n    fn builder_transmute() {\n        let mut world = World::new();\n        world.spawn(A(0));\n        world.spawn((A(1), B(0)));\n        let mut query = QueryBuilder::<()>::new(&mut world)\n            .with::<B>()\n            .transmute::<&A>()\n            .build();\n\n        query.iter(&world).for_each(|a| assert_eq!(a.0, 1));\n    }\n\n    #[test]\n    fn builder_static_components() {\n        let mut world = World::new();\n        let entity = world.spawn((A(0), B(1))).id();\n\n        let mut query = QueryBuilder::<FilteredEntityRef>::new(&mut world)\n            .data::<&A>()\n            .data::<&B>()\n            .build();\n\n        let entity_ref = query.single(&world);\n\n        assert_eq!(entity, entity_ref.id());\n\n        let a = entity_ref.get::<A>().unwrap();\n        let b = entity_ref.get::<B>().unwrap();\n\n        assert_eq!(0, a.0);\n        assert_eq!(1, b.0);\n    }\n\n    #[test]\n    fn builder_dynamic_components() {\n        let mut world = World::new();\n        let entity = world.spawn((A(0), B(1))).id();\n        let component_id_a = world.register_component::<A>();\n        let component_id_b = world.register_component::<B>();\n\n        let mut query = QueryBuilder::<FilteredEntityRef>::new(&mut world)\n            .ref_id(component_id_a)\n            .ref_id(component_id_b)\n            .build();\n\n        let entity_ref = query.single(&world);\n\n        assert_eq!(entity, entity_ref.id());\n\n        let a = entity_ref.get_by_id(component_id_a).unwrap();\n        let b = entity_ref.get_by_id(component_id_b).unwrap();\n\n        // SAFETY: We set these pointers to point to these components\n        unsafe {\n            assert_eq!(0, a.deref::<A>().0);\n            assert_eq!(1, b.deref::<B>().0);\n        }\n    }\n\n    /// Regression test for issue #14348\n    #[test]\n    fn builder_static_dense_dynamic_sparse() {\n        #[derive(Component)]\n        struct Dense;\n\n        #[derive(Component)]\n        #[component(storage = \"SparseSet\")]\n        struct Sparse;\n\n        let mut world = World::new();\n\n        world.spawn(Dense);\n        world.spawn((Dense, Sparse));\n\n        let mut query = QueryBuilder::<&Dense>::new(&mut world)\n            .with::<Sparse>()\n            .build();\n\n        let matched = query.iter(&world).count();\n        assert_eq!(matched, 1);\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "64420337f2d53795f5412032995079c518873ad9",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_asset/src/io/wasm.rs",
    "func": "use crate::io::{\n    get_meta_path, AssetReader, AssetReaderError, EmptyPathStream, PathStream, Reader, VecReader,\n};\nuse bevy_utils::tracing::error;\nuse js_sys::{Uint8Array, JSON};\nuse std::path::{Path, PathBuf};\nuse wasm_bindgen::{prelude::wasm_bindgen, JsCast, JsValue};\nuse wasm_bindgen_futures::JsFuture;\nuse web_sys::Response;\n\n/// Represents the global object in the JavaScript context\n#[wasm_bindgen]\nextern \"C\" {\n    /// The [Global](https://developer.mozilla.org/en-US/docs/Glossary/Global_object) object.\n    type Global;\n\n    /// The [window](https://developer.mozilla.org/en-US/docs/Web/API/Window) global object.\n    #[wasm_bindgen(method, getter, js_name = Window)]\n    fn window(this: &Global) -> JsValue;\n\n    /// The [WorkerGlobalScope](https://developer.mozilla.org/en-US/docs/Web/API/WorkerGlobalScope) global object.\n    #[wasm_bindgen(method, getter, js_name = WorkerGlobalScope)]\n    fn worker(this: &Global) -> JsValue;\n}\n\n/// Reader implementation for loading assets via HTTP in Wasm.\npub struct HttpWasmAssetReader {\n    root_path: PathBuf,\n}\n\nimpl HttpWasmAssetReader {\n    /// Creates a new `WasmAssetReader`. The path provided will be used to build URLs to query for assets.\n    pub fn new<P: AsRef<Path>>(path: P) -> Self {\n        Self {\n            root_path: path.as_ref().to_owned(),\n        }\n    }\n}\n\nfn js_value_to_err(context: &str) -> impl FnOnce(JsValue) -> std::io::Error + '_ {\n    move |value| {\n        let message = match JSON::stringify(&value) {\n            Ok(js_str) => format!(\"Failed to {context}: {js_str}\"),\n            Err(_) => {\n                format!(\"Failed to {context} and also failed to stringify the JSValue of the error\")\n            }\n        };\n\n        std::io::Error::new(std::io::ErrorKind::Other, message)\n    }\n}\n\nimpl HttpWasmAssetReader {\n    async fn fetch_bytes<'a>(&self, path: PathBuf) -> Result<impl Reader, AssetReaderError> {\n        // The JS global scope includes a self-reference via a specializing name, which can be used to determine the type of global context available.\n        let global: Global = js_sys::global().unchecked_into();\n        let promise = if !global.window().is_undefined() {\n            let window: web_sys::Window = global.unchecked_into();\n            window.fetch_with_str(path.to_str().unwrap())\n        } else if !global.worker().is_undefined() {\n            let worker: web_sys::WorkerGlobalScope = global.unchecked_into();\n            worker.fetch_with_str(path.to_str().unwrap())\n        } else {\n            let error = std::io::Error::new(\n                std::io::ErrorKind::Other,\n                \"Unsupported JavaScript global context\",\n            );\n            return Err(AssetReaderError::Io(error.into()));\n        };\n        let resp_value = JsFuture::from(promise)\n            .await\n            .map_err(js_value_to_err(\"fetch path\"))?;\n        let resp = resp_value\n            .dyn_into::<Response>()\n            .map_err(js_value_to_err(\"convert fetch to Response\"))?;\n        match resp.status() {\n            200 => {\n                let data = JsFuture::from(resp.array_buffer().unwrap()).await.unwrap();\n                let bytes = Uint8Array::new(&data).to_vec();\n                let reader = VecReader::new(bytes);\n                Ok(reader)\n            }\n            404 => Err(AssetReaderError::NotFound(path)),\n            status => Err(AssetReaderError::HttpError(status)),\n        }\n    }\n}\n\nimpl AssetReader for HttpWasmAssetReader {\n    async fn read<'a>(&'a self, path: &'a Path) -> Result<impl Reader + 'a, AssetReaderError> {\n        let path = self.root_path.join(path);\n        self.fetch_bytes(path).await\n    }\n\n    async fn read_meta<'a>(&'a self, path: &'a Path) -> Result<impl Reader + 'a, AssetReaderError> {\n        let meta_path = get_meta_path(&self.root_path.join(path));\n        self.fetch_bytes(meta_path).await\n    }\n\n    async fn read_directory<'a>(\n        &'a self,\n        _path: &'a Path,\n    ) -> Result<Box<PathStream>, AssetReaderError> {\n        let stream: Box<PathStream> = Box::new(EmptyPathStream);\n        error!(\"Reading directories is not supported with the HttpWasmAssetReader\");\n        Ok(stream)\n    }\n\n    async fn is_directory<'a>(&'a self, _path: &'a Path) -> Result<bool, AssetReaderError> {\n        error!(\"Reading directories is not supported with the HttpWasmAssetReader\");\n        Ok(false)\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "75614b178e8ea3e529363284c9250de3c0f983dc",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_asset/src/server/mod.rs",
    "func": "mod info;\nmod loaders;\n\nuse crate::{\n    folder::LoadedFolder,\n    io::{\n        AssetReaderError, AssetSource, AssetSourceEvent, AssetSourceId, AssetSources,\n        ErasedAssetReader, MissingAssetSourceError, MissingProcessedAssetReaderError, Reader,\n    },\n    loader::{AssetLoader, ErasedAssetLoader, LoadContext, LoadedAsset},\n    meta::{\n        loader_settings_meta_transform, AssetActionMinimal, AssetMetaDyn, AssetMetaMinimal,\n        MetaTransform, Settings,\n    },\n    path::AssetPath,\n    Asset, AssetEvent, AssetHandleProvider, AssetId, AssetLoadFailedEvent, AssetMetaCheck, Assets,\n    DeserializeMetaError, ErasedLoadedAsset, Handle, LoadedUntypedAsset, UntypedAssetId,\n    UntypedAssetLoadFailedEvent, UntypedHandle,\n};\nuse alloc::sync::Arc;\nuse atomicow::CowArc;\nuse bevy_ecs::prelude::*;\nuse bevy_tasks::IoTaskPool;\nuse bevy_utils::{\n    tracing::{error, info},\n    HashSet,\n};\nuse core::{any::TypeId, future::Future, panic::AssertUnwindSafe, task::Poll};\nuse crossbeam_channel::{Receiver, Sender};\nuse either::Either;\nuse futures_lite::{FutureExt, StreamExt};\nuse info::*;\nuse loaders::*;\nuse parking_lot::{RwLock, RwLockWriteGuard};\nuse std::path::{Path, PathBuf};\nuse thiserror::Error;\n\n/// Loads and tracks the state of [`Asset`] values from a configured [`AssetReader`](crate::io::AssetReader). This can be used to kick off new asset loads and\n/// retrieve their current load states.\n///\n/// The general process to load an asset is:\n/// 1. Initialize a new [`Asset`] type with the [`AssetServer`] via [`AssetApp::init_asset`], which will internally call [`AssetServer::register_asset`]\n///     and set up related ECS [`Assets`] storage and systems.\n/// 2. Register one or more [`AssetLoader`]s for that asset with [`AssetApp::init_asset_loader`]\n/// 3. Add the asset to your asset folder (defaults to `assets`).\n/// 4. Call [`AssetServer::load`] with a path to your asset.\n///\n/// [`AssetServer`] can be cloned. It is backed by an [`Arc`] so clones will share state. Clones can be freely used in parallel.\n///\n/// [`AssetApp::init_asset`]: crate::AssetApp::init_asset\n/// [`AssetApp::init_asset_loader`]: crate::AssetApp::init_asset_loader\n#[derive(Resource, Clone)]\npub struct AssetServer {\n    pub(crate) data: Arc<AssetServerData>,\n}\n\n/// Internal data used by [`AssetServer`]. This is intended to be used from within an [`Arc`].\npub(crate) struct AssetServerData {\n    pub(crate) infos: RwLock<AssetInfos>,\n    pub(crate) loaders: Arc<RwLock<AssetLoaders>>,\n    asset_event_sender: Sender<InternalAssetEvent>,\n    asset_event_receiver: Receiver<InternalAssetEvent>,\n    sources: AssetSources,\n    mode: AssetServerMode,\n    meta_check: AssetMetaCheck,\n}\n\n/// The \"asset mode\" the server is currently in.\n#[derive(Clone, Copy, Debug, PartialEq, Eq)]\npub enum AssetServerMode {\n    /// This server loads unprocessed assets.\n    Unprocessed,\n    /// This server loads processed assets.\n    Processed,\n}\n\nimpl AssetServer {\n    /// Create a new instance of [`AssetServer`]. If `watch_for_changes` is true, the [`AssetReader`](crate::io::AssetReader) storage will watch for changes to\n    /// asset sources and hot-reload them.\n    pub fn new(sources: AssetSources, mode: AssetServerMode, watching_for_changes: bool) -> Self {\n        Self::new_with_loaders(\n            sources,\n            Default::default(),\n            mode,\n            AssetMetaCheck::Always,\n            watching_for_changes,\n        )\n    }\n\n    /// Create a new instance of [`AssetServer`]. If `watch_for_changes` is true, the [`AssetReader`](crate::io::AssetReader) storage will watch for changes to\n    /// asset sources and hot-reload them.\n    pub fn new_with_meta_check(\n        sources: AssetSources,\n        mode: AssetServerMode,\n        meta_check: AssetMetaCheck,\n        watching_for_changes: bool,\n    ) -> Self {\n        Self::new_with_loaders(\n            sources,\n            Default::default(),\n            mode,\n            meta_check,\n            watching_for_changes,\n        )\n    }\n\n    pub(crate) fn new_with_loaders(\n        sources: AssetSources,\n        loaders: Arc<RwLock<AssetLoaders>>,\n        mode: AssetServerMode,\n        meta_check: AssetMetaCheck,\n        watching_for_changes: bool,\n    ) -> Self {\n        let (asset_event_sender, asset_event_receiver) = crossbeam_channel::unbounded();\n        let mut infos = AssetInfos::default();\n        infos.watching_for_changes = watching_for_changes;\n        Self {\n            data: Arc::new(AssetServerData {\n                sources,\n                mode,\n                meta_check,\n                asset_event_sender,\n                asset_event_receiver,\n                loaders,\n                infos: RwLock::new(infos),\n            }),\n        }\n    }\n\n    /// Retrieves the [`AssetSource`] for the given `source`.\n    pub fn get_source<'a>(\n        &self,\n        source: impl Into<AssetSourceId<'a>>,\n    ) -> Result<&AssetSource, MissingAssetSourceError> {\n        self.data.sources.get(source.into())\n    }\n\n    /// Returns true if the [`AssetServer`] watches for changes.\n    pub fn watching_for_changes(&self) -> bool {\n        self.data.infos.read().watching_for_changes\n    }\n\n    /// Registers a new [`AssetLoader`]. [`AssetLoader`]s must be registered before they can be used.\n    pub fn register_loader<L: AssetLoader>(&self, loader: L) {\n        self.data.loaders.write().push(loader);\n    }\n\n    /// Registers a new [`Asset`] type. [`Asset`] types must be registered before assets of that type can be loaded.\n    pub fn register_asset<A: Asset>(&self, assets: &Assets<A>) {\n        self.register_handle_provider(assets.get_handle_provider());\n        fn sender<A: Asset>(world: &mut World, id: UntypedAssetId) {\n            world\n                .resource_mut::<Events<AssetEvent<A>>>()\n                .send(AssetEvent::LoadedWithDependencies { id: id.typed() });\n        }\n        fn failed_sender<A: Asset>(\n            world: &mut World,\n            id: UntypedAssetId,\n            path: AssetPath<'static>,\n            error: AssetLoadError,\n        ) {\n            world\n                .resource_mut::<Events<AssetLoadFailedEvent<A>>>()\n                .send(AssetLoadFailedEvent {\n                    id: id.typed(),\n                    path,\n                    error,\n                });\n        }\n\n        let mut infos = self.data.infos.write();\n\n        infos\n            .dependency_loaded_event_sender\n            .insert(TypeId::of::<A>(), sender::<A>);\n\n        infos\n            .dependency_failed_event_sender\n            .insert(TypeId::of::<A>(), failed_sender::<A>);\n    }\n\n    pub(crate) fn register_handle_provider(&self, handle_provider: AssetHandleProvider) {\n        let mut infos = self.data.infos.write();\n        infos\n            .handle_providers\n            .insert(handle_provider.type_id, handle_provider);\n    }\n\n    /// Returns the registered [`AssetLoader`] associated with the given extension, if it exists.\n    pub async fn get_asset_loader_with_extension(\n        &self,\n        extension: &str,\n    ) -> Result<Arc<dyn ErasedAssetLoader>, MissingAssetLoaderForExtensionError> {\n        let error = || MissingAssetLoaderForExtensionError {\n            extensions: vec![extension.to_string()],\n        };\n\n        let loader = { self.data.loaders.read().get_by_extension(extension) };\n\n        loader.ok_or_else(error)?.get().await.map_err(|_| error())\n    }\n\n    /// Returns the registered [`AssetLoader`] associated with the given [`std::any::type_name`], if it exists.\n    pub async fn get_asset_loader_with_type_name(\n        &self,\n        type_name: &str,\n    ) -> Result<Arc<dyn ErasedAssetLoader>, MissingAssetLoaderForTypeNameError> {\n        let error = || MissingAssetLoaderForTypeNameError {\n            type_name: type_name.to_string(),\n        };\n\n        let loader = { self.data.loaders.read().get_by_name(type_name) };\n\n        loader.ok_or_else(error)?.get().await.map_err(|_| error())\n    }\n\n    /// Retrieves the default [`AssetLoader`] for the given path, if one can be found.\n    pub async fn get_path_asset_loader<'a>(\n        &self,\n        path: impl Into<AssetPath<'a>>,\n    ) -> Result<Arc<dyn ErasedAssetLoader>, MissingAssetLoaderForExtensionError> {\n        let path = path.into();\n\n        let error = || {\n            let Some(full_extension) = path.get_full_extension() else {\n                return MissingAssetLoaderForExtensionError {\n                    extensions: Vec::new(),\n                };\n            };\n\n            let mut extensions = vec![full_extension.clone()];\n            extensions.extend(\n                AssetPath::iter_secondary_extensions(&full_extension).map(ToString::to_string),\n            );\n\n            MissingAssetLoaderForExtensionError { extensions }\n        };\n\n        let loader = { self.data.loaders.read().get_by_path(&path) };\n\n        loader.ok_or_else(error)?.get().await.map_err(|_| error())\n    }\n\n    /// Retrieves the default [`AssetLoader`] for the given [`Asset`] [`TypeId`], if one can be found.\n    pub async fn get_asset_loader_with_asset_type_id(\n        &self,\n        type_id: TypeId,\n    ) -> Result<Arc<dyn ErasedAssetLoader>, MissingAssetLoaderForTypeIdError> {\n        let error = || MissingAssetLoaderForTypeIdError { type_id };\n\n        let loader = { self.data.loaders.read().get_by_type(type_id) };\n\n        loader.ok_or_else(error)?.get().await.map_err(|_| error())\n    }\n\n    /// Retrieves the default [`AssetLoader`] for the given [`Asset`] type, if one can be found.\n    pub async fn get_asset_loader_with_asset_type<A: Asset>(\n        &self,\n    ) -> Result<Arc<dyn ErasedAssetLoader>, MissingAssetLoaderForTypeIdError> {\n        self.get_asset_loader_with_asset_type_id(TypeId::of::<A>())\n            .await\n    }\n\n    /// Begins loading an [`Asset`] of type `A` stored at `path`. This will not block on the asset load. Instead,\n    /// it returns a \"strong\" [`Handle`]. When the [`Asset`] is loaded (and enters [`LoadState::Loaded`]), it will be added to the\n    /// associated [`Assets`] resource.\n    ///\n    /// Note that if the asset at this path is already loaded, this function will return the existing handle,\n    /// and will not waste work spawning a new load task.\n    ///\n    /// In case the file path contains a hashtag (`#`), the `path` must be specified using [`Path`]\n    /// or [`AssetPath`] because otherwise the hashtag would be interpreted as separator between\n    /// the file path and the label. For example:\n    ///\n    /// ```no_run\n    /// # use bevy_asset::{AssetServer, Handle, LoadedUntypedAsset};\n    /// # use bevy_ecs::prelude::Res;\n    /// # use std::path::Path;\n    /// // `#path` is a label.\n    /// # fn setup(asset_server: Res<AssetServer>) {\n    /// # let handle: Handle<LoadedUntypedAsset> =\n    /// asset_server.load(\"some/file#path\");\n    ///\n    /// // `#path` is part of the file name.\n    /// # let handle: Handle<LoadedUntypedAsset> =\n    /// asset_server.load(Path::new(\"some/file#path\"));\n    /// # }\n    /// ```\n    ///\n    /// Furthermore, if you need to load a file with a hashtag in its name _and_ a label, you can\n    /// manually construct an [`AssetPath`].\n    ///\n    /// ```no_run\n    /// # use bevy_asset::{AssetPath, AssetServer, Handle, LoadedUntypedAsset};\n    /// # use bevy_ecs::prelude::Res;\n    /// # use std::path::Path;\n    /// # fn setup(asset_server: Res<AssetServer>) {\n    /// # let handle: Handle<LoadedUntypedAsset> =\n    /// asset_server.load(AssetPath::from_path(Path::new(\"some/file#path\")).with_label(\"subasset\"));\n    /// # }\n    /// ```\n    ///\n    /// You can check the asset's load state by reading [`AssetEvent`] events, calling [`AssetServer::load_state`], or checking\n    /// the [`Assets`] storage to see if the [`Asset`] exists yet.\n    ///\n    /// The asset load will fail and an error will be printed to the logs if the asset stored at `path` is not of type `A`.\n    #[must_use = \"not using the returned strong handle may result in the unexpected release of the asset\"]\n    pub fn load<'a, A: Asset>(&self, path: impl Into<AssetPath<'a>>) -> Handle<A> {\n        self.load_with_meta_transform(path, None, ())\n    }\n\n    /// Begins loading an [`Asset`] of type `A` stored at `path` while holding a guard item.\n    /// The guard item is dropped when either the asset is loaded or loading has failed.\n    ///\n    /// This function returns a \"strong\" [`Handle`]. When the [`Asset`] is loaded (and enters [`LoadState::Loaded`]), it will be added to the\n    /// associated [`Assets`] resource.\n    ///\n    /// The guard item should notify the caller in its [`Drop`] implementation. See example `multi_asset_sync`.\n    /// Synchronously this can be a [`Arc<AtomicU32>`] that decrements its counter, asynchronously this can be a `Barrier`.\n    /// This function only guarantees the asset referenced by the [`Handle`] is loaded. If your asset is separated into\n    /// multiple files, sub-assets referenced by the main asset might still be loading, depend on the implementation of the [`AssetLoader`].\n    ///\n    /// Additionally, you can check the asset's load state by reading [`AssetEvent`] events, calling [`AssetServer::load_state`], or checking\n    /// the [`Assets`] storage to see if the [`Asset`] exists yet.\n    ///\n    /// The asset load will fail and an error will be printed to the logs if the asset stored at `path` is not of type `A`.\n    #[must_use = \"not using the returned strong handle may result in the unexpected release of the asset\"]\n    pub fn load_acquire<'a, A: Asset, G: Send + Sync + 'static>(\n        &self,\n        path: impl Into<AssetPath<'a>>,\n        guard: G,\n    ) -> Handle<A> {\n        self.load_with_meta_transform(path, None, guard)\n    }\n\n    /// Begins loading an [`Asset`] of type `A` stored at `path`. The given `settings` function will override the asset's\n    /// [`AssetLoader`] settings. The type `S` _must_ match the configured [`AssetLoader::Settings`] or `settings` changes\n    /// will be ignored and an error will be printed to the log.\n    #[must_use = \"not using the returned strong handle may result in the unexpected release of the asset\"]\n    pub fn load_with_settings<'a, A: Asset, S: Settings>(\n        &self,\n        path: impl Into<AssetPath<'a>>,\n        settings: impl Fn(&mut S) + Send + Sync + 'static,\n    ) -> Handle<A> {\n        self.load_with_meta_transform(path, Some(loader_settings_meta_transform(settings)), ())\n    }\n\n    /// Begins loading an [`Asset`] of type `A` stored at `path` while holding a guard item.\n    /// The guard item is dropped when either the asset is loaded or loading has failed.\n    ///\n    /// This function only guarantees the asset referenced by the [`Handle`] is loaded. If your asset is separated into\n    /// multiple files, sub-assets referenced by the main asset might still be loading, depend on the implementation of the [`AssetLoader`].\n    ///\n    /// The given `settings` function will override the asset's\n    /// [`AssetLoader`] settings. The type `S` _must_ match the configured [`AssetLoader::Settings`] or `settings` changes\n    /// will be ignored and an error will be printed to the log.\n    #[must_use = \"not using the returned strong handle may result in the unexpected release of the asset\"]\n    pub fn load_acquire_with_settings<'a, A: Asset, S: Settings, G: Send + Sync + 'static>(\n        &self,\n        path: impl Into<AssetPath<'a>>,\n        settings: impl Fn(&mut S) + Send + Sync + 'static,\n        guard: G,\n    ) -> Handle<A> {\n        self.load_with_meta_transform(path, Some(loader_settings_meta_transform(settings)), guard)\n    }\n\n    pub(crate) fn load_with_meta_transform<'a, A: Asset, G: Send + Sync + 'static>(\n        &self,\n        path: impl Into<AssetPath<'a>>,\n        meta_transform: Option<MetaTransform>,\n        guard: G,\n    ) -> Handle<A> {\n        let path = path.into().into_owned();\n        let mut infos = self.data.infos.write();\n        let (handle, should_load) = infos.get_or_create_path_handle::<A>(\n            path.clone(),\n            HandleLoadingMode::Request,\n            meta_transform,\n        );\n\n        if should_load {\n            self.spawn_load_task(handle.clone().untyped(), path, infos, guard);\n        }\n\n        handle\n    }\n\n    pub(crate) fn load_erased_with_meta_transform<'a, G: Send + Sync + 'static>(\n        &self,\n        path: impl Into<AssetPath<'a>>,\n        type_id: TypeId,\n        meta_transform: Option<MetaTransform>,\n        guard: G,\n    ) -> UntypedHandle {\n        let path = path.into().into_owned();\n        let mut infos = self.data.infos.write();\n        let (handle, should_load) = infos.get_or_create_path_handle_erased(\n            path.clone(),\n            type_id,\n            None,\n            HandleLoadingMode::Request,\n            meta_transform,\n        );\n\n        if should_load {\n            self.spawn_load_task(handle.clone(), path, infos, guard);\n        }\n\n        handle\n    }\n\n    pub(crate) fn spawn_load_task<G: Send + Sync + 'static>(\n        &self,\n        handle: UntypedHandle,\n        path: AssetPath<'static>,\n        infos: RwLockWriteGuard<AssetInfos>,\n        guard: G,\n    ) {\n        // drop the lock on `AssetInfos` before spawning a task that may block on it in single-threaded\n        #[cfg(any(target_arch = \"wasm32\", not(feature = \"multi_threaded\")))]\n        drop(infos);\n\n        let owned_handle = handle.clone();\n        let server = self.clone();\n        let task = IoTaskPool::get().spawn(async move {\n            if let Err(err) = server\n                .load_internal(Some(owned_handle), path, false, None)\n                .await\n            {\n                error!(\"{}\", err);\n            }\n            drop(guard);\n        });\n\n        #[cfg(not(any(target_arch = \"wasm32\", not(feature = \"multi_threaded\"))))]\n        {\n            let mut infos = infos;\n            infos.pending_tasks.insert(handle.id(), task);\n        }\n\n        #[cfg(any(target_arch = \"wasm32\", not(feature = \"multi_threaded\")))]\n        task.detach();\n    }\n\n    /// Asynchronously load an asset that you do not know the type of statically. If you _do_ know the type of the asset,\n    /// you should use [`AssetServer::load`]. If you don't know the type of the asset, but you can't use an async method,\n    /// consider using [`AssetServer::load_untyped`].\n    #[must_use = \"not using the returned strong handle may result in the unexpected release of the asset\"]\n    pub async fn load_untyped_async<'a>(\n        &self,\n        path: impl Into<AssetPath<'a>>,\n    ) -> Result<UntypedHandle, AssetLoadError> {\n        let path: AssetPath = path.into();\n        self.load_internal(None, path, false, None).await\n    }\n\n    pub(crate) fn load_unknown_type_with_meta_transform<'a>(\n        &self,\n        path: impl Into<AssetPath<'a>>,\n        meta_transform: Option<MetaTransform>,\n    ) -> Handle<LoadedUntypedAsset> {\n        let path = path.into().into_owned();\n        let untyped_source = AssetSourceId::Name(match path.source() {\n            AssetSourceId::Default => CowArc::Static(UNTYPED_SOURCE_SUFFIX),\n            AssetSourceId::Name(source) => {\n                CowArc::Owned(format!(\"{source}--{UNTYPED_SOURCE_SUFFIX}\").into())\n            }\n        });\n        let mut infos = self.data.infos.write();\n        let (handle, should_load) = infos.get_or_create_path_handle::<LoadedUntypedAsset>(\n            path.clone().with_source(untyped_source),\n            HandleLoadingMode::Request,\n            meta_transform,\n        );\n\n        // drop the lock on `AssetInfos` before spawning a task that may block on it in single-threaded\n        #[cfg(any(target_arch = \"wasm32\", not(feature = \"multi_threaded\")))]\n        drop(infos);\n\n        if !should_load {\n            return handle;\n        }\n        let id = handle.id().untyped();\n\n        let server = self.clone();\n        let task = IoTaskPool::get().spawn(async move {\n            let path_clone = path.clone();\n            match server.load_untyped_async(path).await {\n                Ok(handle) => server.send_asset_event(InternalAssetEvent::Loaded {\n                    id,\n                    loaded_asset: LoadedAsset::new_with_dependencies(\n                        LoadedUntypedAsset { handle },\n                        None,\n                    )\n                    .into(),\n                }),\n                Err(err) => {\n                    error!(\"{err}\");\n                    server.send_asset_event(InternalAssetEvent::Failed {\n                        id,\n                        path: path_clone,\n                        error: err,\n                    });\n                }\n            }\n        });\n\n        #[cfg(not(any(target_arch = \"wasm32\", not(feature = \"multi_threaded\"))))]\n        infos.pending_tasks.insert(handle.id().untyped(), task);\n\n        #[cfg(any(target_arch = \"wasm32\", not(feature = \"multi_threaded\")))]\n        task.detach();\n\n        handle\n    }\n\n    /// Load an asset without knowing its type. The method returns a handle to a [`LoadedUntypedAsset`].\n    ///\n    /// Once the [`LoadedUntypedAsset`] is loaded, an untyped handle for the requested path can be\n    /// retrieved from it.\n    ///\n    /// ```\n    /// use bevy_asset::{Assets, Handle, LoadedUntypedAsset};\n    /// use bevy_ecs::system::{Res, Resource};\n    ///\n    /// #[derive(Resource)]\n    /// struct LoadingUntypedHandle(Handle<LoadedUntypedAsset>);\n    ///\n    /// fn resolve_loaded_untyped_handle(loading_handle: Res<LoadingUntypedHandle>, loaded_untyped_assets: Res<Assets<LoadedUntypedAsset>>) {\n    ///     if let Some(loaded_untyped_asset) = loaded_untyped_assets.get(&loading_handle.0) {\n    ///         let handle = loaded_untyped_asset.handle.clone();\n    ///         // continue working with `handle` which points to the asset at the originally requested path\n    ///     }\n    /// }\n    /// ```\n    ///\n    /// This indirection enables a non blocking load of an untyped asset, since I/O is\n    /// required to figure out the asset type before a handle can be created.\n    #[must_use = \"not using the returned strong handle may result in the unexpected release of the assets\"]\n    pub fn load_untyped<'a>(&self, path: impl Into<AssetPath<'a>>) -> Handle<LoadedUntypedAsset> {\n        self.load_unknown_type_with_meta_transform(path, None)\n    }\n\n    /// Performs an async asset load.\n    ///\n    /// `input_handle` must only be [`Some`] if `should_load` was true when retrieving `input_handle`. This is an optimization to\n    /// avoid looking up `should_load` twice, but it means you _must_ be sure a load is necessary when calling this function with [`Some`].\n    async fn load_internal<'a>(\n        &self,\n        mut input_handle: Option<UntypedHandle>,\n        path: AssetPath<'a>,\n        force: bool,\n        meta_transform: Option<MetaTransform>,\n    ) -> Result<UntypedHandle, AssetLoadError> {\n        let asset_type_id = input_handle.as_ref().map(UntypedHandle::type_id);\n\n        let path = path.into_owned();\n        let path_clone = path.clone();\n        let (mut meta, loader, mut reader) = self\n            .get_meta_loader_and_reader(&path_clone, asset_type_id)\n            .await\n            .inspect_err(|e| {\n                // if there was an input handle, a \"load\" operation has already started, so we must produce a \"failure\" event, if\n                // we cannot find the meta and loader\n                if let Some(handle) = &input_handle {\n                    self.send_asset_event(InternalAssetEvent::Failed {\n                        id: handle.id(),\n                        path: path.clone_owned(),\n                        error: e.clone(),\n                    });\n                }\n            })?;\n\n        if let Some(meta_transform) = input_handle.as_ref().and_then(|h| h.meta_transform()) {\n            (*meta_transform)(&mut *meta);\n        }\n        // downgrade the input handle so we don't keep the asset alive just because we're loading it\n        // note we can't just pass a weak handle in, as only strong handles contain the asset meta transform\n        input_handle = input_handle.map(|h| h.clone_weak());\n\n        // This contains Some(UntypedHandle), if it was retrievable\n        // If it is None, that is because it was _not_ retrievable, due to\n        //    1. The handle was not already passed in for this path, meaning we can't just use that\n        //    2. The asset has not been loaded yet, meaning there is no existing Handle for it\n        //    3. The path has a label, meaning the AssetLoader's root asset type is not the path's asset type\n        //\n        // In the None case, the only course of action is to wait for the asset to load so we can allocate the\n        // handle for that type.\n        //\n        // TODO: Note that in the None case, multiple asset loads for the same path can happen at the same time\n        // (rather than \"early out-ing\" in the \"normal\" case)\n        // This would be resolved by a universal asset id, as we would not need to resolve the asset type\n        // to generate the ID. See this issue: https://github.com/bevyengine/bevy/issues/10549\n        let handle_result = match input_handle {\n            Some(handle) => {\n                // if a handle was passed in, the \"should load\" check was already done\n                Some((handle, true))\n            }\n            None => {\n                let mut infos = self.data.infos.write();\n                let result = infos.get_or_create_path_handle_internal(\n                    path.clone(),\n                    path.label().is_none().then(|| loader.asset_type_id()),\n                    HandleLoadingMode::Request,\n                    meta_transform,\n                );\n                unwrap_with_context(result, Either::Left(loader.asset_type_name()))\n            }\n        };\n\n        let handle = if let Some((handle, should_load)) = handle_result {\n            if path.label().is_none() && handle.type_id() != loader.asset_type_id() {\n                error!(\n                    \"Expected {:?}, got {:?}\",\n                    handle.type_id(),\n                    loader.asset_type_id()\n                );\n                return Err(AssetLoadError::RequestedHandleTypeMismatch {\n                    path: path.into_owned(),\n                    requested: handle.type_id(),\n                    actual_asset_name: loader.asset_type_name(),\n                    loader_name: loader.type_name(),\n                });\n            }\n            if !should_load && !force {\n                return Ok(handle);\n            }\n            Some(handle)\n        } else {\n            None\n        };\n        // if the handle result is None, we definitely need to load the asset\n\n        let (base_handle, base_path) = if path.label().is_some() {\n            let mut infos = self.data.infos.write();\n            let base_path = path.without_label().into_owned();\n            let (base_handle, _) = infos.get_or_create_path_handle_erased(\n                base_path.clone(),\n                loader.asset_type_id(),\n                Some(loader.asset_type_name()),\n                HandleLoadingMode::Force,\n                None,\n            );\n            (base_handle, base_path)\n        } else {\n            (handle.clone().unwrap(), path.clone())\n        };\n\n        match self\n            .load_with_meta_loader_and_reader(&base_path, meta, &*loader, &mut *reader, true, false)\n            .await\n        {\n            Ok(loaded_asset) => {\n                let final_handle = if let Some(label) = path.label_cow() {\n                    match loaded_asset.labeled_assets.get(&label) {\n                        Some(labeled_asset) => labeled_asset.handle.clone(),\n                        None => {\n                            let mut all_labels: Vec<String> = loaded_asset\n                                .labeled_assets\n                                .keys()\n                                .map(|s| (**s).to_owned())\n                                .collect();\n                            all_labels.sort_unstable();\n                            return Err(AssetLoadError::MissingLabel {\n                                base_path,\n                                label: label.to_string(),\n                                all_labels,\n                            });\n                        }\n                    }\n                } else {\n                    // if the path does not have a label, the handle must exist at this point\n                    handle.unwrap()\n                };\n\n                self.send_loaded_asset(base_handle.id(), loaded_asset);\n                Ok(final_handle)\n            }\n            Err(err) => {\n                self.send_asset_event(InternalAssetEvent::Failed {\n                    id: base_handle.id(),\n                    error: err.clone(),\n                    path: path.into_owned(),\n                });\n                Err(err)\n            }\n        }\n    }\n\n    /// Sends a load event for the given `loaded_asset` and does the same recursively for all\n    /// labeled assets.\n    fn send_loaded_asset(&self, id: UntypedAssetId, mut loaded_asset: ErasedLoadedAsset) {\n        for (_, labeled_asset) in loaded_asset.labeled_assets.drain() {\n            self.send_loaded_asset(labeled_asset.handle.id(), labeled_asset.asset);\n        }\n\n        self.send_asset_event(InternalAssetEvent::Loaded { id, loaded_asset });\n    }\n\n    /// Kicks off a reload of the asset stored at the given path. This will only reload the asset if it currently loaded.\n    pub fn reload<'a>(&self, path: impl Into<AssetPath<'a>>) {\n        let server = self.clone();\n        let path = path.into().into_owned();\n        IoTaskPool::get()\n            .spawn(async move {\n                let mut reloaded = false;\n\n                let requests = server\n                    .data\n                    .infos\n                    .read()\n                    .get_path_handles(&path)\n                    .map(|handle| server.load_internal(Some(handle), path.clone(), true, None))\n                    .collect::<Vec<_>>();\n\n                for result in requests {\n                    match result.await {\n                        Ok(_) => reloaded = true,\n                        Err(err) => error!(\"{}\", err),\n                    }\n                }\n\n                if !reloaded && server.data.infos.read().should_reload(&path) {\n                    if let Err(err) = server.load_internal(None, path, true, None).await {\n                        error!(\"{}\", err);\n                    }\n                }\n            })\n            .detach();\n    }\n\n    /// Queues a new asset to be tracked by the [`AssetServer`] and returns a [`Handle`] to it. This can be used to track\n    /// dependencies of assets created at runtime.\n    ///\n    /// After the asset has been fully loaded by the [`AssetServer`], it will show up in the relevant [`Assets`] storage.\n    #[must_use = \"not using the returned strong handle may result in the unexpected release of the asset\"]\n    pub fn add<A: Asset>(&self, asset: A) -> Handle<A> {\n        self.load_asset(LoadedAsset::new_with_dependencies(asset, None))\n    }\n\n    pub(crate) fn load_asset<A: Asset>(&self, asset: impl Into<LoadedAsset<A>>) -> Handle<A> {\n        let loaded_asset: LoadedAsset<A> = asset.into();\n        let erased_loaded_asset: ErasedLoadedAsset = loaded_asset.into();\n        self.load_asset_untyped(None, erased_loaded_asset)\n            .typed_debug_checked()\n    }\n\n    #[must_use = \"not using the returned strong handle may result in the unexpected release of the asset\"]\n    pub(crate) fn load_asset_untyped(\n        &self,\n        path: Option<AssetPath<'static>>,\n        asset: impl Into<ErasedLoadedAsset>,\n    ) -> UntypedHandle {\n        let loaded_asset = asset.into();\n        let handle = if let Some(path) = path {\n            let (handle, _) = self.data.infos.write().get_or_create_path_handle_erased(\n                path,\n                loaded_asset.asset_type_id(),\n                Some(loaded_asset.asset_type_name()),\n                HandleLoadingMode::NotLoading,\n                None,\n            );\n            handle\n        } else {\n            self.data.infos.write().create_loading_handle_untyped(\n                loaded_asset.asset_type_id(),\n                loaded_asset.asset_type_name(),\n            )\n        };\n        self.send_asset_event(InternalAssetEvent::Loaded {\n            id: handle.id(),\n            loaded_asset,\n        });\n        handle\n    }\n\n    /// Queues a new asset to be tracked by the [`AssetServer`] and returns a [`Handle`] to it. This can be used to track\n    /// dependencies of assets created at runtime.\n    ///\n    /// After the asset has been fully loaded, it will show up in the relevant [`Assets`] storage.\n    #[must_use = \"not using the returned strong handle may result in the unexpected release of the asset\"]\n    pub fn add_async<A: Asset, E: core::error::Error + Send + Sync + 'static>(\n        &self,\n        future: impl Future<Output = Result<A, E>> + Send + 'static,\n    ) -> Handle<A> {\n        let mut infos = self.data.infos.write();\n        let handle =\n            infos.create_loading_handle_untyped(TypeId::of::<A>(), core::any::type_name::<A>());\n\n        // drop the lock on `AssetInfos` before spawning a task that may block on it in single-threaded\n        #[cfg(any(target_arch = \"wasm32\", not(feature = \"multi_threaded\")))]\n        drop(infos);\n\n        let id = handle.id();\n\n        let event_sender = self.data.asset_event_sender.clone();\n\n        let task = IoTaskPool::get().spawn(async move {\n            match future.await {\n                Ok(asset) => {\n                    let loaded_asset = LoadedAsset::new_with_dependencies(asset, None).into();\n                    event_sender\n                        .send(InternalAssetEvent::Loaded { id, loaded_asset })\n                        .unwrap();\n                }\n                Err(error) => {\n                    let error = AddAsyncError {\n                        error: Arc::new(error),\n                    };\n                    error!(\"{error}\");\n                    event_sender\n                        .send(InternalAssetEvent::Failed {\n                            id,\n                            path: Default::default(),\n                            error: AssetLoadError::AddAsyncError(error),\n                        })\n                        .unwrap();\n                }\n            }\n        });\n\n        #[cfg(not(any(target_arch = \"wasm32\", not(feature = \"multi_threaded\"))))]\n        infos.pending_tasks.insert(id, task);\n\n        #[cfg(any(target_arch = \"wasm32\", not(feature = \"multi_threaded\")))]\n        task.detach();\n\n        handle.typed_debug_checked()\n    }\n\n    /// Loads all assets from the specified folder recursively. The [`LoadedFolder`] asset (when it loads) will\n    /// contain handles to all assets in the folder. You can wait for all assets to load by checking the [`LoadedFolder`]'s\n    /// [`RecursiveDependencyLoadState`].\n    ///\n    /// Loading the same folder multiple times will return the same handle. If the `file_watcher`\n    /// feature is enabled, [`LoadedFolder`] handles will reload when a file in the folder is\n    /// removed, added or moved. This includes files in subdirectories and moving, adding,\n    /// or removing complete subdirectories.\n    #[must_use = \"not using the returned strong handle may result in the unexpected release of the assets\"]\n    pub fn load_folder<'a>(&self, path: impl Into<AssetPath<'a>>) -> Handle<LoadedFolder> {\n        let path = path.into().into_owned();\n        let (handle, should_load) = self\n            .data\n            .infos\n            .write()\n            .get_or_create_path_handle::<LoadedFolder>(\n                path.clone(),\n                HandleLoadingMode::Request,\n                None,\n            );\n        if !should_load {\n            return handle;\n        }\n        let id = handle.id().untyped();\n        self.load_folder_internal(id, path);\n\n        handle\n    }\n\n    pub(crate) fn load_folder_internal(&self, id: UntypedAssetId, path: AssetPath) {\n        async fn load_folder<'a>(\n            source: AssetSourceId<'static>,\n            path: &'a Path,\n            reader: &'a dyn ErasedAssetReader,\n            server: &'a AssetServer,\n            handles: &'a mut Vec<UntypedHandle>,\n        ) -> Result<(), AssetLoadError> {\n            let is_dir = reader.is_directory(path).await?;\n            if is_dir {\n                let mut path_stream = reader.read_directory(path.as_ref()).await?;\n                while let Some(child_path) = path_stream.next().await {\n                    if reader.is_directory(&child_path).await? {\n                        Box::pin(load_folder(\n                            source.clone(),\n                            &child_path,\n                            reader,\n                            server,\n                            handles,\n                        ))\n                        .await?;\n                    } else {\n                        let path = child_path.to_str().expect(\"Path should be a valid string.\");\n                        let asset_path = AssetPath::parse(path).with_source(source.clone());\n                        match server.load_untyped_async(asset_path).await {\n                            Ok(handle) => handles.push(handle),\n                            // skip assets that cannot be loaded\n                            Err(\n                                AssetLoadError::MissingAssetLoaderForTypeName(_)\n                                | AssetLoadError::MissingAssetLoaderForExtension(_),\n                            ) => {}\n                            Err(err) => return Err(err),\n                        }\n                    }\n                }\n            }\n            Ok(())\n        }\n\n        let path = path.into_owned();\n        let server = self.clone();\n        IoTaskPool::get()\n            .spawn(async move {\n                let Ok(source) = server.get_source(path.source()) else {\n                    error!(\n                        \"Failed to load {path}. AssetSource {:?} does not exist\",\n                        path.source()\n                    );\n                    return;\n                };\n\n                let asset_reader = match server.data.mode {\n                    AssetServerMode::Unprocessed { .. } => source.reader(),\n                    AssetServerMode::Processed { .. } => match source.processed_reader() {\n                        Ok(reader) => reader,\n                        Err(_) => {\n                            error!(\n                                \"Failed to load {path}. AssetSource {:?} does not have a processed AssetReader\",\n                                path.source()\n                            );\n                            return;\n                        }\n                    },\n                };\n\n                let mut handles = Vec::new();\n                match load_folder(source.id(), path.path(), asset_reader, &server, &mut handles).await {\n                    Ok(_) => server.send_asset_event(InternalAssetEvent::Loaded {\n                        id,\n                        loaded_asset: LoadedAsset::new_with_dependencies(\n                            LoadedFolder { handles },\n                            None,\n                        )\n                        .into(),\n                    }),\n                    Err(err) => {\n                        error!(\"Failed to load folder. {err}\");\n                        server.send_asset_event(InternalAssetEvent::Failed { id, error: err, path });\n                    },\n                }\n            })\n            .detach();\n    }\n\n    fn send_asset_event(&self, event: InternalAssetEvent) {\n        self.data.asset_event_sender.send(event).unwrap();\n    }\n\n    /// Retrieves all loads states for the given asset id.\n    pub fn get_load_states(\n        &self,\n        id: impl Into<UntypedAssetId>,\n    ) -> Option<(LoadState, DependencyLoadState, RecursiveDependencyLoadState)> {\n        self.data.infos.read().get(id.into()).map(|i| {\n            (\n                i.load_state.clone(),\n                i.dep_load_state.clone(),\n                i.rec_dep_load_state.clone(),\n            )\n        })\n    }\n\n    /// Retrieves the main [`LoadState`] of a given asset `id`.\n    ///\n    /// Note that this is \"just\" the root asset load state. To get the load state of\n    /// its dependencies or recursive dependencies, see [`AssetServer::get_dependency_load_state`]\n    /// and [`AssetServer::get_recursive_dependency_load_state`] respectively.\n    pub fn get_load_state(&self, id: impl Into<UntypedAssetId>) -> Option<LoadState> {\n        self.data\n            .infos\n            .read()\n            .get(id.into())\n            .map(|i| i.load_state.clone())\n    }\n\n    /// Retrieves the [`DependencyLoadState`] of a given asset `id`'s dependencies.\n    ///\n    /// Note that this is only the load state of direct dependencies of the root asset. To get\n    /// the load state of the root asset itself or its recursive dependencies, see\n    /// [`AssetServer::get_load_state`] and [`AssetServer::get_recursive_dependency_load_state`] respectively.\n    pub fn get_dependency_load_state(\n        &self,\n        id: impl Into<UntypedAssetId>,\n    ) -> Option<DependencyLoadState> {\n        self.data\n            .infos\n            .read()\n            .get(id.into())\n            .map(|i| i.dep_load_state.clone())\n    }\n\n    /// Retrieves the main [`RecursiveDependencyLoadState`] of a given asset `id`'s recursive dependencies.\n    ///\n    /// Note that this is only the load state of recursive dependencies of the root asset. To get\n    /// the load state of the root asset itself or its direct dependencies only, see\n    /// [`AssetServer::get_load_state`] and [`AssetServer::get_dependency_load_state`] respectively.\n    pub fn get_recursive_dependency_load_state(\n        &self,\n        id: impl Into<UntypedAssetId>,\n    ) -> Option<RecursiveDependencyLoadState> {\n        self.data\n            .infos\n            .read()\n            .get(id.into())\n            .map(|i| i.rec_dep_load_state.clone())\n    }\n\n    /// Retrieves the main [`LoadState`] of a given asset `id`.\n    ///\n    /// This is the same as [`AssetServer::get_load_state`] except the result is unwrapped. If\n    /// the result is None, [`LoadState::NotLoaded`] is returned.\n    pub fn load_state(&self, id: impl Into<UntypedAssetId>) -> LoadState {\n        self.get_load_state(id).unwrap_or(LoadState::NotLoaded)\n    }\n\n    /// Retrieves the [`DependencyLoadState`] of a given asset `id`.\n    ///\n    /// This is the same as [`AssetServer::get_dependency_load_state`] except the result is unwrapped. If\n    /// the result is None, [`DependencyLoadState::NotLoaded`] is returned.\n    pub fn dependency_load_state(&self, id: impl Into<UntypedAssetId>) -> DependencyLoadState {\n        self.get_dependency_load_state(id)\n            .unwrap_or(DependencyLoadState::NotLoaded)\n    }\n\n    /// Retrieves the  [`RecursiveDependencyLoadState`] of a given asset `id`.\n    ///\n    /// This is the same as [`AssetServer::get_recursive_dependency_load_state`] except the result is unwrapped. If\n    /// the result is None, [`RecursiveDependencyLoadState::NotLoaded`] is returned.\n    pub fn recursive_dependency_load_state(\n        &self,\n        id: impl Into<UntypedAssetId>,\n    ) -> RecursiveDependencyLoadState {\n        self.get_recursive_dependency_load_state(id)\n            .unwrap_or(RecursiveDependencyLoadState::NotLoaded)\n    }\n\n    /// Convenience method that returns true if the asset has been loaded.\n    pub fn is_loaded(&self, id: impl Into<UntypedAssetId>) -> bool {\n        matches!(self.load_state(id), LoadState::Loaded)\n    }\n\n    /// Convenience method that returns true if the asset and all of its direct dependencies have been loaded.\n    pub fn is_loaded_with_direct_dependencies(&self, id: impl Into<UntypedAssetId>) -> bool {\n        matches!(\n            self.get_load_states(id),\n            Some((LoadState::Loaded, DependencyLoadState::Loaded, _))\n        )\n    }\n\n    /// Convenience method that returns true if the asset, all of its dependencies, and all of its recursive\n    /// dependencies have been loaded.\n    pub fn is_loaded_with_dependencies(&self, id: impl Into<UntypedAssetId>) -> bool {\n        matches!(\n            self.get_load_states(id),\n            Some((\n                LoadState::Loaded,\n                DependencyLoadState::Loaded,\n                RecursiveDependencyLoadState::Loaded\n            ))\n        )\n    }\n\n    /// Returns an active handle for the given path, if the asset at the given path has already started loading,\n    /// or is still \"alive\".\n    pub fn get_handle<'a, A: Asset>(&self, path: impl Into<AssetPath<'a>>) -> Option<Handle<A>> {\n        self.get_path_and_type_id_handle(&path.into(), TypeId::of::<A>())\n            .map(UntypedHandle::typed_debug_checked)\n    }\n\n    /// Get a `Handle` from an `AssetId`.\n    ///\n    /// This only returns `Some` if `id` is derived from a `Handle` that was\n    /// loaded through an `AssetServer`, otherwise it returns `None`.\n    ///\n    /// Consider using [`Assets::get_strong_handle`] in the case the `Handle`\n    /// comes from [`Assets::add`].\n    pub fn get_id_handle<A: Asset>(&self, id: AssetId<A>) -> Option<Handle<A>> {\n        self.get_id_handle_untyped(id.untyped())\n            .map(UntypedHandle::typed)\n    }\n\n    /// Get an `UntypedHandle` from an `UntypedAssetId`.\n    /// See [`AssetServer::get_id_handle`] for details.\n    pub fn get_id_handle_untyped(&self, id: UntypedAssetId) -> Option<UntypedHandle> {\n        self.data.infos.read().get_id_handle(id)\n    }\n\n    /// Returns `true` if the given `id` corresponds to an asset that is managed by this [`AssetServer`].\n    /// Otherwise, returns `false`.\n    pub fn is_managed(&self, id: impl Into<UntypedAssetId>) -> bool {\n        self.data.infos.read().contains_key(id.into())\n    }\n\n    /// Returns an active untyped asset id for the given path, if the asset at the given path has already started loading,\n    /// or is still \"alive\".\n    /// Returns the first ID in the event of multiple assets being registered against a single path.\n    ///\n    /// # See also\n    /// [`get_path_ids`][Self::get_path_ids] for all handles.\n    pub fn get_path_id<'a>(&self, path: impl Into<AssetPath<'a>>) -> Option<UntypedAssetId> {\n        let infos = self.data.infos.read();\n        let path = path.into();\n        let mut ids = infos.get_path_ids(&path);\n        ids.next()\n    }\n\n    /// Returns all active untyped asset IDs for the given path, if the assets at the given path have already started loading,\n    /// or are still \"alive\".\n    /// Multiple IDs will be returned in the event that a single path is used by multiple [`AssetLoader`]'s.\n    pub fn get_path_ids<'a>(&self, path: impl Into<AssetPath<'a>>) -> Vec<UntypedAssetId> {\n        let infos = self.data.infos.read();\n        let path = path.into();\n        infos.get_path_ids(&path).collect()\n    }\n\n    /// Returns an active untyped handle for the given path, if the asset at the given path has already started loading,\n    /// or is still \"alive\".\n    /// Returns the first handle in the event of multiple assets being registered against a single path.\n    ///\n    /// # See also\n    /// [`get_handles_untyped`][Self::get_handles_untyped] for all handles.\n    pub fn get_handle_untyped<'a>(&self, path: impl Into<AssetPath<'a>>) -> Option<UntypedHandle> {\n        let infos = self.data.infos.read();\n        let path = path.into();\n        let mut handles = infos.get_path_handles(&path);\n        handles.next()\n    }\n\n    /// Returns all active untyped handles for the given path, if the assets at the given path have already started loading,\n    /// or are still \"alive\".\n    /// Multiple handles will be returned in the event that a single path is used by multiple [`AssetLoader`]'s.\n    pub fn get_handles_untyped<'a>(&self, path: impl Into<AssetPath<'a>>) -> Vec<UntypedHandle> {\n        let infos = self.data.infos.read();\n        let path = path.into();\n        infos.get_path_handles(&path).collect()\n    }\n\n    /// Returns an active untyped handle for the given path and [`TypeId`], if the asset at the given path has already started loading,\n    /// or is still \"alive\".\n    pub fn get_path_and_type_id_handle(\n        &self,\n        path: &AssetPath,\n        type_id: TypeId,\n    ) -> Option<UntypedHandle> {\n        let infos = self.data.infos.read();\n        let path = path.into();\n        infos.get_path_and_type_id_handle(&path, type_id)\n    }\n\n    /// Returns the path for the given `id`, if it has one.\n    pub fn get_path(&self, id: impl Into<UntypedAssetId>) -> Option<AssetPath> {\n        let infos = self.data.infos.read();\n        let info = infos.get(id.into())?;\n        Some(info.path.as_ref()?.clone())\n    }\n\n    /// Returns the [`AssetServerMode`] this server is currently in.\n    pub fn mode(&self) -> AssetServerMode {\n        self.data.mode\n    }\n\n    /// Pre-register a loader that will later be added.\n    ///\n    /// Assets loaded with matching extensions will be blocked until the\n    /// real loader is added.\n    pub fn preregister_loader<L: AssetLoader>(&self, extensions: &[&str]) {\n        self.data.loaders.write().reserve::<L>(extensions);\n    }\n\n    /// Retrieve a handle for the given path. This will create a handle (and [`AssetInfo`]) if it does not exist\n    pub(crate) fn get_or_create_path_handle<'a, A: Asset>(\n        &self,\n        path: impl Into<AssetPath<'a>>,\n        meta_transform: Option<MetaTransform>,\n    ) -> Handle<A> {\n        let mut infos = self.data.infos.write();\n        infos\n            .get_or_create_path_handle::<A>(\n                path.into().into_owned(),\n                HandleLoadingMode::NotLoading,\n                meta_transform,\n            )\n            .0\n    }\n\n    /// Retrieve a handle for the given path, where the asset type ID and name\n    /// are not known statically.\n    ///\n    /// This will create a handle (and [`AssetInfo`]) if it does not exist.\n    pub(crate) fn get_or_create_path_handle_erased<'a>(\n        &self,\n        path: impl Into<AssetPath<'a>>,\n        type_id: TypeId,\n        meta_transform: Option<MetaTransform>,\n    ) -> UntypedHandle {\n        let mut infos = self.data.infos.write();\n        infos\n            .get_or_create_path_handle_erased(\n                path.into().into_owned(),\n                type_id,\n                None,\n                HandleLoadingMode::NotLoading,\n                meta_transform,\n            )\n            .0\n    }\n\n    pub(crate) async fn get_meta_loader_and_reader<'a>(\n        &'a self,\n        asset_path: &'a AssetPath<'_>,\n        asset_type_id: Option<TypeId>,\n    ) -> Result<\n        (\n            Box<dyn AssetMetaDyn>,\n            Arc<dyn ErasedAssetLoader>,\n            Box<dyn Reader + 'a>,\n        ),\n        AssetLoadError,\n    > {\n        let source = self.get_source(asset_path.source())?;\n        // NOTE: We grab the asset byte reader first to ensure this is transactional for AssetReaders like ProcessorGatedReader\n        // The asset byte reader will \"lock\" the processed asset, preventing writes for the duration of the lock.\n        // Then the meta reader, if meta exists, will correspond to the meta for the current \"version\" of the asset.\n        // See ProcessedAssetInfo::file_transaction_lock for more context\n        let asset_reader = match self.data.mode {\n            AssetServerMode::Unprocessed { .. } => source.reader(),\n            AssetServerMode::Processed { .. } => source.processed_reader()?,\n        };\n        let reader = asset_reader.read(asset_path.path()).await?;\n        let read_meta = match &self.data.meta_check {\n            AssetMetaCheck::Always => true,\n            AssetMetaCheck::Paths(paths) => paths.contains(asset_path),\n            AssetMetaCheck::Never => false,\n        };\n\n        if read_meta {\n            match asset_reader.read_meta_bytes(asset_path.path()).await {\n                Ok(meta_bytes) => {\n                    // TODO: this isn't fully minimal yet. we only need the loader\n                    let minimal: AssetMetaMinimal =\n                        ron::de::from_bytes(&meta_bytes).map_err(|e| {\n                            AssetLoadError::DeserializeMeta {\n                                path: asset_path.clone_owned(),\n                                error: DeserializeMetaError::DeserializeMinimal(e).into(),\n                            }\n                        })?;\n                    let loader_name = match minimal.asset {\n                        AssetActionMinimal::Load { loader } => loader,\n                        AssetActionMinimal::Process { .. } => {\n                            return Err(AssetLoadError::CannotLoadProcessedAsset {\n                                path: asset_path.clone_owned(),\n                            })\n                        }\n                        AssetActionMinimal::Ignore => {\n                            return Err(AssetLoadError::CannotLoadIgnoredAsset {\n                                path: asset_path.clone_owned(),\n                            })\n                        }\n                    };\n                    let loader = self.get_asset_loader_with_type_name(&loader_name).await?;\n                    let meta = loader.deserialize_meta(&meta_bytes).map_err(|e| {\n                        AssetLoadError::DeserializeMeta {\n                            path: asset_path.clone_owned(),\n                            error: e.into(),\n                        }\n                    })?;\n\n                    Ok((meta, loader, reader))\n                }\n                Err(AssetReaderError::NotFound(_)) => {\n                    // TODO: Handle error transformation\n                    let loader = {\n                        self.data\n                            .loaders\n                            .read()\n                            .find(None, asset_type_id, None, Some(asset_path))\n                    };\n\n                    let error = || AssetLoadError::MissingAssetLoader {\n                        loader_name: None,\n                        asset_type_id,\n                        extension: None,\n                        asset_path: Some(asset_path.to_string()),\n                    };\n\n                    let loader = loader.ok_or_else(error)?.get().await.map_err(|_| error())?;\n\n                    let meta = loader.default_meta();\n                    Ok((meta, loader, reader))\n                }\n                Err(err) => Err(err.into()),\n            }\n        } else {\n            let loader = {\n                self.data\n                    .loaders\n                    .read()\n                    .find(None, asset_type_id, None, Some(asset_path))\n            };\n\n            let error = || AssetLoadError::MissingAssetLoader {\n                loader_name: None,\n                asset_type_id,\n                extension: None,\n                asset_path: Some(asset_path.to_string()),\n            };\n\n            let loader = loader.ok_or_else(error)?.get().await.map_err(|_| error())?;\n\n            let meta = loader.default_meta();\n            Ok((meta, loader, reader))\n        }\n    }\n\n    pub(crate) async fn load_with_meta_loader_and_reader(\n        &self,\n        asset_path: &AssetPath<'_>,\n        meta: Box<dyn AssetMetaDyn>,\n        loader: &dyn ErasedAssetLoader,\n        reader: &mut dyn Reader,\n        load_dependencies: bool,\n        populate_hashes: bool,\n    ) -> Result<ErasedLoadedAsset, AssetLoadError> {\n        // TODO: experiment with this\n        let asset_path = asset_path.clone_owned();\n        let load_context =\n            LoadContext::new(self, asset_path.clone(), load_dependencies, populate_hashes);\n        AssertUnwindSafe(loader.load(reader, meta, load_context))\n            .catch_unwind()\n            .await\n            .map_err(|_| AssetLoadError::AssetLoaderPanic {\n                path: asset_path.clone_owned(),\n                loader_name: loader.type_name(),\n            })?\n            .map_err(|e| {\n                AssetLoadError::AssetLoaderError(AssetLoaderError {\n                    path: asset_path.clone_owned(),\n                    loader_name: loader.type_name(),\n                    error: e.into(),\n                })\n            })\n    }\n\n    /// Returns a future that will suspend until the specified asset and its dependencies finish\n    /// loading.\n    ///\n    /// # Errors\n    ///\n    /// This will return an error if the asset or any of its dependencies fail to load,\n    /// or if the asset has not been queued up to be loaded.\n    pub async fn wait_for_asset<A: Asset>(\n        &self,\n        // NOTE: We take a reference to a handle so we know it will outlive the future,\n        // which ensures the handle won't be dropped while waiting for the asset.\n        handle: &Handle<A>,\n    ) -> Result<(), WaitForAssetError> {\n        self.wait_for_asset_id(handle.id().untyped()).await\n    }\n\n    /// Returns a future that will suspend until the specified asset and its dependencies finish\n    /// loading.\n    ///\n    /// # Errors\n    ///\n    /// This will return an error if the asset or any of its dependencies fail to load,\n    /// or if the asset has not been queued up to be loaded.\n    pub async fn wait_for_asset_untyped(\n        &self,\n        // NOTE: We take a reference to a handle so we know it will outlive the future,\n        // which ensures the handle won't be dropped while waiting for the asset.\n        handle: &UntypedHandle,\n    ) -> Result<(), WaitForAssetError> {\n        self.wait_for_asset_id(handle.id()).await\n    }\n\n    /// Returns a future that will suspend until the specified asset and its dependencies finish\n    /// loading.\n    ///\n    /// Note that since an asset ID does not count as a reference to the asset,\n    /// the future returned from this method will *not* keep the asset alive.\n    /// This may lead to the asset unexpectedly being dropped while you are waiting for it to\n    /// finish loading.\n    ///\n    /// When calling this method, make sure a strong handle is stored elsewhere to prevent the\n    /// asset from being dropped.\n    /// If you have access to an asset's strong [`Handle`], you should prefer to call\n    /// [`AssetServer::wait_for_asset`]\n    /// or [`wait_for_asset_untyped`](Self::wait_for_asset_untyped) to ensure the asset finishes\n    /// loading.\n    ///\n    /// # Errors\n    ///\n    /// This will return an error if the asset or any of its dependencies fail to load,\n    /// or if the asset has not been queued up to be loaded.\n    pub async fn wait_for_asset_id(\n        &self,\n        id: impl Into<UntypedAssetId>,\n    ) -> Result<(), WaitForAssetError> {\n        let id = id.into();\n        core::future::poll_fn(move |cx| self.wait_for_asset_id_poll_fn(cx, id)).await\n    }\n\n    /// Used by [`wait_for_asset_id`](AssetServer::wait_for_asset_id) in [`poll_fn`](core::future::poll_fn).\n    fn wait_for_asset_id_poll_fn(\n        &self,\n        cx: &mut core::task::Context<'_>,\n        id: UntypedAssetId,\n    ) -> Poll<Result<(), WaitForAssetError>> {\n        let infos = self.data.infos.read();\n\n        let Some(info) = infos.get(id) else {\n            return Poll::Ready(Err(WaitForAssetError::NotLoaded));\n        };\n\n        match (&info.load_state, &info.rec_dep_load_state) {\n            (LoadState::Loaded, RecursiveDependencyLoadState::Loaded) => Poll::Ready(Ok(())),\n            // Return an error immediately if the asset is not in the process of loading\n            (LoadState::NotLoaded, _) => Poll::Ready(Err(WaitForAssetError::NotLoaded)),\n            // If the asset is loading, leave our waker behind\n            (LoadState::Loading, _)\n            | (_, RecursiveDependencyLoadState::Loading)\n            | (LoadState::Loaded, RecursiveDependencyLoadState::NotLoaded) => {\n                // Check if our waker is already there\n                let has_waker = info\n                    .waiting_tasks\n                    .iter()\n                    .any(|waker| waker.will_wake(cx.waker()));\n\n                if has_waker {\n                    return Poll::Pending;\n                }\n\n                let mut infos = {\n                    // Must drop read-only guard to acquire write guard\n                    drop(infos);\n                    self.data.infos.write()\n                };\n\n                let Some(info) = infos.get_mut(id) else {\n                    return Poll::Ready(Err(WaitForAssetError::NotLoaded));\n                };\n\n                // If the load state changed while reacquiring the lock, immediately\n                // reawaken the task\n                let is_loading = matches!(\n                    (&info.load_state, &info.rec_dep_load_state),\n                    (LoadState::Loading, _)\n                        | (_, RecursiveDependencyLoadState::Loading)\n                        | (LoadState::Loaded, RecursiveDependencyLoadState::NotLoaded)\n                );\n\n                if !is_loading {\n                    cx.waker().wake_by_ref();\n                } else {\n                    // Leave our waker behind\n                    info.waiting_tasks.push(cx.waker().clone());\n                }\n\n                Poll::Pending\n            }\n            (LoadState::Failed(error), _) => {\n                Poll::Ready(Err(WaitForAssetError::Failed(error.clone())))\n            }\n            (_, RecursiveDependencyLoadState::Failed(error)) => {\n                Poll::Ready(Err(WaitForAssetError::DependencyFailed(error.clone())))\n            }\n        }\n    }\n}\n\n/// A system that manages internal [`AssetServer`] events, such as finalizing asset loads.\npub fn handle_internal_asset_events(world: &mut World) {\n    world.resource_scope(|world, server: Mut<AssetServer>| {\n        let mut infos = server.data.infos.write();\n        let mut untyped_failures = vec![];\n        for event in server.data.asset_event_receiver.try_iter() {\n            match event {\n                InternalAssetEvent::Loaded { id, loaded_asset } => {\n                    infos.process_asset_load(\n                        id,\n                        loaded_asset,\n                        world,\n                        &server.data.asset_event_sender,\n                    );\n                }\n                InternalAssetEvent::LoadedWithDependencies { id } => {\n                    let sender = infos\n                        .dependency_loaded_event_sender\n                        .get(&id.type_id())\n                        .expect(\"Asset event sender should exist\");\n                    sender(world, id);\n                    if let Some(info) = infos.get_mut(id) {\n                        for waker in info.waiting_tasks.drain(..) {\n                            waker.wake();\n                        }\n                    }\n                }\n                InternalAssetEvent::Failed { id, path, error } => {\n                    infos.process_asset_fail(id, error.clone());\n\n                    // Send untyped failure event\n                    untyped_failures.push(UntypedAssetLoadFailedEvent {\n                        id,\n                        path: path.clone(),\n                        error: error.clone(),\n                    });\n\n                    // Send typed failure event\n                    let sender = infos\n                        .dependency_failed_event_sender\n                        .get(&id.type_id())\n                        .expect(\"Asset failed event sender should exist\");\n                    sender(world, id, path, error);\n                }\n            }\n        }\n\n        if !untyped_failures.is_empty() {\n            world.send_event_batch(untyped_failures);\n        }\n\n        fn queue_ancestors(\n            asset_path: &AssetPath,\n            infos: &AssetInfos,\n            paths_to_reload: &mut HashSet<AssetPath<'static>>,\n        ) {\n            if let Some(dependents) = infos.loader_dependents.get(asset_path) {\n                for dependent in dependents {\n                    paths_to_reload.insert(dependent.to_owned());\n                    queue_ancestors(dependent, infos, paths_to_reload);\n                }\n            }\n        }\n\n        let reload_parent_folders = |path: PathBuf, source: &AssetSourceId<'static>| {\n            let mut current_folder = path;\n            while let Some(parent) = current_folder.parent() {\n                current_folder = parent.to_path_buf();\n                let parent_asset_path =\n                    AssetPath::from(current_folder.clone()).with_source(source.clone());\n                for folder_handle in infos.get_path_handles(&parent_asset_path) {\n                    info!(\"Reloading folder {parent_asset_path} because the content has changed\");\n                    server.load_folder_internal(folder_handle.id(), parent_asset_path.clone());\n                }\n            }\n        };\n\n        let mut paths_to_reload = HashSet::new();\n        let mut handle_event = |source: AssetSourceId<'static>, event: AssetSourceEvent| {\n            match event {\n                // TODO: if the asset was processed and the processed file was changed, the first modified event\n                // should be skipped?\n                AssetSourceEvent::ModifiedAsset(path) | AssetSourceEvent::ModifiedMeta(path) => {\n                    let path = AssetPath::from(path).with_source(source);\n                    queue_ancestors(&path, &infos, &mut paths_to_reload);\n                    paths_to_reload.insert(path);\n                }\n                AssetSourceEvent::RenamedFolder { old, new } => {\n                    reload_parent_folders(old, &source);\n                    reload_parent_folders(new, &source);\n                }\n                AssetSourceEvent::AddedAsset(path)\n                | AssetSourceEvent::RemovedAsset(path)\n                | AssetSourceEvent::RemovedFolder(path)\n                | AssetSourceEvent::AddedFolder(path) => {\n                    reload_parent_folders(path, &source);\n                }\n                _ => {}\n            }\n        };\n\n        for source in server.data.sources.iter() {\n            match server.data.mode {\n                AssetServerMode::Unprocessed { .. } => {\n                    if let Some(receiver) = source.event_receiver() {\n                        for event in receiver.try_iter() {\n                            handle_event(source.id(), event);\n                        }\n                    }\n                }\n                AssetServerMode::Processed { .. } => {\n                    if let Some(receiver) = source.processed_event_receiver() {\n                        for event in receiver.try_iter() {\n                            handle_event(source.id(), event);\n                        }\n                    }\n                }\n            }\n        }\n\n        for path in paths_to_reload {\n            info!(\"Reloading {path} because it has changed\");\n            server.reload(path);\n        }\n\n        #[cfg(not(any(target_arch = \"wasm32\", not(feature = \"multi_threaded\"))))]\n        infos\n            .pending_tasks\n            .retain(|_, load_task| !load_task.is_finished());\n    });\n}\n\n/// Internal events for asset load results\npub(crate) enum InternalAssetEvent {\n    Loaded {\n        id: UntypedAssetId,\n        loaded_asset: ErasedLoadedAsset,\n    },\n    LoadedWithDependencies {\n        id: UntypedAssetId,\n    },\n    Failed {\n        id: UntypedAssetId,\n        path: AssetPath<'static>,\n        error: AssetLoadError,\n    },\n}\n\n/// The load state of an asset.\n#[derive(Component, Clone, Debug)]\npub enum LoadState {\n    /// The asset has not started loading yet\n    NotLoaded,\n\n    /// The asset is in the process of loading.\n    Loading,\n\n    /// The asset has been loaded and has been added to the [`World`]\n    Loaded,\n\n    /// The asset failed to load. The underlying [`AssetLoadError`] is\n    /// referenced by [`Arc`] clones in all related [`DependencyLoadState`]s\n    /// and [`RecursiveDependencyLoadState`]s in the asset's dependency tree.\n    Failed(Arc<AssetLoadError>),\n}\n\nimpl LoadState {\n    /// Returns `true` if this instance is [`LoadState::Loading`]\n    pub fn is_loading(&self) -> bool {\n        matches!(self, Self::Loading)\n    }\n\n    /// Returns `true` if this instance is [`LoadState::Loaded`]\n    pub fn is_loaded(&self) -> bool {\n        matches!(self, Self::Loaded)\n    }\n\n    /// Returns `true` if this instance is [`LoadState::Failed`]\n    pub fn is_failed(&self) -> bool {\n        matches!(self, Self::Failed(_))\n    }\n}\n\n/// The load state of an asset's dependencies.\n#[derive(Component, Clone, Debug)]\npub enum DependencyLoadState {\n    /// The asset has not started loading yet\n    NotLoaded,\n\n    /// Dependencies are still loading\n    Loading,\n\n    /// Dependencies have all loaded\n    Loaded,\n\n    /// One or more dependencies have failed to load. The underlying [`AssetLoadError`]\n    /// is referenced by [`Arc`] clones in all related [`LoadState`] and\n    /// [`RecursiveDependencyLoadState`]s in the asset's dependency tree.\n    Failed(Arc<AssetLoadError>),\n}\n\nimpl DependencyLoadState {\n    /// Returns `true` if this instance is [`DependencyLoadState::Loading`]\n    pub fn is_loading(&self) -> bool {\n        matches!(self, Self::Loading)\n    }\n\n    /// Returns `true` if this instance is [`DependencyLoadState::Loaded`]\n    pub fn is_loaded(&self) -> bool {\n        matches!(self, Self::Loaded)\n    }\n\n    /// Returns `true` if this instance is [`DependencyLoadState::Failed`]\n    pub fn is_failed(&self) -> bool {\n        matches!(self, Self::Failed(_))\n    }\n}\n\n/// The recursive load state of an asset's dependencies.\n#[derive(Component, Clone, Debug)]\npub enum RecursiveDependencyLoadState {\n    /// The asset has not started loading yet\n    NotLoaded,\n\n    /// Dependencies in this asset's dependency tree are still loading\n    Loading,\n\n    /// Dependencies in this asset's dependency tree have all loaded\n    Loaded,\n\n    /// One or more dependencies have failed to load in this asset's dependency\n    /// tree. The underlying [`AssetLoadError`] is referenced by [`Arc`] clones\n    /// in all related [`LoadState`]s and [`DependencyLoadState`]s in the asset's\n    /// dependency tree.\n    Failed(Arc<AssetLoadError>),\n}\n\nimpl RecursiveDependencyLoadState {\n    /// Returns `true` if this instance is [`RecursiveDependencyLoadState::Loading`]\n    pub fn is_loading(&self) -> bool {\n        matches!(self, Self::Loading)\n    }\n\n    /// Returns `true` if this instance is [`RecursiveDependencyLoadState::Loaded`]\n    pub fn is_loaded(&self) -> bool {\n        matches!(self, Self::Loaded)\n    }\n\n    /// Returns `true` if this instance is [`RecursiveDependencyLoadState::Failed`]\n    pub fn is_failed(&self) -> bool {\n        matches!(self, Self::Failed(_))\n    }\n}\n\n/// An error that occurs during an [`Asset`] load.\n#[derive(Error, Debug, Clone)]\npub enum AssetLoadError {\n    #[error(\"Requested handle of type {requested:?} for asset '{path}' does not match actual asset type '{actual_asset_name}', which used loader '{loader_name}'\")]\n    RequestedHandleTypeMismatch {\n        path: AssetPath<'static>,\n        requested: TypeId,\n        actual_asset_name: &'static str,\n        loader_name: &'static str,\n    },\n    #[error(\"Could not find an asset loader matching: Loader Name: {loader_name:?}; Asset Type: {loader_name:?}; Extension: {extension:?}; Path: {asset_path:?};\")]\n    MissingAssetLoader {\n        loader_name: Option<String>,\n        asset_type_id: Option<TypeId>,\n        extension: Option<String>,\n        asset_path: Option<String>,\n    },\n    #[error(transparent)]\n    MissingAssetLoaderForExtension(#[from] MissingAssetLoaderForExtensionError),\n    #[error(transparent)]\n    MissingAssetLoaderForTypeName(#[from] MissingAssetLoaderForTypeNameError),\n    #[error(transparent)]\n    MissingAssetLoaderForTypeIdError(#[from] MissingAssetLoaderForTypeIdError),\n    #[error(transparent)]\n    AssetReaderError(#[from] AssetReaderError),\n    #[error(transparent)]\n    MissingAssetSourceError(#[from] MissingAssetSourceError),\n    #[error(transparent)]\n    MissingProcessedAssetReaderError(#[from] MissingProcessedAssetReaderError),\n    #[error(\"Encountered an error while reading asset metadata bytes\")]\n    AssetMetaReadError,\n    #[error(\"Failed to deserialize meta for asset {path}: {error}\")]\n    DeserializeMeta {\n        path: AssetPath<'static>,\n        error: Box<DeserializeMetaError>,\n    },\n    #[error(\"Asset '{path}' is configured to be processed. It cannot be loaded directly.\")]\n    #[from(ignore)]\n    CannotLoadProcessedAsset { path: AssetPath<'static> },\n    #[error(\"Asset '{path}' is configured to be ignored. It cannot be loaded.\")]\n    #[from(ignore)]\n    CannotLoadIgnoredAsset { path: AssetPath<'static> },\n    #[error(\"Failed to load asset '{path}', asset loader '{loader_name}' panicked\")]\n    AssetLoaderPanic {\n        path: AssetPath<'static>,\n        loader_name: &'static str,\n    },\n    #[error(transparent)]\n    AssetLoaderError(#[from] AssetLoaderError),\n    #[error(transparent)]\n    AddAsyncError(#[from] AddAsyncError),\n    #[error(\"The file at '{}' does not contain the labeled asset '{}'; it contains the following {} assets: {}\",\n            base_path,\n            label,\n            all_labels.len(),\n            all_labels.iter().map(|l| format!(\"'{}'\", l)).collect::<Vec<_>>().join(\", \"))]\n    MissingLabel {\n        base_path: AssetPath<'static>,\n        label: String,\n        all_labels: Vec<String>,\n    },\n}\n\n#[derive(Error, Debug, Clone)]\n#[error(\"Failed to load asset '{path}' with asset loader '{loader_name}': {error}\")]\npub struct AssetLoaderError {\n    path: AssetPath<'static>,\n    loader_name: &'static str,\n    error: Arc<dyn core::error::Error + Send + Sync + 'static>,\n}\n\nimpl AssetLoaderError {\n    pub fn path(&self) -> &AssetPath<'static> {\n        &self.path\n    }\n}\n\n#[derive(Error, Debug, Clone)]\n#[error(\"An error occurred while resolving an asset added by `add_async`: {error}\")]\npub struct AddAsyncError {\n    error: Arc<dyn core::error::Error + Send + Sync + 'static>,\n}\n\n/// An error that occurs when an [`AssetLoader`] is not registered for a given extension.\n#[derive(Error, Debug, Clone, PartialEq, Eq)]\n#[error(\"no `AssetLoader` found{}\", format_missing_asset_ext(extensions))]\npub struct MissingAssetLoaderForExtensionError {\n    extensions: Vec<String>,\n}\n\n/// An error that occurs when an [`AssetLoader`] is not registered for a given [`std::any::type_name`].\n#[derive(Error, Debug, Clone, PartialEq, Eq)]\n#[error(\"no `AssetLoader` found with the name '{type_name}'\")]\npub struct MissingAssetLoaderForTypeNameError {\n    type_name: String,\n}\n\n/// An error that occurs when an [`AssetLoader`] is not registered for a given [`Asset`] [`TypeId`].\n#[derive(Error, Debug, Clone, PartialEq, Eq)]\n#[error(\"no `AssetLoader` found with the ID '{type_id:?}'\")]\npub struct MissingAssetLoaderForTypeIdError {\n    pub type_id: TypeId,\n}\n\nfn format_missing_asset_ext(exts: &[String]) -> String {\n    if !exts.is_empty() {\n        format!(\n            \" for the following extension{}: {}\",\n            if exts.len() > 1 { \"s\" } else { \"\" },\n            exts.join(\", \")\n        )\n    } else {\n        \" for file with no extension\".to_string()\n    }\n}\n\nimpl core::fmt::Debug for AssetServer {\n    fn fmt(&self, f: &mut core::fmt::Formatter<'_>) -> core::fmt::Result {\n        f.debug_struct(\"AssetServer\")\n            .field(\"info\", &self.data.infos.read())\n            .finish()\n    }\n}\n\n/// This is appended to asset sources when loading a [`LoadedUntypedAsset`]. This provides a unique\n/// source for a given [`AssetPath`].\nconst UNTYPED_SOURCE_SUFFIX: &str = \"--untyped\";\n\n/// An error when attempting to wait asynchronously for an [`Asset`] to load.\n#[derive(Error, Debug, Clone)]\npub enum WaitForAssetError {\n    #[error(\"tried to wait for an asset that is not being loaded\")]\n    NotLoaded,\n    #[error(transparent)]\n    Failed(Arc<AssetLoadError>),\n    #[error(transparent)]\n    DependencyFailed(Arc<AssetLoadError>),\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "84c8a2a64b9014b9d4473a618d514d41147212b1",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_utils/src/once.rs",
    "func": "/// Call some expression only once per call site.\n#[macro_export]\nmacro_rules! once {\n    ($expression:expr) => {{\n        use ::core::sync::atomic::{AtomicBool, Ordering};\n\n        static SHOULD_FIRE: AtomicBool = AtomicBool::new(true);\n        if SHOULD_FIRE.swap(false, Ordering::Relaxed) {\n            $expression;\n        }\n    }};\n}\n\n/// Call [`trace!`](crate::tracing::trace) once per call site.\n///\n/// Useful for logging within systems which are called every frame.\n#[macro_export]\nmacro_rules! trace_once {\n    ($($arg:tt)+) => ({\n        $crate::once!($crate::tracing::trace!($($arg)+))\n    });\n}\n\n/// Call [`debug!`](crate::tracing::debug) once per call site.\n///\n/// Useful for logging within systems which are called every frame.\n#[macro_export]\nmacro_rules! debug_once {\n    ($($arg:tt)+) => ({\n        $crate::once!($crate::tracing::debug!($($arg)+))\n    });\n}\n\n/// Call [`info!`](crate::tracing::info) once per call site.\n///\n/// Useful for logging within systems which are called every frame.\n#[macro_export]\nmacro_rules! info_once {\n    ($($arg:tt)+) => ({\n        $crate::once!($crate::tracing::info!($($arg)+))\n    });\n}\n\n/// Call [`warn!`](crate::tracing::warn) once per call site.\n///\n/// Useful for logging within systems which are called every frame.\n#[macro_export]\nmacro_rules! warn_once {\n    ($($arg:tt)+) => ({\n        $crate::once!($crate::tracing::warn!($($arg)+))\n    });\n}\n\n/// Call [`error!`](crate::tracing::error) once per call site.\n///\n/// Useful for logging within systems which are called every frame.\n#[macro_export]\nmacro_rules! error_once {\n    ($($arg:tt)+) => ({\n        $crate::once!($crate::tracing::error!($($arg)+))\n    });\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "6a231df989dc8c5254d58d2a9147fcd6bb72632e",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_render/src/alpha.rs",
    "func": "use bevy_reflect::{std_traits::ReflectDefault, Reflect};\n\n// TODO: add discussion about performance.\n/// Sets how a material's base color alpha channel is used for transparency.\n#[derive(Debug, Default, Reflect, Copy, Clone, PartialEq)]\n#[reflect(Default, Debug)]\npub enum AlphaMode {\n    /// Base color alpha values are overridden to be fully opaque (1.0).\n    #[default]\n    Opaque,\n    /// Reduce transparency to fully opaque or fully transparent\n    /// based on a threshold.\n    ///\n    /// Compares the base color alpha value to the specified threshold.\n    /// If the value is below the threshold,\n    /// considers the color to be fully transparent (alpha is set to 0.0).\n    /// If it is equal to or above the threshold,\n    /// considers the color to be fully opaque (alpha is set to 1.0).\n    Mask(f32),\n    /// The base color alpha value defines the opacity of the color.\n    /// Standard alpha-blending is used to blend the fragment's color\n    /// with the color behind it.\n    Blend,\n    /// Similar to [`AlphaMode::Blend`], however assumes RGB channel values are\n    /// [premultiplied](https://en.wikipedia.org/wiki/Alpha_compositing#Straight_versus_premultiplied).\n    ///\n    /// For otherwise constant RGB values, behaves more like [`AlphaMode::Blend`] for\n    /// alpha values closer to 1.0, and more like [`AlphaMode::Add`] for\n    /// alpha values closer to 0.0.\n    ///\n    /// Can be used to avoid \u201cborder\u201d or \u201coutline\u201d artifacts that can occur\n    /// when using plain alpha-blended textures.\n    Premultiplied,\n    /// Spreads the fragment out over a hardware-dependent number of sample\n    /// locations proportional to the alpha value. This requires multisample\n    /// antialiasing; if MSAA isn't on, this is identical to\n    /// [`AlphaMode::Mask`] with a value of 0.5.\n    ///\n    /// Alpha to coverage provides improved performance and better visual\n    /// fidelity over [`AlphaMode::Blend`], as Bevy doesn't have to sort objects\n    /// when it's in use. It's especially useful for complex transparent objects\n    /// like foliage.\n    ///\n    /// [alpha to coverage]: https://en.wikipedia.org/wiki/Alpha_to_coverage\n    AlphaToCoverage,\n    /// Combines the color of the fragments with the colors behind them in an\n    /// additive process, (i.e. like light) producing lighter results.\n    ///\n    /// Black produces no effect. Alpha values can be used to modulate the result.\n    ///\n    /// Useful for effects like holograms, ghosts, lasers and other energy beams.\n    Add,\n    /// Combines the color of the fragments with the colors behind them in a\n    /// multiplicative process, (i.e. like pigments) producing darker results.\n    ///\n    /// White produces no effect. Alpha values can be used to modulate the result.\n    ///\n    /// Useful for effects like stained glass, window tint film and some colored liquids.\n    Multiply,\n}\n\nimpl Eq for AlphaMode {}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "d8cd033d4c9a89b0666597bc07ac6d836b6dab9c",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_render/src/globals.rs",
    "func": "use crate::{\n    extract_resource::ExtractResource,\n    prelude::Shader,\n    render_resource::{ShaderType, UniformBuffer},\n    renderer::{RenderDevice, RenderQueue},\n    Extract, ExtractSchedule, Render, RenderApp, RenderSet,\n};\nuse bevy_app::{App, Plugin};\nuse bevy_asset::{load_internal_asset, Handle};\nuse bevy_core::FrameCount;\nuse bevy_ecs::prelude::*;\nuse bevy_reflect::prelude::*;\nuse bevy_time::Time;\n\npub const GLOBALS_TYPE_HANDLE: Handle<Shader> = Handle::weak_from_u128(17924628719070609599);\n\npub struct GlobalsPlugin;\n\nimpl Plugin for GlobalsPlugin {\n    fn build(&self, app: &mut App) {\n        load_internal_asset!(app, GLOBALS_TYPE_HANDLE, \"globals.wgsl\", Shader::from_wgsl);\n        app.register_type::<GlobalsUniform>();\n\n        if let Some(render_app) = app.get_sub_app_mut(RenderApp) {\n            render_app\n                .init_resource::<GlobalsBuffer>()\n                .init_resource::<Time>()\n                .add_systems(ExtractSchedule, (extract_frame_count, extract_time))\n                .add_systems(\n                    Render,\n                    prepare_globals_buffer.in_set(RenderSet::PrepareResources),\n                );\n        }\n    }\n}\n\nfn extract_frame_count(mut commands: Commands, frame_count: Extract<Res<FrameCount>>) {\n    commands.insert_resource(**frame_count);\n}\n\nfn extract_time(mut commands: Commands, time: Extract<Res<Time>>) {\n    commands.insert_resource(**time);\n}\n\n/// Contains global values useful when writing shaders.\n/// Currently only contains values related to time.\n#[derive(Default, Clone, Resource, ExtractResource, Reflect, ShaderType)]\n#[reflect(Resource, Default)]\npub struct GlobalsUniform {\n    /// The time since startup in seconds.\n    /// Wraps to 0 after 1 hour.\n    time: f32,\n    /// The delta time since the previous frame in seconds\n    delta_time: f32,\n    /// Frame count since the start of the app.\n    /// It wraps to zero when it reaches the maximum value of a u32.\n    frame_count: u32,\n    /// WebGL2 structs must be 16 byte aligned.\n    #[cfg(all(feature = \"webgl\", target_arch = \"wasm32\", not(feature = \"webgpu\")))]\n    _wasm_padding: f32,\n}\n\n/// The buffer containing the [`GlobalsUniform`]\n#[derive(Resource, Default)]\npub struct GlobalsBuffer {\n    pub buffer: UniformBuffer<GlobalsUniform>,\n}\n\nfn prepare_globals_buffer(\n    render_device: Res<RenderDevice>,\n    render_queue: Res<RenderQueue>,\n    mut globals_buffer: ResMut<GlobalsBuffer>,\n    time: Res<Time>,\n    frame_count: Res<FrameCount>,\n) {\n    let buffer = globals_buffer.buffer.get_mut();\n    buffer.time = time.elapsed_secs_wrapped();\n    buffer.delta_time = time.delta_secs();\n    buffer.frame_count = frame_count.0;\n\n    globals_buffer\n        .buffer\n        .write_buffer(&render_device, &render_queue);\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "a355a1bd3bd4734784d7c1e61926dcf21958ccb6",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_tasks/src/task.rs",
    "func": "use core::{\n    future::Future,\n    pin::Pin,\n    task::{Context, Poll},\n};\n\n/// Wraps `async_executor::Task`, a spawned future.\n///\n/// Tasks are also futures themselves and yield the output of the spawned future.\n///\n/// When a task is dropped, its gets canceled and won't be polled again. To cancel a task a bit\n/// more gracefully and wait until it stops running, use the [`Task::cancel()`] method.\n///\n/// Tasks that panic get immediately canceled. Awaiting a canceled task also causes a panic.\n#[derive(Debug)]\n#[must_use = \"Tasks are canceled when dropped, use `.detach()` to run them in the background.\"]\npub struct Task<T>(crate::executor::Task<T>);\n\nimpl<T> Task<T> {\n    /// Creates a new task from a given `async_executor::Task`\n    pub fn new(task: crate::executor::Task<T>) -> Self {\n        Self(task)\n    }\n\n    /// Detaches the task to let it keep running in the background. See\n    /// `async_executor::Task::detach`\n    pub fn detach(self) {\n        self.0.detach();\n    }\n\n    /// Cancels the task and waits for it to stop running.\n    ///\n    /// Returns the task's output if it was completed just before it got canceled, or [`None`] if\n    /// it didn't complete.\n    ///\n    /// While it's possible to simply drop the [`Task`] to cancel it, this is a cleaner way of\n    /// canceling because it also waits for the task to stop running.\n    ///\n    /// See `async_executor::Task::cancel`\n    pub async fn cancel(self) -> Option<T> {\n        self.0.cancel().await\n    }\n\n    /// Returns `true` if the current task is finished.\n    ///\n    ///\n    /// Unlike poll, it doesn't resolve the final value, it just checks if the task has finished.\n    /// Note that in a multithreaded environment, this task can be finished immediately after calling this function.\n    pub fn is_finished(&self) -> bool {\n        self.0.is_finished()\n    }\n}\n\nimpl<T> Future for Task<T> {\n    type Output = T;\n\n    fn poll(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> {\n        Pin::new(&mut self.0).poll(cx)\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "2cb8d8ad2ae4f06da4d8421bffb5bd5c33c694ca",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_reflect/compile_fail/tests/func.rs",
    "func": "fn main() -> compile_fail_utils::ui_test::Result<()> {\n    compile_fail_utils::test(\"reflect_into_function\", \"tests/into_function\")\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "03fe7382378988f7465a64ccff5e42999bd5ef5c",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_reflect/src/fields.rs",
    "func": "use crate::{\n    attributes::{impl_custom_attribute_methods, CustomAttributes},\n    type_info::impl_type_methods,\n    MaybeTyped, PartialReflect, Type, TypeInfo, TypePath,\n};\nuse alloc::sync::Arc;\n\n/// The named field of a reflected struct.\n#[derive(Clone, Debug)]\npub struct NamedField {\n    name: &'static str,\n    type_info: fn() -> Option<&'static TypeInfo>,\n    ty: Type,\n    custom_attributes: Arc<CustomAttributes>,\n    #[cfg(feature = \"documentation\")]\n    docs: Option<&'static str>,\n}\n\nimpl NamedField {\n    /// Create a new [`NamedField`].\n    pub fn new<T: PartialReflect + MaybeTyped + TypePath>(name: &'static str) -> Self {\n        Self {\n            name,\n            type_info: T::maybe_type_info,\n            ty: Type::of::<T>(),\n            custom_attributes: Arc::new(CustomAttributes::default()),\n            #[cfg(feature = \"documentation\")]\n            docs: None,\n        }\n    }\n\n    /// Sets the docstring for this field.\n    #[cfg(feature = \"documentation\")]\n    pub fn with_docs(self, docs: Option<&'static str>) -> Self {\n        Self { docs, ..self }\n    }\n\n    /// Sets the custom attributes for this field.\n    pub fn with_custom_attributes(self, custom_attributes: CustomAttributes) -> Self {\n        Self {\n            custom_attributes: Arc::new(custom_attributes),\n            ..self\n        }\n    }\n\n    /// The name of the field.\n    pub fn name(&self) -> &'static str {\n        self.name\n    }\n\n    /// The [`TypeInfo`] of the field.\n    ///\n    ///\n    /// Returns `None` if the field does not contain static type information,\n    /// such as for dynamic types.\n    pub fn type_info(&self) -> Option<&'static TypeInfo> {\n        (self.type_info)()\n    }\n\n    impl_type_methods!(ty);\n\n    /// The docstring of this field, if any.\n    #[cfg(feature = \"documentation\")]\n    pub fn docs(&self) -> Option<&'static str> {\n        self.docs\n    }\n\n    impl_custom_attribute_methods!(self.custom_attributes, \"field\");\n}\n\n/// The unnamed field of a reflected tuple or tuple struct.\n#[derive(Clone, Debug)]\npub struct UnnamedField {\n    index: usize,\n    type_info: fn() -> Option<&'static TypeInfo>,\n    ty: Type,\n    custom_attributes: Arc<CustomAttributes>,\n    #[cfg(feature = \"documentation\")]\n    docs: Option<&'static str>,\n}\n\nimpl UnnamedField {\n    pub fn new<T: PartialReflect + MaybeTyped + TypePath>(index: usize) -> Self {\n        Self {\n            index,\n            type_info: T::maybe_type_info,\n            ty: Type::of::<T>(),\n            custom_attributes: Arc::new(CustomAttributes::default()),\n            #[cfg(feature = \"documentation\")]\n            docs: None,\n        }\n    }\n\n    /// Sets the docstring for this field.\n    #[cfg(feature = \"documentation\")]\n    pub fn with_docs(self, docs: Option<&'static str>) -> Self {\n        Self { docs, ..self }\n    }\n\n    /// Sets the custom attributes for this field.\n    pub fn with_custom_attributes(self, custom_attributes: CustomAttributes) -> Self {\n        Self {\n            custom_attributes: Arc::new(custom_attributes),\n            ..self\n        }\n    }\n\n    /// Returns the index of the field.\n    pub fn index(&self) -> usize {\n        self.index\n    }\n\n    /// The [`TypeInfo`] of the field.\n    ///\n    ///\n    /// Returns `None` if the field does not contain static type information,\n    /// such as for dynamic types.\n    pub fn type_info(&self) -> Option<&'static TypeInfo> {\n        (self.type_info)()\n    }\n\n    impl_type_methods!(ty);\n\n    /// The docstring of this field, if any.\n    #[cfg(feature = \"documentation\")]\n    pub fn docs(&self) -> Option<&'static str> {\n        self.docs\n    }\n\n    impl_custom_attribute_methods!(self.custom_attributes, \"field\");\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "7ef991b6510f8412b1898f98a283cda31d0f32a6",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_reflect/src/tuple.rs",
    "func": "use bevy_reflect_derive::impl_type_path;\nuse variadics_please::all_tuples;\n\nuse crate::generics::impl_generic_info_methods;\nuse crate::{\n    self as bevy_reflect, type_info::impl_type_methods, utility::GenericTypePathCell, ApplyError,\n    FromReflect, Generics, GetTypeRegistration, MaybeTyped, PartialReflect, Reflect, ReflectKind,\n    ReflectMut, ReflectOwned, ReflectRef, Type, TypeInfo, TypePath, TypeRegistration, TypeRegistry,\n    Typed, UnnamedField,\n};\nuse alloc::{boxed::Box, vec, vec::Vec};\nuse core::{\n    any::Any,\n    fmt::{Debug, Formatter},\n    slice::Iter,\n};\n\n/// A trait used to power [tuple-like] operations via [reflection].\n///\n/// This trait uses the [`Reflect`] trait to allow implementors to have their fields\n/// be dynamically addressed by index.\n///\n/// This trait is automatically implemented for arbitrary tuples of up to 12\n/// elements, provided that each element implements [`Reflect`].\n///\n/// # Example\n///\n/// ```\n/// use bevy_reflect::{PartialReflect, Tuple};\n///\n/// let foo = (123_u32, true);\n/// assert_eq!(foo.field_len(), 2);\n///\n/// let field: &dyn PartialReflect = foo.field(0).unwrap();\n/// assert_eq!(field.try_downcast_ref::<u32>(), Some(&123));\n/// ```\n///\n/// [tuple-like]: https://doc.rust-lang.org/book/ch03-02-data-types.html#the-tuple-type\n/// [reflection]: crate\npub trait Tuple: PartialReflect {\n    /// Returns a reference to the value of the field with index `index` as a\n    /// `&dyn Reflect`.\n    fn field(&self, index: usize) -> Option<&dyn PartialReflect>;\n\n    /// Returns a mutable reference to the value of the field with index `index`\n    /// as a `&mut dyn Reflect`.\n    fn field_mut(&mut self, index: usize) -> Option<&mut dyn PartialReflect>;\n\n    /// Returns the number of fields in the tuple.\n    fn field_len(&self) -> usize;\n\n    /// Returns an iterator over the values of the tuple's fields.\n    fn iter_fields(&self) -> TupleFieldIter;\n\n    /// Drain the fields of this tuple to get a vector of owned values.\n    fn drain(self: Box<Self>) -> Vec<Box<dyn PartialReflect>>;\n\n    /// Clones the struct into a [`DynamicTuple`].\n    fn clone_dynamic(&self) -> DynamicTuple;\n\n    /// Will return `None` if [`TypeInfo`] is not available.\n    fn get_represented_tuple_info(&self) -> Option<&'static TupleInfo> {\n        self.get_represented_type_info()?.as_tuple().ok()\n    }\n}\n\n/// An iterator over the field values of a tuple.\npub struct TupleFieldIter<'a> {\n    pub(crate) tuple: &'a dyn Tuple,\n    pub(crate) index: usize,\n}\n\nimpl<'a> TupleFieldIter<'a> {\n    pub fn new(value: &'a dyn Tuple) -> Self {\n        TupleFieldIter {\n            tuple: value,\n            index: 0,\n        }\n    }\n}\n\nimpl<'a> Iterator for TupleFieldIter<'a> {\n    type Item = &'a dyn PartialReflect;\n\n    fn next(&mut self) -> Option<Self::Item> {\n        let value = self.tuple.field(self.index);\n        self.index += value.is_some() as usize;\n        value\n    }\n\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        let size = self.tuple.field_len();\n        (size, Some(size))\n    }\n}\n\nimpl<'a> ExactSizeIterator for TupleFieldIter<'a> {}\n\n/// A convenience trait which combines fetching and downcasting of tuple\n/// fields.\n///\n/// # Example\n///\n/// ```\n/// use bevy_reflect::GetTupleField;\n///\n/// # fn main() {\n/// let foo = (\"blue\".to_string(), 42_i32);\n///\n/// assert_eq!(foo.get_field::<String>(0), Some(&\"blue\".to_string()));\n/// assert_eq!(foo.get_field::<i32>(1), Some(&42));\n/// # }\n/// ```\npub trait GetTupleField {\n    /// Returns a reference to the value of the field with index `index`,\n    /// downcast to `T`.\n    fn get_field<T: Reflect>(&self, index: usize) -> Option<&T>;\n\n    /// Returns a mutable reference to the value of the field with index\n    /// `index`, downcast to `T`.\n    fn get_field_mut<T: Reflect>(&mut self, index: usize) -> Option<&mut T>;\n}\n\nimpl<S: Tuple> GetTupleField for S {\n    fn get_field<T: Reflect>(&self, index: usize) -> Option<&T> {\n        self.field(index)\n            .and_then(|value| value.try_downcast_ref::<T>())\n    }\n\n    fn get_field_mut<T: Reflect>(&mut self, index: usize) -> Option<&mut T> {\n        self.field_mut(index)\n            .and_then(|value| value.try_downcast_mut::<T>())\n    }\n}\n\nimpl GetTupleField for dyn Tuple {\n    fn get_field<T: Reflect>(&self, index: usize) -> Option<&T> {\n        self.field(index)\n            .and_then(|value| value.try_downcast_ref::<T>())\n    }\n\n    fn get_field_mut<T: Reflect>(&mut self, index: usize) -> Option<&mut T> {\n        self.field_mut(index)\n            .and_then(|value| value.try_downcast_mut::<T>())\n    }\n}\n\n/// A container for compile-time tuple info.\n#[derive(Clone, Debug)]\npub struct TupleInfo {\n    ty: Type,\n    generics: Generics,\n    fields: Box<[UnnamedField]>,\n    #[cfg(feature = \"documentation\")]\n    docs: Option<&'static str>,\n}\n\nimpl TupleInfo {\n    /// Create a new [`TupleInfo`].\n    ///\n    /// # Arguments\n    ///\n    /// * `fields`: The fields of this tuple in the order they are defined\n    pub fn new<T: Reflect + TypePath>(fields: &[UnnamedField]) -> Self {\n        Self {\n            ty: Type::of::<T>(),\n            generics: Generics::new(),\n            fields: fields.to_vec().into_boxed_slice(),\n            #[cfg(feature = \"documentation\")]\n            docs: None,\n        }\n    }\n\n    /// Sets the docstring for this tuple.\n    #[cfg(feature = \"documentation\")]\n    pub fn with_docs(self, docs: Option<&'static str>) -> Self {\n        Self { docs, ..self }\n    }\n\n    /// Get the field at the given index.\n    pub fn field_at(&self, index: usize) -> Option<&UnnamedField> {\n        self.fields.get(index)\n    }\n\n    /// Iterate over the fields of this tuple.\n    pub fn iter(&self) -> Iter<'_, UnnamedField> {\n        self.fields.iter()\n    }\n\n    /// The total number of fields in this tuple.\n    pub fn field_len(&self) -> usize {\n        self.fields.len()\n    }\n\n    impl_type_methods!(ty);\n\n    /// The docstring of this tuple, if any.\n    #[cfg(feature = \"documentation\")]\n    pub fn docs(&self) -> Option<&'static str> {\n        self.docs\n    }\n\n    impl_generic_info_methods!(generics);\n}\n\n/// A tuple which allows fields to be added at runtime.\n#[derive(Default, Debug)]\npub struct DynamicTuple {\n    represented_type: Option<&'static TypeInfo>,\n    fields: Vec<Box<dyn PartialReflect>>,\n}\n\nimpl DynamicTuple {\n    /// Sets the [type] to be represented by this `DynamicTuple`.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the given [type] is not a [`TypeInfo::Tuple`].\n    ///\n    /// [type]: TypeInfo\n    pub fn set_represented_type(&mut self, represented_type: Option<&'static TypeInfo>) {\n        if let Some(represented_type) = represented_type {\n            assert!(\n                matches!(represented_type, TypeInfo::Tuple(_)),\n                \"expected TypeInfo::Tuple but received: {:?}\",\n                represented_type\n            );\n        }\n        self.represented_type = represented_type;\n    }\n\n    /// Appends an element with value `value` to the tuple.\n    pub fn insert_boxed(&mut self, value: Box<dyn PartialReflect>) {\n        self.represented_type = None;\n        self.fields.push(value);\n    }\n\n    /// Appends a typed element with value `value` to the tuple.\n    pub fn insert<T: PartialReflect>(&mut self, value: T) {\n        self.represented_type = None;\n        self.insert_boxed(Box::new(value));\n    }\n}\n\nimpl Tuple for DynamicTuple {\n    #[inline]\n    fn field(&self, index: usize) -> Option<&dyn PartialReflect> {\n        self.fields.get(index).map(|field| &**field)\n    }\n\n    #[inline]\n    fn field_mut(&mut self, index: usize) -> Option<&mut dyn PartialReflect> {\n        self.fields.get_mut(index).map(|field| &mut **field)\n    }\n\n    #[inline]\n    fn field_len(&self) -> usize {\n        self.fields.len()\n    }\n\n    #[inline]\n    fn iter_fields(&self) -> TupleFieldIter {\n        TupleFieldIter {\n            tuple: self,\n            index: 0,\n        }\n    }\n\n    #[inline]\n    fn drain(self: Box<Self>) -> Vec<Box<dyn PartialReflect>> {\n        self.fields\n    }\n\n    #[inline]\n    fn clone_dynamic(&self) -> DynamicTuple {\n        DynamicTuple {\n            represented_type: self.represented_type,\n            fields: self\n                .fields\n                .iter()\n                .map(|value| value.clone_value())\n                .collect(),\n        }\n    }\n}\n\nimpl PartialReflect for DynamicTuple {\n    #[inline]\n    fn get_represented_type_info(&self) -> Option<&'static TypeInfo> {\n        self.represented_type\n    }\n\n    #[inline]\n    fn into_partial_reflect(self: Box<Self>) -> Box<dyn PartialReflect> {\n        self\n    }\n\n    fn as_partial_reflect(&self) -> &dyn PartialReflect {\n        self\n    }\n\n    fn as_partial_reflect_mut(&mut self) -> &mut dyn PartialReflect {\n        self\n    }\n\n    fn try_into_reflect(self: Box<Self>) -> Result<Box<dyn Reflect>, Box<dyn PartialReflect>> {\n        Err(self)\n    }\n\n    fn try_as_reflect(&self) -> Option<&dyn Reflect> {\n        None\n    }\n\n    fn try_as_reflect_mut(&mut self) -> Option<&mut dyn Reflect> {\n        None\n    }\n\n    fn apply(&mut self, value: &dyn PartialReflect) {\n        tuple_apply(self, value);\n    }\n\n    #[inline]\n    fn reflect_kind(&self) -> ReflectKind {\n        ReflectKind::Tuple\n    }\n\n    #[inline]\n    fn reflect_ref(&self) -> ReflectRef {\n        ReflectRef::Tuple(self)\n    }\n\n    #[inline]\n    fn reflect_mut(&mut self) -> ReflectMut {\n        ReflectMut::Tuple(self)\n    }\n\n    #[inline]\n    fn reflect_owned(self: Box<Self>) -> ReflectOwned {\n        ReflectOwned::Tuple(self)\n    }\n\n    #[inline]\n    fn clone_value(&self) -> Box<dyn PartialReflect> {\n        Box::new(self.clone_dynamic())\n    }\n\n    fn try_apply(&mut self, value: &dyn PartialReflect) -> Result<(), ApplyError> {\n        tuple_try_apply(self, value)\n    }\n\n    fn reflect_partial_eq(&self, value: &dyn PartialReflect) -> Option<bool> {\n        tuple_partial_eq(self, value)\n    }\n\n    fn debug(&self, f: &mut Formatter<'_>) -> core::fmt::Result {\n        write!(f, \"DynamicTuple(\")?;\n        tuple_debug(self, f)?;\n        write!(f, \")\")\n    }\n\n    #[inline]\n    fn is_dynamic(&self) -> bool {\n        true\n    }\n}\n\nimpl_type_path!((in bevy_reflect) DynamicTuple);\n\nimpl FromIterator<Box<dyn PartialReflect>> for DynamicTuple {\n    fn from_iter<I: IntoIterator<Item = Box<dyn PartialReflect>>>(fields: I) -> Self {\n        Self {\n            represented_type: None,\n            fields: fields.into_iter().collect(),\n        }\n    }\n}\n\nimpl IntoIterator for DynamicTuple {\n    type Item = Box<dyn PartialReflect>;\n    type IntoIter = vec::IntoIter<Self::Item>;\n\n    fn into_iter(self) -> Self::IntoIter {\n        self.fields.into_iter()\n    }\n}\n\nimpl<'a> IntoIterator for &'a DynamicTuple {\n    type Item = &'a dyn PartialReflect;\n    type IntoIter = TupleFieldIter<'a>;\n\n    fn into_iter(self) -> Self::IntoIter {\n        self.iter_fields()\n    }\n}\n\n/// Applies the elements of `b` to the corresponding elements of `a`.\n///\n/// # Panics\n///\n/// This function panics if `b` is not a tuple.\n#[inline]\npub fn tuple_apply<T: Tuple>(a: &mut T, b: &dyn PartialReflect) {\n    if let Err(err) = tuple_try_apply(a, b) {\n        panic!(\"{err}\");\n    }\n}\n\n/// Tries to apply the elements of `b` to the corresponding elements of `a` and\n/// returns a Result.\n///\n/// # Errors\n///\n/// This function returns an [`ApplyError::MismatchedKinds`] if `b` is not a tuple or if\n/// applying elements to each other fails.\n#[inline]\npub fn tuple_try_apply<T: Tuple>(a: &mut T, b: &dyn PartialReflect) -> Result<(), ApplyError> {\n    let tuple = b.reflect_ref().as_tuple()?;\n\n    for (i, value) in tuple.iter_fields().enumerate() {\n        if let Some(v) = a.field_mut(i) {\n            v.try_apply(value)?;\n        }\n    }\n\n    Ok(())\n}\n\n/// Compares a [`Tuple`] with a [`PartialReflect`] value.\n///\n/// Returns true if and only if all of the following are true:\n/// - `b` is a tuple;\n/// - `b` has the same number of elements as `a`;\n/// - [`PartialReflect::reflect_partial_eq`] returns `Some(true)` for pairwise elements of `a` and `b`.\n///\n/// Returns [`None`] if the comparison couldn't even be performed.\n#[inline]\npub fn tuple_partial_eq<T: Tuple + ?Sized>(a: &T, b: &dyn PartialReflect) -> Option<bool> {\n    let ReflectRef::Tuple(b) = b.reflect_ref() else {\n        return Some(false);\n    };\n\n    if a.field_len() != b.field_len() {\n        return Some(false);\n    }\n\n    for (a_field, b_field) in a.iter_fields().zip(b.iter_fields()) {\n        let eq_result = a_field.reflect_partial_eq(b_field);\n        if let failed @ (Some(false) | None) = eq_result {\n            return failed;\n        }\n    }\n\n    Some(true)\n}\n\n/// The default debug formatter for [`Tuple`] types.\n///\n/// # Example\n/// ```\n/// use bevy_reflect::Reflect;\n///\n/// let my_tuple: &dyn Reflect = &(1, 2, 3);\n/// println!(\"{:#?}\", my_tuple);\n///\n/// // Output:\n///\n/// // (\n/// //   1,\n/// //   2,\n/// //   3,\n/// // )\n/// ```\n#[inline]\npub fn tuple_debug(dyn_tuple: &dyn Tuple, f: &mut Formatter<'_>) -> core::fmt::Result {\n    let mut debug = f.debug_tuple(\"\");\n    for field in dyn_tuple.iter_fields() {\n        debug.field(&field as &dyn Debug);\n    }\n    debug.finish()\n}\n\nmacro_rules! impl_reflect_tuple {\n    {$($index:tt : $name:tt),*} => {\n        impl<$($name: Reflect + MaybeTyped + TypePath + GetTypeRegistration),*> Tuple for ($($name,)*) {\n            #[inline]\n            fn field(&self, index: usize) -> Option<&dyn PartialReflect> {\n                match index {\n                    $($index => Some(&self.$index as &dyn PartialReflect),)*\n                    _ => None,\n                }\n            }\n\n            #[inline]\n            fn field_mut(&mut self, index: usize) -> Option<&mut dyn PartialReflect> {\n                match index {\n                    $($index => Some(&mut self.$index as &mut dyn PartialReflect),)*\n                    _ => None,\n                }\n            }\n\n            #[inline]\n            fn field_len(&self) -> usize {\n                let indices: &[usize] = &[$($index as usize),*];\n                indices.len()\n            }\n\n            #[inline]\n            fn iter_fields(&self) -> TupleFieldIter {\n                TupleFieldIter {\n                    tuple: self,\n                    index: 0,\n                }\n            }\n\n            #[inline]\n            fn drain(self: Box<Self>) -> Vec<Box<dyn PartialReflect>> {\n                vec![\n                    $(Box::new(self.$index),)*\n                ]\n            }\n\n            #[inline]\n            fn clone_dynamic(&self) -> DynamicTuple {\n                let info = self.get_represented_type_info();\n                DynamicTuple {\n                    represented_type: info,\n                    fields: self\n                        .iter_fields()\n                        .map(|value| value.clone_value())\n                        .collect(),\n                }\n            }\n        }\n\n        impl<$($name: Reflect + MaybeTyped + TypePath + GetTypeRegistration),*> PartialReflect for ($($name,)*) {\n            fn get_represented_type_info(&self) -> Option<&'static TypeInfo> {\n                Some(<Self as Typed>::type_info())\n            }\n\n            #[inline]\n            fn into_partial_reflect(self: Box<Self>) -> Box<dyn PartialReflect> {\n                self\n            }\n\n            fn as_partial_reflect(&self) -> &dyn PartialReflect {\n                self\n            }\n\n            fn as_partial_reflect_mut(&mut self) -> &mut dyn PartialReflect {\n                self\n            }\n\n            fn try_into_reflect(self: Box<Self>) -> Result<Box<dyn Reflect>, Box<dyn PartialReflect>> {\n                Ok(self)\n            }\n\n            fn try_as_reflect(&self) -> Option<&dyn Reflect> {\n                Some(self)\n            }\n\n            fn try_as_reflect_mut(&mut self) -> Option<&mut dyn Reflect> {\n                Some(self)\n            }\n\n            fn reflect_kind(&self) -> ReflectKind {\n                ReflectKind::Tuple\n            }\n\n            fn reflect_ref(&self) -> ReflectRef {\n                ReflectRef::Tuple(self)\n            }\n\n            fn reflect_mut(&mut self) -> ReflectMut {\n                ReflectMut::Tuple(self)\n            }\n\n            fn reflect_owned(self: Box<Self>) -> ReflectOwned {\n                ReflectOwned::Tuple(self)\n            }\n\n            fn clone_value(&self) -> Box<dyn PartialReflect> {\n                Box::new(self.clone_dynamic())\n            }\n\n            fn reflect_partial_eq(&self, value: &dyn PartialReflect) -> Option<bool> {\n                crate::tuple_partial_eq(self, value)\n            }\n\n            fn apply(&mut self, value: &dyn PartialReflect) {\n                crate::tuple_apply(self, value);\n            }\n\n            fn try_apply(&mut self, value: &dyn PartialReflect) -> Result<(), ApplyError> {\n                crate::tuple_try_apply(self, value)\n            }\n        }\n\n        impl<$($name: Reflect + MaybeTyped + TypePath + GetTypeRegistration),*> Reflect for ($($name,)*) {\n            fn into_any(self: Box<Self>) -> Box<dyn Any> {\n                self\n            }\n\n            fn as_any(&self) -> &dyn Any {\n                self\n            }\n\n            fn as_any_mut(&mut self) -> &mut dyn Any {\n                self\n            }\n\n            fn into_reflect(self: Box<Self>) -> Box<dyn Reflect> {\n                self\n            }\n\n            fn as_reflect(&self) -> &dyn Reflect {\n                self\n            }\n\n            fn as_reflect_mut(&mut self) -> &mut dyn Reflect {\n                self\n            }\n\n            fn set(&mut self, value: Box<dyn Reflect>) -> Result<(), Box<dyn Reflect>> {\n                *self = value.take()?;\n                Ok(())\n            }\n        }\n\n        impl <$($name: Reflect + MaybeTyped + TypePath + GetTypeRegistration),*> Typed for ($($name,)*) {\n            fn type_info() -> &'static TypeInfo {\n                static CELL: $crate::utility::GenericTypeInfoCell = $crate::utility::GenericTypeInfoCell::new();\n                CELL.get_or_insert::<Self, _>(|| {\n                    let fields = [\n                        $(UnnamedField::new::<$name>($index),)*\n                    ];\n                    let info = TupleInfo::new::<Self>(&fields);\n                    TypeInfo::Tuple(info)\n                })\n            }\n        }\n\n        impl<$($name: Reflect + MaybeTyped + TypePath + GetTypeRegistration),*> GetTypeRegistration for ($($name,)*) {\n            fn get_type_registration() -> TypeRegistration {\n                TypeRegistration::of::<($($name,)*)>()\n            }\n\n            fn register_type_dependencies(_registry: &mut TypeRegistry) {\n                $(_registry.register::<$name>();)*\n            }\n        }\n\n        impl<$($name: FromReflect + MaybeTyped + TypePath + GetTypeRegistration),*> FromReflect for ($($name,)*)\n        {\n            fn from_reflect(reflect: &dyn PartialReflect) -> Option<Self> {\n                let _ref_tuple = reflect.reflect_ref().as_tuple().ok()?;\n\n                Some(\n                    (\n                        $(\n                            <$name as FromReflect>::from_reflect(_ref_tuple.field($index)?)?,\n                        )*\n                    )\n                )\n            }\n        }\n    }\n}\n\nimpl_reflect_tuple! {}\nimpl_reflect_tuple! {0: A}\nimpl_reflect_tuple! {0: A, 1: B}\nimpl_reflect_tuple! {0: A, 1: B, 2: C}\nimpl_reflect_tuple! {0: A, 1: B, 2: C, 3: D}\nimpl_reflect_tuple! {0: A, 1: B, 2: C, 3: D, 4: E}\nimpl_reflect_tuple! {0: A, 1: B, 2: C, 3: D, 4: E, 5: F}\nimpl_reflect_tuple! {0: A, 1: B, 2: C, 3: D, 4: E, 5: F, 6: G}\nimpl_reflect_tuple! {0: A, 1: B, 2: C, 3: D, 4: E, 5: F, 6: G, 7: H}\nimpl_reflect_tuple! {0: A, 1: B, 2: C, 3: D, 4: E, 5: F, 6: G, 7: H, 8: I}\nimpl_reflect_tuple! {0: A, 1: B, 2: C, 3: D, 4: E, 5: F, 6: G, 7: H, 8: I, 9: J}\nimpl_reflect_tuple! {0: A, 1: B, 2: C, 3: D, 4: E, 5: F, 6: G, 7: H, 8: I, 9: J, 10: K}\nimpl_reflect_tuple! {0: A, 1: B, 2: C, 3: D, 4: E, 5: F, 6: G, 7: H, 8: I, 9: J, 10: K, 11: L}\n\nmacro_rules! impl_type_path_tuple {\n    ($(#[$meta:meta])*) => {\n        $(#[$meta])*\n        impl TypePath for () {\n            fn type_path() -> &'static str {\n                \"()\"\n            }\n\n            fn short_type_path() -> &'static str {\n                \"()\"\n            }\n        }\n    };\n\n    ($(#[$meta:meta])* $param:ident) => {\n        $(#[$meta])*\n        impl <$param: TypePath> TypePath for ($param,) {\n            fn type_path() -> &'static str {\n                use $crate::__macro_exports::alloc_utils::ToOwned;\n                static CELL: GenericTypePathCell = GenericTypePathCell::new();\n                CELL.get_or_insert::<Self, _>(|| {\n                    \"(\".to_owned() + $param::type_path() + \",)\"\n                })\n            }\n\n            fn short_type_path() -> &'static str {\n                use $crate::__macro_exports::alloc_utils::ToOwned;\n                static CELL: GenericTypePathCell = GenericTypePathCell::new();\n                CELL.get_or_insert::<Self, _>(|| {\n                    \"(\".to_owned() + $param::short_type_path() + \",)\"\n                })\n            }\n        }\n    };\n\n    ($(#[$meta:meta])* $last:ident $(,$param:ident)*) => {\n        $(#[$meta])*\n        impl <$($param: TypePath,)* $last: TypePath> TypePath for ($($param,)* $last) {\n            fn type_path() -> &'static str {\n                use $crate::__macro_exports::alloc_utils::ToOwned;\n                static CELL: GenericTypePathCell = GenericTypePathCell::new();\n                CELL.get_or_insert::<Self, _>(|| {\n                    \"(\".to_owned() $(+ $param::type_path() + \", \")* + $last::type_path() + \")\"\n                })\n            }\n\n            fn short_type_path() -> &'static str {\n                use $crate::__macro_exports::alloc_utils::ToOwned;\n                static CELL: GenericTypePathCell = GenericTypePathCell::new();\n                CELL.get_or_insert::<Self, _>(|| {\n                    \"(\".to_owned() $(+ $param::short_type_path() + \", \")* + $last::short_type_path() + \")\"\n                })\n            }\n        }\n    };\n}\n\nall_tuples!(\n    #[doc(fake_variadic)]\n    impl_type_path_tuple,\n    0,\n    12,\n    P\n);\n\n#[cfg(feature = \"functions\")]\nconst _: () = {\n    macro_rules! impl_get_ownership_tuple {\n    ($(#[$meta:meta])* $($name: ident),*) => {\n        $(#[$meta])*\n        $crate::func::args::impl_get_ownership!(($($name,)*); <$($name),*>);\n    };\n}\n\n    all_tuples!(\n        #[doc(fake_variadic)]\n        impl_get_ownership_tuple,\n        0,\n        12,\n        P\n    );\n\n    macro_rules! impl_from_arg_tuple {\n    ($(#[$meta:meta])* $($name: ident),*) => {\n        $(#[$meta])*\n        $crate::func::args::impl_from_arg!(($($name,)*); <$($name: FromReflect + MaybeTyped + TypePath + GetTypeRegistration),*>);\n    };\n}\n\n    all_tuples!(\n        #[doc(fake_variadic)]\n        impl_from_arg_tuple,\n        0,\n        12,\n        P\n    );\n\n    macro_rules! impl_into_return_tuple {\n    ($(#[$meta:meta])* $($name: ident),+) => {\n        $(#[$meta])*\n        $crate::func::impl_into_return!(($($name,)*); <$($name: FromReflect + MaybeTyped + TypePath + GetTypeRegistration),*>);\n    };\n}\n\n    // The unit type (i.e. `()`) is special-cased, so we skip implementing it here.\n    all_tuples!(\n        #[doc(fake_variadic)]\n        impl_into_return_tuple,\n        1,\n        12,\n        P\n    );\n};\n\n#[cfg(test)]\nmod tests {\n    use super::Tuple;\n\n    #[test]\n    fn next_index_increment() {\n        let mut iter = (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11).iter_fields();\n        let size = iter.len();\n        iter.index = size - 1;\n        let prev_index = iter.index;\n        assert!(iter.next().is_some());\n        assert_eq!(prev_index, iter.index - 1);\n\n        // When None we should no longer increase index\n        assert!(iter.next().is_none());\n        assert_eq!(size, iter.index);\n        assert!(iter.next().is_none());\n        assert_eq!(size, iter.index);\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "ce0c738866a0c3e54ff1ba16eee5b33c6b3cc14e",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/crates/bevy_picking/src/pointer.rs",
    "func": "//! Types and systems for pointer inputs, such as position and buttons.\n//!\n//! The picking system is built around the concept of a 'Pointer', which is an\n//! abstract representation of a user input with a specific screen location. The cursor\n//! and touch input is provided under [`crate::input`], but you can also implement\n//! your own custom pointers by supplying a unique ID.\n//!\n//! The purpose of this module is primarily to provide a common interface that can be\n//! driven by lower-level input devices and consumed by higher-level interaction systems.\n\nuse bevy_ecs::prelude::*;\nuse bevy_math::Vec2;\nuse bevy_reflect::prelude::*;\nuse bevy_render::camera::{Camera, NormalizedRenderTarget};\nuse bevy_utils::HashMap;\nuse bevy_window::PrimaryWindow;\n\nuse uuid::Uuid;\n\nuse core::{fmt::Debug, ops::Deref};\n\nuse crate::backend::HitData;\n\n/// Identifies a unique pointer entity. `Mouse` and `Touch` pointers are automatically spawned.\n///\n/// This component is needed because pointers can be spawned and despawned, but they need to have a\n/// stable ID that persists regardless of the Entity they are associated with.\n#[derive(Debug, Default, Clone, Copy, Eq, PartialEq, Hash, Component, Reflect)]\n#[require(PointerLocation, PointerPress, PointerInteraction)]\n#[reflect(Component, Default, Debug, Hash, PartialEq)]\npub enum PointerId {\n    /// The mouse pointer.\n    #[default]\n    Mouse,\n    /// A touch input, usually numbered by window touch events from `winit`.\n    Touch(u64),\n    /// A custom, uniquely identified pointer. Useful for mocking inputs or implementing a software\n    /// controlled cursor.\n    #[reflect(ignore)]\n    Custom(Uuid),\n}\n\nimpl PointerId {\n    /// Returns true if the pointer is a touch input.\n    pub fn is_touch(&self) -> bool {\n        matches!(self, PointerId::Touch(_))\n    }\n    /// Returns true if the pointer is the mouse.\n    pub fn is_mouse(&self) -> bool {\n        matches!(self, PointerId::Mouse)\n    }\n    /// Returns true if the pointer is a custom input.\n    pub fn is_custom(&self) -> bool {\n        matches!(self, PointerId::Custom(_))\n    }\n    /// Returns the touch id if the pointer is a touch input.\n    pub fn get_touch_id(&self) -> Option<u64> {\n        if let PointerId::Touch(id) = self {\n            Some(*id)\n        } else {\n            None\n        }\n    }\n}\n\n/// Holds a list of entities this pointer is currently interacting with, sorted from nearest to\n/// farthest.\n#[derive(Debug, Default, Clone, Component, Reflect)]\n#[reflect(Component, Default, Debug)]\npub struct PointerInteraction {\n    pub(crate) sorted_entities: Vec<(Entity, HitData)>,\n}\n\nimpl PointerInteraction {\n    /// Returns the nearest hit entity and data about that intersection.\n    pub fn get_nearest_hit(&self) -> Option<&(Entity, HitData)> {\n        self.sorted_entities.first()\n    }\n}\n\nimpl Deref for PointerInteraction {\n    type Target = Vec<(Entity, HitData)>;\n\n    fn deref(&self) -> &Self::Target {\n        &self.sorted_entities\n    }\n}\n\n/// A resource that maps each [`PointerId`] to their [`Entity`] for easy lookups.\n#[derive(Debug, Clone, Default, Resource)]\npub struct PointerMap {\n    inner: HashMap<PointerId, Entity>,\n}\n\nimpl PointerMap {\n    /// Get the [`Entity`] of the supplied [`PointerId`].\n    pub fn get_entity(&self, pointer_id: PointerId) -> Option<Entity> {\n        self.inner.get(&pointer_id).copied()\n    }\n}\n\n/// Update the [`PointerMap`] resource with the current frame's data.\npub fn update_pointer_map(pointers: Query<(Entity, &PointerId)>, mut map: ResMut<PointerMap>) {\n    map.inner.clear();\n    for (entity, id) in &pointers {\n        map.inner.insert(*id, entity);\n    }\n}\n\n/// Tracks the state of the pointer's buttons in response to [`PointerInput`] events.\n#[derive(Debug, Default, Clone, Component, Reflect, PartialEq, Eq)]\n#[reflect(Component, Default, Debug, PartialEq)]\npub struct PointerPress {\n    primary: bool,\n    secondary: bool,\n    middle: bool,\n}\n\nimpl PointerPress {\n    /// Returns true if the primary pointer button is pressed.\n    #[inline]\n    pub fn is_primary_pressed(&self) -> bool {\n        self.primary\n    }\n\n    /// Returns true if the secondary pointer button is pressed.\n    #[inline]\n    pub fn is_secondary_pressed(&self) -> bool {\n        self.secondary\n    }\n\n    /// Returns true if the middle (tertiary) pointer button is pressed.\n    #[inline]\n    pub fn is_middle_pressed(&self) -> bool {\n        self.middle\n    }\n\n    /// Returns true if any pointer button is pressed.\n    #[inline]\n    pub fn is_any_pressed(&self) -> bool {\n        self.primary || self.middle || self.secondary\n    }\n}\n\n/// The stage of the pointer button press event\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Reflect)]\npub enum PressDirection {\n    /// The pointer button was just pressed\n    Down,\n    /// The pointer button was just released\n    Up,\n}\n\n/// The button that was just pressed or released\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Reflect)]\npub enum PointerButton {\n    /// The primary pointer button\n    Primary,\n    /// The secondary pointer button\n    Secondary,\n    /// The tertiary pointer button\n    Middle,\n}\n\nimpl PointerButton {\n    /// Iterator over all buttons that a pointer can have.\n    pub fn iter() -> impl Iterator<Item = PointerButton> {\n        [Self::Primary, Self::Secondary, Self::Middle].into_iter()\n    }\n}\n\n/// Component that tracks a pointer's current [`Location`].\n#[derive(Debug, Default, Clone, Component, Reflect, PartialEq)]\n#[reflect(Component, Default, Debug, PartialEq)]\npub struct PointerLocation {\n    /// The [`Location`] of the pointer. Note that a location is both the target, and the position\n    /// on the target.\n    #[reflect(ignore)]\n    pub location: Option<Location>,\n}\n\nimpl PointerLocation {\n    ///Returns a [`PointerLocation`] associated with the given location\n    pub fn new(location: Location) -> Self {\n        Self {\n            location: Some(location),\n        }\n    }\n\n    /// Returns `Some(&`[`Location`]`)` if the pointer is active, or `None` if the pointer is\n    /// inactive.\n    pub fn location(&self) -> Option<&Location> {\n        self.location.as_ref()\n    }\n}\n\n/// The location of a pointer, including the current [`NormalizedRenderTarget`], and the x/y\n/// position of the pointer on this render target.\n///\n/// Note that:\n/// - a pointer can move freely between render targets\n/// - a pointer is not associated with a [`Camera`] because multiple cameras can target the same\n///   render target. It is up to picking backends to associate a Pointer's `Location` with a\n///   specific `Camera`, if any.\n#[derive(Debug, Clone, Component, Reflect, PartialEq)]\n#[reflect(Component, Debug, PartialEq)]\npub struct Location {\n    /// The [`NormalizedRenderTarget`] associated with the pointer, usually a window.\n    pub target: NormalizedRenderTarget,\n    /// The position of the pointer in the `target`.\n    pub position: Vec2,\n}\n\nimpl Location {\n    /// Returns `true` if this pointer's [`Location`] is within the [`Camera`]'s viewport.\n    ///\n    /// Note this returns `false` if the location and camera have different render targets.\n    #[inline]\n    pub fn is_in_viewport(\n        &self,\n        camera: &Camera,\n        primary_window: &Query<Entity, With<PrimaryWindow>>,\n    ) -> bool {\n        if camera\n            .target\n            .normalize(Some(match primary_window.get_single() {\n                Ok(w) => w,\n                Err(_) => return false,\n            }))\n            .as_ref()\n            != Some(&self.target)\n        {\n            return false;\n        }\n\n        camera\n            .logical_viewport_rect()\n            .map(|rect| rect.contains(self.position))\n            .unwrap_or(false)\n    }\n}\n\n/// Types of actions that can be taken by pointers.\n#[derive(Debug, Clone, Copy, Reflect)]\npub enum PointerAction {\n    /// A button has been pressed on the pointer.\n    Pressed {\n        /// The press direction, either down or up.\n        direction: PressDirection,\n        /// The button that was pressed.\n        button: PointerButton,\n    },\n    /// The pointer has moved.\n    Moved {\n        /// How much the pointer moved from the previous position.\n        delta: Vec2,\n    },\n    /// The pointer has been canceled. The OS can cause this to happen to touch events.\n    Canceled,\n}\n\n/// An input event effecting a pointer.\n#[derive(Event, Debug, Clone, Reflect)]\npub struct PointerInput {\n    /// The id of the pointer.\n    pub pointer_id: PointerId,\n    /// The location of the pointer. For [[`PointerAction::Moved`]], this is the location after the movement.\n    pub location: Location,\n    /// The action that the event describes.\n    pub action: PointerAction,\n}\n\nimpl PointerInput {\n    /// Creates a new pointer input event.\n    ///\n    /// Note that `location` refers to the position of the pointer *after* the event occurred.\n    pub fn new(pointer_id: PointerId, location: Location, action: PointerAction) -> PointerInput {\n        PointerInput {\n            pointer_id,\n            location,\n            action,\n        }\n    }\n\n    /// Returns true if the `target_button` of this pointer was just pressed.\n    #[inline]\n    pub fn button_just_pressed(&self, target_button: PointerButton) -> bool {\n        if let PointerAction::Pressed { direction, button } = self.action {\n            direction == PressDirection::Down && button == target_button\n        } else {\n            false\n        }\n    }\n\n    /// Returns true if the `target_button` of this pointer was just released.\n    #[inline]\n    pub fn button_just_released(&self, target_button: PointerButton) -> bool {\n        if let PointerAction::Pressed { direction, button } = self.action {\n            direction == PressDirection::Up && button == target_button\n        } else {\n            false\n        }\n    }\n\n    /// Updates pointer entities according to the input events.\n    pub fn receive(\n        mut events: EventReader<PointerInput>,\n        mut pointers: Query<(&PointerId, &mut PointerLocation, &mut PointerPress)>,\n    ) {\n        for event in events.read() {\n            match event.action {\n                PointerAction::Pressed { direction, button } => {\n                    pointers\n                        .iter_mut()\n                        .for_each(|(pointer_id, _, mut pointer)| {\n                            if *pointer_id == event.pointer_id {\n                                let is_down = direction == PressDirection::Down;\n                                match button {\n                                    PointerButton::Primary => pointer.primary = is_down,\n                                    PointerButton::Secondary => pointer.secondary = is_down,\n                                    PointerButton::Middle => pointer.middle = is_down,\n                                }\n                            }\n                        });\n                }\n                PointerAction::Moved { .. } => {\n                    pointers.iter_mut().for_each(|(id, mut pointer, _)| {\n                        if *id == event.pointer_id {\n                            pointer.location = Some(event.location.to_owned());\n                        }\n                    });\n                }\n                _ => {}\n            }\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "22933981d3878a3be80862787261406dc665ee11",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/examples/3d/vertex_colors.rs",
    "func": "//! Illustrates the use of vertex colors.\n\nuse bevy::{prelude::*, render::mesh::VertexAttributeValues};\n\nfn main() {\n    App::new()\n        .add_plugins(DefaultPlugins)\n        .add_systems(Startup, setup)\n        .run();\n}\n\n/// set up a simple 3D scene\nfn setup(\n    mut commands: Commands,\n    mut meshes: ResMut<Assets<Mesh>>,\n    mut materials: ResMut<Assets<StandardMaterial>>,\n) {\n    // plane\n    commands.spawn((\n        Mesh3d(meshes.add(Plane3d::default().mesh().size(5.0, 5.0))),\n        MeshMaterial3d(materials.add(Color::srgb(0.3, 0.5, 0.3))),\n    ));\n    // cube\n    // Assign vertex colors based on vertex positions\n    let mut colorful_cube = Mesh::from(Cuboid::default());\n    if let Some(VertexAttributeValues::Float32x3(positions)) =\n        colorful_cube.attribute(Mesh::ATTRIBUTE_POSITION)\n    {\n        let colors: Vec<[f32; 4]> = positions\n            .iter()\n            .map(|[r, g, b]| [(1. - *r) / 2., (1. - *g) / 2., (1. - *b) / 2., 1.])\n            .collect();\n        colorful_cube.insert_attribute(Mesh::ATTRIBUTE_COLOR, colors);\n    }\n    commands.spawn((\n        Mesh3d(meshes.add(colorful_cube)),\n        // This is the default color, but note that vertex colors are\n        // multiplied by the base color, so you'll likely want this to be\n        // white if using vertex colors.\n        MeshMaterial3d(materials.add(Color::srgb(1., 1., 1.))),\n        Transform::from_xyz(0.0, 0.5, 0.0),\n    ));\n\n    // Light\n    commands.spawn((\n        PointLight {\n            shadows_enabled: true,\n            ..default()\n        },\n        Transform::from_xyz(4.0, 5.0, 4.0).looking_at(Vec3::ZERO, Vec3::Y),\n    ));\n\n    // Camera\n    commands.spawn((\n        Camera3d::default(),\n        Transform::from_xyz(-2.0, 2.5, 5.0).looking_at(Vec3::ZERO, Vec3::Y),\n    ));\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "b61a1a9e6c957aac3665630a1d0bccc51f0956cf",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/examples/2d/transparency_2d.rs",
    "func": "//! Demonstrates how to use transparency in 2D.\n//! Shows 3 bevy logos on top of each other, each with a different amount of transparency.\n\nuse bevy::prelude::*;\n\nfn main() {\n    App::new()\n        .add_plugins(DefaultPlugins)\n        .add_systems(Startup, setup)\n        .run();\n}\n\nfn setup(mut commands: Commands, asset_server: Res<AssetServer>) {\n    commands.spawn(Camera2d);\n\n    let sprite_handle = asset_server.load(\"branding/icon.png\");\n\n    commands.spawn(Sprite::from_image(sprite_handle.clone()));\n    commands.spawn((\n        Sprite {\n            image: sprite_handle.clone(),\n            // Alpha channel of the color controls transparency.\n            color: Color::srgba(0.0, 0.0, 1.0, 0.7),\n            ..default()\n        },\n        Transform::from_xyz(100.0, 0.0, 0.1),\n    ));\n    commands.spawn((\n        Sprite {\n            image: sprite_handle,\n            color: Color::srgba(0.0, 1.0, 0.0, 0.3),\n            ..default()\n        },\n        Transform::from_xyz(200.0, 0.0, 0.2),\n    ));\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "12c224f2d5389891f7ecd051abd12cd856fdfaed",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bevy/examples/2d/2d_viewport_to_world.rs",
    "func": "//! This example demonstrates how to use the `Camera::viewport_to_world_2d` method.\n\nuse bevy::{color::palettes::basic::WHITE, prelude::*};\n\nfn main() {\n    App::new()\n        .add_plugins(DefaultPlugins)\n        .add_systems(Startup, setup)\n        .add_systems(Update, draw_cursor)\n        .run();\n}\n\nfn draw_cursor(\n    camera_query: Single<(&Camera, &GlobalTransform)>,\n    window: Single<&Window>,\n    mut gizmos: Gizmos,\n) {\n    let (camera, camera_transform) = *camera_query;\n\n    let Some(cursor_position) = window.cursor_position() else {\n        return;\n    };\n\n    // Calculate a world position based on the cursor's position.\n    let Ok(point) = camera.viewport_to_world_2d(camera_transform, cursor_position) else {\n        return;\n    };\n\n    gizmos.circle_2d(point, 10., WHITE);\n}\n\nfn setup(mut commands: Commands) {\n    commands.spawn(Camera2d);\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "01ddbfaf4a7a729f9e660a660d88e067bf08f8d4",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/diesel_cli/tests/print_schema.rs",
    "func": "#![allow(clippy::expect_fun_call)]\nuse std::fs::File;\nuse std::io::prelude::*;\nuse std::path::{Path, PathBuf};\n\nuse crate::support::{database, project};\n\n#[test]\nfn run_infer_schema_without_docs() {\n    test_print_schema(\"print_schema_simple_without_docs\", vec![]);\n}\n\n#[test]\n#[cfg(feature = \"postgres\")]\nfn run_except_custom_type_definitions() {\n    test_print_schema(\n        \"print_schema_except_custom_type_definitions\",\n        vec![\"--except-custom-type-definitions\", \"MyType2\"],\n    );\n}\n\n#[test]\nfn run_infer_schema() {\n    test_print_schema(\"print_schema_simple\", vec![\"--with-docs\"]);\n}\n\n#[test]\nfn run_infer_schema_include() {\n    test_print_schema(\n        \"print_schema_only_tables\",\n        vec![\"--with-docs\", \"-o\", \"users1\"],\n    );\n}\n\n#[test]\nfn run_infer_schema_include_regex() {\n    test_print_schema(\n        \"print_schema_only_table_regexes\",\n        vec![\"--with-docs\", \"-o\", \"users1\"],\n    );\n}\n\n#[test]\n#[cfg(feature = \"sqlite\")]\nfn run_infer_schema_django_bool_case() {\n    test_print_schema(\n        \"print_schema_django_bool\",\n        vec![\"--with-docs\", \"-o\", \"users1\"],\n    );\n}\n\n#[test]\nfn run_infer_schema_exclude() {\n    test_print_schema(\n        \"print_schema_except_tables\",\n        vec![\"--with-docs\", \"-e\", \"users1\"],\n    );\n}\n\n#[test]\nfn run_infer_schema_exclude_regex() {\n    test_print_schema(\n        \"print_schema_except_table_regexes\",\n        vec![\"--with-docs\", \"-e\", \"users1\"],\n    );\n}\n\n#[test]\nfn run_infer_schema_table_order() {\n    test_print_schema(\"print_schema_table_order\", vec![\"--with-docs\"]);\n}\n\n#[test]\nfn run_infer_schema_column_order() {\n    test_print_schema(\n        \"print_schema_column_order\",\n        vec![\"--column-sorting\", \"name\"],\n    );\n}\n\n#[test]\nfn run_infer_schema_compound_primary_key() {\n    test_print_schema(\"print_schema_compound_primary_key\", vec![\"--with-docs\"]);\n}\n\n#[test]\n#[cfg(feature = \"postgres\")]\nfn print_schema_specifying_schema_name() {\n    test_print_schema(\n        \"print_schema_specifying_schema_name\",\n        vec![\"--with-docs\", \"--schema\", \"custom_schema\"],\n    )\n}\n\n#[test]\n#[cfg(feature = \"postgres\")]\nfn print_schema_specifying_schema_name_with_foreign_keys() {\n    test_print_schema(\n        \"print_schema_specifying_schema_name_with_foreign_keys\",\n        vec![\"--with-docs\", \"--schema\", \"custom_schema\"],\n    )\n}\n\n#[test]\n#[cfg(feature = \"postgres\")]\nfn print_schema_with_compound_foreign_keys() {\n    test_print_schema(\n        \"print_schema_with_compound_foreign_keys\",\n        vec![\"--with-docs\"],\n    );\n}\n\n#[test]\n#[cfg(feature = \"postgres\")]\nfn print_schema_with_foreign_keys() {\n    test_print_schema(\"print_schema_with_foreign_keys\", vec![\"--with-docs\"]);\n}\n\n#[test]\n#[cfg(feature = \"postgres\")]\nfn print_schema_with_foreign_keys_reserved_names() {\n    test_print_schema(\n        \"print_schema_with_foreign_keys_reserved_names\",\n        vec![\"--with-docs\"],\n    );\n}\n\n#[test]\nfn print_schema_column_renaming() {\n    test_print_schema(\"print_schema_column_renaming\", vec![\"--with-docs\"]);\n}\n\n#[test]\n#[cfg(feature = \"postgres\")]\nfn print_schema_type_renaming() {\n    test_print_schema(\"print_schema_type_renaming\", vec![\"--with-docs\"]);\n}\n\n#[test]\n#[cfg(feature = \"mysql\")]\nfn print_schema_unsigned() {\n    test_print_schema(\"print_schema_unsigned\", vec![\"--with-docs\"]);\n}\n\n#[test]\n#[cfg(feature = \"mysql\")]\nfn print_schema_datetime_for_mysql() {\n    test_print_schema(\"print_schema_datetime_for_mysql\", vec![\"--with-docs\"]);\n}\n\n#[test]\n#[cfg(not(windows))]\nfn print_schema_patch_file() {\n    let path_to_patch_file = backend_file_path(\"print_schema_patch_file\", \"schema.patch\");\n    let path = path_to_patch_file.display().to_string();\n    test_print_schema(\"print_schema_patch_file\", vec![\"--patch-file\", &path]);\n}\n\n#[test]\nfn print_schema_custom_types() {\n    test_print_schema(\n        \"print_schema_custom_types\",\n        vec![\"--import-types\", \"foo::*\", \"--import-types\", \"bar::*\"],\n    );\n}\n\n#[test]\n#[cfg(feature = \"postgres\")]\nfn print_schema_custom_types_custom_schema() {\n    test_print_schema(\n        \"print_schema_custom_types_custom_schema\",\n        vec![\n            \"--schema\",\n            \"v2\",\n            \"--custom-type-derives\",\n            \"diesel::query_builder::QueryId\",\n            \"--custom-type-derives\",\n            \"Clone\",\n        ],\n    );\n}\n\n#[test]\nfn print_schema_with_unmappable_names() {\n    test_print_schema(\"print_schema_with_unmappable_names\", vec![\"--with-docs\"]);\n}\n\n#[test]\n#[cfg(feature = \"postgres\")]\nfn print_schema_with_unmappable_names_and_schema_name() {\n    test_print_schema(\n        \"print_schema_with_unmappable_names_and_schema_name\",\n        vec![\"--with-docs\", \"--schema\", \"custom_schema\"],\n    )\n}\n\n#[test]\nfn print_schema_with_separate_unique_constraint_and_foreign_key() {\n    test_print_schema(\"print_schema_regression_test_for_2623\", vec![])\n}\n\n#[test]\nfn schema_file_is_relative_to_project_root() {\n    let p = project(\"schema_file_is_relative_to_project_root\")\n        .folder(\"foo\")\n        .build();\n    let _db = database(&p.database_url());\n\n    p.command(\"setup\").run();\n    p.command(\"migration\").arg(\"run\").cd(\"foo\").run();\n\n    assert!(p.has_file(\"src/schema.rs\"));\n}\n\n#[test]\n#[cfg(feature = \"postgres\")]\nfn print_schema_disabling_custom_type_works() {\n    test_print_schema(\n        \"print_schema_disabling_custom_type_works\",\n        vec![\"--no-generate-missing-sql-type-definitions\"],\n    )\n}\n\n#[test]\n#[cfg(feature = \"postgres\")]\nfn print_schema_default_is_to_generate_custom_types() {\n    test_print_schema(\n        \"print_schema_default_is_to_generate_custom_types\",\n        vec![\"--with-docs\"],\n    )\n}\n\n#[test]\n#[cfg(feature = \"postgres\")]\nfn print_schema_specifying_schema_name_with_custom_type() {\n    test_print_schema(\n        \"print_schema_specifying_schema_name_with_custom_type\",\n        vec![\"--with-docs\", \"--schema\", \"custom_schema\"],\n    )\n}\n\n#[test]\n#[cfg(feature = \"postgres\")]\nfn print_schema_custom_types_check_default_derives() {\n    test_print_schema(\n        \"print_schema_custom_types_check_default_derives\",\n        vec![\"--with-docs\"],\n    )\n}\n\n#[test]\n#[cfg(feature = \"postgres\")]\nfn print_schema_custom_types_overriding_derives_works() {\n    test_print_schema(\n        \"print_schema_custom_types_overriding_derives_works\",\n        vec![\n            \"--with-docs\",\n            \"--custom-type-derives\",\n            \"diesel::sql_types::SqlType\",\n            \"--custom-type-derives\",\n            \"core::fmt::Debug\",\n        ],\n    )\n}\n\n#[test]\n#[cfg(feature = \"sqlite\")]\nfn print_schema_generated_columns() {\n    test_print_schema(\"print_schema_generated_columns\", vec![])\n}\n\n#[test]\n#[cfg(feature = \"sqlite\")]\nfn print_schema_generated_columns_with_generated_always() {\n    test_print_schema(\"print_schema_generated_columns_generated_always\", vec![])\n}\n\n#[test]\n#[cfg(feature = \"sqlite\")]\nfn print_schema_sqlite_rowid_column() {\n    test_print_schema(\n        \"print_schema_sqlite_rowid_column\",\n        vec![\"--sqlite-integer-primary-key-is-bigint\"],\n    )\n}\n\n#[test]\n#[cfg(feature = \"postgres\")]\nfn print_schema_multiple_annotations() {\n    test_print_schema(\"print_schema_multiple_annotations\", vec![])\n}\n\n#[test]\n#[cfg(feature = \"postgres\")]\nfn print_schema_array_type() {\n    test_print_schema(\"print_schema_array_type\", vec![])\n}\n\n#[test]\n#[cfg(feature = \"sqlite\")]\nfn print_schema_sqlite_implicit_foreign_key_reference() {\n    test_print_schema(\"print_schema_sqlite_implicit_foreign_key_reference\", vec![]);\n}\n\n#[test]\n#[cfg(feature = \"sqlite\")]\nfn print_schema_sqlite_without_explicit_primary_key() {\n    test_print_schema(\"print_schema_sqlite_without_explicit_primary_key\", vec![])\n}\n\n#[test]\n#[cfg(feature = \"postgres\")]\nfn print_schema_respects_type_name_case() {\n    test_print_schema(\"print_schema_respects_type_name_case\", vec![\"--with-docs\"])\n}\n\n#[test]\n#[cfg(any(feature = \"postgres\", feature = \"mysql\"))]\nfn print_schema_comments_fallback_on_generated() {\n    test_print_schema(\n        \"print_schema_comments_fallback_on_generated\",\n        vec![\"--with-docs\"],\n    )\n}\n\n#[test]\n#[cfg(any(feature = \"postgres\", feature = \"mysql\"))]\nfn print_schema_with_enum_set_types() {\n    test_print_schema(\n        \"print_schema_with_enum_set_types\",\n        vec![\n            \"--with-docs\",\n            \"--custom-type-derives\",\n            \"diesel::query_builder::QueryId\",\n            \"--custom-type-derives\",\n            \"Clone\",\n        ],\n    )\n}\n\n#[test]\n#[cfg(any(feature = \"postgres\", feature = \"mysql\"))]\nfn print_schema_comments_dont_fallback_on_generated() {\n    test_print_schema(\n        \"print_schema_comments_dont_fallback_on_generated\",\n        vec![\"--with-docs-config\", \"only-database-comments\"],\n    )\n}\n\n#[test]\nfn print_schema_reserved_names() {\n    test_print_schema(\"print_schema_reserved_name_mitigation_issue_3404\", vec![])\n}\n\n#[test]\n#[cfg(feature = \"postgres\")]\nfn print_schema_regression_3446_ignore_compound_foreign_keys() {\n    test_print_schema(\"print_schema_regression_3446_compound_keys\", vec![])\n}\n\n#[test]\nfn print_schema_several_keys_with_compound_key() {\n    test_print_schema(\"print_schema_several_keys_with_compound_key\", vec![])\n}\n\n// some mysql versions concert quoted table names to lowercase\n// anyway\n#[cfg(any(feature = \"postgres\", feature = \"sqlite\"))]\n#[test]\nfn print_schema_quoted_table_name() {\n    test_print_schema(\"print_schema_quoted_table_name\", vec![])\n}\n\n#[cfg(feature = \"postgres\")]\n#[test]\nfn print_schema_quoted_schema_and_table_name() {\n    test_print_schema(\n        \"print_schema_quoted_schema_and_table_name\",\n        vec![\"--schema\", \"CustomSchema\"],\n    )\n}\n\n#[cfg(feature = \"postgres\")]\n#[test]\nfn print_schema_citext() {\n    test_print_schema(\"print_schema_citext\", vec![])\n}\n\n#[test]\nfn print_schema_with_multiple_schema() {\n    test_multiple_print_schema(\n        \"print_schema_with_multiple_schema\",\n        vec![\n            \"--schema-key\",\n            \"default\",\n            \"--schema-key\",\n            \"user1\",\n            \"-o\",\n            \"users1\",\n            \"--with-docs\",\n            \"--schema-key\",\n            \"user2\",\n            \"-o\",\n            \"users2\",\n            \"--with-docs\",\n        ],\n    )\n}\n\n#[cfg(feature = \"sqlite\")]\nconst BACKEND: &str = \"sqlite\";\n#[cfg(feature = \"postgres\")]\nconst BACKEND: &str = \"postgres\";\n#[cfg(feature = \"mysql\")]\nconst BACKEND: &str = \"mysql\";\n\nfn backend_file_path(test_name: &str, file: &str) -> PathBuf {\n    Path::new(env!(\"CARGO_MANIFEST_DIR\"))\n        .join(\"tests\")\n        .join(\"print_schema\")\n        .join(test_name)\n        .join(BACKEND)\n        .join(file)\n}\n\nfn test_multiple_print_schema(test_name: &str, args: Vec<&str>) {\n    let test_path = Path::new(env!(\"CARGO_MANIFEST_DIR\"))\n        .join(\"tests\")\n        .join(\"print_schema\")\n        .join(test_name);\n    let p = project(test_name)\n        .file(\n            \"diesel.toml\",\n            r#\"\n            [print_schema.user1]\n            [print_schema.user2]\n            \"#,\n        )\n        .build();\n    let db = database(&p.database_url());\n\n    p.command(\"setup\").run();\n\n    let schema = read_file(&backend_file_path(test_name, \"schema.sql\"));\n    db.execute(&schema);\n\n    let result = p.command(\"print-schema\").args(args).run();\n\n    assert!(result.is_success(), \"Result was unsuccessful {:?}\", result);\n\n    let result = result.stdout().replace(\"\\r\\n\", \"\\n\");\n\n    let mut setting = insta::Settings::new();\n    setting.set_snapshot_path(backend_file_path(test_name, \"\"));\n    setting.set_omit_expression(true);\n    setting.set_description(format!(\"Test: {test_name}\"));\n    setting.set_prepend_module_to_snapshot(false);\n\n    setting.bind(|| {\n        insta::assert_snapshot!(\"expected\", result);\n        test_multiple_print_schema_config(test_name, &test_path, schema);\n    });\n}\n\nfn test_print_schema(test_name: &str, args: Vec<&str>) {\n    let test_path = Path::new(env!(\"CARGO_MANIFEST_DIR\"))\n        .join(\"tests\")\n        .join(\"print_schema\")\n        .join(test_name);\n    let p = project(test_name).build();\n    let db = database(&p.database_url());\n\n    p.command(\"setup\").run();\n\n    let schema = read_file(&backend_file_path(test_name, \"schema.sql\"));\n    db.execute(&schema);\n\n    let result = p.command(\"print-schema\").args(args).run();\n\n    assert!(result.is_success(), \"Result was unsuccessful {:?}\", result);\n\n    let result = result.stdout().replace(\"\\r\\n\", \"\\n\");\n\n    let mut setting = insta::Settings::new();\n    setting.set_snapshot_path(backend_file_path(test_name, \"\"));\n    setting.set_omit_expression(true);\n    setting.set_description(format!(\"Test: {test_name}\"));\n    setting.set_prepend_module_to_snapshot(false);\n\n    setting.bind(|| {\n        insta::assert_snapshot!(\"expected\", result);\n\n        test_print_schema_config(test_name, &test_path, schema);\n    });\n}\n\nfn test_print_schema_config(test_name: &str, test_path: &Path, schema: String) {\n    let config = read_file(&test_path.join(\"diesel.toml\"));\n    let mut p = project(&format!(\"{}_config\", test_name)).file(\"diesel.toml\", &config);\n\n    let patch_file = backend_file_path(test_name, \"schema.patch\");\n    if patch_file.exists() {\n        let patch_contents = read_file(&patch_file);\n        p = p.file(\"schema.patch\", &patch_contents);\n    }\n\n    let p = p.build();\n\n    p.command(\"setup\").run();\n    p.create_migration(\"12345_create_schema\", &schema, None, None);\n    let result = p.command(\"migration\").arg(\"run\").run();\n    assert!(result.is_success(), \"Result was unsuccessful {:?}\", result);\n\n    let schema = p.file_contents(\"src/schema.rs\").replace(\"\\r\\n\", \"\\n\");\n    insta::assert_snapshot!(\"expected\", schema);\n\n    let result = p.command(\"print-schema\").run();\n    assert!(result.is_success(), \"Result was unsuccessful {:?}\", result);\n\n    let result = result.stdout().replace(\"\\r\\n\", \"\\n\");\n\n    insta::assert_snapshot!(\"expected\", result);\n}\n\nfn test_multiple_print_schema_config(test_name: &str, test_path: &Path, schema: String) {\n    let config = read_file(&test_path.join(\"diesel.toml\"));\n    let mut p = project(&format!(\"{}_config\", test_name)).file(\"diesel.toml\", &config);\n\n    let patch_file = backend_file_path(test_name, \"schema.patch\");\n    if patch_file.exists() {\n        let patch_contents = read_file(&patch_file);\n        p = p.file(\"schema.patch\", &patch_contents);\n    }\n\n    let p = p.build();\n\n    p.command(\"setup\").run();\n    p.create_migration(\"12345_create_schema\", &schema, None, None);\n    let result = p.command(\"migration\").arg(\"run\").run();\n    assert!(result.is_success(), \"Result was unsuccessful {:?}\", result);\n\n    let schema = p.file_contents(\"src/schema1.rs\").replace(\"\\r\\n\", \"\\n\");\n    insta::assert_snapshot!(\"expected_1\", schema);\n    let schema = p.file_contents(\"src/schema2.rs\").replace(\"\\r\\n\", \"\\n\");\n    insta::assert_snapshot!(\"expected_2\", schema);\n\n    let result = p.command(\"print-schema\").run();\n    assert!(result.is_success(), \"Result was unsuccessful {:?}\", result);\n\n    let result = result.stdout().replace(\"\\r\\n\", \"\\n\");\n    insta::assert_snapshot!(\"expected\", result);\n}\n\nfn read_file(path: &Path) -> String {\n    let mut file = File::open(path).expect(&format!(\"Could not open {}\", path.display()));\n    let mut string = String::new();\n    file.read_to_string(&mut string).unwrap();\n    string\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "11920d92bfc6aa379728ddac3e11b163e584018a",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/diesel_cli/tests/support/database.rs",
    "func": "// This file only exists so rustfmt can find it. The path to this module is always overridden by a\n// cfg attr\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "a3aefc2a93797890efb65e659e6b95de05b9ce15",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/diesel_compile_tests/tests/fail/derive_deprecated/deprecated_primary_key.rs",
    "func": "#[macro_use]\nextern crate diesel;\n\ntable! {\n    users {\n        id -> Integer,\n        name -> Text,\n    }\n}\n\n#[derive(AsChangeset)]\n#[primary_key(id, bar = \"baz\")]\nstruct UserForm1 {\n    id: i32,\n    name: String,\n}\n\n#[derive(AsChangeset)]\n#[primary_key(id, qux(id))]\nstruct UserForm2 {\n    id: i32,\n    name: String,\n}\n\n#[derive(AsChangeset)]\n#[primary_key]\nstruct UserForm3 {\n    id: i32,\n    name: String,\n}\n\n#[derive(AsChangeset)]\n#[primary_key = id]\nstruct UserForm4 {\n    id: i32,\n    name: String,\n}\n\n#[derive(AsChangeset)]\n#[diesel(table_name = users)]\n#[primary_key(id, name)]\nstruct UserForm5 {\n    id: i32,\n    name: String,\n}\n\nfn main() {}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "e6613e95c86b5fa8fe090dee8fca1650d37baade",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/diesel/src/result.rs",
    "func": "//! Errors, type aliases, and functions related to working with `Result`.\n\nuse std::error::Error as StdError;\nuse std::ffi::NulError;\nuse std::fmt::{self, Display};\n\n#[derive(Debug)]\n#[allow(clippy::enum_variant_names)]\n/// Represents all the ways that a query can fail.\n///\n/// This type is not intended to be exhaustively matched, and new variants may\n/// be added in the future without a major version bump.\n#[non_exhaustive]\npub enum Error {\n    /// The query contained a nul byte.\n    ///\n    /// This should never occur in normal usage.\n    InvalidCString(NulError),\n\n    /// The database returned an error.\n    ///\n    /// While Diesel prevents almost all sources of runtime errors at compile\n    /// time, it does not attempt to prevent 100% of them. Typically this error\n    /// will occur from insert or update statements due to a constraint\n    /// violation.\n    DatabaseError(\n        DatabaseErrorKind,\n        Box<dyn DatabaseErrorInformation + Send + Sync>,\n    ),\n\n    /// No rows were returned by a query expected to return at least one row.\n    ///\n    /// This variant is only returned by [`get_result`] and [`first`]. [`load`]\n    /// does not treat 0 rows as an error. If you would like to allow either 0\n    /// or 1 rows, call [`optional`] on the result.\n    ///\n    /// [`get_result`]: crate::query_dsl::RunQueryDsl::get_result()\n    /// [`first`]: crate::query_dsl::RunQueryDsl::first()\n    /// [`load`]: crate::query_dsl::RunQueryDsl::load()\n    /// [`optional`]: OptionalExtension::optional\n    NotFound,\n\n    /// The query could not be constructed\n    ///\n    /// An example of when this error could occur is if you are attempting to\n    /// construct an update statement with no changes (e.g. all fields on the\n    /// struct are `None`).\n    QueryBuilderError(Box<dyn StdError + Send + Sync>),\n\n    /// An error occurred deserializing the data being sent to the database.\n    ///\n    /// Typically this error means that the stated type of the query is\n    /// incorrect. An example of when this error might occur in normal usage is\n    /// attempting to deserialize an infinite date into chrono.\n    DeserializationError(Box<dyn StdError + Send + Sync>),\n\n    /// An error occurred serializing the data being sent to the database.\n    ///\n    /// An example of when this error would be returned is if you attempted to\n    /// serialize a `chrono::NaiveDate` earlier than the earliest date supported\n    /// by PostgreSQL.\n    SerializationError(Box<dyn StdError + Send + Sync>),\n\n    /// An error occurred when attempting rollback of a transaction subsequently to a failed\n    /// commit attempt.\n    ///\n    /// When a commit attempt fails and Diesel believes that it can attempt a rollback to return\n    /// the connection back in a usable state (out of that transaction), it attempts it then\n    /// returns the original error.\n    ///\n    /// If that fails, you get this.\n    RollbackErrorOnCommit {\n        /// The error that was encountered when attempting the rollback\n        rollback_error: Box<Error>,\n        /// The error that was encountered during the failed commit attempt\n        commit_error: Box<Error>,\n    },\n\n    /// Roll back the current transaction.\n    ///\n    /// You can return this variant inside of a transaction when you want to\n    /// roll it back, but have no actual error to return. Diesel will never\n    /// return this variant unless you gave it to us, and it can be safely\n    /// ignored in error handling.\n    RollbackTransaction,\n\n    /// Attempted to perform an operation that cannot be done inside a transaction\n    /// when a transaction was already open.\n    AlreadyInTransaction,\n\n    /// Attempted to perform an operation that can only be done inside a transaction\n    /// when no transaction was open\n    NotInTransaction,\n\n    /// Transaction manager broken, likely due to a broken connection. No other operations are possible.\n    BrokenTransactionManager,\n}\n\n#[derive(Debug, Clone, Copy)]\n/// The kind of database error that occurred.\n///\n/// This is not meant to exhaustively cover all possible errors, but is used to\n/// identify errors which are commonly recovered from programmatically. This enum\n/// is not intended to be exhaustively matched, and new variants may be added in\n/// the future without a major version bump.\n#[non_exhaustive]\npub enum DatabaseErrorKind {\n    /// A unique constraint was violated.\n    UniqueViolation,\n\n    /// A foreign key constraint was violated.\n    ForeignKeyViolation,\n\n    /// The query could not be sent to the database due to a protocol violation.\n    ///\n    /// An example of a case where this would occur is if you attempted to send\n    /// a query with more than 65000 bind parameters using PostgreSQL.\n    UnableToSendCommand,\n\n    /// A serializable transaction failed to commit due to a read/write\n    /// dependency on a concurrent transaction.\n    ///\n    /// Corresponds to SQLSTATE code 40001\n    ///\n    /// This error is only detected for PostgreSQL, as we do not yet support\n    /// transaction isolation levels for other backends.\n    SerializationFailure,\n\n    /// The command could not be completed because the transaction was read\n    /// only.\n    ///\n    /// This error will also be returned for `SELECT` statements which attempted\n    /// to lock the rows.\n    ReadOnlyTransaction,\n\n    /// A restrict constraint was violated.\n    RestrictViolation,\n\n    /// A not null constraint was violated.\n    NotNullViolation,\n\n    /// A check constraint was violated.\n    CheckViolation,\n\n    /// An exclusion constraint was violated.\n    ExclusionViolation,\n\n    /// The connection to the server was unexpectedly closed.\n    ///\n    /// This error is only detected for PostgreSQL and is emitted on a best-effort basis\n    /// and may be missed.\n    ClosedConnection,\n\n    #[doc(hidden)]\n    Unknown, // Match against _ instead, more variants may be added in the future\n}\n\n/// Information about an error that was returned by the database.\npub trait DatabaseErrorInformation {\n    /// The primary human-readable error message. Typically one line.\n    fn message(&self) -> &str;\n\n    /// An optional secondary error message providing more details about the\n    /// problem, if it was provided by the database. Might span multiple lines.\n    fn details(&self) -> Option<&str>;\n\n    /// An optional suggestion of what to do about the problem, if one was\n    /// provided by the database.\n    fn hint(&self) -> Option<&str>;\n\n    /// The name of the table the error was associated with, if the error was\n    /// associated with a specific table and the backend supports retrieving\n    /// that information.\n    ///\n    /// Currently this method will return `None` for all backends other than\n    /// PostgreSQL.\n    fn table_name(&self) -> Option<&str>;\n\n    /// The name of the column the error was associated with, if the error was\n    /// associated with a specific column and the backend supports retrieving\n    /// that information.\n    ///\n    /// Currently this method will return `None` for all backends other than\n    /// PostgreSQL.\n    fn column_name(&self) -> Option<&str>;\n\n    /// The constraint that was violated if this error is a constraint violation\n    /// and the backend supports retrieving that information.\n    ///\n    /// Currently this method will return `None` for all backends other than\n    /// PostgreSQL.\n    fn constraint_name(&self) -> Option<&str>;\n\n    /// An optional integer indicating an error cursor position as an index into\n    /// the original statement string.\n    fn statement_position(&self) -> Option<i32>;\n}\n\nimpl fmt::Debug for dyn DatabaseErrorInformation + Send + Sync {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        fmt::Debug::fmt(&self.message(), f)\n    }\n}\n\nimpl DatabaseErrorInformation for String {\n    fn message(&self) -> &str {\n        self\n    }\n    fn details(&self) -> Option<&str> {\n        None\n    }\n    fn hint(&self) -> Option<&str> {\n        None\n    }\n    fn table_name(&self) -> Option<&str> {\n        None\n    }\n    fn column_name(&self) -> Option<&str> {\n        None\n    }\n    fn constraint_name(&self) -> Option<&str> {\n        None\n    }\n    fn statement_position(&self) -> Option<i32> {\n        None\n    }\n}\n\n/// Errors which can occur during [`Connection::establish`]\n///\n/// [`Connection::establish`]: crate::connection::Connection::establish\n#[derive(Debug, PartialEq)]\n#[non_exhaustive]\npub enum ConnectionError {\n    /// The connection URL contained a `NUL` byte.\n    InvalidCString(NulError),\n    /// The database returned an error.\n    BadConnection(String),\n    /// The connection URL could not be parsed.\n    InvalidConnectionUrl(String),\n    /// Diesel could not configure the database connection.\n    ///\n    /// Diesel may try to automatically set session specific configuration\n    /// values, such as UTF8 encoding, or enabling the `||` operator on MySQL.\n    /// This variant is returned if an error occurred executing the query to set\n    /// those options. Diesel will never affect global configuration.\n    CouldntSetupConfiguration(Error),\n}\n\n/// A specialized result type for queries.\n///\n/// This type is exported by `diesel::prelude`, and is generally used by any\n/// code which is interacting with Diesel. This type exists to avoid writing out\n/// `diesel::result::Error`, and is otherwise a direct mapping to `Result`.\npub type QueryResult<T> = Result<T, Error>;\n\n/// A specialized result type for establishing connections.\n///\n/// This type exists to avoid writing out `diesel::result::ConnectionError`, and\n/// is otherwise a direct mapping to `Result`.\npub type ConnectionResult<T> = Result<T, ConnectionError>;\n\n/// See the [method documentation](OptionalExtension::optional).\npub trait OptionalExtension<T> {\n    /// Converts a `QueryResult<T>` into a `QueryResult<Option<T>>`.\n    ///\n    /// By default, Diesel treats 0 rows being returned from a query that is expected to return 1\n    /// row as an error (e.g. the return value of [`get_result`] or [`first`]). This method will\n    /// handle that error, and give you back an `Option<T>` instead.\n    ///\n    /// [`get_result`]: crate::query_dsl::RunQueryDsl::get_result()\n    /// [`first`]: crate::query_dsl::RunQueryDsl::first()\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// use diesel::{QueryResult, NotFound, OptionalExtension};\n    ///\n    /// let result: QueryResult<i32> = Ok(1);\n    /// assert_eq!(Ok(Some(1)), result.optional());\n    ///\n    /// let result: QueryResult<i32> = Err(NotFound);\n    /// assert_eq!(Ok(None), result.optional());\n    /// ```\n    fn optional(self) -> Result<Option<T>, Error>;\n}\n\nimpl<T> OptionalExtension<T> for QueryResult<T> {\n    fn optional(self) -> Result<Option<T>, Error> {\n        match self {\n            Ok(value) => Ok(Some(value)),\n            Err(Error::NotFound) => Ok(None),\n            Err(e) => Err(e),\n        }\n    }\n}\n\n/// See the [method documentation](OptionalEmptyChangesetExtension::optional_empty_changeset).\npub trait OptionalEmptyChangesetExtension<T> {\n    /// By default, Diesel treats an empty update as a `QueryBuilderError`. This method will\n    /// convert that error into `None`.\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// use diesel::{QueryResult, OptionalEmptyChangesetExtension, result::Error::QueryBuilderError, result::EmptyChangeset};\n    /// let result: QueryResult<i32> = Err(QueryBuilderError(Box::new(EmptyChangeset)));\n    /// assert_eq!(Ok(None), result.optional_empty_changeset());\n    /// ```\n    fn optional_empty_changeset(self) -> Result<Option<T>, Error>;\n}\n\nimpl<T> OptionalEmptyChangesetExtension<T> for QueryResult<T> {\n    fn optional_empty_changeset(self) -> Result<Option<T>, Error> {\n        match self {\n            Ok(value) => Ok(Some(value)),\n            Err(Error::QueryBuilderError(e)) if e.is::<EmptyChangeset>() => Ok(None),\n            Err(e) => Err(e),\n        }\n    }\n}\n\nimpl From<NulError> for ConnectionError {\n    fn from(e: NulError) -> Self {\n        ConnectionError::InvalidCString(e)\n    }\n}\n\nimpl From<NulError> for Error {\n    fn from(e: NulError) -> Self {\n        Error::InvalidCString(e)\n    }\n}\n\nimpl Display for Error {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match *self {\n            Error::InvalidCString(ref nul_err) => write!(f, \"{nul_err}\"),\n            Error::DatabaseError(_, ref e) => write!(f, \"{}\", e.message()),\n            Error::NotFound => f.write_str(\"Record not found\"),\n            Error::QueryBuilderError(ref e) => e.fmt(f),\n            Error::DeserializationError(ref e) => e.fmt(f),\n            Error::SerializationError(ref e) => e.fmt(f),\n            Error::RollbackErrorOnCommit {\n                ref rollback_error,\n                ref commit_error,\n            } => {\n                write!(\n                    f,\n                    \"Transaction rollback failed: {} \\\n                        (rollback attempted because of failure to commit: {})\",\n                    &**rollback_error, &**commit_error\n                )?;\n                Ok(())\n            }\n            Error::RollbackTransaction => {\n                write!(f, \"You have asked diesel to rollback the transaction\")\n            }\n            Error::BrokenTransactionManager => write!(f, \"The transaction manager is broken\"),\n            Error::AlreadyInTransaction => write!(\n                f,\n                \"Cannot perform this operation while a transaction is open\",\n            ),\n            Error::NotInTransaction => {\n                write!(f, \"Cannot perform this operation outside of a transaction\",)\n            }\n        }\n    }\n}\n\nimpl StdError for Error {\n    fn cause(&self) -> Option<&dyn StdError> {\n        match *self {\n            Error::InvalidCString(ref e) => Some(e),\n            Error::QueryBuilderError(ref e) => Some(&**e),\n            Error::DeserializationError(ref e) => Some(&**e),\n            Error::SerializationError(ref e) => Some(&**e),\n            _ => None,\n        }\n    }\n}\n\nimpl Display for ConnectionError {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match *self {\n            ConnectionError::InvalidCString(ref nul_err) => nul_err.fmt(f),\n            ConnectionError::BadConnection(ref s) => write!(f, \"{s}\"),\n            ConnectionError::InvalidConnectionUrl(ref s) => write!(f, \"{s}\"),\n            ConnectionError::CouldntSetupConfiguration(ref e) => e.fmt(f),\n        }\n    }\n}\n\nimpl StdError for ConnectionError {\n    fn cause(&self) -> Option<&dyn StdError> {\n        match *self {\n            ConnectionError::InvalidCString(ref e) => Some(e),\n            ConnectionError::CouldntSetupConfiguration(ref e) => Some(e),\n            _ => None,\n        }\n    }\n}\n\nimpl PartialEq for Error {\n    fn eq(&self, other: &Error) -> bool {\n        match (self, other) {\n            (Error::InvalidCString(a), Error::InvalidCString(b)) => a == b,\n            (Error::DatabaseError(_, a), Error::DatabaseError(_, b)) => a.message() == b.message(),\n            (&Error::NotFound, &Error::NotFound) => true,\n            (&Error::RollbackTransaction, &Error::RollbackTransaction) => true,\n            (&Error::AlreadyInTransaction, &Error::AlreadyInTransaction) => true,\n            _ => false,\n        }\n    }\n}\n\n#[cfg(test)]\n#[allow(warnings)]\nfn error_impls_send() {\n    let err: Error = unimplemented!();\n    let x: &dyn Send = &err;\n}\n\n/// An unexpected `NULL` was encountered during deserialization\n#[derive(Debug, Clone, Copy)]\npub struct UnexpectedNullError;\n\nimpl fmt::Display for UnexpectedNullError {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(f, \"Unexpected null for non-null column\")\n    }\n}\n\nimpl StdError for UnexpectedNullError {}\n\n/// Expected more fields then present in the current row while deserializing results\n#[derive(Debug, Clone, Copy)]\npub struct UnexpectedEndOfRow;\n\nimpl fmt::Display for UnexpectedEndOfRow {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(f, \"Unexpected end of row\")\n    }\n}\n\nimpl StdError for UnexpectedEndOfRow {}\n\n/// Expected when an update has no changes to save.\n///\n/// When using `optional_empty_changeset`, this error is turned into `None`.\n#[derive(Debug, Clone, Copy)]\npub struct EmptyChangeset;\n\nimpl fmt::Display for EmptyChangeset {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(\n            f,\n            \"There are no changes to save. This query cannot be built\"\n        )\n    }\n}\n\nimpl StdError for EmptyChangeset {}\n\n/// Expected when you try to execute an empty query\n#[derive(Debug, Clone, Copy)]\npub struct EmptyQuery;\n\nimpl fmt::Display for EmptyQuery {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(\n            f,\n            \"Detected an empty query. These are not supported by your database system\"\n        )\n    }\n}\n\nimpl StdError for EmptyQuery {}\n\n/// An error occurred while deserializing a field\n#[derive(Debug)]\n#[non_exhaustive]\npub struct DeserializeFieldError {\n    /// The name of the field that failed to deserialize\n    pub field_name: Option<String>,\n    /// The error that occurred while deserializing the field\n    pub error: Box<dyn StdError + Send + Sync>,\n}\n\nimpl DeserializeFieldError {\n    #[cold]\n    pub(crate) fn new<'a, F, DB>(field: F, error: Box<dyn std::error::Error + Send + Sync>) -> Self\n    where\n        DB: crate::backend::Backend,\n        F: crate::row::Field<'a, DB>,\n    {\n        DeserializeFieldError {\n            field_name: field.field_name().map(|s| s.to_string()),\n            error,\n        }\n    }\n}\n\nimpl StdError for DeserializeFieldError {\n    fn source(&self) -> Option<&(dyn StdError + 'static)> {\n        Some(&*self.error)\n    }\n}\n\nimpl fmt::Display for DeserializeFieldError {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        if let Some(ref field_name) = self.field_name {\n            write!(\n                f,\n                \"Error deserializing field '{}': {}\",\n                field_name, self.error\n            )\n        } else {\n            write!(f, \"Error deserializing field: {}\", self.error)\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "4f519b72561196a27431c33426b5e2e57da21ebd",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/diesel/src/serialize.rs",
    "func": "//! Types and traits related to serializing values for the database\n\nuse std::error::Error;\nuse std::fmt;\nuse std::io::{self, Write};\nuse std::result;\n\nuse crate::backend::Backend;\nuse crate::query_builder::bind_collector::RawBytesBindCollector;\nuse crate::query_builder::BindCollector;\n\n#[doc(inline)]\n#[cfg(feature = \"postgres_backend\")]\npub use crate::pg::serialize::WriteTuple;\n\n/// A specialized result type representing the result of serializing\n/// a value for the database.\npub type Result = result::Result<IsNull, Box<dyn Error + Send + Sync>>;\n\n#[derive(Debug, Copy, Clone, PartialEq, Eq)]\n/// Tiny enum to make the return type of `ToSql` more descriptive\npub enum IsNull {\n    /// No data was written, as this type is null\n    Yes,\n    /// The value is not null\n    ///\n    /// This does not necessarily mean that any data was written to the buffer.\n    /// For example, an empty string has no data to be sent over the wire, but\n    /// also is not null.\n    No,\n}\n\n/// Wraps a buffer to be written by `ToSql` with additional backend specific\n/// utilities.\npub struct Output<'a, 'b, DB>\nwhere\n    DB: Backend,\n    DB::MetadataLookup: 'a,\n{\n    out: <DB::BindCollector<'a> as BindCollector<'a, DB>>::Buffer,\n    metadata_lookup: Option<&'b mut DB::MetadataLookup>,\n}\n\nimpl<'a, 'b, DB: Backend> Output<'a, 'b, DB> {\n    /// Construct a new `Output`\n    pub fn new(\n        out: <DB::BindCollector<'a> as BindCollector<'a, DB>>::Buffer,\n        metadata_lookup: &'b mut DB::MetadataLookup,\n    ) -> Self {\n        Output {\n            out,\n            metadata_lookup: Some(metadata_lookup),\n        }\n    }\n\n    /// Consume the current `Output` structure to access the inner buffer type\n    ///\n    /// This function is only useful for people implementing their own Backend.\n    pub fn into_inner(self) -> <DB::BindCollector<'a> as BindCollector<'a, DB>>::Buffer {\n        self.out\n    }\n\n    /// Returns the backend's mechanism for dynamically looking up type\n    /// metadata at runtime, if relevant for the given backend.\n    pub fn metadata_lookup(&mut self) -> &mut DB::MetadataLookup {\n        self.metadata_lookup.as_mut().expect(\"Lookup is there\")\n    }\n\n    /// Set the inner buffer to a specific value\n    ///\n    /// Checkout the documentation of the type of `BindCollector::Buffer`\n    /// for your specific backend for supported types.\n    pub fn set_value<V>(&mut self, value: V)\n    where\n        V: Into<<DB::BindCollector<'a> as BindCollector<'a, DB>>::Buffer>,\n    {\n        self.out = value.into();\n    }\n}\n\n#[cfg(test)]\nimpl<'a, DB: Backend> Output<'a, 'static, DB> {\n    /// Returns a `Output` suitable for testing `ToSql` implementations.\n    /// Unsafe to use for testing types which perform dynamic metadata lookup.\n    pub fn test(buffer: <DB::BindCollector<'a> as BindCollector<'a, DB>>::Buffer) -> Self {\n        Self {\n            out: buffer,\n            metadata_lookup: None,\n        }\n    }\n}\n\nimpl<DB> Write for Output<'_, '_, DB>\nwhere\n    for<'c> DB: Backend<BindCollector<'c> = RawBytesBindCollector<DB>>,\n{\n    fn write(&mut self, buf: &[u8]) -> io::Result<usize> {\n        self.out.0.write(buf)\n    }\n\n    fn flush(&mut self) -> io::Result<()> {\n        self.out.0.flush()\n    }\n\n    fn write_all(&mut self, buf: &[u8]) -> io::Result<()> {\n        self.out.0.write_all(buf)\n    }\n\n    fn write_fmt(&mut self, fmt: fmt::Arguments<'_>) -> io::Result<()> {\n        self.out.0.write_fmt(fmt)\n    }\n}\n\nimpl<'a, DB> Output<'a, '_, DB>\nwhere\n    for<'c> DB: Backend<BindCollector<'c> = RawBytesBindCollector<DB>>,\n{\n    /// Call this method whenever you pass an instance of `Output<DB>` by value.\n    ///\n    /// Effectively copies `self`, with a narrower lifetime. When passing a\n    /// reference or a mutable reference, this is normally done by rust\n    /// implicitly. This is why you can pass `&mut Foo` to multiple functions,\n    /// even though mutable references are not `Copy`. However, this is only\n    /// done implicitly for references. For structs with lifetimes it must be\n    /// done explicitly. This method matches the semantics of what Rust would do\n    /// implicitly if you were passing a mutable reference\n    pub fn reborrow<'c>(&'c mut self) -> Output<'c, 'c, DB>\n    where\n        'a: 'c,\n    {\n        Output {\n            out: RawBytesBindCollector::<DB>::reborrow_buffer(&mut self.out),\n            metadata_lookup: match &mut self.metadata_lookup {\n                None => None,\n                Some(m) => Some(&mut **m),\n            },\n        }\n    }\n}\n\nimpl<'a, DB> fmt::Debug for Output<'a, '_, DB>\nwhere\n    <DB::BindCollector<'a> as BindCollector<'a, DB>>::Buffer: fmt::Debug,\n    DB: Backend,\n{\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        self.out.fmt(f)\n    }\n}\n\n/// Serializes a single value to be sent to the database.\n///\n/// The output is sent as a bind parameter, and the data must be written in the\n/// expected format for the given backend.\n///\n/// When possible, implementations of this trait should prefer using an existing\n/// implementation, rather than writing to `out` directly. (For example, if you\n/// are implementing this for an enum, which is represented as an integer in the\n/// database, you should use `i32::to_sql(x, out)` instead of writing to `out`\n/// yourself.)\n///\n/// Any types which implement this trait should also\n/// [`#[derive(AsExpression)]`](derive@crate::expression::AsExpression).\n///\n/// ### Backend specific details\n///\n/// - For PostgreSQL, the bytes will be sent using the binary protocol, not text.\n/// - For SQLite, all implementations should be written in terms of an existing\n///   `ToSql` implementation.\n/// - For MySQL, the expected bytes will depend on the return value of\n///   `type_metadata` for the given SQL type. See [`MysqlType`] for details.\n/// - For third party backends, consult that backend's documentation.\n///\n/// [`MysqlType`]: ../mysql/enum.MysqlType.html\n///\n/// ### Examples\n///\n/// Most implementations of this trait will be defined in terms of an existing\n/// implementation.\n///\n/// ```rust\n/// # use diesel::backend::Backend;\n/// # use diesel::expression::AsExpression;\n/// # use diesel::sql_types::*;\n/// # use diesel::serialize::{self, ToSql, Output};\n/// # use std::io::Write;\n/// #\n/// #[repr(i32)]\n/// #[derive(Debug, Clone, Copy, AsExpression)]\n/// #[diesel(sql_type = Integer)]\n/// pub enum MyEnum {\n///     A = 1,\n///     B = 2,\n/// }\n///\n/// impl<DB> ToSql<Integer, DB> for MyEnum\n/// where\n///     DB: Backend,\n///     i32: ToSql<Integer, DB>,\n/// {\n///     fn to_sql<'b>(&'b self, out: &mut Output<'b, '_, DB>) -> serialize::Result {\n///         match self {\n///             MyEnum::A => 1.to_sql(out),\n///             MyEnum::B => 2.to_sql(out),\n///         }\n///     }\n/// }\n/// ```\n///\n/// Example of creating a custom type mapping based on a MySQL [enum type](https://dev.mysql.com/doc/refman/8.0/en/enum.html)\n///\n/// This is designed to reuse the SQL type definition generated by diesel-cli\n///\n/// ```rust\n/// # use diesel::backend::Backend;\n/// # use diesel::expression::AsExpression;\n/// # use diesel::sql_types::*;\n/// # use diesel::serialize::{self, ToSql, Output, IsNull};\n/// # use std::io::Write;\n/// #\n/// pub mod sql_types {\n///    #[derive(diesel::sql_types::SqlType)]\n///    #[diesel(mysql_type(name = \"Enum\"))]\n///    pub struct PostEnum; //<- generated by diesel cli\n/// }\n/// #[derive(Debug, AsExpression, PartialEq, Clone)]\n/// #[diesel(sql_type = sql_types::PostEnum)]\n/// pub enum Post {\n///    FirstValue,\n///    SecondValue,\n/// }\n///\n/// # #[cfg(feature = \"mysql\")]\n/// impl ToSql<sql_types::PostEnum, diesel::mysql::Mysql> for Post {\n///    fn to_sql<'b>(&'b self, out: &mut Output<'b, '_, diesel::mysql::Mysql>) -> serialize::Result {\n///        match *self {\n///            // these string values need to match the labels used in your\n///            // enum definition in SQL. So this expects that you defined the\n///            /// relevant enum type as`ENUM('one', 'two')` in your `CREATE TABLE` statement\n///            Post::FirstValue => out.write_all(b\"one\")?,\n///            Post::SecondValue => out.write_all(b\"two\")?,\n///        }\n///        Ok(IsNull::No)\n///    }\n/// }\n/// ```\n///\n/// Using temporary values as part of the `ToSql` implementation requires additional\n/// work.\n///\n/// Backends using [`RawBytesBindCollector`] as [`BindCollector`] copy the serialized values as part\n/// of `Write` implementation. This includes the `Mysql` and the `Pg` backend provided by diesel.\n/// This means existing `ToSql` implementations can be used even with\n/// temporary values. For these it is required to call\n/// [`Output::reborrow`] to shorten the lifetime of the `Output` type correspondingly.\n///\n/// ```\n/// # use diesel::backend::Backend;\n/// # use diesel::expression::AsExpression;\n/// # use diesel::sql_types::*;\n/// # use diesel::serialize::{self, ToSql, Output};\n/// # use std::io::Write;\n/// #\n/// #[repr(i32)]\n/// #[derive(Debug, Clone, Copy, AsExpression)]\n/// #[diesel(sql_type = Integer)]\n/// pub enum MyEnum {\n///     A = 1,\n///     B = 2,\n/// }\n///\n/// # #[cfg(feature = \"postgres\")]\n/// impl ToSql<Integer, diesel::pg::Pg> for MyEnum\n/// where\n///     i32: ToSql<Integer, diesel::pg::Pg>,\n/// {\n///     fn to_sql<'b>(&'b self, out: &mut Output<'b, '_, diesel::pg::Pg>) -> serialize::Result {\n///         let v = *self as i32;\n///         <i32 as ToSql<Integer, diesel::pg::Pg>>::to_sql(&v, &mut out.reborrow())\n///     }\n/// }\n/// ````\n///\n/// For any other backend the [`Output::set_value`] method provides a way to\n/// set the output value directly. Checkout the documentation of the corresponding\n/// `BindCollector::Buffer` type for provided `From<T>` implementations for a list\n/// of accepted types. For the `Sqlite` backend see `SqliteBindValue`.\n///\n/// ```\n/// # use diesel::backend::Backend;\n/// # use diesel::expression::AsExpression;\n/// # use diesel::sql_types::*;\n/// # use diesel::serialize::{self, ToSql, Output, IsNull};\n/// # use std::io::Write;\n/// #\n/// #[repr(i32)]\n/// #[derive(Debug, Clone, Copy, AsExpression)]\n/// #[diesel(sql_type = Integer)]\n/// pub enum MyEnum {\n///     A = 1,\n///     B = 2,\n/// }\n///\n/// # #[cfg(feature = \"sqlite\")]\n/// impl ToSql<Integer, diesel::sqlite::Sqlite> for MyEnum\n/// where\n///     i32: ToSql<Integer, diesel::sqlite::Sqlite>,\n/// {\n///     fn to_sql<'b>(&'b self, out: &mut Output<'b, '_, diesel::sqlite::Sqlite>) -> serialize::Result {\n///         out.set_value(*self as i32);\n///         Ok(IsNull::No)\n///     }\n/// }\n/// ````\npub trait ToSql<A, DB: Backend>: fmt::Debug {\n    /// See the trait documentation.\n    fn to_sql<'b>(&'b self, out: &mut Output<'b, '_, DB>) -> Result;\n}\n\nimpl<A, T, DB> ToSql<A, DB> for &T\nwhere\n    DB: Backend,\n    T: ToSql<A, DB> + ?Sized,\n{\n    fn to_sql<'b>(&'b self, out: &mut Output<'b, '_, DB>) -> Result {\n        (*self).to_sql(out)\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "4292828aa75729c49072e2cf4c4d45ec9386dd14",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/diesel/src/pg/types/mac_addr_8.rs",
    "func": "use std::io::prelude::*;\n\nuse super::sql_types::MacAddr8;\nuse crate::deserialize::{self, FromSql};\nuse crate::pg::{Pg, PgValue};\nuse crate::serialize::{self, IsNull, Output, ToSql};\n\n#[allow(dead_code)]\nmod foreign_derives {\n    use super::*;\n    use crate::deserialize::FromSqlRow;\n    use crate::expression::AsExpression;\n\n    #[derive(AsExpression, FromSqlRow)]\n    #[diesel(foreign_derive)]\n    #[diesel(sql_type = MacAddr8)]\n    struct ByteArrayProxy([u8; 8]);\n}\n\n#[cfg(feature = \"postgres_backend\")]\nimpl FromSql<MacAddr8, Pg> for [u8; 8] {\n    fn from_sql(value: PgValue<'_>) -> deserialize::Result<Self> {\n        value\n            .as_bytes()\n            .try_into()\n            .map_err(|_| \"invalid network address format: input isn't 8 bytes.\".into())\n    }\n}\n\n#[cfg(feature = \"postgres_backend\")]\nimpl ToSql<MacAddr8, Pg> for [u8; 8] {\n    fn to_sql<'b>(&'b self, out: &mut Output<'b, '_, Pg>) -> serialize::Result {\n        out.write_all(&self[..])\n            .map(|_| IsNull::No)\n            .map_err(Into::into)\n    }\n}\n\n#[test]\nfn macaddr8_roundtrip() {\n    use crate::query_builder::bind_collector::ByteWrapper;\n\n    let mut buffer = Vec::new();\n    let mut bytes = Output::test(ByteWrapper(&mut buffer));\n    let input_address = [0x52, 0x54, 0x00, 0xfb, 0xc6, 0x16, 0x17, 0xFF];\n    ToSql::<MacAddr8, Pg>::to_sql(&input_address, &mut bytes).unwrap();\n    let output_address: [u8; 8] = FromSql::from_sql(PgValue::for_test(&buffer)).unwrap();\n    assert_eq!(input_address, output_address);\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "9627fda8d27e10061ae7774bf492a3751e2ea2fe",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/diesel/src/query_source/aliasing/mod.rs",
    "func": "//! Everything related to table aliasing\n//!\n//! See [`alias!`](crate::alias!) for more details\n\nmod alias;\nmod aliased_field;\nmod dsl_impls;\nmod field_alias_mapper;\nmod joins;\nmod macros;\n\n// This is reexported from the parent module\n#[allow(unreachable_pub)]\npub use alias::Alias;\n// This is reexported from the parent module\n#[allow(unreachable_pub)]\n#[doc(hidden)] // This is used by the table macro\npub use alias::{\n    AliasAliasAppearsInFromClause, AliasAliasAppearsInFromClauseSameTable, AliasAppearsInFromClause,\n};\n#[allow(unreachable_pub)]\npub use aliased_field::AliasedField;\n#[allow(unreachable_pub)]\n#[doc(hidden)] // This is used by the table macro\npub use field_alias_mapper::{FieldAliasMapper, FieldAliasMapperAssociatedTypesDisjointnessTrick};\n\npub(crate) use alias::GetAliasSourceFromAlias;\n\n/// Types created by the `alias!` macro that serve to distinguish between aliases implement\n/// this trait.\n///\n/// In order to be able to implement within diesel a lot of traits on what will represent the alias,\n/// we cannot use directly that new type within the query builder. Instead, we will use `Alias<S>`,\n/// where `S: AliasSource`.\n///\n/// This trait should never be implemented by an end-user directly.\npub trait AliasSource {\n    /// The name of this alias in the query\n    const NAME: &'static str;\n    /// The table the alias maps to\n    type Target;\n    /// Obtain the table from the source\n    ///\n    /// (used by Diesel to implement some traits)\n    fn target(&self) -> &Self::Target;\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "57ea09775558e97275ded971e0ff6e1f183ffabb",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/diesel/src/mysql/connection/bind.rs",
    "func": "#![allow(unsafe_code)] // module uses ffi\nuse mysqlclient_sys as ffi;\nuse std::mem;\nuse std::mem::MaybeUninit;\nuse std::ops::Index;\nuse std::os::raw as libc;\nuse std::ptr::NonNull;\n\nuse super::stmt::{MysqlFieldMetadata, StatementUse};\nuse crate::mysql::connection::stmt::StatementMetadata;\nuse crate::mysql::types::date_and_time::MysqlTime;\nuse crate::mysql::{MysqlType, MysqlValue};\nuse crate::result::QueryResult;\n\npub(super) struct PreparedStatementBinds(Binds);\n\npub(super) struct OutputBinds(Binds);\n\nimpl Clone for OutputBinds {\n    fn clone(&self) -> Self {\n        Self(Binds {\n            data: self.0.data.clone(),\n        })\n    }\n}\n\nstruct Binds {\n    data: Vec<BindData>,\n}\n\nimpl PreparedStatementBinds {\n    pub(super) fn from_input_data<Iter>(input: Iter) -> Self\n    where\n        Iter: IntoIterator<Item = (MysqlType, Option<Vec<u8>>)>,\n    {\n        let data = input\n            .into_iter()\n            .map(BindData::for_input)\n            .collect::<Vec<_>>();\n\n        Self(Binds { data })\n    }\n\n    pub(super) fn with_mysql_binds<F, T>(&mut self, f: F) -> T\n    where\n        F: FnOnce(*mut ffi::MYSQL_BIND) -> T,\n    {\n        self.0.with_mysql_binds(f)\n    }\n}\n\nimpl OutputBinds {\n    pub(super) fn from_output_types(\n        types: &[Option<MysqlType>],\n        metadata: &StatementMetadata,\n    ) -> Self {\n        let data = metadata\n            .fields()\n            .iter()\n            .zip(types.iter().copied().chain(std::iter::repeat(None)))\n            .map(|(field, tpe)| BindData::for_output(tpe, field))\n            .collect();\n\n        Self(Binds { data })\n    }\n\n    pub(super) fn populate_dynamic_buffers(&mut self, stmt: &StatementUse<'_>) -> QueryResult<()> {\n        for (i, data) in self.0.data.iter_mut().enumerate() {\n            data.did_numeric_overflow_occur()?;\n            // This is safe because we are re-binding the invalidated buffers\n            // at the end of this function\n            unsafe {\n                if let Some((mut bind, offset)) = data.bind_for_truncated_data() {\n                    stmt.fetch_column(&mut bind, i, offset)?\n                } else {\n                    data.update_buffer_length()\n                }\n            }\n        }\n\n        unsafe { self.with_mysql_binds(|bind_ptr| stmt.bind_result(bind_ptr)) }\n    }\n\n    pub(super) fn update_buffer_lengths(&mut self) {\n        for data in &mut self.0.data {\n            data.update_buffer_length();\n        }\n    }\n\n    pub(super) fn with_mysql_binds<F, T>(&mut self, f: F) -> T\n    where\n        F: FnOnce(*mut ffi::MYSQL_BIND) -> T,\n    {\n        self.0.with_mysql_binds(f)\n    }\n}\n\nimpl Binds {\n    fn with_mysql_binds<F, T>(&mut self, f: F) -> T\n    where\n        F: FnOnce(*mut ffi::MYSQL_BIND) -> T,\n    {\n        let mut binds = self\n            .data\n            .iter_mut()\n            .map(|x| unsafe { x.mysql_bind() })\n            .collect::<Vec<_>>();\n        f(binds.as_mut_ptr())\n    }\n}\n\nimpl Index<usize> for OutputBinds {\n    type Output = BindData;\n    fn index(&self, index: usize) -> &Self::Output {\n        &self.0.data[index]\n    }\n}\n\nbitflags::bitflags! {\n    #[derive(Clone, Copy, Debug)]\n    pub(crate) struct Flags: u32 {\n        const NOT_NULL_FLAG = 1;\n        const PRI_KEY_FLAG = 2;\n        const UNIQUE_KEY_FLAG = 4;\n        const MULTIPLE_KEY_FLAG = 8;\n        const BLOB_FLAG = 16;\n        const UNSIGNED_FLAG = 32;\n        const ZEROFILL_FLAG = 64;\n        const BINARY_FLAG = 128;\n        const ENUM_FLAG = 256;\n        const AUTO_INCREMENT_FLAG = 512;\n        const TIMESTAMP_FLAG = 1024;\n        const SET_FLAG = 2048;\n        const NO_DEFAULT_VALUE_FLAG = 4096;\n        const ON_UPDATE_NOW_FLAG = 8192;\n        const NUM_FLAG = 32768;\n        const PART_KEY_FLAG = 16384;\n        const GROUP_FLAG = 32768;\n        const UNIQUE_FLAG = 65536;\n        const BINCMP_FLAG = 130_172;\n        const GET_FIXED_FIELDS_FLAG = (1<<18);\n        const FIELD_IN_PART_FUNC_FLAG = (1 << 19);\n    }\n}\n\nimpl From<u32> for Flags {\n    fn from(flags: u32) -> Self {\n        Flags::from_bits(flags).expect(\n            \"We encountered an unknown type flag while parsing \\\n             Mysql's type information. If you see this error message \\\n             please open an issue at diesels github page.\",\n        )\n    }\n}\n\n#[derive(Debug)]\npub(super) struct BindData {\n    tpe: ffi::enum_field_types,\n    bytes: Option<NonNull<u8>>,\n    length: libc::c_ulong,\n    capacity: usize,\n    flags: Flags,\n    is_null: ffi::my_bool,\n    is_truncated: Option<ffi::my_bool>,\n}\n\n// We need to write a manual clone impl\n// as we need to clone the underlying buffer\n// instead of just copying the pointer\nimpl Clone for BindData {\n    fn clone(&self) -> Self {\n        let (ptr, len, capacity) = if let Some(ptr) = self.bytes {\n            let slice = unsafe {\n                // We know that this points to a slice and the pointer is not null at this\n                // location\n                // The length pointer is valid as long as none missuses `bind_for_truncated_data`\n                // as this is the only location that updates the length field before the corresponding data are\n                // written. At the time of writing this comment, the `BindData::bind_for_truncated_data`\n                // function is only called by `Binds::populate_dynamic_buffers` which ensures the corresponding\n                // invariant.\n                std::slice::from_raw_parts(\n                    ptr.as_ptr(),\n                    self.length.try_into().expect(\"usize is at least 32bit\"),\n                )\n            };\n            let mut vec = slice.to_owned();\n            let ptr = NonNull::new(vec.as_mut_ptr());\n            let len = vec.len() as libc::c_ulong;\n            let capacity = vec.capacity();\n            mem::forget(vec);\n            (ptr, len, capacity)\n        } else {\n            (None, 0, 0)\n        };\n        Self {\n            tpe: self.tpe,\n            bytes: ptr,\n            length: len,\n            capacity,\n            flags: self.flags,\n            is_null: self.is_null,\n            is_truncated: self.is_truncated,\n        }\n    }\n}\n\nimpl Drop for BindData {\n    fn drop(&mut self) {\n        if let Some(bytes) = self.bytes {\n            std::mem::drop(unsafe {\n                // We know that this buffer was allocated by a vector, so constructing a vector from it is fine\n                // We know the correct capacity here\n                // We use 0 as length to prevent situations where the length is already updated but\n                // no date are already written as we could touch uninitialized memory otherwise\n                // Using 0 as length is fine as we don't need to call drop for `u8`\n                // (as there is no drop impl for primitive types)\n                Vec::from_raw_parts(bytes.as_ptr(), 0, self.capacity)\n            });\n            self.bytes = None;\n        }\n    }\n}\n\nimpl BindData {\n    fn for_input((tpe, data): (MysqlType, Option<Vec<u8>>)) -> Self {\n        let (tpe, flags) = tpe.into();\n        let is_null = ffi::my_bool::from(data.is_none());\n        let mut bytes = data.unwrap_or_default();\n        let ptr = NonNull::new(bytes.as_mut_ptr());\n        let len = bytes.len() as libc::c_ulong;\n        let capacity = bytes.capacity();\n        mem::forget(bytes);\n        Self {\n            tpe,\n            bytes: ptr,\n            length: len,\n            capacity,\n            flags,\n            is_null,\n            is_truncated: None,\n        }\n    }\n\n    fn for_output(tpe: Option<MysqlType>, metadata: &MysqlFieldMetadata<'_>) -> Self {\n        let (tpe, flags) = if let Some(tpe) = tpe {\n            match (tpe, metadata.field_type()) {\n                // Those are types where we handle the conversion in diesel itself\n                // and do not relay on libmysqlclient\n                (MysqlType::Tiny, ffi::enum_field_types::MYSQL_TYPE_DECIMAL)\n                | (MysqlType::Tiny, ffi::enum_field_types::MYSQL_TYPE_TINY)\n                | (MysqlType::Tiny, ffi::enum_field_types::MYSQL_TYPE_SHORT)\n                | (MysqlType::Tiny, ffi::enum_field_types::MYSQL_TYPE_LONG)\n                | (MysqlType::Tiny, ffi::enum_field_types::MYSQL_TYPE_FLOAT)\n                | (MysqlType::Tiny, ffi::enum_field_types::MYSQL_TYPE_DOUBLE)\n                | (MysqlType::Tiny, ffi::enum_field_types::MYSQL_TYPE_INT24)\n                | (MysqlType::Tiny, ffi::enum_field_types::MYSQL_TYPE_NEWDECIMAL)\n                | (MysqlType::Tiny, ffi::enum_field_types::MYSQL_TYPE_LONGLONG)\n                | (MysqlType::UnsignedTiny, ffi::enum_field_types::MYSQL_TYPE_DECIMAL)\n                | (MysqlType::UnsignedTiny, ffi::enum_field_types::MYSQL_TYPE_TINY)\n                | (MysqlType::UnsignedTiny, ffi::enum_field_types::MYSQL_TYPE_SHORT)\n                | (MysqlType::UnsignedTiny, ffi::enum_field_types::MYSQL_TYPE_LONG)\n                | (MysqlType::UnsignedTiny, ffi::enum_field_types::MYSQL_TYPE_FLOAT)\n                | (MysqlType::UnsignedTiny, ffi::enum_field_types::MYSQL_TYPE_DOUBLE)\n                | (MysqlType::UnsignedTiny, ffi::enum_field_types::MYSQL_TYPE_INT24)\n                | (MysqlType::UnsignedTiny, ffi::enum_field_types::MYSQL_TYPE_NEWDECIMAL)\n                | (MysqlType::UnsignedTiny, ffi::enum_field_types::MYSQL_TYPE_LONGLONG)\n                | (MysqlType::Short, ffi::enum_field_types::MYSQL_TYPE_DECIMAL)\n                | (MysqlType::Short, ffi::enum_field_types::MYSQL_TYPE_TINY)\n                | (MysqlType::Short, ffi::enum_field_types::MYSQL_TYPE_SHORT)\n                | (MysqlType::Short, ffi::enum_field_types::MYSQL_TYPE_LONG)\n                | (MysqlType::Short, ffi::enum_field_types::MYSQL_TYPE_FLOAT)\n                | (MysqlType::Short, ffi::enum_field_types::MYSQL_TYPE_DOUBLE)\n                | (MysqlType::Short, ffi::enum_field_types::MYSQL_TYPE_INT24)\n                | (MysqlType::Short, ffi::enum_field_types::MYSQL_TYPE_NEWDECIMAL)\n                | (MysqlType::Short, ffi::enum_field_types::MYSQL_TYPE_LONGLONG)\n                | (MysqlType::UnsignedShort, ffi::enum_field_types::MYSQL_TYPE_DECIMAL)\n                | (MysqlType::UnsignedShort, ffi::enum_field_types::MYSQL_TYPE_TINY)\n                | (MysqlType::UnsignedShort, ffi::enum_field_types::MYSQL_TYPE_SHORT)\n                | (MysqlType::UnsignedShort, ffi::enum_field_types::MYSQL_TYPE_LONG)\n                | (MysqlType::UnsignedShort, ffi::enum_field_types::MYSQL_TYPE_FLOAT)\n                | (MysqlType::UnsignedShort, ffi::enum_field_types::MYSQL_TYPE_DOUBLE)\n                | (MysqlType::UnsignedShort, ffi::enum_field_types::MYSQL_TYPE_INT24)\n                | (MysqlType::UnsignedShort, ffi::enum_field_types::MYSQL_TYPE_NEWDECIMAL)\n                | (MysqlType::UnsignedShort, ffi::enum_field_types::MYSQL_TYPE_LONGLONG)\n                | (MysqlType::Long, ffi::enum_field_types::MYSQL_TYPE_DECIMAL)\n                | (MysqlType::Long, ffi::enum_field_types::MYSQL_TYPE_TINY)\n                | (MysqlType::Long, ffi::enum_field_types::MYSQL_TYPE_SHORT)\n                | (MysqlType::Long, ffi::enum_field_types::MYSQL_TYPE_LONG)\n                | (MysqlType::Long, ffi::enum_field_types::MYSQL_TYPE_FLOAT)\n                | (MysqlType::Long, ffi::enum_field_types::MYSQL_TYPE_DOUBLE)\n                | (MysqlType::Long, ffi::enum_field_types::MYSQL_TYPE_INT24)\n                | (MysqlType::Long, ffi::enum_field_types::MYSQL_TYPE_NEWDECIMAL)\n                | (MysqlType::Long, ffi::enum_field_types::MYSQL_TYPE_LONGLONG)\n                | (MysqlType::UnsignedLong, ffi::enum_field_types::MYSQL_TYPE_DECIMAL)\n                | (MysqlType::UnsignedLong, ffi::enum_field_types::MYSQL_TYPE_TINY)\n                | (MysqlType::UnsignedLong, ffi::enum_field_types::MYSQL_TYPE_SHORT)\n                | (MysqlType::UnsignedLong, ffi::enum_field_types::MYSQL_TYPE_LONG)\n                | (MysqlType::UnsignedLong, ffi::enum_field_types::MYSQL_TYPE_FLOAT)\n                | (MysqlType::UnsignedLong, ffi::enum_field_types::MYSQL_TYPE_DOUBLE)\n                | (MysqlType::UnsignedLong, ffi::enum_field_types::MYSQL_TYPE_INT24)\n                | (MysqlType::UnsignedLong, ffi::enum_field_types::MYSQL_TYPE_NEWDECIMAL)\n                | (MysqlType::UnsignedLong, ffi::enum_field_types::MYSQL_TYPE_LONGLONG)\n                | (MysqlType::LongLong, ffi::enum_field_types::MYSQL_TYPE_DECIMAL)\n                | (MysqlType::LongLong, ffi::enum_field_types::MYSQL_TYPE_TINY)\n                | (MysqlType::LongLong, ffi::enum_field_types::MYSQL_TYPE_SHORT)\n                | (MysqlType::LongLong, ffi::enum_field_types::MYSQL_TYPE_LONG)\n                | (MysqlType::LongLong, ffi::enum_field_types::MYSQL_TYPE_FLOAT)\n                | (MysqlType::LongLong, ffi::enum_field_types::MYSQL_TYPE_DOUBLE)\n                | (MysqlType::LongLong, ffi::enum_field_types::MYSQL_TYPE_INT24)\n                | (MysqlType::LongLong, ffi::enum_field_types::MYSQL_TYPE_NEWDECIMAL)\n                | (MysqlType::LongLong, ffi::enum_field_types::MYSQL_TYPE_LONGLONG)\n                | (MysqlType::UnsignedLongLong, ffi::enum_field_types::MYSQL_TYPE_DECIMAL)\n                | (MysqlType::UnsignedLongLong, ffi::enum_field_types::MYSQL_TYPE_TINY)\n                | (MysqlType::UnsignedLongLong, ffi::enum_field_types::MYSQL_TYPE_SHORT)\n                | (MysqlType::UnsignedLongLong, ffi::enum_field_types::MYSQL_TYPE_LONG)\n                | (MysqlType::UnsignedLongLong, ffi::enum_field_types::MYSQL_TYPE_FLOAT)\n                | (MysqlType::UnsignedLongLong, ffi::enum_field_types::MYSQL_TYPE_DOUBLE)\n                | (MysqlType::UnsignedLongLong, ffi::enum_field_types::MYSQL_TYPE_INT24)\n                | (MysqlType::UnsignedLongLong, ffi::enum_field_types::MYSQL_TYPE_NEWDECIMAL)\n                | (MysqlType::UnsignedLongLong, ffi::enum_field_types::MYSQL_TYPE_LONGLONG)\n                | (MysqlType::Float, ffi::enum_field_types::MYSQL_TYPE_DECIMAL)\n                | (MysqlType::Float, ffi::enum_field_types::MYSQL_TYPE_TINY)\n                | (MysqlType::Float, ffi::enum_field_types::MYSQL_TYPE_SHORT)\n                | (MysqlType::Float, ffi::enum_field_types::MYSQL_TYPE_LONG)\n                | (MysqlType::Float, ffi::enum_field_types::MYSQL_TYPE_FLOAT)\n                | (MysqlType::Float, ffi::enum_field_types::MYSQL_TYPE_DOUBLE)\n                | (MysqlType::Float, ffi::enum_field_types::MYSQL_TYPE_INT24)\n                | (MysqlType::Float, ffi::enum_field_types::MYSQL_TYPE_NEWDECIMAL)\n                | (MysqlType::Float, ffi::enum_field_types::MYSQL_TYPE_LONGLONG)\n                | (MysqlType::Numeric, ffi::enum_field_types::MYSQL_TYPE_DECIMAL)\n                | (MysqlType::Numeric, ffi::enum_field_types::MYSQL_TYPE_TINY)\n                | (MysqlType::Numeric, ffi::enum_field_types::MYSQL_TYPE_SHORT)\n                | (MysqlType::Numeric, ffi::enum_field_types::MYSQL_TYPE_LONG)\n                | (MysqlType::Numeric, ffi::enum_field_types::MYSQL_TYPE_FLOAT)\n                | (MysqlType::Numeric, ffi::enum_field_types::MYSQL_TYPE_DOUBLE)\n                | (MysqlType::Numeric, ffi::enum_field_types::MYSQL_TYPE_INT24)\n                | (MysqlType::Numeric, ffi::enum_field_types::MYSQL_TYPE_NEWDECIMAL)\n                | (MysqlType::Numeric, ffi::enum_field_types::MYSQL_TYPE_LONGLONG)\n                | (MysqlType::String, ffi::enum_field_types::MYSQL_TYPE_JSON)\n                | (MysqlType::String, ffi::enum_field_types::MYSQL_TYPE_ENUM)\n                | (MysqlType::String, ffi::enum_field_types::MYSQL_TYPE_SET)\n                | (MysqlType::String, ffi::enum_field_types::MYSQL_TYPE_TINY_BLOB)\n                | (MysqlType::String, ffi::enum_field_types::MYSQL_TYPE_MEDIUM_BLOB)\n                | (MysqlType::String, ffi::enum_field_types::MYSQL_TYPE_LONG_BLOB)\n                | (MysqlType::String, ffi::enum_field_types::MYSQL_TYPE_BLOB)\n                | (MysqlType::String, ffi::enum_field_types::MYSQL_TYPE_VAR_STRING)\n                | (MysqlType::String, ffi::enum_field_types::MYSQL_TYPE_STRING)\n                | (MysqlType::Blob, ffi::enum_field_types::MYSQL_TYPE_TINY_BLOB)\n                | (MysqlType::Blob, ffi::enum_field_types::MYSQL_TYPE_MEDIUM_BLOB)\n                | (MysqlType::Blob, ffi::enum_field_types::MYSQL_TYPE_LONG_BLOB)\n                | (MysqlType::Blob, ffi::enum_field_types::MYSQL_TYPE_BLOB)\n                | (MysqlType::Set, ffi::enum_field_types::MYSQL_TYPE_ENUM)\n                | (MysqlType::Set, ffi::enum_field_types::MYSQL_TYPE_SET)\n                | (MysqlType::Set, ffi::enum_field_types::MYSQL_TYPE_TINY_BLOB)\n                | (MysqlType::Set, ffi::enum_field_types::MYSQL_TYPE_MEDIUM_BLOB)\n                | (MysqlType::Set, ffi::enum_field_types::MYSQL_TYPE_LONG_BLOB)\n                | (MysqlType::Set, ffi::enum_field_types::MYSQL_TYPE_BLOB)\n                | (MysqlType::Set, ffi::enum_field_types::MYSQL_TYPE_VAR_STRING)\n                | (MysqlType::Set, ffi::enum_field_types::MYSQL_TYPE_STRING)\n                | (MysqlType::Enum, ffi::enum_field_types::MYSQL_TYPE_ENUM)\n                | (MysqlType::Enum, ffi::enum_field_types::MYSQL_TYPE_SET)\n                | (MysqlType::Enum, ffi::enum_field_types::MYSQL_TYPE_TINY_BLOB)\n                | (MysqlType::Enum, ffi::enum_field_types::MYSQL_TYPE_MEDIUM_BLOB)\n                | (MysqlType::Enum, ffi::enum_field_types::MYSQL_TYPE_LONG_BLOB)\n                | (MysqlType::Enum, ffi::enum_field_types::MYSQL_TYPE_BLOB)\n                | (MysqlType::Enum, ffi::enum_field_types::MYSQL_TYPE_VAR_STRING)\n                | (MysqlType::Enum, ffi::enum_field_types::MYSQL_TYPE_STRING) => {\n                    (metadata.field_type(), metadata.flags())\n                }\n\n                (tpe, _) => tpe.into(),\n            }\n        } else {\n            (metadata.field_type(), metadata.flags())\n        };\n        Self::from_tpe_and_flags((tpe, flags))\n    }\n\n    fn from_tpe_and_flags((tpe, flags): (ffi::enum_field_types, Flags)) -> Self {\n        // newer mysqlclient versions do not accept a zero sized buffer\n        let len = known_buffer_size_for_ffi_type(tpe).unwrap_or(1);\n        let mut bytes = vec![0; len];\n        let length = bytes.len() as libc::c_ulong;\n        let capacity = bytes.capacity();\n        let ptr = NonNull::new(bytes.as_mut_ptr());\n        mem::forget(bytes);\n\n        Self {\n            tpe,\n            bytes: ptr,\n            length,\n            capacity,\n            flags,\n            is_null: super::raw::ffi_false(),\n            is_truncated: Some(super::raw::ffi_false()),\n        }\n    }\n\n    fn is_truncated(&self) -> bool {\n        self.is_truncated.unwrap_or(super::raw::ffi_false()) != super::raw::ffi_false()\n    }\n\n    fn is_fixed_size_buffer(&self) -> bool {\n        known_buffer_size_for_ffi_type(self.tpe).is_some()\n    }\n\n    pub(super) fn value(&'_ self) -> Option<MysqlValue<'_>> {\n        if self.is_null() {\n            None\n        } else {\n            let data = self.bytes?;\n            let tpe = (self.tpe, self.flags).into();\n            let slice = unsafe {\n                // We know that this points to a slice and the pointer is not null at this\n                // location\n                // The length pointer is valid as long as none missuses `bind_for_truncated_data`\n                // as this is the only location that updates the length field before the corresponding data are\n                // written. At the time of writing this comment, the `BindData::bind_for_truncated_data`\n                // function is only called by `Binds::populate_dynamic_buffers` which ensures the corresponding\n                // invariant.\n                std::slice::from_raw_parts(\n                    data.as_ptr(),\n                    self.length.try_into().expect(\"Usize is at least 32 bit\"),\n                )\n            };\n            Some(MysqlValue::new_internal(slice, tpe))\n        }\n    }\n\n    pub(super) fn is_null(&self) -> bool {\n        self.is_null != ffi::my_bool::default()\n    }\n\n    fn update_buffer_length(&mut self) {\n        use std::cmp::min;\n\n        let actual_bytes_in_buffer = min(\n            self.capacity,\n            self.length.try_into().expect(\"Usize is at least 32 bit\"),\n        );\n        self.length = actual_bytes_in_buffer as libc::c_ulong;\n    }\n\n    // This function is marked as unsafe as it returns an owned value\n    // containing a pointer with a lifetime coupled to self.\n    // Callers need to ensure that the returned value cannot outlive `self`\n    unsafe fn mysql_bind(&mut self) -> ffi::MYSQL_BIND {\n        use std::ptr::addr_of_mut;\n\n        let mut bind: MaybeUninit<ffi::MYSQL_BIND> = mem::MaybeUninit::zeroed();\n        let ptr = bind.as_mut_ptr();\n\n        addr_of_mut!((*ptr).buffer_type).write(self.tpe);\n        addr_of_mut!((*ptr).buffer).write(\n            self.bytes\n                .map(|p| p.as_ptr())\n                .unwrap_or(std::ptr::null_mut()) as *mut libc::c_void,\n        );\n        addr_of_mut!((*ptr).buffer_length).write(self.capacity as libc::c_ulong);\n        addr_of_mut!((*ptr).length).write(&mut self.length);\n        addr_of_mut!((*ptr).is_null).write(&mut self.is_null);\n        addr_of_mut!((*ptr).is_unsigned)\n            .write(self.flags.contains(Flags::UNSIGNED_FLAG) as ffi::my_bool);\n\n        if let Some(ref mut is_truncated) = self.is_truncated {\n            addr_of_mut!((*ptr).error).write(is_truncated);\n        }\n\n        // That's what the mysqlclient examples are doing\n        bind.assume_init()\n    }\n\n    /// Resizes the byte buffer to fit the value of `self.length`, and returns\n    /// a tuple of a bind pointing at the truncated data, and the offset to use\n    /// in order to read the truncated data into it.\n    ///\n    /// This invalidates the bind previously returned by `mysql_bind`. Calling\n    /// this function is unsafe unless the binds are immediately rebound.\n    unsafe fn bind_for_truncated_data(&mut self) -> Option<(ffi::MYSQL_BIND, usize)> {\n        if self.is_truncated() {\n            if let Some(bytes) = self.bytes {\n                let mut bytes = Vec::from_raw_parts(bytes.as_ptr(), self.capacity, self.capacity);\n                self.bytes = None;\n\n                let offset = self.capacity;\n                let truncated_amount =\n                    usize::try_from(self.length).expect(\"Usize is at least 32 bit\") - offset;\n\n                debug_assert!(\n                    truncated_amount > 0,\n                    \"output buffers were invalidated \\\n                     without calling `mysql_stmt_bind_result`\"\n                );\n\n                // reserve space for any missing byte\n                // we know the exact size here\n                bytes.reserve(truncated_amount);\n                self.capacity = bytes.capacity();\n                self.bytes = NonNull::new(bytes.as_mut_ptr());\n                mem::forget(bytes);\n\n                let mut bind = self.mysql_bind();\n\n                if let Some(ptr) = self.bytes {\n                    // Using offset is safe here as we have a u8 array (where std::mem::size_of::<u8> == 1)\n                    // and we have a buffer that has at least\n                    bind.buffer = ptr.as_ptr().add(offset) as *mut libc::c_void;\n                    bind.buffer_length = truncated_amount as libc::c_ulong;\n                } else {\n                    bind.buffer_length = 0;\n                }\n                Some((bind, offset))\n            } else {\n                // offset is zero here as we don't have a buffer yet\n                // we know the requested length here so we can just request\n                // the correct size\n                let mut vec = vec![0_u8; self.length.try_into().expect(\"usize is at least 32 bit\")];\n                self.capacity = vec.capacity();\n                self.bytes = NonNull::new(vec.as_mut_ptr());\n                mem::forget(vec);\n\n                let bind = self.mysql_bind();\n                // As we did not have a buffer before\n                // we couldn't have loaded any data yet, therefore\n                // request everything\n                Some((bind, 0))\n            }\n        } else {\n            None\n        }\n    }\n\n    fn did_numeric_overflow_occur(&self) -> QueryResult<()> {\n        use crate::result::Error::DeserializationError;\n\n        if self.is_truncated() && self.is_fixed_size_buffer() {\n            Err(DeserializationError(\n                \"Numeric overflow/underflow occurred\".into(),\n            ))\n        } else {\n            Ok(())\n        }\n    }\n}\n\nimpl From<MysqlType> for (ffi::enum_field_types, Flags) {\n    fn from(tpe: MysqlType) -> Self {\n        use self::ffi::enum_field_types;\n        let mut flags = Flags::empty();\n        let tpe = match tpe {\n            MysqlType::Tiny => enum_field_types::MYSQL_TYPE_TINY,\n            MysqlType::Short => enum_field_types::MYSQL_TYPE_SHORT,\n            MysqlType::Long => enum_field_types::MYSQL_TYPE_LONG,\n            MysqlType::LongLong => enum_field_types::MYSQL_TYPE_LONGLONG,\n            MysqlType::Float => enum_field_types::MYSQL_TYPE_FLOAT,\n            MysqlType::Double => enum_field_types::MYSQL_TYPE_DOUBLE,\n            MysqlType::Time => enum_field_types::MYSQL_TYPE_TIME,\n            MysqlType::Date => enum_field_types::MYSQL_TYPE_DATE,\n            MysqlType::DateTime => enum_field_types::MYSQL_TYPE_DATETIME,\n            MysqlType::Timestamp => enum_field_types::MYSQL_TYPE_TIMESTAMP,\n            MysqlType::String => enum_field_types::MYSQL_TYPE_STRING,\n            MysqlType::Blob => enum_field_types::MYSQL_TYPE_BLOB,\n            MysqlType::Numeric => enum_field_types::MYSQL_TYPE_NEWDECIMAL,\n            MysqlType::Bit => enum_field_types::MYSQL_TYPE_BIT,\n            MysqlType::UnsignedTiny => {\n                flags = Flags::UNSIGNED_FLAG;\n                enum_field_types::MYSQL_TYPE_TINY\n            }\n            MysqlType::UnsignedShort => {\n                flags = Flags::UNSIGNED_FLAG;\n                enum_field_types::MYSQL_TYPE_SHORT\n            }\n            MysqlType::UnsignedLong => {\n                flags = Flags::UNSIGNED_FLAG;\n                enum_field_types::MYSQL_TYPE_LONG\n            }\n            MysqlType::UnsignedLongLong => {\n                flags = Flags::UNSIGNED_FLAG;\n                enum_field_types::MYSQL_TYPE_LONGLONG\n            }\n            MysqlType::Set => {\n                flags = Flags::SET_FLAG;\n                enum_field_types::MYSQL_TYPE_STRING\n            }\n            MysqlType::Enum => {\n                flags = Flags::ENUM_FLAG;\n                enum_field_types::MYSQL_TYPE_STRING\n            }\n        };\n        (tpe, flags)\n    }\n}\n\nimpl From<(ffi::enum_field_types, Flags)> for MysqlType {\n    fn from((tpe, flags): (ffi::enum_field_types, Flags)) -> Self {\n        use self::ffi::enum_field_types;\n\n        let is_unsigned = flags.contains(Flags::UNSIGNED_FLAG);\n\n        // https://docs.oracle.com/cd/E17952_01/mysql-8.0-en/c-api-data-structures.html\n        // https://dev.mysql.com/doc/dev/mysql-server/8.0.12/binary__log__types_8h.html\n        // https://dev.mysql.com/doc/internals/en/binary-protocol-value.html\n        // https://mariadb.com/kb/en/packet_bindata/\n        match tpe {\n            enum_field_types::MYSQL_TYPE_TINY if is_unsigned => MysqlType::UnsignedTiny,\n            enum_field_types::MYSQL_TYPE_YEAR | enum_field_types::MYSQL_TYPE_SHORT\n                if is_unsigned =>\n            {\n                MysqlType::UnsignedShort\n            }\n            enum_field_types::MYSQL_TYPE_INT24 | enum_field_types::MYSQL_TYPE_LONG\n                if is_unsigned =>\n            {\n                MysqlType::UnsignedLong\n            }\n            enum_field_types::MYSQL_TYPE_LONGLONG if is_unsigned => MysqlType::UnsignedLongLong,\n            enum_field_types::MYSQL_TYPE_TINY => MysqlType::Tiny,\n            enum_field_types::MYSQL_TYPE_SHORT => MysqlType::Short,\n            enum_field_types::MYSQL_TYPE_INT24 | enum_field_types::MYSQL_TYPE_LONG => {\n                MysqlType::Long\n            }\n            enum_field_types::MYSQL_TYPE_LONGLONG => MysqlType::LongLong,\n            enum_field_types::MYSQL_TYPE_FLOAT => MysqlType::Float,\n            enum_field_types::MYSQL_TYPE_DOUBLE => MysqlType::Double,\n            enum_field_types::MYSQL_TYPE_DECIMAL | enum_field_types::MYSQL_TYPE_NEWDECIMAL => {\n                MysqlType::Numeric\n            }\n            enum_field_types::MYSQL_TYPE_BIT => MysqlType::Bit,\n\n            enum_field_types::MYSQL_TYPE_TIME => MysqlType::Time,\n            enum_field_types::MYSQL_TYPE_DATE => MysqlType::Date,\n            enum_field_types::MYSQL_TYPE_DATETIME => MysqlType::DateTime,\n            enum_field_types::MYSQL_TYPE_TIMESTAMP => MysqlType::Timestamp,\n            // Treat json as string because even mysql 8.0\n            // throws errors sometimes if we use json for json\n            enum_field_types::MYSQL_TYPE_JSON => MysqlType::String,\n\n            // The documentation states that\n            // MYSQL_TYPE_STRING is used for enums and sets\n            // but experimentation has shown that\n            // just any string like type works, so\n            // better be safe here\n            enum_field_types::MYSQL_TYPE_BLOB\n            | enum_field_types::MYSQL_TYPE_TINY_BLOB\n            | enum_field_types::MYSQL_TYPE_MEDIUM_BLOB\n            | enum_field_types::MYSQL_TYPE_LONG_BLOB\n            | enum_field_types::MYSQL_TYPE_VAR_STRING\n            | enum_field_types::MYSQL_TYPE_STRING\n                if flags.contains(Flags::ENUM_FLAG) =>\n            {\n                MysqlType::Enum\n            }\n            enum_field_types::MYSQL_TYPE_BLOB\n            | enum_field_types::MYSQL_TYPE_TINY_BLOB\n            | enum_field_types::MYSQL_TYPE_MEDIUM_BLOB\n            | enum_field_types::MYSQL_TYPE_LONG_BLOB\n            | enum_field_types::MYSQL_TYPE_VAR_STRING\n            | enum_field_types::MYSQL_TYPE_STRING\n                if flags.contains(Flags::SET_FLAG) =>\n            {\n                MysqlType::Set\n            }\n\n            // \"blobs\" may contain binary data\n            // also \"strings\" can contain binary data\n            // but all only if the binary flag is set\n            // (see the check_all_the_types test case)\n            enum_field_types::MYSQL_TYPE_BLOB\n            | enum_field_types::MYSQL_TYPE_TINY_BLOB\n            | enum_field_types::MYSQL_TYPE_MEDIUM_BLOB\n            | enum_field_types::MYSQL_TYPE_LONG_BLOB\n            | enum_field_types::MYSQL_TYPE_VAR_STRING\n            | enum_field_types::MYSQL_TYPE_STRING\n                if flags.contains(Flags::BINARY_FLAG) =>\n            {\n                MysqlType::Blob\n            }\n\n            // If the binary flag is not set consider everything as string\n            enum_field_types::MYSQL_TYPE_BLOB\n            | enum_field_types::MYSQL_TYPE_TINY_BLOB\n            | enum_field_types::MYSQL_TYPE_MEDIUM_BLOB\n            | enum_field_types::MYSQL_TYPE_LONG_BLOB\n            | enum_field_types::MYSQL_TYPE_VAR_STRING\n            | enum_field_types::MYSQL_TYPE_STRING => MysqlType::String,\n\n            // unsigned seems to be set for year in any case\n            enum_field_types::MYSQL_TYPE_YEAR => unreachable!(\n                \"The year type should have set the unsigned flag. If you ever \\\n                 see this error message, something has gone very wrong. Please \\\n                 open an issue at the diesel github repo in this case\"\n            ),\n            // Null value\n            enum_field_types::MYSQL_TYPE_NULL => unreachable!(\n                \"We ensure at the call side that we do not hit this type here. \\\n                 If you ever see this error, something has gone very wrong. \\\n                 Please open an issue at the diesel github repo in this case\"\n            ),\n            // Those exist in libmysqlclient\n            // but are just not supported\n            //\n            enum_field_types::MYSQL_TYPE_VARCHAR\n            | enum_field_types::MYSQL_TYPE_ENUM\n            | enum_field_types::MYSQL_TYPE_SET\n            | enum_field_types::MYSQL_TYPE_GEOMETRY => {\n                unimplemented!(\n                    \"Hit a type that should be unsupported in libmysqlclient. If \\\n                     you ever see this error, they probably have added support for \\\n                     one of those types. Please open an issue at the diesel github \\\n                     repo in this case.\"\n                )\n            }\n\n            enum_field_types::MYSQL_TYPE_NEWDATE\n            | enum_field_types::MYSQL_TYPE_TIME2\n            | enum_field_types::MYSQL_TYPE_DATETIME2\n            | enum_field_types::MYSQL_TYPE_TIMESTAMP2 => unreachable!(\n                \"The mysql documentation states that these types are \\\n                 only used on the server side, so if you see this error \\\n                 something has gone wrong. Please open an issue at \\\n                 the diesel github repo.\"\n            ),\n            // depending on the bindings version\n            // there might be no unlisted field type\n            #[allow(unreachable_patterns)]\n            t => unreachable!(\n                \"Unsupported type encountered: {t:?}. \\\n                 If you ever see this error, something has gone wrong. \\\n                 Please open an issue at the diesel github \\\n                 repo in this case.\"\n            ),\n        }\n    }\n}\n\nfn known_buffer_size_for_ffi_type(tpe: ffi::enum_field_types) -> Option<usize> {\n    use self::ffi::enum_field_types as t;\n    use std::mem::size_of;\n\n    match tpe {\n        t::MYSQL_TYPE_TINY => Some(1),\n        t::MYSQL_TYPE_YEAR | t::MYSQL_TYPE_SHORT => Some(2),\n        t::MYSQL_TYPE_INT24 | t::MYSQL_TYPE_LONG | t::MYSQL_TYPE_FLOAT => Some(4),\n        t::MYSQL_TYPE_LONGLONG | t::MYSQL_TYPE_DOUBLE => Some(8),\n        t::MYSQL_TYPE_TIME\n        | t::MYSQL_TYPE_DATE\n        | t::MYSQL_TYPE_DATETIME\n        | t::MYSQL_TYPE_TIMESTAMP => Some(size_of::<MysqlTime>()),\n        _ => None,\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::connection::statement_cache::MaybeCached;\n    use crate::deserialize::FromSql;\n    use crate::mysql::connection::stmt::Statement;\n    use crate::prelude::*;\n    use crate::sql_types::*;\n    #[cfg(feature = \"numeric\")]\n    use std::str::FromStr;\n\n    fn to_value<ST, T>(\n        bind: &BindData,\n    ) -> Result<T, Box<(dyn std::error::Error + Send + Sync + 'static)>>\n    where\n        T: FromSql<ST, crate::mysql::Mysql> + std::fmt::Debug,\n    {\n        let meta = (bind.tpe, bind.flags).into();\n        dbg!(meta);\n\n        let value = bind.value().expect(\"Is not null\");\n        let value = MysqlValue::new_internal(value.as_bytes(), meta);\n\n        dbg!(T::from_sql(value))\n    }\n\n    #[cfg(feature = \"extras\")]\n    #[test]\n    fn check_all_the_types() {\n        let conn = &mut crate::test_helpers::connection();\n\n        crate::sql_query(\"DROP TABLE IF EXISTS all_mysql_types CASCADE\")\n            .execute(conn)\n            .unwrap();\n        crate::sql_query(\n            \"CREATE TABLE all_mysql_types (\n                    tiny_int TINYINT NOT NULL,\n                    small_int SMALLINT NOT NULL,\n                    medium_int MEDIUMINT NOT NULL,\n                    int_col INTEGER NOT NULL,\n                    big_int BIGINT NOT NULL,\n                    unsigned_int INTEGER UNSIGNED NOT NULL,\n                    zero_fill_int INTEGER ZEROFILL NOT NULL,\n                    numeric_col NUMERIC(20,5) NOT NULL,\n                    decimal_col DECIMAL(20,5) NOT NULL,\n                    float_col FLOAT NOT NULL,\n                    double_col DOUBLE NOT NULL,\n                    bit_col BIT(8) NOT NULL,\n                    date_col DATE NOT NULL,\n                    date_time DATETIME NOT NULL,\n                    timestamp_col TIMESTAMP NOT NULL,\n                    time_col TIME NOT NULL,\n                    year_col YEAR NOT NULL,\n                    char_col CHAR(30) NOT NULL,\n                    varchar_col VARCHAR(30) NOT NULL,\n                    binary_col BINARY(30) NOT NULL,\n                    varbinary_col VARBINARY(30) NOT NULL,\n                    blob_col BLOB NOT NULL,\n                    text_col TEXT NOT NULL,\n                    enum_col ENUM('red', 'green', 'blue') NOT NULL,\n                    set_col SET('one', 'two') NOT NULL,\n                    geom GEOMETRY NOT NULL,\n                    point_col POINT NOT NULL,\n                    linestring_col LINESTRING NOT NULL,\n                    polygon_col POLYGON NOT NULL,\n                    multipoint_col MULTIPOINT NOT NULL,\n                    multilinestring_col MULTILINESTRING NOT NULL,\n                    multipolygon_col MULTIPOLYGON NOT NULL,\n                    geometry_collection GEOMETRYCOLLECTION NOT NULL,\n                    json_col JSON NOT NULL\n            )\",\n        )\n        .execute(conn)\n        .unwrap();\n        crate::sql_query(\n                \"INSERT INTO all_mysql_types VALUES (\n                    0, -- tiny_int\n                    1, -- small_int\n                    2, -- medium_int\n                    3, -- int_col\n                    -5, -- big_int\n                    42, -- unsigned_int\n                    1, -- zero_fill_int\n                    -999.999, -- numeric_col,\n                    3.14, -- decimal_col,\n                    1.23, -- float_col\n                    4.5678, -- double_col\n                    b'10101010', -- bit_col\n                    '1000-01-01', -- date_col\n                    '9999-12-31 12:34:45.012345', -- date_time\n                    '2020-01-01 10:10:10', -- timestamp_col\n                    '23:01:01', -- time_col\n                    2020, -- year_col\n                    'abc', -- char_col\n                    'foo', -- varchar_col\n                    'a ', -- binary_col\n                    'a ', -- varbinary_col\n                    'binary', -- blob_col\n                    'some text whatever', -- text_col\n                    'red', -- enum_col\n                    'one', -- set_col\n                    ST_GeomFromText('POINT(1 1)'), -- geom\n                    ST_PointFromText('POINT(1 1)'), -- point_col\n                    ST_LineStringFromText('LINESTRING(0 0,1 1,2 2)'), -- linestring_col\n                    ST_PolygonFromText('POLYGON((0 0,10 0,10 10,0 10,0 0),(5 5,7 5,7 7,5 7, 5 5))'), -- polygon_col\n                    ST_MultiPointFromText('MULTIPOINT(0 0,10 10,10 20,20 20)'), -- multipoint_col\n                    ST_MultiLineStringFromText('MULTILINESTRING((10 48,10 21,10 0),(16 0,16 23,16 48))'), -- multilinestring_col\n                    ST_MultiPolygonFromText('MULTIPOLYGON(((28 26,28 0,84 0,84 42,28 26),(52 18,66 23,73 9,48 6,52 18)),((59 18,67 18,67 13,59 13,59 18)))'), -- multipolygon_col\n                    ST_GeomCollFromText('GEOMETRYCOLLECTION(POINT(1 1),LINESTRING(0 0,1 1,2 2,3 3,4 4))'), -- geometry_collection\n                    '{\\\"key1\\\": \\\"value1\\\", \\\"key2\\\": \\\"value2\\\"}' -- json_col\n)\",\n            ).execute(conn)\n            .unwrap();\n\n        let stmt = crate::mysql::connection::prepared_query(\n            &crate::sql_query(\n                \"SELECT\n                    tiny_int, small_int, medium_int, int_col,\n                    big_int, unsigned_int, zero_fill_int,\n                    numeric_col, decimal_col, float_col, double_col, bit_col,\n                    date_col, date_time, timestamp_col, time_col, year_col,\n                    char_col, varchar_col, binary_col, varbinary_col, blob_col,\n                    text_col, enum_col, set_col, ST_AsText(geom), ST_AsText(point_col), ST_AsText(linestring_col),\n                    ST_AsText(polygon_col), ST_AsText(multipoint_col), ST_AsText(multilinestring_col),\n                    ST_AsText(multipolygon_col), ST_AsText(geometry_collection), json_col\n                 FROM all_mysql_types\",\n            ),\n            &mut conn.statement_cache,\n            &mut conn.raw_connection,\n            &mut *conn.instrumentation,\n        ).unwrap();\n\n        let metadata = stmt.metadata().unwrap();\n        let mut output_binds =\n            OutputBinds::from_output_types(&vec![None; metadata.fields().len()], &metadata);\n        let stmt = stmt.execute_statement(&mut output_binds).unwrap();\n        stmt.populate_row_buffers(&mut output_binds).unwrap();\n\n        let results: Vec<(BindData, &_)> = output_binds\n            .0\n            .data\n            .into_iter()\n            .zip(metadata.fields())\n            .collect::<Vec<_>>();\n\n        let tiny_int_col = &results[0].0;\n        assert_eq!(tiny_int_col.tpe, ffi::enum_field_types::MYSQL_TYPE_TINY);\n        assert!(tiny_int_col.flags.contains(Flags::NUM_FLAG));\n        assert!(!tiny_int_col.flags.contains(Flags::UNSIGNED_FLAG));\n        assert!(matches!(to_value::<TinyInt, i8>(tiny_int_col), Ok(0)));\n\n        let small_int_col = &results[1].0;\n        assert_eq!(small_int_col.tpe, ffi::enum_field_types::MYSQL_TYPE_SHORT);\n        assert!(small_int_col.flags.contains(Flags::NUM_FLAG));\n        assert!(!small_int_col.flags.contains(Flags::UNSIGNED_FLAG));\n        assert!(matches!(to_value::<SmallInt, i16>(small_int_col), Ok(1)));\n\n        let medium_int_col = &results[2].0;\n        assert_eq!(medium_int_col.tpe, ffi::enum_field_types::MYSQL_TYPE_INT24);\n        assert!(medium_int_col.flags.contains(Flags::NUM_FLAG));\n        assert!(!medium_int_col.flags.contains(Flags::UNSIGNED_FLAG));\n        assert!(matches!(to_value::<Integer, i32>(medium_int_col), Ok(2)));\n\n        let int_col = &results[3].0;\n        assert_eq!(int_col.tpe, ffi::enum_field_types::MYSQL_TYPE_LONG);\n        assert!(int_col.flags.contains(Flags::NUM_FLAG));\n        assert!(!int_col.flags.contains(Flags::UNSIGNED_FLAG));\n        assert!(matches!(to_value::<Integer, i32>(int_col), Ok(3)));\n\n        let big_int_col = &results[4].0;\n        assert_eq!(big_int_col.tpe, ffi::enum_field_types::MYSQL_TYPE_LONGLONG);\n        assert!(big_int_col.flags.contains(Flags::NUM_FLAG));\n        assert!(!big_int_col.flags.contains(Flags::UNSIGNED_FLAG));\n        assert!(matches!(to_value::<TinyInt, i8>(big_int_col), Ok(-5)));\n\n        let unsigned_int_col = &results[5].0;\n        assert_eq!(unsigned_int_col.tpe, ffi::enum_field_types::MYSQL_TYPE_LONG);\n        assert!(unsigned_int_col.flags.contains(Flags::NUM_FLAG));\n        assert!(unsigned_int_col.flags.contains(Flags::UNSIGNED_FLAG));\n        assert!(matches!(\n            to_value::<Unsigned<Integer>, u32>(unsigned_int_col),\n            Ok(42)\n        ));\n\n        let zero_fill_int_col = &results[6].0;\n        assert_eq!(\n            zero_fill_int_col.tpe,\n            ffi::enum_field_types::MYSQL_TYPE_LONG\n        );\n        assert!(zero_fill_int_col.flags.contains(Flags::NUM_FLAG));\n        assert!(zero_fill_int_col.flags.contains(Flags::ZEROFILL_FLAG));\n        assert!(matches!(to_value::<Integer, i32>(zero_fill_int_col), Ok(1)));\n\n        let numeric_col = &results[7].0;\n        assert_eq!(\n            numeric_col.tpe,\n            ffi::enum_field_types::MYSQL_TYPE_NEWDECIMAL\n        );\n        assert!(numeric_col.flags.contains(Flags::NUM_FLAG));\n        assert!(!numeric_col.flags.contains(Flags::UNSIGNED_FLAG));\n        assert_eq!(\n            to_value::<Numeric, bigdecimal::BigDecimal>(numeric_col).unwrap(),\n            bigdecimal::BigDecimal::from_str(\"-999.99900\").unwrap()\n        );\n\n        let decimal_col = &results[8].0;\n        assert_eq!(\n            decimal_col.tpe,\n            ffi::enum_field_types::MYSQL_TYPE_NEWDECIMAL\n        );\n        assert!(decimal_col.flags.contains(Flags::NUM_FLAG));\n        assert!(!decimal_col.flags.contains(Flags::UNSIGNED_FLAG));\n        assert_eq!(\n            to_value::<Numeric, bigdecimal::BigDecimal>(decimal_col).unwrap(),\n            bigdecimal::BigDecimal::from_str(\"3.14000\").unwrap()\n        );\n\n        let float_col = &results[9].0;\n        assert_eq!(float_col.tpe, ffi::enum_field_types::MYSQL_TYPE_FLOAT);\n        assert!(float_col.flags.contains(Flags::NUM_FLAG));\n        assert!(!float_col.flags.contains(Flags::UNSIGNED_FLAG));\n        assert_eq!(to_value::<Float, f32>(float_col).unwrap(), 1.23);\n\n        let double_col = &results[10].0;\n        assert_eq!(double_col.tpe, ffi::enum_field_types::MYSQL_TYPE_DOUBLE);\n        assert!(double_col.flags.contains(Flags::NUM_FLAG));\n        assert!(!double_col.flags.contains(Flags::UNSIGNED_FLAG));\n        assert_eq!(to_value::<Double, f64>(double_col).unwrap(), 4.5678);\n\n        let bit_col = &results[11].0;\n        assert_eq!(bit_col.tpe, ffi::enum_field_types::MYSQL_TYPE_BIT);\n        assert!(!bit_col.flags.contains(Flags::NUM_FLAG));\n        assert!(bit_col.flags.contains(Flags::UNSIGNED_FLAG));\n        assert!(!bit_col.flags.contains(Flags::BINARY_FLAG));\n        assert_eq!(to_value::<Blob, Vec<u8>>(bit_col).unwrap(), vec![170]);\n\n        let date_col = &results[12].0;\n        assert_eq!(date_col.tpe, ffi::enum_field_types::MYSQL_TYPE_DATE);\n        assert!(!date_col.flags.contains(Flags::NUM_FLAG));\n        assert_eq!(\n            to_value::<Date, chrono::NaiveDate>(date_col).unwrap(),\n            chrono::NaiveDate::from_ymd_opt(1000, 1, 1).unwrap(),\n        );\n\n        let date_time_col = &results[13].0;\n        assert_eq!(\n            date_time_col.tpe,\n            ffi::enum_field_types::MYSQL_TYPE_DATETIME\n        );\n        assert!(!date_time_col.flags.contains(Flags::NUM_FLAG));\n        assert_eq!(\n            to_value::<Datetime, chrono::NaiveDateTime>(date_time_col).unwrap(),\n            chrono::NaiveDateTime::parse_from_str(\"9999-12-31 12:34:45\", \"%Y-%m-%d %H:%M:%S\")\n                .unwrap()\n        );\n\n        let timestamp_col = &results[14].0;\n        assert_eq!(\n            timestamp_col.tpe,\n            ffi::enum_field_types::MYSQL_TYPE_TIMESTAMP\n        );\n        assert!(!timestamp_col.flags.contains(Flags::NUM_FLAG));\n        assert_eq!(\n            to_value::<Datetime, chrono::NaiveDateTime>(timestamp_col).unwrap(),\n            chrono::NaiveDateTime::parse_from_str(\"2020-01-01 10:10:10\", \"%Y-%m-%d %H:%M:%S\")\n                .unwrap()\n        );\n\n        let time_col = &results[15].0;\n        assert_eq!(time_col.tpe, ffi::enum_field_types::MYSQL_TYPE_TIME);\n        assert!(!time_col.flags.contains(Flags::NUM_FLAG));\n        assert_eq!(\n            to_value::<Time, chrono::NaiveTime>(time_col).unwrap(),\n            chrono::NaiveTime::from_hms_opt(23, 1, 1).unwrap()\n        );\n\n        let year_col = &results[16].0;\n        assert_eq!(year_col.tpe, ffi::enum_field_types::MYSQL_TYPE_YEAR);\n        assert!(year_col.flags.contains(Flags::NUM_FLAG));\n        assert!(year_col.flags.contains(Flags::UNSIGNED_FLAG));\n        assert!(matches!(to_value::<SmallInt, i16>(year_col), Ok(2020)));\n\n        let char_col = &results[17].0;\n        assert_eq!(char_col.tpe, ffi::enum_field_types::MYSQL_TYPE_STRING);\n        assert!(!char_col.flags.contains(Flags::NUM_FLAG));\n        assert!(!char_col.flags.contains(Flags::BLOB_FLAG));\n        assert!(!char_col.flags.contains(Flags::SET_FLAG));\n        assert!(!char_col.flags.contains(Flags::ENUM_FLAG));\n        assert!(!char_col.flags.contains(Flags::BINARY_FLAG));\n        assert_eq!(to_value::<Text, String>(char_col).unwrap(), \"abc\");\n\n        let varchar_col = &results[18].0;\n        assert_eq!(\n            varchar_col.tpe,\n            ffi::enum_field_types::MYSQL_TYPE_VAR_STRING\n        );\n        assert!(!varchar_col.flags.contains(Flags::NUM_FLAG));\n        assert!(!varchar_col.flags.contains(Flags::BLOB_FLAG));\n        assert!(!varchar_col.flags.contains(Flags::SET_FLAG));\n        assert!(!varchar_col.flags.contains(Flags::ENUM_FLAG));\n        assert!(!varchar_col.flags.contains(Flags::BINARY_FLAG));\n        assert_eq!(to_value::<Text, String>(varchar_col).unwrap(), \"foo\");\n\n        let binary_col = &results[19].0;\n        assert_eq!(binary_col.tpe, ffi::enum_field_types::MYSQL_TYPE_STRING);\n        assert!(!binary_col.flags.contains(Flags::NUM_FLAG));\n        assert!(!binary_col.flags.contains(Flags::BLOB_FLAG));\n        assert!(!binary_col.flags.contains(Flags::SET_FLAG));\n        assert!(!binary_col.flags.contains(Flags::ENUM_FLAG));\n        assert!(binary_col.flags.contains(Flags::BINARY_FLAG));\n        assert_eq!(\n            to_value::<Blob, Vec<u8>>(binary_col).unwrap(),\n            b\"a \\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\"\n        );\n\n        let varbinary_col = &results[20].0;\n        assert_eq!(\n            varbinary_col.tpe,\n            ffi::enum_field_types::MYSQL_TYPE_VAR_STRING\n        );\n        assert!(!varbinary_col.flags.contains(Flags::NUM_FLAG));\n        assert!(!varbinary_col.flags.contains(Flags::BLOB_FLAG));\n        assert!(!varbinary_col.flags.contains(Flags::SET_FLAG));\n        assert!(!varbinary_col.flags.contains(Flags::ENUM_FLAG));\n        assert!(varbinary_col.flags.contains(Flags::BINARY_FLAG));\n        assert_eq!(to_value::<Blob, Vec<u8>>(varbinary_col).unwrap(), b\"a \");\n\n        let blob_col = &results[21].0;\n        assert_eq!(blob_col.tpe, ffi::enum_field_types::MYSQL_TYPE_BLOB);\n        assert!(!blob_col.flags.contains(Flags::NUM_FLAG));\n        assert!(blob_col.flags.contains(Flags::BLOB_FLAG));\n        assert!(!blob_col.flags.contains(Flags::SET_FLAG));\n        assert!(!blob_col.flags.contains(Flags::ENUM_FLAG));\n        assert!(blob_col.flags.contains(Flags::BINARY_FLAG));\n        assert_eq!(to_value::<Blob, Vec<u8>>(blob_col).unwrap(), b\"binary\");\n\n        let text_col = &results[22].0;\n        assert_eq!(text_col.tpe, ffi::enum_field_types::MYSQL_TYPE_BLOB);\n        assert!(!text_col.flags.contains(Flags::NUM_FLAG));\n        assert!(text_col.flags.contains(Flags::BLOB_FLAG));\n        assert!(!text_col.flags.contains(Flags::SET_FLAG));\n        assert!(!text_col.flags.contains(Flags::ENUM_FLAG));\n        assert!(!text_col.flags.contains(Flags::BINARY_FLAG));\n        assert_eq!(\n            to_value::<Text, String>(text_col).unwrap(),\n            \"some text whatever\"\n        );\n\n        let enum_col = &results[23].0;\n        assert_eq!(enum_col.tpe, ffi::enum_field_types::MYSQL_TYPE_STRING);\n        assert!(!enum_col.flags.contains(Flags::NUM_FLAG));\n        assert!(!enum_col.flags.contains(Flags::BLOB_FLAG));\n        assert!(!enum_col.flags.contains(Flags::SET_FLAG));\n        assert!(enum_col.flags.contains(Flags::ENUM_FLAG));\n        assert!(!enum_col.flags.contains(Flags::BINARY_FLAG));\n        assert_eq!(to_value::<Text, String>(enum_col).unwrap(), \"red\");\n\n        let set_col = &results[24].0;\n        assert_eq!(set_col.tpe, ffi::enum_field_types::MYSQL_TYPE_STRING);\n        assert!(!set_col.flags.contains(Flags::NUM_FLAG));\n        assert!(!set_col.flags.contains(Flags::BLOB_FLAG));\n        assert!(set_col.flags.contains(Flags::SET_FLAG));\n        assert!(!set_col.flags.contains(Flags::ENUM_FLAG));\n        assert!(!set_col.flags.contains(Flags::BINARY_FLAG));\n        assert_eq!(to_value::<Text, String>(set_col).unwrap(), \"one\");\n\n        let geom = &results[25].0;\n        assert_eq!(geom.tpe, ffi::enum_field_types::MYSQL_TYPE_LONG_BLOB);\n        assert!(!geom.flags.contains(Flags::NUM_FLAG));\n        assert!(!geom.flags.contains(Flags::BLOB_FLAG));\n        assert!(!geom.flags.contains(Flags::SET_FLAG));\n        assert!(!geom.flags.contains(Flags::ENUM_FLAG));\n        assert!(!geom.flags.contains(Flags::BINARY_FLAG));\n        assert_eq!(to_value::<Text, String>(geom).unwrap(), \"POINT(1 1)\");\n\n        let point_col = &results[26].0;\n        assert_eq!(point_col.tpe, ffi::enum_field_types::MYSQL_TYPE_LONG_BLOB);\n        assert!(!point_col.flags.contains(Flags::NUM_FLAG));\n        assert!(!point_col.flags.contains(Flags::BLOB_FLAG));\n        assert!(!point_col.flags.contains(Flags::SET_FLAG));\n        assert!(!point_col.flags.contains(Flags::ENUM_FLAG));\n        assert!(!point_col.flags.contains(Flags::BINARY_FLAG));\n        assert_eq!(to_value::<Text, String>(point_col).unwrap(), \"POINT(1 1)\");\n\n        let linestring_col = &results[27].0;\n        assert_eq!(\n            linestring_col.tpe,\n            ffi::enum_field_types::MYSQL_TYPE_LONG_BLOB\n        );\n        assert!(!linestring_col.flags.contains(Flags::NUM_FLAG));\n        assert!(!linestring_col.flags.contains(Flags::BLOB_FLAG));\n        assert!(!linestring_col.flags.contains(Flags::SET_FLAG));\n        assert!(!linestring_col.flags.contains(Flags::ENUM_FLAG));\n        assert!(!linestring_col.flags.contains(Flags::BINARY_FLAG));\n        assert_eq!(\n            to_value::<Text, String>(linestring_col).unwrap(),\n            \"LINESTRING(0 0,1 1,2 2)\"\n        );\n\n        let polygon_col = &results[28].0;\n        assert_eq!(polygon_col.tpe, ffi::enum_field_types::MYSQL_TYPE_LONG_BLOB);\n        assert!(!polygon_col.flags.contains(Flags::NUM_FLAG));\n        assert!(!polygon_col.flags.contains(Flags::BLOB_FLAG));\n        assert!(!polygon_col.flags.contains(Flags::SET_FLAG));\n        assert!(!polygon_col.flags.contains(Flags::ENUM_FLAG));\n        assert!(!polygon_col.flags.contains(Flags::BINARY_FLAG));\n        assert_eq!(\n            to_value::<Text, String>(polygon_col).unwrap(),\n            \"POLYGON((0 0,10 0,10 10,0 10,0 0),(5 5,7 5,7 7,5 7,5 5))\"\n        );\n\n        let multipoint_col = &results[29].0;\n        assert_eq!(\n            multipoint_col.tpe,\n            ffi::enum_field_types::MYSQL_TYPE_LONG_BLOB\n        );\n        assert!(!multipoint_col.flags.contains(Flags::NUM_FLAG));\n        assert!(!multipoint_col.flags.contains(Flags::BLOB_FLAG));\n        assert!(!multipoint_col.flags.contains(Flags::SET_FLAG));\n        assert!(!multipoint_col.flags.contains(Flags::ENUM_FLAG));\n        assert!(!multipoint_col.flags.contains(Flags::BINARY_FLAG));\n        // older mysql and mariadb versions get back another encoding here\n        // we test for both as there seems to be no clear pattern when one or\n        // the other is returned\n        let multipoint_res = to_value::<Text, String>(multipoint_col).unwrap();\n        assert!(\n            multipoint_res == \"MULTIPOINT((0 0),(10 10),(10 20),(20 20))\"\n                || multipoint_res == \"MULTIPOINT(0 0,10 10,10 20,20 20)\"\n        );\n\n        let multilinestring_col = &results[30].0;\n        assert_eq!(\n            multilinestring_col.tpe,\n            ffi::enum_field_types::MYSQL_TYPE_LONG_BLOB\n        );\n        assert!(!multilinestring_col.flags.contains(Flags::NUM_FLAG));\n        assert!(!multilinestring_col.flags.contains(Flags::BLOB_FLAG));\n        assert!(!multilinestring_col.flags.contains(Flags::SET_FLAG));\n        assert!(!multilinestring_col.flags.contains(Flags::ENUM_FLAG));\n        assert!(!multilinestring_col.flags.contains(Flags::BINARY_FLAG));\n        assert_eq!(\n            to_value::<Text, String>(multilinestring_col).unwrap(),\n            \"MULTILINESTRING((10 48,10 21,10 0),(16 0,16 23,16 48))\"\n        );\n\n        let polygon_col = &results[31].0;\n        assert_eq!(polygon_col.tpe, ffi::enum_field_types::MYSQL_TYPE_LONG_BLOB);\n        assert!(!polygon_col.flags.contains(Flags::NUM_FLAG));\n        assert!(!polygon_col.flags.contains(Flags::BLOB_FLAG));\n        assert!(!polygon_col.flags.contains(Flags::SET_FLAG));\n        assert!(!polygon_col.flags.contains(Flags::ENUM_FLAG));\n        assert!(!polygon_col.flags.contains(Flags::BINARY_FLAG));\n        assert_eq!(\n                to_value::<Text, String>(polygon_col).unwrap(),\n                \"MULTIPOLYGON(((28 26,28 0,84 0,84 42,28 26),(52 18,66 23,73 9,48 6,52 18)),((59 18,67 18,67 13,59 13,59 18)))\"\n            );\n\n        let geometry_collection = &results[32].0;\n        assert_eq!(\n            geometry_collection.tpe,\n            ffi::enum_field_types::MYSQL_TYPE_LONG_BLOB\n        );\n        assert!(!geometry_collection.flags.contains(Flags::NUM_FLAG));\n        assert!(!geometry_collection.flags.contains(Flags::BLOB_FLAG));\n        assert!(!geometry_collection.flags.contains(Flags::SET_FLAG));\n        assert!(!geometry_collection.flags.contains(Flags::ENUM_FLAG));\n        assert!(!geometry_collection.flags.contains(Flags::BINARY_FLAG));\n        assert_eq!(\n            to_value::<Text, String>(geometry_collection).unwrap(),\n            \"GEOMETRYCOLLECTION(POINT(1 1),LINESTRING(0 0,1 1,2 2,3 3,4 4))\"\n        );\n\n        let json_col = &results[33].0;\n        // mariadb >= 10.2 and mysql >=8.0 are supporting a json type\n        // from those mariadb >= 10.3 and mysql >= 8.0 are reporting\n        // json here, so we assert that we get back json\n        // mariadb 10.5 returns again blob\n        assert!(\n            json_col.tpe == ffi::enum_field_types::MYSQL_TYPE_JSON\n                || json_col.tpe == ffi::enum_field_types::MYSQL_TYPE_BLOB\n        );\n        assert!(!json_col.flags.contains(Flags::NUM_FLAG));\n        assert!(json_col.flags.contains(Flags::BLOB_FLAG));\n        assert!(!json_col.flags.contains(Flags::SET_FLAG));\n        assert!(!json_col.flags.contains(Flags::ENUM_FLAG));\n        assert!(json_col.flags.contains(Flags::BINARY_FLAG));\n        assert_eq!(\n            to_value::<Text, String>(json_col).unwrap(),\n            \"{\\\"key1\\\": \\\"value1\\\", \\\"key2\\\": \\\"value2\\\"}\"\n        );\n    }\n\n    fn query_single_table(\n        query: &'static str,\n        conn: &MysqlConnection,\n        bind_tpe: impl Into<(ffi::enum_field_types, Flags)>,\n    ) -> BindData {\n        let stmt: Statement = conn.raw_connection.prepare(query).unwrap();\n        let stmt = MaybeCached::CannotCache(stmt);\n\n        let bind = BindData::from_tpe_and_flags(bind_tpe.into());\n\n        let mut binds = OutputBinds(Binds { data: vec![bind] });\n\n        let stmt = stmt.execute_statement(&mut binds).unwrap();\n        stmt.populate_row_buffers(&mut binds).unwrap();\n\n        binds.0.data.remove(0)\n    }\n\n    fn input_bind(\n        query: &'static str,\n        conn: &MysqlConnection,\n        id: i32,\n        (mut field, tpe): (Vec<u8>, impl Into<(ffi::enum_field_types, Flags)>),\n    ) {\n        let mut stmt = conn.raw_connection.prepare(query).unwrap();\n        let length = field.len() as _;\n        let (tpe, flags) = tpe.into();\n        let capacity = field.capacity();\n        let ptr = NonNull::new(field.as_mut_ptr());\n        mem::forget(field);\n\n        let field_bind = BindData {\n            tpe,\n            bytes: ptr,\n            capacity,\n            length,\n            flags,\n            is_null: ffi::FALSE,\n            is_truncated: None,\n        };\n\n        let mut bytes = id.to_be_bytes().to_vec();\n        let length = bytes.len() as _;\n        let capacity = bytes.capacity();\n        let ptr = NonNull::new(bytes.as_mut_ptr());\n        mem::forget(bytes);\n\n        let id_bind = BindData {\n            tpe: ffi::enum_field_types::MYSQL_TYPE_LONG,\n            bytes: ptr,\n            capacity,\n            length,\n            flags: Flags::empty(),\n            is_null: ffi::FALSE,\n            is_truncated: None,\n        };\n\n        let binds = PreparedStatementBinds(Binds {\n            data: vec![id_bind, field_bind],\n        });\n        stmt.input_bind(binds).unwrap();\n        stmt.did_an_error_occur().unwrap();\n        let stmt = MaybeCached::CannotCache(stmt);\n        unsafe {\n            stmt.execute().unwrap();\n        }\n    }\n\n    #[test]\n    fn check_json_bind() {\n        table! {\n            json_test {\n                id -> Integer,\n                json_field -> Text,\n            }\n        }\n\n        let conn = &mut crate::test_helpers::connection();\n\n        crate::sql_query(\"DROP TABLE IF EXISTS json_test CASCADE\")\n            .execute(conn)\n            .unwrap();\n\n        crate::sql_query(\n            \"CREATE TABLE json_test(id INTEGER PRIMARY KEY, json_field JSON NOT NULL)\",\n        )\n        .execute(conn)\n        .unwrap();\n\n        crate::sql_query(\"INSERT INTO json_test(id, json_field) VALUES (1, '{\\\"key1\\\": \\\"value1\\\", \\\"key2\\\": \\\"value2\\\"}')\").execute(conn).unwrap();\n\n        let json_col_as_json = query_single_table(\n            \"SELECT json_field FROM json_test\",\n            conn,\n            (ffi::enum_field_types::MYSQL_TYPE_JSON, Flags::empty()),\n        );\n\n        assert_eq!(json_col_as_json.tpe, ffi::enum_field_types::MYSQL_TYPE_JSON);\n        assert!(!json_col_as_json.flags.contains(Flags::NUM_FLAG));\n        assert!(!json_col_as_json.flags.contains(Flags::BLOB_FLAG));\n        assert!(!json_col_as_json.flags.contains(Flags::SET_FLAG));\n        assert!(!json_col_as_json.flags.contains(Flags::ENUM_FLAG));\n        assert!(!json_col_as_json.flags.contains(Flags::BINARY_FLAG));\n        assert_eq!(\n            to_value::<Text, String>(&json_col_as_json).unwrap(),\n            \"{\\\"key1\\\": \\\"value1\\\", \\\"key2\\\": \\\"value2\\\"}\"\n        );\n\n        let json_col_as_text = query_single_table(\n            \"SELECT json_field FROM json_test\",\n            conn,\n            (ffi::enum_field_types::MYSQL_TYPE_BLOB, Flags::empty()),\n        );\n\n        assert_eq!(json_col_as_text.tpe, ffi::enum_field_types::MYSQL_TYPE_BLOB);\n        assert!(!json_col_as_text.flags.contains(Flags::NUM_FLAG));\n        assert!(!json_col_as_text.flags.contains(Flags::BLOB_FLAG));\n        assert!(!json_col_as_text.flags.contains(Flags::SET_FLAG));\n        assert!(!json_col_as_text.flags.contains(Flags::ENUM_FLAG));\n        assert!(!json_col_as_text.flags.contains(Flags::BINARY_FLAG));\n        assert_eq!(\n            to_value::<Text, String>(&json_col_as_text).unwrap(),\n            \"{\\\"key1\\\": \\\"value1\\\", \\\"key2\\\": \\\"value2\\\"}\"\n        );\n        assert_eq!(\n            json_col_as_json.value().unwrap().as_bytes(),\n            json_col_as_text.value().unwrap().as_bytes()\n        );\n\n        crate::sql_query(\"DELETE FROM json_test\")\n            .execute(conn)\n            .unwrap();\n\n        input_bind(\n            \"INSERT INTO json_test(id, json_field) VALUES (?, ?)\",\n            conn,\n            41,\n            (\n                b\"{\\\"abc\\\": 42}\".to_vec(),\n                MysqlType::String,\n                //                (ffi::enum_field_types::MYSQL_TYPE_JSON, Flags::empty()),\n            ),\n        );\n\n        let json_col_as_json = query_single_table(\n            \"SELECT json_field FROM json_test\",\n            conn,\n            (ffi::enum_field_types::MYSQL_TYPE_JSON, Flags::empty()),\n        );\n\n        assert_eq!(json_col_as_json.tpe, ffi::enum_field_types::MYSQL_TYPE_JSON);\n        assert!(!json_col_as_json.flags.contains(Flags::NUM_FLAG));\n        assert!(!json_col_as_json.flags.contains(Flags::BLOB_FLAG));\n        assert!(!json_col_as_json.flags.contains(Flags::SET_FLAG));\n        assert!(!json_col_as_json.flags.contains(Flags::ENUM_FLAG));\n        assert!(!json_col_as_json.flags.contains(Flags::BINARY_FLAG));\n        assert_eq!(\n            to_value::<Text, String>(&json_col_as_json).unwrap(),\n            \"{\\\"abc\\\": 42}\"\n        );\n\n        let json_col_as_text = query_single_table(\n            \"SELECT json_field FROM json_test\",\n            conn,\n            (ffi::enum_field_types::MYSQL_TYPE_BLOB, Flags::empty()),\n        );\n\n        assert_eq!(json_col_as_text.tpe, ffi::enum_field_types::MYSQL_TYPE_BLOB);\n        assert!(!json_col_as_text.flags.contains(Flags::NUM_FLAG));\n        assert!(!json_col_as_text.flags.contains(Flags::BLOB_FLAG));\n        assert!(!json_col_as_text.flags.contains(Flags::SET_FLAG));\n        assert!(!json_col_as_text.flags.contains(Flags::ENUM_FLAG));\n        assert!(!json_col_as_text.flags.contains(Flags::BINARY_FLAG));\n        assert_eq!(\n            to_value::<Text, String>(&json_col_as_text).unwrap(),\n            \"{\\\"abc\\\": 42}\"\n        );\n        assert_eq!(\n            json_col_as_json.value().unwrap().as_bytes(),\n            json_col_as_text.value().unwrap().as_bytes()\n        );\n\n        crate::sql_query(\"DELETE FROM json_test\")\n            .execute(conn)\n            .unwrap();\n\n        input_bind(\n            \"INSERT INTO json_test(id, json_field) VALUES (?, ?)\",\n            conn,\n            41,\n            (b\"{\\\"abca\\\": 42}\".to_vec(), MysqlType::String),\n        );\n\n        let json_col_as_json = query_single_table(\n            \"SELECT json_field FROM json_test\",\n            conn,\n            (ffi::enum_field_types::MYSQL_TYPE_JSON, Flags::empty()),\n        );\n\n        assert_eq!(json_col_as_json.tpe, ffi::enum_field_types::MYSQL_TYPE_JSON);\n        assert!(!json_col_as_json.flags.contains(Flags::NUM_FLAG));\n        assert!(!json_col_as_json.flags.contains(Flags::BLOB_FLAG));\n        assert!(!json_col_as_json.flags.contains(Flags::SET_FLAG));\n        assert!(!json_col_as_json.flags.contains(Flags::ENUM_FLAG));\n        assert!(!json_col_as_json.flags.contains(Flags::BINARY_FLAG));\n        assert_eq!(\n            to_value::<Text, String>(&json_col_as_json).unwrap(),\n            \"{\\\"abca\\\": 42}\"\n        );\n\n        let json_col_as_text = query_single_table(\n            \"SELECT json_field FROM json_test\",\n            conn,\n            (ffi::enum_field_types::MYSQL_TYPE_BLOB, Flags::empty()),\n        );\n\n        assert_eq!(json_col_as_text.tpe, ffi::enum_field_types::MYSQL_TYPE_BLOB);\n        assert!(!json_col_as_text.flags.contains(Flags::NUM_FLAG));\n        assert!(!json_col_as_text.flags.contains(Flags::BLOB_FLAG));\n        assert!(!json_col_as_text.flags.contains(Flags::SET_FLAG));\n        assert!(!json_col_as_text.flags.contains(Flags::ENUM_FLAG));\n        assert!(!json_col_as_text.flags.contains(Flags::BINARY_FLAG));\n        assert_eq!(\n            to_value::<Text, String>(&json_col_as_text).unwrap(),\n            \"{\\\"abca\\\": 42}\"\n        );\n        assert_eq!(\n            json_col_as_json.value().unwrap().as_bytes(),\n            json_col_as_text.value().unwrap().as_bytes()\n        );\n    }\n\n    #[test]\n    fn check_enum_bind() {\n        let conn = &mut crate::test_helpers::connection();\n\n        crate::sql_query(\"DROP TABLE IF EXISTS enum_test CASCADE\")\n            .execute(conn)\n            .unwrap();\n\n        crate::sql_query(\"CREATE TABLE enum_test(id INTEGER PRIMARY KEY, enum_field ENUM('red', 'green', 'blue') NOT NULL)\").execute(conn)\n            .unwrap();\n\n        crate::sql_query(\"INSERT INTO enum_test(id, enum_field) VALUES (1, 'green')\")\n            .execute(conn)\n            .unwrap();\n\n        let enum_col_as_enum: BindData =\n            query_single_table(\"SELECT enum_field FROM enum_test\", conn, MysqlType::Enum);\n\n        assert_eq!(\n            enum_col_as_enum.tpe,\n            ffi::enum_field_types::MYSQL_TYPE_STRING\n        );\n        assert!(!enum_col_as_enum.flags.contains(Flags::NUM_FLAG));\n        assert!(!enum_col_as_enum.flags.contains(Flags::BLOB_FLAG));\n        assert!(!enum_col_as_enum.flags.contains(Flags::SET_FLAG));\n        assert!(enum_col_as_enum.flags.contains(Flags::ENUM_FLAG));\n        assert!(!enum_col_as_enum.flags.contains(Flags::BINARY_FLAG));\n        assert_eq!(\n            to_value::<Text, String>(&enum_col_as_enum).unwrap(),\n            \"green\"\n        );\n\n        for tpe in &[\n            ffi::enum_field_types::MYSQL_TYPE_BLOB,\n            ffi::enum_field_types::MYSQL_TYPE_VAR_STRING,\n            ffi::enum_field_types::MYSQL_TYPE_TINY_BLOB,\n            ffi::enum_field_types::MYSQL_TYPE_MEDIUM_BLOB,\n            ffi::enum_field_types::MYSQL_TYPE_LONG_BLOB,\n        ] {\n            let enum_col_as_text = query_single_table(\n                \"SELECT enum_field FROM enum_test\",\n                conn,\n                (*tpe, Flags::ENUM_FLAG),\n            );\n\n            assert_eq!(enum_col_as_text.tpe, *tpe);\n            assert!(!enum_col_as_text.flags.contains(Flags::NUM_FLAG));\n            assert!(!enum_col_as_text.flags.contains(Flags::BLOB_FLAG));\n            assert!(!enum_col_as_text.flags.contains(Flags::SET_FLAG));\n            assert!(enum_col_as_text.flags.contains(Flags::ENUM_FLAG));\n            assert!(!enum_col_as_text.flags.contains(Flags::BINARY_FLAG));\n            assert_eq!(\n                to_value::<Text, String>(&enum_col_as_text).unwrap(),\n                \"green\"\n            );\n            assert_eq!(\n                enum_col_as_enum.value().unwrap().as_bytes(),\n                enum_col_as_text.value().unwrap().as_bytes()\n            );\n        }\n\n        let enum_col_as_text = query_single_table(\n            \"SELECT enum_field FROM enum_test\",\n            conn,\n            (ffi::enum_field_types::MYSQL_TYPE_BLOB, Flags::empty()),\n        );\n\n        assert_eq!(enum_col_as_text.tpe, ffi::enum_field_types::MYSQL_TYPE_BLOB);\n        assert!(!enum_col_as_text.flags.contains(Flags::NUM_FLAG));\n        assert!(!enum_col_as_text.flags.contains(Flags::BLOB_FLAG));\n        assert!(!enum_col_as_text.flags.contains(Flags::SET_FLAG));\n        assert!(!enum_col_as_text.flags.contains(Flags::ENUM_FLAG));\n        assert!(!enum_col_as_text.flags.contains(Flags::BINARY_FLAG));\n        assert_eq!(\n            to_value::<Text, String>(&enum_col_as_text).unwrap(),\n            \"green\"\n        );\n        assert_eq!(\n            enum_col_as_enum.value().unwrap().as_bytes(),\n            enum_col_as_text.value().unwrap().as_bytes()\n        );\n\n        crate::sql_query(\"DELETE FROM enum_test\")\n            .execute(conn)\n            .unwrap();\n\n        input_bind(\n            \"INSERT INTO enum_test(id, enum_field) VALUES (?, ?)\",\n            conn,\n            41,\n            (b\"blue\".to_vec(), MysqlType::Enum),\n        );\n\n        let enum_col_as_enum =\n            query_single_table(\"SELECT enum_field FROM enum_test\", conn, MysqlType::Enum);\n\n        assert_eq!(\n            enum_col_as_enum.tpe,\n            ffi::enum_field_types::MYSQL_TYPE_STRING\n        );\n        assert!(!enum_col_as_enum.flags.contains(Flags::NUM_FLAG));\n        assert!(!enum_col_as_enum.flags.contains(Flags::BLOB_FLAG));\n        assert!(!enum_col_as_enum.flags.contains(Flags::SET_FLAG));\n        assert!(enum_col_as_enum.flags.contains(Flags::ENUM_FLAG));\n        assert!(!enum_col_as_enum.flags.contains(Flags::BINARY_FLAG));\n        assert_eq!(to_value::<Text, String>(&enum_col_as_enum).unwrap(), \"blue\");\n\n        let enum_col_as_text = query_single_table(\n            \"SELECT enum_field FROM enum_test\",\n            conn,\n            (ffi::enum_field_types::MYSQL_TYPE_BLOB, Flags::ENUM_FLAG),\n        );\n\n        assert_eq!(enum_col_as_text.tpe, ffi::enum_field_types::MYSQL_TYPE_BLOB);\n        assert!(!enum_col_as_text.flags.contains(Flags::NUM_FLAG));\n        assert!(!enum_col_as_text.flags.contains(Flags::BLOB_FLAG));\n        assert!(!enum_col_as_text.flags.contains(Flags::SET_FLAG));\n        assert!(enum_col_as_text.flags.contains(Flags::ENUM_FLAG));\n        assert!(!enum_col_as_text.flags.contains(Flags::BINARY_FLAG));\n        assert_eq!(to_value::<Text, String>(&enum_col_as_text).unwrap(), \"blue\");\n        assert_eq!(\n            enum_col_as_enum.value().unwrap().as_bytes(),\n            enum_col_as_text.value().unwrap().as_bytes()\n        );\n\n        let enum_col_as_text = query_single_table(\n            \"SELECT enum_field FROM enum_test\",\n            conn,\n            (ffi::enum_field_types::MYSQL_TYPE_BLOB, Flags::ENUM_FLAG),\n        );\n\n        assert_eq!(enum_col_as_text.tpe, ffi::enum_field_types::MYSQL_TYPE_BLOB);\n        assert!(!enum_col_as_text.flags.contains(Flags::NUM_FLAG));\n        assert!(!enum_col_as_text.flags.contains(Flags::BLOB_FLAG));\n        assert!(!enum_col_as_text.flags.contains(Flags::SET_FLAG));\n        assert!(enum_col_as_text.flags.contains(Flags::ENUM_FLAG));\n        assert!(!enum_col_as_text.flags.contains(Flags::BINARY_FLAG));\n        assert_eq!(to_value::<Text, String>(&enum_col_as_text).unwrap(), \"blue\");\n        assert_eq!(\n            enum_col_as_enum.value().unwrap().as_bytes(),\n            enum_col_as_text.value().unwrap().as_bytes()\n        );\n\n        crate::sql_query(\"DELETE FROM enum_test\")\n            .execute(conn)\n            .unwrap();\n\n        input_bind(\n            \"INSERT INTO enum_test(id, enum_field) VALUES (?, ?)\",\n            conn,\n            41,\n            (\n                b\"red\".to_vec(),\n                (ffi::enum_field_types::MYSQL_TYPE_BLOB, Flags::ENUM_FLAG),\n            ),\n        );\n\n        let enum_col_as_enum =\n            query_single_table(\"SELECT enum_field FROM enum_test\", conn, MysqlType::Enum);\n\n        assert_eq!(\n            enum_col_as_enum.tpe,\n            ffi::enum_field_types::MYSQL_TYPE_STRING\n        );\n        assert!(!enum_col_as_enum.flags.contains(Flags::NUM_FLAG));\n        assert!(!enum_col_as_enum.flags.contains(Flags::BLOB_FLAG));\n        assert!(!enum_col_as_enum.flags.contains(Flags::SET_FLAG));\n        assert!(enum_col_as_enum.flags.contains(Flags::ENUM_FLAG));\n        assert!(!enum_col_as_enum.flags.contains(Flags::BINARY_FLAG));\n        assert_eq!(to_value::<Text, String>(&enum_col_as_enum).unwrap(), \"red\");\n\n        let enum_col_as_text = query_single_table(\n            \"SELECT enum_field FROM enum_test\",\n            conn,\n            (ffi::enum_field_types::MYSQL_TYPE_BLOB, Flags::ENUM_FLAG),\n        );\n\n        assert_eq!(enum_col_as_text.tpe, ffi::enum_field_types::MYSQL_TYPE_BLOB);\n        assert!(!enum_col_as_text.flags.contains(Flags::NUM_FLAG));\n        assert!(!enum_col_as_text.flags.contains(Flags::BLOB_FLAG));\n        assert!(!enum_col_as_text.flags.contains(Flags::SET_FLAG));\n        assert!(enum_col_as_text.flags.contains(Flags::ENUM_FLAG));\n        assert!(!enum_col_as_text.flags.contains(Flags::BINARY_FLAG));\n        assert_eq!(to_value::<Text, String>(&enum_col_as_text).unwrap(), \"red\");\n        assert_eq!(\n            enum_col_as_enum.value().unwrap().as_bytes(),\n            enum_col_as_text.value().unwrap().as_bytes()\n        );\n    }\n\n    #[test]\n    fn check_set_bind() {\n        let conn = &mut crate::test_helpers::connection();\n\n        crate::sql_query(\"DROP TABLE IF EXISTS set_test CASCADE\")\n            .execute(conn)\n            .unwrap();\n\n        crate::sql_query(\"CREATE TABLE set_test(id INTEGER PRIMARY KEY, set_field SET('red', 'green', 'blue') NOT NULL)\").execute(conn)\n            .unwrap();\n\n        crate::sql_query(\"INSERT INTO set_test(id, set_field) VALUES (1, 'green')\")\n            .execute(conn)\n            .unwrap();\n\n        let set_col_as_set: BindData =\n            query_single_table(\"SELECT set_field FROM set_test\", conn, MysqlType::Set);\n\n        assert_eq!(set_col_as_set.tpe, ffi::enum_field_types::MYSQL_TYPE_STRING);\n        assert!(!set_col_as_set.flags.contains(Flags::NUM_FLAG));\n        assert!(!set_col_as_set.flags.contains(Flags::BLOB_FLAG));\n        assert!(set_col_as_set.flags.contains(Flags::SET_FLAG));\n        assert!(!set_col_as_set.flags.contains(Flags::ENUM_FLAG));\n        assert!(!set_col_as_set.flags.contains(Flags::BINARY_FLAG));\n        assert_eq!(to_value::<Text, String>(&set_col_as_set).unwrap(), \"green\");\n\n        for tpe in &[\n            ffi::enum_field_types::MYSQL_TYPE_BLOB,\n            ffi::enum_field_types::MYSQL_TYPE_VAR_STRING,\n            ffi::enum_field_types::MYSQL_TYPE_TINY_BLOB,\n            ffi::enum_field_types::MYSQL_TYPE_MEDIUM_BLOB,\n            ffi::enum_field_types::MYSQL_TYPE_LONG_BLOB,\n        ] {\n            let set_col_as_text = query_single_table(\n                \"SELECT set_field FROM set_test\",\n                conn,\n                (*tpe, Flags::SET_FLAG),\n            );\n\n            assert_eq!(set_col_as_text.tpe, *tpe);\n            assert!(!set_col_as_text.flags.contains(Flags::NUM_FLAG));\n            assert!(!set_col_as_text.flags.contains(Flags::BLOB_FLAG));\n            assert!(set_col_as_text.flags.contains(Flags::SET_FLAG));\n            assert!(!set_col_as_text.flags.contains(Flags::ENUM_FLAG));\n            assert!(!set_col_as_text.flags.contains(Flags::BINARY_FLAG));\n            assert_eq!(to_value::<Text, String>(&set_col_as_text).unwrap(), \"green\");\n            assert_eq!(\n                set_col_as_set.value().unwrap().as_bytes(),\n                set_col_as_text.value().unwrap().as_bytes()\n            );\n        }\n        let set_col_as_text = query_single_table(\n            \"SELECT set_field FROM set_test\",\n            conn,\n            (ffi::enum_field_types::MYSQL_TYPE_BLOB, Flags::empty()),\n        );\n\n        assert_eq!(set_col_as_text.tpe, ffi::enum_field_types::MYSQL_TYPE_BLOB);\n        assert!(!set_col_as_text.flags.contains(Flags::NUM_FLAG));\n        assert!(!set_col_as_text.flags.contains(Flags::BLOB_FLAG));\n        assert!(!set_col_as_text.flags.contains(Flags::SET_FLAG));\n        assert!(!set_col_as_text.flags.contains(Flags::ENUM_FLAG));\n        assert!(!set_col_as_text.flags.contains(Flags::BINARY_FLAG));\n        assert_eq!(to_value::<Text, String>(&set_col_as_text).unwrap(), \"green\");\n        assert_eq!(\n            set_col_as_set.value().unwrap().as_bytes(),\n            set_col_as_text.value().unwrap().as_bytes()\n        );\n\n        crate::sql_query(\"DELETE FROM set_test\")\n            .execute(conn)\n            .unwrap();\n\n        input_bind(\n            \"INSERT INTO set_test(id, set_field) VALUES (?, ?)\",\n            conn,\n            41,\n            (b\"blue\".to_vec(), MysqlType::Set),\n        );\n\n        let set_col_as_set =\n            query_single_table(\"SELECT set_field FROM set_test\", conn, MysqlType::Set);\n\n        assert_eq!(set_col_as_set.tpe, ffi::enum_field_types::MYSQL_TYPE_STRING);\n        assert!(!set_col_as_set.flags.contains(Flags::NUM_FLAG));\n        assert!(!set_col_as_set.flags.contains(Flags::BLOB_FLAG));\n        assert!(set_col_as_set.flags.contains(Flags::SET_FLAG));\n        assert!(!set_col_as_set.flags.contains(Flags::ENUM_FLAG));\n        assert!(!set_col_as_set.flags.contains(Flags::BINARY_FLAG));\n        assert_eq!(to_value::<Text, String>(&set_col_as_set).unwrap(), \"blue\");\n\n        let set_col_as_text = query_single_table(\n            \"SELECT set_field FROM set_test\",\n            conn,\n            (ffi::enum_field_types::MYSQL_TYPE_BLOB, Flags::SET_FLAG),\n        );\n\n        assert_eq!(set_col_as_text.tpe, ffi::enum_field_types::MYSQL_TYPE_BLOB);\n        assert!(!set_col_as_text.flags.contains(Flags::NUM_FLAG));\n        assert!(!set_col_as_text.flags.contains(Flags::BLOB_FLAG));\n        assert!(set_col_as_text.flags.contains(Flags::SET_FLAG));\n        assert!(!set_col_as_text.flags.contains(Flags::ENUM_FLAG));\n        assert!(!set_col_as_text.flags.contains(Flags::BINARY_FLAG));\n        assert_eq!(to_value::<Text, String>(&set_col_as_text).unwrap(), \"blue\");\n        assert_eq!(\n            set_col_as_set.value().unwrap().as_bytes(),\n            set_col_as_text.value().unwrap().as_bytes()\n        );\n\n        crate::sql_query(\"DELETE FROM set_test\")\n            .execute(conn)\n            .unwrap();\n\n        input_bind(\n            \"INSERT INTO set_test(id, set_field) VALUES (?, ?)\",\n            conn,\n            41,\n            (b\"red\".to_vec(), MysqlType::String),\n        );\n\n        let set_col_as_set =\n            query_single_table(\"SELECT set_field FROM set_test\", conn, MysqlType::Set);\n\n        assert_eq!(set_col_as_set.tpe, ffi::enum_field_types::MYSQL_TYPE_STRING);\n        assert!(!set_col_as_set.flags.contains(Flags::NUM_FLAG));\n        assert!(!set_col_as_set.flags.contains(Flags::BLOB_FLAG));\n        assert!(set_col_as_set.flags.contains(Flags::SET_FLAG));\n        assert!(!set_col_as_set.flags.contains(Flags::ENUM_FLAG));\n        assert!(!set_col_as_set.flags.contains(Flags::BINARY_FLAG));\n        assert_eq!(to_value::<Text, String>(&set_col_as_set).unwrap(), \"red\");\n\n        let set_col_as_text = query_single_table(\n            \"SELECT set_field FROM set_test\",\n            conn,\n            (ffi::enum_field_types::MYSQL_TYPE_BLOB, Flags::SET_FLAG),\n        );\n\n        assert_eq!(set_col_as_text.tpe, ffi::enum_field_types::MYSQL_TYPE_BLOB);\n        assert!(!set_col_as_text.flags.contains(Flags::NUM_FLAG));\n        assert!(!set_col_as_text.flags.contains(Flags::BLOB_FLAG));\n        assert!(set_col_as_text.flags.contains(Flags::SET_FLAG));\n        assert!(!set_col_as_text.flags.contains(Flags::ENUM_FLAG));\n        assert!(!set_col_as_text.flags.contains(Flags::BINARY_FLAG));\n        assert_eq!(to_value::<Text, String>(&set_col_as_text).unwrap(), \"red\");\n        assert_eq!(\n            set_col_as_set.value().unwrap().as_bytes(),\n            set_col_as_text.value().unwrap().as_bytes()\n        );\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "d374e793eb28936932b63a741f05d88d86f793ea",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/diesel/src/mysql/connection/stmt/iterator.rs",
    "func": "#![allow(unsafe_code)] // module uses ffi\nuse std::cell::{Ref, RefCell};\nuse std::rc::Rc;\n\nuse super::{OutputBinds, Statement, StatementMetadata, StatementUse};\nuse crate::backend::Backend;\nuse crate::connection::statement_cache::MaybeCached;\nuse crate::mysql::{Mysql, MysqlType};\nuse crate::result::QueryResult;\nuse crate::row::*;\n\n#[allow(missing_debug_implementations)]\npub struct StatementIterator<'a> {\n    stmt: StatementUse<'a>,\n    last_row: Rc<RefCell<PrivateMysqlRow>>,\n    metadata: Rc<StatementMetadata>,\n    len: usize,\n}\n\nimpl<'a> StatementIterator<'a> {\n    pub fn from_stmt(\n        stmt: MaybeCached<'a, Statement>,\n        types: &[Option<MysqlType>],\n    ) -> QueryResult<Self> {\n        let metadata = stmt.metadata()?;\n\n        let mut output_binds = OutputBinds::from_output_types(types, &metadata);\n\n        let mut stmt = stmt.execute_statement(&mut output_binds)?;\n        let size = unsafe { stmt.result_size() }?;\n\n        Ok(StatementIterator {\n            metadata: Rc::new(metadata),\n            last_row: Rc::new(RefCell::new(PrivateMysqlRow::Direct(output_binds))),\n            len: size,\n            stmt,\n        })\n    }\n}\n\nimpl Iterator for StatementIterator<'_> {\n    type Item = QueryResult<MysqlRow>;\n\n    fn next(&mut self) -> Option<Self::Item> {\n        // check if we own the only instance of the bind buffer\n        // if that's the case we can reuse the underlying allocations\n        // if that's not the case, we need to copy the output bind buffers\n        // to somewhere else\n        let res = if let Some(binds) = Rc::get_mut(&mut self.last_row) {\n            if let PrivateMysqlRow::Direct(ref mut binds) = RefCell::get_mut(binds) {\n                self.stmt.populate_row_buffers(binds)\n            } else {\n                // any other state than `PrivateMysqlRow::Direct` is invalid here\n                // and should not happen. If this ever happens this is a logic error\n                // in the code above\n                unreachable!(\n                    \"You've reached an impossible internal state. \\\n                     If you ever see this error message please open \\\n                     an issue at https://github.com/diesel-rs/diesel \\\n                     providing example code how to trigger this error.\"\n                )\n            }\n        } else {\n            // The shared bind buffer is in use by someone else,\n            // this means we copy out the values and replace the used reference\n            // by the copied values. After this we can advance the statement\n            // another step\n            let mut last_row = {\n                let mut last_row = match self.last_row.try_borrow_mut() {\n                    Ok(o) => o,\n                    Err(_e) => {\n                        return Some(Err(crate::result::Error::DeserializationError(\n                            \"Failed to reborrow row. Try to release any `MysqlField` or `MysqlValue` \\\n                             that exists at this point\"\n                                .into(),\n                        )));\n                    }\n                };\n                let last_row = &mut *last_row;\n                let duplicated = last_row.duplicate();\n                std::mem::replace(last_row, duplicated)\n            };\n            let res = if let PrivateMysqlRow::Direct(ref mut binds) = last_row {\n                self.stmt.populate_row_buffers(binds)\n            } else {\n                // any other state than `PrivateMysqlRow::Direct` is invalid here\n                // and should not happen. If this ever happens this is a logic error\n                // in the code above\n                unreachable!(\n                    \"You've reached an impossible internal state. \\\n                     If you ever see this error message please open \\\n                     an issue at https://github.com/diesel-rs/diesel \\\n                     providing example code how to trigger this error.\"\n                )\n            };\n            self.last_row = Rc::new(RefCell::new(last_row));\n            res\n        };\n\n        match res {\n            Ok(Some(())) => {\n                self.len = self.len.saturating_sub(1);\n                Some(Ok(MysqlRow {\n                    metadata: self.metadata.clone(),\n                    row: self.last_row.clone(),\n                }))\n            }\n            Ok(None) => None,\n            Err(e) => {\n                self.len = self.len.saturating_sub(1);\n                Some(Err(e))\n            }\n        }\n    }\n\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        (self.len(), Some(self.len()))\n    }\n\n    fn count(self) -> usize\n    where\n        Self: Sized,\n    {\n        self.len()\n    }\n}\n\nimpl ExactSizeIterator for StatementIterator<'_> {\n    fn len(&self) -> usize {\n        self.len\n    }\n}\n\n#[derive(Clone)]\n#[allow(missing_debug_implementations)]\npub struct MysqlRow {\n    row: Rc<RefCell<PrivateMysqlRow>>,\n    metadata: Rc<StatementMetadata>,\n}\n\nenum PrivateMysqlRow {\n    Direct(OutputBinds),\n    Copied(OutputBinds),\n}\n\nimpl PrivateMysqlRow {\n    fn duplicate(&self) -> Self {\n        match self {\n            Self::Copied(b) | Self::Direct(b) => Self::Copied(b.clone()),\n        }\n    }\n}\n\nimpl RowSealed for MysqlRow {}\n\nimpl<'a> Row<'a, Mysql> for MysqlRow {\n    type Field<'f>\n        = MysqlField<'f>\n    where\n        'a: 'f,\n        Self: 'f;\n    type InnerPartialRow = Self;\n\n    fn field_count(&self) -> usize {\n        self.metadata.fields().len()\n    }\n\n    fn get<'b, I>(&'b self, idx: I) -> Option<Self::Field<'b>>\n    where\n        'a: 'b,\n        Self: RowIndex<I>,\n    {\n        let idx = self.idx(idx)?;\n        Some(MysqlField {\n            binds: self.row.borrow(),\n            metadata: self.metadata.clone(),\n            idx,\n        })\n    }\n\n    fn partial_row(&self, range: std::ops::Range<usize>) -> PartialRow<'_, Self::InnerPartialRow> {\n        PartialRow::new(self, range)\n    }\n}\n\nimpl RowIndex<usize> for MysqlRow {\n    fn idx(&self, idx: usize) -> Option<usize> {\n        if idx < self.field_count() {\n            Some(idx)\n        } else {\n            None\n        }\n    }\n}\n\nimpl<'a> RowIndex<&'a str> for MysqlRow {\n    fn idx(&self, idx: &'a str) -> Option<usize> {\n        self.metadata\n            .fields()\n            .iter()\n            .enumerate()\n            .find(|(_, field_meta)| field_meta.field_name() == Some(idx))\n            .map(|(idx, _)| idx)\n    }\n}\n\n#[allow(missing_debug_implementations)]\npub struct MysqlField<'a> {\n    binds: Ref<'a, PrivateMysqlRow>,\n    metadata: Rc<StatementMetadata>,\n    idx: usize,\n}\n\nimpl<'a> Field<'a, Mysql> for MysqlField<'a> {\n    fn field_name(&self) -> Option<&str> {\n        self.metadata.fields()[self.idx].field_name()\n    }\n\n    fn is_null(&self) -> bool {\n        match &*self.binds {\n            PrivateMysqlRow::Copied(b) | PrivateMysqlRow::Direct(b) => b[self.idx].is_null(),\n        }\n    }\n\n    fn value(&self) -> Option<<Mysql as Backend>::RawValue<'_>> {\n        match &*self.binds {\n            PrivateMysqlRow::Copied(b) | PrivateMysqlRow::Direct(b) => b[self.idx].value(),\n        }\n    }\n}\n\n#[test]\n#[allow(clippy::drop_non_drop)] // we want to explicitly extend lifetimes here\nfn fun_with_row_iters() {\n    crate::table! {\n        users(id) {\n            id -> Integer,\n            name -> Text,\n        }\n    }\n\n    use crate::connection::LoadConnection;\n    use crate::deserialize::{FromSql, FromSqlRow};\n    use crate::prelude::*;\n    use crate::row::{Field, Row};\n    use crate::sql_types;\n\n    let conn = &mut crate::test_helpers::connection();\n\n    crate::sql_query(\n        \"CREATE TEMPORARY TABLE IF NOT EXISTS users(id INTEGER PRIMARY KEY, name TEXT NOT NULL);\",\n    )\n    .execute(conn)\n    .unwrap();\n\n    crate::insert_into(users::table)\n        .values(vec![\n            (users::id.eq(1), users::name.eq(\"Sean\")),\n            (users::id.eq(2), users::name.eq(\"Tess\")),\n        ])\n        .execute(conn)\n        .unwrap();\n\n    let query = users::table.select((users::id, users::name));\n\n    let expected = vec![(1, String::from(\"Sean\")), (2, String::from(\"Tess\"))];\n\n    {\n        let row_iter = conn.load(query).unwrap();\n        for (row, expected) in row_iter.zip(&expected) {\n            let row = row.unwrap();\n\n            let deserialized = <(i32, String) as FromSqlRow<\n                (sql_types::Integer, sql_types::Text),\n                _,\n            >>::build_from_row(&row)\n            .unwrap();\n\n            assert_eq!(&deserialized, expected);\n        }\n    }\n\n    {\n        let collected_rows = conn.load(query).unwrap().collect::<Vec<_>>();\n        assert_eq!(collected_rows.len(), 2);\n        for (row, expected) in collected_rows.iter().zip(&expected) {\n            let deserialized = row\n                .as_ref()\n                .map(|row| {\n                    <(i32, String) as FromSqlRow<\n                            (sql_types::Integer, sql_types::Text),\n                        _,\n                        >>::build_from_row(row).unwrap()\n                })\n                .unwrap();\n            assert_eq!(&deserialized, expected);\n        }\n    }\n\n    let mut row_iter = conn.load(query).unwrap();\n\n    let first_row = row_iter.next().unwrap().unwrap();\n    let first_fields = (\n        Row::get(&first_row, 0).unwrap(),\n        Row::get(&first_row, 1).unwrap(),\n    );\n    let first_values = (first_fields.0.value(), first_fields.1.value());\n\n    assert!(row_iter.next().unwrap().is_err());\n    std::mem::drop(first_values);\n    assert!(row_iter.next().unwrap().is_err());\n    std::mem::drop(first_fields);\n\n    let second_row = row_iter.next().unwrap().unwrap();\n    let second_fields = (\n        Row::get(&second_row, 0).unwrap(),\n        Row::get(&second_row, 1).unwrap(),\n    );\n    let second_values = (second_fields.0.value(), second_fields.1.value());\n\n    assert!(row_iter.next().unwrap().is_err());\n    std::mem::drop(second_values);\n    assert!(row_iter.next().unwrap().is_err());\n    std::mem::drop(second_fields);\n\n    assert!(row_iter.next().is_none());\n\n    let first_fields = (\n        Row::get(&first_row, 0).unwrap(),\n        Row::get(&first_row, 1).unwrap(),\n    );\n    let second_fields = (\n        Row::get(&second_row, 0).unwrap(),\n        Row::get(&second_row, 1).unwrap(),\n    );\n\n    let first_values = (first_fields.0.value(), first_fields.1.value());\n    let second_values = (second_fields.0.value(), second_fields.1.value());\n\n    assert_eq!(\n        <i32 as FromSql<sql_types::Integer, Mysql>>::from_nullable_sql(first_values.0).unwrap(),\n        expected[0].0\n    );\n    assert_eq!(\n        <String as FromSql<sql_types::Text, Mysql>>::from_nullable_sql(first_values.1).unwrap(),\n        expected[0].1\n    );\n\n    assert_eq!(\n        <i32 as FromSql<sql_types::Integer, Mysql>>::from_nullable_sql(second_values.0).unwrap(),\n        expected[1].0\n    );\n    assert_eq!(\n        <String as FromSql<sql_types::Text, Mysql>>::from_nullable_sql(second_values.1).unwrap(),\n        expected[1].1\n    );\n\n    let first_fields = (\n        Row::get(&first_row, 0).unwrap(),\n        Row::get(&first_row, 1).unwrap(),\n    );\n    let first_values = (first_fields.0.value(), first_fields.1.value());\n\n    assert_eq!(\n        <i32 as FromSql<sql_types::Integer, Mysql>>::from_nullable_sql(first_values.0).unwrap(),\n        expected[0].0\n    );\n    assert_eq!(\n        <String as FromSql<sql_types::Text, Mysql>>::from_nullable_sql(first_values.1).unwrap(),\n        expected[0].1\n    );\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "8b9bb2b1824dae7c4b5870ceb160bc2a0390ba6e",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/diesel/src/query_builder/distinct_clause.rs",
    "func": "use crate::backend::DieselReserveSpecialization;\nuse crate::query_builder::*;\nuse crate::query_dsl::order_dsl::ValidOrderingForDistinct;\n\n#[derive(Debug, Clone, Copy, QueryId)]\npub struct NoDistinctClause;\n#[derive(Debug, Clone, Copy, QueryId)]\npub struct DistinctClause;\n\nimpl<DB> QueryFragment<DB> for NoDistinctClause\nwhere\n    DB: Backend + DieselReserveSpecialization,\n{\n    fn walk_ast<'b>(&'b self, _: AstPass<'_, 'b, DB>) -> QueryResult<()> {\n        Ok(())\n    }\n}\n\nimpl<DB> QueryFragment<DB> for DistinctClause\nwhere\n    DB: Backend + DieselReserveSpecialization,\n{\n    fn walk_ast<'b>(&'b self, mut out: AstPass<'_, 'b, DB>) -> QueryResult<()> {\n        out.push_sql(\"DISTINCT \");\n        Ok(())\n    }\n}\n\nimpl<O> ValidOrderingForDistinct<NoDistinctClause> for O {}\nimpl<O> ValidOrderingForDistinct<DistinctClause> for O {}\n\n// This is rexported from another location\n#[allow(unreachable_pub, unused_imports)]\n#[cfg(feature = \"postgres_backend\")]\npub use crate::pg::DistinctOnClause;\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "f99058d6247ed3a7f1584ee1e4e17e20371c1ea9",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/examples/sqlite/getting_started_step_3/src/bin/publish_post.rs",
    "func": "use diesel::prelude::*;\nuse getting_started_step_3_sqlite::models::Post;\nuse getting_started_step_3_sqlite::*;\nuse std::env::args;\n\nfn main() {\n    use getting_started_step_3_sqlite::schema::posts::dsl::{posts, published};\n\n    let id = args()\n        .nth(1)\n        .expect(\"publish_post requires a post id\")\n        .parse::<i32>()\n        .expect(\"Invalid ID\");\n    let connection = &mut establish_connection();\n\n    let post = diesel::update(posts.find(id))\n        .set(published.eq(true))\n        .returning(Post::as_returning())\n        .get_result(connection)\n        .unwrap();\n\n    println!(\"Published post {}\", post.title);\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "c8b0e2d5a1c5b1afac5dbe8de4515f98ce978966",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/examples/postgres/composite_types/examples/composite2rust_coordinates.rs",
    "func": "// Function to connect to database.\nuse composite_types::establish_connection;\n\n// Bring column names of the table into scope\nuse composite_types::schema::coordinates::{coord_id, dsl::coordinates, xcoord, ycoord};\n\n// Define the signature of the SQL function we want to call:\nuse diesel::define_sql_function;\nuse diesel::sql_types::Integer;\ndefine_sql_function!(fn distance_from_origin(re: Integer,im: Integer) -> Float);\ndefine_sql_function!(fn shortest_distance() -> Record<(Integer,Float)>);\ndefine_sql_function!(fn longest_distance() -> Record<(Integer,Float)>);\n\n// Needed to select, construct the query and submit it.\nuse diesel::select;\nuse diesel::{QueryDsl, RunQueryDsl};\n\nfn main() {\n    let connection = &mut establish_connection();\n    // Experiment 1: Read tuple directly from processed table\n    let results: Vec<(i32, f32)> = coordinates\n        .select((coord_id, distance_from_origin(xcoord, ycoord)))\n        .load(connection)\n        .expect(\"Error loading numbers\");\n    for r in results {\n        println!(\"index {:?}, length {:?}\", r.0, r.1);\n    }\n    // Experiment 2: Define a type for clearer re-use\n    type Distance = (i32, f32);\n    let results: Vec<Distance> = coordinates\n        .select((coord_id, distance_from_origin(xcoord, ycoord)))\n        .load(connection)\n        .expect(\"Error loading numbers\");\n    for r in results {\n        println!(\"index {:?}, length {:?}\", r.0, r.1);\n    }\n    // Experiment 3: use tuple for single result and do some math in SQL\n    // Notice that we only expect one result, not an vector\n    // of results, so use get_result() instead of load())\n    let result: Distance = select(shortest_distance())\n        .get_result(connection)\n        .expect(\"Error loading longest distance\");\n    println!(\n        \"Coordinate {:?} has shortest distance of {:?}\",\n        result.0, result.1\n    );\n    // Unfortunately, the members of our Distance struct, a tuple, are anonymous.\n    // Will be unhandy for longer tuples.\n\n    // Experiment 4: use composite type in SQL, read as Record in Rust\n    // Notice that we only expect one result, not an vector\n    // of results, so use get_result() instead of load())\n    let result: Distance = select(longest_distance())\n        .get_result(connection)\n        .expect(\"Error loading longest distance\");\n    println!(\n        \"Coordinate {:?} has longest distance of {:?}\",\n        result.0, result.1\n    );\n    // TODO: also show an example with a recursively interpreted Record<Integer,Record<Integer,Integer>>\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "26e90143faea225771a4200c035cd8d704cc234c",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/diesel/examples/postgres/getting_started_step_3/src/bin/show_posts.rs",
    "func": "use self::models::*;\nuse diesel::prelude::*;\nuse getting_started_step_3_pg::*;\n\nfn main() {\n    use self::schema::posts::dsl::*;\n\n    let connection = &mut establish_connection();\n    let results = posts\n        .filter(published.eq(true))\n        .limit(5)\n        .select(Post::as_select())\n        .load(connection)\n        .expect(\"Error loading posts\");\n\n    println!(\"Displaying {} posts\", results.len());\n    for post in results {\n        println!(\"{}\", post.title);\n        println!(\"-----------\\n\");\n        println!(\"{}\", post.body);\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "c4d6dd69e8045be28f5d93dd0be0afd54ffa4789",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tokio/tests-build/tests/pass/macros_main_loop.rs",
    "func": "use tests_build::tokio;\n\n#[tokio::main]\nasync fn main() -> Result<(), ()> {\n    loop {\n        if !never() {\n            return Ok(());\n        }\n    }\n}\n\nfn never() -> bool {\n    std::time::Instant::now() > std::time::Instant::now()\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "5a08e3619c4da0a59d968e2d95b75e26fd8f15ac",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tokio/tokio-util/tests/length_delimited.rs",
    "func": "#![warn(rust_2018_idioms)]\n\nuse tokio::io::{AsyncRead, AsyncWrite, ReadBuf};\nuse tokio_test::task;\nuse tokio_test::{\n    assert_err, assert_ok, assert_pending, assert_ready, assert_ready_err, assert_ready_ok,\n};\nuse tokio_util::codec::*;\n\nuse bytes::{BufMut, Bytes, BytesMut};\nuse futures::{pin_mut, Sink, Stream};\nuse std::collections::VecDeque;\nuse std::io;\nuse std::pin::Pin;\nuse std::task::{Context, Poll};\n\nmacro_rules! mock {\n    ($($x:expr,)*) => {{\n        let mut v = VecDeque::new();\n        v.extend(vec![$($x),*]);\n        Mock { calls: v }\n    }};\n}\n\nmacro_rules! assert_next_eq {\n    ($io:ident, $expect:expr) => {{\n        task::spawn(()).enter(|cx, _| {\n            let res = assert_ready!($io.as_mut().poll_next(cx));\n            match res {\n                Some(Ok(v)) => assert_eq!(v, $expect.as_ref()),\n                Some(Err(e)) => panic!(\"error = {:?}\", e),\n                None => panic!(\"none\"),\n            }\n        });\n    }};\n}\n\nmacro_rules! assert_next_pending {\n    ($io:ident) => {{\n        task::spawn(()).enter(|cx, _| match $io.as_mut().poll_next(cx) {\n            Poll::Ready(Some(Ok(v))) => panic!(\"value = {:?}\", v),\n            Poll::Ready(Some(Err(e))) => panic!(\"error = {:?}\", e),\n            Poll::Ready(None) => panic!(\"done\"),\n            Poll::Pending => {}\n        });\n    }};\n}\n\nmacro_rules! assert_next_err {\n    ($io:ident) => {{\n        task::spawn(()).enter(|cx, _| match $io.as_mut().poll_next(cx) {\n            Poll::Ready(Some(Ok(v))) => panic!(\"value = {:?}\", v),\n            Poll::Ready(Some(Err(_))) => {}\n            Poll::Ready(None) => panic!(\"done\"),\n            Poll::Pending => panic!(\"pending\"),\n        });\n    }};\n}\n\nmacro_rules! assert_done {\n    ($io:ident) => {{\n        task::spawn(()).enter(|cx, _| {\n            let res = assert_ready!($io.as_mut().poll_next(cx));\n            match res {\n                Some(Ok(v)) => panic!(\"value = {:?}\", v),\n                Some(Err(e)) => panic!(\"error = {:?}\", e),\n                None => {}\n            }\n        });\n    }};\n}\n\n#[test]\nfn read_empty_io_yields_nothing() {\n    let io = Box::pin(FramedRead::new(mock!(), LengthDelimitedCodec::new()));\n    pin_mut!(io);\n\n    assert_done!(io);\n}\n\n#[test]\nfn read_single_frame_one_packet() {\n    let io = FramedRead::new(\n        mock! {\n            data(b\"\\x00\\x00\\x00\\x09abcdefghi\"),\n        },\n        LengthDelimitedCodec::new(),\n    );\n    pin_mut!(io);\n\n    assert_next_eq!(io, b\"abcdefghi\");\n    assert_done!(io);\n}\n\n#[test]\nfn read_single_frame_one_packet_little_endian() {\n    let io = length_delimited::Builder::new()\n        .little_endian()\n        .new_read(mock! {\n            data(b\"\\x09\\x00\\x00\\x00abcdefghi\"),\n        });\n    pin_mut!(io);\n\n    assert_next_eq!(io, b\"abcdefghi\");\n    assert_done!(io);\n}\n\n#[test]\nfn read_single_frame_one_packet_native_endian() {\n    let d = if cfg!(target_endian = \"big\") {\n        b\"\\x00\\x00\\x00\\x09abcdefghi\"\n    } else {\n        b\"\\x09\\x00\\x00\\x00abcdefghi\"\n    };\n    let io = length_delimited::Builder::new()\n        .native_endian()\n        .new_read(mock! {\n            data(d),\n        });\n    pin_mut!(io);\n\n    assert_next_eq!(io, b\"abcdefghi\");\n    assert_done!(io);\n}\n\n#[test]\nfn read_single_multi_frame_one_packet() {\n    let mut d: Vec<u8> = vec![];\n    d.extend_from_slice(b\"\\x00\\x00\\x00\\x09abcdefghi\");\n    d.extend_from_slice(b\"\\x00\\x00\\x00\\x03123\");\n    d.extend_from_slice(b\"\\x00\\x00\\x00\\x0bhello world\");\n\n    let io = FramedRead::new(\n        mock! {\n            data(&d),\n        },\n        LengthDelimitedCodec::new(),\n    );\n    pin_mut!(io);\n\n    assert_next_eq!(io, b\"abcdefghi\");\n    assert_next_eq!(io, b\"123\");\n    assert_next_eq!(io, b\"hello world\");\n    assert_done!(io);\n}\n\n#[test]\nfn read_single_frame_multi_packet() {\n    let io = FramedRead::new(\n        mock! {\n            data(b\"\\x00\\x00\"),\n            data(b\"\\x00\\x09abc\"),\n            data(b\"defghi\"),\n        },\n        LengthDelimitedCodec::new(),\n    );\n    pin_mut!(io);\n\n    assert_next_eq!(io, b\"abcdefghi\");\n    assert_done!(io);\n}\n\n#[test]\nfn read_multi_frame_multi_packet() {\n    let io = FramedRead::new(\n        mock! {\n            data(b\"\\x00\\x00\"),\n            data(b\"\\x00\\x09abc\"),\n            data(b\"defghi\"),\n            data(b\"\\x00\\x00\\x00\\x0312\"),\n            data(b\"3\\x00\\x00\\x00\\x0bhello world\"),\n        },\n        LengthDelimitedCodec::new(),\n    );\n    pin_mut!(io);\n\n    assert_next_eq!(io, b\"abcdefghi\");\n    assert_next_eq!(io, b\"123\");\n    assert_next_eq!(io, b\"hello world\");\n    assert_done!(io);\n}\n\n#[test]\nfn read_single_frame_multi_packet_wait() {\n    let io = FramedRead::new(\n        mock! {\n            data(b\"\\x00\\x00\"),\n            Poll::Pending,\n            data(b\"\\x00\\x09abc\"),\n            Poll::Pending,\n            data(b\"defghi\"),\n            Poll::Pending,\n        },\n        LengthDelimitedCodec::new(),\n    );\n    pin_mut!(io);\n\n    assert_next_pending!(io);\n    assert_next_pending!(io);\n    assert_next_eq!(io, b\"abcdefghi\");\n    assert_next_pending!(io);\n    assert_done!(io);\n}\n\n#[test]\nfn read_multi_frame_multi_packet_wait() {\n    let io = FramedRead::new(\n        mock! {\n            data(b\"\\x00\\x00\"),\n            Poll::Pending,\n            data(b\"\\x00\\x09abc\"),\n            Poll::Pending,\n            data(b\"defghi\"),\n            Poll::Pending,\n            data(b\"\\x00\\x00\\x00\\x0312\"),\n            Poll::Pending,\n            data(b\"3\\x00\\x00\\x00\\x0bhello world\"),\n            Poll::Pending,\n        },\n        LengthDelimitedCodec::new(),\n    );\n    pin_mut!(io);\n\n    assert_next_pending!(io);\n    assert_next_pending!(io);\n    assert_next_eq!(io, b\"abcdefghi\");\n    assert_next_pending!(io);\n    assert_next_pending!(io);\n    assert_next_eq!(io, b\"123\");\n    assert_next_eq!(io, b\"hello world\");\n    assert_next_pending!(io);\n    assert_done!(io);\n}\n\n#[test]\nfn read_incomplete_head() {\n    let io = FramedRead::new(\n        mock! {\n            data(b\"\\x00\\x00\"),\n        },\n        LengthDelimitedCodec::new(),\n    );\n    pin_mut!(io);\n\n    assert_next_err!(io);\n}\n\n#[test]\nfn read_incomplete_head_multi() {\n    let io = FramedRead::new(\n        mock! {\n            Poll::Pending,\n            data(b\"\\x00\"),\n            Poll::Pending,\n        },\n        LengthDelimitedCodec::new(),\n    );\n    pin_mut!(io);\n\n    assert_next_pending!(io);\n    assert_next_pending!(io);\n    assert_next_err!(io);\n}\n\n#[test]\nfn read_incomplete_payload() {\n    let io = FramedRead::new(\n        mock! {\n            data(b\"\\x00\\x00\\x00\\x09ab\"),\n            Poll::Pending,\n            data(b\"cd\"),\n            Poll::Pending,\n        },\n        LengthDelimitedCodec::new(),\n    );\n    pin_mut!(io);\n\n    assert_next_pending!(io);\n    assert_next_pending!(io);\n    assert_next_err!(io);\n}\n\n#[test]\nfn read_max_frame_len() {\n    let io = length_delimited::Builder::new()\n        .max_frame_length(5)\n        .new_read(mock! {\n            data(b\"\\x00\\x00\\x00\\x09abcdefghi\"),\n        });\n    pin_mut!(io);\n\n    assert_next_err!(io);\n}\n\n#[test]\nfn read_update_max_frame_len_at_rest() {\n    let io = length_delimited::Builder::new().new_read(mock! {\n        data(b\"\\x00\\x00\\x00\\x09abcdefghi\"),\n        data(b\"\\x00\\x00\\x00\\x09abcdefghi\"),\n    });\n    pin_mut!(io);\n\n    assert_next_eq!(io, b\"abcdefghi\");\n    io.decoder_mut().set_max_frame_length(5);\n    assert_next_err!(io);\n}\n\n#[test]\nfn read_update_max_frame_len_in_flight() {\n    let io = length_delimited::Builder::new().new_read(mock! {\n        data(b\"\\x00\\x00\\x00\\x09abcd\"),\n        Poll::Pending,\n        data(b\"efghi\"),\n        data(b\"\\x00\\x00\\x00\\x09abcdefghi\"),\n    });\n    pin_mut!(io);\n\n    assert_next_pending!(io);\n    io.decoder_mut().set_max_frame_length(5);\n    assert_next_eq!(io, b\"abcdefghi\");\n    assert_next_err!(io);\n}\n\n#[test]\nfn read_one_byte_length_field() {\n    let io = length_delimited::Builder::new()\n        .length_field_length(1)\n        .new_read(mock! {\n            data(b\"\\x09abcdefghi\"),\n        });\n    pin_mut!(io);\n\n    assert_next_eq!(io, b\"abcdefghi\");\n    assert_done!(io);\n}\n\n#[test]\nfn read_header_offset() {\n    let io = length_delimited::Builder::new()\n        .length_field_length(2)\n        .length_field_offset(4)\n        .new_read(mock! {\n            data(b\"zzzz\\x00\\x09abcdefghi\"),\n        });\n    pin_mut!(io);\n\n    assert_next_eq!(io, b\"abcdefghi\");\n    assert_done!(io);\n}\n\n#[test]\nfn read_single_multi_frame_one_packet_skip_none_adjusted() {\n    let mut d: Vec<u8> = vec![];\n    d.extend_from_slice(b\"xx\\x00\\x09abcdefghi\");\n    d.extend_from_slice(b\"yy\\x00\\x03123\");\n    d.extend_from_slice(b\"zz\\x00\\x0bhello world\");\n\n    let io = length_delimited::Builder::new()\n        .length_field_length(2)\n        .length_field_offset(2)\n        .num_skip(0)\n        .length_adjustment(4)\n        .new_read(mock! {\n            data(&d),\n        });\n    pin_mut!(io);\n\n    assert_next_eq!(io, b\"xx\\x00\\x09abcdefghi\");\n    assert_next_eq!(io, b\"yy\\x00\\x03123\");\n    assert_next_eq!(io, b\"zz\\x00\\x0bhello world\");\n    assert_done!(io);\n}\n\n#[test]\nfn read_single_frame_length_adjusted() {\n    let mut d: Vec<u8> = vec![];\n    d.extend_from_slice(b\"\\x00\\x00\\x0b\\x0cHello world\");\n\n    let io = length_delimited::Builder::new()\n        .length_field_offset(0)\n        .length_field_length(3)\n        .length_adjustment(0)\n        .num_skip(4)\n        .new_read(mock! {\n            data(&d),\n        });\n    pin_mut!(io);\n\n    assert_next_eq!(io, b\"Hello world\");\n    assert_done!(io);\n}\n\n#[test]\nfn read_single_multi_frame_one_packet_length_includes_head() {\n    let mut d: Vec<u8> = vec![];\n    d.extend_from_slice(b\"\\x00\\x0babcdefghi\");\n    d.extend_from_slice(b\"\\x00\\x05123\");\n    d.extend_from_slice(b\"\\x00\\x0dhello world\");\n\n    let io = length_delimited::Builder::new()\n        .length_field_length(2)\n        .length_adjustment(-2)\n        .new_read(mock! {\n            data(&d),\n        });\n    pin_mut!(io);\n\n    assert_next_eq!(io, b\"abcdefghi\");\n    assert_next_eq!(io, b\"123\");\n    assert_next_eq!(io, b\"hello world\");\n    assert_done!(io);\n}\n\n#[test]\nfn write_single_frame_length_adjusted() {\n    let io = length_delimited::Builder::new()\n        .length_adjustment(-2)\n        .new_write(mock! {\n            data(b\"\\x00\\x00\\x00\\x0b\"),\n            data(b\"abcdefghi\"),\n            flush(),\n        });\n    pin_mut!(io);\n\n    task::spawn(()).enter(|cx, _| {\n        assert_ready_ok!(io.as_mut().poll_ready(cx));\n        assert_ok!(io.as_mut().start_send(Bytes::from(\"abcdefghi\")));\n        assert_ready_ok!(io.as_mut().poll_flush(cx));\n        assert!(io.get_ref().calls.is_empty());\n    });\n}\n\n#[test]\nfn write_nothing_yields_nothing() {\n    let io = FramedWrite::new(mock!(), LengthDelimitedCodec::new());\n    pin_mut!(io);\n\n    task::spawn(()).enter(|cx, _| {\n        assert_ready_ok!(io.poll_flush(cx));\n    });\n}\n\n#[test]\nfn write_single_frame_one_packet() {\n    let io = FramedWrite::new(\n        mock! {\n            data(b\"\\x00\\x00\\x00\\x09\"),\n            data(b\"abcdefghi\"),\n            flush(),\n        },\n        LengthDelimitedCodec::new(),\n    );\n    pin_mut!(io);\n\n    task::spawn(()).enter(|cx, _| {\n        assert_ready_ok!(io.as_mut().poll_ready(cx));\n        assert_ok!(io.as_mut().start_send(Bytes::from(\"abcdefghi\")));\n        assert_ready_ok!(io.as_mut().poll_flush(cx));\n        assert!(io.get_ref().calls.is_empty());\n    });\n}\n\n#[test]\nfn write_single_multi_frame_one_packet() {\n    let io = FramedWrite::new(\n        mock! {\n            data(b\"\\x00\\x00\\x00\\x09\"),\n            data(b\"abcdefghi\"),\n            data(b\"\\x00\\x00\\x00\\x03\"),\n            data(b\"123\"),\n            data(b\"\\x00\\x00\\x00\\x0b\"),\n            data(b\"hello world\"),\n            flush(),\n        },\n        LengthDelimitedCodec::new(),\n    );\n    pin_mut!(io);\n\n    task::spawn(()).enter(|cx, _| {\n        assert_ready_ok!(io.as_mut().poll_ready(cx));\n        assert_ok!(io.as_mut().start_send(Bytes::from(\"abcdefghi\")));\n\n        assert_ready_ok!(io.as_mut().poll_ready(cx));\n        assert_ok!(io.as_mut().start_send(Bytes::from(\"123\")));\n\n        assert_ready_ok!(io.as_mut().poll_ready(cx));\n        assert_ok!(io.as_mut().start_send(Bytes::from(\"hello world\")));\n\n        assert_ready_ok!(io.as_mut().poll_flush(cx));\n        assert!(io.get_ref().calls.is_empty());\n    });\n}\n\n#[test]\nfn write_single_multi_frame_multi_packet() {\n    let io = FramedWrite::new(\n        mock! {\n            data(b\"\\x00\\x00\\x00\\x09\"),\n            data(b\"abcdefghi\"),\n            flush(),\n            data(b\"\\x00\\x00\\x00\\x03\"),\n            data(b\"123\"),\n            flush(),\n            data(b\"\\x00\\x00\\x00\\x0b\"),\n            data(b\"hello world\"),\n            flush(),\n        },\n        LengthDelimitedCodec::new(),\n    );\n    pin_mut!(io);\n\n    task::spawn(()).enter(|cx, _| {\n        assert_ready_ok!(io.as_mut().poll_ready(cx));\n        assert_ok!(io.as_mut().start_send(Bytes::from(\"abcdefghi\")));\n\n        assert_ready_ok!(io.as_mut().poll_flush(cx));\n\n        assert_ready_ok!(io.as_mut().poll_ready(cx));\n        assert_ok!(io.as_mut().start_send(Bytes::from(\"123\")));\n\n        assert_ready_ok!(io.as_mut().poll_flush(cx));\n\n        assert_ready_ok!(io.as_mut().poll_ready(cx));\n        assert_ok!(io.as_mut().start_send(Bytes::from(\"hello world\")));\n\n        assert_ready_ok!(io.as_mut().poll_flush(cx));\n        assert!(io.get_ref().calls.is_empty());\n    });\n}\n\n#[test]\nfn write_single_frame_would_block() {\n    let io = FramedWrite::new(\n        mock! {\n            Poll::Pending,\n            data(b\"\\x00\\x00\"),\n            Poll::Pending,\n            data(b\"\\x00\\x09\"),\n            data(b\"abcdefghi\"),\n            flush(),\n        },\n        LengthDelimitedCodec::new(),\n    );\n    pin_mut!(io);\n\n    task::spawn(()).enter(|cx, _| {\n        assert_ready_ok!(io.as_mut().poll_ready(cx));\n        assert_ok!(io.as_mut().start_send(Bytes::from(\"abcdefghi\")));\n\n        assert_pending!(io.as_mut().poll_flush(cx));\n        assert_pending!(io.as_mut().poll_flush(cx));\n        assert_ready_ok!(io.as_mut().poll_flush(cx));\n\n        assert!(io.get_ref().calls.is_empty());\n    });\n}\n\n#[test]\nfn write_single_frame_little_endian() {\n    let io = length_delimited::Builder::new()\n        .little_endian()\n        .new_write(mock! {\n            data(b\"\\x09\\x00\\x00\\x00\"),\n            data(b\"abcdefghi\"),\n            flush(),\n        });\n    pin_mut!(io);\n\n    task::spawn(()).enter(|cx, _| {\n        assert_ready_ok!(io.as_mut().poll_ready(cx));\n        assert_ok!(io.as_mut().start_send(Bytes::from(\"abcdefghi\")));\n\n        assert_ready_ok!(io.as_mut().poll_flush(cx));\n        assert!(io.get_ref().calls.is_empty());\n    });\n}\n\n#[test]\nfn write_single_frame_with_short_length_field() {\n    let io = length_delimited::Builder::new()\n        .length_field_length(1)\n        .new_write(mock! {\n            data(b\"\\x09\"),\n            data(b\"abcdefghi\"),\n            flush(),\n        });\n    pin_mut!(io);\n\n    task::spawn(()).enter(|cx, _| {\n        assert_ready_ok!(io.as_mut().poll_ready(cx));\n        assert_ok!(io.as_mut().start_send(Bytes::from(\"abcdefghi\")));\n\n        assert_ready_ok!(io.as_mut().poll_flush(cx));\n\n        assert!(io.get_ref().calls.is_empty());\n    });\n}\n\n#[test]\nfn write_max_frame_len() {\n    let io = length_delimited::Builder::new()\n        .max_frame_length(5)\n        .new_write(mock! {});\n    pin_mut!(io);\n\n    task::spawn(()).enter(|cx, _| {\n        assert_ready_ok!(io.as_mut().poll_ready(cx));\n        assert_err!(io.as_mut().start_send(Bytes::from(\"abcdef\")));\n\n        assert!(io.get_ref().calls.is_empty());\n    });\n}\n\n#[test]\nfn write_update_max_frame_len_at_rest() {\n    let io = length_delimited::Builder::new().new_write(mock! {\n        data(b\"\\x00\\x00\\x00\\x06\"),\n        data(b\"abcdef\"),\n        flush(),\n    });\n    pin_mut!(io);\n\n    task::spawn(()).enter(|cx, _| {\n        assert_ready_ok!(io.as_mut().poll_ready(cx));\n        assert_ok!(io.as_mut().start_send(Bytes::from(\"abcdef\")));\n\n        assert_ready_ok!(io.as_mut().poll_flush(cx));\n\n        io.encoder_mut().set_max_frame_length(5);\n\n        assert_err!(io.as_mut().start_send(Bytes::from(\"abcdef\")));\n\n        assert!(io.get_ref().calls.is_empty());\n    });\n}\n\n#[test]\nfn write_update_max_frame_len_in_flight() {\n    let io = length_delimited::Builder::new().new_write(mock! {\n        data(b\"\\x00\\x00\\x00\\x06\"),\n        data(b\"ab\"),\n        Poll::Pending,\n        data(b\"cdef\"),\n        flush(),\n    });\n    pin_mut!(io);\n\n    task::spawn(()).enter(|cx, _| {\n        assert_ready_ok!(io.as_mut().poll_ready(cx));\n        assert_ok!(io.as_mut().start_send(Bytes::from(\"abcdef\")));\n\n        assert_pending!(io.as_mut().poll_flush(cx));\n\n        io.encoder_mut().set_max_frame_length(5);\n\n        assert_ready_ok!(io.as_mut().poll_flush(cx));\n\n        assert_err!(io.as_mut().start_send(Bytes::from(\"abcdef\")));\n        assert!(io.get_ref().calls.is_empty());\n    });\n}\n\n#[test]\nfn write_zero() {\n    let io = length_delimited::Builder::new().new_write(mock! {});\n    pin_mut!(io);\n\n    task::spawn(()).enter(|cx, _| {\n        assert_ready_ok!(io.as_mut().poll_ready(cx));\n        assert_ok!(io.as_mut().start_send(Bytes::from(\"abcdef\")));\n\n        assert_ready_err!(io.as_mut().poll_flush(cx));\n\n        assert!(io.get_ref().calls.is_empty());\n    });\n}\n\n#[test]\nfn encode_overflow() {\n    // Test reproducing tokio-rs/tokio#681.\n    let mut codec = length_delimited::Builder::new().new_codec();\n    let mut buf = BytesMut::with_capacity(1024);\n\n    // Put some data into the buffer without resizing it to hold more.\n    let some_as = std::iter::repeat(b'a').take(1024).collect::<Vec<_>>();\n    buf.put_slice(&some_as[..]);\n\n    // Trying to encode the length header should resize the buffer if it won't fit.\n    codec.encode(Bytes::from(\"hello\"), &mut buf).unwrap();\n}\n\n#[test]\nfn frame_does_not_fit() {\n    let codec = LengthDelimitedCodec::builder()\n        .length_field_length(1)\n        .max_frame_length(256)\n        .new_codec();\n\n    assert_eq!(codec.max_frame_length(), 255);\n}\n\n#[test]\nfn neg_adjusted_frame_does_not_fit() {\n    let codec = LengthDelimitedCodec::builder()\n        .length_field_length(1)\n        .length_adjustment(-1)\n        .new_codec();\n\n    assert_eq!(codec.max_frame_length(), 254);\n}\n\n#[test]\nfn pos_adjusted_frame_does_not_fit() {\n    let codec = LengthDelimitedCodec::builder()\n        .length_field_length(1)\n        .length_adjustment(1)\n        .new_codec();\n\n    assert_eq!(codec.max_frame_length(), 256);\n}\n\n#[test]\nfn max_allowed_frame_fits() {\n    let codec = LengthDelimitedCodec::builder()\n        .length_field_length(std::mem::size_of::<usize>())\n        .max_frame_length(usize::MAX)\n        .new_codec();\n\n    assert_eq!(codec.max_frame_length(), usize::MAX);\n}\n\n#[test]\nfn smaller_frame_len_not_adjusted() {\n    let codec = LengthDelimitedCodec::builder()\n        .max_frame_length(10)\n        .length_field_length(std::mem::size_of::<usize>())\n        .new_codec();\n\n    assert_eq!(codec.max_frame_length(), 10);\n}\n\n#[test]\nfn max_allowed_length_field() {\n    let codec = LengthDelimitedCodec::builder()\n        .length_field_length(8)\n        .max_frame_length(usize::MAX)\n        .new_codec();\n\n    assert_eq!(codec.max_frame_length(), usize::MAX);\n}\n\n// ===== Test utils =====\n\nstruct Mock {\n    calls: VecDeque<Poll<io::Result<Op>>>,\n}\n\nenum Op {\n    Data(Vec<u8>),\n    Flush,\n}\n\nimpl AsyncRead for Mock {\n    fn poll_read(\n        mut self: Pin<&mut Self>,\n        _cx: &mut Context<'_>,\n        dst: &mut ReadBuf<'_>,\n    ) -> Poll<io::Result<()>> {\n        match self.calls.pop_front() {\n            Some(Poll::Ready(Ok(Op::Data(data)))) => {\n                debug_assert!(dst.remaining() >= data.len());\n                dst.put_slice(&data);\n                Poll::Ready(Ok(()))\n            }\n            Some(Poll::Ready(Ok(_))) => panic!(),\n            Some(Poll::Ready(Err(e))) => Poll::Ready(Err(e)),\n            Some(Poll::Pending) => Poll::Pending,\n            None => Poll::Ready(Ok(())),\n        }\n    }\n}\n\nimpl AsyncWrite for Mock {\n    fn poll_write(\n        mut self: Pin<&mut Self>,\n        _cx: &mut Context<'_>,\n        src: &[u8],\n    ) -> Poll<Result<usize, io::Error>> {\n        match self.calls.pop_front() {\n            Some(Poll::Ready(Ok(Op::Data(data)))) => {\n                let len = data.len();\n                assert!(src.len() >= len, \"expect={data:?}; actual={src:?}\");\n                assert_eq!(&data[..], &src[..len]);\n                Poll::Ready(Ok(len))\n            }\n            Some(Poll::Ready(Ok(_))) => panic!(),\n            Some(Poll::Ready(Err(e))) => Poll::Ready(Err(e)),\n            Some(Poll::Pending) => Poll::Pending,\n            None => Poll::Ready(Ok(0)),\n        }\n    }\n\n    fn poll_flush(mut self: Pin<&mut Self>, _cx: &mut Context<'_>) -> Poll<Result<(), io::Error>> {\n        match self.calls.pop_front() {\n            Some(Poll::Ready(Ok(Op::Flush))) => Poll::Ready(Ok(())),\n            Some(Poll::Ready(Ok(_))) => panic!(),\n            Some(Poll::Ready(Err(e))) => Poll::Ready(Err(e)),\n            Some(Poll::Pending) => Poll::Pending,\n            None => Poll::Ready(Ok(())),\n        }\n    }\n\n    fn poll_shutdown(self: Pin<&mut Self>, _cx: &mut Context<'_>) -> Poll<Result<(), io::Error>> {\n        Poll::Ready(Ok(()))\n    }\n}\n\nimpl<'a> From<&'a [u8]> for Op {\n    fn from(src: &'a [u8]) -> Op {\n        Op::Data(src.into())\n    }\n}\n\nimpl From<Vec<u8>> for Op {\n    fn from(src: Vec<u8>) -> Op {\n        Op::Data(src)\n    }\n}\n\nfn data(bytes: &[u8]) -> Poll<io::Result<Op>> {\n    Poll::Ready(Ok(bytes.into()))\n}\n\nfn flush() -> Poll<io::Result<Op>> {\n    Poll::Ready(Ok(Op::Flush))\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "e37e3615bcb7ea6933a0677856eff055e15b1751",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tokio/tokio-util/tests/compat.rs",
    "func": "#![cfg(feature = \"compat\")]\n#![cfg(not(target_os = \"wasi\"))] // WASI does not support all fs operations\n#![warn(rust_2018_idioms)]\n\nuse futures_io::SeekFrom;\nuse futures_util::{AsyncReadExt, AsyncSeekExt, AsyncWriteExt};\nuse tempfile::NamedTempFile;\nuse tokio::fs::OpenOptions;\nuse tokio_util::compat::TokioAsyncWriteCompatExt;\n\n#[tokio::test]\nasync fn compat_file_seek() -> futures_util::io::Result<()> {\n    let temp_file = NamedTempFile::new()?;\n    let mut file = OpenOptions::new()\n        .read(true)\n        .write(true)\n        .create(true)\n        .truncate(true)\n        .open(temp_file)\n        .await?\n        .compat_write();\n\n    file.write_all(&[0, 1, 2, 3, 4, 5]).await?;\n    file.write_all(&[6, 7]).await?;\n\n    assert_eq!(file.stream_position().await?, 8);\n\n    // Modify elements at position 2.\n    assert_eq!(file.seek(SeekFrom::Start(2)).await?, 2);\n    file.write_all(&[8, 9]).await?;\n\n    file.flush().await?;\n\n    // Verify we still have 8 elements.\n    assert_eq!(file.seek(SeekFrom::End(0)).await?, 8);\n    // Seek back to the start of the file to read and verify contents.\n    file.seek(SeekFrom::Start(0)).await?;\n\n    let mut buf = Vec::new();\n    let num_bytes = file.read_to_end(&mut buf).await?;\n    assert_eq!(&buf[..num_bytes], &[0, 1, 8, 9, 4, 5, 6, 7]);\n\n    Ok(())\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "e5533041abe4272fb47866008168df2e75e52b63",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tokio/tokio-util/src/sync/mod.rs",
    "func": "//! Synchronization primitives\n\nmod cancellation_token;\npub use cancellation_token::{\n    guard::DropGuard, CancellationToken, WaitForCancellationFuture, WaitForCancellationFutureOwned,\n};\n\nmod mpsc;\npub use mpsc::{PollSendError, PollSender};\n\nmod poll_semaphore;\npub use poll_semaphore::PollSemaphore;\n\nmod reusable_box;\npub use reusable_box::ReusableBoxFuture;\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "b11afdd8173d66fd2de23ee90316f9dcd80702e2",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tokio/tests-integration/src/bin/test-mem.rs",
    "func": "use std::future::poll_fn;\n\nfn main() {\n    let rt = tokio::runtime::Builder::new_multi_thread()\n        .worker_threads(1)\n        .enable_io()\n        .build()\n        .unwrap();\n\n    rt.block_on(async {\n        let listener = tokio::net::TcpListener::bind(\"0.0.0.0:0\").await.unwrap();\n        tokio::spawn(async move {\n            loop {\n                poll_fn(|cx| listener.poll_accept(cx)).await.unwrap();\n            }\n        });\n    });\n\n    std::thread::sleep(std::time::Duration::from_millis(50));\n    drop(rt);\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "31b83437233ab27e54fe11a6e8965b62aca2c4b7",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tokio/tokio/tests/signal_multi_rt.rs",
    "func": "#![warn(rust_2018_idioms)]\n#![cfg(feature = \"full\")]\n#![cfg(unix)]\n#![cfg(not(miri))] // No `sigaction` on Miri.\n\nmod support {\n    pub mod signal;\n}\nuse support::signal::send_signal;\n\nuse tokio::runtime::Runtime;\nuse tokio::signal::unix::{signal, SignalKind};\n\nuse std::sync::mpsc::channel;\nuse std::thread;\n\n#[test]\nfn multi_loop() {\n    // An \"ordinary\" (non-future) channel\n    let (sender, receiver) = channel();\n    // Run multiple times, to make sure there are no race conditions\n    for _ in 0..10 {\n        // Run multiple event loops, each one in its own thread\n        let threads: Vec<_> = (0..4)\n            .map(|_| {\n                let sender = sender.clone();\n                thread::spawn(move || {\n                    let rt = rt();\n                    let _ = rt.block_on(async {\n                        let mut signal = signal(SignalKind::hangup()).unwrap();\n                        sender.send(()).unwrap();\n                        signal.recv().await\n                    });\n                })\n            })\n            .collect();\n        // Wait for them to declare they're ready\n        for &_ in threads.iter() {\n            receiver.recv().unwrap();\n        }\n        // Send a signal\n        send_signal(libc::SIGHUP);\n        // Make sure the threads terminated correctly\n        for t in threads {\n            t.join().unwrap();\n        }\n    }\n}\n\nfn rt() -> Runtime {\n    tokio::runtime::Builder::new_current_thread()\n        .enable_all()\n        .build()\n        .unwrap()\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "a643df4db0142e9d596f80734ad6fe2e9faeb058",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tokio/tokio/tests/io_sink.rs",
    "func": "#![warn(rust_2018_idioms)]\n#![cfg(feature = \"full\")]\n\nuse tokio::io::AsyncWriteExt;\n\n#[tokio::test]\nasync fn sink_poll_write_is_cooperative() {\n    tokio::select! {\n        biased;\n        _ = async {\n            loop {\n                let buf = vec![1, 2, 3];\n                tokio::io::sink().write_all(&buf).await.unwrap();\n            }\n        } => {},\n        _ = tokio::task::yield_now() => {}\n    }\n}\n\n#[tokio::test]\nasync fn sink_poll_flush_is_cooperative() {\n    tokio::select! {\n        biased;\n        _ = async {\n            loop {\n                tokio::io::sink().flush().await.unwrap();\n            }\n        } => {},\n        _ = tokio::task::yield_now() => {}\n    }\n}\n\n#[tokio::test]\nasync fn sink_poll_shutdown_is_cooperative() {\n    tokio::select! {\n        biased;\n        _ = async {\n            loop {\n                tokio::io::sink().shutdown().await.unwrap();\n            }\n        } => {},\n        _ = tokio::task::yield_now() => {}\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "bb76ae1487a7c52bd114ca79e901854127a5e04a",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tokio/tokio/tests/sync_mpsc.rs",
    "func": "#![allow(clippy::redundant_clone)]\n#![warn(rust_2018_idioms)]\n#![cfg(feature = \"sync\")]\n\n#[cfg(all(target_family = \"wasm\", not(target_os = \"wasi\")))]\nuse wasm_bindgen_test::wasm_bindgen_test as test;\n#[cfg(all(target_family = \"wasm\", not(target_os = \"wasi\")))]\nuse wasm_bindgen_test::wasm_bindgen_test as maybe_tokio_test;\n\n#[cfg(not(all(target_family = \"wasm\", not(target_os = \"wasi\"))))]\nuse tokio::test as maybe_tokio_test;\n\nuse std::fmt;\nuse std::panic;\nuse std::sync::Arc;\nuse tokio::sync::mpsc;\nuse tokio::sync::mpsc::error::{TryRecvError, TrySendError};\nuse tokio_test::*;\n\n#[cfg(not(target_family = \"wasm\"))]\nmod support {\n    pub(crate) mod mpsc_stream;\n}\n\n#[allow(unused)]\ntrait AssertRefUnwindSafe: panic::RefUnwindSafe {}\nimpl<T> AssertRefUnwindSafe for mpsc::OwnedPermit<T> {}\nimpl<'a, T> AssertRefUnwindSafe for mpsc::Permit<'a, T> {}\nimpl<'a, T> AssertRefUnwindSafe for mpsc::PermitIterator<'a, T> {}\nimpl<T> AssertRefUnwindSafe for mpsc::Receiver<T> {}\nimpl<T> AssertRefUnwindSafe for mpsc::Sender<T> {}\nimpl<T> AssertRefUnwindSafe for mpsc::UnboundedReceiver<T> {}\nimpl<T> AssertRefUnwindSafe for mpsc::UnboundedSender<T> {}\nimpl<T> AssertRefUnwindSafe for mpsc::WeakSender<T> {}\nimpl<T> AssertRefUnwindSafe for mpsc::WeakUnboundedSender<T> {}\n\n#[allow(unused)]\ntrait AssertUnwindSafe: panic::UnwindSafe {}\nimpl<T> AssertUnwindSafe for mpsc::OwnedPermit<T> {}\nimpl<'a, T> AssertUnwindSafe for mpsc::Permit<'a, T> {}\nimpl<'a, T> AssertUnwindSafe for mpsc::PermitIterator<'a, T> {}\nimpl<T> AssertUnwindSafe for mpsc::Receiver<T> {}\nimpl<T> AssertUnwindSafe for mpsc::Sender<T> {}\nimpl<T> AssertUnwindSafe for mpsc::UnboundedReceiver<T> {}\nimpl<T> AssertUnwindSafe for mpsc::UnboundedSender<T> {}\nimpl<T> AssertUnwindSafe for mpsc::WeakSender<T> {}\nimpl<T> AssertUnwindSafe for mpsc::WeakUnboundedSender<T> {}\n\n#[maybe_tokio_test]\nasync fn send_recv_with_buffer() {\n    let (tx, mut rx) = mpsc::channel::<i32>(16);\n\n    // Using poll_ready / try_send\n    // let permit assert_ready_ok!(tx.reserve());\n    let permit = tx.reserve().await.unwrap();\n    permit.send(1);\n\n    // Without poll_ready\n    tx.try_send(2).unwrap();\n\n    drop(tx);\n\n    let val = rx.recv().await;\n    assert_eq!(val, Some(1));\n\n    let val = rx.recv().await;\n    assert_eq!(val, Some(2));\n\n    let val = rx.recv().await;\n    assert!(val.is_none());\n}\n\n#[tokio::test]\n#[cfg(feature = \"full\")]\nasync fn reserve_disarm() {\n    let (tx, mut rx) = mpsc::channel::<i32>(2);\n    let tx1 = tx.clone();\n    let tx2 = tx.clone();\n    let tx3 = tx.clone();\n    let tx4 = tx;\n\n    // We should be able to `poll_ready` two handles without problem\n    let permit1 = assert_ok!(tx1.reserve().await);\n    let permit2 = assert_ok!(tx2.reserve().await);\n\n    // But a third should not be ready\n    let mut r3 = tokio_test::task::spawn(tx3.reserve());\n    assert_pending!(r3.poll());\n\n    let mut r4 = tokio_test::task::spawn(tx4.reserve());\n    assert_pending!(r4.poll());\n\n    // Using one of the reserved slots should allow a new handle to become ready\n    permit1.send(1);\n\n    // We also need to receive for the slot to be free\n    assert!(!r3.is_woken());\n    rx.recv().await.unwrap();\n    // Now there's a free slot!\n    assert!(r3.is_woken());\n    assert!(!r4.is_woken());\n\n    // Dropping a permit should also open up a slot\n    drop(permit2);\n    assert!(r4.is_woken());\n\n    let mut r1 = tokio_test::task::spawn(tx1.reserve());\n    assert_pending!(r1.poll());\n}\n\n#[tokio::test]\n#[cfg(all(feature = \"full\", not(target_os = \"wasi\")))] // Wasi doesn't support threads\nasync fn send_recv_stream_with_buffer() {\n    use tokio_stream::StreamExt;\n\n    let (tx, rx) = support::mpsc_stream::channel_stream::<i32>(16);\n    let mut rx = Box::pin(rx);\n\n    tokio::spawn(async move {\n        assert_ok!(tx.send(1).await);\n        assert_ok!(tx.send(2).await);\n    });\n\n    assert_eq!(Some(1), rx.next().await);\n    assert_eq!(Some(2), rx.next().await);\n    assert_eq!(None, rx.next().await);\n}\n\n#[tokio::test]\n#[cfg(feature = \"full\")]\nasync fn async_send_recv_with_buffer() {\n    let (tx, mut rx) = mpsc::channel(16);\n\n    tokio::spawn(async move {\n        assert_ok!(tx.send(1).await);\n        assert_ok!(tx.send(2).await);\n    });\n\n    assert_eq!(Some(1), rx.recv().await);\n    assert_eq!(Some(2), rx.recv().await);\n    assert_eq!(None, rx.recv().await);\n}\n\n#[tokio::test]\n#[cfg(feature = \"full\")]\nasync fn async_send_recv_many_with_buffer() {\n    let (tx, mut rx) = mpsc::channel(2);\n    let mut buffer = Vec::<i32>::with_capacity(3);\n\n    // With `limit=0` does not sleep, returns immediately\n    assert_eq!(0, rx.recv_many(&mut buffer, 0).await);\n\n    let handle = tokio::spawn(async move {\n        assert_ok!(tx.send(1).await);\n        assert_ok!(tx.send(2).await);\n        assert_ok!(tx.send(7).await);\n        assert_ok!(tx.send(0).await);\n    });\n\n    let limit = 3;\n    let mut recv_count = 0usize;\n    while recv_count < 4 {\n        recv_count += rx.recv_many(&mut buffer, limit).await;\n        assert_eq!(buffer.len(), recv_count);\n    }\n\n    assert_eq!(vec![1, 2, 7, 0], buffer);\n    assert_eq!(0, rx.recv_many(&mut buffer, limit).await);\n    handle.await.unwrap();\n}\n\n#[tokio::test]\n#[cfg(feature = \"full\")]\nasync fn start_send_past_cap() {\n    use std::future::Future;\n\n    let mut t1 = tokio_test::task::spawn(());\n\n    let (tx1, mut rx) = mpsc::channel(1);\n    let tx2 = tx1.clone();\n\n    assert_ok!(tx1.try_send(()));\n\n    let mut r1 = Box::pin(tx1.reserve());\n    t1.enter(|cx, _| assert_pending!(r1.as_mut().poll(cx)));\n\n    {\n        let mut r2 = tokio_test::task::spawn(tx2.reserve());\n        assert_pending!(r2.poll());\n\n        drop(r1);\n\n        assert!(rx.recv().await.is_some());\n\n        assert!(r2.is_woken());\n        assert!(!t1.is_woken());\n    }\n\n    drop(tx1);\n    drop(tx2);\n\n    assert!(rx.recv().await.is_none());\n}\n\n#[test]\n#[should_panic]\n#[cfg(not(target_family = \"wasm\"))] // wasm currently doesn't support unwinding\nfn buffer_gteq_one() {\n    mpsc::channel::<i32>(0);\n}\n\n#[maybe_tokio_test]\nasync fn send_recv_unbounded() {\n    let (tx, mut rx) = mpsc::unbounded_channel::<i32>();\n\n    // Using `try_send`\n    assert_ok!(tx.send(1));\n    assert_ok!(tx.send(2));\n\n    assert_eq!(rx.recv().await, Some(1));\n    assert_eq!(rx.recv().await, Some(2));\n\n    drop(tx);\n\n    assert!(rx.recv().await.is_none());\n}\n\n#[maybe_tokio_test]\nasync fn send_recv_many_unbounded() {\n    let (tx, mut rx) = mpsc::unbounded_channel::<i32>();\n\n    let mut buffer: Vec<i32> = Vec::new();\n\n    // With `limit=0` does not sleep, returns immediately\n    rx.recv_many(&mut buffer, 0).await;\n    assert_eq!(0, buffer.len());\n\n    assert_ok!(tx.send(7));\n    assert_ok!(tx.send(13));\n    assert_ok!(tx.send(100));\n    assert_ok!(tx.send(1002));\n\n    rx.recv_many(&mut buffer, 0).await;\n    assert_eq!(0, buffer.len());\n\n    let mut count = 0;\n    while count < 4 {\n        count += rx.recv_many(&mut buffer, 1).await;\n    }\n    assert_eq!(count, 4);\n    assert_eq!(vec![7, 13, 100, 1002], buffer);\n    let final_capacity = buffer.capacity();\n    assert!(final_capacity > 0);\n\n    buffer.clear();\n\n    assert_ok!(tx.send(5));\n    assert_ok!(tx.send(6));\n    assert_ok!(tx.send(7));\n    assert_ok!(tx.send(2));\n\n    // Re-use existing capacity\n    count = rx.recv_many(&mut buffer, 32).await;\n\n    assert_eq!(final_capacity, buffer.capacity());\n    assert_eq!(count, 4);\n    assert_eq!(vec![5, 6, 7, 2], buffer);\n\n    drop(tx);\n\n    // recv_many will immediately return zero if the channel\n    // is closed and no more messages are waiting\n    assert_eq!(0, rx.recv_many(&mut buffer, 4).await);\n    assert!(rx.recv().await.is_none());\n}\n\n#[tokio::test]\n#[cfg(feature = \"full\")]\nasync fn send_recv_many_bounded_capacity() {\n    let mut buffer: Vec<String> = Vec::with_capacity(9);\n    let limit = buffer.capacity();\n    let (tx, mut rx) = mpsc::channel(100);\n\n    let mut expected: Vec<String> = (0..limit)\n        .map(|x: usize| format!(\"{x}\"))\n        .collect::<Vec<_>>();\n    for x in expected.clone() {\n        tx.send(x).await.unwrap()\n    }\n    tx.send(\"one more\".to_string()).await.unwrap();\n\n    // Here `recv_many` receives all but the last value;\n    // the initial capacity is adequate, so the buffer does\n    // not increase in side.\n    assert_eq!(buffer.capacity(), rx.recv_many(&mut buffer, limit).await);\n    assert_eq!(expected, buffer);\n    assert_eq!(limit, buffer.capacity());\n\n    // Receive up more values:\n    assert_eq!(1, rx.recv_many(&mut buffer, limit).await);\n    assert!(buffer.capacity() > limit);\n    expected.push(\"one more\".to_string());\n    assert_eq!(expected, buffer);\n\n    tokio::spawn(async move {\n        tx.send(\"final\".to_string()).await.unwrap();\n    });\n\n    // 'tx' is dropped, but `recv_many` is guaranteed not\n    // to return 0 as the channel has outstanding permits\n    assert_eq!(1, rx.recv_many(&mut buffer, limit).await);\n    expected.push(\"final\".to_string());\n    assert_eq!(expected, buffer);\n    // The channel is now closed and `recv_many` returns 0.\n    assert_eq!(0, rx.recv_many(&mut buffer, limit).await);\n    assert_eq!(expected, buffer);\n}\n\n#[tokio::test]\n#[cfg(feature = \"full\")]\nasync fn send_recv_many_unbounded_capacity() {\n    let mut buffer: Vec<String> = Vec::with_capacity(9); // capacity >= 9\n    let limit = buffer.capacity();\n    let (tx, mut rx) = mpsc::unbounded_channel();\n\n    let mut expected: Vec<String> = (0..limit)\n        .map(|x: usize| format!(\"{x}\"))\n        .collect::<Vec<_>>();\n    for x in expected.clone() {\n        tx.send(x).unwrap()\n    }\n    tx.send(\"one more\".to_string()).unwrap();\n\n    // Here `recv_many` receives all but the last value;\n    // the initial capacity is adequate, so the buffer does\n    // not increase in side.\n    assert_eq!(buffer.capacity(), rx.recv_many(&mut buffer, limit).await);\n    assert_eq!(expected, buffer);\n    assert_eq!(limit, buffer.capacity());\n\n    // Receive up more values:\n    assert_eq!(1, rx.recv_many(&mut buffer, limit).await);\n    assert!(buffer.capacity() > limit);\n    expected.push(\"one more\".to_string());\n    assert_eq!(expected, buffer);\n\n    tokio::spawn(async move {\n        tx.send(\"final\".to_string()).unwrap();\n    });\n\n    // 'tx' is dropped, but `recv_many` is guaranteed not\n    // to return 0 as the channel has outstanding permits\n    assert_eq!(1, rx.recv_many(&mut buffer, limit).await);\n    expected.push(\"final\".to_string());\n    assert_eq!(expected, buffer);\n    // The channel is now closed and `recv_many` returns 0.\n    assert_eq!(0, rx.recv_many(&mut buffer, limit).await);\n    assert_eq!(expected, buffer);\n}\n\n#[tokio::test]\n#[cfg(feature = \"full\")]\nasync fn async_send_recv_unbounded() {\n    let (tx, mut rx) = mpsc::unbounded_channel();\n\n    tokio::spawn(async move {\n        assert_ok!(tx.send(1));\n        assert_ok!(tx.send(2));\n    });\n\n    assert_eq!(Some(1), rx.recv().await);\n    assert_eq!(Some(2), rx.recv().await);\n    assert_eq!(None, rx.recv().await);\n}\n\n#[tokio::test]\n#[cfg(all(feature = \"full\", not(target_os = \"wasi\")))] // Wasi doesn't support threads\nasync fn send_recv_stream_unbounded() {\n    use tokio_stream::StreamExt;\n\n    let (tx, rx) = support::mpsc_stream::unbounded_channel_stream::<i32>();\n\n    let mut rx = Box::pin(rx);\n\n    tokio::spawn(async move {\n        assert_ok!(tx.send(1));\n        assert_ok!(tx.send(2));\n    });\n\n    assert_eq!(Some(1), rx.next().await);\n    assert_eq!(Some(2), rx.next().await);\n    assert_eq!(None, rx.next().await);\n}\n\n#[maybe_tokio_test]\nasync fn no_t_bounds_buffer() {\n    struct NoImpls;\n\n    let (tx, mut rx) = mpsc::channel(100);\n\n    // sender should be Debug even though T isn't Debug\n    is_debug(&tx);\n    // same with Receiver\n    is_debug(&rx);\n    // and sender should be Clone even though T isn't Clone\n    assert!(tx.clone().try_send(NoImpls).is_ok());\n\n    assert!(rx.recv().await.is_some());\n}\n\n#[maybe_tokio_test]\nasync fn no_t_bounds_unbounded() {\n    struct NoImpls;\n\n    let (tx, mut rx) = mpsc::unbounded_channel();\n\n    // sender should be Debug even though T isn't Debug\n    is_debug(&tx);\n    // same with Receiver\n    is_debug(&rx);\n    // and sender should be Clone even though T isn't Clone\n    assert!(tx.clone().send(NoImpls).is_ok());\n\n    assert!(rx.recv().await.is_some());\n}\n\n#[tokio::test]\n#[cfg(feature = \"full\")]\nasync fn send_recv_buffer_limited() {\n    let (tx, mut rx) = mpsc::channel::<i32>(1);\n\n    // Reserve capacity\n    let p1 = assert_ok!(tx.reserve().await);\n\n    // Send first message\n    p1.send(1);\n\n    // Not ready\n    let mut p2 = tokio_test::task::spawn(tx.reserve());\n    assert_pending!(p2.poll());\n\n    // Take the value\n    assert!(rx.recv().await.is_some());\n\n    // Notified\n    assert!(p2.is_woken());\n\n    // Trying to send fails\n    assert_err!(tx.try_send(1337));\n\n    // Send second\n    let permit = assert_ready_ok!(p2.poll());\n    permit.send(2);\n\n    assert!(rx.recv().await.is_some());\n}\n\n#[maybe_tokio_test]\nasync fn recv_close_gets_none_idle() {\n    let (tx, mut rx) = mpsc::channel::<i32>(10);\n\n    rx.close();\n\n    assert!(rx.recv().await.is_none());\n\n    assert_err!(tx.send(1).await);\n}\n\n#[tokio::test]\n#[cfg(feature = \"full\")]\nasync fn recv_close_gets_none_reserved() {\n    let (tx1, mut rx) = mpsc::channel::<i32>(1);\n    let tx2 = tx1.clone();\n\n    let permit1 = assert_ok!(tx1.reserve().await);\n    let mut permit2 = tokio_test::task::spawn(tx2.reserve());\n    assert_pending!(permit2.poll());\n\n    rx.close();\n\n    assert!(permit2.is_woken());\n    assert_ready_err!(permit2.poll());\n\n    {\n        let mut recv = tokio_test::task::spawn(rx.recv());\n        assert_pending!(recv.poll());\n\n        permit1.send(123);\n        assert!(recv.is_woken());\n\n        let v = assert_ready!(recv.poll());\n        assert_eq!(v, Some(123));\n    }\n\n    assert!(rx.recv().await.is_none());\n}\n\n#[maybe_tokio_test]\nasync fn tx_close_gets_none() {\n    let (_, mut rx) = mpsc::channel::<i32>(10);\n    assert!(rx.recv().await.is_none());\n}\n\n#[maybe_tokio_test]\nasync fn try_send_fail() {\n    let (tx, mut rx) = mpsc::channel(1);\n\n    tx.try_send(\"hello\").unwrap();\n\n    // This should fail\n    match assert_err!(tx.try_send(\"fail\")) {\n        TrySendError::Full(..) => {}\n        _ => panic!(),\n    }\n\n    assert_eq!(rx.recv().await, Some(\"hello\"));\n\n    assert_ok!(tx.try_send(\"goodbye\"));\n    drop(tx);\n\n    assert_eq!(rx.recv().await, Some(\"goodbye\"));\n    assert!(rx.recv().await.is_none());\n}\n\n#[maybe_tokio_test]\nasync fn try_send_fail_with_try_recv() {\n    let (tx, mut rx) = mpsc::channel(1);\n\n    tx.try_send(\"hello\").unwrap();\n\n    // This should fail\n    match assert_err!(tx.try_send(\"fail\")) {\n        TrySendError::Full(..) => {}\n        _ => panic!(),\n    }\n\n    assert_eq!(rx.try_recv(), Ok(\"hello\"));\n\n    assert_ok!(tx.try_send(\"goodbye\"));\n    drop(tx);\n\n    assert_eq!(rx.try_recv(), Ok(\"goodbye\"));\n    assert_eq!(rx.try_recv(), Err(TryRecvError::Disconnected));\n}\n\n#[maybe_tokio_test]\nasync fn reserve_many_above_cap() {\n    const MAX_PERMITS: usize = tokio::sync::Semaphore::MAX_PERMITS;\n    let (tx, _rx) = mpsc::channel::<()>(1);\n\n    assert_err!(tx.reserve_many(2).await);\n    assert_err!(tx.reserve_many(MAX_PERMITS + 1).await);\n    assert_err!(tx.reserve_many(usize::MAX).await);\n}\n\n#[test]\nfn try_reserve_many_zero() {\n    let (tx, rx) = mpsc::channel::<()>(1);\n\n    // Succeeds when not closed.\n    assert!(assert_ok!(tx.try_reserve_many(0)).next().is_none());\n\n    // Even when channel is full.\n    tx.try_send(()).unwrap();\n    assert!(assert_ok!(tx.try_reserve_many(0)).next().is_none());\n\n    drop(rx);\n\n    // Closed error when closed.\n    assert_eq!(\n        assert_err!(tx.try_reserve_many(0)),\n        TrySendError::Closed(())\n    );\n}\n\n#[maybe_tokio_test]\nasync fn reserve_many_zero() {\n    let (tx, rx) = mpsc::channel::<()>(1);\n\n    // Succeeds when not closed.\n    assert!(assert_ok!(tx.reserve_many(0).await).next().is_none());\n\n    // Even when channel is full.\n    tx.send(()).await.unwrap();\n    assert!(assert_ok!(tx.reserve_many(0).await).next().is_none());\n\n    drop(rx);\n\n    // Closed error when closed.\n    assert_err!(tx.reserve_many(0).await);\n}\n\n#[maybe_tokio_test]\nasync fn try_reserve_many_edge_cases() {\n    const MAX_PERMITS: usize = tokio::sync::Semaphore::MAX_PERMITS;\n\n    let (tx, rx) = mpsc::channel::<()>(1);\n\n    let mut permit = assert_ok!(tx.try_reserve_many(0));\n    assert!(permit.next().is_none());\n\n    let permit = tx.try_reserve_many(MAX_PERMITS + 1);\n    match assert_err!(permit) {\n        TrySendError::Full(..) => {}\n        _ => panic!(),\n    }\n\n    let permit = tx.try_reserve_many(usize::MAX);\n    match assert_err!(permit) {\n        TrySendError::Full(..) => {}\n        _ => panic!(),\n    }\n\n    // Dropping the receiver should close the channel\n    drop(rx);\n    assert_err!(tx.reserve_many(0).await);\n}\n\n#[maybe_tokio_test]\nasync fn try_reserve_fails() {\n    let (tx, mut rx) = mpsc::channel(1);\n\n    let permit = tx.try_reserve().unwrap();\n\n    // This should fail\n    match assert_err!(tx.try_reserve()) {\n        TrySendError::Full(()) => {}\n        _ => panic!(),\n    }\n\n    permit.send(\"foo\");\n\n    assert_eq!(rx.recv().await, Some(\"foo\"));\n\n    // Dropping permit releases the slot.\n    let permit = tx.try_reserve().unwrap();\n    drop(permit);\n\n    let _permit = tx.try_reserve().unwrap();\n}\n\n#[maybe_tokio_test]\nasync fn reserve_many_and_send() {\n    let (tx, mut rx) = mpsc::channel(100);\n    for i in 0..100 {\n        for permit in assert_ok!(tx.reserve_many(i).await) {\n            permit.send(\"foo\");\n            assert_eq!(rx.recv().await, Some(\"foo\"));\n        }\n        assert_eq!(rx.try_recv(), Err(TryRecvError::Empty));\n    }\n}\n#[maybe_tokio_test]\nasync fn try_reserve_many_and_send() {\n    let (tx, mut rx) = mpsc::channel(100);\n    for i in 0..100 {\n        for permit in assert_ok!(tx.try_reserve_many(i)) {\n            permit.send(\"foo\");\n            assert_eq!(rx.recv().await, Some(\"foo\"));\n        }\n        assert_eq!(rx.try_recv(), Err(TryRecvError::Empty));\n    }\n}\n\n#[maybe_tokio_test]\nasync fn reserve_many_on_closed_channel() {\n    let (tx, rx) = mpsc::channel::<()>(100);\n    drop(rx);\n    assert_err!(tx.reserve_many(10).await);\n}\n\n#[maybe_tokio_test]\nasync fn try_reserve_many_on_closed_channel() {\n    let (tx, rx) = mpsc::channel::<usize>(100);\n    drop(rx);\n    match assert_err!(tx.try_reserve_many(10)) {\n        TrySendError::Closed(()) => {}\n        _ => panic!(),\n    };\n}\n\n#[maybe_tokio_test]\n#[cfg_attr(miri, ignore)] // Too slow on miri.\nasync fn try_reserve_many_full() {\n    // Reserve n capacity and send k messages\n    for n in 1..100 {\n        for k in 0..n {\n            let (tx, mut rx) = mpsc::channel::<usize>(n);\n            let permits = assert_ok!(tx.try_reserve_many(n));\n\n            assert_eq!(permits.len(), n);\n            assert_eq!(tx.capacity(), 0);\n\n            match assert_err!(tx.try_reserve_many(1)) {\n                TrySendError::Full(..) => {}\n                _ => panic!(),\n            };\n\n            for permit in permits.take(k) {\n                permit.send(0);\n            }\n            // We only used k permits on the n reserved\n            assert_eq!(tx.capacity(), n - k);\n\n            // We can reserve more permits\n            assert_ok!(tx.try_reserve_many(1));\n\n            // But not more than the current capacity\n            match assert_err!(tx.try_reserve_many(n - k + 1)) {\n                TrySendError::Full(..) => {}\n                _ => panic!(),\n            };\n\n            for _i in 0..k {\n                assert_eq!(rx.recv().await, Some(0));\n            }\n\n            // Now that we've received everything, capacity should be back to n\n            assert_eq!(tx.capacity(), n);\n        }\n    }\n}\n\n#[tokio::test]\n#[cfg(feature = \"full\")]\nasync fn drop_permit_releases_permit() {\n    // poll_ready reserves capacity, ensure that the capacity is released if tx\n    // is dropped w/o sending a value.\n    let (tx1, _rx) = mpsc::channel::<i32>(1);\n    let tx2 = tx1.clone();\n\n    let permit = assert_ok!(tx1.reserve().await);\n\n    let mut reserve2 = tokio_test::task::spawn(tx2.reserve());\n    assert_pending!(reserve2.poll());\n\n    drop(permit);\n\n    assert!(reserve2.is_woken());\n    assert_ready_ok!(reserve2.poll());\n}\n\n#[maybe_tokio_test]\nasync fn drop_permit_iterator_releases_permits() {\n    // poll_ready reserves capacity, ensure that the capacity is released if tx\n    // is dropped w/o sending a value.\n    for n in 1..100 {\n        let (tx1, _rx) = mpsc::channel::<i32>(n);\n        let tx2 = tx1.clone();\n\n        let permits = assert_ok!(tx1.reserve_many(n).await);\n\n        let mut reserve2 = tokio_test::task::spawn(tx2.reserve_many(n));\n        assert_pending!(reserve2.poll());\n\n        drop(permits);\n\n        assert!(reserve2.is_woken());\n\n        let permits = assert_ready_ok!(reserve2.poll());\n        drop(permits);\n\n        assert_eq!(tx1.capacity(), n);\n    }\n}\n\n#[maybe_tokio_test]\nasync fn dropping_rx_closes_channel() {\n    let (tx, rx) = mpsc::channel(100);\n\n    let msg = Arc::new(());\n    assert_ok!(tx.try_send(msg.clone()));\n\n    drop(rx);\n    assert_err!(tx.reserve().await);\n    assert_err!(tx.reserve_many(10).await);\n    assert_eq!(1, Arc::strong_count(&msg));\n}\n\n#[test]\nfn dropping_rx_closes_channel_for_try() {\n    let (tx, rx) = mpsc::channel(100);\n\n    let msg = Arc::new(());\n    tx.try_send(msg.clone()).unwrap();\n\n    drop(rx);\n\n    assert!(matches!(\n        tx.try_send(msg.clone()),\n        Err(TrySendError::Closed(_))\n    ));\n    assert!(matches!(tx.try_reserve(), Err(TrySendError::Closed(_))));\n    assert!(matches!(\n        tx.try_reserve_owned(),\n        Err(TrySendError::Closed(_))\n    ));\n\n    assert_eq!(1, Arc::strong_count(&msg));\n}\n\n#[test]\nfn unconsumed_messages_are_dropped() {\n    let msg = Arc::new(());\n\n    let (tx, rx) = mpsc::channel(100);\n\n    tx.try_send(msg.clone()).unwrap();\n\n    assert_eq!(2, Arc::strong_count(&msg));\n\n    drop((tx, rx));\n\n    assert_eq!(1, Arc::strong_count(&msg));\n}\n\n#[test]\n#[cfg(all(feature = \"full\", not(target_os = \"wasi\")))] // Wasi doesn't support threads\nfn blocking_recv() {\n    let (tx, mut rx) = mpsc::channel::<u8>(1);\n\n    let sync_code = std::thread::spawn(move || {\n        assert_eq!(Some(10), rx.blocking_recv());\n    });\n\n    tokio::runtime::Runtime::new()\n        .unwrap()\n        .block_on(async move {\n            let _ = tx.send(10).await;\n        });\n    sync_code.join().unwrap()\n}\n\n#[tokio::test]\n#[should_panic]\n#[cfg(not(target_family = \"wasm\"))] // wasm currently doesn't support unwinding\nasync fn blocking_recv_async() {\n    let (_tx, mut rx) = mpsc::channel::<()>(1);\n    let _ = rx.blocking_recv();\n}\n\n#[test]\n#[cfg(all(feature = \"full\", not(target_os = \"wasi\")))] // Wasi doesn't support threads\nfn blocking_send() {\n    let (tx, mut rx) = mpsc::channel::<u8>(1);\n\n    let sync_code = std::thread::spawn(move || {\n        tx.blocking_send(10).unwrap();\n    });\n\n    tokio::runtime::Runtime::new()\n        .unwrap()\n        .block_on(async move {\n            assert_eq!(Some(10), rx.recv().await);\n        });\n    sync_code.join().unwrap()\n}\n\n#[tokio::test]\n#[should_panic]\n#[cfg(not(target_family = \"wasm\"))] // wasm currently doesn't support unwinding\nasync fn blocking_send_async() {\n    let (tx, _rx) = mpsc::channel::<()>(1);\n    let _ = tx.blocking_send(());\n}\n\n#[tokio::test]\n#[cfg(feature = \"full\")]\nasync fn ready_close_cancel_bounded() {\n    let (tx, mut rx) = mpsc::channel::<()>(100);\n    let _tx2 = tx.clone();\n\n    let permit = assert_ok!(tx.reserve().await);\n\n    rx.close();\n\n    let mut recv = tokio_test::task::spawn(rx.recv());\n    assert_pending!(recv.poll());\n\n    drop(permit);\n\n    assert!(recv.is_woken());\n    let val = assert_ready!(recv.poll());\n    assert!(val.is_none());\n}\n\n#[tokio::test]\n#[cfg(feature = \"full\")]\nasync fn permit_available_not_acquired_close() {\n    let (tx1, mut rx) = mpsc::channel::<()>(1);\n    let tx2 = tx1.clone();\n\n    let permit1 = assert_ok!(tx1.reserve().await);\n\n    let mut permit2 = tokio_test::task::spawn(tx2.reserve());\n    assert_pending!(permit2.poll());\n\n    rx.close();\n\n    drop(permit1);\n    assert!(permit2.is_woken());\n\n    drop(permit2);\n    assert!(rx.recv().await.is_none());\n}\n\n#[test]\nfn try_recv_bounded() {\n    let (tx, mut rx) = mpsc::channel(5);\n\n    tx.try_send(\"hello\").unwrap();\n    tx.try_send(\"hello\").unwrap();\n    tx.try_send(\"hello\").unwrap();\n    tx.try_send(\"hello\").unwrap();\n    tx.try_send(\"hello\").unwrap();\n    assert!(tx.try_send(\"hello\").is_err());\n\n    assert_eq!(Ok(\"hello\"), rx.try_recv());\n    assert_eq!(Ok(\"hello\"), rx.try_recv());\n    assert_eq!(Ok(\"hello\"), rx.try_recv());\n    assert_eq!(Ok(\"hello\"), rx.try_recv());\n    assert_eq!(Ok(\"hello\"), rx.try_recv());\n    assert_eq!(Err(TryRecvError::Empty), rx.try_recv());\n\n    tx.try_send(\"hello\").unwrap();\n    tx.try_send(\"hello\").unwrap();\n    tx.try_send(\"hello\").unwrap();\n    tx.try_send(\"hello\").unwrap();\n    assert_eq!(Ok(\"hello\"), rx.try_recv());\n    tx.try_send(\"hello\").unwrap();\n    tx.try_send(\"hello\").unwrap();\n    assert!(tx.try_send(\"hello\").is_err());\n    assert_eq!(Ok(\"hello\"), rx.try_recv());\n    assert_eq!(Ok(\"hello\"), rx.try_recv());\n    assert_eq!(Ok(\"hello\"), rx.try_recv());\n    assert_eq!(Ok(\"hello\"), rx.try_recv());\n    assert_eq!(Ok(\"hello\"), rx.try_recv());\n    assert_eq!(Err(TryRecvError::Empty), rx.try_recv());\n\n    tx.try_send(\"hello\").unwrap();\n    tx.try_send(\"hello\").unwrap();\n    tx.try_send(\"hello\").unwrap();\n    drop(tx);\n    assert_eq!(Ok(\"hello\"), rx.try_recv());\n    assert_eq!(Ok(\"hello\"), rx.try_recv());\n    assert_eq!(Ok(\"hello\"), rx.try_recv());\n    assert_eq!(Err(TryRecvError::Disconnected), rx.try_recv());\n}\n\n#[test]\nfn try_recv_unbounded() {\n    for num in 0..100 {\n        let (tx, mut rx) = mpsc::unbounded_channel();\n\n        for i in 0..num {\n            tx.send(i).unwrap();\n        }\n\n        for i in 0..num {\n            assert_eq!(rx.try_recv(), Ok(i));\n        }\n\n        assert_eq!(rx.try_recv(), Err(TryRecvError::Empty));\n        drop(tx);\n        assert_eq!(rx.try_recv(), Err(TryRecvError::Disconnected));\n    }\n}\n\n#[test]\nfn try_recv_close_while_empty_bounded() {\n    let (tx, mut rx) = mpsc::channel::<()>(5);\n\n    assert_eq!(Err(TryRecvError::Empty), rx.try_recv());\n    drop(tx);\n    assert_eq!(Err(TryRecvError::Disconnected), rx.try_recv());\n}\n\n#[test]\nfn try_recv_close_while_empty_unbounded() {\n    let (tx, mut rx) = mpsc::unbounded_channel::<()>();\n\n    assert_eq!(Err(TryRecvError::Empty), rx.try_recv());\n    drop(tx);\n    assert_eq!(Err(TryRecvError::Disconnected), rx.try_recv());\n}\n\n#[tokio::test(start_paused = true)]\n#[cfg(feature = \"full\")]\nasync fn recv_timeout() {\n    use tokio::sync::mpsc::error::SendTimeoutError::{Closed, Timeout};\n    use tokio::time::Duration;\n\n    let (tx, rx) = mpsc::channel(5);\n\n    assert_eq!(tx.send_timeout(10, Duration::from_secs(1)).await, Ok(()));\n    assert_eq!(tx.send_timeout(20, Duration::from_secs(1)).await, Ok(()));\n    assert_eq!(tx.send_timeout(30, Duration::from_secs(1)).await, Ok(()));\n    assert_eq!(tx.send_timeout(40, Duration::from_secs(1)).await, Ok(()));\n    assert_eq!(tx.send_timeout(50, Duration::from_secs(1)).await, Ok(()));\n    assert_eq!(\n        tx.send_timeout(60, Duration::from_secs(1)).await,\n        Err(Timeout(60))\n    );\n\n    drop(rx);\n    assert_eq!(\n        tx.send_timeout(70, Duration::from_secs(1)).await,\n        Err(Closed(70))\n    );\n}\n\n#[test]\n#[should_panic = \"there is no reactor running, must be called from the context of a Tokio 1.x runtime\"]\n#[cfg(not(target_family = \"wasm\"))] // wasm currently doesn't support unwinding\nfn recv_timeout_panic() {\n    use futures::future::FutureExt;\n    use tokio::time::Duration;\n\n    let (tx, _rx) = mpsc::channel(5);\n    tx.send_timeout(10, Duration::from_secs(1)).now_or_never();\n}\n\n// Tests that channel `capacity` changes and `max_capacity` stays the same\n#[tokio::test]\nasync fn test_tx_capacity() {\n    let (tx, _rx) = mpsc::channel::<()>(10);\n    // both capacities are same before\n    assert_eq!(tx.capacity(), 10);\n    assert_eq!(tx.max_capacity(), 10);\n\n    let _permit = tx.reserve().await.unwrap();\n    // after reserve, only capacity should drop by one\n    assert_eq!(tx.capacity(), 9);\n    assert_eq!(tx.max_capacity(), 10);\n\n    tx.send(()).await.unwrap();\n    // after send, capacity should drop by one again\n    assert_eq!(tx.capacity(), 8);\n    assert_eq!(tx.max_capacity(), 10);\n}\n\n#[tokio::test]\nasync fn test_rx_is_closed_when_calling_close_with_sender() {\n    // is_closed should return true after calling close but still has a sender\n    let (_tx, mut rx) = mpsc::channel::<()>(10);\n    rx.close();\n\n    assert!(rx.is_closed());\n}\n\n#[tokio::test]\nasync fn test_rx_is_closed_when_dropping_all_senders() {\n    // is_closed should return true after dropping all senders\n    let (tx, rx) = mpsc::channel::<()>(10);\n    let another_tx = tx.clone();\n    let task = tokio::spawn(async move {\n        drop(another_tx);\n    });\n\n    drop(tx);\n    let _ = task.await;\n\n    assert!(rx.is_closed());\n}\n\n#[tokio::test]\nasync fn test_rx_is_not_closed_when_there_are_senders() {\n    // is_closed should return false when there is a sender\n    let (_tx, rx) = mpsc::channel::<()>(10);\n    assert!(!rx.is_closed());\n}\n\n#[tokio::test]\nasync fn test_rx_is_not_closed_when_there_are_senders_and_buffer_filled() {\n    // is_closed should return false when there is a sender, even if enough messages have been sent to fill the channel\n    let (tx, rx) = mpsc::channel(10);\n    for i in 0..10 {\n        assert!(tx.send(i).await.is_ok());\n    }\n    assert!(!rx.is_closed());\n}\n\n#[tokio::test]\nasync fn test_rx_is_closed_when_there_are_no_senders_and_there_are_messages() {\n    // is_closed should return true when there are messages in the buffer, but no senders\n    let (tx, rx) = mpsc::channel(10);\n    for i in 0..10 {\n        assert!(tx.send(i).await.is_ok());\n    }\n    drop(tx);\n    assert!(rx.is_closed());\n}\n\n#[tokio::test]\nasync fn test_rx_is_closed_when_there_are_messages_and_close_is_called() {\n    // is_closed should return true when there are messages in the buffer, and close is called\n    let (tx, mut rx) = mpsc::channel(10);\n    for i in 0..10 {\n        assert!(tx.send(i).await.is_ok());\n    }\n    rx.close();\n    assert!(rx.is_closed());\n}\n\n#[tokio::test]\nasync fn test_rx_is_not_closed_when_there_are_permits_but_not_senders() {\n    // is_closed should return false when there is a permit (but no senders)\n    let (tx, rx) = mpsc::channel::<()>(10);\n    let _permit = tx.reserve_owned().await.expect(\"Failed to reserve permit\");\n    assert!(!rx.is_closed());\n}\n\n#[tokio::test]\nasync fn test_rx_is_empty_when_no_messages_were_sent() {\n    let (_tx, rx) = mpsc::channel::<()>(10);\n    assert!(rx.is_empty())\n}\n\n#[tokio::test]\nasync fn test_rx_is_not_empty_when_there_are_messages_in_the_buffer() {\n    let (tx, rx) = mpsc::channel::<()>(10);\n    assert!(tx.send(()).await.is_ok());\n    assert!(!rx.is_empty())\n}\n\n#[tokio::test]\nasync fn test_rx_is_not_empty_when_the_buffer_is_full() {\n    let (tx, rx) = mpsc::channel(10);\n    for i in 0..10 {\n        assert!(tx.send(i).await.is_ok());\n    }\n    assert!(!rx.is_empty())\n}\n\n#[tokio::test]\nasync fn test_rx_is_not_empty_when_all_but_one_messages_are_consumed() {\n    let (tx, mut rx) = mpsc::channel(10);\n    for i in 0..10 {\n        assert!(tx.send(i).await.is_ok());\n    }\n\n    for _ in 0..9 {\n        assert!(rx.recv().await.is_some());\n    }\n\n    assert!(!rx.is_empty())\n}\n\n#[tokio::test]\nasync fn test_rx_is_empty_when_all_messages_are_consumed() {\n    let (tx, mut rx) = mpsc::channel(10);\n    for i in 0..10 {\n        assert!(tx.send(i).await.is_ok());\n    }\n    while rx.try_recv().is_ok() {}\n    assert!(rx.is_empty())\n}\n\n#[tokio::test]\nasync fn test_rx_is_empty_all_senders_are_dropped_and_messages_consumed() {\n    let (tx, mut rx) = mpsc::channel(10);\n    for i in 0..10 {\n        assert!(tx.send(i).await.is_ok());\n    }\n    drop(tx);\n\n    for _ in 0..10 {\n        assert!(rx.recv().await.is_some());\n    }\n\n    assert!(rx.is_empty())\n}\n\n#[tokio::test]\nasync fn test_rx_len_on_empty_channel() {\n    let (_tx, rx) = mpsc::channel::<()>(100);\n    assert_eq!(rx.len(), 0);\n}\n\n#[tokio::test]\nasync fn test_rx_len_on_empty_channel_without_senders() {\n    // when all senders are dropped, a \"closed\" value is added to the end of the linked list.\n    // here we test that the \"closed\" value does not change the len of the channel.\n\n    let (tx, rx) = mpsc::channel::<()>(100);\n    drop(tx);\n    assert_eq!(rx.len(), 0);\n}\n\n#[tokio::test]\nasync fn test_rx_len_on_filled_channel() {\n    let (tx, rx) = mpsc::channel(100);\n\n    for i in 0..100 {\n        assert!(tx.send(i).await.is_ok());\n    }\n    assert_eq!(rx.len(), 100);\n}\n\n#[tokio::test]\nasync fn test_rx_len_on_filled_channel_without_senders() {\n    let (tx, rx) = mpsc::channel(100);\n\n    for i in 0..100 {\n        assert!(tx.send(i).await.is_ok());\n    }\n    drop(tx);\n    assert_eq!(rx.len(), 100);\n}\n\n#[tokio::test]\nasync fn test_rx_len_when_consuming_all_messages() {\n    let (tx, mut rx) = mpsc::channel(100);\n\n    for i in 0..100 {\n        assert!(tx.send(i).await.is_ok());\n        assert_eq!(rx.len(), i + 1);\n    }\n\n    drop(tx);\n\n    for i in (0..100).rev() {\n        assert!(rx.recv().await.is_some());\n        assert_eq!(rx.len(), i);\n    }\n}\n\n#[tokio::test]\nasync fn test_rx_len_when_close_is_called() {\n    let (tx, mut rx) = mpsc::channel(100);\n    tx.send(()).await.unwrap();\n    rx.close();\n\n    assert_eq!(rx.len(), 1);\n}\n\n#[tokio::test]\nasync fn test_rx_len_when_close_is_called_before_dropping_sender() {\n    let (tx, mut rx) = mpsc::channel(100);\n    tx.send(()).await.unwrap();\n    rx.close();\n    drop(tx);\n\n    assert_eq!(rx.len(), 1);\n}\n\n#[tokio::test]\nasync fn test_rx_len_when_close_is_called_after_dropping_sender() {\n    let (tx, mut rx) = mpsc::channel(100);\n    tx.send(()).await.unwrap();\n    drop(tx);\n    rx.close();\n\n    assert_eq!(rx.len(), 1);\n}\n\n#[tokio::test]\nasync fn test_rx_unbounded_is_closed_when_calling_close_with_sender() {\n    // is_closed should return true after calling close but still has a sender\n    let (_tx, mut rx) = mpsc::unbounded_channel::<()>();\n    rx.close();\n\n    assert!(rx.is_closed());\n}\n\n#[tokio::test]\nasync fn test_rx_unbounded_is_closed_when_dropping_all_senders() {\n    // is_closed should return true after dropping all senders\n    let (tx, rx) = mpsc::unbounded_channel::<()>();\n    let another_tx = tx.clone();\n    let task = tokio::spawn(async move {\n        drop(another_tx);\n    });\n\n    drop(tx);\n    let _ = task.await;\n\n    assert!(rx.is_closed());\n}\n\n#[tokio::test]\nasync fn test_rx_unbounded_is_not_closed_when_there_are_senders() {\n    // is_closed should return false when there is a sender\n    let (_tx, rx) = mpsc::unbounded_channel::<()>();\n    assert!(!rx.is_closed());\n}\n\n#[tokio::test]\nasync fn test_rx_unbounded_is_closed_when_there_are_no_senders_and_there_are_messages() {\n    // is_closed should return true when there are messages in the buffer, but no senders\n    let (tx, rx) = mpsc::unbounded_channel();\n    for i in 0..10 {\n        assert!(tx.send(i).is_ok());\n    }\n    drop(tx);\n    assert!(rx.is_closed());\n}\n\n#[tokio::test]\nasync fn test_rx_unbounded_is_closed_when_there_are_messages_and_close_is_called() {\n    // is_closed should return true when there are messages in the buffer, and close is called\n    let (tx, mut rx) = mpsc::unbounded_channel();\n    for i in 0..10 {\n        assert!(tx.send(i).is_ok());\n    }\n    rx.close();\n    assert!(rx.is_closed());\n}\n\n#[tokio::test]\nasync fn test_rx_unbounded_is_empty_when_no_messages_were_sent() {\n    let (_tx, rx) = mpsc::unbounded_channel::<()>();\n    assert!(rx.is_empty())\n}\n\n#[tokio::test]\nasync fn test_rx_unbounded_is_not_empty_when_there_are_messages_in_the_buffer() {\n    let (tx, rx) = mpsc::unbounded_channel();\n    assert!(tx.send(()).is_ok());\n    assert!(!rx.is_empty())\n}\n\n#[tokio::test]\nasync fn test_rx_unbounded_is_not_empty_when_all_but_one_messages_are_consumed() {\n    let (tx, mut rx) = mpsc::unbounded_channel();\n    for i in 0..10 {\n        assert!(tx.send(i).is_ok());\n    }\n\n    for _ in 0..9 {\n        assert!(rx.recv().await.is_some());\n    }\n\n    assert!(!rx.is_empty())\n}\n\n#[tokio::test]\nasync fn test_rx_unbounded_is_empty_when_all_messages_are_consumed() {\n    let (tx, mut rx) = mpsc::unbounded_channel();\n    for i in 0..10 {\n        assert!(tx.send(i).is_ok());\n    }\n    while rx.try_recv().is_ok() {}\n    assert!(rx.is_empty())\n}\n\n#[tokio::test]\nasync fn test_rx_unbounded_is_empty_all_senders_are_dropped_and_messages_consumed() {\n    let (tx, mut rx) = mpsc::unbounded_channel();\n    for i in 0..10 {\n        assert!(tx.send(i).is_ok());\n    }\n    drop(tx);\n\n    for _ in 0..10 {\n        assert!(rx.recv().await.is_some());\n    }\n\n    assert!(rx.is_empty())\n}\n\n#[tokio::test]\nasync fn test_rx_unbounded_len_on_empty_channel() {\n    let (_tx, rx) = mpsc::unbounded_channel::<()>();\n    assert_eq!(rx.len(), 0);\n}\n\n#[tokio::test]\nasync fn test_rx_unbounded_len_on_empty_channel_without_senders() {\n    // when all senders are dropped, a \"closed\" value is added to the end of the linked list.\n    // here we test that the \"closed\" value does not change the len of the channel.\n\n    let (tx, rx) = mpsc::unbounded_channel::<()>();\n    drop(tx);\n    assert_eq!(rx.len(), 0);\n}\n\n#[tokio::test]\nasync fn test_rx_unbounded_len_with_multiple_messages() {\n    let (tx, rx) = mpsc::unbounded_channel();\n\n    for i in 0..100 {\n        assert!(tx.send(i).is_ok());\n    }\n    assert_eq!(rx.len(), 100);\n}\n\n#[tokio::test]\nasync fn test_rx_unbounded_len_with_multiple_messages_and_dropped_senders() {\n    let (tx, rx) = mpsc::unbounded_channel();\n\n    for i in 0..100 {\n        assert!(tx.send(i).is_ok());\n    }\n    drop(tx);\n    assert_eq!(rx.len(), 100);\n}\n\n#[tokio::test]\nasync fn test_rx_unbounded_len_when_consuming_all_messages() {\n    let (tx, mut rx) = mpsc::unbounded_channel();\n\n    for i in 0..100 {\n        assert!(tx.send(i).is_ok());\n        assert_eq!(rx.len(), i + 1);\n    }\n\n    drop(tx);\n\n    for i in (0..100).rev() {\n        assert!(rx.recv().await.is_some());\n        assert_eq!(rx.len(), i);\n    }\n}\n\n#[tokio::test]\nasync fn test_rx_unbounded_len_when_close_is_called() {\n    let (tx, mut rx) = mpsc::unbounded_channel();\n    tx.send(()).unwrap();\n    rx.close();\n\n    assert_eq!(rx.len(), 1);\n}\n\n#[tokio::test]\nasync fn test_rx_unbounded_len_when_close_is_called_before_dropping_sender() {\n    let (tx, mut rx) = mpsc::unbounded_channel();\n    tx.send(()).unwrap();\n    rx.close();\n    drop(tx);\n\n    assert_eq!(rx.len(), 1);\n}\n\n#[tokio::test]\nasync fn test_rx_unbounded_len_when_close_is_called_after_dropping_sender() {\n    let (tx, mut rx) = mpsc::unbounded_channel();\n    tx.send(()).unwrap();\n    drop(tx);\n    rx.close();\n\n    assert_eq!(rx.len(), 1);\n}\n\n// Regression test for https://github.com/tokio-rs/tokio/issues/6602\n#[tokio::test]\nasync fn test_is_empty_32_msgs() {\n    let (sender, mut receiver) = mpsc::channel(33);\n\n    for value in 1..257 {\n        sender.send(value).await.unwrap();\n        receiver.recv().await.unwrap();\n        assert!(receiver.is_empty(), \"{value}. len: {}\", receiver.len());\n    }\n}\n\nfn is_debug<T: fmt::Debug>(_: &T) {}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "9d5f5fd0039a4f3a0429233407a304f0a790b6c3",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tokio/tokio/src/sync/broadcast.rs",
    "func": "//! A multi-producer, multi-consumer broadcast queue. Each sent value is seen by\n//! all consumers.\n//!\n//! A [`Sender`] is used to broadcast values to **all** connected [`Receiver`]\n//! values. [`Sender`] handles are clone-able, allowing concurrent send and\n//! receive actions. [`Sender`] and [`Receiver`] are both `Send` and `Sync` as\n//! long as `T` is `Send`.\n//!\n//! When a value is sent, **all** [`Receiver`] handles are notified and will\n//! receive the value. The value is stored once inside the channel and cloned on\n//! demand for each receiver. Once all receivers have received a clone of the\n//! value, the value is released from the channel.\n//!\n//! A channel is created by calling [`channel`], specifying the maximum number\n//! of messages the channel can retain at any given time.\n//!\n//! New [`Receiver`] handles are created by calling [`Sender::subscribe`]. The\n//! returned [`Receiver`] will receive values sent **after** the call to\n//! `subscribe`.\n//!\n//! This channel is also suitable for the single-producer multi-consumer\n//! use-case, where a single sender broadcasts values to many receivers.\n//!\n//! ## Lagging\n//!\n//! As sent messages must be retained until **all** [`Receiver`] handles receive\n//! a clone, broadcast channels are susceptible to the \"slow receiver\" problem.\n//! In this case, all but one receiver are able to receive values at the rate\n//! they are sent. Because one receiver is stalled, the channel starts to fill\n//! up.\n//!\n//! This broadcast channel implementation handles this case by setting a hard\n//! upper bound on the number of values the channel may retain at any given\n//! time. This upper bound is passed to the [`channel`] function as an argument.\n//!\n//! If a value is sent when the channel is at capacity, the oldest value\n//! currently held by the channel is released. This frees up space for the new\n//! value. Any receiver that has not yet seen the released value will return\n//! [`RecvError::Lagged`] the next time [`recv`] is called.\n//!\n//! Once [`RecvError::Lagged`] is returned, the lagging receiver's position is\n//! updated to the oldest value contained by the channel. The next call to\n//! [`recv`] will return this value.\n//!\n//! This behavior enables a receiver to detect when it has lagged so far behind\n//! that data has been dropped. The caller may decide how to respond to this:\n//! either by aborting its task or by tolerating lost messages and resuming\n//! consumption of the channel.\n//!\n//! ## Closing\n//!\n//! When **all** [`Sender`] handles have been dropped, no new values may be\n//! sent. At this point, the channel is \"closed\". Once a receiver has received\n//! all values retained by the channel, the next call to [`recv`] will return\n//! with [`RecvError::Closed`].\n//!\n//! When a [`Receiver`] handle is dropped, any messages not read by the receiver\n//! will be marked as read. If this receiver was the only one not to have read\n//! that message, the message will be dropped at this point.\n//!\n//! [`Sender`]: crate::sync::broadcast::Sender\n//! [`Sender::subscribe`]: crate::sync::broadcast::Sender::subscribe\n//! [`Receiver`]: crate::sync::broadcast::Receiver\n//! [`channel`]: crate::sync::broadcast::channel\n//! [`RecvError::Lagged`]: crate::sync::broadcast::error::RecvError::Lagged\n//! [`RecvError::Closed`]: crate::sync::broadcast::error::RecvError::Closed\n//! [`recv`]: crate::sync::broadcast::Receiver::recv\n//!\n//! # Examples\n//!\n//! Basic usage\n//!\n//! ```\n//! use tokio::sync::broadcast;\n//!\n//! #[tokio::main]\n//! async fn main() {\n//!     let (tx, mut rx1) = broadcast::channel(16);\n//!     let mut rx2 = tx.subscribe();\n//!\n//!     tokio::spawn(async move {\n//!         assert_eq!(rx1.recv().await.unwrap(), 10);\n//!         assert_eq!(rx1.recv().await.unwrap(), 20);\n//!     });\n//!\n//!     tokio::spawn(async move {\n//!         assert_eq!(rx2.recv().await.unwrap(), 10);\n//!         assert_eq!(rx2.recv().await.unwrap(), 20);\n//!     });\n//!\n//!     tx.send(10).unwrap();\n//!     tx.send(20).unwrap();\n//! }\n//! ```\n//!\n//! Handling lag\n//!\n//! ```\n//! use tokio::sync::broadcast;\n//!\n//! #[tokio::main]\n//! async fn main() {\n//!     let (tx, mut rx) = broadcast::channel(2);\n//!\n//!     tx.send(10).unwrap();\n//!     tx.send(20).unwrap();\n//!     tx.send(30).unwrap();\n//!\n//!     // The receiver lagged behind\n//!     assert!(rx.recv().await.is_err());\n//!\n//!     // At this point, we can abort or continue with lost messages\n//!\n//!     assert_eq!(20, rx.recv().await.unwrap());\n//!     assert_eq!(30, rx.recv().await.unwrap());\n//! }\n//! ```\n\nuse crate::loom::cell::UnsafeCell;\nuse crate::loom::sync::atomic::{AtomicBool, AtomicUsize};\nuse crate::loom::sync::{Arc, Mutex, MutexGuard, RwLock, RwLockReadGuard};\nuse crate::runtime::coop::cooperative;\nuse crate::util::linked_list::{self, GuardedLinkedList, LinkedList};\nuse crate::util::WakeList;\n\nuse std::fmt;\nuse std::future::Future;\nuse std::marker::PhantomPinned;\nuse std::pin::Pin;\nuse std::ptr::NonNull;\nuse std::sync::atomic::Ordering::{Acquire, Relaxed, Release, SeqCst};\nuse std::task::{ready, Context, Poll, Waker};\n\n/// Sending-half of the [`broadcast`] channel.\n///\n/// May be used from many threads. Messages can be sent with\n/// [`send`][Sender::send].\n///\n/// # Examples\n///\n/// ```\n/// use tokio::sync::broadcast;\n///\n/// #[tokio::main]\n/// async fn main() {\n///     let (tx, mut rx1) = broadcast::channel(16);\n///     let mut rx2 = tx.subscribe();\n///\n///     tokio::spawn(async move {\n///         assert_eq!(rx1.recv().await.unwrap(), 10);\n///         assert_eq!(rx1.recv().await.unwrap(), 20);\n///     });\n///\n///     tokio::spawn(async move {\n///         assert_eq!(rx2.recv().await.unwrap(), 10);\n///         assert_eq!(rx2.recv().await.unwrap(), 20);\n///     });\n///\n///     tx.send(10).unwrap();\n///     tx.send(20).unwrap();\n/// }\n/// ```\n///\n/// [`broadcast`]: crate::sync::broadcast\npub struct Sender<T> {\n    shared: Arc<Shared<T>>,\n}\n\n/// Receiving-half of the [`broadcast`] channel.\n///\n/// Must not be used concurrently. Messages may be retrieved using\n/// [`recv`][Receiver::recv].\n///\n/// To turn this receiver into a `Stream`, you can use the [`BroadcastStream`]\n/// wrapper.\n///\n/// [`BroadcastStream`]: https://docs.rs/tokio-stream/0.1/tokio_stream/wrappers/struct.BroadcastStream.html\n///\n/// # Examples\n///\n/// ```\n/// use tokio::sync::broadcast;\n///\n/// #[tokio::main]\n/// async fn main() {\n///     let (tx, mut rx1) = broadcast::channel(16);\n///     let mut rx2 = tx.subscribe();\n///\n///     tokio::spawn(async move {\n///         assert_eq!(rx1.recv().await.unwrap(), 10);\n///         assert_eq!(rx1.recv().await.unwrap(), 20);\n///     });\n///\n///     tokio::spawn(async move {\n///         assert_eq!(rx2.recv().await.unwrap(), 10);\n///         assert_eq!(rx2.recv().await.unwrap(), 20);\n///     });\n///\n///     tx.send(10).unwrap();\n///     tx.send(20).unwrap();\n/// }\n/// ```\n///\n/// [`broadcast`]: crate::sync::broadcast\npub struct Receiver<T> {\n    /// State shared with all receivers and senders.\n    shared: Arc<Shared<T>>,\n\n    /// Next position to read from\n    next: u64,\n}\n\npub mod error {\n    //! Broadcast error types\n\n    use std::fmt;\n\n    /// Error returned by the [`send`] function on a [`Sender`].\n    ///\n    /// A **send** operation can only fail if there are no active receivers,\n    /// implying that the message could never be received. The error contains the\n    /// message being sent as a payload so it can be recovered.\n    ///\n    /// [`send`]: crate::sync::broadcast::Sender::send\n    /// [`Sender`]: crate::sync::broadcast::Sender\n    #[derive(Debug)]\n    pub struct SendError<T>(pub T);\n\n    impl<T> fmt::Display for SendError<T> {\n        fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n            write!(f, \"channel closed\")\n        }\n    }\n\n    impl<T: fmt::Debug> std::error::Error for SendError<T> {}\n\n    /// An error returned from the [`recv`] function on a [`Receiver`].\n    ///\n    /// [`recv`]: crate::sync::broadcast::Receiver::recv\n    /// [`Receiver`]: crate::sync::broadcast::Receiver\n    #[derive(Debug, PartialEq, Eq, Clone)]\n    pub enum RecvError {\n        /// There are no more active senders implying no further messages will ever\n        /// be sent.\n        Closed,\n\n        /// The receiver lagged too far behind. Attempting to receive again will\n        /// return the oldest message still retained by the channel.\n        ///\n        /// Includes the number of skipped messages.\n        Lagged(u64),\n    }\n\n    impl fmt::Display for RecvError {\n        fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n            match self {\n                RecvError::Closed => write!(f, \"channel closed\"),\n                RecvError::Lagged(amt) => write!(f, \"channel lagged by {amt}\"),\n            }\n        }\n    }\n\n    impl std::error::Error for RecvError {}\n\n    /// An error returned from the [`try_recv`] function on a [`Receiver`].\n    ///\n    /// [`try_recv`]: crate::sync::broadcast::Receiver::try_recv\n    /// [`Receiver`]: crate::sync::broadcast::Receiver\n    #[derive(Debug, PartialEq, Eq, Clone)]\n    pub enum TryRecvError {\n        /// The channel is currently empty. There are still active\n        /// [`Sender`] handles, so data may yet become available.\n        ///\n        /// [`Sender`]: crate::sync::broadcast::Sender\n        Empty,\n\n        /// There are no more active senders implying no further messages will ever\n        /// be sent.\n        Closed,\n\n        /// The receiver lagged too far behind and has been forcibly disconnected.\n        /// Attempting to receive again will return the oldest message still\n        /// retained by the channel.\n        ///\n        /// Includes the number of skipped messages.\n        Lagged(u64),\n    }\n\n    impl fmt::Display for TryRecvError {\n        fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n            match self {\n                TryRecvError::Empty => write!(f, \"channel empty\"),\n                TryRecvError::Closed => write!(f, \"channel closed\"),\n                TryRecvError::Lagged(amt) => write!(f, \"channel lagged by {amt}\"),\n            }\n        }\n    }\n\n    impl std::error::Error for TryRecvError {}\n}\n\nuse self::error::{RecvError, SendError, TryRecvError};\n\n/// Data shared between senders and receivers.\nstruct Shared<T> {\n    /// slots in the channel.\n    buffer: Box<[RwLock<Slot<T>>]>,\n\n    /// Mask a position -> index.\n    mask: usize,\n\n    /// Tail of the queue. Includes the rx wait list.\n    tail: Mutex<Tail>,\n\n    /// Number of outstanding Sender handles.\n    num_tx: AtomicUsize,\n}\n\n/// Next position to write a value.\nstruct Tail {\n    /// Next position to write to.\n    pos: u64,\n\n    /// Number of active receivers.\n    rx_cnt: usize,\n\n    /// True if the channel is closed.\n    closed: bool,\n\n    /// Receivers waiting for a value.\n    waiters: LinkedList<Waiter, <Waiter as linked_list::Link>::Target>,\n}\n\n/// Slot in the buffer.\nstruct Slot<T> {\n    /// Remaining number of receivers that are expected to see this value.\n    ///\n    /// When this goes to zero, the value is released.\n    ///\n    /// An atomic is used as it is mutated concurrently with the slot read lock\n    /// acquired.\n    rem: AtomicUsize,\n\n    /// Uniquely identifies the `send` stored in the slot.\n    pos: u64,\n\n    /// The value being broadcast.\n    ///\n    /// The value is set by `send` when the write lock is held. When a reader\n    /// drops, `rem` is decremented. When it hits zero, the value is dropped.\n    val: UnsafeCell<Option<T>>,\n}\n\n/// An entry in the wait queue.\nstruct Waiter {\n    /// True if queued.\n    queued: AtomicBool,\n\n    /// Task waiting on the broadcast channel.\n    waker: Option<Waker>,\n\n    /// Intrusive linked-list pointers.\n    pointers: linked_list::Pointers<Waiter>,\n\n    /// Should not be `Unpin`.\n    _p: PhantomPinned,\n}\n\nimpl Waiter {\n    fn new() -> Self {\n        Self {\n            queued: AtomicBool::new(false),\n            waker: None,\n            pointers: linked_list::Pointers::new(),\n            _p: PhantomPinned,\n        }\n    }\n}\n\ngenerate_addr_of_methods! {\n    impl<> Waiter {\n        unsafe fn addr_of_pointers(self: NonNull<Self>) -> NonNull<linked_list::Pointers<Waiter>> {\n            &self.pointers\n        }\n    }\n}\n\nstruct RecvGuard<'a, T> {\n    slot: RwLockReadGuard<'a, Slot<T>>,\n}\n\n/// Receive a value future.\nstruct Recv<'a, T> {\n    /// Receiver being waited on.\n    receiver: &'a mut Receiver<T>,\n\n    /// Entry in the waiter `LinkedList`.\n    waiter: UnsafeCell<Waiter>,\n}\n\nunsafe impl<'a, T: Send> Send for Recv<'a, T> {}\nunsafe impl<'a, T: Send> Sync for Recv<'a, T> {}\n\n/// Max number of receivers. Reserve space to lock.\nconst MAX_RECEIVERS: usize = usize::MAX >> 2;\n\n/// Create a bounded, multi-producer, multi-consumer channel where each sent\n/// value is broadcasted to all active receivers.\n///\n/// **Note:** The actual capacity may be greater than the provided `capacity`.\n///\n/// All data sent on [`Sender`] will become available on every active\n/// [`Receiver`] in the same order as it was sent.\n///\n/// The `Sender` can be cloned to `send` to the same channel from multiple\n/// points in the process or it can be used concurrently from an `Arc`. New\n/// `Receiver` handles are created by calling [`Sender::subscribe`].\n///\n/// If all [`Receiver`] handles are dropped, the `send` method will return a\n/// [`SendError`]. Similarly, if all [`Sender`] handles are dropped, the [`recv`]\n/// method will return a [`RecvError`].\n///\n/// [`Sender`]: crate::sync::broadcast::Sender\n/// [`Sender::subscribe`]: crate::sync::broadcast::Sender::subscribe\n/// [`Receiver`]: crate::sync::broadcast::Receiver\n/// [`recv`]: crate::sync::broadcast::Receiver::recv\n/// [`SendError`]: crate::sync::broadcast::error::SendError\n/// [`RecvError`]: crate::sync::broadcast::error::RecvError\n///\n/// # Examples\n///\n/// ```\n/// use tokio::sync::broadcast;\n///\n/// #[tokio::main]\n/// async fn main() {\n///     let (tx, mut rx1) = broadcast::channel(16);\n///     let mut rx2 = tx.subscribe();\n///\n///     tokio::spawn(async move {\n///         assert_eq!(rx1.recv().await.unwrap(), 10);\n///         assert_eq!(rx1.recv().await.unwrap(), 20);\n///     });\n///\n///     tokio::spawn(async move {\n///         assert_eq!(rx2.recv().await.unwrap(), 10);\n///         assert_eq!(rx2.recv().await.unwrap(), 20);\n///     });\n///\n///     tx.send(10).unwrap();\n///     tx.send(20).unwrap();\n/// }\n/// ```\n///\n/// # Panics\n///\n/// This will panic if `capacity` is equal to `0` or larger\n/// than `usize::MAX / 2`.\n#[track_caller]\npub fn channel<T: Clone>(capacity: usize) -> (Sender<T>, Receiver<T>) {\n    // SAFETY: In the line below we are creating one extra receiver, so there will be 1 in total.\n    let tx = unsafe { Sender::new_with_receiver_count(1, capacity) };\n    let rx = Receiver {\n        shared: tx.shared.clone(),\n        next: 0,\n    };\n    (tx, rx)\n}\n\nunsafe impl<T: Send> Send for Sender<T> {}\nunsafe impl<T: Send> Sync for Sender<T> {}\n\nunsafe impl<T: Send> Send for Receiver<T> {}\nunsafe impl<T: Send> Sync for Receiver<T> {}\n\nimpl<T> Sender<T> {\n    /// Creates the sending-half of the [`broadcast`] channel.\n    ///\n    /// See the documentation of [`broadcast::channel`] for more information on this method.\n    ///\n    /// [`broadcast`]: crate::sync::broadcast\n    /// [`broadcast::channel`]: crate::sync::broadcast::channel\n    #[track_caller]\n    pub fn new(capacity: usize) -> Self {\n        // SAFETY: We don't create extra receivers, so there are 0.\n        unsafe { Self::new_with_receiver_count(0, capacity) }\n    }\n\n    /// Creates the sending-half of the [`broadcast`](self) channel, and provide the receiver\n    /// count.\n    ///\n    /// See the documentation of [`broadcast::channel`](self::channel) for more errors when\n    /// calling this function.\n    ///\n    /// # Safety:\n    ///\n    /// The caller must ensure that the amount of receivers for this Sender is correct before\n    /// the channel functionalities are used, the count is zero by default, as this function\n    /// does not create any receivers by itself.\n    #[track_caller]\n    unsafe fn new_with_receiver_count(receiver_count: usize, mut capacity: usize) -> Self {\n        assert!(capacity > 0, \"broadcast channel capacity cannot be zero\");\n        assert!(\n            capacity <= usize::MAX >> 1,\n            \"broadcast channel capacity exceeded `usize::MAX / 2`\"\n        );\n\n        // Round to a power of two\n        capacity = capacity.next_power_of_two();\n\n        let mut buffer = Vec::with_capacity(capacity);\n\n        for i in 0..capacity {\n            buffer.push(RwLock::new(Slot {\n                rem: AtomicUsize::new(0),\n                pos: (i as u64).wrapping_sub(capacity as u64),\n                val: UnsafeCell::new(None),\n            }));\n        }\n\n        let shared = Arc::new(Shared {\n            buffer: buffer.into_boxed_slice(),\n            mask: capacity - 1,\n            tail: Mutex::new(Tail {\n                pos: 0,\n                rx_cnt: receiver_count,\n                closed: false,\n                waiters: LinkedList::new(),\n            }),\n            num_tx: AtomicUsize::new(1),\n        });\n\n        Sender { shared }\n    }\n\n    /// Attempts to send a value to all active [`Receiver`] handles, returning\n    /// it back if it could not be sent.\n    ///\n    /// A successful send occurs when there is at least one active [`Receiver`]\n    /// handle. An unsuccessful send would be one where all associated\n    /// [`Receiver`] handles have already been dropped.\n    ///\n    /// # Return\n    ///\n    /// On success, the number of subscribed [`Receiver`] handles is returned.\n    /// This does not mean that this number of receivers will see the message as\n    /// a receiver may drop or lag ([see lagging](self#lagging)) before receiving\n    /// the message.\n    ///\n    /// # Note\n    ///\n    /// A return value of `Ok` **does not** mean that the sent value will be\n    /// observed by all or any of the active [`Receiver`] handles. [`Receiver`]\n    /// handles may be dropped before receiving the sent message.\n    ///\n    /// A return value of `Err` **does not** mean that future calls to `send`\n    /// will fail. New [`Receiver`] handles may be created by calling\n    /// [`subscribe`].\n    ///\n    /// [`Receiver`]: crate::sync::broadcast::Receiver\n    /// [`subscribe`]: crate::sync::broadcast::Sender::subscribe\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use tokio::sync::broadcast;\n    ///\n    /// #[tokio::main]\n    /// async fn main() {\n    ///     let (tx, mut rx1) = broadcast::channel(16);\n    ///     let mut rx2 = tx.subscribe();\n    ///\n    ///     tokio::spawn(async move {\n    ///         assert_eq!(rx1.recv().await.unwrap(), 10);\n    ///         assert_eq!(rx1.recv().await.unwrap(), 20);\n    ///     });\n    ///\n    ///     tokio::spawn(async move {\n    ///         assert_eq!(rx2.recv().await.unwrap(), 10);\n    ///         assert_eq!(rx2.recv().await.unwrap(), 20);\n    ///     });\n    ///\n    ///     tx.send(10).unwrap();\n    ///     tx.send(20).unwrap();\n    /// }\n    /// ```\n    pub fn send(&self, value: T) -> Result<usize, SendError<T>> {\n        let mut tail = self.shared.tail.lock();\n\n        if tail.rx_cnt == 0 {\n            return Err(SendError(value));\n        }\n\n        // Position to write into\n        let pos = tail.pos;\n        let rem = tail.rx_cnt;\n        let idx = (pos & self.shared.mask as u64) as usize;\n\n        // Update the tail position\n        tail.pos = tail.pos.wrapping_add(1);\n\n        // Get the slot\n        let mut slot = self.shared.buffer[idx].write();\n\n        // Track the position\n        slot.pos = pos;\n\n        // Set remaining receivers\n        slot.rem.with_mut(|v| *v = rem);\n\n        // Write the value\n        slot.val = UnsafeCell::new(Some(value));\n\n        // Release the slot lock before notifying the receivers.\n        drop(slot);\n\n        // Notify and release the mutex. This must happen after the slot lock is\n        // released, otherwise the writer lock bit could be cleared while another\n        // thread is in the critical section.\n        self.shared.notify_rx(tail);\n\n        Ok(rem)\n    }\n\n    /// Creates a new [`Receiver`] handle that will receive values sent **after**\n    /// this call to `subscribe`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use tokio::sync::broadcast;\n    ///\n    /// #[tokio::main]\n    /// async fn main() {\n    ///     let (tx, _rx) = broadcast::channel(16);\n    ///\n    ///     // Will not be seen\n    ///     tx.send(10).unwrap();\n    ///\n    ///     let mut rx = tx.subscribe();\n    ///\n    ///     tx.send(20).unwrap();\n    ///\n    ///     let value = rx.recv().await.unwrap();\n    ///     assert_eq!(20, value);\n    /// }\n    /// ```\n    pub fn subscribe(&self) -> Receiver<T> {\n        let shared = self.shared.clone();\n        new_receiver(shared)\n    }\n\n    /// Returns the number of queued values.\n    ///\n    /// A value is queued until it has either been seen by all receivers that were alive at the time\n    /// it was sent, or has been evicted from the queue by subsequent sends that exceeded the\n    /// queue's capacity.\n    ///\n    /// # Note\n    ///\n    /// In contrast to [`Receiver::len`], this method only reports queued values and not values that\n    /// have been evicted from the queue before being seen by all receivers.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use tokio::sync::broadcast;\n    ///\n    /// #[tokio::main]\n    /// async fn main() {\n    ///     let (tx, mut rx1) = broadcast::channel(16);\n    ///     let mut rx2 = tx.subscribe();\n    ///\n    ///     tx.send(10).unwrap();\n    ///     tx.send(20).unwrap();\n    ///     tx.send(30).unwrap();\n    ///\n    ///     assert_eq!(tx.len(), 3);\n    ///\n    ///     rx1.recv().await.unwrap();\n    ///\n    ///     // The len is still 3 since rx2 hasn't seen the first value yet.\n    ///     assert_eq!(tx.len(), 3);\n    ///\n    ///     rx2.recv().await.unwrap();\n    ///\n    ///     assert_eq!(tx.len(), 2);\n    /// }\n    /// ```\n    pub fn len(&self) -> usize {\n        let tail = self.shared.tail.lock();\n\n        let base_idx = (tail.pos & self.shared.mask as u64) as usize;\n        let mut low = 0;\n        let mut high = self.shared.buffer.len();\n        while low < high {\n            let mid = low + (high - low) / 2;\n            let idx = base_idx.wrapping_add(mid) & self.shared.mask;\n            if self.shared.buffer[idx].read().rem.load(SeqCst) == 0 {\n                low = mid + 1;\n            } else {\n                high = mid;\n            }\n        }\n\n        self.shared.buffer.len() - low\n    }\n\n    /// Returns true if there are no queued values.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use tokio::sync::broadcast;\n    ///\n    /// #[tokio::main]\n    /// async fn main() {\n    ///     let (tx, mut rx1) = broadcast::channel(16);\n    ///     let mut rx2 = tx.subscribe();\n    ///\n    ///     assert!(tx.is_empty());\n    ///\n    ///     tx.send(10).unwrap();\n    ///\n    ///     assert!(!tx.is_empty());\n    ///\n    ///     rx1.recv().await.unwrap();\n    ///\n    ///     // The queue is still not empty since rx2 hasn't seen the value.\n    ///     assert!(!tx.is_empty());\n    ///\n    ///     rx2.recv().await.unwrap();\n    ///\n    ///     assert!(tx.is_empty());\n    /// }\n    /// ```\n    pub fn is_empty(&self) -> bool {\n        let tail = self.shared.tail.lock();\n\n        let idx = (tail.pos.wrapping_sub(1) & self.shared.mask as u64) as usize;\n        self.shared.buffer[idx].read().rem.load(SeqCst) == 0\n    }\n\n    /// Returns the number of active receivers.\n    ///\n    /// An active receiver is a [`Receiver`] handle returned from [`channel`] or\n    /// [`subscribe`]. These are the handles that will receive values sent on\n    /// this [`Sender`].\n    ///\n    /// # Note\n    ///\n    /// It is not guaranteed that a sent message will reach this number of\n    /// receivers. Active receivers may never call [`recv`] again before\n    /// dropping.\n    ///\n    /// [`recv`]: crate::sync::broadcast::Receiver::recv\n    /// [`Receiver`]: crate::sync::broadcast::Receiver\n    /// [`Sender`]: crate::sync::broadcast::Sender\n    /// [`subscribe`]: crate::sync::broadcast::Sender::subscribe\n    /// [`channel`]: crate::sync::broadcast::channel\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use tokio::sync::broadcast;\n    ///\n    /// #[tokio::main]\n    /// async fn main() {\n    ///     let (tx, _rx1) = broadcast::channel(16);\n    ///\n    ///     assert_eq!(1, tx.receiver_count());\n    ///\n    ///     let mut _rx2 = tx.subscribe();\n    ///\n    ///     assert_eq!(2, tx.receiver_count());\n    ///\n    ///     tx.send(10).unwrap();\n    /// }\n    /// ```\n    pub fn receiver_count(&self) -> usize {\n        let tail = self.shared.tail.lock();\n        tail.rx_cnt\n    }\n\n    /// Returns `true` if senders belong to the same channel.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use tokio::sync::broadcast;\n    ///\n    /// #[tokio::main]\n    /// async fn main() {\n    ///     let (tx, _rx) = broadcast::channel::<()>(16);\n    ///     let tx2 = tx.clone();\n    ///\n    ///     assert!(tx.same_channel(&tx2));\n    ///\n    ///     let (tx3, _rx3) = broadcast::channel::<()>(16);\n    ///\n    ///     assert!(!tx3.same_channel(&tx2));\n    /// }\n    /// ```\n    pub fn same_channel(&self, other: &Self) -> bool {\n        Arc::ptr_eq(&self.shared, &other.shared)\n    }\n\n    fn close_channel(&self) {\n        let mut tail = self.shared.tail.lock();\n        tail.closed = true;\n\n        self.shared.notify_rx(tail);\n    }\n}\n\n/// Create a new `Receiver` which reads starting from the tail.\nfn new_receiver<T>(shared: Arc<Shared<T>>) -> Receiver<T> {\n    let mut tail = shared.tail.lock();\n\n    assert!(tail.rx_cnt != MAX_RECEIVERS, \"max receivers\");\n\n    tail.rx_cnt = tail.rx_cnt.checked_add(1).expect(\"overflow\");\n\n    let next = tail.pos;\n\n    drop(tail);\n\n    Receiver { shared, next }\n}\n\n/// List used in `Shared::notify_rx`. It wraps a guarded linked list\n/// and gates the access to it on the `Shared.tail` mutex. It also empties\n/// the list on drop.\nstruct WaitersList<'a, T> {\n    list: GuardedLinkedList<Waiter, <Waiter as linked_list::Link>::Target>,\n    is_empty: bool,\n    shared: &'a Shared<T>,\n}\n\nimpl<'a, T> Drop for WaitersList<'a, T> {\n    fn drop(&mut self) {\n        // If the list is not empty, we unlink all waiters from it.\n        // We do not wake the waiters to avoid double panics.\n        if !self.is_empty {\n            let _lock_guard = self.shared.tail.lock();\n            while self.list.pop_back().is_some() {}\n        }\n    }\n}\n\nimpl<'a, T> WaitersList<'a, T> {\n    fn new(\n        unguarded_list: LinkedList<Waiter, <Waiter as linked_list::Link>::Target>,\n        guard: Pin<&'a Waiter>,\n        shared: &'a Shared<T>,\n    ) -> Self {\n        let guard_ptr = NonNull::from(guard.get_ref());\n        let list = unguarded_list.into_guarded(guard_ptr);\n        WaitersList {\n            list,\n            is_empty: false,\n            shared,\n        }\n    }\n\n    /// Removes the last element from the guarded list. Modifying this list\n    /// requires an exclusive access to the main list in `Notify`.\n    fn pop_back_locked(&mut self, _tail: &mut Tail) -> Option<NonNull<Waiter>> {\n        let result = self.list.pop_back();\n        if result.is_none() {\n            // Save information about emptiness to avoid waiting for lock\n            // in the destructor.\n            self.is_empty = true;\n        }\n        result\n    }\n}\n\nimpl<T> Shared<T> {\n    fn notify_rx<'a, 'b: 'a>(&'b self, mut tail: MutexGuard<'a, Tail>) {\n        // It is critical for `GuardedLinkedList` safety that the guard node is\n        // pinned in memory and is not dropped until the guarded list is dropped.\n        let guard = Waiter::new();\n        pin!(guard);\n\n        // We move all waiters to a secondary list. It uses a `GuardedLinkedList`\n        // underneath to allow every waiter to safely remove itself from it.\n        //\n        // * This list will be still guarded by the `waiters` lock.\n        //   `NotifyWaitersList` wrapper makes sure we hold the lock to modify it.\n        // * This wrapper will empty the list on drop. It is critical for safety\n        //   that we will not leave any list entry with a pointer to the local\n        //   guard node after this function returns / panics.\n        let mut list = WaitersList::new(std::mem::take(&mut tail.waiters), guard.as_ref(), self);\n\n        let mut wakers = WakeList::new();\n        'outer: loop {\n            while wakers.can_push() {\n                match list.pop_back_locked(&mut tail) {\n                    Some(waiter) => {\n                        unsafe {\n                            // Safety: accessing `waker` is safe because\n                            // the tail lock is held.\n                            if let Some(waker) = (*waiter.as_ptr()).waker.take() {\n                                wakers.push(waker);\n                            }\n\n                            // Safety: `queued` is atomic.\n                            let queued = &(*waiter.as_ptr()).queued;\n                            // `Relaxed` suffices because the tail lock is held.\n                            assert!(queued.load(Relaxed));\n                            // `Release` is needed to synchronize with `Recv::drop`.\n                            // It is critical to set this variable **after** waker\n                            // is extracted, otherwise we may data race with `Recv::drop`.\n                            queued.store(false, Release);\n                        }\n                    }\n                    None => {\n                        break 'outer;\n                    }\n                }\n            }\n\n            // Release the lock before waking.\n            drop(tail);\n\n            // Before we acquire the lock again all sorts of things can happen:\n            // some waiters may remove themselves from the list and new waiters\n            // may be added. This is fine since at worst we will unnecessarily\n            // wake up waiters which will then queue themselves again.\n\n            wakers.wake_all();\n\n            // Acquire the lock again.\n            tail = self.tail.lock();\n        }\n\n        // Release the lock before waking.\n        drop(tail);\n\n        wakers.wake_all();\n    }\n}\n\nimpl<T> Clone for Sender<T> {\n    fn clone(&self) -> Sender<T> {\n        let shared = self.shared.clone();\n        shared.num_tx.fetch_add(1, SeqCst);\n\n        Sender { shared }\n    }\n}\n\nimpl<T> Drop for Sender<T> {\n    fn drop(&mut self) {\n        if 1 == self.shared.num_tx.fetch_sub(1, SeqCst) {\n            self.close_channel();\n        }\n    }\n}\n\nimpl<T> Receiver<T> {\n    /// Returns the number of messages that were sent into the channel and that\n    /// this [`Receiver`] has yet to receive.\n    ///\n    /// If the returned value from `len` is larger than the next largest power of 2\n    /// of the capacity of the channel any call to [`recv`] will return an\n    /// `Err(RecvError::Lagged)` and any call to [`try_recv`] will return an\n    /// `Err(TryRecvError::Lagged)`, e.g. if the capacity of the channel is 10,\n    /// [`recv`] will start to return `Err(RecvError::Lagged)` once `len` returns\n    /// values larger than 16.\n    ///\n    /// [`Receiver`]: crate::sync::broadcast::Receiver\n    /// [`recv`]: crate::sync::broadcast::Receiver::recv\n    /// [`try_recv`]: crate::sync::broadcast::Receiver::try_recv\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use tokio::sync::broadcast;\n    ///\n    /// #[tokio::main]\n    /// async fn main() {\n    ///     let (tx, mut rx1) = broadcast::channel(16);\n    ///\n    ///     tx.send(10).unwrap();\n    ///     tx.send(20).unwrap();\n    ///\n    ///     assert_eq!(rx1.len(), 2);\n    ///     assert_eq!(rx1.recv().await.unwrap(), 10);\n    ///     assert_eq!(rx1.len(), 1);\n    ///     assert_eq!(rx1.recv().await.unwrap(), 20);\n    ///     assert_eq!(rx1.len(), 0);\n    /// }\n    /// ```\n    pub fn len(&self) -> usize {\n        let next_send_pos = self.shared.tail.lock().pos;\n        (next_send_pos - self.next) as usize\n    }\n\n    /// Returns true if there aren't any messages in the channel that the [`Receiver`]\n    /// has yet to receive.\n    ///\n    /// [`Receiver]: create::sync::broadcast::Receiver\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use tokio::sync::broadcast;\n    ///\n    /// #[tokio::main]\n    /// async fn main() {\n    ///     let (tx, mut rx1) = broadcast::channel(16);\n    ///\n    ///     assert!(rx1.is_empty());\n    ///\n    ///     tx.send(10).unwrap();\n    ///     tx.send(20).unwrap();\n    ///\n    ///     assert!(!rx1.is_empty());\n    ///     assert_eq!(rx1.recv().await.unwrap(), 10);\n    ///     assert_eq!(rx1.recv().await.unwrap(), 20);\n    ///     assert!(rx1.is_empty());\n    /// }\n    /// ```\n    pub fn is_empty(&self) -> bool {\n        self.len() == 0\n    }\n\n    /// Returns `true` if receivers belong to the same channel.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use tokio::sync::broadcast;\n    ///\n    /// #[tokio::main]\n    /// async fn main() {\n    ///     let (tx, rx) = broadcast::channel::<()>(16);\n    ///     let rx2 = tx.subscribe();\n    ///\n    ///     assert!(rx.same_channel(&rx2));\n    ///\n    ///     let (_tx3, rx3) = broadcast::channel::<()>(16);\n    ///\n    ///     assert!(!rx3.same_channel(&rx2));\n    /// }\n    /// ```\n    pub fn same_channel(&self, other: &Self) -> bool {\n        Arc::ptr_eq(&self.shared, &other.shared)\n    }\n\n    /// Locks the next value if there is one.\n    fn recv_ref(\n        &mut self,\n        waiter: Option<(&UnsafeCell<Waiter>, &Waker)>,\n    ) -> Result<RecvGuard<'_, T>, TryRecvError> {\n        let idx = (self.next & self.shared.mask as u64) as usize;\n\n        // The slot holding the next value to read\n        let mut slot = self.shared.buffer[idx].read();\n\n        if slot.pos != self.next {\n            // Release the `slot` lock before attempting to acquire the `tail`\n            // lock. This is required because `send2` acquires the tail lock\n            // first followed by the slot lock. Acquiring the locks in reverse\n            // order here would result in a potential deadlock: `recv_ref`\n            // acquires the `slot` lock and attempts to acquire the `tail` lock\n            // while `send2` acquired the `tail` lock and attempts to acquire\n            // the slot lock.\n            drop(slot);\n\n            let mut old_waker = None;\n\n            let mut tail = self.shared.tail.lock();\n\n            // Acquire slot lock again\n            slot = self.shared.buffer[idx].read();\n\n            // Make sure the position did not change. This could happen in the\n            // unlikely event that the buffer is wrapped between dropping the\n            // read lock and acquiring the tail lock.\n            if slot.pos != self.next {\n                let next_pos = slot.pos.wrapping_add(self.shared.buffer.len() as u64);\n\n                if next_pos == self.next {\n                    // At this point the channel is empty for *this* receiver. If\n                    // it's been closed, then that's what we return, otherwise we\n                    // set a waker and return empty.\n                    if tail.closed {\n                        return Err(TryRecvError::Closed);\n                    }\n\n                    // Store the waker\n                    if let Some((waiter, waker)) = waiter {\n                        // Safety: called while locked.\n                        unsafe {\n                            // Only queue if not already queued\n                            waiter.with_mut(|ptr| {\n                                // If there is no waker **or** if the currently\n                                // stored waker references a **different** task,\n                                // track the tasks' waker to be notified on\n                                // receipt of a new value.\n                                match (*ptr).waker {\n                                    Some(ref w) if w.will_wake(waker) => {}\n                                    _ => {\n                                        old_waker = std::mem::replace(\n                                            &mut (*ptr).waker,\n                                            Some(waker.clone()),\n                                        );\n                                    }\n                                }\n\n                                // If the waiter is not already queued, enqueue it.\n                                // `Relaxed` order suffices: we have synchronized with\n                                // all writers through the tail lock that we hold.\n                                if !(*ptr).queued.load(Relaxed) {\n                                    // `Relaxed` order suffices: all the readers will\n                                    // synchronize with this write through the tail lock.\n                                    (*ptr).queued.store(true, Relaxed);\n                                    tail.waiters.push_front(NonNull::new_unchecked(&mut *ptr));\n                                }\n                            });\n                        }\n                    }\n\n                    // Drop the old waker after releasing the locks.\n                    drop(slot);\n                    drop(tail);\n                    drop(old_waker);\n\n                    return Err(TryRecvError::Empty);\n                }\n\n                // At this point, the receiver has lagged behind the sender by\n                // more than the channel capacity. The receiver will attempt to\n                // catch up by skipping dropped messages and setting the\n                // internal cursor to the **oldest** message stored by the\n                // channel.\n                let next = tail.pos.wrapping_sub(self.shared.buffer.len() as u64);\n\n                let missed = next.wrapping_sub(self.next);\n\n                drop(tail);\n\n                // The receiver is slow but no values have been missed\n                if missed == 0 {\n                    self.next = self.next.wrapping_add(1);\n\n                    return Ok(RecvGuard { slot });\n                }\n\n                self.next = next;\n\n                return Err(TryRecvError::Lagged(missed));\n            }\n        }\n\n        self.next = self.next.wrapping_add(1);\n\n        Ok(RecvGuard { slot })\n    }\n}\n\nimpl<T: Clone> Receiver<T> {\n    /// Re-subscribes to the channel starting from the current tail element.\n    ///\n    /// This [`Receiver`] handle will receive a clone of all values sent\n    /// **after** it has resubscribed. This will not include elements that are\n    /// in the queue of the current receiver. Consider the following example.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use tokio::sync::broadcast;\n    ///\n    /// #[tokio::main]\n    /// async fn main() {\n    ///   let (tx, mut rx) = broadcast::channel(2);\n    ///\n    ///   tx.send(1).unwrap();\n    ///   let mut rx2 = rx.resubscribe();\n    ///   tx.send(2).unwrap();\n    ///\n    ///   assert_eq!(rx2.recv().await.unwrap(), 2);\n    ///   assert_eq!(rx.recv().await.unwrap(), 1);\n    /// }\n    /// ```\n    pub fn resubscribe(&self) -> Self {\n        let shared = self.shared.clone();\n        new_receiver(shared)\n    }\n    /// Receives the next value for this receiver.\n    ///\n    /// Each [`Receiver`] handle will receive a clone of all values sent\n    /// **after** it has subscribed.\n    ///\n    /// `Err(RecvError::Closed)` is returned when all `Sender` halves have\n    /// dropped, indicating that no further values can be sent on the channel.\n    ///\n    /// If the [`Receiver`] handle falls behind, once the channel is full, newly\n    /// sent values will overwrite old values. At this point, a call to [`recv`]\n    /// will return with `Err(RecvError::Lagged)` and the [`Receiver`]'s\n    /// internal cursor is updated to point to the oldest value still held by\n    /// the channel. A subsequent call to [`recv`] will return this value\n    /// **unless** it has been since overwritten.\n    ///\n    /// # Cancel safety\n    ///\n    /// This method is cancel safe. If `recv` is used as the event in a\n    /// [`tokio::select!`](crate::select) statement and some other branch\n    /// completes first, it is guaranteed that no messages were received on this\n    /// channel.\n    ///\n    /// [`Receiver`]: crate::sync::broadcast::Receiver\n    /// [`recv`]: crate::sync::broadcast::Receiver::recv\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use tokio::sync::broadcast;\n    ///\n    /// #[tokio::main]\n    /// async fn main() {\n    ///     let (tx, mut rx1) = broadcast::channel(16);\n    ///     let mut rx2 = tx.subscribe();\n    ///\n    ///     tokio::spawn(async move {\n    ///         assert_eq!(rx1.recv().await.unwrap(), 10);\n    ///         assert_eq!(rx1.recv().await.unwrap(), 20);\n    ///     });\n    ///\n    ///     tokio::spawn(async move {\n    ///         assert_eq!(rx2.recv().await.unwrap(), 10);\n    ///         assert_eq!(rx2.recv().await.unwrap(), 20);\n    ///     });\n    ///\n    ///     tx.send(10).unwrap();\n    ///     tx.send(20).unwrap();\n    /// }\n    /// ```\n    ///\n    /// Handling lag\n    ///\n    /// ```\n    /// use tokio::sync::broadcast;\n    ///\n    /// #[tokio::main]\n    /// async fn main() {\n    ///     let (tx, mut rx) = broadcast::channel(2);\n    ///\n    ///     tx.send(10).unwrap();\n    ///     tx.send(20).unwrap();\n    ///     tx.send(30).unwrap();\n    ///\n    ///     // The receiver lagged behind\n    ///     assert!(rx.recv().await.is_err());\n    ///\n    ///     // At this point, we can abort or continue with lost messages\n    ///\n    ///     assert_eq!(20, rx.recv().await.unwrap());\n    ///     assert_eq!(30, rx.recv().await.unwrap());\n    /// }\n    /// ```\n    pub async fn recv(&mut self) -> Result<T, RecvError> {\n        cooperative(Recv::new(self)).await\n    }\n\n    /// Attempts to return a pending value on this receiver without awaiting.\n    ///\n    /// This is useful for a flavor of \"optimistic check\" before deciding to\n    /// await on a receiver.\n    ///\n    /// Compared with [`recv`], this function has three failure cases instead of two\n    /// (one for closed, one for an empty buffer, one for a lagging receiver).\n    ///\n    /// `Err(TryRecvError::Closed)` is returned when all `Sender` halves have\n    /// dropped, indicating that no further values can be sent on the channel.\n    ///\n    /// If the [`Receiver`] handle falls behind, once the channel is full, newly\n    /// sent values will overwrite old values. At this point, a call to [`recv`]\n    /// will return with `Err(TryRecvError::Lagged)` and the [`Receiver`]'s\n    /// internal cursor is updated to point to the oldest value still held by\n    /// the channel. A subsequent call to [`try_recv`] will return this value\n    /// **unless** it has been since overwritten. If there are no values to\n    /// receive, `Err(TryRecvError::Empty)` is returned.\n    ///\n    /// [`recv`]: crate::sync::broadcast::Receiver::recv\n    /// [`try_recv`]: crate::sync::broadcast::Receiver::try_recv\n    /// [`Receiver`]: crate::sync::broadcast::Receiver\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use tokio::sync::broadcast;\n    ///\n    /// #[tokio::main]\n    /// async fn main() {\n    ///     let (tx, mut rx) = broadcast::channel(16);\n    ///\n    ///     assert!(rx.try_recv().is_err());\n    ///\n    ///     tx.send(10).unwrap();\n    ///\n    ///     let value = rx.try_recv().unwrap();\n    ///     assert_eq!(10, value);\n    /// }\n    /// ```\n    pub fn try_recv(&mut self) -> Result<T, TryRecvError> {\n        let guard = self.recv_ref(None)?;\n        guard.clone_value().ok_or(TryRecvError::Closed)\n    }\n\n    /// Blocking receive to call outside of asynchronous contexts.\n    ///\n    /// # Panics\n    ///\n    /// This function panics if called within an asynchronous execution\n    /// context.\n    ///\n    /// # Examples\n    /// ```\n    /// use std::thread;\n    /// use tokio::sync::broadcast;\n    ///\n    /// #[tokio::main]\n    /// async fn main() {\n    ///     let (tx, mut rx) = broadcast::channel(16);\n    ///\n    ///     let sync_code = thread::spawn(move || {\n    ///         assert_eq!(rx.blocking_recv(), Ok(10));\n    ///     });\n    ///\n    ///     let _ = tx.send(10);\n    ///     sync_code.join().unwrap();\n    /// }\n    /// ```\n    pub fn blocking_recv(&mut self) -> Result<T, RecvError> {\n        crate::future::block_on(self.recv())\n    }\n}\n\nimpl<T> Drop for Receiver<T> {\n    fn drop(&mut self) {\n        let mut tail = self.shared.tail.lock();\n\n        tail.rx_cnt -= 1;\n        let until = tail.pos;\n\n        drop(tail);\n\n        while self.next < until {\n            match self.recv_ref(None) {\n                Ok(_) => {}\n                // The channel is closed\n                Err(TryRecvError::Closed) => break,\n                // Ignore lagging, we will catch up\n                Err(TryRecvError::Lagged(..)) => {}\n                // Can't be empty\n                Err(TryRecvError::Empty) => panic!(\"unexpected empty broadcast channel\"),\n            }\n        }\n    }\n}\n\nimpl<'a, T> Recv<'a, T> {\n    fn new(receiver: &'a mut Receiver<T>) -> Recv<'a, T> {\n        Recv {\n            receiver,\n            waiter: UnsafeCell::new(Waiter {\n                queued: AtomicBool::new(false),\n                waker: None,\n                pointers: linked_list::Pointers::new(),\n                _p: PhantomPinned,\n            }),\n        }\n    }\n\n    /// A custom `project` implementation is used in place of `pin-project-lite`\n    /// as a custom drop implementation is needed.\n    fn project(self: Pin<&mut Self>) -> (&mut Receiver<T>, &UnsafeCell<Waiter>) {\n        unsafe {\n            // Safety: Receiver is Unpin\n            is_unpin::<&mut Receiver<T>>();\n\n            let me = self.get_unchecked_mut();\n            (me.receiver, &me.waiter)\n        }\n    }\n}\n\nimpl<'a, T> Future for Recv<'a, T>\nwhere\n    T: Clone,\n{\n    type Output = Result<T, RecvError>;\n\n    fn poll(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Result<T, RecvError>> {\n        ready!(crate::trace::trace_leaf(cx));\n\n        let (receiver, waiter) = self.project();\n\n        let guard = match receiver.recv_ref(Some((waiter, cx.waker()))) {\n            Ok(value) => value,\n            Err(TryRecvError::Empty) => return Poll::Pending,\n            Err(TryRecvError::Lagged(n)) => return Poll::Ready(Err(RecvError::Lagged(n))),\n            Err(TryRecvError::Closed) => return Poll::Ready(Err(RecvError::Closed)),\n        };\n\n        Poll::Ready(guard.clone_value().ok_or(RecvError::Closed))\n    }\n}\n\nimpl<'a, T> Drop for Recv<'a, T> {\n    fn drop(&mut self) {\n        // Safety: `waiter.queued` is atomic.\n        // Acquire ordering is required to synchronize with\n        // `Shared::notify_rx` before we drop the object.\n        let queued = self\n            .waiter\n            .with(|ptr| unsafe { (*ptr).queued.load(Acquire) });\n\n        // If the waiter is queued, we need to unlink it from the waiters list.\n        // If not, no further synchronization is required, since the waiter\n        // is not in the list and, as such, is not shared with any other threads.\n        if queued {\n            // Acquire the tail lock. This is required for safety before accessing\n            // the waiter node.\n            let mut tail = self.receiver.shared.tail.lock();\n\n            // Safety: tail lock is held.\n            // `Relaxed` order suffices because we hold the tail lock.\n            let queued = self\n                .waiter\n                .with_mut(|ptr| unsafe { (*ptr).queued.load(Relaxed) });\n\n            if queued {\n                // Remove the node\n                //\n                // safety: tail lock is held and the wait node is verified to be in\n                // the list.\n                unsafe {\n                    self.waiter.with_mut(|ptr| {\n                        tail.waiters.remove((&mut *ptr).into());\n                    });\n                }\n            }\n        }\n    }\n}\n\n/// # Safety\n///\n/// `Waiter` is forced to be !Unpin.\nunsafe impl linked_list::Link for Waiter {\n    type Handle = NonNull<Waiter>;\n    type Target = Waiter;\n\n    fn as_raw(handle: &NonNull<Waiter>) -> NonNull<Waiter> {\n        *handle\n    }\n\n    unsafe fn from_raw(ptr: NonNull<Waiter>) -> NonNull<Waiter> {\n        ptr\n    }\n\n    unsafe fn pointers(target: NonNull<Waiter>) -> NonNull<linked_list::Pointers<Waiter>> {\n        Waiter::addr_of_pointers(target)\n    }\n}\n\nimpl<T> fmt::Debug for Sender<T> {\n    fn fmt(&self, fmt: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(fmt, \"broadcast::Sender\")\n    }\n}\n\nimpl<T> fmt::Debug for Receiver<T> {\n    fn fmt(&self, fmt: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(fmt, \"broadcast::Receiver\")\n    }\n}\n\nimpl<'a, T> RecvGuard<'a, T> {\n    fn clone_value(&self) -> Option<T>\n    where\n        T: Clone,\n    {\n        self.slot.val.with(|ptr| unsafe { (*ptr).clone() })\n    }\n}\n\nimpl<'a, T> Drop for RecvGuard<'a, T> {\n    fn drop(&mut self) {\n        // Decrement the remaining counter\n        if 1 == self.slot.rem.fetch_sub(1, SeqCst) {\n            // Safety: Last receiver, drop the value\n            self.slot.val.with_mut(|ptr| unsafe { *ptr = None });\n        }\n    }\n}\n\nfn is_unpin<T: Unpin>() {}\n\n#[cfg(not(loom))]\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn receiver_count_on_sender_constructor() {\n        let sender = Sender::<i32>::new(16);\n        assert_eq!(sender.receiver_count(), 0);\n\n        let rx_1 = sender.subscribe();\n        assert_eq!(sender.receiver_count(), 1);\n\n        let rx_2 = rx_1.resubscribe();\n        assert_eq!(sender.receiver_count(), 2);\n\n        let rx_3 = sender.subscribe();\n        assert_eq!(sender.receiver_count(), 3);\n\n        drop(rx_3);\n        drop(rx_1);\n        assert_eq!(sender.receiver_count(), 1);\n\n        drop(rx_2);\n        assert_eq!(sender.receiver_count(), 0);\n    }\n\n    #[cfg(not(loom))]\n    #[test]\n    fn receiver_count_on_channel_constructor() {\n        let (sender, rx) = channel::<i32>(16);\n        assert_eq!(sender.receiver_count(), 1);\n\n        let _rx_2 = rx.resubscribe();\n        assert_eq!(sender.receiver_count(), 2);\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "50b1300ad3b09170688f8f4be9ca3d5df57ba6e2",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tokio/tokio/src/task/blocking.rs",
    "func": "use crate::task::JoinHandle;\n\ncfg_rt_multi_thread! {\n    /// Runs the provided blocking function on the current thread without\n    /// blocking the executor.\n    ///\n    /// In general, issuing a blocking call or performing a lot of compute in a\n    /// future without yielding is problematic, as it may prevent the executor\n    /// from driving other tasks forward. Calling this function informs the\n    /// executor that the currently executing task is about to block the thread,\n    /// so the executor is able to hand off any other tasks it has to a new\n    /// worker thread before that happens. See the [CPU-bound tasks and blocking\n    /// code][blocking] section for more information.\n    ///\n    /// Be aware that although this function avoids starving other independently\n    /// spawned tasks, any other code running concurrently in the same task will\n    /// be suspended during the call to `block_in_place`. This can happen e.g.\n    /// when using the [`join!`] macro. To avoid this issue, use\n    /// [`spawn_blocking`] instead of `block_in_place`.\n    ///\n    /// Note that this function cannot be used within a [`current_thread`] runtime\n    /// because in this case there are no other worker threads to hand off tasks\n    /// to. On the other hand, calling the function outside a runtime is\n    /// allowed. In this case, `block_in_place` just calls the provided closure\n    /// normally.\n    ///\n    /// Code running behind `block_in_place` cannot be cancelled. When you shut\n    /// down the executor, it will wait indefinitely for all blocking operations\n    /// to finish. You can use [`shutdown_timeout`] to stop waiting for them\n    /// after a certain timeout. Be aware that this will still not cancel the\n    /// tasks \u2014 they are simply allowed to keep running after the method\n    /// returns.\n    ///\n    /// [blocking]: ../index.html#cpu-bound-tasks-and-blocking-code\n    /// [`spawn_blocking`]: fn@crate::task::spawn_blocking\n    /// [`join!`]: macro@join\n    /// [`thread::spawn`]: fn@std::thread::spawn\n    /// [`shutdown_timeout`]: fn@crate::runtime::Runtime::shutdown_timeout\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use tokio::task;\n    ///\n    /// # async fn docs() {\n    /// task::block_in_place(move || {\n    ///     // do some compute-heavy work or call synchronous code\n    /// });\n    /// # }\n    /// ```\n    ///\n    /// Code running inside `block_in_place` may use `block_on` to reenter the\n    /// async context.\n    ///\n    /// ```\n    /// use tokio::task;\n    /// use tokio::runtime::Handle;\n    ///\n    /// # async fn docs() {\n    /// task::block_in_place(move || {\n    ///     Handle::current().block_on(async move {\n    ///         // do something async\n    ///     });\n    /// });\n    /// # }\n    /// ```\n    ///\n    /// # Panics\n    ///\n    /// This function panics if called from a [`current_thread`] runtime.\n    ///\n    /// [`current_thread`]: fn@crate::runtime::Builder::new_current_thread\n    #[track_caller]\n    pub fn block_in_place<F, R>(f: F) -> R\n    where\n        F: FnOnce() -> R,\n    {\n        crate::runtime::scheduler::block_in_place(f)\n    }\n}\n\ncfg_rt! {\n    /// Runs the provided closure on a thread where blocking is acceptable.\n    ///\n    /// In general, issuing a blocking call or performing a lot of compute in a\n    /// future without yielding is problematic, as it may prevent the executor from\n    /// driving other futures forward. This function runs the provided closure on a\n    /// thread dedicated to blocking operations. See the [CPU-bound tasks and\n    /// blocking code][blocking] section for more information.\n    ///\n    /// Tokio will spawn more blocking threads when they are requested through this\n    /// function until the upper limit configured on the [`Builder`] is reached.\n    /// After reaching the upper limit, the tasks are put in a queue.\n    /// The thread limit is very large by default, because `spawn_blocking` is often\n    /// used for various kinds of IO operations that cannot be performed\n    /// asynchronously.  When you run CPU-bound code using `spawn_blocking`, you\n    /// should keep this large upper limit in mind. When running many CPU-bound\n    /// computations, a semaphore or some other synchronization primitive should be\n    /// used to limit the number of computation executed in parallel. Specialized\n    /// CPU-bound executors, such as [rayon], may also be a good fit.\n    ///\n    /// This function is intended for non-async operations that eventually finish on\n    /// their own. If you want to spawn an ordinary thread, you should use\n    /// [`thread::spawn`] instead.\n    ///\n    /// Be aware that tasks spawned using `spawn_blocking` cannot be aborted\n    /// because they are not async. If you call [`abort`] on a `spawn_blocking`\n    /// task, then this *will not have any effect*, and the task will continue\n    /// running normally. The exception is if the task has not started running\n    /// yet; in that case, calling `abort` may prevent the task from starting.\n    ///\n    /// When you shut down the executor, it will wait indefinitely for all blocking operations to\n    /// finish. You can use [`shutdown_timeout`] to stop waiting for them after a\n    /// certain timeout. Be aware that this will still not cancel the tasks \u2014 they\n    /// are simply allowed to keep running after the method returns.  It is possible\n    /// for a blocking task to be cancelled if it has not yet started running, but this\n    /// is not guaranteed.\n    ///\n    /// Note that if you are using the single threaded runtime, this function will\n    /// still spawn additional threads for blocking operations. The current-thread\n    /// scheduler's single thread is only used for asynchronous code.\n    ///\n    /// # Related APIs and patterns for bridging asynchronous and blocking code\n    ///\n    /// In simple cases, it is sufficient to have the closure accept input\n    /// parameters at creation time and return a single value (or struct/tuple, etc.).\n    ///\n    /// For more complex situations in which it is desirable to stream data to or from\n    /// the synchronous context, the [`mpsc channel`] has `blocking_send` and\n    /// `blocking_recv` methods for use in non-async code such as the thread created\n    /// by `spawn_blocking`.\n    ///\n    /// Another option is [`SyncIoBridge`] for cases where the synchronous context\n    /// is operating on byte streams.  For example, you might use an asynchronous\n    /// HTTP client such as [hyper] to fetch data, but perform complex parsing\n    /// of the payload body using a library written for synchronous I/O.\n    ///\n    /// Finally, see also [Bridging with sync code][bridgesync] for discussions\n    /// around the opposite case of using Tokio as part of a larger synchronous\n    /// codebase.\n    ///\n    /// [`Builder`]: struct@crate::runtime::Builder\n    /// [blocking]: ../index.html#cpu-bound-tasks-and-blocking-code\n    /// [rayon]: https://docs.rs/rayon\n    /// [`mpsc channel`]: crate::sync::mpsc\n    /// [`SyncIoBridge`]: https://docs.rs/tokio-util/latest/tokio_util/io/struct.SyncIoBridge.html\n    /// [hyper]: https://docs.rs/hyper\n    /// [`thread::spawn`]: fn@std::thread::spawn\n    /// [`shutdown_timeout`]: fn@crate::runtime::Runtime::shutdown_timeout\n    /// [bridgesync]: https://tokio.rs/tokio/topics/bridging\n    /// [`AtomicBool`]: struct@std::sync::atomic::AtomicBool\n    /// [`abort`]: crate::task::JoinHandle::abort\n    ///\n    /// # Examples\n    ///\n    /// Pass an input value and receive result of computation:\n    ///\n    /// ```\n    /// use tokio::task;\n    ///\n    /// # async fn docs() -> Result<(), Box<dyn std::error::Error>>{\n    /// // Initial input\n    /// let mut v = \"Hello, \".to_string();\n    /// let res = task::spawn_blocking(move || {\n    ///     // Stand-in for compute-heavy work or using synchronous APIs\n    ///     v.push_str(\"world\");\n    ///     // Pass ownership of the value back to the asynchronous context\n    ///     v\n    /// }).await?;\n    ///\n    /// // `res` is the value returned from the thread\n    /// assert_eq!(res.as_str(), \"Hello, world\");\n    /// # Ok(())\n    /// # }\n    /// ```\n    ///\n    /// Use a channel:\n    ///\n    /// ```\n    /// use tokio::task;\n    /// use tokio::sync::mpsc;\n    ///\n    /// # async fn docs() {\n    /// let (tx, mut rx) = mpsc::channel(2);\n    /// let start = 5;\n    /// let worker = task::spawn_blocking(move || {\n    ///     for x in 0..10 {\n    ///         // Stand in for complex computation\n    ///         tx.blocking_send(start + x).unwrap();\n    ///     }\n    /// });\n    ///\n    /// let mut acc = 0;\n    /// while let Some(v) = rx.recv().await {\n    ///     acc += v;\n    /// }\n    /// assert_eq!(acc, 95);\n    /// worker.await.unwrap();\n    /// # }\n    /// ```\n    #[track_caller]\n    pub fn spawn_blocking<F, R>(f: F) -> JoinHandle<R>\n    where\n        F: FnOnce() -> R + Send + 'static,\n        R: Send + 'static,\n    {\n        crate::runtime::spawn_blocking(f)\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "c51c5cb363892c9fa08c70b88121993ea0954995",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tokio/tokio/src/net/tcp/mod.rs",
    "func": "//! TCP utility types.\n\npub(crate) mod listener;\n\ncfg_not_wasi! {\n    pub(crate) mod socket;\n}\n\nmod split;\npub use split::{ReadHalf, WriteHalf};\n\nmod split_owned;\npub use split_owned::{OwnedReadHalf, OwnedWriteHalf, ReuniteError};\n\npub(crate) mod stream;\npub(crate) use stream::TcpStream;\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "9dfc6239a753997d8c376fac9e1a87bd28e41a64",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tokio/tokio/src/macros/try_join.rs",
    "func": "macro_rules! doc {\n    ($try_join:item) => {\n        /// Waits on multiple concurrent branches, returning when **all** branches\n        /// complete with `Ok(_)` or on the first `Err(_)`.\n        ///\n        /// The `try_join!` macro must be used inside of async functions, closures, and\n        /// blocks.\n        ///\n        /// Similar to [`join!`], the `try_join!` macro takes a list of async\n        /// expressions and evaluates them concurrently on the same task. Each async\n        /// expression evaluates to a future and the futures from each expression are\n        /// multiplexed on the current task. The `try_join!` macro returns when **all**\n        /// branches return with `Ok` or when the **first** branch returns with `Err`.\n        ///\n        /// [`join!`]: macro@join\n        ///\n        /// # Notes\n        ///\n        /// The supplied futures are stored inline and do not require allocating a\n        /// `Vec`.\n        ///\n        /// ### Runtime characteristics\n        ///\n        /// By running all async expressions on the current task, the expressions are\n        /// able to run **concurrently** but not in **parallel**. This means all\n        /// expressions are run on the same thread and if one branch blocks the thread,\n        /// all other expressions will be unable to continue. If parallelism is\n        /// required, spawn each async expression using [`tokio::spawn`] and pass the\n        /// join handle to `try_join!`.\n        ///\n        /// [`tokio::spawn`]: crate::spawn\n        ///\n        /// # Examples\n        ///\n        /// Basic `try_join` with two branches.\n        ///\n        /// ```\n        /// async fn do_stuff_async() -> Result<(), &'static str> {\n        ///     // async work\n        /// # Ok(())\n        /// }\n        ///\n        /// async fn more_async_work() -> Result<(), &'static str> {\n        ///     // more here\n        /// # Ok(())\n        /// }\n        ///\n        /// #[tokio::main]\n        /// async fn main() {\n        ///     let res = tokio::try_join!(\n        ///         do_stuff_async(),\n        ///         more_async_work());\n        ///\n        ///     match res {\n        ///          Ok((first, second)) => {\n        ///              // do something with the values\n        ///          }\n        ///          Err(err) => {\n        ///             println!(\"processing failed; error = {}\", err);\n        ///          }\n        ///     }\n        /// }\n        /// ```\n        ///\n        /// Using `try_join!` with spawned tasks.\n        ///\n        /// ```\n        /// use tokio::task::JoinHandle;\n        ///\n        /// async fn do_stuff_async() -> Result<(), &'static str> {\n        ///     // async work\n        /// # Err(\"failed\")\n        /// }\n        ///\n        /// async fn more_async_work() -> Result<(), &'static str> {\n        ///     // more here\n        /// # Ok(())\n        /// }\n        ///\n        /// async fn flatten<T>(handle: JoinHandle<Result<T, &'static str>>) -> Result<T, &'static str> {\n        ///     match handle.await {\n        ///         Ok(Ok(result)) => Ok(result),\n        ///         Ok(Err(err)) => Err(err),\n        ///         Err(err) => Err(\"handling failed\"),\n        ///     }\n        /// }\n        ///\n        /// #[tokio::main]\n        /// async fn main() {\n        ///     let handle1 = tokio::spawn(do_stuff_async());\n        ///     let handle2 = tokio::spawn(more_async_work());\n        ///     match tokio::try_join!(flatten(handle1), flatten(handle2)) {\n        ///         Ok(val) => {\n        ///             // do something with the values\n        ///         }\n        ///         Err(err) => {\n        ///             println!(\"Failed with {}.\", err);\n        ///             # assert_eq!(err, \"failed\");\n        ///         }\n        ///     }\n        /// }\n        /// ```\n        #[macro_export]\n        #[cfg_attr(docsrs, doc(cfg(feature = \"macros\")))]\n        $try_join\n    };\n}\n\n#[cfg(doc)]\ndoc! {macro_rules! try_join {\n    ($($future:expr),*) => { unimplemented!() }\n}}\n\n#[cfg(not(doc))]\ndoc! {macro_rules! try_join {\n    (@ {\n        // One `_` for each branch in the `try_join!` macro. This is not used once\n        // normalization is complete.\n        ( $($count:tt)* )\n\n        // The expression `0+1+1+ ... +1` equal to the number of branches.\n        ( $($total:tt)* )\n\n        // Normalized try_join! branches\n        $( ( $($skip:tt)* ) $e:expr, )*\n\n    }) => {{\n        use $crate::macros::support::{maybe_done, poll_fn, Future, Pin};\n        use $crate::macros::support::Poll::{Ready, Pending};\n\n        // Safety: nothing must be moved out of `futures`. This is to satisfy\n        // the requirement of `Pin::new_unchecked` called below.\n        //\n        // We can't use the `pin!` macro for this because `futures` is a tuple\n        // and the standard library provides no way to pin-project to the fields\n        // of a tuple.\n        let mut futures = ( $( maybe_done($e), )* );\n\n        // This assignment makes sure that the `poll_fn` closure only has a\n        // reference to the futures, instead of taking ownership of them. This\n        // mitigates the issue described in\n        // <https://internals.rust-lang.org/t/surprising-soundness-trouble-around-pollfn/17484>\n        let mut futures = &mut futures;\n\n        // Each time the future created by poll_fn is polled, a different future will be polled first\n        // to ensure every future passed to join! gets a chance to make progress even if\n        // one of the futures consumes the whole budget.\n        //\n        // This is number of futures that will be skipped in the first loop\n        // iteration the next time.\n        let mut skip_next_time: u32 = 0;\n\n        poll_fn(move |cx| {\n            const COUNT: u32 = $($total)*;\n\n            let mut is_pending = false;\n\n            let mut to_run = COUNT;\n\n            // The number of futures that will be skipped in the first loop iteration\n            let mut skip = skip_next_time;\n\n            skip_next_time = if skip + 1 == COUNT { 0 } else { skip + 1 };\n\n            // This loop runs twice and the first `skip` futures\n            // are not polled in the first iteration.\n            loop {\n            $(\n                if skip == 0 {\n                    if to_run == 0 {\n                        // Every future has been polled\n                        break;\n                    }\n                    to_run -= 1;\n\n                    // Extract the future for this branch from the tuple.\n                    let ( $($skip,)* fut, .. ) = &mut *futures;\n\n                    // Safety: future is stored on the stack above\n                    // and never moved.\n                    let mut fut = unsafe { Pin::new_unchecked(fut) };\n\n                    // Try polling\n                    if fut.as_mut().poll(cx).is_pending() {\n                        is_pending = true;\n                    } else if fut.as_mut().output_mut().expect(\"expected completed future\").is_err() {\n                        return Ready(Err(fut.take_output().expect(\"expected completed future\").err().unwrap()))\n                    }\n                } else {\n                    // Future skipped, one less future to skip in the next iteration\n                    skip -= 1;\n                }\n            )*\n            }\n\n            if is_pending {\n                Pending\n            } else {\n                Ready(Ok(($({\n                    // Extract the future for this branch from the tuple.\n                    let ( $($skip,)* fut, .. ) = &mut futures;\n\n                    // Safety: future is stored on the stack above\n                    // and never moved.\n                    let mut fut = unsafe { Pin::new_unchecked(fut) };\n\n                    fut\n                        .take_output()\n                        .expect(\"expected completed future\")\n                        .ok()\n                        .expect(\"expected Ok(_)\")\n                },)*)))\n            }\n        }).await\n    }};\n\n    // ===== Normalize =====\n\n    (@ { ( $($s:tt)* ) ( $($n:tt)* ) $($t:tt)* } $e:expr, $($r:tt)* ) => {\n      $crate::try_join!(@{ ($($s)* _) ($($n)* + 1) $($t)* ($($s)*) $e, } $($r)*)\n    };\n\n    // ===== Entry point =====\n\n    ( $($e:expr),+ $(,)?) => {\n        $crate::try_join!(@{ () (0) } $($e,)*)\n    };\n\n    () => { async { Ok(()) }.await }\n}}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "aa0552fbb3242ccc2fc84bbfa6af4ff76ee80d9a",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tokio/tokio-stream/tests/stream_iter.rs",
    "func": "use tokio_stream as stream;\nuse tokio_test::task;\n\nuse std::iter;\n\n#[tokio::test]\nasync fn coop() {\n    let mut stream = task::spawn(stream::iter(iter::repeat(1)));\n\n    for _ in 0..10_000 {\n        if stream.poll_next().is_pending() {\n            assert!(stream.is_woken());\n            return;\n        }\n    }\n\n    panic!(\"did not yield\");\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "3266352fe6c4dceef5634186e5af8f03c65ea5f2",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/tokio/tokio-macros/src/lib.rs",
    "func": "#![allow(unknown_lints, unexpected_cfgs)]\n#![allow(clippy::needless_doctest_main)]\n#![warn(\n    missing_debug_implementations,\n    missing_docs,\n    rust_2018_idioms,\n    unreachable_pub\n)]\n#![doc(test(\n    no_crate_inject,\n    attr(deny(warnings, rust_2018_idioms), allow(dead_code, unused_variables))\n))]\n\n//! Macros for use with Tokio\n\n// This `extern` is required for older `rustc` versions but newer `rustc`\n// versions warn about the unused `extern crate`.\n#[allow(unused_extern_crates)]\nextern crate proc_macro;\n\nmod entry;\nmod select;\n\nuse proc_macro::TokenStream;\n\n/// Marks async function to be executed by the selected runtime. This macro\n/// helps set up a `Runtime` without requiring the user to use\n/// [Runtime](../tokio/runtime/struct.Runtime.html) or\n/// [Builder](../tokio/runtime/struct.Builder.html) directly.\n///\n/// Note: This macro is designed to be simplistic and targets applications that\n/// do not require a complex setup. If the provided functionality is not\n/// sufficient, you may be interested in using\n/// [Builder](../tokio/runtime/struct.Builder.html), which provides a more\n/// powerful interface.\n///\n/// Note: This macro can be used on any function and not just the `main`\n/// function. Using it on a non-main function makes the function behave as if it\n/// was synchronous by starting a new runtime each time it is called. If the\n/// function is called often, it is preferable to create the runtime using the\n/// runtime builder so the runtime can be reused across calls.\n///\n/// # Non-worker async function\n///\n/// Note that the async function marked with this macro does not run as a\n/// worker. The expectation is that other tasks are spawned by the function here.\n/// Awaiting on other futures from the function provided here will not\n/// perform as fast as those spawned as workers.\n///\n/// # Multi-threaded runtime\n///\n/// To use the multi-threaded runtime, the macro can be configured using\n///\n/// ```\n/// #[tokio::main(flavor = \"multi_thread\", worker_threads = 10)]\n/// # async fn main() {}\n/// ```\n///\n/// The `worker_threads` option configures the number of worker threads, and\n/// defaults to the number of cpus on the system. This is the default flavor.\n///\n/// Note: The multi-threaded runtime requires the `rt-multi-thread` feature\n/// flag.\n///\n/// # Current thread runtime\n///\n/// To use the single-threaded runtime known as the `current_thread` runtime,\n/// the macro can be configured using\n///\n/// ```\n/// #[tokio::main(flavor = \"current_thread\")]\n/// # async fn main() {}\n/// ```\n///\n/// ## Function arguments:\n///\n/// Arguments are allowed for any functions aside from `main` which is special\n///\n/// ## Usage\n///\n/// ### Using the multi-thread runtime\n///\n/// ```rust\n/// #[tokio::main]\n/// async fn main() {\n///     println!(\"Hello world\");\n/// }\n/// ```\n///\n/// Equivalent code not using `#[tokio::main]`\n///\n/// ```rust\n/// fn main() {\n///     tokio::runtime::Builder::new_multi_thread()\n///         .enable_all()\n///         .build()\n///         .unwrap()\n///         .block_on(async {\n///             println!(\"Hello world\");\n///         })\n/// }\n/// ```\n///\n/// ### Using current thread runtime\n///\n/// The basic scheduler is single-threaded.\n///\n/// ```rust\n/// #[tokio::main(flavor = \"current_thread\")]\n/// async fn main() {\n///     println!(\"Hello world\");\n/// }\n/// ```\n///\n/// Equivalent code not using `#[tokio::main]`\n///\n/// ```rust\n/// fn main() {\n///     tokio::runtime::Builder::new_current_thread()\n///         .enable_all()\n///         .build()\n///         .unwrap()\n///         .block_on(async {\n///             println!(\"Hello world\");\n///         })\n/// }\n/// ```\n///\n/// ### Set number of worker threads\n///\n/// ```rust\n/// #[tokio::main(worker_threads = 2)]\n/// async fn main() {\n///     println!(\"Hello world\");\n/// }\n/// ```\n///\n/// Equivalent code not using `#[tokio::main]`\n///\n/// ```rust\n/// fn main() {\n///     tokio::runtime::Builder::new_multi_thread()\n///         .worker_threads(2)\n///         .enable_all()\n///         .build()\n///         .unwrap()\n///         .block_on(async {\n///             println!(\"Hello world\");\n///         })\n/// }\n/// ```\n///\n/// ### Configure the runtime to start with time paused\n///\n/// ```rust\n/// #[tokio::main(flavor = \"current_thread\", start_paused = true)]\n/// async fn main() {\n///     println!(\"Hello world\");\n/// }\n/// ```\n///\n/// Equivalent code not using `#[tokio::main]`\n///\n/// ```rust\n/// fn main() {\n///     tokio::runtime::Builder::new_current_thread()\n///         .enable_all()\n///         .start_paused(true)\n///         .build()\n///         .unwrap()\n///         .block_on(async {\n///             println!(\"Hello world\");\n///         })\n/// }\n/// ```\n///\n/// Note that `start_paused` requires the `test-util` feature to be enabled.\n///\n/// ### Rename package\n///\n/// ```rust\n/// use tokio as tokio1;\n///\n/// #[tokio1::main(crate = \"tokio1\")]\n/// async fn main() {\n///     println!(\"Hello world\");\n/// }\n/// ```\n///\n/// Equivalent code not using `#[tokio::main]`\n///\n/// ```rust\n/// use tokio as tokio1;\n///\n/// fn main() {\n///     tokio1::runtime::Builder::new_multi_thread()\n///         .enable_all()\n///         .build()\n///         .unwrap()\n///         .block_on(async {\n///             println!(\"Hello world\");\n///         })\n/// }\n/// ```\n///\n/// ### Configure unhandled panic behavior\n///\n/// Available options are `shutdown_runtime` and `ignore`. For more details, see\n/// [`Builder::unhandled_panic`].\n///\n/// This option is only compatible with the `current_thread` runtime.\n///\n/// ```no_run\n/// # #![allow(unknown_lints, unexpected_cfgs)]\n/// #[cfg(tokio_unstable)]\n/// #[tokio::main(flavor = \"current_thread\", unhandled_panic = \"shutdown_runtime\")]\n/// async fn main() {\n///     let _ = tokio::spawn(async {\n///         panic!(\"This panic will shutdown the runtime.\");\n///     }).await;\n/// }\n/// # #[cfg(not(tokio_unstable))]\n/// # fn main() { }\n/// ```\n///\n/// Equivalent code not using `#[tokio::main]`\n///\n/// ```no_run\n/// # #![allow(unknown_lints, unexpected_cfgs)]\n/// #[cfg(tokio_unstable)]\n/// fn main() {\n///     tokio::runtime::Builder::new_current_thread()\n///         .enable_all()\n///         .unhandled_panic(UnhandledPanic::ShutdownRuntime)\n///         .build()\n///         .unwrap()\n///         .block_on(async {\n///             let _ = tokio::spawn(async {\n///                 panic!(\"This panic will shutdown the runtime.\");\n///             }).await;\n///         })\n/// }\n/// # #[cfg(not(tokio_unstable))]\n/// # fn main() { }\n/// ```\n///\n/// **Note**: This option depends on Tokio's [unstable API][unstable]. See [the\n/// documentation on unstable features][unstable] for details on how to enable\n/// Tokio's unstable features.\n///\n/// [`Builder::unhandled_panic`]: ../tokio/runtime/struct.Builder.html#method.unhandled_panic\n/// [unstable]: ../tokio/index.html#unstable-features\n#[proc_macro_attribute]\npub fn main(args: TokenStream, item: TokenStream) -> TokenStream {\n    entry::main(args.into(), item.into(), true).into()\n}\n\n/// Marks async function to be executed by selected runtime. This macro helps set up a `Runtime`\n/// without requiring the user to use [Runtime](../tokio/runtime/struct.Runtime.html) or\n/// [Builder](../tokio/runtime/struct.Builder.html) directly.\n///\n/// ## Function arguments:\n///\n/// Arguments are allowed for any functions aside from `main` which is special\n///\n/// ## Usage\n///\n/// ### Using default\n///\n/// ```rust\n/// #[tokio::main(flavor = \"current_thread\")]\n/// async fn main() {\n///     println!(\"Hello world\");\n/// }\n/// ```\n///\n/// Equivalent code not using `#[tokio::main]`\n///\n/// ```rust\n/// fn main() {\n///     tokio::runtime::Builder::new_current_thread()\n///         .enable_all()\n///         .build()\n///         .unwrap()\n///         .block_on(async {\n///             println!(\"Hello world\");\n///         })\n/// }\n/// ```\n///\n/// ### Rename package\n///\n/// ```rust\n/// use tokio as tokio1;\n///\n/// #[tokio1::main(crate = \"tokio1\")]\n/// async fn main() {\n///     println!(\"Hello world\");\n/// }\n/// ```\n///\n/// Equivalent code not using `#[tokio::main]`\n///\n/// ```rust\n/// use tokio as tokio1;\n///\n/// fn main() {\n///     tokio1::runtime::Builder::new_multi_thread()\n///         .enable_all()\n///         .build()\n///         .unwrap()\n///         .block_on(async {\n///             println!(\"Hello world\");\n///         })\n/// }\n/// ```\n#[proc_macro_attribute]\npub fn main_rt(args: TokenStream, item: TokenStream) -> TokenStream {\n    entry::main(args.into(), item.into(), false).into()\n}\n\n/// Marks async function to be executed by runtime, suitable to test environment.\n/// This macro helps set up a `Runtime` without requiring the user to use\n/// [Runtime](../tokio/runtime/struct.Runtime.html) or\n/// [Builder](../tokio/runtime/struct.Builder.html) directly.\n///\n/// Note: This macro is designed to be simplistic and targets applications that\n/// do not require a complex setup. If the provided functionality is not\n/// sufficient, you may be interested in using\n/// [Builder](../tokio/runtime/struct.Builder.html), which provides a more\n/// powerful interface.\n///\n/// # Multi-threaded runtime\n///\n/// To use the multi-threaded runtime, the macro can be configured using\n///\n/// ```no_run\n/// #[tokio::test(flavor = \"multi_thread\", worker_threads = 1)]\n/// async fn my_test() {\n///     assert!(true);\n/// }\n/// ```\n///\n/// The `worker_threads` option configures the number of worker threads, and\n/// defaults to the number of cpus on the system.\n///\n/// Note: The multi-threaded runtime requires the `rt-multi-thread` feature\n/// flag.\n///\n/// # Current thread runtime\n///\n/// The default test runtime is single-threaded. Each test gets a\n/// separate current-thread runtime.\n///\n/// ```no_run\n/// #[tokio::test]\n/// async fn my_test() {\n///     assert!(true);\n/// }\n/// ```\n///\n/// ## Usage\n///\n/// ### Using the multi-thread runtime\n///\n/// ```no_run\n/// #[tokio::test(flavor = \"multi_thread\")]\n/// async fn my_test() {\n///     assert!(true);\n/// }\n/// ```\n///\n/// Equivalent code not using `#[tokio::test]`\n///\n/// ```no_run\n/// #[test]\n/// fn my_test() {\n///     tokio::runtime::Builder::new_multi_thread()\n///         .enable_all()\n///         .build()\n///         .unwrap()\n///         .block_on(async {\n///             assert!(true);\n///         })\n/// }\n/// ```\n///\n/// ### Using current thread runtime\n///\n/// ```no_run\n/// #[tokio::test]\n/// async fn my_test() {\n///     assert!(true);\n/// }\n/// ```\n///\n/// Equivalent code not using `#[tokio::test]`\n///\n/// ```no_run\n/// #[test]\n/// fn my_test() {\n///     tokio::runtime::Builder::new_current_thread()\n///         .enable_all()\n///         .build()\n///         .unwrap()\n///         .block_on(async {\n///             assert!(true);\n///         })\n/// }\n/// ```\n///\n/// ### Set number of worker threads\n///\n/// ```no_run\n/// #[tokio::test(flavor = \"multi_thread\", worker_threads = 2)]\n/// async fn my_test() {\n///     assert!(true);\n/// }\n/// ```\n///\n/// Equivalent code not using `#[tokio::test]`\n///\n/// ```no_run\n/// #[test]\n/// fn my_test() {\n///     tokio::runtime::Builder::new_multi_thread()\n///         .worker_threads(2)\n///         .enable_all()\n///         .build()\n///         .unwrap()\n///         .block_on(async {\n///             assert!(true);\n///         })\n/// }\n/// ```\n///\n/// ### Configure the runtime to start with time paused\n///\n/// ```no_run\n/// #[tokio::test(start_paused = true)]\n/// async fn my_test() {\n///     assert!(true);\n/// }\n/// ```\n///\n/// Equivalent code not using `#[tokio::test]`\n///\n/// ```no_run\n/// #[test]\n/// fn my_test() {\n///     tokio::runtime::Builder::new_current_thread()\n///         .enable_all()\n///         .start_paused(true)\n///         .build()\n///         .unwrap()\n///         .block_on(async {\n///             assert!(true);\n///         })\n/// }\n/// ```\n///\n/// Note that `start_paused` requires the `test-util` feature to be enabled.\n///\n/// ### Rename package\n///\n/// ```rust\n/// use tokio as tokio1;\n///\n/// #[tokio1::test(crate = \"tokio1\")]\n/// async fn my_test() {\n///     println!(\"Hello world\");\n/// }\n/// ```\n///\n/// ### Configure unhandled panic behavior\n///\n/// Available options are `shutdown_runtime` and `ignore`. For more details, see\n/// [`Builder::unhandled_panic`].\n///\n/// This option is only compatible with the `current_thread` runtime.\n///\n/// ```no_run\n/// # #![allow(unknown_lints, unexpected_cfgs)]\n/// #[cfg(tokio_unstable)]\n/// #[tokio::test(flavor = \"current_thread\", unhandled_panic = \"shutdown_runtime\")]\n/// async fn my_test() {\n///     let _ = tokio::spawn(async {\n///         panic!(\"This panic will shutdown the runtime.\");\n///     }).await;\n/// }\n/// # #[cfg(not(tokio_unstable))]\n/// # fn main() { }\n/// ```\n///\n/// Equivalent code not using `#[tokio::test]`\n///\n/// ```no_run\n/// # #![allow(unknown_lints, unexpected_cfgs)]\n/// #[cfg(tokio_unstable)]\n/// #[test]\n/// fn my_test() {\n///     tokio::runtime::Builder::new_current_thread()\n///         .enable_all()\n///         .unhandled_panic(UnhandledPanic::ShutdownRuntime)\n///         .build()\n///         .unwrap()\n///         .block_on(async {\n///             let _ = tokio::spawn(async {\n///                 panic!(\"This panic will shutdown the runtime.\");\n///             }).await;\n///         })\n/// }\n/// # #[cfg(not(tokio_unstable))]\n/// # fn main() { }\n/// ```\n///\n/// **Note**: This option depends on Tokio's [unstable API][unstable]. See [the\n/// documentation on unstable features][unstable] for details on how to enable\n/// Tokio's unstable features.\n///\n/// [`Builder::unhandled_panic`]: ../tokio/runtime/struct.Builder.html#method.unhandled_panic\n/// [unstable]: ../tokio/index.html#unstable-features\n#[proc_macro_attribute]\npub fn test(args: TokenStream, item: TokenStream) -> TokenStream {\n    entry::test(args.into(), item.into(), true).into()\n}\n\n/// Marks async function to be executed by runtime, suitable to test environment\n///\n/// ## Usage\n///\n/// ```no_run\n/// #[tokio::test]\n/// async fn my_test() {\n///     assert!(true);\n/// }\n/// ```\n#[proc_macro_attribute]\npub fn test_rt(args: TokenStream, item: TokenStream) -> TokenStream {\n    entry::test(args.into(), item.into(), false).into()\n}\n\n/// Always fails with the error message below.\n/// ```text\n/// The #[tokio::main] macro requires rt or rt-multi-thread.\n/// ```\n#[proc_macro_attribute]\npub fn main_fail(_args: TokenStream, _item: TokenStream) -> TokenStream {\n    syn::Error::new(\n        proc_macro2::Span::call_site(),\n        \"The #[tokio::main] macro requires rt or rt-multi-thread.\",\n    )\n    .to_compile_error()\n    .into()\n}\n\n/// Always fails with the error message below.\n/// ```text\n/// The #[tokio::test] macro requires rt or rt-multi-thread.\n/// ```\n#[proc_macro_attribute]\npub fn test_fail(_args: TokenStream, _item: TokenStream) -> TokenStream {\n    syn::Error::new(\n        proc_macro2::Span::call_site(),\n        \"The #[tokio::test] macro requires rt or rt-multi-thread.\",\n    )\n    .to_compile_error()\n    .into()\n}\n\n/// Implementation detail of the `select!` macro. This macro is **not** intended\n/// to be used as part of the public API and is permitted to change.\n#[proc_macro]\n#[doc(hidden)]\npub fn select_priv_declare_output_enum(input: TokenStream) -> TokenStream {\n    select::declare_output_enum(input)\n}\n\n/// Implementation detail of the `select!` macro. This macro is **not** intended\n/// to be used as part of the public API and is permitted to change.\n#[proc_macro]\n#[doc(hidden)]\npub fn select_priv_clean_pattern(input: TokenStream) -> TokenStream {\n    select::clean_pattern_macro(input)\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "0d0218faab9f76d9a05021ccba185d37a03a361f",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/tests/bits_tests.rs",
    "func": "#![allow(unused_imports, dead_code)]\n\npub mod common;\n\nuse common::features::*;\nuse pretty_assertions::assert_eq;\nuse sea_orm::{entity::prelude::*, entity::*, DatabaseConnection};\n\n#[sea_orm_macros::test]\n#[cfg(feature = \"sqlx-postgres\")]\nasync fn main() -> Result<(), DbErr> {\n    let ctx = common::TestContext::new(\"bits_tests\").await;\n    create_tables(&ctx.db).await?;\n    create_and_update(&ctx.db).await?;\n    ctx.delete().await;\n\n    Ok(())\n}\n\npub async fn create_and_update(db: &DatabaseConnection) -> Result<(), DbErr> {\n    let bits = bits::Model {\n        id: 1,\n        bit0: 0,\n        bit1: 1,\n        bit8: 8,\n        bit16: 16,\n        bit32: 32,\n        bit64: 64,\n    };\n\n    let res = bits.clone().into_active_model().insert(db).await?;\n\n    let model = Bits::find().one(db).await?;\n    assert_eq!(model, Some(res));\n    assert_eq!(model, Some(bits.clone()));\n\n    let res = bits::ActiveModel {\n        bit32: Set(320),\n        bit64: Set(640),\n        ..bits.clone().into_active_model()\n    }\n    .update(db)\n    .await?;\n\n    let model = Bits::find().one(db).await?;\n    assert_eq!(model, Some(res));\n    assert_eq!(\n        model,\n        Some(bits::Model {\n            id: 1,\n            bit0: 0,\n            bit1: 1,\n            bit8: 8,\n            bit16: 16,\n            bit32: 320,\n            bit64: 640,\n        })\n    );\n\n    Ok(())\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "a42cbc16da86ef4f6ee8d8a3279ad4344d7f70e6",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/sea-orm-migration/tests/common/migration/m20220118_000002_create_fruit_table.rs",
    "func": "use super::m20220118_000001_create_cake_table::Cake;\nuse sea_orm_migration::sea_orm::DbBackend;\nuse sea_orm_migration::{prelude::*, schema::*};\n\n#[derive(DeriveMigrationName)]\npub struct Migration;\n\n#[async_trait::async_trait]\nimpl MigrationTrait for Migration {\n    async fn up(&self, manager: &SchemaManager) -> Result<(), DbErr> {\n        manager\n            .create_table(\n                Table::create()\n                    .table(Fruit::Table)\n                    .col(pk_auto(Fruit::Id))\n                    .col(string(Fruit::Name))\n                    .col(integer(Fruit::CakeId))\n                    .foreign_key(\n                        ForeignKey::create()\n                            .name(\"fk-fruit-cake_id\")\n                            .from(Fruit::Table, Fruit::CakeId)\n                            .to(Cake::Table, Cake::Id),\n                    )\n                    .to_owned(),\n            )\n            .await\n    }\n\n    async fn down(&self, manager: &SchemaManager) -> Result<(), DbErr> {\n        if manager.get_database_backend() != DbBackend::Sqlite {\n            manager\n                .drop_foreign_key(\n                    ForeignKey::drop()\n                        .table(Fruit::Table)\n                        .name(\"fk-fruit-cake_id\")\n                        .to_owned(),\n                )\n                .await?;\n        }\n        manager\n            .drop_table(Table::drop().table(Fruit::Table).to_owned())\n            .await\n    }\n}\n\n#[derive(DeriveIden)]\npub enum Fruit {\n    Table,\n    Id,\n    Name,\n    CakeId,\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "c542864b9d3d3f014890730814cae98a01ddcb7e",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/sea-orm-macros/src/derives/try_getable_from_json.rs",
    "func": "use proc_macro2::{Ident, TokenStream};\nuse quote::quote;\n\npub fn expand_derive_from_json_query_result(ident: Ident) -> syn::Result<TokenStream> {\n    let impl_not_u8 = if cfg!(feature = \"postgres-array\") {\n        quote!(\n            #[automatically_derived]\n            impl sea_orm::sea_query::value::with_array::NotU8 for #ident {}\n        )\n    } else {\n        quote!()\n    };\n\n    Ok(quote!(\n        #[automatically_derived]\n        impl sea_orm::TryGetableFromJson for #ident {}\n\n        #[automatically_derived]\n        impl std::convert::From<#ident> for sea_orm::Value {\n            fn from(source: #ident) -> Self {\n                sea_orm::Value::Json(serde_json::to_value(&source).ok().map(|s| std::boxed::Box::new(s)))\n            }\n        }\n\n        #[automatically_derived]\n        impl sea_orm::sea_query::ValueType for #ident {\n            fn try_from(v: sea_orm::Value) -> Result<Self, sea_orm::sea_query::ValueTypeErr> {\n                match v {\n                    sea_orm::Value::Json(Some(json)) => Ok(\n                        serde_json::from_value(*json).map_err(|_| sea_orm::sea_query::ValueTypeErr)?,\n                    ),\n                    _ => Err(sea_orm::sea_query::ValueTypeErr),\n                }\n            }\n\n            fn type_name() -> String {\n                stringify!(#ident).to_owned()\n            }\n\n            fn array_type() -> sea_orm::sea_query::ArrayType {\n                sea_orm::sea_query::ArrayType::Json\n            }\n\n            fn column_type() -> sea_orm::sea_query::ColumnType {\n                sea_orm::sea_query::ColumnType::Json\n            }\n        }\n\n        #[automatically_derived]\n        impl sea_orm::sea_query::Nullable for #ident {\n            fn null() -> sea_orm::Value {\n                sea_orm::Value::Json(None)\n            }\n        }\n\n        #impl_not_u8\n    ))\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "8267efa90a5d28c3c3ed3c8fbac2786a25dae7c4",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/sea-orm-macros/src/derives/relation.rs",
    "func": "use proc_macro2::TokenStream;\nuse quote::{format_ident, quote, quote_spanned};\n\nuse super::attributes::{derive_attr, field_attr};\n\nenum Error {\n    InputNotEnum,\n    Syn(syn::Error),\n}\n\nstruct DeriveRelation {\n    entity_ident: syn::Ident,\n    ident: syn::Ident,\n    variants: syn::punctuated::Punctuated<syn::Variant, syn::token::Comma>,\n}\n\nimpl DeriveRelation {\n    fn new(input: syn::DeriveInput) -> Result<Self, Error> {\n        let variants = match input.data {\n            syn::Data::Enum(syn::DataEnum { variants, .. }) => variants,\n            _ => return Err(Error::InputNotEnum),\n        };\n\n        let sea_attr = derive_attr::SeaOrm::try_from_attributes(&input.attrs)\n            .map_err(Error::Syn)?\n            .unwrap_or_default();\n\n        let ident = input.ident;\n        let entity_ident = sea_attr.entity.unwrap_or_else(|| format_ident!(\"Entity\"));\n\n        Ok(DeriveRelation {\n            entity_ident,\n            ident,\n            variants,\n        })\n    }\n\n    fn expand(&self) -> syn::Result<TokenStream> {\n        let expanded_impl_relation_trait = self.impl_relation_trait()?;\n\n        Ok(expanded_impl_relation_trait)\n    }\n\n    fn impl_relation_trait(&self) -> syn::Result<TokenStream> {\n        let ident = &self.ident;\n        let entity_ident = &self.entity_ident;\n        let no_relation_def_msg = format!(\"No RelationDef for {ident}\");\n\n        let variant_relation_defs: Vec<TokenStream> = self\n            .variants\n            .iter()\n            .map(|variant| {\n                let variant_ident = &variant.ident;\n                let attr = field_attr::SeaOrm::from_attributes(&variant.attrs)?;\n                let mut relation_type = quote! { error };\n                let related_to = if attr.belongs_to.is_some() {\n                    relation_type = quote! { belongs_to };\n                    attr.belongs_to\n                        .as_ref()\n                        .map(Self::parse_lit_string)\n                        .ok_or_else(|| {\n                            syn::Error::new_spanned(variant, \"Missing value for 'belongs_to'\")\n                        })\n                } else if attr.has_one.is_some() {\n                    relation_type = quote! { has_one };\n                    attr.has_one\n                        .as_ref()\n                        .map(Self::parse_lit_string)\n                        .ok_or_else(|| {\n                            syn::Error::new_spanned(variant, \"Missing value for 'has_one'\")\n                        })\n                } else if attr.has_many.is_some() {\n                    relation_type = quote! { has_many };\n                    attr.has_many\n                        .as_ref()\n                        .map(Self::parse_lit_string)\n                        .ok_or_else(|| {\n                            syn::Error::new_spanned(variant, \"Missing value for 'has_many'\")\n                        })\n                } else {\n                    Err(syn::Error::new_spanned(\n                        variant,\n                        \"Missing one of 'has_one', 'has_many' or 'belongs_to'\",\n                    ))\n                }??;\n\n                let mut result = quote!(\n                    Self::#variant_ident => #entity_ident::#relation_type(#related_to)\n                );\n\n                if attr.from.is_some() {\n                    let from =\n                        attr.from\n                            .as_ref()\n                            .map(Self::parse_lit_string)\n                            .ok_or_else(|| {\n                                syn::Error::new_spanned(variant, \"Missing value for 'from'\")\n                            })??;\n                    result = quote! { #result.from(#from) };\n                } else if attr.belongs_to.is_some() {\n                    return Err(syn::Error::new_spanned(variant, \"Missing attribute 'from'\"));\n                }\n\n                if attr.to.is_some() {\n                    let to = attr\n                        .to\n                        .as_ref()\n                        .map(Self::parse_lit_string)\n                        .ok_or_else(|| {\n                            syn::Error::new_spanned(variant, \"Missing value for 'to'\")\n                        })??;\n                    result = quote! { #result.to(#to) };\n                } else if attr.belongs_to.is_some() {\n                    return Err(syn::Error::new_spanned(variant, \"Missing attribute 'to'\"));\n                }\n\n                if attr.on_update.is_some() {\n                    let on_update = attr\n                        .on_update\n                        .as_ref()\n                        .map(Self::parse_lit_string)\n                        .ok_or_else(|| {\n                            syn::Error::new_spanned(variant, \"Missing value for 'on_update'\")\n                        })??;\n                    result = quote! { #result.on_update(sea_orm::prelude::ForeignKeyAction::#on_update) };\n                }\n\n                if attr.on_delete.is_some() {\n                    let on_delete = attr\n                        .on_delete\n                        .as_ref()\n                        .map(Self::parse_lit_string)\n                        .ok_or_else(|| {\n                            syn::Error::new_spanned(variant, \"Missing value for 'on_delete'\")\n                        })??;\n                    result = quote! { #result.on_delete(sea_orm::prelude::ForeignKeyAction::#on_delete) };\n                }\n\n                if attr.on_condition.is_some() {\n                    let on_condition = attr\n                        .on_condition\n                        .as_ref()\n                        .map(Self::parse_lit_string)\n                        .ok_or_else(|| {\n                            syn::Error::new_spanned(variant, \"Missing value for 'on_condition'\")\n                        })??;\n                    result = quote! { #result.on_condition(|_, _| sea_orm::sea_query::IntoCondition::into_condition(#on_condition)) };\n                }\n\n                if attr.fk_name.is_some() {\n                    let fk_name = attr\n                        .fk_name\n                        .as_ref()\n                        .map(|lit| {\n                            match lit {\n                                syn::Lit::Str(lit_str) => Ok(lit_str.value()),\n                                _ => Err(syn::Error::new_spanned(lit, \"attribute must be a string\")),\n                            }\n                        })\n                        .ok_or_else(|| {\n                            syn::Error::new_spanned(variant, \"Missing value for 'fk_name'\")\n                        })??;\n                    result = quote! { #result.fk_name(#fk_name) };\n                }\n\n                if attr.condition_type.is_some() {\n                    let condition_type = attr\n                        .condition_type\n                        .as_ref()\n                        .map(|lit| {\n                            match lit {\n                                syn::Lit::Str(lit_str) => {\n                                    match lit_str.value().to_ascii_lowercase().as_str() {\n                                        \"all\" => Ok(quote!( sea_orm::sea_query::ConditionType::All )),\n                                        \"any\" => Ok(quote!( sea_orm::sea_query::ConditionType::Any )),\n                                        _ => Err(syn::Error::new_spanned(lit, \"Condition type must be one of `all` or `any`\")),\n                                    }\n                                },\n                                _ => Err(syn::Error::new_spanned(lit, \"attribute must be a string\")),\n                            }\n                        })\n                        .ok_or_else(|| {\n                            syn::Error::new_spanned(variant, \"Missing value for 'condition_type'\")\n                        })??;\n                    result = quote! { #result.condition_type(#condition_type) };\n                }\n\n                result = quote! { #result.into() };\n\n                Result::<_, syn::Error>::Ok(result)\n            })\n            .collect::<Result<Vec<_>, _>>()?;\n\n        Ok(quote!(\n            #[automatically_derived]\n            impl sea_orm::entity::RelationTrait for #ident {\n                fn def(&self) -> sea_orm::entity::RelationDef {\n                    match self {\n                        #( #variant_relation_defs, )*\n                        _ => panic!(#no_relation_def_msg)\n                    }\n                }\n            }\n        ))\n    }\n\n    fn parse_lit_string(lit: &syn::Lit) -> syn::Result<TokenStream> {\n        match lit {\n            syn::Lit::Str(lit_str) => lit_str\n                .value()\n                .parse()\n                .map_err(|_| syn::Error::new_spanned(lit, \"attribute not valid\")),\n            _ => Err(syn::Error::new_spanned(lit, \"attribute must be a string\")),\n        }\n    }\n}\n\n/// Method to derive a Relation\npub fn expand_derive_relation(input: syn::DeriveInput) -> syn::Result<TokenStream> {\n    let ident_span = input.ident.span();\n\n    match DeriveRelation::new(input) {\n        Ok(model) => model.expand(),\n        Err(Error::InputNotEnum) => Ok(quote_spanned! {\n            ident_span => compile_error!(\"you can only derive DeriveRelation on enums\");\n        }),\n        Err(Error::Syn(err)) => Err(err),\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "3965038917866a6c73bb33f4a0bebe4898573061",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/sea-orm-macros/src/strum/helpers/type_props.rs",
    "func": "use proc_macro2::TokenStream;\nuse quote::quote;\nuse std::default::Default;\nuse syn::{parse_quote, DeriveInput, Ident, Path, Visibility};\n\nuse super::case_style::CaseStyle;\nuse super::metadata::{DeriveInputExt, EnumDiscriminantsMeta, EnumMeta};\nuse super::occurrence_error;\n\npub trait HasTypeProperties {\n    fn get_type_properties(&self) -> syn::Result<StrumTypeProperties>;\n}\n\n#[derive(Debug, Clone, Default)]\npub struct StrumTypeProperties {\n    pub case_style: Option<CaseStyle>,\n    pub ascii_case_insensitive: bool,\n    pub crate_module_path: Option<Path>,\n    pub discriminant_derives: Vec<Path>,\n    pub discriminant_name: Option<Ident>,\n    pub discriminant_others: Vec<TokenStream>,\n    pub discriminant_vis: Option<Visibility>,\n    pub use_phf: bool,\n}\n\nimpl HasTypeProperties for DeriveInput {\n    fn get_type_properties(&self) -> syn::Result<StrumTypeProperties> {\n        let mut output = StrumTypeProperties::default();\n\n        let strum_meta = self.get_metadata()?;\n        let discriminants_meta = self.get_discriminants_metadata()?;\n\n        let mut serialize_all_kw = None;\n        let mut ascii_case_insensitive_kw = None;\n        let mut use_phf_kw = None;\n        let mut crate_module_path_kw = None;\n        for meta in strum_meta {\n            match meta {\n                EnumMeta::SerializeAll { case_style, kw } => {\n                    if let Some(fst_kw) = serialize_all_kw {\n                        return Err(occurrence_error(fst_kw, kw, \"serialize_all\"));\n                    }\n\n                    serialize_all_kw = Some(kw);\n                    output.case_style = Some(case_style);\n                }\n                EnumMeta::AsciiCaseInsensitive(kw) => {\n                    if let Some(fst_kw) = ascii_case_insensitive_kw {\n                        return Err(occurrence_error(fst_kw, kw, \"ascii_case_insensitive\"));\n                    }\n\n                    ascii_case_insensitive_kw = Some(kw);\n                    output.ascii_case_insensitive = true;\n                }\n                EnumMeta::UsePhf(kw) => {\n                    if let Some(fst_kw) = use_phf_kw {\n                        return Err(occurrence_error(fst_kw, kw, \"use_phf\"));\n                    }\n\n                    use_phf_kw = Some(kw);\n                    output.use_phf = true;\n                }\n                EnumMeta::Crate {\n                    crate_module_path,\n                    kw,\n                } => {\n                    if let Some(fst_kw) = crate_module_path_kw {\n                        return Err(occurrence_error(fst_kw, kw, \"Crate\"));\n                    }\n\n                    crate_module_path_kw = Some(kw);\n                    output.crate_module_path = Some(crate_module_path);\n                }\n            }\n        }\n\n        let mut name_kw = None;\n        let mut vis_kw = None;\n        for meta in discriminants_meta {\n            match meta {\n                EnumDiscriminantsMeta::Derive { paths, .. } => {\n                    output.discriminant_derives.extend(paths);\n                }\n                EnumDiscriminantsMeta::Name { name, kw } => {\n                    if let Some(fst_kw) = name_kw {\n                        return Err(occurrence_error(fst_kw, kw, \"name\"));\n                    }\n\n                    name_kw = Some(kw);\n                    output.discriminant_name = Some(name);\n                }\n                EnumDiscriminantsMeta::Vis { vis, kw } => {\n                    if let Some(fst_kw) = vis_kw {\n                        return Err(occurrence_error(fst_kw, kw, \"vis\"));\n                    }\n\n                    vis_kw = Some(kw);\n                    output.discriminant_vis = Some(vis);\n                }\n                EnumDiscriminantsMeta::Other { path, nested } => {\n                    output.discriminant_others.push(quote! { #path(#nested) });\n                }\n            }\n        }\n\n        Ok(output)\n    }\n}\n\nimpl StrumTypeProperties {\n    pub fn crate_module_path(&self) -> Path {\n        self.crate_module_path\n            .as_ref()\n            .map_or_else(|| parse_quote!(sea_orm::strum), |path| parse_quote!(#path))\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "0525c9a595b9a3bdf80419019f26385e6a462ba2",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/examples/loco_seaography/migration/src/m20240520_173001_files.rs",
    "func": "use sea_orm_migration::{prelude::*, schema::*};\n\nuse super::m20231103_114510_notes::Notes;\n\n#[derive(DeriveMigrationName)]\npub struct Migration;\n\n#[async_trait::async_trait]\nimpl MigrationTrait for Migration {\n    async fn up(&self, manager: &SchemaManager) -> Result<(), DbErr> {\n        manager\n            .create_table(\n                table_auto(Files::Table)\n                    .col(pk_auto(Files::Id))\n                    .col(integer(Files::NotesId))\n                    .col(string(Files::FilePath))\n                    .foreign_key(\n                        ForeignKey::create()\n                            .name(\"FK_files_notes_id\")\n                            .from(Files::Table, Files::NotesId)\n                            .to(Notes::Table, Notes::Id),\n                    )\n                    .to_owned(),\n            )\n            .await\n    }\n\n    async fn down(&self, manager: &SchemaManager) -> Result<(), DbErr> {\n        manager\n            .drop_table(Table::drop().table(Files::Table).to_owned())\n            .await\n    }\n}\n\n#[derive(DeriveIden)]\npub enum Files {\n    Table,\n    Id,\n    NotesId,\n    FilePath,\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "f7f2798ffcf1196abc12c98488a5706dbdeebd04",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/examples/loco_starter/src/controllers/notes.rs",
    "func": "#![allow(clippy::missing_errors_doc)]\n#![allow(clippy::unnecessary_struct_initialization)]\n#![allow(clippy::unused_async)]\nuse axum::debug_handler;\nuse loco_rs::prelude::*;\nuse serde::{Deserialize, Serialize};\n\nuse crate::models::_entities::notes::{ActiveModel, Entity, Model};\n\n#[derive(Clone, Debug, Serialize, Deserialize)]\npub struct Params {\n    pub title: Option<String>,\n    pub content: Option<String>,\n}\n\nimpl Params {\n    fn update(&self, item: &mut ActiveModel) {\n        item.title = Set(self.title.clone());\n        item.content = Set(self.content.clone());\n    }\n}\n\nasync fn load_item(ctx: &AppContext, id: i32) -> Result<Model> {\n    let item = Entity::find_by_id(id).one(&ctx.db).await?;\n    item.ok_or_else(|| Error::NotFound)\n}\n\n#[debug_handler]\npub async fn list(State(ctx): State<AppContext>) -> Result<Response> {\n    format::json(Entity::find().all(&ctx.db).await?)\n}\n\n#[debug_handler]\npub async fn add(State(ctx): State<AppContext>, Json(params): Json<Params>) -> Result<Response> {\n    let mut item = ActiveModel {\n        ..Default::default()\n    };\n    params.update(&mut item);\n    let item = item.insert(&ctx.db).await?;\n    format::json(item)\n}\n\n#[debug_handler]\npub async fn update(\n    Path(id): Path<i32>,\n    State(ctx): State<AppContext>,\n    Json(params): Json<Params>,\n) -> Result<Response> {\n    let item = load_item(&ctx, id).await?;\n    let mut item = item.into_active_model();\n    params.update(&mut item);\n    let item = item.update(&ctx.db).await?;\n    format::json(item)\n}\n\n#[debug_handler]\npub async fn remove(Path(id): Path<i32>, State(ctx): State<AppContext>) -> Result<Response> {\n    load_item(&ctx, id).await?.delete(&ctx.db).await?;\n    format::empty()\n}\n\n#[debug_handler]\npub async fn get_one(Path(id): Path<i32>, State(ctx): State<AppContext>) -> Result<Response> {\n    format::json(load_item(&ctx, id).await?)\n}\n\npub fn routes() -> Routes {\n    Routes::new()\n        .prefix(\"notes\")\n        .add(\"/\", get(list))\n        .add(\"/\", post(add))\n        .add(\"/:id\", get(get_one))\n        .add(\"/:id\", delete(remove))\n        .add(\"/:id\", post(update))\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "163ad4b1a641384997d8b386c164f1dc2da64311",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/examples/loco_example/src/lib.rs",
    "func": "pub mod app;\npub mod controllers;\npub mod models;\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "459ff8c8d07d563908364a890c9adc4007dff938",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/examples/poem_example/migration/src/m20220120_000001_create_post_table.rs",
    "func": "use sea_orm_migration::{prelude::*, schema::*};\n\n#[derive(DeriveMigrationName)]\npub struct Migration;\n\n#[async_trait::async_trait]\nimpl MigrationTrait for Migration {\n    async fn up(&self, manager: &SchemaManager) -> Result<(), DbErr> {\n        manager\n            .create_table(\n                Table::create()\n                    .table(Posts::Table)\n                    .if_not_exists()\n                    .col(pk_auto(Posts::Id))\n                    .col(string(Posts::Title))\n                    .col(string(Posts::Text))\n                    .to_owned(),\n            )\n            .await\n    }\n\n    async fn down(&self, manager: &SchemaManager) -> Result<(), DbErr> {\n        manager\n            .drop_table(Table::drop().table(Posts::Table).to_owned())\n            .await\n    }\n}\n\n#[derive(DeriveIden)]\nenum Posts {\n    Table,\n    Id,\n    Title,\n    Text,\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "722771aabdaf051a98e40f9cc8500ad2ad922348",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/src/entity/identity.rs",
    "func": "use crate::{ColumnTrait, EntityTrait, IdenStatic};\nuse sea_query::{Alias, DynIden, Iden, IntoIden, SeaRc};\nuse std::fmt;\n\n/// List of column identifier\n#[derive(Debug, Clone)]\npub enum Identity {\n    /// Column identifier consists of 1 column\n    Unary(DynIden),\n    /// Column identifier consists of 2 columns\n    Binary(DynIden, DynIden),\n    /// Column identifier consists of 3 columns\n    Ternary(DynIden, DynIden, DynIden),\n    /// Column identifier consists of more than 3 columns\n    Many(Vec<DynIden>),\n}\n\nimpl IntoIterator for Identity {\n    type Item = DynIden;\n    type IntoIter = std::vec::IntoIter<Self::Item>;\n\n    fn into_iter(self) -> Self::IntoIter {\n        match self {\n            Identity::Unary(ident1) => vec![ident1].into_iter(),\n            Identity::Binary(ident1, ident2) => vec![ident1, ident2].into_iter(),\n            Identity::Ternary(ident1, ident2, ident3) => vec![ident1, ident2, ident3].into_iter(),\n            Identity::Many(vec) => vec.into_iter(),\n        }\n    }\n}\n\nimpl Iden for Identity {\n    fn unquoted(&self, s: &mut dyn fmt::Write) {\n        match self {\n            Identity::Unary(iden) => {\n                write!(s, \"{}\", iden.to_string()).unwrap();\n            }\n            Identity::Binary(iden1, iden2) => {\n                write!(s, \"{}\", iden1.to_string()).unwrap();\n                write!(s, \"{}\", iden2.to_string()).unwrap();\n            }\n            Identity::Ternary(iden1, iden2, iden3) => {\n                write!(s, \"{}\", iden1.to_string()).unwrap();\n                write!(s, \"{}\", iden2.to_string()).unwrap();\n                write!(s, \"{}\", iden3.to_string()).unwrap();\n            }\n            Identity::Many(vec) => {\n                for iden in vec.iter() {\n                    write!(s, \"{}\", iden.to_string()).unwrap();\n                }\n            }\n        }\n    }\n}\n\n/// Performs a conversion into an [Identity]\npub trait IntoIdentity {\n    /// Method to perform the conversion\n    fn into_identity(self) -> Identity;\n}\n\n/// Check the [Identity] of an Entity\npub trait IdentityOf<E>\nwhere\n    E: EntityTrait,\n{\n    /// Method to call to perform this check\n    fn identity_of(self) -> Identity;\n}\n\nimpl IntoIdentity for Identity {\n    fn into_identity(self) -> Identity {\n        self\n    }\n}\n\nimpl IntoIdentity for String {\n    fn into_identity(self) -> Identity {\n        self.as_str().into_identity()\n    }\n}\n\nimpl IntoIdentity for &str {\n    fn into_identity(self) -> Identity {\n        Identity::Unary(SeaRc::new(Alias::new(self)))\n    }\n}\n\nimpl<T> IntoIdentity for T\nwhere\n    T: IdenStatic,\n{\n    fn into_identity(self) -> Identity {\n        Identity::Unary(self.into_iden())\n    }\n}\n\nimpl<T, C> IntoIdentity for (T, C)\nwhere\n    T: IdenStatic,\n    C: IdenStatic,\n{\n    fn into_identity(self) -> Identity {\n        Identity::Binary(self.0.into_iden(), self.1.into_iden())\n    }\n}\n\nimpl<T, C, R> IntoIdentity for (T, C, R)\nwhere\n    T: IdenStatic,\n    C: IdenStatic,\n    R: IdenStatic,\n{\n    fn into_identity(self) -> Identity {\n        Identity::Ternary(self.0.into_iden(), self.1.into_iden(), self.2.into_iden())\n    }\n}\n\nmacro_rules! impl_into_identity {\n    ( $($T:ident : $N:tt),+ $(,)? ) => {\n        impl< $($T),+ > IntoIdentity for ( $($T),+ )\n        where\n            $($T: IdenStatic),+\n        {\n            fn into_identity(self) -> Identity {\n                Identity::Many(vec![\n                    $(self.$N.into_iden()),+\n                ])\n            }\n        }\n    };\n}\n\n#[rustfmt::skip]\nmod impl_into_identity {\n    use super::*;\n\n    impl_into_identity!(T0:0, T1:1, T2:2, T3:3);\n    impl_into_identity!(T0:0, T1:1, T2:2, T3:3, T4:4);\n    impl_into_identity!(T0:0, T1:1, T2:2, T3:3, T4:4, T5:5);\n    impl_into_identity!(T0:0, T1:1, T2:2, T3:3, T4:4, T5:5, T6:6);\n    impl_into_identity!(T0:0, T1:1, T2:2, T3:3, T4:4, T5:5, T6:6, T7:7);\n    impl_into_identity!(T0:0, T1:1, T2:2, T3:3, T4:4, T5:5, T6:6, T7:7, T8:8);\n    impl_into_identity!(T0:0, T1:1, T2:2, T3:3, T4:4, T5:5, T6:6, T7:7, T8:8, T9:9);\n    impl_into_identity!(T0:0, T1:1, T2:2, T3:3, T4:4, T5:5, T6:6, T7:7, T8:8, T9:9, T10:10);\n    impl_into_identity!(T0:0, T1:1, T2:2, T3:3, T4:4, T5:5, T6:6, T7:7, T8:8, T9:9, T10:10, T11:11);\n}\n\nimpl<E, C> IdentityOf<E> for C\nwhere\n    E: EntityTrait<Column = C>,\n    C: ColumnTrait,\n{\n    fn identity_of(self) -> Identity {\n        self.into_identity()\n    }\n}\n\nmacro_rules! impl_identity_of {\n    ( $($T:ident),+ $(,)? ) => {\n        impl<E, C> IdentityOf<E> for ( $($T),+ )\n        where\n            E: EntityTrait<Column = C>,\n            C: ColumnTrait,\n        {\n            fn identity_of(self) -> Identity {\n                self.into_identity()\n            }\n        }\n    };\n}\n\n#[rustfmt::skip]\nmod impl_identity_of {\n    use super::*;\n\n    impl_identity_of!(C, C);\n    impl_identity_of!(C, C, C);\n    impl_identity_of!(C, C, C, C);\n    impl_identity_of!(C, C, C, C, C);\n    impl_identity_of!(C, C, C, C, C, C);\n    impl_identity_of!(C, C, C, C, C, C, C);\n    impl_identity_of!(C, C, C, C, C, C, C, C);\n    impl_identity_of!(C, C, C, C, C, C, C, C, C);\n    impl_identity_of!(C, C, C, C, C, C, C, C, C, C);\n    impl_identity_of!(C, C, C, C, C, C, C, C, C, C, C);\n    impl_identity_of!(C, C, C, C, C, C, C, C, C, C, C, C);\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "b5dc6074f592785aefb8a29ed6655f6b90cb5309",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/sea-orm-codegen/tests/expanded_with_serde/cake_serialize.rs",
    "func": "//! SeaORM Entity. Generated by sea-orm-codegen 0.1.0\n\nuse sea_orm::entity::prelude:: * ;\nuse serde::Serialize;\n\n#[derive(Copy, Clone, Default, Debug, DeriveEntity)]\npub struct Entity;\n\nimpl EntityName for Entity {\n    fn table_name(&self) -> &str {\n        \"cake\"\n    }\n}\n\n#[derive(Clone, Debug, PartialEq, DeriveModel, DeriveActiveModel, Eq, Serialize)]\npub struct Model {\n    pub id: i32,\n    pub name: Option<String> ,\n}\n\n#[derive(Copy, Clone, Debug, EnumIter, DeriveColumn)]\npub enum Column {\n    Id,\n    Name,\n}\n\n#[derive(Copy, Clone, Debug, EnumIter, DerivePrimaryKey)]\npub enum PrimaryKey {\n    Id,\n}\n\nimpl PrimaryKeyTrait for PrimaryKey {\n    type ValueType = i32;\n\n    fn auto_increment() -> bool {\n        true\n    }\n}\n\n#[derive(Copy, Clone, Debug, EnumIter)]\npub enum Relation {\n    Fruit,\n}\n\nimpl ColumnTrait for Column {\n    type EntityName = Entity;\n    fn def(&self) -> ColumnDef {\n        match self {\n            Self::Id => ColumnType::Integer.def(),\n            Self::Name => ColumnType::Text.def().null(),\n        }\n    }\n}\n\nimpl RelationTrait for Relation {\n    fn def(&self) -> RelationDef {\n        match self {\n            Self::Fruit => Entity::has_many(super::fruit::Entity).into(),\n        }\n    }\n}\n\nimpl Related<super::fruit::Entity> for Entity {\n    fn to() -> RelationDef {\n        Relation::Fruit.def()\n    }\n}\n\nimpl Related<super::filling::Entity> for Entity {\n    fn to() -> RelationDef {\n        super::cake_filling::Relation::Filling.def()\n    }\n    fn via() -> Option<RelationDef> {\n        Some(super::cake_filling::Relation::Cake.def().rev())\n    }\n}\n\nimpl ActiveModelBehavior for ActiveModel {}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "c9dec5fa17337efd609db303b2baf89c6b28ba41",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/sea-orm/sea-orm-codegen/src/tests_cfg/many_to_many_multiple/users_votes.rs",
    "func": "use sea_orm::entity::prelude::*;\n\n#[derive(Clone, Debug, PartialEq, DeriveEntityModel, Eq)]\n#[sea_orm(table_name = \"users_votes\")]\npub struct Model {\n    #[sea_orm(primary_key, auto_increment = false)]\n    pub user_id: i32,\n    #[sea_orm(primary_key, auto_increment = false)]\n    pub bill_id: i32,\n    pub user_idd: Option<i32> ,\n    pub bill_idd: Option<i32> ,\n    pub vote: bool,\n}\n\n#[derive(Copy, Clone, Debug, EnumIter, DeriveRelation)]\npub enum Relation {\n    #[sea_orm(\n        belongs_to = \"super::bills::Entity\",\n        from = \"Column::BillIdd\",\n        to = \"super::bills::Column::Id\",\n    )]\n    Bills2,\n    #[sea_orm(\n        belongs_to = \"super::bills::Entity\",\n        from = \"Column::BillId\",\n        to = \"super::bills::Column::Id\",\n    )]\n    Bills1,\n    #[sea_orm(\n        belongs_to = \"super::users::Entity\",\n        from = \"Column::UserIdd\",\n        to = \"super::users::Column::Id\",\n    )]\n    Users2,\n    #[sea_orm(\n        belongs_to = \"super::users::Entity\",\n        from = \"Column::UserId\",\n        to = \"super::users::Column::Id\",\n    )]\n    Users1,\n}\n\nimpl ActiveModelBehavior for ActiveModel {}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "b5ce2583f1fd4fe97b74b0add73d175aa50cbaf7",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/pingora/pingora-cache/src/max_file_size.rs",
    "func": "// Copyright 2024 Cloudflare, Inc.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n// http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n//! Set limit on the largest size to cache\n\nuse crate::storage::HandleMiss;\nuse crate::MissHandler;\nuse async_trait::async_trait;\nuse bytes::Bytes;\nuse pingora_error::{Error, ErrorType};\n\n/// [MaxFileSizeMissHandler] wraps a MissHandler to enforce a maximum asset size that should be\n/// written to the MissHandler.\n///\n/// This is used to enforce a maximum cache size for a request when the\n/// response size is not known ahead of time (no Content-Length header). When the response size _is_\n/// known ahead of time, it should be checked up front (when calculating cacheability) for efficiency.\n/// Note: for requests with partial read support (where downstream reads the response from cache as\n/// it is filled), this will cause the request as a whole to fail. The response will be remembered\n/// as uncacheable, though, so downstream will be able to retry the request, since the cache will be\n/// disabled for the retried request.\npub struct MaxFileSizeMissHandler {\n    inner: MissHandler,\n    max_file_size_bytes: usize,\n    bytes_written: usize,\n}\n\nimpl MaxFileSizeMissHandler {\n    /// Create a new [MaxFileSizeMissHandler] wrapping the given [MissHandler]\n    pub fn new(inner: MissHandler, max_file_size_bytes: usize) -> MaxFileSizeMissHandler {\n        MaxFileSizeMissHandler {\n            inner,\n            max_file_size_bytes,\n            bytes_written: 0,\n        }\n    }\n}\n\n/// Error type returned when the limit is reached.\npub const ERR_RESPONSE_TOO_LARGE: ErrorType = ErrorType::Custom(\"response too large\");\n\n#[async_trait]\nimpl HandleMiss for MaxFileSizeMissHandler {\n    async fn write_body(&mut self, data: Bytes, eof: bool) -> pingora_error::Result<()> {\n        // fail if writing the body would exceed the max_file_size_bytes\n        if self.bytes_written + data.len() > self.max_file_size_bytes {\n            return Error::e_explain(\n                ERR_RESPONSE_TOO_LARGE,\n                format!(\n                    \"writing data of size {} bytes would exceed max file size of {} bytes\",\n                    data.len(),\n                    self.max_file_size_bytes\n                ),\n            );\n        }\n\n        self.bytes_written += data.len();\n        self.inner.write_body(data, eof).await\n    }\n\n    async fn finish(self: Box<Self>) -> pingora_error::Result<usize> {\n        self.inner.finish().await\n    }\n\n    fn streaming_write_tag(&self) -> Option<&[u8]> {\n        self.inner.streaming_write_tag()\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "a168e31bea51ebe9566f41160992406ca89ab821",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/pingora/pingora-core/src/protocols/http/bridge/grpc_web.rs",
    "func": "// Copyright 2024 Cloudflare, Inc.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n// http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\nuse bytes::{BufMut, Bytes, BytesMut};\nuse http::{\n    header::{CONTENT_LENGTH, CONTENT_TYPE, TRANSFER_ENCODING},\n    HeaderMap,\n};\nuse pingora_error::{ErrorType::ReadError, OrErr, Result};\nuse pingora_http::{RequestHeader, ResponseHeader};\n\n/// Used for bridging gRPC to gRPC-web and vice-versa.\n/// See gRPC-web [spec](https://github.com/grpc/grpc/blob/master/doc/PROTOCOL-WEB.md) and\n/// gRPC h2 [spec](https://github.com/grpc/grpc/blob/master/doc/PROTOCOL-HTTP2.md) for more details.\n#[derive(Default, PartialEq, Debug)]\npub enum GrpcWebCtx {\n    #[default]\n    Disabled,\n    Init,\n    Upgrade,\n    Trailers,\n    Done,\n}\n\nconst GRPC: &str = \"application/grpc\";\nconst GRPC_WEB: &str = \"application/grpc-web\";\n\nimpl GrpcWebCtx {\n    pub fn init(&mut self) {\n        *self = Self::Init;\n    }\n\n    /// gRPC-web request is fed into this filter, if the module is initialized\n    /// we attempt to convert it to a gRPC request\n    pub fn request_header_filter(&mut self, req: &mut RequestHeader) {\n        if *self != Self::Init {\n            // not enabled\n            return;\n        }\n\n        let content_type = req\n            .headers\n            .get(CONTENT_TYPE)\n            .and_then(|v| v.to_str().ok())\n            .unwrap_or_default();\n\n        // check we have a valid grpc-web prefix\n        if !(content_type.len() >= GRPC_WEB.len()\n            && content_type[..GRPC_WEB.len()].eq_ignore_ascii_case(GRPC_WEB))\n        {\n            // not gRPC-web\n            return;\n        }\n\n        // change content type to grpc\n        let ct = content_type.to_lowercase().replace(GRPC_WEB, GRPC);\n        req.insert_header(CONTENT_TYPE, ct).expect(\"insert header\");\n\n        // The 'te' request header is used to detect incompatible proxies\n        // which are supposed to remove 'te' if it is unsupported.\n        // This header is required by gRPC over h2 protocol.\n        // https://github.com/grpc/grpc/blob/master/doc/PROTOCOL-HTTP2.md\n        req.insert_header(\"te\", \"trailers\").expect(\"insert header\");\n\n        // For gRPC requests, EOS (end-of-stream) is indicated by the presence of the\n        // END_STREAM flag on the last received DATA frame.\n        // In scenarios where the Request stream needs to be closed\n        // but no data remains to be sent implementations\n        // MUST send an empty DATA frame with this flag set.\n        req.set_send_end_stream(false);\n\n        *self = Self::Upgrade\n    }\n\n    /// gRPC response is fed into this filter, if the module is in the bridge state\n    /// attempt to convert the response it to a gRPC-web response\n    pub fn response_header_filter(&mut self, resp: &mut ResponseHeader) {\n        if *self != Self::Upgrade {\n            // not an upgrade\n            return;\n        }\n\n        if resp.status.is_informational() {\n            // proxy informational statuses through\n            return;\n        }\n\n        let content_type = resp\n            .headers\n            .get(CONTENT_TYPE)\n            .and_then(|v| v.to_str().ok())\n            .unwrap_or_default();\n\n        // upstream h2, no reason to normalize case\n        if !content_type.starts_with(GRPC) {\n            // not gRPC\n            *self = Self::Disabled;\n            return;\n        }\n\n        // change content type to gRPC-web\n        let ct = content_type.replace(GRPC, GRPC_WEB);\n        resp.insert_header(CONTENT_TYPE, ct).expect(\"insert header\");\n\n        // always use chunked for gRPC-web\n        resp.remove_header(&CONTENT_LENGTH);\n        resp.insert_header(TRANSFER_ENCODING, \"chunked\")\n            .expect(\"insert header\");\n\n        *self = Self::Trailers\n    }\n\n    /// Used to convert gRPC trailers into gRPC-web trailers, note\n    /// gRPC-web trailers are encoded into the response body so we return\n    /// the encoded bytes here.\n    pub fn response_trailer_filter(\n        &mut self,\n        resp_trailers: &mut HeaderMap,\n    ) -> Result<Option<Bytes>> {\n        /* Trailer header frame and trailer headers\n            0 - - 1 - - 2 - - 3 - - 4 - - 5 - - 6 - - 7 - - 8\n            | Ind |        Length         |     Headers     | <- trailer header indicator, length of headers\n            |                    Headers                    | <- rest is headers\n            |                    Headers                    |\n        */\n        // TODO compressed trailer?\n        // grpc-web trailers frame head\n        const GRPC_WEB_TRAILER: u8 = 0x80;\n\n        // number of bytes in trailer header\n        const GRPC_TRAILER_HEADER_LEN: usize = 5;\n\n        // just some estimate\n        const DEFAULT_TRAILER_BUFFER_SIZE: usize = 256;\n\n        if *self != Self::Trailers {\n            // not an upgrade\n            *self = Self::Disabled;\n            return Ok(None);\n        }\n\n        // trailers are expected to arrive all at once encoded into a single trailers frame\n        // trailers in frame are separated by CRLFs\n        let mut buf = BytesMut::with_capacity(DEFAULT_TRAILER_BUFFER_SIZE);\n        let mut trailers = buf.split_off(GRPC_TRAILER_HEADER_LEN);\n\n        // iterate the key/value pairs and encode them into the tmp buffer\n        for (key, value) in resp_trailers.iter() {\n            // encode header\n            trailers.put_slice(key.as_ref());\n            trailers.put_slice(b\":\");\n\n            // encode value\n            trailers.put_slice(value.as_ref());\n\n            // encode header separator\n            trailers.put_slice(b\"\\r\\n\");\n        }\n\n        // ensure trailer length within u32\n        let len = trailers.len().try_into().or_err_with(ReadError, || {\n            format!(\"invalid gRPC trailer length: {}\", trailers.len())\n        })?;\n        buf.put_u8(GRPC_WEB_TRAILER);\n        buf.put_u32(len);\n        buf.unsplit(trailers);\n\n        *self = Self::Done;\n        Ok(Some(buf.freeze()))\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use http::{request::Request, response::Response, Version};\n\n    #[test]\n    fn non_grpc_web_request_ignored() {\n        let request = Request::get(\"https://pingora.dev/\")\n            .header(CONTENT_TYPE, \"application/grpc-we\")\n            .version(Version::HTTP_2) // only set this to verify send_end_stream is configured\n            .body(())\n            .unwrap();\n        let mut request = request.into_parts().0.into();\n\n        let mut filter = GrpcWebCtx::default();\n        filter.init();\n        filter.request_header_filter(&mut request);\n        assert_eq!(filter, GrpcWebCtx::Init);\n\n        let headers = &request.headers;\n        assert_eq!(headers.get(\"te\"), None);\n        assert_eq!(headers.get(\"application/grpc\"), None);\n        assert_eq!(request.send_end_stream(), Some(true));\n    }\n\n    #[test]\n    fn grpc_web_request_module_disabled_ignored() {\n        let request = Request::get(\"https://pingora.dev/\")\n            .header(CONTENT_TYPE, \"application/grpc-web\")\n            .version(Version::HTTP_2) // only set this to verify send_end_stream is configured\n            .body(())\n            .unwrap();\n        let mut request = request.into_parts().0.into();\n\n        // do not init\n        let mut filter = GrpcWebCtx::default();\n        filter.request_header_filter(&mut request);\n        assert_eq!(filter, GrpcWebCtx::Disabled);\n\n        let headers = &request.headers;\n        assert_eq!(headers.get(\"te\"), None);\n        assert_eq!(headers.get(CONTENT_TYPE).unwrap(), \"application/grpc-web\");\n        assert_eq!(request.send_end_stream(), Some(true));\n    }\n\n    #[test]\n    fn grpc_web_request_upgrade() {\n        let request = Request::get(\"https://pingora.org/\")\n            .header(CONTENT_TYPE, \"application/gRPC-web+thrift\")\n            .version(Version::HTTP_2) // only set this to verify send_end_stream is configured\n            .body(())\n            .unwrap();\n        let mut request = request.into_parts().0.into();\n\n        let mut filter = GrpcWebCtx::default();\n        filter.init();\n        filter.request_header_filter(&mut request);\n        assert_eq!(filter, GrpcWebCtx::Upgrade);\n\n        let headers = &request.headers;\n        assert_eq!(headers.get(\"te\").unwrap(), \"trailers\");\n        assert_eq!(\n            headers.get(CONTENT_TYPE).unwrap(),\n            \"application/grpc+thrift\"\n        );\n        assert_eq!(request.send_end_stream(), Some(false));\n    }\n\n    #[test]\n    fn non_grpc_response_ignored() {\n        let response = Response::builder()\n            .header(CONTENT_TYPE, \"text/html\")\n            .header(CONTENT_LENGTH, \"10\")\n            .body(())\n            .unwrap();\n        let mut response = response.into_parts().0.into();\n\n        let mut filter = GrpcWebCtx::Upgrade;\n        filter.response_header_filter(&mut response);\n        assert_eq!(filter, GrpcWebCtx::Disabled);\n\n        let headers = &response.headers;\n        assert_eq!(headers.get(CONTENT_TYPE).unwrap(), \"text/html\");\n        assert_eq!(headers.get(CONTENT_LENGTH).unwrap(), \"10\");\n    }\n\n    #[test]\n    fn grpc_response_module_disabled_ignored() {\n        let response = Response::builder()\n            .header(CONTENT_TYPE, \"application/grpc\")\n            .body(())\n            .unwrap();\n        let mut response = response.into_parts().0.into();\n\n        let mut filter = GrpcWebCtx::default();\n        filter.response_header_filter(&mut response);\n        assert_eq!(filter, GrpcWebCtx::Disabled);\n\n        let headers = &response.headers;\n        assert_eq!(headers.get(CONTENT_TYPE).unwrap(), \"application/grpc\");\n    }\n\n    #[test]\n    fn grpc_response_upgrade() {\n        let response = Response::builder()\n            .header(CONTENT_TYPE, \"application/grpc+proto\")\n            .header(CONTENT_LENGTH, \"0\")\n            .body(())\n            .unwrap();\n        let mut response = response.into_parts().0.into();\n\n        let mut filter = GrpcWebCtx::Upgrade;\n        filter.response_header_filter(&mut response);\n        assert_eq!(filter, GrpcWebCtx::Trailers);\n\n        let headers = &response.headers;\n        assert_eq!(\n            headers.get(CONTENT_TYPE).unwrap(),\n            \"application/grpc-web+proto\"\n        );\n        assert_eq!(headers.get(TRANSFER_ENCODING).unwrap(), \"chunked\");\n        assert!(headers.get(CONTENT_LENGTH).is_none());\n    }\n\n    #[test]\n    fn grpc_response_informational_proxied() {\n        let response = Response::builder().status(100).body(()).unwrap();\n        let mut response = response.into_parts().0.into();\n\n        let mut filter = GrpcWebCtx::Upgrade;\n        filter.response_header_filter(&mut response);\n        assert_eq!(filter, GrpcWebCtx::Upgrade); // still upgrade\n    }\n\n    #[test]\n    fn grpc_response_trailer_headers_convert_to_byte_buf() {\n        let mut response = Response::builder()\n            .header(\"grpc-status\", \"0\")\n            .header(\"grpc-message\", \"OK\")\n            .body(())\n            .unwrap();\n        let response = response.headers_mut();\n\n        let mut filter = GrpcWebCtx::Trailers;\n        let buf = filter.response_trailer_filter(response).unwrap().unwrap();\n        assert_eq!(filter, GrpcWebCtx::Done);\n\n        let expected = b\"grpc-status:0\\r\\ngrpc-message:OK\\r\\n\";\n        let expected_len: u32 = expected.len() as u32; // 32 bytes\n\n        // assert the length prefix message frame\n        // [1 byte (header)| 4 byte (length) | 15 byte (grpc-status:0\\r\\n) | 17 bytes (grpc-message:OK\\r\\n)]\n        assert_eq!(0x80, buf[0]); // frame should start with trailer header\n        assert_eq!(expected_len.to_be_bytes(), buf[1..5]); // next 4 bytes length of trailer\n        assert_eq!(expected[..15], buf[5..20]); // grpc-status:0\\r\\n (15 bytes)\n        assert_eq!(expected[15..], buf[20..]); // grpc-message:OK\\r\\n (17 bytes)\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "0f3eba5d14dd4051707e3f9b81936994f7539b3b",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/serde/test_suite/tests/test_roundtrip.rs",
    "func": "use serde_test::{assert_tokens, Configure, Token};\nuse std::net;\n\n#[macro_use]\n#[allow(unused_macros)]\nmod macros;\n\n#[test]\nfn ip_addr_roundtrip() {\n    assert_tokens(\n        &net::IpAddr::from(*b\"1234\").compact(),\n        &seq![\n            Token::NewtypeVariant {\n                name: \"IpAddr\",\n                variant: \"V4\"\n            },\n            Token::Tuple { len: 4 },\n            b\"1234\".iter().copied().map(Token::U8),\n            Token::TupleEnd,\n        ],\n    );\n}\n\n#[test]\nfn socket_addr_roundtrip() {\n    assert_tokens(\n        &net::SocketAddr::from((*b\"1234567890123456\", 1234)).compact(),\n        &seq![\n            Token::NewtypeVariant {\n                name: \"SocketAddr\",\n                variant: \"V6\"\n            },\n            Token::Tuple { len: 2 },\n            Token::Tuple { len: 16 },\n            b\"1234567890123456\".iter().copied().map(Token::U8),\n            Token::TupleEnd,\n            Token::U16(1234),\n            Token::TupleEnd,\n        ],\n    );\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "9d5c6eda4e410290202c88ba4dc0aa81aca11a60",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/yew/packages/yew-macro/src/use_prepared_state.rs",
    "func": "use proc_macro2::TokenStream;\nuse quote::quote;\nuse syn::parse::{Parse, ParseStream};\nuse syn::{Expr, ExprClosure, ReturnType, Token, Type};\n\n#[derive(Debug)]\npub struct PreparedState {\n    closure: ExprClosure,\n    return_type: Type,\n    deps: Expr,\n}\n\nimpl Parse for PreparedState {\n    fn parse(input: ParseStream) -> syn::Result<Self> {\n        // Reads the deps.\n        let deps = input.parse()?;\n\n        input.parse::<Token![,]>().map_err(|e| {\n            syn::Error::new(\n                e.span(),\n                \"this hook takes 2 arguments but 1 argument was supplied\",\n            )\n        })?;\n\n        // Reads a closure.\n        let expr: Expr = input.parse()?;\n\n        let closure = match expr {\n            Expr::Closure(m) => m,\n            other => return Err(syn::Error::new_spanned(other, \"expected closure\")),\n        };\n\n        let return_type = match &closure.output {\n            ReturnType::Default => {\n                return Err(syn::Error::new_spanned(\n                    &closure,\n                    \"You must specify a return type for this closure. This is used when the \\\n                     closure is omitted from the client side rendering bundle.\",\n                ))\n            }\n            ReturnType::Type(_rarrow, ty) => *ty.to_owned(),\n        };\n\n        if !input.is_empty() {\n            let maybe_trailing_comma = input.lookahead1();\n\n            if !maybe_trailing_comma.peek(Token![,]) {\n                return Err(maybe_trailing_comma.error());\n            }\n        }\n\n        Ok(Self {\n            closure,\n            return_type,\n            deps,\n        })\n    }\n}\n\nimpl PreparedState {\n    // Async closure is not stable, so we rewrite it to closure + async block\n    #[cfg(not(nightly_yew))]\n    pub fn rewrite_to_closure_with_async_block(&self) -> ExprClosure {\n        use proc_macro2::Span;\n        use syn::parse_quote;\n\n        let async_token = match &self.closure.asyncness {\n            Some(m) => m,\n            None => return self.closure.clone(),\n        };\n\n        // The async block always need to be move so input can be moved into it.\n        let move_token = self\n            .closure\n            .capture\n            .unwrap_or_else(|| Token![move](Span::call_site()));\n        let body = &self.closure.body;\n\n        let inner = parse_quote! {\n            #async_token #move_token {\n                #body\n            }\n        };\n\n        let mut closure = self.closure.clone();\n\n        closure.asyncness = None;\n        // We omit the output type as it's an opaque future type.\n        closure.output = ReturnType::Default;\n\n        closure.body = inner;\n\n        closure.attrs.push(parse_quote! { #[allow(unused_braces)] });\n\n        closure\n    }\n\n    #[cfg(nightly_yew)]\n    pub fn rewrite_to_closure_with_async_block(&self) -> ExprClosure {\n        self.closure.clone()\n    }\n\n    pub fn to_token_stream_with_closure(&self) -> TokenStream {\n        let deps = &self.deps;\n        let rt = &self.return_type;\n        let closure = self.rewrite_to_closure_with_async_block();\n\n        match &self.closure.asyncness {\n            Some(_) => quote! {\n                ::yew::functional::use_prepared_state_with_suspension::<#rt, _, _, _>(#deps, #closure)\n            },\n            None => quote! {\n                ::yew::functional::use_prepared_state::<#rt, _, _>(#deps, #closure)\n            },\n        }\n    }\n\n    // Expose a hook for the client side.\n    //\n    // The closure is stripped from the client side.\n    pub fn to_token_stream_without_closure(&self) -> TokenStream {\n        let deps = &self.deps;\n        let rt = &self.return_type;\n\n        quote! {\n            ::yew::functional::use_prepared_state::<#rt, _>(#deps)\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "d67ca1510d2af68412c5d0f8529610baafdd9f2e",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/yew/packages/yew-macro/src/props/mod.rs",
    "func": "mod component;\nmod element;\nmod prop;\nmod prop_macro;\n\npub use component::*;\npub use element::*;\npub use prop::*;\npub use prop_macro::PropsMacroInput;\n\nconst CHILDREN_LABEL: &str = \"children\";\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "2c1150e7ccf070f72d11f03ace562ce63e2c5753",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/yew/packages/yew-agent-macro/src/agent_fn.rs",
    "func": "use proc_macro2::{Span, TokenStream};\nuse quote::ToTokens;\nuse syn::parse::{Parse, ParseStream};\nuse syn::punctuated::Punctuated;\nuse syn::token::Comma;\nuse syn::{Attribute, FnArg, Generics, Ident, Item, ItemFn, Signature, Type, Visibility};\n\npub trait AgentFnType {\n    type RecvType;\n    type OutputType;\n\n    fn attr_name() -> &'static str;\n    fn agent_type_name() -> &'static str;\n    fn parse_recv_type(sig: &Signature) -> syn::Result<Self::RecvType>;\n    fn parse_output_type(sig: &Signature) -> syn::Result<Self::OutputType>;\n\n    fn extract_fn_arg_type(arg: &FnArg) -> syn::Result<Type> {\n        let ty = match arg {\n            FnArg::Typed(arg) => arg.ty.clone(),\n\n            FnArg::Receiver(_) => {\n                return Err(syn::Error::new_spanned(\n                    arg,\n                    format!(\"{} agents can't accept a receiver\", Self::agent_type_name()),\n                ));\n            }\n        };\n\n        Ok(*ty)\n    }\n\n    fn assert_no_left_argument<I, T>(rest_inputs: I, expected_len: usize) -> syn::Result<()>\n    where\n        I: ExactSizeIterator + IntoIterator<Item = T>,\n        T: ToTokens,\n    {\n        // Checking after param parsing may make it a little inefficient\n        // but that's a requirement for better error messages in case of receivers\n        // `>0` because first one is already consumed.\n        if rest_inputs.len() > 0 {\n            let params: TokenStream = rest_inputs\n                .into_iter()\n                .map(|it| it.to_token_stream())\n                .collect();\n            return Err(syn::Error::new_spanned(\n                params,\n                format!(\n                    \"{} agent can accept at most {} argument{}\",\n                    Self::agent_type_name(),\n                    expected_len,\n                    if expected_len > 1 { \"s\" } else { \"\" }\n                ),\n            ));\n        }\n\n        Ok(())\n    }\n}\n\n#[derive(Clone)]\npub struct AgentFn<F>\nwhere\n    F: AgentFnType + 'static,\n{\n    pub recv_type: F::RecvType,\n    pub output_type: F::OutputType,\n    pub generics: Generics,\n    pub vis: Visibility,\n    pub attrs: Vec<Attribute>,\n    pub name: Ident,\n    pub agent_name: Option<Ident>,\n    pub is_async: bool,\n\n    pub func: ItemFn,\n}\n\nimpl<F> Parse for AgentFn<F>\nwhere\n    F: AgentFnType + 'static,\n{\n    fn parse(input: ParseStream) -> syn::Result<Self> {\n        let parsed: Item = input.parse()?;\n\n        let func = match parsed {\n            Item::Fn(m) => m,\n\n            item => {\n                return Err(syn::Error::new_spanned(\n                    item,\n                    format!(\n                        \"`{}` attribute can only be applied to functions\",\n                        F::attr_name()\n                    ),\n                ))\n            }\n        };\n\n        let ItemFn {\n            attrs, vis, sig, ..\n        } = func.clone();\n\n        if sig.generics.lifetimes().next().is_some() {\n            return Err(syn::Error::new_spanned(\n                sig.generics,\n                format!(\n                    \"{} agents can't have generic lifetime parameters\",\n                    F::agent_type_name()\n                ),\n            ));\n        }\n\n        if sig.constness.is_some() {\n            return Err(syn::Error::new_spanned(\n                sig.constness,\n                format!(\"const functions can't be {} agents\", F::agent_type_name()),\n            ));\n        }\n\n        if sig.abi.is_some() {\n            return Err(syn::Error::new_spanned(\n                sig.abi,\n                format!(\"extern functions can't be {} agents\", F::agent_type_name()),\n            ));\n        }\n        let recv_type = F::parse_recv_type(&sig)?;\n        let output_type = F::parse_output_type(&sig)?;\n\n        let is_async = sig.asyncness.is_some();\n\n        Ok(Self {\n            recv_type,\n            output_type,\n            generics: sig.generics,\n            is_async,\n            vis,\n            attrs,\n            name: sig.ident,\n            agent_name: None,\n            func,\n        })\n    }\n}\n\nimpl<F> AgentFn<F>\nwhere\n    F: AgentFnType + 'static,\n{\n    /// Filters attributes that should be copied to agent definition.\n    pub fn filter_attrs_for_agent_struct(&self) -> Vec<Attribute> {\n        self.attrs\n            .iter()\n            .filter_map(|m| {\n                m.path()\n                    .get_ident()\n                    .and_then(|ident| match ident.to_string().as_str() {\n                        \"doc\" | \"allow\" => Some(m.clone()),\n                        _ => None,\n                    })\n            })\n            .collect()\n    }\n\n    /// Filters attributes that should be copied to the agent impl block.\n    pub fn filter_attrs_for_agent_impl(&self) -> Vec<Attribute> {\n        self.attrs\n            .iter()\n            .filter_map(|m| {\n                m.path()\n                    .get_ident()\n                    .and_then(|ident| match ident.to_string().as_str() {\n                        \"allow\" => Some(m.clone()),\n                        _ => None,\n                    })\n            })\n            .collect()\n    }\n\n    pub fn phantom_generics(&self) -> Punctuated<Ident, Comma> {\n        self.generics\n            .type_params()\n            .map(|ty_param| ty_param.ident.clone()) // create a new Punctuated sequence without any type bounds\n            .collect::<Punctuated<_, Comma>>()\n    }\n\n    pub fn merge_agent_name(&mut self, name: AgentName) -> syn::Result<()> {\n        if let Some(ref m) = name.agent_name {\n            if m == &self.name {\n                return Err(syn::Error::new_spanned(\n                    m,\n                    format!(\n                        \"the {} must not have the same name as the function\",\n                        F::agent_type_name()\n                    ),\n                ));\n            }\n        }\n\n        self.agent_name = name.agent_name;\n\n        Ok(())\n    }\n\n    pub fn inner_fn_ident(&self) -> Ident {\n        if self.agent_name.is_some() {\n            self.name.clone()\n        } else {\n            Ident::new(\"inner\", Span::mixed_site())\n        }\n    }\n\n    pub fn agent_name(&self) -> Ident {\n        self.agent_name.clone().unwrap_or_else(|| self.name.clone())\n    }\n\n    pub fn print_inner_fn(&self) -> ItemFn {\n        let mut func = self.func.clone();\n        func.sig.ident = self.inner_fn_ident();\n\n        func.vis = Visibility::Inherited;\n\n        func\n    }\n}\n\npub struct AgentName {\n    agent_name: Option<Ident>,\n}\n\nimpl Parse for AgentName {\n    fn parse(input: ParseStream) -> syn::Result<Self> {\n        if input.is_empty() {\n            return Ok(Self { agent_name: None });\n        }\n\n        let agent_name = input.parse()?;\n\n        Ok(Self {\n            agent_name: Some(agent_name),\n        })\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "34c490cec0d74ca460aabbbf07becf2b15a9016a",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/yew/packages/yew/tests/use_reducer.rs",
    "func": "#![cfg(all(target_arch = \"wasm32\", not(target_os = \"wasi\")))]\n\nuse std::collections::HashSet;\nuse std::rc::Rc;\nuse std::time::Duration;\n\nuse gloo::utils::document;\nuse wasm_bindgen::JsCast;\nuse wasm_bindgen_test::*;\nuse web_sys::HtmlElement;\nuse yew::platform::time::sleep;\nuse yew::prelude::*;\n\nmod common;\n\nuse common::obtain_result;\n\nwasm_bindgen_test::wasm_bindgen_test_configure!(run_in_browser);\n\n#[derive(Debug)]\nstruct CounterState {\n    counter: i32,\n}\n\nimpl Reducible for CounterState {\n    type Action = i32;\n\n    fn reduce(self: Rc<Self>, action: Self::Action) -> Rc<Self> {\n        Self {\n            counter: self.counter + action,\n        }\n        .into()\n    }\n}\n\n#[wasm_bindgen_test]\nasync fn use_reducer_works() {\n    #[function_component(UseReducerComponent)]\n    fn use_reducer_comp() -> Html {\n        let counter = use_reducer(|| CounterState { counter: 10 });\n\n        let counter_clone = counter.clone();\n        use_effect_with((), move |_| {\n            counter_clone.dispatch(1);\n            || {}\n        });\n        html! {\n            <div>\n                {\"The test result is\"}\n                <div id=\"result\">{counter.counter}</div>\n                {\"\\n\"}\n            </div>\n        }\n    }\n\n    yew::Renderer::<UseReducerComponent>::with_root(\n        gloo::utils::document().get_element_by_id(\"output\").unwrap(),\n    )\n    .render();\n    sleep(Duration::ZERO).await;\n    let result = obtain_result();\n\n    assert_eq!(result.as_str(), \"11\");\n}\n\n#[derive(Debug, Clone, PartialEq)]\nstruct ContentState {\n    content: HashSet<String>,\n}\n\nimpl Reducible for ContentState {\n    type Action = String;\n\n    fn reduce(self: Rc<Self>, action: Self::Action) -> Rc<Self> {\n        let mut self_: Self = (*self).clone();\n        self_.content.insert(action);\n        self_.into()\n    }\n}\n\n#[wasm_bindgen_test]\nasync fn use_reducer_eq_works() {\n    #[function_component(UseReducerComponent)]\n    fn use_reducer_comp() -> Html {\n        let content = use_reducer_eq(|| ContentState {\n            content: HashSet::default(),\n        });\n\n        let render_count = use_mut_ref(|| 0);\n\n        let render_count = {\n            let mut render_count = render_count.borrow_mut();\n            *render_count += 1;\n\n            *render_count\n        };\n\n        let add_content_a = {\n            let content = content.clone();\n            Callback::from(move |_| content.dispatch(\"A\".to_string()))\n        };\n\n        let add_content_b = Callback::from(move |_| content.dispatch(\"B\".to_string()));\n\n        html! {\n            <>\n                <div>\n                    {\"This component has been rendered: \"}<span id=\"result\">{render_count}</span>{\" Time(s).\"}\n                </div>\n                <button onclick={add_content_a} id=\"add-a\">{\"Add A to Content\"}</button>\n                <button onclick={add_content_b} id=\"add-b\">{\"Add B to Content\"}</button>\n            </>\n        }\n    }\n\n    yew::Renderer::<UseReducerComponent>::with_root(\n        document().get_element_by_id(\"output\").unwrap(),\n    )\n    .render();\n    sleep(Duration::ZERO).await;\n\n    let result = obtain_result();\n    assert_eq!(result.as_str(), \"1\");\n\n    document()\n        .get_element_by_id(\"add-a\")\n        .unwrap()\n        .unchecked_into::<HtmlElement>()\n        .click();\n    sleep(Duration::ZERO).await;\n\n    let result = obtain_result();\n    assert_eq!(result.as_str(), \"2\");\n\n    document()\n        .get_element_by_id(\"add-a\")\n        .unwrap()\n        .unchecked_into::<HtmlElement>()\n        .click();\n    sleep(Duration::ZERO).await;\n\n    let result = obtain_result();\n    assert_eq!(result.as_str(), \"2\");\n\n    document()\n        .get_element_by_id(\"add-b\")\n        .unwrap()\n        .unchecked_into::<HtmlElement>()\n        .click();\n    sleep(Duration::ZERO).await;\n\n    let result = obtain_result();\n    assert_eq!(result.as_str(), \"3\");\n\n    document()\n        .get_element_by_id(\"add-b\")\n        .unwrap()\n        .unchecked_into::<HtmlElement>()\n        .click();\n    sleep(Duration::ZERO).await;\n\n    let result = obtain_result();\n    assert_eq!(result.as_str(), \"3\");\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "78b7382d20cf59c82cbd2c2175eb3d2af9f28327",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/yew/packages/yew/src/html/component/children.rs",
    "func": "//! Component children module\n\nuse std::fmt;\nuse std::rc::Rc;\n\nuse crate::html::Html;\nuse crate::virtual_dom::{VChild, VComp, VList, VNode};\nuse crate::{BaseComponent, Properties};\n\n/// A type used for accepting children elements in Component::Properties.\n///\n/// # Example\n/// **`model.rs`**\n///\n/// In this example, the `Wrapper` component is used to wrap other elements.\n/// ```\n/// # use yew::{Children, Html, Properties, Component, Context, html};\n/// # #[derive(Clone, Properties, PartialEq)]\n/// # struct WrapperProps {\n/// #     children: Children,\n/// # }\n/// # struct Wrapper;\n/// # impl Component for Wrapper {\n/// #     type Message = ();\n/// #     type Properties = WrapperProps;\n/// #   fn create(ctx: &Context<Self>) -> Self { Self }\n/// #   fn view(&self, ctx: &Context<Self>) -> Html {\n/// html! {\n///     <Wrapper>\n///         <h4>{ \"Hi\" }</h4>\n///         <div>{ \"Hello\" }</div>\n///     </Wrapper>\n/// }\n/// #     }\n/// # }\n/// ```\n///\n/// **`wrapper.rs`**\n///\n/// The Wrapper component must define a `children` property in order to wrap other elements. The\n/// children property can be used to render the wrapped elements.\n/// ```\n/// # use yew::{Children, Html, Properties, Component, Context, html};\n/// #[derive(Clone, Properties, PartialEq)]\n/// struct WrapperProps {\n///     children: Children,\n/// }\n///\n/// # struct Wrapper;\n/// impl Component for Wrapper {\n///     // ...\n/// #     type Message = ();\n/// #     type Properties = WrapperProps;\n/// #    fn create(ctx: &Context<Self>) -> Self { Self }\n///     fn view(&self, ctx: &Context<Self>) -> Html {\n///         html! {\n///             <div id=\"container\">\n///                 { ctx.props().children.clone() }\n///             </div>\n///         }\n///     }\n/// }\n/// ```\npub type Children = ChildrenRenderer<Html>;\n\n/// A type used for accepting children elements in Component::Properties and accessing their props.\n///\n/// # Example\n/// **`model.rs`**\n///\n/// In this example, the `List` component can wrap `ListItem` components.\n/// ```\n/// # use yew::{html, Component, Html, Context, ChildrenWithProps, Properties};\n/// #\n/// # #[derive(Clone, Properties, PartialEq)]\n/// # struct ListProps {\n/// #     children: ChildrenWithProps<ListItem>,\n/// # }\n/// # struct List;\n/// # impl Component for List {\n/// #     type Message = ();\n/// #     type Properties = ListProps;\n/// #   fn create(ctx: &Context<Self>) -> Self { Self }\n/// #   fn view(&self, ctx: &Context<Self>) -> Html { unimplemented!() }\n/// # }\n/// # #[derive(Clone, Properties, PartialEq)]\n/// # struct ListItemProps {\n/// #     value: String\n/// # }\n/// # struct ListItem;\n/// # impl Component for ListItem {\n/// #     type Message = ();\n/// #     type Properties = ListItemProps;\n/// #   fn create(ctx: &Context<Self>) -> Self { Self }\n/// #   fn view(&self, ctx: &Context<Self>) -> Html { unimplemented!() }\n/// # }\n/// # fn view() -> Html {\n/// html! {\n///   <List>\n///     <ListItem value=\"a\" />\n///     <ListItem value=\"b\" />\n///     <ListItem value=\"c\" />\n///   </List>\n/// }\n/// # }\n/// ```\n///\n/// **`list.rs`**\n///\n/// The `List` component must define a `children` property in order to wrap the list items. The\n/// `children` property can be used to filter, mutate, and render the items.\n/// ```\n/// # use yew::{html, Component, Html, ChildrenWithProps, Context, Properties};\n/// # use std::rc::Rc;\n/// #\n/// #[derive(Clone, Properties, PartialEq)]\n/// struct ListProps {\n///     children: ChildrenWithProps<ListItem>,\n/// }\n///\n/// # struct List;\n/// impl Component for List {\n/// #     type Message = ();\n/// #     type Properties = ListProps;\n/// #   fn create(ctx: &Context<Self>) -> Self { Self }\n/// #   fn view(&self, ctx: &Context<Self>) -> Html {\n///         html!{{\n///             for ctx.props().children.iter().map(|mut item| {\n///                 let mut props = Rc::make_mut(&mut item.props);\n///                 props.value = format!(\"item-{}\", props.value);\n///                 item\n///             })\n///         }}\n///     }\n/// }\n/// #\n/// # #[derive(Clone, Properties, PartialEq)]\n/// # struct ListItemProps {\n/// #     #[prop_or_default]\n/// #     value: String\n/// # }\n/// #\n/// # struct ListItem;\n/// # impl Component for ListItem {\n/// #     type Message = ();\n/// #     type Properties = ListItemProps;\n/// #   fn create(ctx: &Context<Self>) -> Self { Self }\n/// #   fn view(&self, ctx: &Context<Self>) -> Html { unimplemented!() }\n/// # }\n/// ```\npub type ChildrenWithProps<CHILD> = ChildrenRenderer<VChild<CHILD>>;\n\n/// A type used for rendering children html.\n#[derive(Clone)]\npub struct ChildrenRenderer<T> {\n    pub(crate) children: Vec<T>,\n}\n\nimpl<T: PartialEq> PartialEq for ChildrenRenderer<T> {\n    fn eq(&self, other: &Self) -> bool {\n        self.children == other.children\n    }\n}\n\nimpl<T> ChildrenRenderer<T>\nwhere\n    T: Clone,\n{\n    /// Create children\n    pub fn new(children: Vec<T>) -> Self {\n        Self { children }\n    }\n\n    /// Children list is empty\n    pub fn is_empty(&self) -> bool {\n        self.children.is_empty()\n    }\n\n    /// Number of children elements\n    pub fn len(&self) -> usize {\n        self.children.len()\n    }\n\n    /// Render children components and return `Iterator`\n    pub fn iter(&self) -> impl Iterator<Item = T> + '_ {\n        // clone each child lazily.\n        // This way `self.iter().next()` only has to clone a single node.\n        self.children.iter().cloned()\n    }\n\n    /// Convert the children elements to another object (if there are any).\n    ///\n    /// ```\n    /// # let children = Children::new(Vec::new());\n    /// # use yew::{classes, html, Children};\n    /// # let _ =\n    /// children.map(|children| {\n    ///     html! {\n    ///         <div class={classes!(\"container\")}>\n    ///             {children.clone()}\n    ///         </div>\n    ///     }\n    /// })\n    /// # ;\n    /// ```\n    pub fn map<OUT: Default>(&self, closure: impl FnOnce(&Self) -> OUT) -> OUT {\n        if self.is_empty() {\n            Default::default()\n        } else {\n            closure(self)\n        }\n    }\n}\n\nimpl<T> Default for ChildrenRenderer<T> {\n    fn default() -> Self {\n        Self {\n            children: Vec::new(),\n        }\n    }\n}\n\nimpl<T> fmt::Debug for ChildrenRenderer<T> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.write_str(\"ChildrenRenderer<_>\")\n    }\n}\n\nimpl<T> IntoIterator for ChildrenRenderer<T> {\n    type IntoIter = std::vec::IntoIter<Self::Item>;\n    type Item = T;\n\n    fn into_iter(self) -> Self::IntoIter {\n        self.children.into_iter()\n    }\n}\n\nimpl From<ChildrenRenderer<Html>> for Html {\n    fn from(mut val: ChildrenRenderer<Html>) -> Self {\n        if val.children.len() == 1 {\n            if let Some(m) = val.children.pop() {\n                return m;\n            }\n        }\n\n        Html::VList(Rc::new(val.into()))\n    }\n}\n\nimpl From<ChildrenRenderer<Html>> for VList {\n    fn from(val: ChildrenRenderer<Html>) -> Self {\n        if val.is_empty() {\n            return VList::new();\n        }\n        VList::with_children(val.children, None)\n    }\n}\n\nimpl<COMP> From<ChildrenRenderer<VChild<COMP>>> for ChildrenRenderer<Html>\nwhere\n    COMP: BaseComponent,\n{\n    fn from(value: ChildrenRenderer<VChild<COMP>>) -> Self {\n        Self::new(\n            value\n                .into_iter()\n                .map(VComp::from)\n                .map(VNode::from)\n                .collect(),\n        )\n    }\n}\n\n/// A [Properties] type with Children being the only property.\n#[derive(Debug, Properties, PartialEq)]\npub struct ChildrenProps {\n    /// The Children of a Component.\n    #[prop_or_default]\n    pub children: Html,\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn children_map() {\n        let children = Children::new(vec![]);\n        let res = children.map(|children| Some(children.clone()));\n        assert!(res.is_none());\n        let children = Children::new(vec![Default::default()]);\n        let res = children.map(|children| Some(children.clone()));\n        assert!(res.is_some());\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "2e0e217655a2cc2900d6b21f1bc6dcbf962ddbc6",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/yew/packages/yew/src/dom_bundle/blist.rs",
    "func": "//! This module contains fragments bundles, a [BList]\nuse std::borrow::Borrow;\nuse std::cmp::Ordering;\nuse std::collections::HashSet;\nuse std::hash::Hash;\nuse std::ops::Deref;\n\nuse web_sys::Element;\n\nuse super::{test_log, BNode, BSubtree, DomSlot};\nuse crate::dom_bundle::{Reconcilable, ReconcileTarget};\nuse crate::html::AnyScope;\nuse crate::utils::RcExt;\nuse crate::virtual_dom::{Key, VList, VNode};\n\n/// This struct represents a mounted [VList]\n#[derive(Debug)]\npub(super) struct BList {\n    /// The reverse (render order) list of child [BNode]s\n    rev_children: Vec<BNode>,\n    /// All [BNode]s in the BList have keys\n    fully_keyed: bool,\n    key: Option<Key>,\n}\n\nimpl VList {\n    // Splits a VList for creating / reconciling to a BList.\n    fn split_for_blist(self) -> (Option<Key>, bool, Vec<VNode>) {\n        let fully_keyed = self.fully_keyed();\n\n        let children = self\n            .children\n            .map(RcExt::unwrap_or_clone)\n            .unwrap_or_default();\n\n        (self.key, fully_keyed, children)\n    }\n}\n\nimpl Deref for BList {\n    type Target = Vec<BNode>;\n\n    fn deref(&self) -> &Self::Target {\n        &self.rev_children\n    }\n}\n\n/// Helper struct, that keeps the position where the next element is to be placed at\n#[derive(Clone)]\nstruct NodeWriter<'s> {\n    root: &'s BSubtree,\n    parent_scope: &'s AnyScope,\n    parent: &'s Element,\n    slot: DomSlot,\n}\n\nimpl<'s> NodeWriter<'s> {\n    /// Write a new node that has no ancestor\n    fn add(self, node: VNode) -> (Self, BNode) {\n        test_log!(\"adding: {:?}\", node);\n        test_log!(\n            \"  parent={:?}, slot={:?}\",\n            self.parent.outer_html(),\n            self.slot\n        );\n        let (next, bundle) = node.attach(self.root, self.parent_scope, self.parent, self.slot);\n        test_log!(\"  next_slot: {:?}\", next);\n        (Self { slot: next, ..self }, bundle)\n    }\n\n    /// Shift a bundle into place without patching it\n    fn shift(&self, bundle: &mut BNode) {\n        bundle.shift(self.parent, self.slot.clone());\n    }\n\n    /// Patch a bundle with a new node\n    fn patch(self, node: VNode, bundle: &mut BNode) -> Self {\n        test_log!(\"patching: {:?} -> {:?}\", bundle, node);\n        test_log!(\n            \"  parent={:?}, slot={:?}\",\n            self.parent.outer_html(),\n            self.slot\n        );\n        // Advance the next sibling reference (from right to left)\n        let next =\n            node.reconcile_node(self.root, self.parent_scope, self.parent, self.slot, bundle);\n        test_log!(\"  next_position: {:?}\", next);\n        Self { slot: next, ..self }\n    }\n}\n/// Helper struct implementing [Eq] and [Hash] by only looking at a node's key\nstruct KeyedEntry(usize, BNode);\nimpl Borrow<Key> for KeyedEntry {\n    fn borrow(&self) -> &Key {\n        self.1.key().expect(\"unkeyed child in fully keyed list\")\n    }\n}\nimpl Hash for KeyedEntry {\n    fn hash<H: std::hash::Hasher>(&self, state: &mut H) {\n        <Self as Borrow<Key>>::borrow(self).hash(state)\n    }\n}\nimpl PartialEq for KeyedEntry {\n    fn eq(&self, other: &Self) -> bool {\n        <Self as Borrow<Key>>::borrow(self) == <Self as Borrow<Key>>::borrow(other)\n    }\n}\nimpl Eq for KeyedEntry {}\n\nimpl BNode {\n    /// Assert that a bundle node is a list, or convert it to a list with a single child\n    fn make_list(&mut self) -> &mut BList {\n        match self {\n            Self::List(blist) => blist,\n            self_ => {\n                let b = std::mem::replace(self_, BNode::List(BList::new()));\n                let self_list = match self_ {\n                    BNode::List(blist) => blist,\n                    _ => unreachable!(\"just been set to the variant\"),\n                };\n                let key = b.key().cloned();\n                self_list.rev_children.push(b);\n                self_list.fully_keyed = key.is_some();\n                self_list.key = key;\n                self_list\n            }\n        }\n    }\n}\n\nimpl BList {\n    /// Create a new empty [BList]\n    pub const fn new() -> BList {\n        BList {\n            rev_children: vec![],\n            fully_keyed: true,\n            key: None,\n        }\n    }\n\n    /// Get the key of the underlying fragment\n    pub fn key(&self) -> Option<&Key> {\n        self.key.as_ref()\n    }\n\n    /// Diff and patch unkeyed child lists\n    fn apply_unkeyed(\n        root: &BSubtree,\n        parent_scope: &AnyScope,\n        parent: &Element,\n        slot: DomSlot,\n        lefts: Vec<VNode>,\n        rights: &mut Vec<BNode>,\n    ) -> DomSlot {\n        let mut writer = NodeWriter {\n            root,\n            parent_scope,\n            parent,\n            slot,\n        };\n\n        // Remove extra nodes\n        if lefts.len() < rights.len() {\n            for r in rights.drain(lefts.len()..) {\n                test_log!(\"removing: {:?}\", r);\n                r.detach(root, parent, false);\n            }\n        }\n\n        let mut lefts_it = lefts.into_iter().rev();\n        for (r, l) in rights.iter_mut().zip(&mut lefts_it) {\n            writer = writer.patch(l, r);\n        }\n\n        // Add missing nodes\n        for l in lefts_it {\n            let (next_writer, el) = writer.add(l);\n            rights.push(el);\n            writer = next_writer;\n        }\n        writer.slot\n    }\n\n    /// Diff and patch fully keyed child lists.\n    ///\n    /// Optimized for node addition or removal from either end of the list and small changes in the\n    /// middle.\n    fn apply_keyed(\n        root: &BSubtree,\n        parent_scope: &AnyScope,\n        parent: &Element,\n        slot: DomSlot,\n        left_vdoms: Vec<VNode>,\n        rev_bundles: &mut Vec<BNode>,\n    ) -> DomSlot {\n        macro_rules! key {\n            ($v:expr) => {\n                $v.key().expect(\"unkeyed child in fully keyed list\")\n            };\n        }\n        /// Find the first differing key in 2 iterators\n        fn matching_len<'a, 'b>(\n            a: impl Iterator<Item = &'a Key>,\n            b: impl Iterator<Item = &'b Key>,\n        ) -> usize {\n            a.zip(b).take_while(|(a, b)| a == b).count()\n        }\n\n        // Find first key mismatch from the back\n        let matching_len_end = matching_len(\n            left_vdoms.iter().map(|v| key!(v)).rev(),\n            rev_bundles.iter().map(|v| key!(v)),\n        );\n\n        // If there is no key mismatch, apply the unkeyed approach\n        // Corresponds to adding or removing items from the back of the list\n        if matching_len_end == std::cmp::min(left_vdoms.len(), rev_bundles.len()) {\n            // No key changes\n            return Self::apply_unkeyed(root, parent_scope, parent, slot, left_vdoms, rev_bundles);\n        }\n\n        // We partially drain the new vnodes in several steps.\n        let mut lefts = left_vdoms;\n        let mut writer = NodeWriter {\n            root,\n            parent_scope,\n            parent,\n            slot,\n        };\n        // Step 1. Diff matching children at the end\n        let lefts_to = lefts.len() - matching_len_end;\n        for (l, r) in lefts\n            .drain(lefts_to..)\n            .rev()\n            .zip(rev_bundles[..matching_len_end].iter_mut())\n        {\n            writer = writer.patch(l, r);\n        }\n\n        // Step 2. Diff matching children in the middle, that is between the first and last key\n        // mismatch Find first key mismatch from the front\n        let matching_len_start = matching_len(\n            lefts.iter().map(|v| key!(v)),\n            rev_bundles.iter().map(|v| key!(v)).rev(),\n        );\n\n        // Step 2.1. Splice out the existing middle part and build a lookup by key\n        let rights_to = rev_bundles.len() - matching_len_start;\n        let mut spliced_middle =\n            rev_bundles.splice(matching_len_end..rights_to, std::iter::empty());\n        #[allow(clippy::mutable_key_type)]\n        let mut spare_bundles: HashSet<KeyedEntry> =\n            HashSet::with_capacity((matching_len_end..rights_to).len());\n        for (idx, r) in (&mut spliced_middle).enumerate() {\n            spare_bundles.insert(KeyedEntry(idx, r));\n        }\n\n        // Step 2.2. Put the middle part back together in the new key order\n        let mut replacements: Vec<BNode> = Vec::with_capacity((matching_len_start..lefts_to).len());\n        // The goal is to shift as few nodes as possible.\n\n        // We handle runs of in-order nodes. When we encounter one out-of-order, we decide whether:\n        // - to shift all nodes in the current run to the position after the node before of the run,\n        //   or to\n        // - \"commit\" to the current run, shift all nodes before the end of the run that we might\n        //   encounter in the future, and then start a new run.\n        // Example of a run:\n        //               barrier_idx --v                   v-- end_idx\n        // spliced_middle  [ ... , M , N , C , D , E , F , G , ... ] (original element order)\n        //                                 ^---^-----------^ the nodes that are part of the current\n        // run                           v start_writer\n        // replacements    [ ... , M , C , D , G ]                   (new element order)\n        //                             ^-- start_idx\n        let mut barrier_idx = 0; // nodes from spliced_middle[..barrier_idx] are shifted unconditionally\n        struct RunInformation<'a> {\n            start_writer: NodeWriter<'a>,\n            start_idx: usize,\n            end_idx: usize,\n        }\n        let mut current_run: Option<RunInformation<'_>> = None;\n\n        for l in lefts\n            .drain(matching_len_start..) // lefts_to.. has been drained\n            .rev()\n        {\n            let ancestor = spare_bundles.take(key!(l));\n            // Check if we need to shift or commit a run\n            if let Some(run) = current_run.as_mut() {\n                if let Some(KeyedEntry(idx, _)) = ancestor {\n                    // If there are only few runs, this is a cold path\n                    if idx < run.end_idx {\n                        // Have to decide whether to shift or commit the current run. A few\n                        // calculations: A perfect estimate of the amount of\n                        // nodes we have to shift if we move this run:\n                        let run_length = replacements.len() - run.start_idx;\n                        // A very crude estimate of the amount of nodes we will have to shift if we\n                        // commit the run: Note nodes of the current run\n                        // should not be counted here!\n                        let estimated_skipped_nodes = run.end_idx - idx.max(barrier_idx);\n                        // double run_length to counteract that the run is part of the\n                        // estimated_skipped_nodes\n                        if 2 * run_length > estimated_skipped_nodes {\n                            // less work to commit to this run\n                            barrier_idx = 1 + run.end_idx;\n                        } else {\n                            // Less work to shift this run\n                            for r in replacements[run.start_idx..].iter_mut().rev() {\n                                run.start_writer.shift(r);\n                            }\n                        }\n                        current_run = None;\n                    }\n                }\n            }\n            let bundle = if let Some(KeyedEntry(idx, mut r_bundle)) = ancestor {\n                match current_run.as_mut() {\n                    // hot path\n                    // We know that idx >= run.end_idx, so this node doesn't need to shift\n                    Some(run) => run.end_idx = idx,\n                    None => match idx.cmp(&barrier_idx) {\n                        // peep hole optimization, don't start a run as the element is already where\n                        // it should be\n                        Ordering::Equal => barrier_idx += 1,\n                        // shift the node unconditionally, don't start a run\n                        Ordering::Less => writer.shift(&mut r_bundle),\n                        // start a run\n                        Ordering::Greater => {\n                            current_run = Some(RunInformation {\n                                start_writer: writer.clone(),\n                                start_idx: replacements.len(),\n                                end_idx: idx,\n                            })\n                        }\n                    },\n                }\n                writer = writer.patch(l, &mut r_bundle);\n                r_bundle\n            } else {\n                // Even if there is an active run, we don't have to modify it\n                let (next_writer, bundle) = writer.add(l);\n                writer = next_writer;\n                bundle\n            };\n            replacements.push(bundle);\n        }\n        // drop the splice iterator and immediately replace the range with the reordered elements\n        drop(spliced_middle);\n        rev_bundles.splice(matching_len_end..matching_len_end, replacements);\n\n        // Step 2.3. Remove any extra rights\n        for KeyedEntry(_, r) in spare_bundles.drain() {\n            test_log!(\"removing: {:?}\", r);\n            r.detach(root, parent, false);\n        }\n\n        // Step 3. Diff matching children at the start\n        let rights_to = rev_bundles.len() - matching_len_start;\n        for (l, r) in lefts\n            .drain(..) // matching_len_start.. has been drained already\n            .rev()\n            .zip(rev_bundles[rights_to..].iter_mut())\n        {\n            writer = writer.patch(l, r);\n        }\n\n        writer.slot\n    }\n}\n\nimpl ReconcileTarget for BList {\n    fn detach(self, root: &BSubtree, parent: &Element, parent_to_detach: bool) {\n        for child in self.rev_children.into_iter() {\n            child.detach(root, parent, parent_to_detach);\n        }\n    }\n\n    fn shift(&self, next_parent: &Element, mut slot: DomSlot) -> DomSlot {\n        for node in self.rev_children.iter() {\n            slot = node.shift(next_parent, slot);\n        }\n\n        slot\n    }\n}\n\nimpl Reconcilable for VList {\n    type Bundle = BList;\n\n    fn attach(\n        self,\n        root: &BSubtree,\n        parent_scope: &AnyScope,\n        parent: &Element,\n        slot: DomSlot,\n    ) -> (DomSlot, Self::Bundle) {\n        let mut self_ = BList::new();\n        let node_ref = self.reconcile(root, parent_scope, parent, slot, &mut self_);\n        (node_ref, self_)\n    }\n\n    fn reconcile_node(\n        self,\n        root: &BSubtree,\n        parent_scope: &AnyScope,\n        parent: &Element,\n        slot: DomSlot,\n        bundle: &mut BNode,\n    ) -> DomSlot {\n        // 'Forcefully' pretend the existing node is a list. Creates a\n        // singleton list if it isn't already.\n        let blist = bundle.make_list();\n        self.reconcile(root, parent_scope, parent, slot, blist)\n    }\n\n    fn reconcile(\n        self,\n        root: &BSubtree,\n        parent_scope: &AnyScope,\n        parent: &Element,\n        slot: DomSlot,\n        blist: &mut BList,\n    ) -> DomSlot {\n        // Here, we will try to diff the previous list elements with the new\n        // ones we want to insert. For that, we will use two lists:\n        //  - lefts: new elements to render in the DOM\n        //  - rights: previously rendered elements.\n        //\n        // The left items are known since we want to insert them\n        // (self.children). For the right ones, we will look at the bundle,\n        // i.e. the current DOM list element that we want to replace with self.\n        let (key, fully_keyed, lefts) = self.split_for_blist();\n\n        let rights = &mut blist.rev_children;\n        test_log!(\"lefts: {:?}\", lefts);\n        test_log!(\"rights: {:?}\", rights);\n\n        if let Some(additional) = lefts.len().checked_sub(rights.len()) {\n            rights.reserve_exact(additional);\n        }\n        let first = if fully_keyed && blist.fully_keyed {\n            BList::apply_keyed(root, parent_scope, parent, slot, lefts, rights)\n        } else {\n            BList::apply_unkeyed(root, parent_scope, parent, slot, lefts, rights)\n        };\n        blist.fully_keyed = fully_keyed;\n        blist.key = key;\n        test_log!(\"result: {:?}\", rights);\n        first\n    }\n}\n\n#[cfg(feature = \"hydration\")]\nmod feat_hydration {\n    use super::*;\n    use crate::dom_bundle::{Fragment, Hydratable};\n\n    impl Hydratable for VList {\n        fn hydrate(\n            self,\n            root: &BSubtree,\n            parent_scope: &AnyScope,\n            parent: &Element,\n            fragment: &mut Fragment,\n        ) -> Self::Bundle {\n            let (key, fully_keyed, vchildren) = self.split_for_blist();\n\n            let mut children = Vec::with_capacity(vchildren.len());\n\n            for child in vchildren.into_iter() {\n                let child = child.hydrate(root, parent_scope, parent, fragment);\n\n                children.push(child);\n            }\n\n            children.reverse();\n\n            BList {\n                rev_children: children,\n                fully_keyed,\n                key,\n            }\n        }\n    }\n}\n\n#[cfg(all(target_arch = \"wasm32\", not(target_os = \"wasi\")))]\n#[cfg(test)]\nmod layout_tests {\n    extern crate self as yew;\n\n    use wasm_bindgen_test::{wasm_bindgen_test as test, wasm_bindgen_test_configure};\n\n    use crate::html;\n    use crate::tests::layout_tests::{diff_layouts, TestLayout};\n\n    wasm_bindgen_test_configure!(run_in_browser);\n\n    #[test]\n    fn diff() {\n        let layout1 = TestLayout {\n            name: \"1\",\n            node: html! {\n                <>\n                    {\"a\"}\n                    {\"b\"}\n                    <>\n                        {\"c\"}\n                        {\"d\"}\n                    </>\n                    {\"e\"}\n                </>\n            },\n            expected: \"abcde\",\n        };\n\n        let layout2 = TestLayout {\n            name: \"2\",\n            node: html! {\n                <>\n                    {\"a\"}\n                    {\"b\"}\n                    <></>\n                    {\"e\"}\n                    {\"f\"}\n                </>\n            },\n            expected: \"abef\",\n        };\n\n        let layout3 = TestLayout {\n            name: \"3\",\n            node: html! {\n                <>\n                    {\"a\"}\n                    <></>\n                    {\"b\"}\n                    {\"e\"}\n                </>\n            },\n            expected: \"abe\",\n        };\n\n        let layout4 = TestLayout {\n            name: \"4\",\n            node: html! {\n                <>\n                    {\"a\"}\n                    <>\n                        {\"c\"}\n                        {\"d\"}\n                    </>\n                    {\"b\"}\n                    {\"e\"}\n                </>\n            },\n            expected: \"acdbe\",\n        };\n\n        diff_layouts(vec![layout1, layout2, layout3, layout4]);\n    }\n}\n\n#[cfg(all(target_arch = \"wasm32\", not(target_os = \"wasi\")))]\n#[cfg(test)]\nmod layout_tests_keys {\n    extern crate self as yew;\n\n    use wasm_bindgen_test::{wasm_bindgen_test as test, wasm_bindgen_test_configure};\n    use web_sys::Node;\n\n    use crate::tests::layout_tests::{diff_layouts, TestLayout};\n    use crate::virtual_dom::VNode;\n    use crate::{html, Children, Component, Context, Html, Properties};\n\n    wasm_bindgen_test_configure!(run_in_browser);\n\n    struct Comp {}\n\n    #[derive(Properties, Clone, PartialEq)]\n    struct CountingCompProps {\n        id: usize,\n        #[prop_or(false)]\n        can_change: bool,\n    }\n\n    impl Component for Comp {\n        type Message = ();\n        type Properties = CountingCompProps;\n\n        fn create(_: &Context<Self>) -> Self {\n            Comp {}\n        }\n\n        fn update(&mut self, _ctx: &Context<Self>, _: Self::Message) -> bool {\n            unimplemented!();\n        }\n\n        fn view(&self, ctx: &Context<Self>) -> Html {\n            html! { <p>{ ctx.props().id }</p> }\n        }\n    }\n\n    #[derive(Clone, Properties, PartialEq)]\n    pub struct ListProps {\n        pub children: Children,\n    }\n\n    pub struct List();\n\n    impl Component for List {\n        type Message = ();\n        type Properties = ListProps;\n\n        fn create(_: &Context<Self>) -> Self {\n            Self()\n        }\n\n        fn update(&mut self, _ctx: &Context<Self>, _: Self::Message) -> bool {\n            unimplemented!();\n        }\n\n        fn view(&self, ctx: &Context<Self>) -> Html {\n            html! { <>{ for ctx.props().children.iter() }</> }\n        }\n    }\n\n    #[test]\n    fn diff() {\n        let mut layouts = vec![];\n\n        let vref_node: Node = gloo::utils::document().create_element(\"i\").unwrap().into();\n        layouts.push(TestLayout {\n            name: \"All VNode types as children\",\n            node: html! {\n                <>\n                    {\"a\"}\n                    <span key=\"vtag\"></span>\n                    {\"c\"}\n                    {\"d\"}\n                    <Comp id=0 key=\"vchild\" />\n                    <key=\"vlist\">\n                        {\"foo\"}\n                        {\"bar\"}\n                    </>\n                    {VNode::VRef(vref_node)}\n                </>\n            },\n            expected: \"a<span></span>cd<p>0</p>foobar<i></i>\",\n        });\n\n        layouts.extend(vec![\n            TestLayout {\n                name: \"Inserting into VList first child - before\",\n                node: html! {\n                    <>\n                        <key=\"VList\">\n                            <i key=\"i\"></i>\n                        </>\n                        <p key=\"p\"></p>\n                    </>\n                },\n                expected: \"<i></i><p></p>\",\n            },\n            TestLayout {\n                name: \"Inserting into VList first child - after\",\n                node: html! {\n                    <>\n                        <key=\"VList\">\n                            <i key=\"i\"></i>\n                            <e key=\"e\"></e>\n                        </>\n                        <p key=\"p\"></p>\n                    </>\n                },\n                expected: \"<i></i><e></e><p></p>\",\n            },\n        ]);\n\n        layouts.extend(vec![\n            TestLayout {\n                name: \"No matches - before\",\n                node: html! {\n                    <>\n                        <i key=\"i\"></i>\n                        <e key=\"e\"></e>\n                    </>\n                },\n                expected: \"<i></i><e></e>\",\n            },\n            TestLayout {\n                name: \"No matches - after\",\n                node: html! {\n                    <>\n                        <a key=\"a\"></a>\n                        <p key=\"p\"></p>\n                    </>\n                },\n                expected: \"<a></a><p></p>\",\n            },\n        ]);\n\n        layouts.extend(vec![\n            TestLayout {\n                name: \"Append - before\",\n                node: html! {\n                    <>\n                        <i key=\"i\"></i>\n                        <e key=\"e\"></e>\n                    </>\n                },\n                expected: \"<i></i><e></e>\",\n            },\n            TestLayout {\n                name: \"Append - after\",\n                node: html! {\n                    <>\n                        <i key=\"i\"></i>\n                        <e key=\"e\"></e>\n                        <p key=\"p\"></p>\n                    </>\n                },\n                expected: \"<i></i><e></e><p></p>\",\n            },\n        ]);\n\n        layouts.extend(vec![\n            TestLayout {\n                name: \"Prepend - before\",\n                node: html! {\n                    <>\n                        <i key=\"i\"></i>\n                        <e key=\"e\"></e>\n                    </>\n                },\n                expected: \"<i></i><e></e>\",\n            },\n            TestLayout {\n                name: \"Prepend - after\",\n                node: html! {\n                    <>\n                        <p key=\"p\"></p>\n                        <i key=\"i\"></i>\n                        <e key=\"e\"></e>\n                    </>\n                },\n                expected: \"<p></p><i></i><e></e>\",\n            },\n        ]);\n\n        layouts.extend(vec![\n            TestLayout {\n                name: \"Delete first - before\",\n                node: html! {\n                    <>\n                        <i key=\"i\"></i>\n                        <e key=\"e\"></e>\n                        <p key=\"p\"></p>\n                    </>\n                },\n                expected: \"<i></i><e></e><p></p>\",\n            },\n            TestLayout {\n                name: \"Delete first - after\",\n                node: html! {\n                    <>\n                        <e key=\"e\"></e>\n                        <p key=\"p\"></p>\n                    </>\n                },\n                expected: \"<e></e><p></p>\",\n            },\n        ]);\n\n        layouts.extend(vec![\n            TestLayout {\n                name: \"Delete last - before\",\n                node: html! {\n                    <>\n                        <i key=\"i\"></i>\n                        <e key=\"e\"></e>\n                        <p key=\"p\"></p>\n                    </>\n                },\n                expected: \"<i></i><e></e><p></p>\",\n            },\n            TestLayout {\n                name: \"Delete last - after\",\n                node: html! {\n                    <>\n                        <i key=\"i\"></i>\n                        <e key=\"e\"></e>\n                    </>\n                },\n                expected: \"<i></i><e></e>\",\n            },\n        ]);\n\n        layouts.extend(vec![\n            TestLayout {\n                name: \"Delete last and change node type - before\",\n                node: html! {\n                    <>\n                        <i key=\"i\"></i>\n                        <e key=\"e\"></e>\n                        <p key=\"p\"></p>\n                    </>\n                },\n                expected: \"<i></i><e></e><p></p>\",\n            },\n            TestLayout {\n                name: \"Delete last - after\",\n                node: html! {\n                    <>\n                        <List key=\"i\"><i/></List>\n                        <List key=\"e\"><e/></List>\n                        <List key=\"a\"><a/></List>\n                    </>\n                },\n                expected: \"<i></i><e></e><a></a>\",\n            },\n        ]);\n\n        layouts.extend(vec![\n            TestLayout {\n                name: \"Delete middle - before\",\n                node: html! {\n                    <>\n                        <i key=\"i\"></i>\n                        <e key=\"e\"></e>\n                        <p key=\"p\"></p>\n                        <a key=\"a\"></a>\n                    </>\n                },\n                expected: \"<i></i><e></e><p></p><a></a>\",\n            },\n            TestLayout {\n                name: \"Delete middle - after\",\n                node: html! {\n                    <>\n                        <i key=\"i\"></i>\n                        <e key=\"e2\"></e>\n                        <p key=\"p2\"></p>\n                        <a key=\"a\"></a>\n                    </>\n                },\n                expected: \"<i></i><e></e><p></p><a></a>\",\n            },\n        ]);\n\n        layouts.extend(vec![\n            TestLayout {\n                name: \"Delete middle and change node type - before\",\n                node: html! {\n                    <>\n                        <i key=\"i\"></i>\n                        <e key=\"e\"></e>\n                        <p key=\"p\"></p>\n                        <a key=\"a\"></a>\n                    </>\n                },\n                expected: \"<i></i><e></e><p></p><a></a>\",\n            },\n            TestLayout {\n                name: \"Delete middle and change node type- after\",\n                node: html! {\n                    <>\n                        <List key=\"i2\"><i/></List>\n                        <e key=\"e\"></e>\n                        <List key=\"p\"><p/></List>\n                        <List key=\"a2\"><a/></List>\n                    </>\n                },\n                expected: \"<i></i><e></e><p></p><a></a>\",\n            },\n        ]);\n\n        layouts.extend(vec![\n            TestLayout {\n                name: \"Reverse - before\",\n                node: html! {\n                    <>\n                        <i key=\"i\"></i>\n                        <e key=\"e\"></e>\n                        <p key=\"p\"></p>\n                        <u key=\"u\"></u>\n                    </>\n                },\n                expected: \"<i></i><e></e><p></p><u></u>\",\n            },\n            TestLayout {\n                name: \"Reverse - after\",\n                node: html! {\n                    <>\n                        <u key=\"u\"></u>\n                        <p key=\"p\"></p>\n                        <e key=\"e\"></e>\n                        <i key=\"i\"></i>\n                    </>\n                },\n                expected: \"<u></u><p></p><e></e><i></i>\",\n            },\n        ]);\n\n        layouts.extend(vec![\n            TestLayout {\n                name: \"Reverse and change node type - before\",\n                node: html! {\n                    <>\n                        <i key=\"i\"></i>\n                        <key=\"i1\"></>\n                        <key=\"i2\"></>\n                        <key=\"i3\"></>\n                        <e key=\"e\"></e>\n                        <key=\"yo\">\n                            <p key=\"p\"></p>\n                        </>\n                        <u key=\"u\"></u>\n                    </>\n                },\n                expected: \"<i></i><e></e><p></p><u></u>\",\n            },\n            TestLayout {\n                name: \"Reverse and change node type - after\",\n                node: html! {\n                    <>\n                        <List key=\"u\"><u/></List>\n                        <List key=\"p\"><p/></List>\n                        <List key=\"e\"><e/></List>\n                        <List key=\"i\"><i/></List>\n                    </>\n                },\n                expected: \"<u></u><p></p><e></e><i></i>\",\n            },\n        ]);\n\n        layouts.extend(vec![\n            TestLayout {\n                name: \"Swap 1&2 - before\",\n                node: html! {\n                    <>\n                        <i key=\"1\"></i>\n                        <e key=\"2\"></e>\n                        <p key=\"3\"></p>\n                        <a key=\"4\"></a>\n                        <u key=\"5\"></u>\n                    </>\n                },\n                expected: \"<i></i><e></e><p></p><a></a><u></u>\",\n            },\n            TestLayout {\n                name: \"Swap 1&2 - after\",\n                node: html! {\n                    <>\n                        <e key=\"2\"></e>\n                        <i key=\"1\"></i>\n                        <p key=\"3\"></p>\n                        <a key=\"4\"></a>\n                        <u key=\"5\"></u>\n                    </>\n                },\n                expected: \"<e></e><i></i><p></p><a></a><u></u>\",\n            },\n        ]);\n\n        layouts.extend(vec![\n            TestLayout {\n                name: \"Swap 1&2 and change node type - before\",\n                node: html! {\n                    <>\n                        <i key=\"1\"></i>\n                        <e key=\"2\"></e>\n                        <p key=\"3\"></p>\n                        <a key=\"4\"></a>\n                        <u key=\"5\"></u>\n                    </>\n                },\n                expected: \"<i></i><e></e><p></p><a></a><u></u>\",\n            },\n            TestLayout {\n                name: \"Swap 1&2 and change node type - after\",\n                node: html! {\n                    <>\n                        <List key=\"2\"><e/></List>\n                        <List key=\"1\"><i/></List>\n                        <List key=\"3\"><p/></List>\n                        <List key=\"4\"><a/></List>\n                        <List key=\"5\"><u/></List>\n                    </>\n                },\n                expected: \"<e></e><i></i><p></p><a></a><u></u>\",\n            },\n        ]);\n\n        layouts.extend(vec![\n            TestLayout {\n                name: \"test - before\",\n                node: html! {\n                    <>\n                        <key=\"1\">\n                            <e key=\"e\"></e>\n                            <p key=\"p\"></p>\n                            <a key=\"a\"></a>\n                            <u key=\"u\"></u>\n                        </>\n                        <key=\"2\">\n                            <e key=\"e\"></e>\n                            <p key=\"p\"></p>\n                            <a key=\"a\"></a>\n                            <u key=\"u\"></u>\n                        </>\n                    </>\n                },\n                expected: \"<e></e><p></p><a></a><u></u><e></e><p></p><a></a><u></u>\",\n            },\n            TestLayout {\n                name: \"Swap 4&5 - after\",\n                node: html! {\n                    <>\n                        <e key=\"1\"></e>\n                        <key=\"2\">\n                            <p key=\"p\"></p>\n                            <i key=\"i\"></i>\n                        </>\n                    </>\n                },\n                expected: \"<e></e><p></p><i></i>\",\n            },\n        ]);\n\n        layouts.extend(vec![\n            TestLayout {\n                name: \"Swap 4&5 - before\",\n                node: html! {\n                    <>\n                        <i key=\"1\"></i>\n                        <e key=\"2\"></e>\n                        <p key=\"3\"></p>\n                        <a key=\"4\"></a>\n                        <u key=\"5\"></u>\n                    </>\n                },\n                expected: \"<i></i><e></e><p></p><a></a><u></u>\",\n            },\n            TestLayout {\n                name: \"Swap 4&5 - after\",\n                node: html! {\n                    <>\n                        <i key=\"1\"></i>\n                        <e key=\"2\"></e>\n                        <p key=\"3\"></p>\n                        <u key=\"5\"></u>\n                        <a key=\"4\"></a>\n                    </>\n                },\n                expected: \"<i></i><e></e><p></p><u></u><a></a>\",\n            },\n        ]);\n\n        layouts.extend(vec![\n            TestLayout {\n                name: \"Swap 1&5 - before\",\n                node: html! {\n                    <>\n                        <i key=\"1\"></i>\n                        <e key=\"2\"></e>\n                        <p key=\"3\"></p>\n                        <a key=\"4\"></a>\n                        <u key=\"5\"></u>\n                    </>\n                },\n                expected: \"<i></i><e></e><p></p><a></a><u></u>\",\n            },\n            TestLayout {\n                name: \"Swap 1&5 - after\",\n                node: html! {\n                    <>\n                        <u key=\"5\"></u>\n                        <e key=\"2\"></e>\n                        <p key=\"3\"></p>\n                        <a key=\"4\"></a>\n                        <i key=\"1\"></i>\n                    </>\n                },\n                expected: \"<u></u><e></e><p></p><a></a><i></i>\",\n            },\n        ]);\n\n        layouts.extend(vec![\n            TestLayout {\n                name: \"Move 2 after 4 - before\",\n                node: html! {\n                    <>\n                        <i key=\"1\"></i>\n                        <e key=\"2\"></e>\n                        <p key=\"3\"></p>\n                        <a key=\"4\"></a>\n                        <u key=\"5\"></u>\n                    </>\n                },\n                expected: \"<i></i><e></e><p></p><a></a><u></u>\",\n            },\n            TestLayout {\n                name: \"Move 2 after 4 - after\",\n                node: html! {\n                    <>\n                        <i key=\"1\"></i>\n                        <p key=\"3\"></p>\n                        <a key=\"4\"></a>\n                        <e key=\"2\"></e>\n                        <u key=\"5\"></u>\n                    </>\n                },\n                expected: \"<i></i><p></p><a></a><e></e><u></u>\",\n            },\n        ]);\n\n        layouts.extend(vec![\n            TestLayout {\n                name: \"Swap 1,2 <-> 3,4 - before\",\n                node: html! {\n                    <>\n                        <i key=\"1\"></i>\n                        <e key=\"2\"></e>\n                        <p key=\"3\"></p>\n                        <a key=\"4\"></a>\n                        <u key=\"5\"></u>\n                    </>\n                },\n                expected: \"<i></i><e></e><p></p><a></a><u></u>\",\n            },\n            TestLayout {\n                name: \"Swap 1,2 <-> 3,4 - after\",\n                node: html! {\n                    <>\n                        <p key=\"3\"></p>\n                        <a key=\"4\"></a>\n                        <i key=\"1\"></i>\n                        <e key=\"2\"></e>\n                        <u key=\"5\"></u>\n                    </>\n                },\n                expected: \"<p></p><a></a><i></i><e></e><u></u>\",\n            },\n        ]);\n\n        layouts.extend(vec![\n            TestLayout {\n                name: \"Swap lists - before\",\n                node: html! {\n                    <>\n                        <key=\"1\">\n                            <i></i>\n                            <e></e>\n                        </>\n                        <key=\"2\">\n                            <a></a>\n                            <u></u>\n                        </>\n                    </>\n                },\n                expected: \"<i></i><e></e><a></a><u></u>\",\n            },\n            TestLayout {\n                name: \"Swap lists - after\",\n                node: html! {\n                    <>\n                        <key=\"2\">\n                            <a></a>\n                            <u></u>\n                        </>\n                        <key=\"1\">\n                            <i></i>\n                            <e></e>\n                        </>\n                    </>\n                },\n                expected: \"<a></a><u></u><i></i><e></e>\",\n            },\n        ]);\n\n        layouts.extend(vec![\n            TestLayout {\n                name: \"Swap lists with in-between - before\",\n                node: html! {\n                    <>\n                        <key=\"1\">\n                            <i></i>\n                            <e></e>\n                        </>\n                        <p key=\"between\"></p>\n                        <key=\"2\">\n                            <a></a>\n                            <u></u>\n                        </>\n                    </>\n                },\n                expected: \"<i></i><e></e><p></p><a></a><u></u>\",\n            },\n            TestLayout {\n                name: \"Swap lists with in-between - after\",\n                node: html! {\n                    <>\n                        <key=\"2\">\n                            <a></a>\n                            <u></u>\n                        </>\n                        <p key=\"between\"></p>\n                        <key=\"1\">\n                            <i></i>\n                            <e></e>\n                        </>\n                    </>\n                },\n                expected: \"<a></a><u></u><p></p><i></i><e></e>\",\n            },\n        ]);\n\n        layouts.extend(vec![\n            TestLayout {\n                name: \"Insert VComp front - before\",\n                node: html! {\n                    <>\n                        <u key=1></u>\n                        <a key=2></a>\n                    </>\n                },\n                expected: \"<u></u><a></a>\",\n            },\n            TestLayout {\n                name: \"Insert VComp front - after\",\n                node: html! {\n                    <>\n                        <Comp id=0 key=\"comp\"/>\n                        <u key=1></u>\n                        <a key=2></a>\n                    </>\n                },\n                expected: \"<p>0</p><u></u><a></a>\",\n            },\n        ]);\n\n        layouts.extend(vec![\n            TestLayout {\n                name: \"Insert VComp middle - before\",\n                node: html! {\n                    <>\n                        <u key=1></u>\n                        <a key=2></a>\n                    </>\n                },\n                expected: \"<u></u><a></a>\",\n            },\n            TestLayout {\n                name: \"Insert VComp middle - after\",\n                node: html! {\n                    <>\n                        <u key=1></u>\n                        <Comp id=0 key=\"comp\"/>\n                        <a key=2></a>\n                    </>\n                },\n                expected: \"<u></u><p>0</p><a></a>\",\n            },\n        ]);\n\n        layouts.extend(vec![\n            TestLayout {\n                name: \"Insert VComp back - before\",\n                node: html! {\n                    <>\n                        <u key=1></u>\n                        <a key=2></a>\n                    </>\n                },\n                expected: \"<u></u><a></a>\",\n            },\n            TestLayout {\n                name: \"Insert VComp back - after\",\n                node: html! {\n                    <>\n                        <u key=1></u>\n                        <a key=2></a>\n                        <Comp id=0 key=\"comp\"/>\n                    </>\n                },\n                expected: \"<u></u><a></a><p>0</p>\",\n            },\n        ]);\n\n        layouts.extend(vec![\n            TestLayout {\n                name: \"Reverse VComp children - before\",\n                node: html! {\n                    <>\n                        <Comp id=1 key=\"comp-1\"/>\n                        <Comp id=2 key=\"comp-2\"/>\n                        <Comp id=3 key=\"comp-3\"/>\n                    </>\n                },\n                expected: \"<p>1</p><p>2</p><p>3</p>\",\n            },\n            TestLayout {\n                name: \"Reverse VComp children - after\",\n                node: html! {\n                    <>\n                        <Comp id=3 key=\"comp-3\"/>\n                        <Comp id=2 key=\"comp-2\"/>\n                        <Comp id=1 key=\"comp-1\"/>\n                    </>\n                },\n                expected: \"<p>3</p><p>2</p><p>1</p>\",\n            },\n        ]);\n\n        layouts.extend(vec![\n            TestLayout {\n                name: \"Reverse VComp children with children - before\",\n                node: html! {\n                    <>\n                        <List key=\"comp-1\"><p>{\"11\"}</p><p>{\"12\"}</p></List>\n                        <List key=\"comp-2\"><p>{\"21\"}</p><p>{\"22\"}</p></List>\n                        <List key=\"comp-3\"><p>{\"31\"}</p><p>{\"32\"}</p></List>\n                    </>\n                },\n                expected: \"<p>11</p><p>12</p><p>21</p><p>22</p><p>31</p><p>32</p>\",\n            },\n            TestLayout {\n                name: \"Reverse VComp children with children - after\",\n                node: html! {\n                    <>\n                        <List key=\"comp-3\"><p>{\"31\"}</p><p>{\"32\"}</p></List>\n                        <List key=\"comp-2\"><p>{\"21\"}</p><p>{\"22\"}</p></List>\n                        <List key=\"comp-1\"><p>{\"11\"}</p><p>{\"12\"}</p></List>\n                    </>\n                },\n                expected: \"<p>31</p><p>32</p><p>21</p><p>22</p><p>11</p><p>12</p>\",\n            },\n        ]);\n\n        layouts.extend(vec![\n            TestLayout {\n                name: \"Complex component update - before\",\n                node: html! {\n                    <List>\n                        <Comp id=1 key=\"comp-1\"/>\n                        <Comp id=2 key=\"comp-2\"/>\n                    </List>\n                },\n                expected: \"<p>1</p><p>2</p>\",\n            },\n            TestLayout {\n                name: \"Complex component update - after\",\n                node: html! {\n                    <List>\n                        <List key=\"comp-1\">\n                            <Comp id=1 />\n                        </List>\n                        <List key=\"comp-2\">\n                            <p>{\"2\"}</p>\n                        </List>\n                    </List>\n                },\n                expected: \"<p>1</p><p>2</p>\",\n            },\n        ]);\n\n        layouts.extend(vec![\n            TestLayout {\n                name: \"Reorder VComp children with children - before\",\n                node: html! {\n                    <>\n                        <List key=\"comp-1\"><p>{\"1\"}</p></List>\n                        <List key=\"comp-3\"><p>{\"3\"}</p></List>\n                        <List key=\"comp-5\"><p>{\"5\"}</p></List>\n                        <List key=\"comp-2\"><p>{\"2\"}</p></List>\n                        <List key=\"comp-4\"><p>{\"4\"}</p></List>\n                        <List key=\"comp-6\"><p>{\"6\"}</p></List>\n                    </>\n                },\n                expected: \"<p>1</p><p>3</p><p>5</p><p>2</p><p>4</p><p>6</p>\",\n            },\n            TestLayout {\n                name: \"Reorder VComp children with children - after\",\n                node: html! {\n                    <>\n                        <Comp id=6 key=\"comp-6\"/>\n                        <Comp id=5 key=\"comp-5\"/>\n                        <Comp id=4 key=\"comp-4\"/>\n                        <Comp id=3 key=\"comp-3\"/>\n                        <Comp id=2 key=\"comp-2\"/>\n                        <Comp id=1 key=\"comp-1\"/>\n                    </>\n                },\n                expected: \"<p>6</p><p>5</p><p>4</p><p>3</p><p>2</p><p>1</p>\",\n            },\n        ]);\n\n        layouts.extend(vec![\n            TestLayout {\n                name: \"Replace and reorder components - before\",\n                node: html! {\n                    <List>\n                        <List key=\"comp-1\"><p>{\"1\"}</p></List>\n                        <List key=\"comp-2\"><p>{\"2\"}</p></List>\n                        <List key=\"comp-3\"><p>{\"3\"}</p></List>\n                    </List>\n                },\n                expected: \"<p>1</p><p>2</p><p>3</p>\",\n            },\n            TestLayout {\n                name: \"Replace and reorder components - after\",\n                node: html! {\n                    <List>\n                        <Comp id=3 key=\"comp-3\" />\n                        <Comp id=2 key=\"comp-2\" />\n                        <Comp id=1 key=\"comp-1\" />\n                    </List>\n                },\n                expected: \"<p>3</p><p>2</p><p>1</p>\",\n            },\n        ]);\n\n        diff_layouts(layouts);\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "dd20d7b0a0c563d497c066b6b13378230978e978",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/yew/packages/yew/src/virtual_dom/vsuspense.rs",
    "func": "use super::{Key, VNode};\nuse crate::html::ImplicitClone;\n\n/// This struct represents a suspendable DOM fragment.\n#[derive(Clone, Debug, PartialEq)]\npub struct VSuspense {\n    /// Child nodes.\n    pub(crate) children: VNode,\n    /// Fallback nodes when suspended.\n    pub(crate) fallback: VNode,\n    /// Whether the current status is suspended.\n    pub(crate) suspended: bool,\n    /// The Key.\n    pub(crate) key: Option<Key>,\n}\n\nimpl ImplicitClone for VSuspense {}\n\nimpl VSuspense {\n    pub fn new(children: VNode, fallback: VNode, suspended: bool, key: Option<Key>) -> Self {\n        Self {\n            children,\n            fallback,\n            suspended,\n            key,\n        }\n    }\n}\n\n#[cfg(feature = \"ssr\")]\nmod feat_ssr {\n    use super::*;\n    use crate::feat_ssr::VTagKind;\n    use crate::html::AnyScope;\n    use crate::platform::fmt::BufWriter;\n    use crate::virtual_dom::Collectable;\n\n    impl VSuspense {\n        pub(crate) async fn render_into_stream(\n            &self,\n            w: &mut BufWriter,\n            parent_scope: &AnyScope,\n            hydratable: bool,\n            parent_vtag_kind: VTagKind,\n        ) {\n            let collectable = Collectable::Suspense;\n\n            if hydratable {\n                collectable.write_open_tag(w);\n            }\n\n            // always render children on the server side.\n            self.children\n                .render_into_stream(w, parent_scope, hydratable, parent_vtag_kind)\n                .await;\n\n            if hydratable {\n                collectable.write_close_tag(w);\n            }\n        }\n    }\n}\n\n#[cfg(any(not(target_arch = \"wasm32\"), target_os = \"wasi\"))]\n#[cfg(feature = \"ssr\")]\n#[cfg(test)]\nmod ssr_tests {\n    use std::rc::Rc;\n    use std::time::Duration;\n\n    use tokio::task::{spawn_local, LocalSet};\n    use tokio::test;\n\n    use crate::platform::time::sleep;\n    use crate::prelude::*;\n    use crate::suspense::{Suspension, SuspensionResult};\n    use crate::ServerRenderer;\n\n    #[cfg(not(target_os = \"wasi\"))]\n    #[test(flavor = \"multi_thread\", worker_threads = 2)]\n    async fn test_suspense() {\n        #[derive(PartialEq)]\n        pub struct SleepState {\n            s: Suspension,\n        }\n\n        impl SleepState {\n            fn new() -> Self {\n                let (s, handle) = Suspension::new();\n\n                // we use tokio spawn local here.\n                spawn_local(async move {\n                    // we use tokio sleep here.\n                    sleep(Duration::from_millis(50)).await;\n\n                    handle.resume();\n                });\n\n                Self { s }\n            }\n        }\n\n        impl Reducible for SleepState {\n            type Action = ();\n\n            fn reduce(self: Rc<Self>, _action: Self::Action) -> Rc<Self> {\n                Self::new().into()\n            }\n        }\n\n        #[hook]\n        pub fn use_sleep() -> SuspensionResult<Rc<dyn Fn()>> {\n            let sleep_state = use_reducer(SleepState::new);\n\n            if sleep_state.s.resumed() {\n                Ok(Rc::new(move || sleep_state.dispatch(())))\n            } else {\n                Err(sleep_state.s.clone())\n            }\n        }\n\n        #[derive(PartialEq, Properties, Debug)]\n        struct ChildProps {\n            name: String,\n        }\n\n        #[function_component]\n        fn Child(props: &ChildProps) -> HtmlResult {\n            use_sleep()?;\n            Ok(html! { <div>{\"Hello, \"}{&props.name}{\"!\"}</div> })\n        }\n\n        #[function_component]\n        fn Comp() -> Html {\n            let fallback = html! {\"loading...\"};\n\n            html! {\n                <Suspense {fallback}>\n                    <Child name=\"Jane\" />\n                    <Child name=\"John\" />\n                    <Child name=\"Josh\" />\n                </Suspense>\n            }\n        }\n\n        let local = LocalSet::new();\n\n        let s = local\n            .run_until(async move {\n                ServerRenderer::<Comp>::new()\n                    .hydratable(false)\n                    .render()\n                    .await\n            })\n            .await;\n\n        assert_eq!(\n            s,\n            \"<div>Hello, Jane!</div><div>Hello, John!</div><div>Hello, Josh!</div>\"\n        );\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "bab0216831f6df59c44954a7c11da9d6ccf85bf4",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/yew/examples/router/src/main.rs",
    "func": "use yew::prelude::*;\nuse yew_router::prelude::*;\n\nmod components;\nmod content;\nmod generator;\nmod pages;\nuse pages::author::Author;\nuse pages::author_list::AuthorList;\nuse pages::home::Home;\nuse pages::page_not_found::PageNotFound;\nuse pages::post::Post;\nuse pages::post_list::PostList;\nuse yew::html::Scope;\n\n#[derive(Routable, PartialEq, Eq, Clone, Debug)]\npub enum Route {\n    #[at(\"/posts/:id\")]\n    Post { id: u64 },\n    #[at(\"/posts\")]\n    Posts,\n    #[at(\"/authors/:id\")]\n    Author { id: u64 },\n    #[at(\"/authors\")]\n    Authors,\n    #[at(\"/\")]\n    Home,\n    #[not_found]\n    #[at(\"/404\")]\n    NotFound,\n}\n\npub enum Msg {\n    ToggleNavbar,\n}\n\npub struct App {\n    navbar_active: bool,\n}\nimpl Component for App {\n    type Message = Msg;\n    type Properties = ();\n\n    fn create(_ctx: &Context<Self>) -> Self {\n        Self {\n            navbar_active: false,\n        }\n    }\n\n    fn update(&mut self, _ctx: &Context<Self>, msg: Self::Message) -> bool {\n        match msg {\n            Msg::ToggleNavbar => {\n                self.navbar_active = !self.navbar_active;\n                true\n            }\n        }\n    }\n\n    fn view(&self, ctx: &Context<Self>) -> Html {\n        html! {\n            <BrowserRouter>\n                { self.view_nav(ctx.link()) }\n\n                <main>\n                    <Switch<Route> render={switch} />\n                </main>\n                <footer class=\"footer\">\n                    <div class=\"content has-text-centered\">\n                        { \"Powered by \" }\n                        <a href=\"https://yew.rs\">{ \"Yew\" }</a>\n                        { \" using \" }\n                        <a href=\"https://bulma.io\">{ \"Bulma\" }</a>\n                        { \" and images from \" }\n                        <a href=\"https://unsplash.com\">{ \"Unsplash\" }</a>\n                    </div>\n                </footer>\n            </BrowserRouter>\n        }\n    }\n}\nimpl App {\n    fn view_nav(&self, link: &Scope<Self>) -> Html {\n        let Self { navbar_active, .. } = *self;\n\n        let active_class = if !navbar_active { \"is-active\" } else { \"\" };\n\n        html! {\n            <nav class=\"navbar is-primary\" role=\"navigation\" aria-label=\"main navigation\">\n                <div class=\"navbar-brand\">\n                    <h1 class=\"navbar-item is-size-3\">{ \"Yew Blog\" }</h1>\n\n                    <button class={classes!(\"navbar-burger\", \"burger\", active_class)}\n                        aria-label=\"menu\" aria-expanded=\"false\"\n                        onclick={link.callback(|_| Msg::ToggleNavbar)}\n                    >\n                        <span aria-hidden=\"true\"></span>\n                        <span aria-hidden=\"true\"></span>\n                        <span aria-hidden=\"true\"></span>\n                    </button>\n                </div>\n                <div class={classes!(\"navbar-menu\", active_class)}>\n                    <div class=\"navbar-start\">\n                        <Link<Route> classes={classes!(\"navbar-item\")} to={Route::Home}>\n                            { \"Home\" }\n                        </Link<Route>>\n                        <Link<Route> classes={classes!(\"navbar-item\")} to={Route::Posts}>\n                            { \"Posts\" }\n                        </Link<Route>>\n\n                        <div class=\"navbar-item has-dropdown is-hoverable\">\n                            <div class=\"navbar-link\">\n                                { \"More\" }\n                            </div>\n                            <div class=\"navbar-dropdown\">\n                                <Link<Route> classes={classes!(\"navbar-item\")} to={Route::Authors}>\n                                    { \"Meet the authors\" }\n                                </Link<Route>>\n                            </div>\n                        </div>\n                    </div>\n                </div>\n            </nav>\n        }\n    }\n}\n\nfn switch(routes: Route) -> Html {\n    match routes {\n        Route::Post { id } => {\n            html! { <Post seed={id} /> }\n        }\n        Route::Posts => {\n            html! { <PostList /> }\n        }\n        Route::Author { id } => {\n            html! { <Author seed={id} /> }\n        }\n        Route::Authors => {\n            html! { <AuthorList /> }\n        }\n        Route::Home => {\n            html! { <Home /> }\n        }\n        Route::NotFound => {\n            html! { <PageNotFound /> }\n        }\n    }\n}\n\nfn main() {\n    wasm_logger::init(wasm_logger::Config::new(log::Level::Trace));\n    yew::Renderer::<App>::new().render();\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "ab700187f82325335c64ef6244dc4ec78b532cbf",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/yew/examples/counter_functional/src/main.rs",
    "func": "use yew::prelude::*;\n\n#[function_component]\nfn App() -> Html {\n    let state = use_state(|| 0);\n\n    let incr_counter = {\n        let state = state.clone();\n        Callback::from(move |_| state.set(*state + 1))\n    };\n\n    let decr_counter = {\n        let state = state.clone();\n        Callback::from(move |_| state.set(*state - 1))\n    };\n\n    html! {\n        <>\n            <p> {\"current count: \"} {*state} </p>\n            <button onclick={incr_counter}> {\"+\"} </button>\n            <button onclick={decr_counter}> {\"-\"} </button>\n        </>\n    }\n}\n\nfn main() {\n    yew::Renderer::<App>::new().render();\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "557449fc4c25fb4e0f1537dbad5465c4977cfa6f",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/yew/examples/contexts/src/struct_component_producer.rs",
    "func": "use yew::prelude::*;\n\nuse super::msg_ctx::MessageContext;\n\npub struct StructComponentProducer;\n\nimpl Component for StructComponentProducer {\n    type Message = ();\n    type Properties = ();\n\n    fn create(_ctx: &Context<Self>) -> Self {\n        Self\n    }\n\n    fn view(&self, ctx: &Context<Self>) -> Html {\n        let (msg_ctx, _) = ctx\n            .link()\n            .context::<MessageContext>(Callback::noop())\n            .expect(\"No Message Context Provided\");\n\n        html! {\n            <button onclick={move |_| msg_ctx.dispatch(\"Other message received.\".to_owned())}>\n                {\"OR ME\"}\n            </button>\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "18cf2fdd6d87f76a739ae90a1ad7e67bba7c6b9e",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/yew/examples/function_todomvc/src/hooks.rs",
    "func": "pub mod use_bool_toggle;\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "59df9742905ce726e258c046d72b5d167d5b0cef",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/starship/src/context.rs",
    "func": "use crate::config::{ModuleConfig, StarshipConfig};\nuse crate::configs::StarshipRootConfig;\nuse crate::context_env::Env;\nuse crate::module::Module;\nuse crate::utils::{create_command, exec_timeout, read_file, CommandOutput, PathExt};\n\nuse crate::modules;\nuse crate::utils;\nuse clap::Parser;\nuse gix::{\n    repository::Kind,\n    sec::{self as git_sec, trust::DefaultForLevel},\n    state as git_state, Repository, ThreadSafeRepository,\n};\n#[cfg(test)]\nuse std::collections::HashMap;\nuse std::collections::HashSet;\nuse std::env;\nuse std::ffi::{OsStr, OsString};\nuse std::fmt::Debug;\nuse std::fs;\nuse std::marker::PhantomData;\nuse std::num::ParseIntError;\nuse std::path::{Path, PathBuf};\nuse std::str::FromStr;\nuse std::string::String;\nuse std::sync::OnceLock;\nuse std::time::{Duration, Instant};\nuse terminal_size::terminal_size;\n\n/// Context contains data or common methods that may be used by multiple modules.\n/// The data contained within Context will be relevant to this particular rendering\n/// of the prompt.\npub struct Context<'a> {\n    /// The deserialized configuration map from the user's `starship.toml` file.\n    pub config: StarshipConfig,\n\n    /// The current working directory that starship is being called in.\n    pub current_dir: PathBuf,\n\n    /// A logical directory path which should represent the same directory as `current_dir`,\n    /// though may appear different.\n    /// E.g. when navigating to a `PSDrive` in `PowerShell`, or a path without symlinks resolved.\n    pub logical_dir: PathBuf,\n\n    /// A struct containing directory contents in a lookup-optimized format.\n    dir_contents: OnceLock<Result<DirContents, std::io::Error>>,\n\n    /// Properties to provide to modules.\n    pub properties: Properties,\n\n    /// Private field to store Git information for modules who need it\n    repo: OnceLock<Result<Repo, Box<gix::discover::Error>>>,\n\n    /// The shell the user is assumed to be running\n    pub shell: Shell,\n\n    /// Which prompt to print (main, right, ...)\n    pub target: Target,\n\n    /// Width of terminal, or zero if width cannot be detected.\n    pub width: usize,\n\n    /// A `HashMap` of environment variable mocks\n    pub env: Env<'a>,\n\n    /// A `HashMap` of command mocks\n    #[cfg(test)]\n    pub cmd: HashMap<&'a str, Option<CommandOutput>>,\n\n    /// a mock of the root directory\n    #[cfg(test)]\n    pub root_dir: tempfile::TempDir,\n\n    #[cfg(feature = \"battery\")]\n    pub battery_info_provider: &'a (dyn crate::modules::BatteryInfoProvider + Send + Sync),\n\n    /// Starship root config\n    pub root_config: StarshipRootConfig,\n\n    /// Avoid issues with unused lifetimes when features are disabled\n    _marker: PhantomData<&'a ()>,\n}\n\nimpl<'a> Context<'a> {\n    /// Identify the current working directory and create an instance of Context\n    /// for it. \"logical-path\" is used when a shell allows the \"current working directory\"\n    /// to be something other than a file system path (like powershell provider specific paths).\n    pub fn new(arguments: Properties, target: Target) -> Self {\n        let shell = Context::get_shell();\n\n        // Retrieve the \"current directory\".\n        // If the path argument is not set fall back to the OS current directory.\n        let path = arguments\n            .path\n            .clone()\n            .or_else(|| env::current_dir().ok())\n            .or_else(|| env::var(\"PWD\").map(PathBuf::from).ok())\n            .or_else(|| arguments.logical_path.clone())\n            .unwrap_or_default();\n\n        // Retrieve the \"logical directory\".\n        // If the path argument is not set fall back to the PWD env variable set by many shells\n        // or to the other path.\n        let logical_path = arguments\n            .logical_path\n            .clone()\n            .or_else(|| env::var(\"PWD\").map(PathBuf::from).ok())\n            .unwrap_or_else(|| path.clone());\n\n        Context::new_with_shell_and_path(\n            arguments,\n            shell,\n            target,\n            path,\n            logical_path,\n            Default::default(),\n        )\n    }\n\n    /// Create a new instance of Context for the provided directory\n    pub fn new_with_shell_and_path(\n        mut properties: Properties,\n        shell: Shell,\n        target: Target,\n        path: PathBuf,\n        logical_path: PathBuf,\n        env: Env<'a>,\n    ) -> Self {\n        let config = StarshipConfig::initialize(&get_config_path_os(&env));\n\n        // If the vector is zero-length, we should pretend that we didn't get a\n        // pipestatus at all (since this is the input `--pipestatus=\"\"`)\n        if properties\n            .pipestatus\n            .as_deref()\n            .map_or(false, |p| p.len() == 1 && p[0].is_empty())\n        {\n            properties.pipestatus = None;\n        }\n        log::trace!(\n            \"Received completed pipestatus of {:?}\",\n            properties.pipestatus\n        );\n\n        // If status-code is empty, set it to None\n        if matches!(properties.status_code.as_deref(), Some(\"\")) {\n            properties.status_code = None;\n        }\n\n        // Canonicalize the current path to resolve symlinks, etc.\n        // NOTE: On Windows this may convert the path to extended-path syntax.\n        let current_dir = Context::expand_tilde(path);\n        let current_dir = dunce::canonicalize(&current_dir).unwrap_or(current_dir);\n        let logical_dir = logical_path;\n\n        let root_config = config\n            .config\n            .as_ref()\n            .map_or_else(StarshipRootConfig::default, StarshipRootConfig::load);\n\n        let width = properties.terminal_width;\n\n        Context {\n            config,\n            properties,\n            current_dir,\n            logical_dir,\n            dir_contents: OnceLock::new(),\n            repo: OnceLock::new(),\n            shell,\n            target,\n            width,\n            env,\n            #[cfg(test)]\n            root_dir: tempfile::TempDir::new().unwrap(),\n            #[cfg(test)]\n            cmd: HashMap::new(),\n            #[cfg(feature = \"battery\")]\n            battery_info_provider: &crate::modules::BatteryInfoProviderImpl,\n            root_config,\n            _marker: PhantomData,\n        }\n    }\n\n    /// Sets the context config, overwriting the existing config\n    pub fn set_config(mut self, config: toml::Table) -> Self {\n        self.root_config = StarshipRootConfig::load(&config);\n        self.config = StarshipConfig {\n            config: Some(config),\n        };\n        self\n    }\n\n    // Tries to retrieve home directory from a table in testing mode or else retrieves it from the os\n    pub fn get_home(&self) -> Option<PathBuf> {\n        home_dir(&self.env)\n    }\n\n    // Retrieves a environment variable from the os or from a table if in testing mode\n    #[inline]\n    pub fn get_env<K: AsRef<str>>(&self, key: K) -> Option<String> {\n        self.env.get_env(key)\n    }\n\n    // Retrieves a environment variable from the os or from a table if in testing mode (os version)\n    #[inline]\n    pub fn get_env_os<K: AsRef<str>>(&self, key: K) -> Option<OsString> {\n        self.env.get_env_os(key)\n    }\n\n    /// Convert a `~` in a path to the home directory\n    pub fn expand_tilde(dir: PathBuf) -> PathBuf {\n        if dir.starts_with(\"~\") {\n            let without_home = dir.strip_prefix(\"~\").unwrap();\n            return utils::home_dir().unwrap().join(without_home);\n        }\n        dir\n    }\n\n    /// Create a new module\n    pub fn new_module(&self, name: &str) -> Module {\n        let config = self.config.get_module_config(name);\n        let desc = modules::description(name);\n\n        Module::new(name, desc, config)\n    }\n\n    /// Check if `disabled` option of the module is true in configuration file.\n    pub fn is_module_disabled_in_config(&self, name: &str) -> bool {\n        let config = self.config.get_module_config(name);\n\n        // If the segment has \"disabled\" set to \"true\", don't show it\n        let disabled = config.and_then(|table| table.as_table()?.get(\"disabled\")?.as_bool());\n\n        disabled == Some(true)\n    }\n\n    /// Returns true when a negated environment variable is defined in `env_vars` and is present\n    fn has_negated_env_var(&self, env_vars: &'a [&'a str]) -> bool {\n        env_vars\n            .iter()\n            .filter_map(|env_var| env_var.strip_prefix('!'))\n            .any(|env_var| self.get_env(env_var).is_some())\n    }\n\n    /// Returns true if `detect_env_vars` is empty,\n    /// or if at least one environment variable is set and no negated environment variable is set\n    pub fn detect_env_vars(&'a self, env_vars: &'a [&'a str]) -> bool {\n        if env_vars.is_empty() {\n            return true;\n        }\n\n        if self.has_negated_env_var(env_vars) {\n            return false;\n        }\n\n        // Returns true if at least one environment variable is set\n        let mut iter = env_vars\n            .iter()\n            .filter(|env_var| !env_var.starts_with('!'))\n            .peekable();\n\n        iter.peek().is_none() || iter.any(|env_var| self.get_env(env_var).is_some())\n    }\n\n    // returns a new ScanDir struct with reference to current dir_files of context\n    // see ScanDir for methods\n    pub fn try_begin_scan(&'a self) -> Option<ScanDir<'a>> {\n        Some(ScanDir {\n            dir_contents: self.dir_contents().ok()?,\n            files: &[],\n            folders: &[],\n            extensions: &[],\n        })\n    }\n\n    /// Begins an ancestor scan at the current directory, see [`ScanAncestors`] for available\n    /// methods.\n    pub fn begin_ancestor_scan(&'a self) -> ScanAncestors<'a> {\n        ScanAncestors {\n            path: &self.current_dir,\n            files: &[],\n            folders: &[],\n        }\n    }\n\n    /// Will lazily get repo root and branch when a module requests it.\n    pub fn get_repo(&self) -> Result<&Repo, &gix::discover::Error> {\n        self.repo\n            .get_or_init(|| -> Result<Repo, Box<gix::discover::Error>> {\n                // custom open options\n                let mut git_open_opts_map =\n                    git_sec::trust::Mapping::<gix::open::Options>::default();\n\n                // don't use the global git configs\n                let config = gix::open::permissions::Config {\n                    git_binary: false,\n                    system: false,\n                    git: false,\n                    user: false,\n                    env: true,\n                    includes: true,\n                };\n                // change options for config permissions without touching anything else\n                git_open_opts_map.reduced =\n                    git_open_opts_map\n                        .reduced\n                        .permissions(gix::open::Permissions {\n                            config,\n                            ..gix::open::Permissions::default_for_level(git_sec::Trust::Reduced)\n                        });\n                git_open_opts_map.full =\n                    git_open_opts_map.full.permissions(gix::open::Permissions {\n                        config,\n                        ..gix::open::Permissions::default_for_level(git_sec::Trust::Full)\n                    });\n\n                let shared_repo =\n                    match ThreadSafeRepository::discover_with_environment_overrides_opts(\n                        &self.current_dir,\n                        gix::discover::upwards::Options {\n                            match_ceiling_dir_or_error: false,\n                            ..Default::default()\n                        },\n                        git_open_opts_map,\n                    ) {\n                        Ok(repo) => repo,\n                        Err(e) => {\n                            log::debug!(\"Failed to find git repo: {e}\");\n                            return Err(Box::new(e));\n                        }\n                    };\n\n                let repository = shared_repo.to_thread_local();\n                log::trace!(\n                    \"Found git repo: {repository:?}, (trust: {:?})\",\n                    repository.git_dir_trust()\n                );\n\n                let branch = get_current_branch(&repository);\n                let remote =\n                    get_remote_repository_info(&repository, branch.as_ref().map(AsRef::as_ref));\n                let path = repository.path().to_path_buf();\n\n                let fs_monitor_value_is_true = repository\n                    .config_snapshot()\n                    .boolean(\"core.fsmonitor\")\n                    .unwrap_or(false);\n\n                Ok(Repo {\n                    repo: shared_repo,\n                    branch: branch.map(|b| b.shorten().to_string()),\n                    workdir: repository.work_dir().map(PathBuf::from),\n                    path,\n                    state: repository.state(),\n                    remote,\n                    fs_monitor_value_is_true,\n                    kind: repository.kind(),\n                })\n            })\n            .as_ref()\n            .map_err(std::convert::AsRef::as_ref)\n    }\n\n    pub fn dir_contents(&self) -> Result<&DirContents, &std::io::Error> {\n        self.dir_contents\n            .get_or_init(|| {\n                let timeout = self.root_config.scan_timeout;\n                DirContents::from_path_with_timeout(\n                    &self.current_dir,\n                    Duration::from_millis(timeout),\n                    self.root_config.follow_symlinks,\n                )\n            })\n            .as_ref()\n    }\n\n    fn get_shell() -> Shell {\n        let shell = env::var(\"STARSHIP_SHELL\").unwrap_or_default();\n        match shell.as_str() {\n            \"bash\" => Shell::Bash,\n            \"fish\" => Shell::Fish,\n            \"ion\" => Shell::Ion,\n            \"pwsh\" => Shell::Pwsh,\n            \"powershell\" => Shell::PowerShell,\n            \"zsh\" => Shell::Zsh,\n            \"elvish\" => Shell::Elvish,\n            \"tcsh\" => Shell::Tcsh,\n            \"nu\" => Shell::Nu,\n            \"xonsh\" => Shell::Xonsh,\n            \"cmd\" => Shell::Cmd,\n            _ => Shell::Unknown,\n        }\n    }\n\n    // TODO: This should be used directly by clap parse\n    pub fn get_cmd_duration(&self) -> Option<u128> {\n        self.properties\n            .cmd_duration\n            .as_deref()\n            .and_then(|cd| cd.parse::<u128>().ok())\n    }\n\n    /// Execute a command and return the output on stdout and stderr if successful\n    #[inline]\n    pub fn exec_cmd<T: AsRef<OsStr> + Debug, U: AsRef<OsStr> + Debug>(\n        &self,\n        cmd: T,\n        args: &[U],\n    ) -> Option<CommandOutput> {\n        log::trace!(\n            \"Executing command {:?} with args {:?} from context\",\n            cmd,\n            args\n        );\n        #[cfg(test)]\n        {\n            let command = crate::utils::display_command(&cmd, args);\n            if let Some(output) = self\n                .cmd\n                .get(command.as_str())\n                .cloned()\n                .or_else(|| crate::utils::mock_cmd(&cmd, args))\n            {\n                return output;\n            }\n        }\n        let mut cmd = create_command(cmd).ok()?;\n        cmd.args(args).current_dir(&self.current_dir);\n        exec_timeout(\n            &mut cmd,\n            Duration::from_millis(self.root_config.command_timeout),\n        )\n    }\n\n    /// Attempt to execute several commands with `exec_cmd`, return the results of the first that works\n    pub fn exec_cmds_return_first(&self, commands: Vec<Vec<&str>>) -> Option<CommandOutput> {\n        commands\n            .iter()\n            .find_map(|attempt| self.exec_cmd(attempt[0], &attempt[1..]))\n    }\n\n    /// Returns the string contents of a file from the current working directory\n    pub fn read_file_from_pwd(&self, file_name: &str) -> Option<String> {\n        if !self.try_begin_scan()?.set_files(&[file_name]).is_match() {\n            log::debug!(\n                \"Not attempting to read {file_name} because, it was not found during scan.\"\n            );\n            return None;\n        }\n\n        read_file(self.current_dir.join(file_name)).ok()\n    }\n\n    pub fn get_config_path_os(&self) -> Option<OsString> {\n        get_config_path_os(&self.env)\n    }\n}\n\nimpl Default for Context<'_> {\n    fn default() -> Self {\n        Context::new(Default::default(), Target::Main)\n    }\n}\n\nfn home_dir(env: &Env) -> Option<PathBuf> {\n    if cfg!(test) {\n        if let Some(home) = env.get_env(\"HOME\") {\n            return Some(PathBuf::from(home));\n        }\n    }\n    utils::home_dir()\n}\n\nfn get_config_path_os(env: &Env) -> Option<OsString> {\n    if let Some(config_path) = env.get_env_os(\"STARSHIP_CONFIG\") {\n        return Some(config_path);\n    }\n    Some(home_dir(env)?.join(\".config\").join(\"starship.toml\").into())\n}\n\n#[derive(Debug)]\npub struct DirContents {\n    // HashSet of all files, no folders, relative to the base directory given at construction.\n    files: HashSet<PathBuf>,\n    // HashSet of all file names, e.g. the last section without any folders, as strings.\n    file_names: HashSet<String>,\n    // HashSet of all folders, relative to the base directory given at construction.\n    folders: HashSet<PathBuf>,\n    // HashSet of all extensions found, without dots, e.g. \"js\" instead of \".js\".\n    extensions: HashSet<String>,\n}\n\nimpl DirContents {\n    #[cfg(test)]\n    fn from_path(base: &Path, follow_symlinks: bool) -> Result<Self, std::io::Error> {\n        Self::from_path_with_timeout(base, Duration::from_secs(30), follow_symlinks)\n    }\n\n    fn from_path_with_timeout(\n        base: &Path,\n        timeout: Duration,\n        follow_symlinks: bool,\n    ) -> Result<Self, std::io::Error> {\n        let start = Instant::now();\n\n        let mut folders: HashSet<PathBuf> = HashSet::new();\n        let mut files: HashSet<PathBuf> = HashSet::new();\n        let mut file_names: HashSet<String> = HashSet::new();\n        let mut extensions: HashSet<String> = HashSet::new();\n\n        fs::read_dir(base)?\n            .enumerate()\n            .take_while(|(n, _)| {\n                cfg!(test) // ignore timeout during tests\n                || n & 0xFF != 0 // only check timeout once every 2^8 entries\n                || start.elapsed() < timeout\n            })\n            .filter_map(|(_, entry)| entry.ok())\n            .for_each(|entry| {\n                let path = PathBuf::from(entry.path().strip_prefix(base).unwrap());\n\n                let is_dir = match follow_symlinks {\n                    true => entry.path().is_dir(),\n                    false => fs::symlink_metadata(entry.path())\n                        .map(|m| m.is_dir())\n                        .unwrap_or(false),\n                };\n\n                if is_dir {\n                    folders.insert(path);\n                } else {\n                    if !path.to_string_lossy().starts_with('.') {\n                        // Extract the file extensions (yes, that's plural) from a filename.\n                        // Why plural? Consider the case of foo.tar.gz. It's a compressed\n                        // tarball (tar.gz), and it's a gzipped file (gz). We should be able\n                        // to match both.\n\n                        // find the minimal extension on a file. ie, the gz in foo.tar.gz\n                        // NB the .to_string_lossy().to_string() here looks weird but is\n                        // required to convert it from a Cow.\n                        path.extension()\n                            .map(|ext| extensions.insert(ext.to_string_lossy().to_string()));\n\n                        // find the full extension on a file. ie, the tar.gz in foo.tar.gz\n                        path.file_name().map(|file_name| {\n                            file_name\n                                .to_string_lossy()\n                                .split_once('.')\n                                .map(|(_, after)| extensions.insert(after.to_string()))\n                        });\n                    }\n                    if let Some(file_name) = path.file_name() {\n                        // this .to_string_lossy().to_string() is also required\n                        file_names.insert(file_name.to_string_lossy().to_string());\n                    }\n                    files.insert(path);\n                }\n            });\n\n        log::trace!(\n            \"Building HashSets of directory files, folders and extensions took {:?}\",\n            start.elapsed()\n        );\n\n        Ok(Self {\n            files,\n            file_names,\n            folders,\n            extensions,\n        })\n    }\n\n    pub fn files(&self) -> impl Iterator<Item = &PathBuf> {\n        self.files.iter()\n    }\n\n    pub fn has_file(&self, path: &str) -> bool {\n        self.files.contains(Path::new(path))\n    }\n\n    pub fn has_file_name(&self, name: &str) -> bool {\n        self.file_names.contains(name)\n    }\n\n    pub fn has_folder(&self, path: &str) -> bool {\n        self.folders.contains(Path::new(path))\n    }\n\n    pub fn has_extension(&self, ext: &str) -> bool {\n        self.extensions.contains(ext)\n    }\n\n    pub fn has_any_positive_file_name(&self, names: &[&str]) -> bool {\n        names\n            .iter()\n            .any(|name| !name.starts_with('!') && self.has_file_name(name))\n    }\n\n    pub fn has_any_positive_folder(&self, paths: &[&str]) -> bool {\n        paths\n            .iter()\n            .any(|path| !path.starts_with('!') && self.has_folder(path))\n    }\n\n    pub fn has_any_positive_extension(&self, exts: &[&str]) -> bool {\n        exts.iter()\n            .any(|ext| !ext.starts_with('!') && self.has_extension(ext))\n    }\n\n    pub fn has_no_negative_file_name(&self, names: &[&str]) -> bool {\n        !names\n            .iter()\n            .any(|name| name.starts_with('!') && self.has_file_name(&name[1..]))\n    }\n\n    pub fn has_no_negative_folder(&self, paths: &[&str]) -> bool {\n        !paths\n            .iter()\n            .any(|path| path.starts_with('!') && self.has_folder(&path[1..]))\n    }\n\n    pub fn has_no_negative_extension(&self, exts: &[&str]) -> bool {\n        !exts\n            .iter()\n            .any(|ext| ext.starts_with('!') && self.has_extension(&ext[1..]))\n    }\n}\n\npub struct Repo {\n    pub repo: ThreadSafeRepository,\n\n    /// If `current_dir` is a git repository or is contained within one,\n    /// this is the short name of the current branch name of that repo,\n    /// i.e. `main`.\n    pub branch: Option<String>,\n\n    /// If `current_dir` is a git repository or is contained within one,\n    /// this is the path to the root of that repo.\n    pub workdir: Option<PathBuf>,\n\n    /// The path of the repository's `.git` directory.\n    pub path: PathBuf,\n\n    /// State\n    pub state: Option<git_state::InProgress>,\n\n    /// Remote repository\n    pub remote: Option<Remote>,\n\n    /// Contains `true` if the value of `core.fsmonitor` is set to `true`.\n    /// If not `true`, `fsmonitor` is explicitly disabled in git commands.\n    fs_monitor_value_is_true: bool,\n\n    // Kind of repository, work tree or bare\n    pub kind: Kind,\n}\n\nimpl Repo {\n    /// Opens the associated git repository.\n    pub fn open(&self) -> Repository {\n        self.repo.to_thread_local()\n    }\n\n    /// Wrapper to execute external git commands.\n    /// Handles adding the appropriate `--git-dir` and `--work-tree` flags to the command.\n    /// Also handles additional features required for security, such as disabling `fsmonitor`.\n    /// At this time, mocking is not supported.\n    pub fn exec_git<T: AsRef<OsStr> + Debug>(\n        &self,\n        context: &Context,\n        git_args: &[T],\n    ) -> Option<CommandOutput> {\n        let mut command = create_command(\"git\").ok()?;\n\n        // A value of `true` should not execute external commands.\n        let fsm_config_value = if self.fs_monitor_value_is_true {\n            \"core.fsmonitor=true\"\n        } else {\n            \"core.fsmonitor=\"\n        };\n\n        command.env(\"GIT_OPTIONAL_LOCKS\", \"0\").args([\n            OsStr::new(\"-C\"),\n            context.current_dir.as_os_str(),\n            OsStr::new(\"--git-dir\"),\n            self.path.as_os_str(),\n            OsStr::new(\"-c\"),\n            OsStr::new(fsm_config_value),\n        ]);\n\n        // Bare repositories might not have a workdir, so we need to check for that.\n        if let Some(wt) = self.workdir.as_ref() {\n            command.args([OsStr::new(\"--work-tree\"), wt.as_os_str()]);\n        }\n\n        command.args(git_args);\n        log::trace!(\"Executing git command: {:?}\", command);\n\n        exec_timeout(\n            &mut command,\n            Duration::from_millis(context.root_config.command_timeout),\n        )\n    }\n}\n\n/// Remote repository\npub struct Remote {\n    pub branch: Option<String>,\n    pub name: Option<String>,\n}\n\n// A struct of Criteria which will be used to verify current PathBuf is\n// of X language, criteria can be set via the builder pattern\npub struct ScanDir<'a> {\n    dir_contents: &'a DirContents,\n    files: &'a [&'a str],\n    folders: &'a [&'a str],\n    extensions: &'a [&'a str],\n}\n\nimpl<'a> ScanDir<'a> {\n    #[must_use]\n    pub const fn set_files(mut self, files: &'a [&'a str]) -> Self {\n        self.files = files;\n        self\n    }\n\n    #[must_use]\n    pub const fn set_extensions(mut self, extensions: &'a [&'a str]) -> Self {\n        self.extensions = extensions;\n        self\n    }\n\n    #[must_use]\n    pub const fn set_folders(mut self, folders: &'a [&'a str]) -> Self {\n        self.folders = folders;\n        self\n    }\n\n    /// based on the current `PathBuf` check to see\n    /// if any of this criteria match or exist and returning a boolean\n    pub fn is_match(&self) -> bool {\n        // if there exists a file with a file/folder/ext we've said we don't want,\n        // fail the match straight away\n        self.dir_contents.has_no_negative_extension(self.extensions)\n            && self.dir_contents.has_no_negative_file_name(self.files)\n            && self.dir_contents.has_no_negative_folder(self.folders)\n            && (self\n                .dir_contents\n                .has_any_positive_extension(self.extensions)\n                || self.dir_contents.has_any_positive_file_name(self.files)\n                || self.dir_contents.has_any_positive_folder(self.folders))\n    }\n}\n\n/// Scans the ancestors of a given path until a directory containing one of the given files or\n/// folders is found.\npub struct ScanAncestors<'a> {\n    path: &'a Path,\n    files: &'a [&'a str],\n    folders: &'a [&'a str],\n}\n\nimpl<'a> ScanAncestors<'a> {\n    #[must_use]\n    pub const fn set_files(mut self, files: &'a [&'a str]) -> Self {\n        self.files = files;\n        self\n    }\n\n    #[must_use]\n    pub const fn set_folders(mut self, folders: &'a [&'a str]) -> Self {\n        self.folders = folders;\n        self\n    }\n\n    /// Scans upwards starting from the initial path until a directory containing one of the given\n    /// files or folders is found.\n    ///\n    /// The scan does not cross device boundaries.\n    pub fn scan(&self) -> Option<&'a Path> {\n        let initial_device_id = self.path.device_id();\n        for dir in self.path.ancestors() {\n            if initial_device_id != dir.device_id() {\n                break;\n            }\n\n            if self.files.iter().any(|name| dir.join(name).is_file())\n                || self.folders.iter().any(|name| dir.join(name).is_dir())\n            {\n                return Some(dir);\n            }\n        }\n        None\n    }\n}\n\nfn get_current_branch(repository: &Repository) -> Option<gix::refs::FullName> {\n    repository.head_name().ok()?\n}\n\nfn get_remote_repository_info(\n    repository: &Repository,\n    branch_name: Option<&gix::refs::FullNameRef>,\n) -> Option<Remote> {\n    let branch_name = branch_name?;\n    let branch = repository\n        .branch_remote_ref_name(branch_name, gix::remote::Direction::Fetch)\n        .and_then(std::result::Result::ok)\n        .map(|r| r.shorten().to_string());\n    let name = repository\n        .branch_remote_name(branch_name.shorten(), gix::remote::Direction::Fetch)\n        .map(|n| n.as_bstr().to_string());\n\n    Some(Remote { branch, name })\n}\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub enum Shell {\n    Bash,\n    Fish,\n    Ion,\n    Pwsh,\n    PowerShell,\n    Zsh,\n    Elvish,\n    Tcsh,\n    Nu,\n    Xonsh,\n    Cmd,\n    Unknown,\n}\n\n/// Which kind of prompt target to print (main prompt, rprompt, ...)\n#[derive(Debug, Clone, PartialEq, Eq)]\npub enum Target {\n    Main,\n    Right,\n    Continuation,\n    Profile(String),\n}\n\n/// Properties as passed on from the shell as arguments\n#[derive(Parser, Debug)]\npub struct Properties {\n    /// The status code of the previously run command as an unsigned or signed 32bit integer\n    #[clap(short = 's', long = \"status\")]\n    pub status_code: Option<String>,\n    /// Bash, Fish and Zsh support returning codes for each process in a pipeline.\n    #[clap(long, value_delimiter = ' ')]\n    pub pipestatus: Option<Vec<String>>,\n    /// The width of the current interactive terminal.\n    #[clap(short = 'w', long, default_value_t=default_width(), value_parser=parse_width)]\n    terminal_width: usize,\n    /// The path that the prompt should render for.\n    #[clap(short, long)]\n    path: Option<PathBuf>,\n    /// The logical path that the prompt should render for.\n    /// This path should be a virtual/logical representation of the PATH argument.\n    #[clap(short = 'P', long)]\n    logical_path: Option<PathBuf>,\n    /// The execution duration of the last command, in milliseconds\n    #[clap(short = 'd', long)]\n    pub cmd_duration: Option<String>,\n    /// The keymap of fish/zsh/cmd\n    #[clap(short = 'k', long, default_value = \"viins\")]\n    pub keymap: String,\n    /// The number of currently running jobs\n    #[clap(short, long, default_value_t, value_parser=parse_jobs)]\n    pub jobs: i64,\n}\n\nimpl Default for Properties {\n    fn default() -> Self {\n        Self {\n            status_code: None,\n            pipestatus: None,\n            terminal_width: default_width(),\n            path: None,\n            logical_path: None,\n            cmd_duration: None,\n            keymap: \"viins\".to_string(),\n            jobs: 0,\n        }\n    }\n}\n\n/// Parse String, but treat empty strings as `None`\nfn parse_trim<F: FromStr>(value: &str) -> Option<Result<F, F::Err>> {\n    let value = value.trim();\n    if value.is_empty() {\n        return None;\n    }\n    Some(F::from_str(value))\n}\n\nfn parse_jobs(jobs: &str) -> Result<i64, ParseIntError> {\n    parse_trim(jobs).unwrap_or(Ok(0))\n}\n\nfn default_width() -> usize {\n    terminal_size().map_or(80, |(w, _)| w.0 as usize)\n}\n\nfn parse_width(width: &str) -> Result<usize, ParseIntError> {\n    parse_trim(width).unwrap_or_else(|| Ok(default_width()))\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::test::default_context;\n    use std::io;\n\n    fn testdir(paths: &[&str]) -> Result<tempfile::TempDir, std::io::Error> {\n        let dir = tempfile::tempdir()?;\n        for path in paths {\n            let p = dir.path().join(Path::new(path));\n            if let Some(parent) = p.parent() {\n                fs::create_dir_all(parent)?;\n            }\n            fs::File::create(p)?.sync_all()?;\n        }\n        Ok(dir)\n    }\n\n    #[test]\n    fn test_scan_dir_no_symlinks() -> Result<(), Box<dyn std::error::Error>> {\n        #[cfg(not(target_os = \"windows\"))]\n        use std::os::unix::fs::symlink;\n        #[cfg(target_os = \"windows\")]\n        use std::os::windows::fs::symlink_dir as symlink;\n\n        let d = testdir(&[\"file\"])?;\n        fs::create_dir(d.path().join(\"folder\"))?;\n\n        symlink(d.path().join(\"folder\"), d.path().join(\"link_to_folder\"))?;\n        symlink(d.path().join(\"file\"), d.path().join(\"link_to_file\"))?;\n\n        let dc_following_symlinks = DirContents::from_path(d.path(), true)?;\n\n        assert!(ScanDir {\n            dir_contents: &dc_following_symlinks,\n            files: &[\"link_to_file\"],\n            extensions: &[],\n            folders: &[],\n        }\n        .is_match());\n\n        assert!(ScanDir {\n            dir_contents: &dc_following_symlinks,\n            files: &[],\n            extensions: &[],\n            folders: &[\"link_to_folder\"],\n        }\n        .is_match());\n\n        let dc_not_following_symlinks = DirContents::from_path(d.path(), false)?;\n\n        assert!(ScanDir {\n            dir_contents: &dc_not_following_symlinks,\n            files: &[\"link_to_file\"],\n            extensions: &[],\n            folders: &[],\n        }\n        .is_match());\n\n        assert!(!ScanDir {\n            dir_contents: &dc_not_following_symlinks,\n            files: &[],\n            extensions: &[],\n            folders: &[\"link_to_folder\"],\n        }\n        .is_match());\n\n        Ok(())\n    }\n\n    #[test]\n    fn test_scan_dir() -> Result<(), Box<dyn std::error::Error>> {\n        let empty = testdir(&[])?;\n        let follow_symlinks = true;\n        let empty_dc = DirContents::from_path(empty.path(), follow_symlinks)?;\n\n        assert!(!ScanDir {\n            dir_contents: &empty_dc,\n            files: &[\"package.json\"],\n            extensions: &[\"js\"],\n            folders: &[\"node_modules\"],\n        }\n        .is_match());\n        empty.close()?;\n\n        let rust = testdir(&[\"README.md\", \"Cargo.toml\", \"src/main.rs\"])?;\n        let rust_dc = DirContents::from_path(rust.path(), follow_symlinks)?;\n        assert!(!ScanDir {\n            dir_contents: &rust_dc,\n            files: &[\"package.json\"],\n            extensions: &[\"js\"],\n            folders: &[\"node_modules\"],\n        }\n        .is_match());\n        rust.close()?;\n\n        let java = testdir(&[\"README.md\", \"src/com/test/Main.java\", \"pom.xml\"])?;\n        let java_dc = DirContents::from_path(java.path(), follow_symlinks)?;\n        assert!(!ScanDir {\n            dir_contents: &java_dc,\n            files: &[\"package.json\"],\n            extensions: &[\"js\"],\n            folders: &[\"node_modules\"],\n        }\n        .is_match());\n        java.close()?;\n\n        let node = testdir(&[\"README.md\", \"node_modules/lodash/main.js\", \"package.json\"])?;\n        let node_dc = DirContents::from_path(node.path(), follow_symlinks)?;\n        assert!(ScanDir {\n            dir_contents: &node_dc,\n            files: &[\"package.json\"],\n            extensions: &[\"js\"],\n            folders: &[\"node_modules\"],\n        }\n        .is_match());\n        node.close()?;\n\n        let tarballs = testdir(&[\"foo.tgz\", \"foo.tar.gz\"])?;\n        let tarballs_dc = DirContents::from_path(tarballs.path(), follow_symlinks)?;\n        assert!(ScanDir {\n            dir_contents: &tarballs_dc,\n            files: &[],\n            extensions: &[\"tar.gz\"],\n            folders: &[],\n        }\n        .is_match());\n        tarballs.close()?;\n\n        let dont_match_ext = testdir(&[\"foo.js\", \"foo.ts\"])?;\n        let dont_match_ext_dc = DirContents::from_path(dont_match_ext.path(), follow_symlinks)?;\n        assert!(!ScanDir {\n            dir_contents: &dont_match_ext_dc,\n            files: &[],\n            extensions: &[\"js\", \"!notfound\", \"!ts\"],\n            folders: &[],\n        }\n        .is_match());\n        dont_match_ext.close()?;\n\n        let dont_match_file = testdir(&[\"goodfile\", \"evilfile\"])?;\n        let dont_match_file_dc = DirContents::from_path(dont_match_file.path(), follow_symlinks)?;\n        assert!(!ScanDir {\n            dir_contents: &dont_match_file_dc,\n            files: &[\"goodfile\", \"!notfound\", \"!evilfile\"],\n            extensions: &[],\n            folders: &[],\n        }\n        .is_match());\n        dont_match_file.close()?;\n\n        let dont_match_folder = testdir(&[\"gooddir/somefile\", \"evildir/somefile\"])?;\n        let dont_match_folder_dc =\n            DirContents::from_path(dont_match_folder.path(), follow_symlinks)?;\n        assert!(!ScanDir {\n            dir_contents: &dont_match_folder_dc,\n            files: &[],\n            extensions: &[],\n            folders: &[\"gooddir\", \"!notfound\", \"!evildir\"],\n        }\n        .is_match());\n        dont_match_folder.close()?;\n\n        Ok(())\n    }\n\n    #[test]\n    fn context_constructor_should_canonicalize_current_dir() -> io::Result<()> {\n        #[cfg(not(windows))]\n        use std::os::unix::fs::symlink as symlink_dir;\n        #[cfg(windows)]\n        use std::os::windows::fs::symlink_dir;\n\n        let tmp_dir = tempfile::TempDir::new()?;\n        let path = tmp_dir.path().join(\"a/xxx/yyy\");\n        fs::create_dir_all(path)?;\n\n        // Set up a mock symlink\n        let path_actual = tmp_dir.path().join(\"a/xxx\");\n        let path_symlink = tmp_dir.path().join(\"a/symlink\");\n        symlink_dir(&path_actual, &path_symlink).expect(\"create symlink\");\n\n        // Mock navigation into the symlink path\n        let test_path = path_symlink.join(\"yyy\");\n        let context = Context::new_with_shell_and_path(\n            Default::default(),\n            Shell::Unknown,\n            Target::Main,\n            test_path.clone(),\n            test_path.clone(),\n            Default::default(),\n        );\n\n        assert_ne!(context.current_dir, context.logical_dir);\n\n        let expected_current_dir =\n            dunce::canonicalize(path_actual.join(\"yyy\")).expect(\"canonicalize\");\n        assert_eq!(expected_current_dir, context.current_dir);\n\n        let expected_logical_dir = test_path;\n        assert_eq!(expected_logical_dir, context.logical_dir);\n\n        tmp_dir.close()\n    }\n\n    #[test]\n    fn context_constructor_should_fail_gracefully_when_canonicalization_fails() {\n        // Mock navigation to a directory which does not exist on disk\n        let test_path = Path::new(\"/path_which_does_not_exist\").to_path_buf();\n        let context = Context::new_with_shell_and_path(\n            Default::default(),\n            Shell::Unknown,\n            Target::Main,\n            test_path.clone(),\n            test_path.clone(),\n            Default::default(),\n        );\n\n        let expected_current_dir = &test_path;\n        assert_eq!(expected_current_dir, &context.current_dir);\n\n        let expected_logical_dir = &test_path;\n        assert_eq!(expected_logical_dir, &context.logical_dir);\n    }\n\n    #[test]\n    fn context_constructor_should_fall_back_to_tilde_replacement_when_canonicalization_fails() {\n        use utils::home_dir;\n\n        // Mock navigation to a directory which does not exist on disk\n        let test_path = Path::new(\"~/path_which_does_not_exist\").to_path_buf();\n        let context = Context::new_with_shell_and_path(\n            Default::default(),\n            Shell::Unknown,\n            Target::Main,\n            test_path.clone(),\n            test_path.clone(),\n            Default::default(),\n        );\n\n        let expected_current_dir = home_dir()\n            .expect(\"home_dir\")\n            .join(\"path_which_does_not_exist\");\n        assert_eq!(expected_current_dir, context.current_dir);\n\n        let expected_logical_dir = test_path;\n        assert_eq!(expected_logical_dir, context.logical_dir);\n    }\n\n    #[test]\n    fn set_config_method_overwrites_constructor() {\n        let context = default_context();\n        let mod_context = default_context().set_config(toml::toml! {\n            add_newline = true\n        });\n\n        assert_ne!(context.config.config, mod_context.config.config);\n    }\n\n    #[cfg(windows)]\n    #[test]\n    fn strip_extended_path_prefix() {\n        let test_path = Path::new(r\"\\\\?\\C:\\\").to_path_buf();\n        let context = Context::new_with_shell_and_path(\n            Properties::default(),\n            Shell::Unknown,\n            Target::Main,\n            test_path.clone(),\n            test_path,\n            Default::default(),\n        );\n\n        let expected_path = Path::new(r\"C:\\\");\n\n        assert_eq!(&context.current_dir, expected_path);\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "56376d3d651b48ac98357e0c3c48c5b1f5702983",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/starship/src/formatter/version.rs",
    "func": "use super::string_formatter::StringFormatterError;\nuse super::StringFormatter;\nuse crate::segment;\nuse std::ops::Deref;\nuse std::sync::LazyLock;\nuse versions::Versioning;\n\npub struct VersionFormatter<'a> {\n    formatter: StringFormatter<'a>,\n}\n\nimpl<'a> VersionFormatter<'a> {\n    /// Creates an instance of a `VersionFormatter` from a format string\n    ///\n    /// Like the `StringFormatter`, this will throw an error when the string isn't\n    /// parseable.\n    pub fn new(format: &'a str) -> Result<Self, StringFormatterError> {\n        let formatter = StringFormatter::new(format)?;\n\n        Ok(Self { formatter })\n    }\n\n    /// Format version string using provided format\n    pub fn format_version(\n        version: &'a str,\n        format: &'a str,\n    ) -> Result<String, StringFormatterError> {\n        Self::new(format).and_then(|formatter| formatter.format(version))\n    }\n\n    /// Formats a version structure into a readable string\n    pub fn format(self, version: &'a str) -> Result<String, StringFormatterError> {\n        let parsed = LazyLock::new(|| Versioning::new(version));\n        let formatted = self\n            .formatter\n            .map(|variable| match variable {\n                \"raw\" => Some(Ok(version.to_string())),\n                \"major\" => match parsed.deref().as_ref() {\n                    Some(Versioning::Ideal(v)) => Some(Ok(v.major.to_string())),\n                    Some(Versioning::General(v)) => Some(Ok(v.nth_lenient(0)?.to_string())),\n                    _ => None,\n                },\n                \"minor\" => match parsed.deref().as_ref() {\n                    Some(Versioning::Ideal(v)) => Some(Ok(v.minor.to_string())),\n                    Some(Versioning::General(v)) => Some(Ok(v.nth_lenient(1)?.to_string())),\n                    _ => None,\n                },\n                \"patch\" => match parsed.deref().as_ref() {\n                    Some(Versioning::Ideal(v)) => Some(Ok(v.patch.to_string())),\n                    Some(Versioning::General(v)) => Some(Ok(v.nth_lenient(2)?.to_string())),\n                    _ => None,\n                },\n                _ => None,\n            })\n            .parse(None, None);\n\n        formatted.map(|segments| {\n            segments\n                .iter()\n                .map(segment::Segment::value)\n                .collect::<String>()\n        })\n    }\n\n    pub fn format_module_version(\n        module_name: &str,\n        version: &str,\n        version_format: &str,\n    ) -> Option<String> {\n        match VersionFormatter::format_version(version, version_format) {\n            Ok(formatted) => Some(formatted),\n            Err(error) => {\n                log::warn!(\"Error formatting `{}` version:\\n{}\", module_name, error);\n                Some(format!(\"v{version}\"))\n            }\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    const VERSION_FORMAT: &str = \"major:${major} minor:${minor} patch:${patch} raw:${raw}\";\n\n    #[test]\n    fn test_semver_full() {\n        assert_eq!(\n            VersionFormatter::format_version(\"1.2.3\", VERSION_FORMAT),\n            Ok(\"major:1 minor:2 patch:3 raw:1.2.3\".to_string())\n        );\n    }\n\n    #[test]\n    fn test_semver_partial() {\n        assert_eq!(\n            VersionFormatter::format_version(\"1.2\", VERSION_FORMAT),\n            Ok(\"major:1 minor:2 patch: raw:1.2\".to_string())\n        );\n    }\n\n    #[test]\n    fn test_general() {\n        assert_eq!(\n            VersionFormatter::format_version(\"1.2-a.3\", VERSION_FORMAT),\n            Ok(\"major:1 minor:2 patch: raw:1.2-a.3\".to_string())\n        );\n    }\n\n    #[test]\n    fn test_dummy() {\n        assert_eq!(\n            VersionFormatter::format_version(\"dummy version\", VERSION_FORMAT),\n            Ok(\"major: minor: patch: raw:dummy version\".to_string())\n        );\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "030578273898ff658027b5f158b3271ff5800dc4",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/starship/src/modules/cobol.rs",
    "func": "use super::{Context, Module, ModuleConfig};\n\nuse crate::configs::cobol::CobolConfig;\nuse crate::formatter::StringFormatter;\nuse crate::formatter::VersionFormatter;\n\n/// Creates a module with the current COBOL version\npub fn module<'a>(context: &'a Context) -> Option<Module<'a>> {\n    let mut module = context.new_module(\"cobol\");\n    let config = CobolConfig::try_load(module.config);\n    let is_cobol_project = context\n        .try_begin_scan()?\n        .set_files(&config.detect_files)\n        .set_extensions(&config.detect_extensions)\n        .set_folders(&config.detect_folders)\n        .is_match();\n\n    if !is_cobol_project {\n        return None;\n    }\n\n    let parsed = StringFormatter::new(config.format).and_then(|formatter| {\n        formatter\n            .map_meta(|var, _| match var {\n                \"symbol\" => Some(config.symbol),\n                _ => None,\n            })\n            .map_style(|variable| match variable {\n                \"style\" => Some(Ok(config.style)),\n                _ => None,\n            })\n            .map(|variable| match variable {\n                \"version\" => {\n                    let cobol_version =\n                        get_cobol_version(&context.exec_cmd(\"cobc\", &[\"-version\"])?.stdout)?;\n\n                    VersionFormatter::format_module_version(\n                        module.get_name(),\n                        &cobol_version,\n                        config.version_format,\n                    )\n                    .map(Ok)\n                }\n                _ => None,\n            })\n            .parse(None, Some(context))\n    });\n\n    module.set_segments(match parsed {\n        Ok(segments) => segments,\n        Err(error) => {\n            log::warn!(\"Error in module `cobol`:\\n{}\", error);\n            return None;\n        }\n    });\n\n    Some(module)\n}\n\nfn get_cobol_version(cobol_stdout: &str) -> Option<String> {\n    // cobol output looks like this:\n    // cobc (GnuCOBOL) 3.1.2.0\n    // ...\n\n    Some(\n        cobol_stdout\n            // split into [\"cobc\", \"(GNUCOBOL)\", \"3.1.2.0\"...]\n            .split_whitespace()\n            // return \"3.1.2.0\"\n            .nth(2)?\n            .to_string(),\n    )\n}\n\n#[cfg(test)]\nmod tests {\n    use crate::test::ModuleRenderer;\n    use nu_ansi_term::Color;\n    use std::fs::File;\n    use std::io;\n\n    #[test]\n    fn folder_without_cobol_files() -> io::Result<()> {\n        let dir = tempfile::tempdir()?;\n\n        let actual = ModuleRenderer::new(\"cobol\").path(dir.path()).collect();\n\n        let expected = None;\n\n        assert_eq!(expected, actual);\n        dir.close()\n    }\n\n    #[test]\n    fn folder_with_lowercase_cob_files() -> io::Result<()> {\n        let dir = tempfile::tempdir()?;\n        File::create(dir.path().join(\"main.cob\"))?.sync_all()?;\n\n        let actual = ModuleRenderer::new(\"cobol\").path(dir.path()).collect();\n\n        let expected = Some(format!(\"via {}\", Color::Blue.bold().paint(\"\u2699\ufe0f v3.1.2.0 \")));\n        assert_eq!(expected, actual);\n        dir.close()\n    }\n\n    #[test]\n    fn folder_with_lowercase_cbl_files() -> io::Result<()> {\n        let dir = tempfile::tempdir()?;\n        File::create(dir.path().join(\"main.cbl\"))?.sync_all()?;\n\n        let actual = ModuleRenderer::new(\"cobol\").path(dir.path()).collect();\n\n        let expected = Some(format!(\"via {}\", Color::Blue.bold().paint(\"\u2699\ufe0f v3.1.2.0 \")));\n        assert_eq!(expected, actual);\n        dir.close()\n    }\n\n    #[test]\n    fn folder_with_capital_cob_files() -> io::Result<()> {\n        let dir = tempfile::tempdir()?;\n        File::create(dir.path().join(\"MAIN.COB\"))?.sync_all()?;\n\n        let actual = ModuleRenderer::new(\"cobol\").path(dir.path()).collect();\n\n        let expected = Some(format!(\"via {}\", Color::Blue.bold().paint(\"\u2699\ufe0f v3.1.2.0 \")));\n        assert_eq!(expected, actual);\n        dir.close()\n    }\n\n    #[test]\n    fn folder_with_capital_cbl_files() -> io::Result<()> {\n        let dir = tempfile::tempdir()?;\n        File::create(dir.path().join(\"MAIN.CBL\"))?.sync_all()?;\n\n        let actual = ModuleRenderer::new(\"cobol\").path(dir.path()).collect();\n\n        let expected = Some(format!(\"via {}\", Color::Blue.bold().paint(\"\u2699\ufe0f v3.1.2.0 \")));\n        assert_eq!(expected, actual);\n        dir.close()\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "2de956c353c812cd62be2194a2ab7b1e4fe2d203",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/starship/src/modules/kubernetes.rs",
    "func": "use serde_json::Value as JsonValue;\nuse yaml_rust2::{Yaml, YamlLoader};\n\nuse std::borrow::Cow;\nuse std::env;\n\nuse super::{Context, Module, ModuleConfig};\n\nuse crate::configs::kubernetes::KubernetesConfig;\nuse crate::formatter::StringFormatter;\nuse crate::utils;\n\n#[derive(Default)]\nstruct KubeCtxComponents {\n    user: Option<String>,\n    namespace: Option<String>,\n    cluster: Option<String>,\n}\n\nfn get_current_kube_context_name<T: DataValue>(document: &T) -> Option<&str> {\n    document\n        .get(\"current-context\")\n        .and_then(DataValue::as_str)\n        .filter(|s| !s.is_empty())\n}\n\nfn get_kube_ctx_components<T: DataValue>(\n    document: &T,\n    current_ctx_name: &str,\n) -> Option<KubeCtxComponents> {\n    document\n        .get(\"contexts\")?\n        .as_array()?\n        .iter()\n        .find(|ctx| ctx.get(\"name\").and_then(DataValue::as_str) == Some(current_ctx_name))\n        .map(|ctx| KubeCtxComponents {\n            user: ctx\n                .get(\"context\")\n                .and_then(|v| v.get(\"user\"))\n                .and_then(DataValue::as_str)\n                .map(String::from),\n            namespace: ctx\n                .get(\"context\")\n                .and_then(|v| v.get(\"namespace\"))\n                .and_then(DataValue::as_str)\n                .map(String::from),\n            cluster: ctx\n                .get(\"context\")\n                .and_then(|v| v.get(\"cluster\"))\n                .and_then(DataValue::as_str)\n                .map(String::from),\n        })\n}\n\nfn get_aliased_name<'a>(\n    pattern: Option<&'a str>,\n    current_value: Option<&str>,\n    alias: Option<&'a str>,\n) -> Option<String> {\n    let replacement = alias.or(current_value)?.to_string();\n    let Some(pattern) = pattern else {\n        // If user pattern not set, treat it as a match-all pattern\n        return Some(replacement);\n    };\n    // If a pattern is set, but we have no value, there is no match\n    let value = current_value?;\n    if value == pattern {\n        return Some(replacement);\n    }\n    let re = match regex::Regex::new(&format!(\"^{pattern}$\")) {\n        Ok(re) => re,\n        Err(error) => {\n            log::warn!(\n                \"Could not compile regular expression `{}`:\\n{}\",\n                &format!(\"^{pattern}$\"),\n                error\n            );\n            return None;\n        }\n    };\n    let replaced = re.replace(value, replacement.as_str());\n    match replaced {\n        Cow::Owned(replaced) => Some(replaced),\n        // It didn't match...\n        _ => None,\n    }\n}\n\n#[derive(Debug)]\nenum Document {\n    Json(JsonValue),\n    Yaml(Yaml),\n}\n\ntrait DataValue {\n    fn get(&self, key: &str) -> Option<&Self>;\n    fn as_str(&self) -> Option<&str>;\n    fn as_array(&self) -> Option<Vec<&Self>>;\n}\n\nimpl DataValue for JsonValue {\n    fn get(&self, key: &str) -> Option<&Self> {\n        self.get(key)\n    }\n\n    fn as_str(&self) -> Option<&str> {\n        self.as_str()\n    }\n\n    fn as_array(&self) -> Option<Vec<&Self>> {\n        self.as_array().map(|arr| arr.iter().collect())\n    }\n}\n\nimpl DataValue for Yaml {\n    fn get(&self, key: &str) -> Option<&Self> {\n        match self {\n            Self::Hash(map) => map.get(&Self::String(key.to_string())),\n            _ => None,\n        }\n    }\n\n    fn as_str(&self) -> Option<&str> {\n        self.as_str()\n    }\n\n    fn as_array(&self) -> Option<Vec<&Self>> {\n        match self {\n            Self::Array(arr) => Some(arr.iter().collect()),\n            _ => None,\n        }\n    }\n}\n\npub fn module<'a>(context: &'a Context) -> Option<Module<'a>> {\n    let mut module = context.new_module(\"kubernetes\");\n    let config: KubernetesConfig = KubernetesConfig::try_load(module.config);\n\n    // As we default to disabled=true, we have to check here after loading our config module,\n    // before it was only checking against whatever is in the config starship.toml\n    if config.disabled {\n        return None;\n    };\n\n    let have_env_config = !config.detect_env_vars.is_empty();\n    let have_env_vars = have_env_config.then(|| context.detect_env_vars(&config.detect_env_vars));\n\n    // If we have some config for doing the directory scan then we use it but if we don't then we\n    // assume we should treat it like the module is enabled to preserve backward compatibility.\n    let have_scan_config = [\n        &config.detect_files,\n        &config.detect_folders,\n        &config.detect_extensions,\n    ]\n    .into_iter()\n    .any(|v| !v.is_empty());\n\n    let is_kube_project = have_scan_config.then(|| {\n        context.try_begin_scan().map_or(false, |scanner| {\n            scanner\n                .set_files(&config.detect_files)\n                .set_folders(&config.detect_folders)\n                .set_extensions(&config.detect_extensions)\n                .is_match()\n        })\n    });\n\n    if !is_kube_project.or(have_env_vars).unwrap_or(true) {\n        return None;\n    }\n\n    let default_config_file = context.get_home()?.join(\".kube\").join(\"config\");\n\n    let kube_cfg = context\n        .get_env(\"KUBECONFIG\")\n        .unwrap_or(default_config_file.to_str()?.to_string());\n\n    let raw_kubeconfigs = env::split_paths(&kube_cfg).map(|file| utils::read_file(file).ok());\n    let kubeconfigs = parse_kubeconfigs(raw_kubeconfigs);\n\n    let current_kube_ctx_name = kubeconfigs.iter().find_map(|v| match v {\n        Document::Json(json) => get_current_kube_context_name(json),\n        Document::Yaml(yaml) => get_current_kube_context_name(yaml),\n    })?;\n\n    // Even if we have multiple config files, the first key wins\n    // https://kubernetes.io/docs/concepts/configuration/organize-cluster-access-kubeconfig/\n    // > Never change the value or map key. ... Example: If two files specify a red-user,\n    // > use only values from the first file's red-user. Even if the second file has\n    // > non-conflicting entries under red-user, discard them.\n    // for that reason, we can pick the first context with that name\n    let ctx_components: KubeCtxComponents = kubeconfigs.iter().find_map(|kubeconfig|  match kubeconfig {\n        Document::Json(json) => get_kube_ctx_components(json, current_kube_ctx_name),\n        Document::Yaml(yaml) => get_kube_ctx_components(yaml, current_kube_ctx_name),\n    }).unwrap_or_else(|| {\n            // TODO: figure out if returning is more sensible. But currently we have tests depending on this\n            log::warn!(\n                \"Invalid KUBECONFIG: identified current-context `{}`, but couldn't find the context in any config file(s): `{}`.\\n\",\n                &current_kube_ctx_name,\n                &kube_cfg\n                );\n            KubeCtxComponents::default()\n        });\n\n    // Select the first style that matches the context_pattern and,\n    // if it is defined, the user_pattern\n    let (matched_context_config, display_context, display_user) = config\n        .contexts\n        .iter()\n        .find_map(|context_config| {\n            let context_alias = get_aliased_name(\n                Some(context_config.context_pattern),\n                Some(current_kube_ctx_name),\n                context_config.context_alias,\n            )?;\n\n            let user_alias = get_aliased_name(\n                context_config.user_pattern,\n                ctx_components.user.as_deref(),\n                context_config.user_alias,\n            );\n            if matches!((context_config.user_pattern, &user_alias), (Some(_), None)) {\n                // defined pattern, but it didn't match\n                return None;\n            }\n\n            Some((Some(context_config), context_alias, user_alias))\n        })\n        .unwrap_or_else(|| (None, current_kube_ctx_name.to_string(), ctx_components.user));\n\n    // TODO: remove deprecated aliases after starship 2.0\n    let display_context =\n        deprecated::get_alias(display_context, &config.context_aliases, \"context\").unwrap();\n    let display_user =\n        display_user.and_then(|user| deprecated::get_alias(user, &config.user_aliases, \"user\"));\n\n    let display_style = matched_context_config\n        .and_then(|ctx_cfg| ctx_cfg.style)\n        .unwrap_or(config.style);\n    let display_symbol = matched_context_config\n        .and_then(|ctx_cfg| ctx_cfg.symbol)\n        .unwrap_or(config.symbol);\n\n    let parsed = StringFormatter::new(config.format).and_then(|formatter| {\n        formatter\n            .map_meta(|variable, _| match variable {\n                \"symbol\" => Some(display_symbol),\n                _ => None,\n            })\n            .map_style(|variable| match variable {\n                \"style\" => Some(Ok(display_style)),\n                _ => None,\n            })\n            .map(|variable| match variable {\n                \"context\" => Some(Ok(Cow::Borrowed(display_context.as_str()))),\n                \"namespace\" => ctx_components\n                    .namespace\n                    .as_ref()\n                    .map(|kube_ns| Ok(Cow::Borrowed(kube_ns.as_str()))),\n                \"cluster\" => ctx_components\n                    .cluster\n                    .as_ref()\n                    .map(|kube_cluster| Ok(Cow::Borrowed(kube_cluster.as_str()))),\n                \"user\" => display_user\n                    .as_ref()\n                    .map(|kube_user| Ok(Cow::Borrowed(kube_user.as_str()))),\n                _ => None,\n            })\n            .parse(None, Some(context))\n    });\n\n    module.set_segments(match parsed {\n        Ok(segments) => segments,\n        Err(error) => {\n            log::warn!(\"Error in module `kubernetes`: \\n{}\", error);\n            return None;\n        }\n    });\n\n    Some(module)\n}\n\nfn parse_kubeconfigs<I>(raw_kubeconfigs: I) -> Vec<Document>\nwhere\n    I: Iterator<Item = Option<String>>,\n{\n    raw_kubeconfigs\n        .filter_map(|content| match content {\n            Some(value) => match value.chars().next() {\n                // Parsing as json is about an order of magnitude faster than parsing\n                // as yaml, so do that if possible.\n                Some('{') => match serde_json::from_str(&value) {\n                    Ok(json) => Some(Document::Json(json)),\n                    Err(_) => parse_yaml(&value),\n                },\n                _ => parse_yaml(&value),\n            },\n            _ => None,\n        })\n        .collect()\n}\n\nfn parse_yaml(s: &str) -> Option<Document> {\n    YamlLoader::load_from_str(s)\n        .ok()\n        .and_then(|yaml| yaml.into_iter().next().map(Document::Yaml))\n}\n\nmod deprecated {\n    use std::borrow::Cow;\n    use std::collections::HashMap;\n\n    pub fn get_alias<'a>(\n        current_value: String,\n        aliases: &'a HashMap<String, &'a str>,\n        name: &'a str,\n    ) -> Option<String> {\n        let alias = if let Some(val) = aliases.get(current_value.as_str()) {\n            // simple match without regex\n            Some((*val).to_string())\n        } else {\n            // regex match\n            aliases.iter().find_map(|(k, v)| {\n                let re = regex::Regex::new(&format!(\"^{k}$\")).ok()?;\n                let replaced = re.replace(current_value.as_str(), *v);\n                match replaced {\n                    // We have a match if the replaced string is different from the original\n                    Cow::Owned(replaced) => Some(replaced),\n                    _ => None,\n                }\n            })\n        };\n\n        match alias {\n            Some(alias) => {\n                log::warn!(\n                        \"Usage of '{}_aliases' is deprecated and will be removed in 2.0; Use 'contexts' with '{}_alias' instead. (`{}` -> `{}`)\",\n                        &name,\n                        &name,\n                        &current_value,\n                        &alias\n                    );\n                Some(alias)\n            }\n            None => Some(current_value),\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use crate::modules::kubernetes::parse_kubeconfigs;\n    use crate::modules::kubernetes::Document;\n    use crate::test::ModuleRenderer;\n    use nu_ansi_term::Color;\n    use std::env;\n    use std::fs::{create_dir, File};\n    use std::io::{self, Write};\n\n    #[test]\n    fn test_none_when_disabled() -> io::Result<()> {\n        let dir = tempfile::tempdir()?;\n\n        let filename = dir.path().join(\"config\");\n\n        let mut file = File::create(&filename)?;\n        file.write_all(\n            b\"\napiVersion: v1\nclusters: []\ncontexts:\n  - context:\n      cluster: test_cluster\n      user: test_user\n    name: test_context\ncurrent-context: test_context\nkind: Config\npreferences: {}\nusers: []\n\",\n        )?;\n        file.sync_all()?;\n\n        let actual = ModuleRenderer::new(\"kubernetes\")\n            .path(dir.path())\n            .env(\"KUBECONFIG\", filename.to_string_lossy().as_ref())\n            .collect();\n\n        assert_eq!(None, actual);\n\n        dir.close()\n    }\n\n    #[test]\n    fn test_none_when_no_detected_files_folders_or_env_vars() -> io::Result<()> {\n        let dir = tempfile::tempdir()?;\n\n        let filename = dir.path().join(\"config\");\n\n        let mut file = File::create(&filename)?;\n        file.write_all(\n            b\"\napiVersion: v1\nclusters: []\ncontexts:\n  - context:\n      cluster: test_cluster\n      user: test_user\n    name: test_context\ncurrent-context: test_context\nkind: Config\npreferences: {}\nusers: []\n\",\n        )?;\n        file.sync_all()?;\n\n        let actual = ModuleRenderer::new(\"kubernetes\")\n            .path(dir.path())\n            .env(\"KUBECONFIG\", filename.to_string_lossy().as_ref())\n            .config(toml::toml! {\n                [kubernetes]\n                disabled = false\n                detect_files = [\"k8s.ext\"]\n                detect_extensions = [\"k8s\"]\n                detect_folders = [\"k8s_folder\"]\n                detect_env_vars = [\"k8s_env_var\"]\n            })\n            .collect();\n\n        assert_eq!(None, actual);\n\n        dir.close()\n    }\n\n    #[test]\n    fn test_with_detected_files_folder_and_env_vars() -> io::Result<()> {\n        let dir = tempfile::tempdir()?;\n\n        let filename = dir.path().join(\"config\");\n\n        let mut file = File::create(&filename)?;\n        file.write_all(\n            b\"\napiVersion: v1\nclusters: []\ncontexts:\n  - context:\n      cluster: test_cluster\n      user: test_user\n    name: test_context\ncurrent-context: test_context\nkind: Config\npreferences: {}\nusers: []\n\",\n        )?;\n        file.sync_all()?;\n\n        let dir_with_file = tempfile::tempdir()?;\n        File::create(dir_with_file.path().join(\"k8s.ext\"))?.sync_all()?;\n\n        let actual_file = ModuleRenderer::new(\"kubernetes\")\n            .path(dir_with_file.path())\n            .env(\"KUBECONFIG\", filename.to_string_lossy().as_ref())\n            .config(toml::toml! {\n                [kubernetes]\n                disabled = false\n                detect_files = [\"k8s.ext\"]\n                detect_extensions = [\"k8s\"]\n                detect_folders = [\"k8s_folder\"]\n            })\n            .collect();\n\n        let dir_with_ext = tempfile::tempdir()?;\n        File::create(dir_with_ext.path().join(\"test.k8s\"))?.sync_all()?;\n\n        let actual_ext = ModuleRenderer::new(\"kubernetes\")\n            .path(dir_with_ext.path())\n            .env(\"KUBECONFIG\", filename.to_string_lossy().as_ref())\n            .config(toml::toml! {\n                [kubernetes]\n                disabled = false\n                detect_files = [\"k8s.ext\"]\n                detect_extensions = [\"k8s\"]\n                detect_folders = [\"k8s_folder\"]\n            })\n            .collect();\n\n        let dir_with_dir = tempfile::tempdir()?;\n        create_dir(dir_with_dir.path().join(\"k8s_folder\"))?;\n\n        let actual_dir = ModuleRenderer::new(\"kubernetes\")\n            .path(dir_with_dir.path())\n            .env(\"KUBECONFIG\", filename.to_string_lossy().as_ref())\n            .config(toml::toml! {\n                [kubernetes]\n                disabled = false\n                detect_files = [\"k8s.ext\"]\n                detect_extensions = [\"k8s\"]\n                detect_folders = [\"k8s_folder\"]\n            })\n            .collect();\n\n        let empty_dir = tempfile::tempdir()?;\n\n        let actual_env_var = ModuleRenderer::new(\"kubernetes\")\n            .path(empty_dir.path())\n            .env(\"KUBECONFIG\", filename.to_string_lossy().as_ref())\n            .env(\"TEST_K8S_ENV\", \"foo\")\n            .config(toml::toml! {\n                [kubernetes]\n                disabled = false\n                detect_env_vars = [\"TEST_K8S_ENV\"]\n            })\n            .collect();\n\n        let actual_none = ModuleRenderer::new(\"kubernetes\")\n            .path(empty_dir.path())\n            .env(\"KUBECONFIG\", filename.to_string_lossy().as_ref())\n            .config(toml::toml! {\n                [kubernetes]\n                disabled = false\n                detect_files = [\"k8s.ext\"]\n            })\n            .collect();\n\n        let expected = Some(format!(\n            \"{} in \",\n            Color::Cyan.bold().paint(\"\u2638 test_context\")\n        ));\n\n        assert_eq!(expected, actual_file);\n        assert_eq!(expected, actual_ext);\n        assert_eq!(expected, actual_dir);\n        assert_eq!(expected, actual_env_var);\n        assert_eq!(None, actual_none);\n\n        dir.close()\n    }\n\n    fn base_test_ctx_alias(ctx_name: &str, config: toml::Table, expected: &str) -> io::Result<()> {\n        let dir = tempfile::tempdir()?;\n\n        let filename = dir.path().join(\"config\");\n\n        let mut file = File::create(&filename)?;\n        file.write_all(\n            format!(\n                \"\napiVersion: v1\nclusters: []\ncontexts: []\ncurrent-context: {ctx_name}\nkind: Config\npreferences: {{}}\nusers: []\n\"\n            )\n            .as_bytes(),\n        )?;\n        file.sync_all()?;\n\n        let actual = ModuleRenderer::new(\"kubernetes\")\n            .path(dir.path())\n            .env(\"KUBECONFIG\", filename.to_string_lossy().as_ref())\n            .config(config)\n            .collect();\n\n        let expected = Some(format!(\"{} in \", Color::Cyan.bold().paint(expected)));\n        assert_eq!(expected, actual);\n\n        dir.close()\n    }\n\n    #[test]\n    fn test_ctx_alias_simple() -> io::Result<()> {\n        base_test_ctx_alias(\n            \"test_context\",\n            toml::toml! {\n                [kubernetes]\n                disabled = false\n                [kubernetes.context_aliases]\n                \"test_context\" = \"test_alias\"\n                \".*\" = \"literal match has precedence\"\n            },\n            \"\u2638 test_alias\",\n        )\n    }\n\n    #[test]\n    fn test_ctx_alias_regex() -> io::Result<()> {\n        base_test_ctx_alias(\n            \"namespace/openshift-cluster/user\",\n            toml::toml! {\n                [kubernetes]\n                disabled = false\n                [kubernetes.context_aliases]\n                \".*/openshift-cluster/.*\" = \"test_alias\"\n            },\n            \"\u2638 test_alias\",\n        )\n    }\n\n    #[test]\n    fn test_ctx_alias_regex_replace() -> io::Result<()> {\n        base_test_ctx_alias(\n            \"gke_infra-cluster-28cccff6_europe-west4_cluster-1\",\n            toml::toml! {\n                [kubernetes]\n                disabled = false\n                [kubernetes.context_aliases]\n                \"gke_.*_(?P<cluster>[\\\\w-]+)\" = \"example: $cluster\"\n            },\n            \"\u2638 example: cluster-1\",\n        )\n    }\n\n    #[test]\n    fn test_config_context_ctx_alias_regex_replace() -> io::Result<()> {\n        base_test_ctx_alias(\n            \"gke_infra-cluster-28cccff6_europe-west4_cluster-1\",\n            toml::toml! {\n                [kubernetes]\n                disabled = false\n                [[kubernetes.contexts]]\n                context_pattern = \"gke_.*_(?P<cluster>[\\\\w-]+)\"\n                context_alias = \"example: $cluster\"\n            },\n            \"\u2638 example: cluster-1\",\n        )\n    }\n\n    #[test]\n    fn test_ctx_alias_broken_regex() -> io::Result<()> {\n        base_test_ctx_alias(\n            \"input\",\n            toml::toml! {\n                [kubernetes]\n                disabled = false\n                [kubernetes.context_aliases]\n                \"input[.*\" = \"this does not match\"\n            },\n            \"\u2638 input\",\n        )\n    }\n\n    #[test]\n    fn test_single_config_file_no_ns() -> io::Result<()> {\n        let dir = tempfile::tempdir()?;\n\n        let filename = dir.path().join(\"config\");\n\n        let mut file = File::create(&filename)?;\n        file.write_all(\n            b\"\napiVersion: v1\nclusters: []\ncontexts:\n  - context:\n      cluster: test_cluster\n      user: test_user\n    name: test_context\ncurrent-context: test_context\nkind: Config\npreferences: {}\nusers: []\n\",\n        )?;\n        file.sync_all()?;\n\n        let actual = ModuleRenderer::new(\"kubernetes\")\n            .path(dir.path())\n            .env(\"KUBECONFIG\", filename.to_string_lossy().as_ref())\n            .config(toml::toml! {\n                [kubernetes]\n                disabled = false\n            })\n            .collect();\n\n        let expected = Some(format!(\n            \"{} in \",\n            Color::Cyan.bold().paint(\"\u2638 test_context\")\n        ));\n        assert_eq!(expected, actual);\n\n        dir.close()\n    }\n\n    #[test]\n    fn test_single_config_file_with_ns() -> io::Result<()> {\n        let dir = tempfile::tempdir()?;\n\n        let filename = dir.path().join(\"config\");\n\n        let mut file = File::create(&filename)?;\n        file.write_all(\n            b\"\napiVersion: v1\nclusters: []\ncontexts:\n  - context:\n      cluster: test_cluster\n      user: test_user\n      namespace: test_namespace\n    name: test_context\ncurrent-context: test_context\nkind: Config\npreferences: {}\nusers: []\n\",\n        )?;\n        file.sync_all()?;\n\n        let actual = ModuleRenderer::new(\"kubernetes\")\n            .path(dir.path())\n            .env(\"KUBECONFIG\", filename.to_string_lossy().as_ref())\n            .config(toml::toml! {\n                [kubernetes]\n                disabled = false\n            })\n            .collect();\n\n        let expected = Some(format!(\n            \"{} in \",\n            Color::Cyan.bold().paint(\"\u2638 test_context (test_namespace)\")\n        ));\n        assert_eq!(expected, actual);\n\n        dir.close()\n    }\n\n    #[test]\n    fn test_single_config_file_with_multiple_ctxs() -> io::Result<()> {\n        let dir = tempfile::tempdir()?;\n\n        let filename = dir.path().join(\"config\");\n\n        let mut file = File::create(&filename)?;\n        file.write_all(\n            b\"\napiVersion: v1\nclusters: []\ncontexts:\n  - context:\n      cluster: another_cluster\n      user: another_user\n      namespace: another_namespace\n    name: another_context\n  - context:\n      cluster: test_cluster\n      user: test_user\n      namespace: test_namespace\n    name: test_context\ncurrent-context: test_context\nkind: Config\npreferences: {}\nusers: []\n\",\n        )?;\n        file.sync_all()?;\n\n        let actual = ModuleRenderer::new(\"kubernetes\")\n            .path(dir.path())\n            .env(\"KUBECONFIG\", filename.to_string_lossy().as_ref())\n            .config(toml::toml! {\n                [kubernetes]\n                disabled = false\n            })\n            .collect();\n\n        let expected = Some(format!(\n            \"{} in \",\n            Color::Cyan.bold().paint(\"\u2638 test_context (test_namespace)\")\n        ));\n        assert_eq!(expected, actual);\n\n        dir.close()\n    }\n\n    #[test]\n    fn test_multiple_config_files_with_context_defined_once() -> io::Result<()> {\n        // test that we get the current context from the first config file in the KUBECONFIG,\n        // no matter if it is only defined in the latter\n        let dir = tempfile::tempdir()?;\n\n        let filename_cc = dir.path().join(\"config_cc\");\n\n        let mut file_cc = File::create(&filename_cc)?;\n        file_cc.write_all(\n            b\"\napiVersion: v1\nclusters: []\ncontexts: []\ncurrent-context: test_context\nkind: Config\npreferences: {}\nusers: []\n\",\n        )?;\n        file_cc.sync_all()?;\n\n        let filename_ctx = dir.path().join(\"config_ctx\");\n        let mut file_ctx = File::create(&filename_ctx)?;\n        file_ctx.write_all(\n            b\"\napiVersion: v1\nclusters: []\ncontexts:\n  - context:\n      cluster: test_cluster\n      user: test_user\n      namespace: test_namespace\n    name: test_context\nkind: Config\npreferences: {}\nusers: []\n\",\n        )?;\n        file_ctx.sync_all()?;\n\n        // Test current_context first\n        let actual_cc_first = ModuleRenderer::new(\"kubernetes\")\n            .path(dir.path())\n            .env(\n                \"KUBECONFIG\",\n                env::join_paths([&filename_cc, &filename_ctx])\n                    .unwrap()\n                    .to_string_lossy(),\n            )\n            .config(toml::toml! {\n                [kubernetes]\n                disabled = false\n            })\n            .collect();\n\n        // And test with context and namespace first\n        let actual_ctx_first = ModuleRenderer::new(\"kubernetes\")\n            .path(dir.path())\n            .env(\n                \"KUBECONFIG\",\n                env::join_paths([&filename_ctx, &filename_cc])\n                    .unwrap()\n                    .to_string_lossy(),\n            )\n            .config(toml::toml! {\n                [kubernetes]\n                disabled = false\n            })\n            .collect();\n\n        let expected = Some(format!(\n            \"{} in \",\n            Color::Cyan.bold().paint(\"\u2638 test_context (test_namespace)\")\n        ));\n        assert_eq!(expected, actual_cc_first);\n        assert_eq!(expected, actual_ctx_first);\n\n        dir.close()\n    }\n\n    #[test]\n    fn test_multiple_config_files_with_context_defined_twice() -> io::Result<()> {\n        // tests that, if two files contain the same context,\n        // only the context config from the first is used.\n        let dir = tempfile::tempdir()?;\n\n        let config1 = dir.path().join(\"config1\");\n\n        let mut file1 = File::create(&config1)?;\n        file1.write_all(\n            b\"\napiVersion: v1\nclusters: []\ncontexts:\n  - context:\n      cluster: test_cluster1\n      namespace: test_namespace1\n    name: test_context\ncurrent-context: test_context\nkind: Config\npreferences: {}\nusers: []\n\",\n        )?;\n        file1.sync_all()?;\n\n        let config2 = dir.path().join(\"config2\");\n\n        let mut file2 = File::create(&config2)?;\n        file2.write_all(\n            b\"\napiVersion: v1\nclusters: []\ncontexts:\n  - context:\n      cluster: test_cluster2\n      user: test_user2\n    name: test_context\ncurrent-context: test_context\nkind: Config\npreferences: {}\nusers: []\n\",\n        )?;\n        file2.sync_all()?;\n\n        let paths1 = [config1.clone(), config2.clone()];\n        let kubeconfig_content1 = env::join_paths(paths1.iter()).unwrap();\n\n        let actual1 = ModuleRenderer::new(\"kubernetes\")\n            .path(dir.path())\n            .env(\"KUBECONFIG\", kubeconfig_content1.to_string_lossy())\n            .config(toml::toml! {\n                [kubernetes]\n                format = \"($user )($cluster )($namespace )\"\n                disabled = false\n            })\n            .collect();\n\n        let expected1 = Some(\"test_cluster1 test_namespace1 \".to_string());\n        assert_eq!(expected1, actual1);\n\n        let paths2 = [config2, config1];\n        let kubeconfig_content2 = env::join_paths(paths2.iter()).unwrap();\n\n        let actual2 = ModuleRenderer::new(\"kubernetes\")\n            .path(dir.path())\n            .env(\"KUBECONFIG\", kubeconfig_content2.to_string_lossy())\n            .config(toml::toml! {\n                [kubernetes]\n                format = \"($user )($cluster )($namespace )\"\n                disabled = false\n            })\n            .collect();\n\n        let expected2 = Some(\"test_user2 test_cluster2 \".to_string());\n        assert_eq!(expected2, actual2);\n\n        dir.close()\n    }\n\n    fn base_test_user_alias(\n        user_name: &str,\n        config: toml::Table,\n        expected: &str,\n    ) -> io::Result<()> {\n        let dir = tempfile::tempdir()?;\n\n        let filename = dir.path().join(\"config\");\n\n        let mut file = File::create(&filename)?;\n        file.write_all(\n            format!(\n                \"\napiVersion: v1\nclusters: []\ncontexts:\n  - context:\n      cluster: test_cluster\n      user: {user_name}\n      namespace: test_namespace\n    name: test_context\ncurrent-context: test_context\nkind: Config\npreferences: {{}}\nusers: []\n\"\n            )\n            .as_bytes(),\n        )?;\n        file.sync_all()?;\n\n        let actual = ModuleRenderer::new(\"kubernetes\")\n            .path(dir.path())\n            .env(\"KUBECONFIG\", filename.to_string_lossy().as_ref())\n            .config(config)\n            .collect();\n\n        let expected = Some(format!(\"{} in \", Color::Cyan.bold().paint(expected)));\n        assert_eq!(expected, actual);\n\n        dir.close()\n    }\n\n    #[test]\n    fn test_user_alias_simple() -> io::Result<()> {\n        base_test_user_alias(\n            \"test_user\",\n            toml::toml! {\n                [kubernetes]\n                disabled = false\n                format = \"[$symbol$context( \\\\($user\\\\))]($style) in \"\n                [kubernetes.user_aliases]\n                \"test_user\" = \"test_alias\"\n                \".*\" = \"literal match has precedence\"\n            },\n            \"\u2638 test_context (test_alias)\",\n        )\n    }\n\n    #[test]\n    fn test_user_alias_regex() -> io::Result<()> {\n        base_test_user_alias(\n            \"openshift-cluster/user\",\n            toml::toml! {\n                [kubernetes]\n                disabled = false\n                format = \"[$symbol$context( \\\\($user\\\\))]($style) in \"\n                [kubernetes.user_aliases]\n                \"openshift-cluster/.*\" = \"test_alias\"\n            },\n            \"\u2638 test_context (test_alias)\",\n        )\n    }\n\n    #[test]\n    fn test_user_alias_regex_replace() -> io::Result<()> {\n        base_test_user_alias(\n            \"gke_infra-user-28cccff6_europe-west4_cluster-1\",\n            toml::toml! {\n                [kubernetes]\n                disabled = false\n                format = \"[$symbol$context( \\\\($user\\\\))]($style) in \"\n                [kubernetes.user_aliases]\n                \"gke_.*_(?P<cluster>[\\\\w-]+)\" = \"example: $cluster\"\n            },\n            \"\u2638 test_context (example: cluster-1)\",\n        )\n    }\n\n    #[test]\n    fn test_config_context_user_alias_regex_replace() -> io::Result<()> {\n        base_test_user_alias(\n            \"gke_infra-user-28cccff6_europe-west4_cluster-1\",\n            toml::toml! {\n                [kubernetes]\n                disabled = false\n                format = \"[$symbol$context( \\\\($user\\\\))]($style) in \"\n                [[kubernetes.contexts]]\n                context_pattern = \".*\"\n                user_pattern = \"gke_.*_(?P<cluster>[\\\\w-]+)\"\n                user_alias = \"example: $cluster\"\n            },\n            \"\u2638 test_context (example: cluster-1)\",\n        )\n    }\n\n    #[test]\n    fn test_user_alias_broken_regex() -> io::Result<()> {\n        base_test_user_alias(\n            \"input\",\n            toml::toml! {\n                [kubernetes]\n                disabled = false\n                format = \"[$symbol$context( \\\\($user\\\\))]($style) in \"\n                [kubernetes.user_aliases]\n                \"input[.*\" = \"this does not match\"\n            },\n            \"\u2638 test_context (input)\",\n        )\n    }\n\n    #[test]\n    fn test_user_should_use_default_if_no_matching_alias() -> io::Result<()> {\n        base_test_user_alias(\n            \"gke_infra-user-28cccff6_europe-west4_cluster-1\",\n            toml::toml! {\n                [kubernetes]\n                disabled = false\n                format = \"[$symbol$context( \\\\($user\\\\))]($style) in \"\n                [kubernetes.user_aliases]\n                \"([A-Z])\\\\w+\" = \"this does not match\"\n                \"gke_infra-user-28cccff6\" = \"this does not match\"\n            },\n            \"\u2638 test_context (gke_infra-user-28cccff6_europe-west4_cluster-1)\",\n        )\n    }\n\n    #[test]\n    fn test_kube_user() -> io::Result<()> {\n        let dir = tempfile::tempdir()?;\n\n        let filename = dir.path().join(\"config\");\n\n        let mut file = File::create(&filename)?;\n        file.write_all(\n            b\"\napiVersion: v1\nclusters: []\ncontexts:\n  - context:\n      cluster: test_cluster\n      user: test_user\n      namespace: test_namespace\n    name: test_context\ncurrent-context: test_context\nkind: Config\npreferences: {}\nusers: []\n\",\n        )?;\n        file.sync_all()?;\n\n        let actual = ModuleRenderer::new(\"kubernetes\")\n            .path(dir.path())\n            .env(\"KUBECONFIG\", filename.to_string_lossy().as_ref())\n            .config(toml::toml! {\n                [kubernetes]\n                format = \"($user)\"\n                disabled = false\n            })\n            .collect();\n\n        let expected = Some(\"test_user\".to_string());\n        assert_eq!(expected, actual);\n        dir.close()\n    }\n\n    #[test]\n    fn test_kube_cluster() -> io::Result<()> {\n        let dir = tempfile::tempdir()?;\n\n        let filename = dir.path().join(\"config\");\n\n        let mut file = File::create(&filename)?;\n        file.write_all(\n            b\"\napiVersion: v1\nclusters: []\ncontexts:\n  - context:\n      cluster: test_cluster\n      user: test_user\n      namespace: test_namespace\n    name: test_context\ncurrent-context: test_context\nkind: Config\npreferences: {}\nusers: []\n\",\n        )?;\n        file.sync_all()?;\n\n        let actual = ModuleRenderer::new(\"kubernetes\")\n            .path(dir.path())\n            .env(\"KUBECONFIG\", filename.to_string_lossy().as_ref())\n            .config(toml::toml! {\n                [kubernetes]\n                format = \"($cluster)\"\n                disabled = false\n            })\n            .collect();\n\n        let expected = Some(\"test_cluster\".to_string());\n        assert_eq!(expected, actual);\n        dir.close()\n    }\n\n    #[test]\n    fn test_kube_user_missing() -> io::Result<()> {\n        let dir = tempfile::tempdir()?;\n\n        let filename = dir.path().join(\"config\");\n\n        let mut file = File::create(&filename)?;\n        file.write_all(\n            b\"\napiVersion: v1\nclusters: []\ncontexts:\n  - context:\n      cluster: test_cluster\n      namespace: test_namespace\n    name: test_context\ncurrent-context: test_context\nkind: Config\npreferences: {}\nusers: []\n\",\n        )?;\n        file.sync_all()?;\n\n        let actual = ModuleRenderer::new(\"kubernetes\")\n            .path(dir.path())\n            .env(\"KUBECONFIG\", filename.to_string_lossy().as_ref())\n            .config(toml::toml! {\n                [kubernetes]\n                format = \"$symbol($user )($cluster )($namespace)\"\n                disabled = false\n            })\n            .collect();\n\n        let expected = Some(\"\u2638 test_cluster test_namespace\".to_string());\n        assert_eq!(expected, actual);\n        dir.close()\n    }\n\n    #[test]\n    fn test_kube_cluster_missing() -> io::Result<()> {\n        let dir = tempfile::tempdir()?;\n\n        let filename = dir.path().join(\"config\");\n\n        let mut file = File::create(&filename)?;\n        file.write_all(\n            b\"\napiVersion: v1\nclusters: []\ncontexts:\n  - context:\n      user: test_user\n      namespace: test_namespace\n    name: test_context\ncurrent-context: test_context\nkind: Config\npreferences: {}\nusers: []\n\",\n        )?;\n        file.sync_all()?;\n\n        let actual = ModuleRenderer::new(\"kubernetes\")\n            .path(dir.path())\n            .env(\"KUBECONFIG\", filename.to_string_lossy().as_ref())\n            .config(toml::toml! {\n                [kubernetes]\n                format = \"$symbol($user )($cluster )($namespace)\"\n                disabled = false\n            })\n            .collect();\n\n        let expected = Some(\"\u2638 test_user test_namespace\".to_string());\n        assert_eq!(expected, actual);\n        dir.close()\n    }\n\n    #[test]\n    fn test_config_context_overwrites_defaults() -> std::io::Result<()> {\n        let dir = tempfile::tempdir()?;\n        let filename = dir.path().join(\"config\");\n        let mut file = File::create(&filename)?;\n        file.write_all(\n            b\"\napiVersion: v1\nclusters: []\ncontexts:\n  - context:\n      user: test_user\n      namespace: test_namespace\n    name: test_context\ncurrent-context: test_context\nkind: Config\npreferences: {}\nusers: []\n\",\n        )?;\n        file.sync_all()?;\n\n        let actual = ModuleRenderer::new(\"kubernetes\")\n            .path(dir.path())\n            .env(\"KUBECONFIG\", filename.to_string_lossy().as_ref())\n            .config(toml::toml! {\n                [kubernetes]\n                disabled = false\n                style = \"bold red\"\n\n                [[kubernetes.contexts]]\n                context_pattern = \"test.*\"\n                style = \"bold green\"\n                symbol = \"\u00a7 \"\n            })\n            .collect();\n\n        let expected = Some(format!(\n            \"{} in \",\n            Color::Green.bold().paint(\"\u00a7 test_context (test_namespace)\")\n        ));\n        assert_eq!(expected, actual);\n        dir.close()\n    }\n\n    #[test]\n    fn test_config_context_both_pattern_must_match() -> io::Result<()> {\n        let dir = tempfile::tempdir()?;\n        let filename = dir.path().join(\"config\");\n        let mut file = File::create(&filename)?;\n        file.write_all(\n            b\"\napiVersion: v1\nclusters: []\ncontexts:\n  - context:\n      user: test_user\n    name: test_context\ncurrent-context: test_context\nkind: Config\npreferences: {}\nusers: []\n\",\n        )?;\n        file.sync_all()?;\n\n        let actual = ModuleRenderer::new(\"kubernetes\")\n            .path(dir.path())\n            .env(\"KUBECONFIG\", filename.to_string_lossy().as_ref())\n            .config(toml::toml! {\n                [kubernetes]\n                disabled = false\n                format = \"$symbol$context ($user )\"\n\n                [[kubernetes.contexts]]\n                context_pattern = \"test.*\"\n                user_pattern = \"test.*\"\n                context_alias = \"yy\"\n                user_alias = \"xx\"\n                symbol = \"\u00a7 \"\n            })\n            .collect();\n\n        let expected = Some(\"\u00a7 yy xx \".to_string());\n        assert_eq!(expected, actual);\n        dir.close()\n    }\n\n    #[test]\n    fn test_config_context_only_one_pattern_matches() -> io::Result<()> {\n        let dir = tempfile::tempdir()?;\n        let filename = dir.path().join(\"config\");\n        let mut file = File::create(&filename)?;\n        file.write_all(\n            b\"\napiVersion: v1\nclusters: []\ncontexts:\n  - context:\n      user: test_user\n    name: test_context\ncurrent-context: test_context\nkind: Config\npreferences: {}\nusers: []\n\",\n        )?;\n        file.sync_all()?;\n\n        let actual = ModuleRenderer::new(\"kubernetes\")\n            .path(dir.path())\n            .env(\"KUBECONFIG\", filename.to_string_lossy().as_ref())\n            .config(toml::toml! {\n                [kubernetes]\n                disabled = false\n                format = \"$symbol$context ($user )\"\n\n                [[kubernetes.contexts]]\n                context_pattern = \"test.*\"\n                user_pattern = \"test_BAD.*\"\n                context_alias = \"yy\"\n                user_alias = \"xx\"\n                symbol = \"\u00a7 \"\n            })\n            .collect();\n\n        let expected = Some(\"\u2638 test_context test_user \".to_string());\n        assert_eq!(expected, actual);\n        dir.close()\n    }\n\n    #[test]\n    fn test_config_context_uses_aliases() -> std::io::Result<()> {\n        let dir = tempfile::tempdir()?;\n        let filename = dir.path().join(\"config\");\n        let mut file = File::create(&filename)?;\n        file.write_all(\n            b\"\napiVersion: v1\nclusters: []\ncontexts:\n  - context:\n      user: test_user\n      namespace: test_namespace\n    name: test_context\ncurrent-context: test_context\nkind: Config\npreferences: {}\nusers: []\n\",\n        )?;\n        file.sync_all()?;\n\n        let actual = ModuleRenderer::new(\"kubernetes\")\n            .path(dir.path())\n            .env(\"KUBECONFIG\", filename.to_string_lossy().as_ref())\n            .config(toml::toml! {\n                [kubernetes]\n                disabled = false\n                style = \"bold red\"\n                format = \"$symbol($user )($context )($cluster )($namespace)\"\n\n                [[kubernetes.contexts]]\n                context_pattern = \"test.*\"\n                context_alias = \"xyz\"\n                user_alias = \"abc\"\n                symbol = \"\u00a7 \"\n            })\n            .collect();\n\n        let expected = Some(\"\u00a7 abc xyz test_namespace\".to_string());\n        assert_eq!(expected, actual);\n        dir.close()\n    }\n\n    #[test]\n    fn test_config_context_user_pattern_does_not_match() -> std::io::Result<()> {\n        let dir = tempfile::tempdir()?;\n        let filename = dir.path().join(\"config\");\n        let mut file = File::create(&filename)?;\n        file.write_all(\n            b\"\napiVersion: v1\nclusters: []\ncontexts:\n  - context:\n      user: test_user\n      namespace: test_namespace\n    name: test_context\ncurrent-context: test_context\nkind: Config\npreferences: {}\nusers: []\n\",\n        )?;\n        file.sync_all()?;\n\n        let actual = ModuleRenderer::new(\"kubernetes\")\n            .path(dir.path())\n            .env(\"KUBECONFIG\", filename.to_string_lossy().as_ref())\n            .config(toml::toml! {\n                [kubernetes]\n                disabled = false\n                style = \"bold red\"\n                format = \"$symbol($user )($context )($cluster )($namespace)\"\n\n                [[kubernetes.contexts]]\n                context_pattern = \"test\"\n                user_pattern = \"not_matching\"\n                context_alias = \"xyz\"\n                user_alias = \"abc\"\n                symbol = \"\u00a7 \"\n            })\n            .collect();\n\n        let expected = Some(\"\u2638 test_user test_context test_namespace\".to_string());\n        assert_eq!(expected, actual);\n        dir.close()\n    }\n\n    #[test]\n    fn test_config_contexts_does_not_match() -> std::io::Result<()> {\n        let dir = tempfile::tempdir()?;\n        let filename = dir.path().join(\"config\");\n        let mut file = File::create(&filename)?;\n        file.write_all(\n            b\"\napiVersion: v1\nclusters: []\ncontexts:\n  - context:\n      user: test_user\n      namespace: test_namespace\n    name: test_context\ncurrent-context: test_context\nkind: Config\npreferences: {}\nusers: []\n\",\n        )?;\n        file.sync_all()?;\n\n        let actual = ModuleRenderer::new(\"kubernetes\")\n            .path(dir.path())\n            .env(\"KUBECONFIG\", filename.to_string_lossy().as_ref())\n            .config(toml::toml! {\n                [kubernetes]\n                disabled = false\n                style = \"bold red\"\n                contexts = [\n                    {context_pattern = \"tests_.*\", style = \"bold green\", symbol = \"\u00a7 \"},\n                ]\n            })\n            .collect();\n\n        let expected = Some(format!(\n            \"{} in \",\n            Color::Red.bold().paint(\"\u2638 test_context (test_namespace)\")\n        ));\n        assert_eq!(expected, actual);\n        dir.close()\n    }\n\n    #[test]\n    fn test_config_context_bad_regex_should_not_panic() -> std::io::Result<()> {\n        let dir = tempfile::tempdir()?;\n        let filename = dir.path().join(\"config\");\n        let mut file = File::create(&filename)?;\n        file.write_all(\n            b\"\napiVersion: v1\nclusters: []\ncontexts:\n  - context:\n      user: test_user\n      namespace: test_namespace\n    name: test_context\ncurrent-context: test_context\nkind: Config\npreferences: {}\nusers: []\n\",\n        )?;\n        file.sync_all()?;\n\n        let actual = ModuleRenderer::new(\"kubernetes\")\n            .path(dir.path())\n            .env(\"KUBECONFIG\", filename.to_string_lossy().as_ref())\n            .config(toml::toml! {\n                [kubernetes]\n                disabled = false\n                style = \"bold red\"\n                contexts = [\n                    {context_pattern = \"tests_(.*\", style = \"bold green\", symbol = \"\u00a7 \"},\n                ]\n            })\n            .collect();\n\n        let expected = Some(format!(\n            \"{} in \",\n            Color::Red.bold().paint(\"\u2638 test_context (test_namespace)\")\n        ));\n        assert_eq!(expected, actual);\n        dir.close()\n    }\n\n    #[test]\n    fn test_json_kubeconfig_is_parsed_as_json() -> std::io::Result<()> {\n        let json_kubeconfig = r#\"{\n  \"apiVersion\": \"v1\",\n  \"clusters\": [],\n  \"contexts\": [\n    {\n      \"context\": {\n        \"user\": \"test_user\",\n        \"namespace\": \"test_namespace\"\n      },\n      \"name\": \"test_context\"\n    }\n  ],\n  \"current-context\": \"test_context\",\n  \"kind\": \"Config\",\n  \"preferences\": {},\n  \"users\": []\n}\"#\n        .to_string();\n\n        let kubeconfigs = [Some(json_kubeconfig)];\n        let results = parse_kubeconfigs(kubeconfigs.iter().cloned());\n        let actual = results.first().unwrap();\n        match actual {\n            Document::Json(..) => {}\n            _ => panic!(\"Expected Document::Json, got {actual:?}\"),\n        }\n        Ok(())\n    }\n\n    #[test]\n    fn fallback_to_yaml_parsing() -> std::io::Result<()> {\n        let json_kubeconfig = r#\"{\n  \"apiVersion\": v1,\n  \"clusters\": [],\n  \"contexts\": [\n    {\n      \"context\": {\n        \"user\": test_user,\n        \"namespace\": test_namespace\n      },\n      \"name\": test_context\n    }\n  ],\n  \"current-context\": test_context,\n  \"kind\": Config,\n  \"preferences\": {},\n  \"users\": []\n}\"#\n        .to_string();\n\n        let kubeconfigs = [Some(json_kubeconfig)];\n        let results = parse_kubeconfigs(kubeconfigs.iter().cloned());\n        let actual = results.first().unwrap();\n        match actual {\n            Document::Yaml(..) => {}\n            _ => panic!(\"Expected Document::Yaml, got {actual:?}\"),\n        }\n        Ok(())\n    }\n\n    #[test]\n    fn test_parse_json_kubeconfig() -> std::io::Result<()> {\n        let dir = tempfile::tempdir()?;\n        let filename = dir.path().join(\"config\");\n        let mut file = File::create(&filename)?;\n        file.write_all(\n            br#\"{\n  \"contexts\": [\n    {\n      \"name\": \"test_context\",\n      \"context\": {\n        \"user\": \"test_user\",\n        \"namespace\": \"test_namespace\"\n      }\n    }\n  ],\n  \"current-context\": \"test_context\",\n  \"kind\": \"Config\",\n  \"apiVersion\": \"v1\"\n}\n\"#,\n        )?;\n        file.sync_all()?;\n\n        let actual = ModuleRenderer::new(\"kubernetes\")\n            .path(dir.path())\n            .env(\"KUBECONFIG\", filename.to_string_lossy().as_ref())\n            .config(toml::toml! {\n                [kubernetes]\n                disabled = false\n                format = \"($user )($context )($cluster )($namespace)\"\n            })\n            .collect();\n\n        let expected = Some(\"test_user test_context test_namespace\".to_string());\n        assert_eq!(expected, actual);\n        dir.close()\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "14f50a9559b62a1526ba6f62f64a259eb4104b17",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/starship/src/modules/vagrant.rs",
    "func": "use super::{Context, Module, ModuleConfig};\n\nuse crate::configs::vagrant::VagrantConfig;\nuse crate::formatter::StringFormatter;\nuse crate::formatter::VersionFormatter;\n\n/// Creates a module with the current Vagrant version\npub fn module<'a>(context: &'a Context) -> Option<Module<'a>> {\n    let mut module = context.new_module(\"vagrant\");\n    let config = VagrantConfig::try_load(module.config);\n\n    let is_vagrant_project = context\n        .try_begin_scan()?\n        .set_files(&config.detect_files)\n        .set_extensions(&config.detect_extensions)\n        .set_folders(&config.detect_folders)\n        .is_match();\n\n    if !is_vagrant_project {\n        return None;\n    }\n\n    let parsed = StringFormatter::new(config.format).and_then(|formatter| {\n        formatter\n            .map_meta(|var, _| match var {\n                \"symbol\" => Some(config.symbol),\n                _ => None,\n            })\n            .map_style(|variable| match variable {\n                \"style\" => Some(Ok(config.style)),\n                _ => None,\n            })\n            .map(|variable| match variable {\n                \"version\" => {\n                    let vagrant_version = parse_vagrant_version(\n                        &context.exec_cmd(\"vagrant\", &[\"--version\"])?.stdout,\n                    )?;\n                    VersionFormatter::format_module_version(\n                        module.get_name(),\n                        &vagrant_version,\n                        config.version_format,\n                    )\n                }\n                .map(Ok),\n                _ => None,\n            })\n            .parse(None, Some(context))\n    });\n\n    module.set_segments(match parsed {\n        Ok(segments) => segments,\n        Err(error) => {\n            log::warn!(\"Error in module `vagrant`:\\n{}\", error);\n            return None;\n        }\n    });\n\n    Some(module)\n}\n\nfn parse_vagrant_version(vagrant_stdout: &str) -> Option<String> {\n    // `vagrant --version` output looks like this:\n    // Vagrant 2.2.10\n    let version = vagrant_stdout\n        // split into [\"Vagrant\", \"2.2.10\"]\n        .split_whitespace()\n        // return \"2.2.10\"\n        .nth(1)?;\n\n    Some(version.to_string())\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::test::ModuleRenderer;\n    use nu_ansi_term::Color;\n    use std::fs::File;\n    use std::io;\n\n    #[test]\n    fn folder_without_vagrant_files() -> io::Result<()> {\n        let dir = tempfile::tempdir()?;\n\n        let actual = ModuleRenderer::new(\"vagrant\").path(dir.path()).collect();\n\n        let expected = None;\n        assert_eq!(expected, actual);\n        dir.close()\n    }\n\n    #[test]\n    fn folder_with_vagrant_file() -> io::Result<()> {\n        let dir = tempfile::tempdir()?;\n        File::create(dir.path().join(\"Vagrantfile\"))?.sync_all()?;\n\n        let actual = ModuleRenderer::new(\"vagrant\").path(dir.path()).collect();\n\n        let expected = Some(format!(\"via {}\", Color::Cyan.bold().paint(\"\u2371 v2.2.10 \")));\n        assert_eq!(expected, actual);\n        dir.close()\n    }\n\n    #[test]\n    fn test_parse_vagrant_version() {\n        let vagrant = \"Vagrant 2.2.10\\n\";\n        assert_eq!(parse_vagrant_version(vagrant), Some(\"2.2.10\".to_string()));\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "37479a3b9420e6ef793c6d107277863351127c0f",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/starship/src/configs/nix_shell.rs",
    "func": "use serde::{Deserialize, Serialize};\n\n#[derive(Clone, Deserialize, Serialize)]\n#[cfg_attr(\n    feature = \"config-schema\",\n    derive(schemars::JsonSchema),\n    schemars(deny_unknown_fields)\n)]\n#[serde(default)]\npub struct NixShellConfig<'a> {\n    pub format: &'a str,\n    pub symbol: &'a str,\n    pub style: &'a str,\n    pub impure_msg: &'a str,\n    pub pure_msg: &'a str,\n    pub unknown_msg: &'a str,\n    pub disabled: bool,\n    pub heuristic: bool,\n}\n\n/* The trailing double spaces in `symbol` are needed to work around issues with\nmultiwidth emoji support in some shells. Please do not file a PR to change this\nunless you can show that your changes do not affect this workaround.  */\nimpl<'a> Default for NixShellConfig<'a> {\n    fn default() -> Self {\n        NixShellConfig {\n            format: \"via [$symbol$state( \\\\($name\\\\))]($style) \",\n            symbol: \"\u2744\ufe0f  \",\n            style: \"bold blue\",\n            impure_msg: \"impure\",\n            pure_msg: \"pure\",\n            unknown_msg: \"\",\n            disabled: false,\n            heuristic: false,\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "b3ef1b25677d9c50037192bb1b9e3ecdea43edc2",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/starship/src/configs/opa.rs",
    "func": "use serde::{Deserialize, Serialize};\n\n#[derive(Clone, Deserialize, Serialize)]\n#[cfg_attr(\n    feature = \"config-schema\",\n    derive(schemars::JsonSchema),\n    schemars(deny_unknown_fields)\n)]\n#[serde(default)]\npub struct OpaConfig<'a> {\n    pub format: &'a str,\n    pub version_format: &'a str,\n    pub symbol: &'a str,\n    pub style: &'a str,\n    pub disabled: bool,\n    pub detect_extensions: Vec<&'a str>,\n    pub detect_files: Vec<&'a str>,\n    pub detect_folders: Vec<&'a str>,\n}\n\nimpl<'a> Default for OpaConfig<'a> {\n    fn default() -> Self {\n        OpaConfig {\n            format: \"via [$symbol($version )]($style)\",\n            version_format: \"v${raw}\",\n            symbol: \"\ud83e\ude96  \",\n            style: \"bold blue\",\n            disabled: false,\n            detect_extensions: vec![\"rego\"],\n            detect_files: vec![],\n            detect_folders: vec![],\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "9ef463e8517af0efc49aa9f3709cbd151dbd4a3f",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/starship/src/configs/battery.rs",
    "func": "use serde::{Deserialize, Serialize};\n\n#[derive(Clone, Deserialize, Serialize)]\n#[cfg_attr(\n    feature = \"config-schema\",\n    derive(schemars::JsonSchema),\n    schemars(deny_unknown_fields)\n)]\n#[serde(default)]\npub struct BatteryConfig<'a> {\n    pub full_symbol: &'a str,\n    pub charging_symbol: &'a str,\n    pub discharging_symbol: &'a str,\n    pub unknown_symbol: &'a str,\n    pub empty_symbol: &'a str,\n    #[serde(borrow)]\n    pub display: Vec<BatteryDisplayConfig<'a>>,\n    pub disabled: bool,\n    pub format: &'a str,\n}\n\nimpl<'a> Default for BatteryConfig<'a> {\n    fn default() -> Self {\n        BatteryConfig {\n            full_symbol: \"\udb80\udc79 \",\n            charging_symbol: \"\udb80\udc84 \",\n            discharging_symbol: \"\udb80\udc83 \",\n            unknown_symbol: \"\udb80\udc7d \",\n            empty_symbol: \"\udb80\udc8e \",\n            format: \"[$symbol$percentage]($style) \",\n            display: vec![BatteryDisplayConfig::default()],\n            disabled: false,\n        }\n    }\n}\n\n#[derive(Clone, Deserialize, Serialize)]\n#[cfg_attr(\n    feature = \"config-schema\",\n    derive(schemars::JsonSchema),\n    schemars(deny_unknown_fields)\n)]\n#[serde(default)]\npub struct BatteryDisplayConfig<'a> {\n    pub threshold: i64,\n    pub style: &'a str,\n    pub charging_symbol: Option<&'a str>,\n    pub discharging_symbol: Option<&'a str>,\n}\n\nimpl<'a> Default for BatteryDisplayConfig<'a> {\n    fn default() -> Self {\n        BatteryDisplayConfig {\n            threshold: 10,\n            style: \"red bold\",\n            charging_symbol: None,\n            discharging_symbol: None,\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "315e7ed03f6ff0ed2584f9416db30450dee49c55",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bat/tests/syntax-tests/source/Rust/output.rs",
    "func": "use std::io::{self, Write};\n#[cfg(feature = \"paging\")]\nuse std::process::Child;\n\nuse crate::error::*;\n#[cfg(feature = \"paging\")]\nuse crate::less::retrieve_less_version;\n#[cfg(feature = \"paging\")]\nuse crate::paging::PagingMode;\n\n#[derive(Debug)]\npub enum OutputType {\n    #[cfg(feature = \"paging\")]\n    Pager(Child),\n    Stdout(io::Stdout),\n}\n\nimpl OutputType {\n    #[cfg(feature = \"paging\")]\n    pub fn from_mode(mode: PagingMode, pager: Option<&str>) -> Result<Self> {\n        use self::PagingMode::*;\n        Ok(match mode {\n            Always => OutputType::try_pager(false, pager)?,\n            QuitIfOneScreen => OutputType::try_pager(true, pager)?,\n            _ => OutputType::stdout(),\n        })\n    }\n\n    /// Try to launch the pager. Fall back to stdout in case of errors.\n    #[cfg(feature = \"paging\")]\n    fn try_pager(quit_if_one_screen: bool, pager_from_config: Option<&str>) -> Result<Self> {\n        use std::env;\n        use std::ffi::OsString;\n        use std::path::PathBuf;\n        use std::process::{Command, Stdio};\n\n        let mut replace_arguments_to_less = false;\n\n        let pager_from_env = match (env::var(\"BAT_PAGER\"), env::var(\"PAGER\")) {\n            (Ok(bat_pager), _) => Some(bat_pager),\n            (_, Ok(pager)) => {\n                // less needs to be called with the '-R' option in order to properly interpret the\n                // ANSI color sequences printed by bat. If someone has set PAGER=\"less -F\", we\n                // therefore need to overwrite the arguments and add '-R'.\n                //\n                // We only do this for PAGER (as it is not specific to 'bat'), not for BAT_PAGER\n                // or bats '--pager' command line option.\n                replace_arguments_to_less = true;\n                Some(pager)\n            }\n            _ => None,\n        };\n\n        let pager_from_config = pager_from_config.map(|p| p.to_string());\n\n        if pager_from_config.is_some() {\n            replace_arguments_to_less = false;\n        }\n\n        let pager = pager_from_config\n            .or(pager_from_env)\n            .unwrap_or_else(|| String::from(\"less\"));\n\n        let pagerflags =\n            shell_words::split(&pager).chain_err(|| \"Could not parse pager command.\")?;\n\n        match pagerflags.split_first() {\n            Some((pager_name, args)) => {\n                let mut pager_path = PathBuf::from(pager_name);\n\n                if pager_path.file_stem() == Some(&OsString::from(\"bat\")) {\n                    pager_path = PathBuf::from(\"less\");\n                }\n\n                let is_less = pager_path.file_stem() == Some(&OsString::from(\"less\"));\n\n                let mut process = if is_less {\n                    let mut p = Command::new(&pager_path);\n                    if args.is_empty() || replace_arguments_to_less {\n                        p.arg(\"--RAW-CONTROL-CHARS\");\n                        if quit_if_one_screen {\n                            p.arg(\"--quit-if-one-screen\");\n                        }\n\n                        // Passing '--no-init' fixes a bug with '--quit-if-one-screen' in older\n                        // versions of 'less'. Unfortunately, it also breaks mouse-wheel support.\n                        //\n                        // See: http://www.greenwoodsoftware.com/less/news.530.html\n                        //\n                        // For newer versions (530 or 558 on Windows), we omit '--no-init' as it\n                        // is not needed anymore.\n                        match retrieve_less_version() {\n                            None => {\n                                p.arg(\"--no-init\");\n                            }\n                            Some(version)\n                                if (version < 530 || (cfg!(windows) && version < 558)) =>\n                            {\n                                p.arg(\"--no-init\");\n                            }\n                            _ => {}\n                        }\n                    } else {\n                        p.args(args);\n                    }\n                    p.env(\"LESSCHARSET\", \"UTF-8\");\n                    p\n                } else {\n                    let mut p = Command::new(&pager_path);\n                    p.args(args);\n                    p\n                };\n\n                Ok(process\n                    .stdin(Stdio::piped())\n                    .spawn()\n                    .map(OutputType::Pager)\n                    .unwrap_or_else(|_| OutputType::stdout()))\n            }\n            None => Ok(OutputType::stdout()),\n        }\n    }\n\n    pub(crate) fn stdout() -> Self {\n        OutputType::Stdout(io::stdout())\n    }\n\n    #[cfg(feature = \"paging\")]\n    pub(crate) fn is_pager(&self) -> bool {\n        if let OutputType::Pager(_) = self {\n            true\n        } else {\n            false\n        }\n    }\n\n    #[cfg(not(feature = \"paging\"))]\n    pub(crate) fn is_pager(&self) -> bool {\n        false\n    }\n\n    pub fn handle(&mut self) -> Result<&mut dyn Write> {\n        Ok(match *self {\n            #[cfg(feature = \"paging\")]\n            OutputType::Pager(ref mut command) => command\n                .stdin\n                .as_mut()\n                .chain_err(|| \"Could not open stdin for pager\")?,\n            OutputType::Stdout(ref mut handle) => handle,\n        })\n    }\n}\n\n#[cfg(feature = \"paging\")]\nimpl Drop for OutputType {\n    fn drop(&mut self) {\n        if let OutputType::Pager(ref mut command) = *self {\n            let _ = command.wait();\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "2d2ec8156e98aaade85c89e7a038e9949b63f9ed",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bat/examples/inputs.rs",
    "func": "/// A small demonstration of the Input API.\n/// This prints embedded bytes with a custom header and then reads from STDIN.\nuse bat::{Input, PrettyPrinter};\n\nfn main() {\n    PrettyPrinter::new()\n        .header(true)\n        .grid(true)\n        .line_numbers(true)\n        .inputs(vec![\n            Input::from_bytes(b\"echo 'Hello World!'\")\n                .name(\"embedded.sh\") // Dummy name provided to detect the syntax.\n                .kind(\"Embedded\")\n                .title(\"An embedded shell script.\"),\n            Input::from_stdin().title(\"Standard Input\").kind(\"FD\"),\n        ])\n        .print()\n        .unwrap();\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "c4f2c4c780a8b66495ed0da5878460ecc89a3e4e",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/bat/src/syntax_mapping.rs",
    "func": "use std::{\n    path::Path,\n    sync::{\n        atomic::{AtomicBool, Ordering},\n        Arc,\n    },\n    thread,\n};\n\nuse globset::{Candidate, GlobBuilder, GlobMatcher};\nuse once_cell::sync::Lazy;\n\nuse crate::error::Result;\nuse builtin::BUILTIN_MAPPINGS;\nuse ignored_suffixes::IgnoredSuffixes;\n\nmod builtin;\npub mod ignored_suffixes;\n\nfn make_glob_matcher(from: &str) -> Result<GlobMatcher> {\n    let matcher = GlobBuilder::new(from)\n        .case_insensitive(true)\n        .literal_separator(true)\n        .build()?\n        .compile_matcher();\n    Ok(matcher)\n}\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\n#[non_exhaustive]\npub enum MappingTarget<'a> {\n    /// For mapping a path to a specific syntax.\n    MapTo(&'a str),\n\n    /// For mapping a path (typically an extension-less file name) to an unknown\n    /// syntax. This typically means later using the contents of the first line\n    /// of the file to determine what syntax to use.\n    MapToUnknown,\n\n    /// For mapping a file extension (e.g. `*.conf`) to an unknown syntax. This\n    /// typically means later using the contents of the first line of the file\n    /// to determine what syntax to use. However, if a syntax handles a file\n    /// name that happens to have the given file extension (e.g. `resolv.conf`),\n    /// then that association will have higher precedence, and the mapping will\n    /// be ignored.\n    MapExtensionToUnknown,\n}\n\n#[derive(Debug, Clone, Default)]\npub struct SyntaxMapping<'a> {\n    /// User-defined mappings at run time.\n    ///\n    /// Rules in front have precedence.\n    custom_mappings: Vec<(GlobMatcher, MappingTarget<'a>)>,\n\n    pub(crate) ignored_suffixes: IgnoredSuffixes<'a>,\n\n    /// A flag to halt glob matcher building, which is offloaded to another thread.\n    ///\n    /// We have this so that we can signal the thread to halt early when appropriate.\n    halt_glob_build: Arc<AtomicBool>,\n}\n\nimpl<'a> Drop for SyntaxMapping<'a> {\n    fn drop(&mut self) {\n        // signal the offload thread to halt early\n        self.halt_glob_build.store(true, Ordering::Relaxed);\n    }\n}\n\nimpl<'a> SyntaxMapping<'a> {\n    pub fn new() -> SyntaxMapping<'a> {\n        Default::default()\n    }\n\n    /// Start a thread to build the glob matchers for all builtin mappings.\n    ///\n    /// The use of this function while not necessary, is useful to speed up startup\n    /// times by starting this work early in parallel.\n    ///\n    /// The thread halts if/when `halt_glob_build` is set to true.\n    pub fn start_offload_build_all(&self) {\n        let halt = Arc::clone(&self.halt_glob_build);\n        thread::spawn(move || {\n            for (matcher, _) in BUILTIN_MAPPINGS.iter() {\n                if halt.load(Ordering::Relaxed) {\n                    break;\n                }\n                Lazy::force(matcher);\n            }\n        });\n        // Note that this thread is not joined upon completion because there's\n        // no shared resources that need synchronization to be safely dropped.\n        // If we later add code into this thread that requires interesting\n        // resources (e.g. IO), it would be a good idea to store the handle\n        // and join it on drop.\n    }\n\n    pub fn insert(&mut self, from: &str, to: MappingTarget<'a>) -> Result<()> {\n        let matcher = make_glob_matcher(from)?;\n        self.custom_mappings.push((matcher, to));\n        Ok(())\n    }\n\n    /// Returns an iterator over all mappings. User-defined mappings are listed\n    /// before builtin mappings; mappings in front have higher precedence.\n    ///\n    /// Builtin mappings' `GlobMatcher`s are lazily compiled.\n    ///\n    /// Note that this function only returns mappings that are valid under the\n    /// current environment. For details see [`Self::builtin_mappings`].\n    pub fn all_mappings(&self) -> impl Iterator<Item = (&GlobMatcher, &MappingTarget<'a>)> {\n        self.custom_mappings()\n            .iter()\n            .map(|(matcher, target)| (matcher, target)) // as_ref\n            .chain(\n                // we need a map with a closure to \"do\" the lifetime variance\n                // see: https://discord.com/channels/273534239310479360/1120124565591425034/1170543402870382653\n                // also, clippy false positive:\n                // see: https://github.com/rust-lang/rust-clippy/issues/9280\n                #[allow(clippy::map_identity)]\n                self.builtin_mappings().map(|rule| rule),\n            )\n    }\n\n    /// Returns an iterator over all valid builtin mappings. Mappings in front\n    /// have higher precedence.\n    ///\n    /// The `GlabMatcher`s are lazily compiled.\n    ///\n    /// Mappings that are invalid under the current environment (i.e. rule\n    /// requires environment variable(s) that is unset, or the joined string\n    /// after variable(s) replacement is not a valid glob expression) are\n    /// ignored.\n    pub fn builtin_mappings(\n        &self,\n    ) -> impl Iterator<Item = (&'static GlobMatcher, &'static MappingTarget<'static>)> {\n        BUILTIN_MAPPINGS\n            .iter()\n            .filter_map(|(matcher, target)| matcher.as_ref().map(|glob| (glob, target)))\n    }\n\n    /// Returns all user-defined mappings.\n    pub fn custom_mappings(&self) -> &[(GlobMatcher, MappingTarget<'a>)] {\n        &self.custom_mappings\n    }\n\n    pub fn get_syntax_for(&self, path: impl AsRef<Path>) -> Option<MappingTarget<'a>> {\n        // Try matching on the file name as-is.\n        let candidate = Candidate::new(&path);\n        let candidate_filename = path.as_ref().file_name().map(Candidate::new);\n        for (glob, syntax) in self.all_mappings() {\n            if glob.is_match_candidate(&candidate)\n                || candidate_filename\n                    .as_ref()\n                    .map_or(false, |filename| glob.is_match_candidate(filename))\n            {\n                return Some(*syntax);\n            }\n        }\n        // Try matching on the file name after removing an ignored suffix.\n        let file_name = path.as_ref().file_name()?;\n        self.ignored_suffixes\n            .try_with_stripped_suffix(file_name, |stripped_file_name| {\n                Ok(self.get_syntax_for(stripped_file_name))\n            })\n            .ok()?\n    }\n\n    pub fn insert_ignored_suffix(&mut self, suffix: &'a str) {\n        self.ignored_suffixes.add_suffix(suffix);\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn builtin_mappings_work() {\n        let map = SyntaxMapping::new();\n\n        assert_eq!(\n            map.get_syntax_for(\"/path/to/build\"),\n            Some(MappingTarget::MapToUnknown)\n        );\n    }\n\n    #[test]\n    fn all_fixed_builtin_mappings_can_compile() {\n        let map = SyntaxMapping::new();\n\n        // collect call evaluates all lazy closures\n        // fixed builtin mappings will panic if they fail to compile\n        let _mappings = map.builtin_mappings().collect::<Vec<_>>();\n    }\n\n    #[test]\n    fn builtin_mappings_matcher_only_compile_once() {\n        let map = SyntaxMapping::new();\n\n        let two_iterations: Vec<_> = (0..2)\n            .map(|_| {\n                // addresses of every matcher\n                map.builtin_mappings()\n                    .map(|(matcher, _)| matcher as *const _ as usize)\n                    .collect::<Vec<_>>()\n            })\n            .collect();\n\n        // if the matchers are only compiled once, their address should remain the same\n        assert_eq!(two_iterations[0], two_iterations[1]);\n    }\n\n    #[test]\n    fn custom_mappings_work() {\n        let mut map = SyntaxMapping::new();\n        map.insert(\"/path/to/Cargo.lock\", MappingTarget::MapTo(\"TOML\"))\n            .ok();\n        map.insert(\"/path/to/.ignore\", MappingTarget::MapTo(\"Git Ignore\"))\n            .ok();\n\n        assert_eq!(\n            map.get_syntax_for(\"/path/to/Cargo.lock\"),\n            Some(MappingTarget::MapTo(\"TOML\"))\n        );\n        assert_eq!(map.get_syntax_for(\"/path/to/other.lock\"), None);\n\n        assert_eq!(\n            map.get_syntax_for(\"/path/to/.ignore\"),\n            Some(MappingTarget::MapTo(\"Git Ignore\"))\n        );\n    }\n\n    #[test]\n    fn custom_mappings_override_builtin() {\n        let mut map = SyntaxMapping::new();\n\n        assert_eq!(\n            map.get_syntax_for(\"/path/to/httpd.conf\"),\n            Some(MappingTarget::MapTo(\"Apache Conf\"))\n        );\n        map.insert(\"httpd.conf\", MappingTarget::MapTo(\"My Syntax\"))\n            .ok();\n        assert_eq!(\n            map.get_syntax_for(\"/path/to/httpd.conf\"),\n            Some(MappingTarget::MapTo(\"My Syntax\"))\n        );\n    }\n\n    #[test]\n    fn custom_mappings_precedence() {\n        let mut map = SyntaxMapping::new();\n\n        map.insert(\"/path/to/foo\", MappingTarget::MapTo(\"alpha\"))\n            .ok();\n        map.insert(\"/path/to/foo\", MappingTarget::MapTo(\"bravo\"))\n            .ok();\n        assert_eq!(\n            map.get_syntax_for(\"/path/to/foo\"),\n            Some(MappingTarget::MapTo(\"alpha\"))\n        );\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "736df51a488f7d2fe9be7189a8dc292ebb482118",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/axum/examples/websockets/src/main.rs",
    "func": "//! Example websocket server.\n//!\n//! Run the server with\n//! ```not_rust\n//! cargo run -p example-websockets --bin example-websockets\n//! ```\n//!\n//! Run a browser client with\n//! ```not_rust\n//! firefox http://localhost:3000\n//! ```\n//!\n//! Alternatively you can run the rust client (showing two\n//! concurrent websocket connections being established) with\n//! ```not_rust\n//! cargo run -p example-websockets --bin example-client\n//! ```\n\nuse axum::{\n    extract::ws::{Message, WebSocket, WebSocketUpgrade},\n    response::IntoResponse,\n    routing::any,\n    Router,\n};\nuse axum_extra::TypedHeader;\n\nuse std::borrow::Cow;\nuse std::ops::ControlFlow;\nuse std::{net::SocketAddr, path::PathBuf};\nuse tower_http::{\n    services::ServeDir,\n    trace::{DefaultMakeSpan, TraceLayer},\n};\n\nuse tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt};\n\n//allows to extract the IP of connecting user\nuse axum::extract::connect_info::ConnectInfo;\nuse axum::extract::ws::CloseFrame;\n\n//allows to split the websocket stream into separate TX and RX branches\nuse futures::{sink::SinkExt, stream::StreamExt};\n\n#[tokio::main]\nasync fn main() {\n    tracing_subscriber::registry()\n        .with(\n            tracing_subscriber::EnvFilter::try_from_default_env().unwrap_or_else(|_| {\n                format!(\"{}=debug,tower_http=debug\", env!(\"CARGO_CRATE_NAME\")).into()\n            }),\n        )\n        .with(tracing_subscriber::fmt::layer())\n        .init();\n\n    let assets_dir = PathBuf::from(env!(\"CARGO_MANIFEST_DIR\")).join(\"assets\");\n\n    // build our application with some routes\n    let app = Router::new()\n        .fallback_service(ServeDir::new(assets_dir).append_index_html_on_directories(true))\n        .route(\"/ws\", any(ws_handler))\n        // logging so we can see whats going on\n        .layer(\n            TraceLayer::new_for_http()\n                .make_span_with(DefaultMakeSpan::default().include_headers(true)),\n        );\n\n    // run it with hyper\n    let listener = tokio::net::TcpListener::bind(\"127.0.0.1:3000\")\n        .await\n        .unwrap();\n    tracing::debug!(\"listening on {}\", listener.local_addr().unwrap());\n    axum::serve(\n        listener,\n        app.into_make_service_with_connect_info::<SocketAddr>(),\n    )\n    .await\n    .unwrap();\n}\n\n/// The handler for the HTTP request (this gets called when the HTTP request lands at the start\n/// of websocket negotiation). After this completes, the actual switching from HTTP to\n/// websocket protocol will occur.\n/// This is the last point where we can extract TCP/IP metadata such as IP address of the client\n/// as well as things from HTTP headers such as user-agent of the browser etc.\nasync fn ws_handler(\n    ws: WebSocketUpgrade,\n    user_agent: Option<TypedHeader<headers::UserAgent>>,\n    ConnectInfo(addr): ConnectInfo<SocketAddr>,\n) -> impl IntoResponse {\n    let user_agent = if let Some(TypedHeader(user_agent)) = user_agent {\n        user_agent.to_string()\n    } else {\n        String::from(\"Unknown browser\")\n    };\n    println!(\"`{user_agent}` at {addr} connected.\");\n    // finalize the upgrade process by returning upgrade callback.\n    // we can customize the callback by sending additional info such as address.\n    ws.on_upgrade(move |socket| handle_socket(socket, addr))\n}\n\n/// Actual websocket statemachine (one will be spawned per connection)\nasync fn handle_socket(mut socket: WebSocket, who: SocketAddr) {\n    // send a ping (unsupported by some browsers) just to kick things off and get a response\n    if socket.send(Message::Ping(vec![1, 2, 3])).await.is_ok() {\n        println!(\"Pinged {who}...\");\n    } else {\n        println!(\"Could not send ping {who}!\");\n        // no Error here since the only thing we can do is to close the connection.\n        // If we can not send messages, there is no way to salvage the statemachine anyway.\n        return;\n    }\n\n    // receive single message from a client (we can either receive or send with socket).\n    // this will likely be the Pong for our Ping or a hello message from client.\n    // waiting for message from a client will block this task, but will not block other client's\n    // connections.\n    if let Some(msg) = socket.recv().await {\n        if let Ok(msg) = msg {\n            if process_message(msg, who).is_break() {\n                return;\n            }\n        } else {\n            println!(\"client {who} abruptly disconnected\");\n            return;\n        }\n    }\n\n    // Since each client gets individual statemachine, we can pause handling\n    // when necessary to wait for some external event (in this case illustrated by sleeping).\n    // Waiting for this client to finish getting its greetings does not prevent other clients from\n    // connecting to server and receiving their greetings.\n    for i in 1..5 {\n        if socket\n            .send(Message::Text(format!(\"Hi {i} times!\")))\n            .await\n            .is_err()\n        {\n            println!(\"client {who} abruptly disconnected\");\n            return;\n        }\n        tokio::time::sleep(std::time::Duration::from_millis(100)).await;\n    }\n\n    // By splitting socket we can send and receive at the same time. In this example we will send\n    // unsolicited messages to client based on some sort of server's internal event (i.e .timer).\n    let (mut sender, mut receiver) = socket.split();\n\n    // Spawn a task that will push several messages to the client (does not matter what client does)\n    let mut send_task = tokio::spawn(async move {\n        let n_msg = 20;\n        for i in 0..n_msg {\n            // In case of any websocket error, we exit.\n            if sender\n                .send(Message::Text(format!(\"Server message {i} ...\")))\n                .await\n                .is_err()\n            {\n                return i;\n            }\n\n            tokio::time::sleep(std::time::Duration::from_millis(300)).await;\n        }\n\n        println!(\"Sending close to {who}...\");\n        if let Err(e) = sender\n            .send(Message::Close(Some(CloseFrame {\n                code: axum::extract::ws::close_code::NORMAL,\n                reason: Cow::from(\"Goodbye\"),\n            })))\n            .await\n        {\n            println!(\"Could not send Close due to {e}, probably it is ok?\");\n        }\n        n_msg\n    });\n\n    // This second task will receive messages from client and print them on server console\n    let mut recv_task = tokio::spawn(async move {\n        let mut cnt = 0;\n        while let Some(Ok(msg)) = receiver.next().await {\n            cnt += 1;\n            // print message and break if instructed to do so\n            if process_message(msg, who).is_break() {\n                break;\n            }\n        }\n        cnt\n    });\n\n    // If any one of the tasks exit, abort the other.\n    tokio::select! {\n        rv_a = (&mut send_task) => {\n            match rv_a {\n                Ok(a) => println!(\"{a} messages sent to {who}\"),\n                Err(a) => println!(\"Error sending messages {a:?}\")\n            }\n            recv_task.abort();\n        },\n        rv_b = (&mut recv_task) => {\n            match rv_b {\n                Ok(b) => println!(\"Received {b} messages\"),\n                Err(b) => println!(\"Error receiving messages {b:?}\")\n            }\n            send_task.abort();\n        }\n    }\n\n    // returning from the handler closes the websocket connection\n    println!(\"Websocket context {who} destroyed\");\n}\n\n/// helper to print contents of messages to stdout. Has special treatment for Close.\nfn process_message(msg: Message, who: SocketAddr) -> ControlFlow<(), ()> {\n    match msg {\n        Message::Text(t) => {\n            println!(\">>> {who} sent str: {t:?}\");\n        }\n        Message::Binary(d) => {\n            println!(\">>> {} sent {} bytes: {:?}\", who, d.len(), d);\n        }\n        Message::Close(c) => {\n            if let Some(cf) = c {\n                println!(\n                    \">>> {} sent close with code {} and reason `{}`\",\n                    who, cf.code, cf.reason\n                );\n            } else {\n                println!(\">>> {who} somehow sent close message without CloseFrame\");\n            }\n            return ControlFlow::Break(());\n        }\n\n        Message::Pong(v) => {\n            println!(\">>> {who} sent pong with {v:?}\");\n        }\n        // You should never need to manually handle Message::Ping, as axum's websocket library\n        // will do so for you automagically by replying with Pong and copying the v according to\n        // spec. But if you need the contents of the pings you can see them here.\n        Message::Ping(v) => {\n            println!(\">>> {who} sent ping with {v:?}\");\n        }\n    }\n    ControlFlow::Continue(())\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "c93b66b6306f4866deaefce9d37d420c68a3a56c",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/axum/examples/request-id/src/main.rs",
    "func": "//! Run with\n//!\n//! ```not_rust\n//! cargo run -p example-request-id\n//! ```\n\nuse axum::{\n    http::{HeaderName, Request},\n    response::Html,\n    routing::get,\n    Router,\n};\nuse tower::ServiceBuilder;\nuse tower_http::{\n    request_id::{MakeRequestUuid, PropagateRequestIdLayer, SetRequestIdLayer},\n    trace::TraceLayer,\n};\nuse tracing::{error, info, info_span};\nuse tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt};\n\nconst REQUEST_ID_HEADER: &str = \"x-request-id\";\n\n#[tokio::main]\nasync fn main() {\n    tracing_subscriber::registry()\n        .with(\n            tracing_subscriber::EnvFilter::try_from_default_env().unwrap_or_else(|_| {\n                // axum logs rejections from built-in extractors with the `axum::rejection`\n                // target, at `TRACE` level. `axum::rejection=trace` enables showing those events\n                format!(\n                    \"{}=debug,tower_http=debug,axum::rejection=trace\",\n                    env!(\"CARGO_CRATE_NAME\")\n                )\n                .into()\n            }),\n        )\n        .with(tracing_subscriber::fmt::layer())\n        .init();\n\n    let x_request_id = HeaderName::from_static(REQUEST_ID_HEADER);\n\n    let middleware = ServiceBuilder::new()\n        .layer(SetRequestIdLayer::new(\n            x_request_id.clone(),\n            MakeRequestUuid,\n        ))\n        .layer(\n            TraceLayer::new_for_http().make_span_with(|request: &Request<_>| {\n                // Log the request id as generated.\n                let request_id = request.headers().get(REQUEST_ID_HEADER);\n\n                match request_id {\n                    Some(request_id) => info_span!(\n                        \"http_request\",\n                        request_id = ?request_id,\n                    ),\n                    None => {\n                        error!(\"could not extract request_id\");\n                        info_span!(\"http_request\")\n                    }\n                }\n            }),\n        )\n        // send headers from request to response headers\n        .layer(PropagateRequestIdLayer::new(x_request_id));\n\n    // build our application with a route\n    let app = Router::new().route(\"/\", get(handler)).layer(middleware);\n\n    // run it\n    let listener = tokio::net::TcpListener::bind(\"127.0.0.1:3000\")\n        .await\n        .unwrap();\n    println!(\"listening on {}\", listener.local_addr().unwrap());\n    axum::serve(listener, app).await.unwrap();\n}\n\nasync fn handler() -> Html<&'static str> {\n    info!(\"Hello world!\");\n    Html(\"<h1>Hello, World!</h1>\")\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "b26a48046033581414c2a7bb74d2d62e6aa2acf8",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/axum/axum/src/response/redirect.rs",
    "func": "use axum_core::response::{IntoResponse, Response};\nuse http::{header::LOCATION, HeaderValue, StatusCode};\n\n/// Response that redirects the request to another location.\n///\n/// # Example\n///\n/// ```rust\n/// use axum::{\n///     routing::get,\n///     response::Redirect,\n///     Router,\n/// };\n///\n/// let app = Router::new()\n///     .route(\"/old\", get(|| async { Redirect::permanent(\"/new\") }))\n///     .route(\"/new\", get(|| async { \"Hello!\" }));\n/// # let _: Router = app;\n/// ```\n#[must_use = \"needs to be returned from a handler or otherwise turned into a Response to be useful\"]\n#[derive(Debug, Clone)]\npub struct Redirect {\n    status_code: StatusCode,\n    location: HeaderValue,\n}\n\nimpl Redirect {\n    /// Create a new [`Redirect`] that uses a [`303 See Other`][mdn] status code.\n    ///\n    /// This redirect instructs the client to change the method to GET for the subsequent request\n    /// to the given `uri`, which is useful after successful form submission, file upload or when\n    /// you generally don't want the redirected-to page to observe the original request method and\n    /// body (if non-empty). If you want to preserve the request method and body,\n    /// [`Redirect::temporary`] should be used instead.\n    ///\n    /// # Panics\n    ///\n    /// If `uri` isn't a valid [`HeaderValue`].\n    ///\n    /// [mdn]: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/303\n    pub fn to(uri: &str) -> Self {\n        Self::with_status_code(StatusCode::SEE_OTHER, uri)\n    }\n\n    /// Create a new [`Redirect`] that uses a [`307 Temporary Redirect`][mdn] status code.\n    ///\n    /// This has the same behavior as [`Redirect::to`], except it will preserve the original HTTP\n    /// method and body.\n    ///\n    /// # Panics\n    ///\n    /// If `uri` isn't a valid [`HeaderValue`].\n    ///\n    /// [mdn]: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/307\n    pub fn temporary(uri: &str) -> Self {\n        Self::with_status_code(StatusCode::TEMPORARY_REDIRECT, uri)\n    }\n\n    /// Create a new [`Redirect`] that uses a [`308 Permanent Redirect`][mdn] status code.\n    ///\n    /// # Panics\n    ///\n    /// If `uri` isn't a valid [`HeaderValue`].\n    ///\n    /// [mdn]: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/308\n    pub fn permanent(uri: &str) -> Self {\n        Self::with_status_code(StatusCode::PERMANENT_REDIRECT, uri)\n    }\n\n    // This is intentionally not public since other kinds of redirects might not\n    // use the `Location` header, namely `304 Not Modified`.\n    //\n    // We're open to adding more constructors upon request, if they make sense :)\n    fn with_status_code(status_code: StatusCode, uri: &str) -> Self {\n        assert!(\n            status_code.is_redirection(),\n            \"not a redirection status code\"\n        );\n\n        Self {\n            status_code,\n            location: HeaderValue::try_from(uri).expect(\"URI isn't a valid header value\"),\n        }\n    }\n}\n\nimpl IntoResponse for Redirect {\n    fn into_response(self) -> Response {\n        (self.status_code, [(LOCATION, self.location)]).into_response()\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "e346107bc04da592c09759dddb1afc264d85e906",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/axum/axum/src/routing/method_filter.rs",
    "func": "use http::Method;\nuse std::{\n    fmt,\n    fmt::{Debug, Formatter},\n};\n\n/// A filter that matches one or more HTTP methods.\n#[derive(Debug, Copy, Clone, PartialEq)]\npub struct MethodFilter(u16);\n\nimpl MethodFilter {\n    /// Match `CONNECT` requests.\n    ///\n    /// This is useful for implementing HTTP/2's [extended CONNECT method],\n    /// in which the `:protocol` pseudoheader is read\n    /// (using [`hyper::ext::Protocol`])\n    /// and the connection upgraded to a bidirectional byte stream\n    /// (using [`hyper::upgrade::on`]).\n    ///\n    /// As seen in the [HTTP Upgrade Token Registry],\n    /// common uses include WebSockets and proxying UDP or IP \u2013\n    /// though note that when using [`WebSocketUpgrade`]\n    /// it's more useful to use [`any`](crate::routing::any)\n    /// as HTTP/1.1 WebSockets need to support `GET`.\n    ///\n    /// [extended CONNECT]: https://www.rfc-editor.org/rfc/rfc8441.html#section-4\n    /// [HTTP Upgrade Token Registry]: https://www.iana.org/assignments/http-upgrade-tokens/http-upgrade-tokens.xhtml\n    /// [`WebSocketUpgrade`]: crate::extract::WebSocketUpgrade\n    pub const CONNECT: Self = Self::from_bits(0b0_0000_0001);\n    /// Match `DELETE` requests.\n    pub const DELETE: Self = Self::from_bits(0b0_0000_0010);\n    /// Match `GET` requests.\n    pub const GET: Self = Self::from_bits(0b0_0000_0100);\n    /// Match `HEAD` requests.\n    pub const HEAD: Self = Self::from_bits(0b0_0000_1000);\n    /// Match `OPTIONS` requests.\n    pub const OPTIONS: Self = Self::from_bits(0b0_0001_0000);\n    /// Match `PATCH` requests.\n    pub const PATCH: Self = Self::from_bits(0b0_0010_0000);\n    /// Match `POST` requests.\n    pub const POST: Self = Self::from_bits(0b0_0100_0000);\n    /// Match `PUT` requests.\n    pub const PUT: Self = Self::from_bits(0b0_1000_0000);\n    /// Match `TRACE` requests.\n    pub const TRACE: Self = Self::from_bits(0b1_0000_0000);\n\n    const fn bits(&self) -> u16 {\n        let bits = self;\n        bits.0\n    }\n\n    const fn from_bits(bits: u16) -> Self {\n        Self(bits)\n    }\n\n    pub(crate) const fn contains(&self, other: Self) -> bool {\n        self.bits() & other.bits() == other.bits()\n    }\n\n    /// Performs the OR operation between the [`MethodFilter`] in `self` with `other`.\n    pub const fn or(self, other: Self) -> Self {\n        Self(self.0 | other.0)\n    }\n}\n\n/// Error type used when converting a [`Method`] to a [`MethodFilter`] fails.\n#[derive(Debug)]\npub struct NoMatchingMethodFilter {\n    method: Method,\n}\n\nimpl NoMatchingMethodFilter {\n    /// Get the [`Method`] that couldn't be converted to a [`MethodFilter`].\n    pub fn method(&self) -> &Method {\n        &self.method\n    }\n}\n\nimpl fmt::Display for NoMatchingMethodFilter {\n    fn fmt(&self, f: &mut Formatter<'_>) -> fmt::Result {\n        write!(f, \"no `MethodFilter` for `{}`\", self.method.as_str())\n    }\n}\n\nimpl std::error::Error for NoMatchingMethodFilter {}\n\nimpl TryFrom<Method> for MethodFilter {\n    type Error = NoMatchingMethodFilter;\n\n    fn try_from(m: Method) -> Result<Self, NoMatchingMethodFilter> {\n        match m {\n            Method::CONNECT => Ok(MethodFilter::CONNECT),\n            Method::DELETE => Ok(MethodFilter::DELETE),\n            Method::GET => Ok(MethodFilter::GET),\n            Method::HEAD => Ok(MethodFilter::HEAD),\n            Method::OPTIONS => Ok(MethodFilter::OPTIONS),\n            Method::PATCH => Ok(MethodFilter::PATCH),\n            Method::POST => Ok(MethodFilter::POST),\n            Method::PUT => Ok(MethodFilter::PUT),\n            Method::TRACE => Ok(MethodFilter::TRACE),\n            other => Err(NoMatchingMethodFilter { method: other }),\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn from_http_method() {\n        assert_eq!(\n            MethodFilter::try_from(Method::CONNECT).unwrap(),\n            MethodFilter::CONNECT\n        );\n\n        assert_eq!(\n            MethodFilter::try_from(Method::DELETE).unwrap(),\n            MethodFilter::DELETE\n        );\n\n        assert_eq!(\n            MethodFilter::try_from(Method::GET).unwrap(),\n            MethodFilter::GET\n        );\n\n        assert_eq!(\n            MethodFilter::try_from(Method::HEAD).unwrap(),\n            MethodFilter::HEAD\n        );\n\n        assert_eq!(\n            MethodFilter::try_from(Method::OPTIONS).unwrap(),\n            MethodFilter::OPTIONS\n        );\n\n        assert_eq!(\n            MethodFilter::try_from(Method::PATCH).unwrap(),\n            MethodFilter::PATCH\n        );\n\n        assert_eq!(\n            MethodFilter::try_from(Method::POST).unwrap(),\n            MethodFilter::POST\n        );\n\n        assert_eq!(\n            MethodFilter::try_from(Method::PUT).unwrap(),\n            MethodFilter::PUT\n        );\n\n        assert_eq!(\n            MethodFilter::try_from(Method::TRACE).unwrap(),\n            MethodFilter::TRACE\n        );\n\n        assert!(\n            MethodFilter::try_from(http::Method::from_bytes(b\"CUSTOM\").unwrap())\n                .unwrap_err()\n                .to_string()\n                .contains(\"CUSTOM\")\n        );\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "b9b8daf2b2b895f263f9d3e9c7d9a3c10482b89e",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/axum/axum-extra/src/extract/query.rs",
    "func": "use axum::{\n    extract::FromRequestParts,\n    response::{IntoResponse, Response},\n    Error,\n};\nuse http::{request::Parts, StatusCode};\nuse serde::de::DeserializeOwned;\nuse std::fmt;\n\n/// Extractor that deserializes query strings into some type.\n///\n/// `T` is expected to implement [`serde::Deserialize`].\n///\n/// # Differences from `axum::extract::Query`\n///\n/// This extractor uses [`serde_html_form`] under-the-hood which supports multi-value items. These\n/// are sent by multiple `<input>` attributes of the same name (e.g. checkboxes) and `<select>`s\n/// with the `multiple` attribute. Those values can be collected into a `Vec` or other sequential\n/// container.\n///\n/// # Example\n///\n/// ```rust,no_run\n/// use axum::{routing::get, Router};\n/// use axum_extra::extract::Query;\n/// use serde::Deserialize;\n///\n/// #[derive(Deserialize)]\n/// struct Pagination {\n///     page: usize,\n///     per_page: usize,\n/// }\n///\n/// // This will parse query strings like `?page=2&per_page=30` into `Pagination`\n/// // structs.\n/// async fn list_things(pagination: Query<Pagination>) {\n///     let pagination: Pagination = pagination.0;\n///\n///     // ...\n/// }\n///\n/// let app = Router::new().route(\"/list_things\", get(list_things));\n/// # let _: Router = app;\n/// ```\n///\n/// If the query string cannot be parsed it will reject the request with a `400\n/// Bad Request` response.\n///\n/// For handling values being empty vs missing see the [query-params-with-empty-strings][example]\n/// example.\n///\n/// [example]: https://github.com/tokio-rs/axum/blob/main/examples/query-params-with-empty-strings/src/main.rs\n///\n/// While `Option<T>` will handle empty parameters (e.g. `param=`), beware when using this with a\n/// `Vec<T>`. If your list is optional, use `Vec<T>` in combination with `#[serde(default)]`\n/// instead of `Option<Vec<T>>`. `Option<Vec<T>>` will handle 0, 2, or more arguments, but not one\n/// argument.\n///\n/// # Example\n///\n/// ```rust,no_run\n/// use axum::{routing::get, Router};\n/// use axum_extra::extract::Query;\n/// use serde::Deserialize;\n///\n/// #[derive(Deserialize)]\n/// struct Params {\n///     #[serde(default)]\n///     items: Vec<usize>,\n/// }\n///\n/// // This will parse 0 occurrences of `items` as an empty `Vec`.\n/// async fn process_items(Query(params): Query<Params>) {\n///     // ...\n/// }\n///\n/// let app = Router::new().route(\"/process_items\", get(process_items));\n/// # let _: Router = app;\n/// ```\n#[cfg_attr(docsrs, doc(cfg(feature = \"query\")))]\n#[derive(Debug, Clone, Copy, Default)]\npub struct Query<T>(pub T);\n\nimpl<T, S> FromRequestParts<S> for Query<T>\nwhere\n    T: DeserializeOwned,\n    S: Send + Sync,\n{\n    type Rejection = QueryRejection;\n\n    async fn from_request_parts(parts: &mut Parts, _state: &S) -> Result<Self, Self::Rejection> {\n        let query = parts.uri.query().unwrap_or_default();\n        let value = serde_html_form::from_str(query)\n            .map_err(|err| QueryRejection::FailedToDeserializeQueryString(Error::new(err)))?;\n        Ok(Query(value))\n    }\n}\n\naxum_core::__impl_deref!(Query);\n\n/// Rejection used for [`Query`].\n///\n/// Contains one variant for each way the [`Query`] extractor can fail.\n#[derive(Debug)]\n#[non_exhaustive]\n#[cfg(feature = \"query\")]\npub enum QueryRejection {\n    #[allow(missing_docs)]\n    FailedToDeserializeQueryString(Error),\n}\n\nimpl IntoResponse for QueryRejection {\n    fn into_response(self) -> Response {\n        match self {\n            Self::FailedToDeserializeQueryString(inner) => {\n                let body = format!(\"Failed to deserialize query string: {inner}\");\n                let status = StatusCode::BAD_REQUEST;\n                axum_core::__log_rejection!(\n                    rejection_type = Self,\n                    body_text = body,\n                    status = status,\n                );\n                (status, body).into_response()\n            }\n        }\n    }\n}\n\nimpl fmt::Display for QueryRejection {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match self {\n            Self::FailedToDeserializeQueryString(inner) => inner.fmt(f),\n        }\n    }\n}\n\nimpl std::error::Error for QueryRejection {\n    fn source(&self) -> Option<&(dyn std::error::Error + 'static)> {\n        match self {\n            Self::FailedToDeserializeQueryString(inner) => Some(inner),\n        }\n    }\n}\n\n/// Extractor that deserializes query strings into `None` if no query parameters are present.\n/// Otherwise behaviour is identical to [`Query`]\n///\n/// `T` is expected to implement [`serde::Deserialize`].\n///\n/// # Example\n///\n/// ```rust,no_run\n/// use axum::{routing::get, Router};\n/// use axum_extra::extract::OptionalQuery;\n/// use serde::Deserialize;\n///\n/// #[derive(Deserialize)]\n/// struct Pagination {\n///     page: usize,\n///     per_page: usize,\n/// }\n///\n/// // This will parse query strings like `?page=2&per_page=30` into `Some(Pagination)` and\n/// // empty query string into `None`\n/// async fn list_things(OptionalQuery(pagination): OptionalQuery<Pagination>) {\n///     match pagination {\n///         Some(Pagination{ page, per_page }) => { /* return specified page */ },\n///         None => { /* return fist page */ }\n///     }\n///     // ...\n/// }\n///\n/// let app = Router::new().route(\"/list_things\", get(list_things));\n/// # let _: Router = app;\n/// ```\n///\n/// If the query string cannot be parsed it will reject the request with a `400\n/// Bad Request` response.\n///\n/// For handling values being empty vs missing see the [query-params-with-empty-strings][example]\n/// example.\n///\n/// [example]: https://github.com/tokio-rs/axum/blob/main/examples/query-params-with-empty-strings/src/main.rs\n#[cfg_attr(docsrs, doc(cfg(feature = \"query\")))]\n#[derive(Debug, Clone, Copy, Default)]\npub struct OptionalQuery<T>(pub Option<T>);\n\nimpl<T, S> FromRequestParts<S> for OptionalQuery<T>\nwhere\n    T: DeserializeOwned,\n    S: Send + Sync,\n{\n    type Rejection = OptionalQueryRejection;\n\n    async fn from_request_parts(parts: &mut Parts, _state: &S) -> Result<Self, Self::Rejection> {\n        if let Some(query) = parts.uri.query() {\n            let value = serde_html_form::from_str(query).map_err(|err| {\n                OptionalQueryRejection::FailedToDeserializeQueryString(Error::new(err))\n            })?;\n            Ok(OptionalQuery(Some(value)))\n        } else {\n            Ok(OptionalQuery(None))\n        }\n    }\n}\n\nimpl<T> std::ops::Deref for OptionalQuery<T> {\n    type Target = Option<T>;\n\n    #[inline]\n    fn deref(&self) -> &Self::Target {\n        &self.0\n    }\n}\n\nimpl<T> std::ops::DerefMut for OptionalQuery<T> {\n    #[inline]\n    fn deref_mut(&mut self) -> &mut Self::Target {\n        &mut self.0\n    }\n}\n\n/// Rejection used for [`OptionalQuery`].\n///\n/// Contains one variant for each way the [`OptionalQuery`] extractor can fail.\n#[derive(Debug)]\n#[non_exhaustive]\n#[cfg(feature = \"query\")]\npub enum OptionalQueryRejection {\n    #[allow(missing_docs)]\n    FailedToDeserializeQueryString(Error),\n}\n\nimpl IntoResponse for OptionalQueryRejection {\n    fn into_response(self) -> Response {\n        match self {\n            Self::FailedToDeserializeQueryString(inner) => (\n                StatusCode::BAD_REQUEST,\n                format!(\"Failed to deserialize query string: {inner}\"),\n            )\n                .into_response(),\n        }\n    }\n}\n\nimpl fmt::Display for OptionalQueryRejection {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match self {\n            Self::FailedToDeserializeQueryString(inner) => inner.fmt(f),\n        }\n    }\n}\n\nimpl std::error::Error for OptionalQueryRejection {\n    fn source(&self) -> Option<&(dyn std::error::Error + 'static)> {\n        match self {\n            Self::FailedToDeserializeQueryString(inner) => Some(inner),\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::test_helpers::*;\n    use axum::{routing::post, Router};\n    use http::header::CONTENT_TYPE;\n    use serde::Deserialize;\n\n    #[tokio::test]\n    async fn query_supports_multiple_values() {\n        #[derive(Deserialize)]\n        struct Data {\n            #[serde(rename = \"value\")]\n            values: Vec<String>,\n        }\n\n        let app = Router::new().route(\n            \"/\",\n            post(|Query(data): Query<Data>| async move { data.values.join(\",\") }),\n        );\n\n        let client = TestClient::new(app);\n\n        let res = client\n            .post(\"/?value=one&value=two\")\n            .header(CONTENT_TYPE, \"application/x-www-form-urlencoded\")\n            .body(\"\")\n            .await;\n\n        assert_eq!(res.status(), StatusCode::OK);\n        assert_eq!(res.text().await, \"one,two\");\n    }\n\n    #[tokio::test]\n    async fn optional_query_supports_multiple_values() {\n        #[derive(Deserialize)]\n        struct Data {\n            #[serde(rename = \"value\")]\n            values: Vec<String>,\n        }\n\n        let app = Router::new().route(\n            \"/\",\n            post(|OptionalQuery(data): OptionalQuery<Data>| async move {\n                data.map(|Data { values }| values.join(\",\"))\n                    .unwrap_or(\"None\".to_owned())\n            }),\n        );\n\n        let client = TestClient::new(app);\n\n        let res = client\n            .post(\"/?value=one&value=two\")\n            .header(CONTENT_TYPE, \"application/x-www-form-urlencoded\")\n            .body(\"\")\n            .await;\n\n        assert_eq!(res.status(), StatusCode::OK);\n        assert_eq!(res.text().await, \"one,two\");\n    }\n\n    #[tokio::test]\n    async fn optional_query_deserializes_no_parameters_into_none() {\n        #[derive(Deserialize)]\n        struct Data {\n            value: String,\n        }\n\n        let app = Router::new().route(\n            \"/\",\n            post(|OptionalQuery(data): OptionalQuery<Data>| async move {\n                match data {\n                    None => \"None\".into(),\n                    Some(data) => data.value,\n                }\n            }),\n        );\n\n        let client = TestClient::new(app);\n\n        let res = client.post(\"/\").body(\"\").await;\n\n        assert_eq!(res.status(), StatusCode::OK);\n        assert_eq!(res.text().await, \"None\");\n    }\n\n    #[tokio::test]\n    async fn optional_query_preserves_parsing_errors() {\n        #[derive(Deserialize)]\n        struct Data {\n            value: String,\n        }\n\n        let app = Router::new().route(\n            \"/\",\n            post(|OptionalQuery(data): OptionalQuery<Data>| async move {\n                match data {\n                    None => \"None\".into(),\n                    Some(data) => data.value,\n                }\n            }),\n        );\n\n        let client = TestClient::new(app);\n\n        let res = client\n            .post(\"/?other=something\")\n            .header(CONTENT_TYPE, \"application/x-www-form-urlencoded\")\n            .body(\"\")\n            .await;\n\n        assert_eq!(res.status(), StatusCode::BAD_REQUEST);\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "467a331602a37cb36cccf353b1e03768e61cc2af",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/axum/axum-extra/src/extract/cookie/signed.rs",
    "func": "use super::{cookies_from_request, set_cookies};\nuse axum::{\n    extract::{FromRef, FromRequestParts},\n    response::{IntoResponse, IntoResponseParts, Response, ResponseParts},\n};\nuse cookie::SignedJar;\nuse cookie::{Cookie, Key};\nuse http::{request::Parts, HeaderMap};\nuse std::{convert::Infallible, fmt, marker::PhantomData};\n\n/// Extractor that grabs signed cookies from the request and manages the jar.\n///\n/// All cookies will be signed and verified with a [`Key`]. Do not use this to store private data\n/// as the values are still transmitted in plaintext.\n///\n/// Note that methods like [`SignedCookieJar::add`], [`SignedCookieJar::remove`], etc updates the\n/// [`SignedCookieJar`] and returns it. This value _must_ be returned from the handler as part of\n/// the response for the changes to be propagated.\n///\n/// # Example\n///\n/// ```rust\n/// use axum::{\n///     Router,\n///     routing::{post, get},\n///     extract::FromRef,\n///     response::{IntoResponse, Redirect},\n///     http::StatusCode,\n/// };\n/// use axum_extra::{\n///     TypedHeader,\n///     headers::authorization::{Authorization, Bearer},\n///     extract::cookie::{SignedCookieJar, Cookie, Key},\n/// };\n///\n/// async fn create_session(\n///     TypedHeader(auth): TypedHeader<Authorization<Bearer>>,\n///     jar: SignedCookieJar,\n/// ) -> Result<(SignedCookieJar, Redirect), StatusCode> {\n///     if let Some(session_id) = authorize_and_create_session(auth.token()).await {\n///         Ok((\n///             // the updated jar must be returned for the changes\n///             // to be included in the response\n///             jar.add(Cookie::new(\"session_id\", session_id)),\n///             Redirect::to(\"/me\"),\n///         ))\n///     } else {\n///         Err(StatusCode::UNAUTHORIZED)\n///     }\n/// }\n///\n/// async fn me(jar: SignedCookieJar) -> Result<(), StatusCode> {\n///     if let Some(session_id) = jar.get(\"session_id\") {\n///         // fetch and render user...\n///         # Ok(())\n///     } else {\n///         Err(StatusCode::UNAUTHORIZED)\n///     }\n/// }\n///\n/// async fn authorize_and_create_session(token: &str) -> Option<String> {\n///     // authorize the user and create a session...\n///     # todo!()\n/// }\n///\n/// // our application state\n/// #[derive(Clone)]\n/// struct AppState {\n///     // that holds the key used to sign cookies\n///     key: Key,\n/// }\n///\n/// // this impl tells `SignedCookieJar` how to access the key from our state\n/// impl FromRef<AppState> for Key {\n///     fn from_ref(state: &AppState) -> Self {\n///         state.key.clone()\n///     }\n/// }\n///\n/// let state = AppState {\n///     // Generate a secure key\n///     //\n///     // You probably don't wanna generate a new one each time the app starts though\n///     key: Key::generate(),\n/// };\n///\n/// let app = Router::new()\n///     .route(\"/sessions\", post(create_session))\n///     .route(\"/me\", get(me))\n///     .with_state(state);\n/// # let _: axum::Router = app;\n/// ```\n/// If you have been using `Arc<AppState>` you cannot implement `FromRef<Arc<AppState>> for Key`.\n/// You can use a new type instead:\n///\n/// ```rust\n/// # use axum::extract::FromRef;\n/// # use axum_extra::extract::cookie::{PrivateCookieJar, Cookie, Key};\n/// use std::sync::Arc;\n/// use std::ops::Deref;\n///\n/// #[derive(Clone)]\n/// struct AppState(Arc<InnerState>);\n///\n/// // deref so you can still access the inner fields easily\n/// impl Deref for AppState {\n///     type Target = InnerState;\n///\n///     fn deref(&self) -> &Self::Target {\n///         &*self.0\n///     }\n/// }\n///\n/// struct InnerState {\n///     key: Key\n/// }\n///\n/// impl FromRef<AppState> for Key {\n///     fn from_ref(state: &AppState) -> Self {\n///         state.0.key.clone()\n///     }\n/// }\n/// ```\npub struct SignedCookieJar<K = Key> {\n    jar: cookie::CookieJar,\n    key: Key,\n    // The key used to extract the key. Allows users to use multiple keys for different\n    // jars. Maybe a library wants its own key.\n    _marker: PhantomData<K>,\n}\n\nimpl<K> fmt::Debug for SignedCookieJar<K> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"SignedCookieJar\")\n            .field(\"jar\", &self.jar)\n            .field(\"key\", &\"REDACTED\")\n            .finish()\n    }\n}\n\nimpl<S, K> FromRequestParts<S> for SignedCookieJar<K>\nwhere\n    S: Send + Sync,\n    K: FromRef<S> + Into<Key>,\n{\n    type Rejection = Infallible;\n\n    async fn from_request_parts(parts: &mut Parts, state: &S) -> Result<Self, Self::Rejection> {\n        let k = K::from_ref(state);\n        let key = k.into();\n        let SignedCookieJar {\n            jar,\n            key,\n            _marker: _,\n        } = SignedCookieJar::from_headers(&parts.headers, key);\n        Ok(SignedCookieJar {\n            jar,\n            key,\n            _marker: PhantomData,\n        })\n    }\n}\n\nimpl SignedCookieJar {\n    /// Create a new `SignedCookieJar` from a map of request headers.\n    ///\n    /// The valid cookies in `headers` will be added to the jar.\n    ///\n    /// This is intended to be used in middleware and other places where it might be difficult to\n    /// run extractors. Normally you should create `SignedCookieJar`s through [`FromRequestParts`].\n    ///\n    /// [`FromRequestParts`]: axum::extract::FromRequestParts\n    pub fn from_headers(headers: &HeaderMap, key: Key) -> Self {\n        let mut jar = cookie::CookieJar::new();\n        let mut signed_jar = jar.signed_mut(&key);\n        for cookie in cookies_from_request(headers) {\n            if let Some(cookie) = signed_jar.verify(cookie) {\n                signed_jar.add_original(cookie);\n            }\n        }\n\n        Self {\n            jar,\n            key,\n            _marker: PhantomData,\n        }\n    }\n\n    /// Create a new empty `SignedCookieJar`.\n    ///\n    /// This is intended to be used in middleware and other places where it might be difficult to\n    /// run extractors. Normally you should create `SignedCookieJar`s through [`FromRequestParts`].\n    ///\n    /// [`FromRequestParts`]: axum::extract::FromRequestParts\n    pub fn new(key: Key) -> Self {\n        Self {\n            jar: Default::default(),\n            key,\n            _marker: PhantomData,\n        }\n    }\n}\n\nimpl<K> SignedCookieJar<K> {\n    /// Get a cookie from the jar.\n    ///\n    /// If the cookie exists and its authenticity and integrity can be verified then it is returned\n    /// in plaintext.\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// use axum_extra::extract::cookie::SignedCookieJar;\n    /// use axum::response::IntoResponse;\n    ///\n    /// async fn handle(jar: SignedCookieJar) {\n    ///     let value: Option<String> = jar\n    ///         .get(\"foo\")\n    ///         .map(|cookie| cookie.value().to_owned());\n    /// }\n    /// ```\n    pub fn get(&self, name: &str) -> Option<Cookie<'static>> {\n        self.signed_jar().get(name)\n    }\n\n    /// Remove a cookie from the jar.\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// use axum_extra::extract::cookie::{SignedCookieJar, Cookie};\n    /// use axum::response::IntoResponse;\n    ///\n    /// async fn handle(jar: SignedCookieJar) -> SignedCookieJar {\n    ///     jar.remove(Cookie::from(\"foo\"))\n    /// }\n    /// ```\n    #[must_use]\n    pub fn remove<C: Into<Cookie<'static>>>(mut self, cookie: C) -> Self {\n        self.signed_jar_mut().remove(cookie);\n        self\n    }\n\n    /// Add a cookie to the jar.\n    ///\n    /// The value will automatically be percent-encoded.\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// use axum_extra::extract::cookie::{SignedCookieJar, Cookie};\n    /// use axum::response::IntoResponse;\n    ///\n    /// async fn handle(jar: SignedCookieJar) -> SignedCookieJar {\n    ///     jar.add(Cookie::new(\"foo\", \"bar\"))\n    /// }\n    /// ```\n    #[must_use]\n    #[allow(clippy::should_implement_trait)]\n    pub fn add<C: Into<Cookie<'static>>>(mut self, cookie: C) -> Self {\n        self.signed_jar_mut().add(cookie);\n        self\n    }\n\n    /// Verifies the authenticity and integrity of `cookie`, returning the plaintext version if\n    /// verification succeeds or `None` otherwise.\n    pub fn verify(&self, cookie: Cookie<'static>) -> Option<Cookie<'static>> {\n        self.signed_jar().verify(cookie)\n    }\n\n    /// Get an iterator over all cookies in the jar.\n    ///\n    /// Only cookies with valid authenticity and integrity are yielded by the iterator.\n    pub fn iter(&self) -> impl Iterator<Item = Cookie<'static>> + '_ {\n        SignedCookieJarIter {\n            jar: self,\n            iter: self.jar.iter(),\n        }\n    }\n\n    fn signed_jar(&self) -> SignedJar<&'_ cookie::CookieJar> {\n        self.jar.signed(&self.key)\n    }\n\n    fn signed_jar_mut(&mut self) -> SignedJar<&'_ mut cookie::CookieJar> {\n        self.jar.signed_mut(&self.key)\n    }\n}\n\nimpl<K> IntoResponseParts for SignedCookieJar<K> {\n    type Error = Infallible;\n\n    fn into_response_parts(self, mut res: ResponseParts) -> Result<ResponseParts, Self::Error> {\n        set_cookies(self.jar, res.headers_mut());\n        Ok(res)\n    }\n}\n\nimpl<K> IntoResponse for SignedCookieJar<K> {\n    fn into_response(self) -> Response {\n        (self, ()).into_response()\n    }\n}\n\nstruct SignedCookieJarIter<'a, K> {\n    jar: &'a SignedCookieJar<K>,\n    iter: cookie::Iter<'a>,\n}\n\nimpl<K> Iterator for SignedCookieJarIter<'_, K> {\n    type Item = Cookie<'static>;\n\n    fn next(&mut self) -> Option<Self::Item> {\n        loop {\n            let cookie = self.iter.next()?;\n\n            if let Some(cookie) = self.jar.get(cookie.name()) {\n                return Some(cookie);\n            }\n        }\n    }\n}\n\nimpl<K> Clone for SignedCookieJar<K> {\n    fn clone(&self) -> Self {\n        Self {\n            jar: self.jar.clone(),\n            key: self.key.clone(),\n            _marker: self._marker,\n        }\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "177ec7887cb42aa5dfd4c4f763cc38532bd833d3",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/Rocket/examples/databases/src/tests.rs",
    "func": "use rocket::fairing::AdHoc;\nuse rocket::local::blocking::Client;\nuse rocket::serde::{Serialize, Deserialize};\nuse rocket::http::Status;\n\n#[derive(Debug, Clone, PartialEq, Deserialize, Serialize)]\n#[serde(crate = \"rocket::serde\")]\nstruct Post {\n    title: String,\n    text: String,\n}\n\nfn test(base: &str, stage: AdHoc) {\n    // Number of posts we're going to create/read/delete.\n    const N: usize = 20;\n\n    // NOTE: If we had more than one test running concurrently that dispatches\n    // DB-accessing requests, we'd need transactions or to serialize all tests.\n    let client = Client::tracked(rocket::build().attach(stage)).unwrap();\n\n    // Clear everything from the database.\n    assert_eq!(client.delete(base).dispatch().status(), Status::Ok);\n    assert_eq!(client.get(base).dispatch().into_json::<Vec<i64>>(), Some(vec![]));\n\n    // Add some random posts, ensure they're listable and readable.\n    for i in 1..=N{\n        let title = format!(\"My Post - {}\", i);\n        let text = format!(\"Once upon a time, at {}'o clock...\", i);\n        let post = Post { title: title.clone(), text: text.clone() };\n\n        // Create a new post.\n        let response = client.post(base).json(&post).dispatch().into_json::<Post>();\n        assert_eq!(response.unwrap(), post);\n\n        // Ensure the index shows one more post.\n        let list = client.get(base).dispatch().into_json::<Vec<i64>>().unwrap();\n        assert_eq!(list.len(), i);\n\n        // The last in the index is the new one; ensure contents match.\n        let last = list.last().unwrap();\n        let response = client.get(format!(\"{}/{}\", base, last)).dispatch();\n        assert_eq!(response.into_json::<Post>().unwrap(), post);\n    }\n\n    // Now delete all of the posts.\n    for _ in 1..=N {\n        // Get a valid ID from the index.\n        let list = client.get(base).dispatch().into_json::<Vec<i64>>().unwrap();\n        let id = list.first().expect(\"have post\");\n\n        // Delete that post.\n        let response = client.delete(format!(\"{}/{}\", base, id)).dispatch();\n        assert_eq!(response.status(), Status::Ok);\n    }\n\n    // Ensure they're all gone.\n    let list = client.get(base).dispatch().into_json::<Vec<i64>>().unwrap();\n    assert!(list.is_empty());\n\n    // Trying to delete should now 404.\n    let response = client.delete(format!(\"{}/{}\", base, 1)).dispatch();\n    assert_eq!(response.status(), Status::NotFound);\n}\n\n#[test]\nfn test_sqlx() {\n    test(\"/sqlx\", crate::sqlx::stage())\n}\n\n#[test]\nfn test_diesel() {\n    test(\"/diesel\", crate::diesel_sqlite::stage())\n}\n\n#[test]\nfn test_rusqlite() {\n    test(\"/rusqlite\", crate::rusqlite::stage())\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "38dcc65aa935d27ac1be4c78aa8bfd4361577f75",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/Rocket/examples/static-files/src/main.rs",
    "func": "#[cfg(test)] mod tests;\n\nuse rocket::fs::{FileServer, relative};\n\n// If we wanted or needed to serve files manually, we'd use `NamedFile`. Always\n// prefer to use `FileServer`!\nmod manual {\n    use std::path::{PathBuf, Path};\n    use rocket::fs::NamedFile;\n\n    #[rocket::get(\"/second/<path..>\")]\n    pub async fn second(path: PathBuf) -> Option<NamedFile> {\n        let mut path = Path::new(super::relative!(\"static\")).join(path);\n        if path.is_dir() {\n            path.push(\"index.html\");\n        }\n\n        NamedFile::open(path).await.ok()\n    }\n}\n\n#[rocket::launch]\nfn rocket() -> _ {\n    rocket::build()\n        .mount(\"/\", rocket::routes![manual::second])\n        .mount(\"/\", FileServer::new(relative!(\"static\")))\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "1663ad86d558ad74868d990e4f6d33488233ae54",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/Rocket/core/lib/tests/byte-slices-form-field-issue-2148.rs",
    "func": "#[macro_use] extern crate rocket;\n\nuse std::str::from_utf8;\n\nuse rocket::form::Form;\nuse rocket::http::{ContentType, Status};\nuse rocket::local::blocking::Client;\n\n#[derive(FromForm)]\nstruct DataForm<'r> {\n    foo: &'r [u8],\n    bar: &'r [u8],\n}\n\n#[post(\"/\", data = \"<form>\")]\nfn form(form: Form<DataForm<'_>>) -> String {\n    from_utf8(form.foo).unwrap().to_string() + from_utf8(form.bar).unwrap()\n}\n\n#[test]\nfn test_from_form_fields_of_multipart_files_into_byte_slices() {\n    let body = &[\n        \"--X-BOUNDARY\",\n        r#\"Content-Disposition: form-data; name=\"foo\"; filename=\"foo.txt\"\"#,\n        \"Content-Type: text/plain\",\n        \"\",\n        \"start>\",\n        \"--X-BOUNDARY\",\n        r#\"Content-Disposition: form-data; name=\"foo\"; filename=\"foo2.txt\"\"#,\n        \"Content-Type: text/plain\",\n        \"\",\n        \"second-start...\",\n        \"--X-BOUNDARY\",\n        r#\"Content-Disposition: form-data; name=\"bar\"; filename=\"bar.txt\"\"#,\n        \"Content-Type: text/plain\",\n        \"\",\n        \"<finish\",\n        \"--X-BOUNDARY--\",\n        \"\",\n    ].join(\"\\r\\n\");\n\n    let client = Client::debug_with(routes![form]).unwrap();\n    let response = client.post(\"/\")\n        .header(\"multipart/form-data; boundary=X-BOUNDARY\".parse::<ContentType>().unwrap())\n        .body(body)\n        .dispatch();\n\n    assert_eq!(response.status(), Status::Ok);\n    assert_eq!(response.into_string().unwrap(), \"start><finish\");\n}\n\n#[test]\nfn test_from_form_fields_of_values_into_byte_slices() {\n    let client = Client::debug_with(routes![form]).unwrap();\n    let response = client.post(\"/\")\n        .header(ContentType::Form)\n        .body(format!(\"bar={}&foo={}\", \"...finish\", \"start...\"))\n        .dispatch();\n\n    assert_eq!(response.status(), Status::Ok);\n    assert_eq!(response.into_string().unwrap(), \"start......finish\");\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "4a50205984e50b92ef55b57c17f6f2beec1fe4ac",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/Rocket/core/lib/tests/config-proxy-proto-header.rs",
    "func": "#[macro_use] extern crate rocket;\n\n#[get(\"/\")]\nfn inspect_proto(proto: rocket::http::ProxyProto<'_>) -> String {\n    proto.to_string()\n}\n\nmod tests {\n    use rocket::{Rocket, Build, Route};\n    use rocket::http::{Header, Status};\n    use rocket::local::blocking::Client;\n    use rocket::figment::Figment;\n\n    fn routes() -> Vec<Route> {\n        routes![super::inspect_proto]\n    }\n\n    fn rocket_with_proto_header(header: Option<&'static str>) -> Rocket<Build> {\n        let mut config = rocket::Config::debug_default();\n        config.proxy_proto_header = header.map(|h| h.into());\n        rocket::custom(config).mount(\"/\", routes())\n    }\n\n    #[test]\n    fn check_proxy_proto_header_works() {\n        let client = Client::debug(rocket_with_proto_header(Some(\"X-Url-Scheme\"))).unwrap();\n        let response = client.get(\"/\")\n            .header(Header::new(\"X-Forwarded-Proto\", \"https\"))\n            .header(Header::new(\"X-Url-Scheme\", \"http\"))\n            .dispatch();\n\n        assert_eq!(response.into_string().unwrap(), \"http\");\n\n        let response = client.get(\"/\").header(Header::new(\"X-Url-Scheme\", \"https\")).dispatch();\n        assert_eq!(response.into_string().unwrap(), \"https\");\n\n        let response = client.get(\"/\").dispatch();\n        assert_eq!(response.status(), Status::InternalServerError);\n    }\n\n    #[test]\n    fn check_proxy_proto_header_works_again() {\n        let client = Client::debug(rocket_with_proto_header(Some(\"x-url-scheme\"))).unwrap();\n        let response = client.get(\"/\")\n            .header(Header::new(\"X-Url-Scheme\", \"hTTpS\"))\n            .dispatch();\n\n        assert_eq!(response.into_string().unwrap(), \"https\");\n\n        let config = Figment::from(rocket::Config::debug_default())\n            .merge((\"proxy_proto_header\", \"x-url-scheme\"));\n\n        let client = Client::debug(rocket::custom(config).mount(\"/\", routes())).unwrap();\n        let response = client.get(\"/\")\n            .header(Header::new(\"X-url-Scheme\", \"HTTPS\"))\n            .dispatch();\n\n        assert_eq!(response.into_string().unwrap(), \"https\");\n    }\n\n    #[test]\n    fn check_default_proxy_proto_header_works() {\n        let client = Client::debug_with(routes()).unwrap();\n        let response = client.get(\"/\")\n            .header(Header::new(\"X-Forwarded-Proto\", \"https\"))\n            .dispatch();\n\n        assert_eq!(response.status(), Status::InternalServerError);\n    }\n\n    #[test]\n    fn check_no_proxy_proto_header_works() {\n        let client = Client::debug(rocket_with_proto_header(None)).unwrap();\n        let response = client.get(\"/\")\n            .header(Header::new(\"X-Forwarded-Proto\", \"https\"))\n            .dispatch();\n\n        assert_eq!(response.status(), Status::InternalServerError);\n\n        let config =\n            Figment::from(rocket::Config::debug_default()).merge((\"proxy_proto_header\", false));\n\n        let client = Client::debug(rocket::custom(config).mount(\"/\", routes())).unwrap();\n        let response = client.get(\"/\")\n            .header(Header::new(\"X-Forwarded-Proto\", \"https\"))\n            .dispatch();\n\n        assert_eq!(response.status(), Status::InternalServerError);\n\n        let config = Figment::from(rocket::Config::debug_default())\n            .merge((\"proxy_proto_header\", \"x-forwarded-proto\"));\n\n        let client = Client::debug(rocket::custom(config).mount(\"/\", routes())).unwrap();\n        let response = client.get(\"/\")\n            .header(Header::new(\"x-Forwarded-Proto\", \"https\"))\n            .dispatch();\n\n        assert_eq!(response.into_string(), Some(\"https\".into()));\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "7a0fd0f635004f277940f2fcc82345e3865b2a03",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/Rocket/core/lib/tests/absolute-uris-okay-issue-443.rs",
    "func": "#[macro_use] extern crate rocket;\n\nuse rocket::response::Redirect;\n\n#[get(\"/http\")]\nfn http() -> Redirect {\n    Redirect::to(uri!(\"http://rocket.rs\"))\n}\n\n#[get(\"/rocket\")]\nfn redirect() -> Redirect {\n    Redirect::to(\"https://rocket.rs:80\")\n}\n\nmod test_absolute_uris_okay {\n    use super::*;\n    use rocket::local::blocking::Client;\n\n    #[test]\n    fn redirect_works() {\n        let client = Client::debug_with(routes![http, redirect]).unwrap();\n\n        let response = client.get(uri!(http)).dispatch();\n        let location = response.headers().get_one(\"Location\");\n        assert_eq!(location, Some(\"http://rocket.rs\"));\n\n        let response = client.get(uri!(redirect)).dispatch();\n        let location = response.headers().get_one(\"Location\");\n        assert_eq!(location, Some(\"https://rocket.rs:80\"));\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "dc63d234fa8a23fddb168581afaac9358913f2bc",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/Rocket/core/lib/src/trace/level.rs",
    "func": "use std::fmt;\n\nuse serde::{de, Serialize, Deserializer, Serializer};\nuse tracing::{level_filters::LevelFilter, Level};\n\npub fn serialize<S: Serializer>(level: &Option<Level>, s: S) -> Result<S::Ok, S::Error> {\n    LevelFilter::from(*level).to_string().serialize(s)\n}\n\npub fn deserialize<'de, D: Deserializer<'de>>(de: D) -> Result<Option<Level>, D::Error> {\n    struct Visitor;\n\n    const E: &str = r#\"one of \"off\", \"error\", \"warn\", \"info\", \"debug\", \"trace\", or 0-5\"#;\n\n    impl<'de> de::Visitor<'de> for Visitor {\n        type Value = Option<Level>;\n\n        fn expecting(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n            write!(f, \"expected {E}\")\n        }\n\n        fn visit_i64<E: de::Error>(self, v: i64) -> Result<Self::Value, E> {\n            v.try_into()\n                .map_err(|_| E::invalid_value(de::Unexpected::Signed(v), &E))\n                .and_then(|v| self.visit_u64(v))\n        }\n\n        fn visit_u64<E: de::Error>(self, v: u64) -> Result<Self::Value, E> {\n            let filter = match v {\n                0 => LevelFilter::OFF,\n                1 => LevelFilter::ERROR,\n                2 => LevelFilter::WARN,\n                3 => LevelFilter::INFO,\n                4 => LevelFilter::DEBUG,\n                5 => LevelFilter::TRACE,\n                _ => return Err(E::invalid_value(de::Unexpected::Unsigned(v), &E)),\n            };\n\n            Ok(filter.into_level())\n        }\n\n        fn visit_str<E: de::Error>(self, v: &str) -> Result<Self::Value, E> {\n            v.parse::<LevelFilter>()\n                .map(|f| f.into_level())\n                .map_err(|_| E::invalid_value(de::Unexpected::Str(v), &E))\n        }\n    }\n\n    de.deserialize_map(Visitor)\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "e661bd7cfe227fc6909e540a7dd310bd12934100",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/Rocket/core/lib/src/request/atomic_method.rs",
    "func": "use crate::http::Method;\n\npub struct AtomicMethod(ref_swap::RefSwap<'static, Method>);\n\nimpl AtomicMethod {\n    #[inline]\n    pub fn new(value: Method) -> Self {\n        Self(ref_swap::RefSwap::new(value.as_ref()))\n    }\n\n    #[inline]\n    pub fn load(&self) -> Method {\n        *self.0.load(std::sync::atomic::Ordering::Acquire)\n    }\n\n    #[inline]\n    pub fn set(&mut self, new: Method) {\n        *self = Self::new(new);\n    }\n\n    #[inline]\n    pub fn store(&self, new: Method) {\n        self.0.store(new.as_ref(), std::sync::atomic::Ordering::Release)\n    }\n}\n\nimpl Clone for AtomicMethod {\n    fn clone(&self) -> Self {\n        let inner = self.0.load(std::sync::atomic::Ordering::Acquire);\n        Self(ref_swap::RefSwap::new(inner))\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "12fb26fcb62fba66419352cd747cae5bc4bdbb68",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/Rocket/core/lib/src/fs/rewrite.rs",
    "func": "use std::borrow::Cow;\nuse std::path::{Path, PathBuf};\n\nuse crate::Request;\nuse crate::http::{ext::IntoOwned, HeaderMap};\nuse crate::response::Redirect;\n\n/// A file server [`Rewrite`] rewriter.\n///\n/// A [`FileServer`] is a sequence of [`Rewriter`]s which transform the incoming\n/// request path into a [`Rewrite`] or `None`. The first rewriter is called with\n/// the request path as a [`Rewrite::File`]. Each `Rewriter` thereafter is\n/// called in-turn with the previously returned [`Rewrite`], and the value\n/// returned from the last `Rewriter` is used to respond to the request. If the\n/// final rewrite is `None` or a nonexistent path or a directory, [`FileServer`]\n/// responds with [`Status::NotFound`]. Otherwise it responds with the file\n/// contents, if [`Rewrite::File`] is specified, or a redirect, if\n/// [`Rewrite::Redirect`] is specified.\n///\n/// [`FileServer`]: super::FileServer\n/// [`Status::NotFound`]: crate::http::Status::NotFound\npub trait Rewriter: Send + Sync + 'static {\n    /// Alter the [`Rewrite`] as needed.\n    fn rewrite<'r>(&self, opt: Option<Rewrite<'r>>, req: &'r Request<'_>) -> Option<Rewrite<'r>>;\n}\n\n/// A Response from a [`FileServer`](super::FileServer)\n#[derive(Debug, Clone)]\n#[non_exhaustive]\npub enum Rewrite<'r> {\n    /// Return the contents of the specified file.\n    File(File<'r>),\n    /// Returns a Redirect.\n    Redirect(Redirect),\n}\n\n/// A File response from a [`FileServer`](super::FileServer) and a rewriter.\n#[derive(Debug, Clone)]\n#[non_exhaustive]\npub struct File<'r> {\n    /// The path to the file that [`FileServer`](super::FileServer) will respond with.\n    pub path: Cow<'r, Path>,\n    /// A list of headers to be added to the generated response.\n    pub headers: HeaderMap<'r>,\n}\n\nimpl<'r> File<'r> {\n    /// A new `File`, with not additional headers.\n    pub fn new(path: impl Into<Cow<'r, Path>>) -> Self {\n        Self { path: path.into(), headers: HeaderMap::new() }\n    }\n\n    /// A new `File`, with not additional headers.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the `path` does not exist.\n    pub fn checked<P: AsRef<Path>>(path: P) -> Self {\n        let path = path.as_ref();\n        if !path.exists() {\n            let path = path.display();\n            error!(%path, \"FileServer path does not exist.\\n\\\n                Panicking to prevent inevitable handler error.\");\n            panic!(\"missing file {}: refusing to continue\", path);\n        }\n\n        Self::new(path.to_path_buf())\n    }\n\n    /// Replace the path in `self` with the result of applying `f` to the path.\n    pub fn map_path<F, P>(self, f: F) -> Self\n        where F: FnOnce(Cow<'r, Path>) -> P, P: Into<Cow<'r, Path>>,\n    {\n        Self {\n            path: f(self.path).into(),\n            headers: self.headers,\n        }\n    }\n\n    /// Returns `true` if the file is a dotfile. A dotfile is a file whose\n    /// name or any directory in it's path start with a period (`.`) and is\n    /// considered hidden.\n    ///\n    /// # Windows Note\n    ///\n    /// This does *not* check the file metadata on any platform, so hidden files\n    /// on Windows will not be detected by this method.\n    pub fn is_hidden(&self) -> bool {\n        self.path.iter().any(|s| s.as_encoded_bytes().starts_with(b\".\"))\n    }\n\n    /// Returns `true` if the file is not hidden. This is the inverse of\n    /// [`File::is_hidden()`].\n    pub fn is_visible(&self) -> bool {\n        !self.is_hidden()\n    }\n}\n\n/// Prefixes all paths with a given path.\n///\n/// # Example\n///\n/// ```rust,no_run\n/// use rocket::fs::FileServer;\n/// use rocket::fs::rewrite::Prefix;\n///\n/// FileServer::identity()\n///    .filter(|f, _| f.is_visible())\n///    .rewrite(Prefix::checked(\"static\"));\n/// ```\npub struct Prefix(PathBuf);\n\nimpl Prefix {\n    /// Panics if `path` does not exist.\n    pub fn checked<P: AsRef<Path>>(path: P) -> Self {\n        let path = path.as_ref();\n        if !path.is_dir() {\n            let path = path.display();\n            error!(%path, \"FileServer path is not a directory.\");\n            warn!(\"Aborting early to prevent inevitable handler error.\");\n            panic!(\"invalid directory: refusing to continue\");\n        }\n\n        Self(path.to_path_buf())\n    }\n\n    /// Creates a new `Prefix` from a path.\n    pub fn unchecked<P: AsRef<Path>>(path: P) -> Self {\n        Self(path.as_ref().to_path_buf())\n    }\n}\n\nimpl Rewriter for Prefix {\n    fn rewrite<'r>(&self, opt: Option<Rewrite<'r>>, _: &Request<'_>) -> Option<Rewrite<'r>> {\n        opt.map(|r| match r {\n            Rewrite::File(f) => Rewrite::File(f.map_path(|p| self.0.join(p))),\n            Rewrite::Redirect(r) => Rewrite::Redirect(r),\n        })\n    }\n}\n\nimpl Rewriter for PathBuf {\n    fn rewrite<'r>(&self, _: Option<Rewrite<'r>>, _: &Request<'_>) -> Option<Rewrite<'r>> {\n        Some(Rewrite::File(File::new(self.clone())))\n    }\n}\n\n/// Normalize directories to always include a trailing slash by redirecting\n/// (with a 302 temporary redirect) requests for directories without a trailing\n/// slash to the same path with a trailing slash.\n///\n/// # Example\n///\n/// ```rust,no_run\n/// use rocket::fs::FileServer;\n/// use rocket::fs::rewrite::{Prefix, TrailingDirs};\n///\n/// FileServer::identity()\n///     .filter(|f, _| f.is_visible())\n///     .rewrite(TrailingDirs);\n/// ```\npub struct TrailingDirs;\n\nimpl Rewriter for TrailingDirs {\n    fn rewrite<'r>(&self, opt: Option<Rewrite<'r>>, req: &Request<'_>) -> Option<Rewrite<'r>> {\n        if let Some(Rewrite::File(f)) = &opt {\n            if !req.uri().path().ends_with('/') && f.path.is_dir() {\n                let uri = req.uri().clone().into_owned();\n                let uri = uri.map_path(|p| format!(\"{p}/\")).unwrap();\n                return Some(Rewrite::Redirect(Redirect::temporary(uri)));\n            }\n        }\n\n        opt\n    }\n}\n\n/// Rewrite a directory to a file inside of that directory.\n///\n/// # Example\n///\n/// Rewrites all directory requests to `directory/index.html`.\n///\n/// ```rust,no_run\n/// use rocket::fs::FileServer;\n/// use rocket::fs::rewrite::DirIndex;\n///\n/// FileServer::without_index(\"static\")\n///     .rewrite(DirIndex::if_exists(\"index.htm\"))\n///     .rewrite(DirIndex::unconditional(\"index.html\"));\n/// ```\npub struct DirIndex {\n    path: PathBuf,\n    check: bool,\n}\n\nimpl DirIndex {\n    /// Appends `path` to every request for a directory.\n    pub fn unconditional(path: impl AsRef<Path>) -> Self {\n        Self { path: path.as_ref().to_path_buf(), check: false }\n    }\n\n    /// Only appends `path` to a request for a directory if the file exists.\n    pub fn if_exists(path: impl AsRef<Path>) -> Self {\n        Self { path: path.as_ref().to_path_buf(), check: true }\n    }\n}\n\nimpl Rewriter for DirIndex {\n    fn rewrite<'r>(&self, opt: Option<Rewrite<'r>>, _: &Request<'_>) -> Option<Rewrite<'r>> {\n        match opt? {\n            Rewrite::File(f) if f.path.is_dir() => {\n                let candidate = f.path.join(&self.path);\n                if self.check && !candidate.is_file() {\n                    return Some(Rewrite::File(f));\n                }\n\n                Some(Rewrite::File(f.map_path(|_| candidate)))\n            }\n            r => Some(r),\n        }\n    }\n}\n\nimpl<'r> From<File<'r>> for Rewrite<'r> {\n    fn from(value: File<'r>) -> Self {\n        Self::File(value)\n    }\n}\n\nimpl<'r> From<Redirect> for Rewrite<'r> {\n    fn from(value: Redirect) -> Self {\n        Self::Redirect(value)\n    }\n}\n\nimpl<F: Send + Sync + 'static> Rewriter for F\n    where F: for<'r> Fn(Option<Rewrite<'r>>, &Request<'_>) -> Option<Rewrite<'r>>\n{\n    fn rewrite<'r>(&self, f: Option<Rewrite<'r>>, r: &Request<'_>) -> Option<Rewrite<'r>> {\n        self(f, r)\n    }\n}\n\nimpl Rewriter for Rewrite<'static> {\n    fn rewrite<'r>(&self, _: Option<Rewrite<'r>>, _: &Request<'_>) -> Option<Rewrite<'r>> {\n        Some(self.clone())\n    }\n}\n\nimpl Rewriter for File<'static> {\n    fn rewrite<'r>(&self, _: Option<Rewrite<'r>>, _: &Request<'_>) -> Option<Rewrite<'r>> {\n        Some(Rewrite::File(self.clone()))\n    }\n}\n\nimpl Rewriter for Redirect {\n    fn rewrite<'r>(&self, _: Option<Rewrite<'r>>, _: &Request<'_>) -> Option<Rewrite<'r>> {\n        Some(Rewrite::Redirect(self.clone()))\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "fa1f2ff3247f7f7255698d3453921c7c6c431b58",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/Rocket/core/lib/src/config/http_header.rs",
    "func": "use std::fmt;\n\nuse serde::de;\n\nuse crate::http::Header;\nuse crate::http::uncased::Uncased;\n\npub(crate) fn deserialize<'de, D>(de: D) -> Result<Option<Uncased<'static>>, D::Error>\n    where D: de::Deserializer<'de>\n{\n    struct Visitor;\n\n    impl<'de> de::Visitor<'de> for Visitor {\n        type Value = Option<Uncased<'static>>;\n\n        fn expecting(&self, formatter: &mut fmt::Formatter<'_>) -> fmt::Result {\n            formatter.write_str(\"a valid header name or `false`\")\n        }\n\n        fn visit_bool<E: de::Error>(self, v: bool) -> Result<Self::Value, E> {\n            if !v {\n                return Ok(None);\n            }\n\n            Err(E::invalid_value(de::Unexpected::Bool(v), &self))\n        }\n\n        fn visit_some<D>(self, de: D) -> Result<Self::Value, D::Error>\n            where D: de::Deserializer<'de>\n        {\n            de.deserialize_string(self)\n        }\n\n        fn visit_none<E: de::Error>(self) -> Result<Self::Value, E> {\n            Ok(None)\n        }\n\n        fn visit_unit<E: de::Error>(self) -> Result<Self::Value, E> {\n            Ok(None)\n        }\n\n        fn visit_str<E: de::Error>(self, v: &str) -> Result<Self::Value, E> {\n            self.visit_string(v.into())\n        }\n\n        fn visit_string<E: de::Error>(self, v: String) -> Result<Self::Value, E> {\n            if Header::is_valid_name(&v) {\n                Ok(Some(Uncased::from_owned(v)))\n            } else {\n                Err(E::invalid_value(de::Unexpected::Str(&v), &self))\n            }\n        }\n    }\n\n    de.deserialize_string(Visitor)\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "fd82c556803d17099515b2f675b950841bc3916b",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/Rocket/core/codegen/tests/ui-fail-nightly/bad-ignored-segments.rs",
    "func": "#[macro_use] extern crate rocket;\n\n#[get(\"/<_>\")]\nfn i0() {}\n\n#[get(\"/c?<_>\")]\nfn i1() {}\n\n#[post(\"/d\", data = \"<_>\")]\nfn i2() {}\n\nfn main() {  }\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "0cb4e7333b37b7a961f6176a7739414ba2c05fe7",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/Rocket/core/codegen/src/proc_macro_ext.rs",
    "func": "use std::ops::RangeBounds;\n\nuse devise::Diagnostic;\nuse proc_macro2::{Span, Literal};\n\n// An experiment.\npub struct Diagnostics(Vec<Diagnostic>);\n\nimpl Diagnostics {\n    pub fn new() -> Self {\n        Diagnostics(vec![])\n    }\n\n    pub fn push(&mut self, diag: Diagnostic) {\n        self.0.push(diag);\n    }\n\n    pub fn emit_head(self) -> Diagnostic {\n        let mut iter = self.0.into_iter();\n        let mut last = iter.next().expect(\"Diagnostic::emit_head empty\");\n        for diag in iter {\n            // FIXME(diag: emit, can there be errors here?)\n            last.emit_as_item_tokens();\n            last = diag;\n        }\n\n        last\n    }\n\n    pub fn head_err_or<T>(self, ok: T) -> devise::Result<T> {\n        match self.0.is_empty() {\n            true => Ok(ok),\n            false => Err(self.emit_head())\n        }\n    }\n}\n\nimpl From<Diagnostic> for Diagnostics {\n    fn from(diag: Diagnostic) -> Self {\n        Diagnostics(vec![diag])\n    }\n}\n\nimpl From<Vec<Diagnostic>> for Diagnostics {\n    fn from(diags: Vec<Diagnostic>) -> Self {\n        Diagnostics(diags)\n    }\n}\n\npub struct StringLit(pub String, pub Literal);\n\nimpl StringLit {\n    pub fn new<S: Into<String>>(string: S, span: Span) -> Self {\n        let string = string.into();\n        let mut lit = Literal::string(&string);\n        lit.set_span(span);\n        StringLit(string, lit)\n    }\n\n    pub fn span(&self) -> Span {\n        self.1.span()\n    }\n\n    /// Attempt to obtain a subspan, or, failing that, produce the full span.\n    /// This will create suboptimal diagnostics, but better than failing to\n    /// build entirely.\n    pub fn subspan<R: RangeBounds<usize>>(&self, range: R) -> Span {\n        self.1.subspan(range).unwrap_or_else(|| self.span())\n    }\n}\n\nimpl syn::parse::Parse for StringLit {\n    fn parse(input: syn::parse::ParseStream<'_>) -> syn::Result<Self> {\n        let lit = input.parse::<syn::LitStr>()?;\n        Ok(StringLit::new(lit.value(), lit.span()))\n    }\n}\n\nimpl devise::FromMeta for StringLit {\n    fn from_meta(meta: &devise::MetaItem) -> devise::Result<Self> {\n        Ok(StringLit::new(String::from_meta(meta)?, meta.value_span()))\n    }\n}\n\nimpl std::ops::Deref for StringLit {\n    type Target = str;\n\n    fn deref(&self) -> &str {\n        &self.0\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "38614e8dd442e900a8acacab6081c71b99341164",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/Rocket/core/codegen/src/syn_ext.rs",
    "func": "//! Extensions to `syn` types.\n\nuse std::ops::Deref;\nuse std::hash::{Hash, Hasher};\nuse std::borrow::Cow;\n\nuse syn::{Ident, ext::IdentExt as _, visit::Visit};\nuse proc_macro2::{Span, TokenStream};\nuse devise::ext::{PathExt, TypeExt as _};\nuse rocket_http::ext::IntoOwned;\n\npub trait IdentExt {\n    fn prepend(&self, string: &str) -> syn::Ident;\n    fn append(&self, string: &str) -> syn::Ident;\n    fn with_span(self, span: Span) -> syn::Ident;\n    fn rocketized(&self) -> syn::Ident;\n    fn uniqueify_with<F: FnMut(&mut dyn Hasher)>(&self, f: F) -> syn::Ident;\n}\n\npub trait ReturnTypeExt {\n    fn ty(&self) -> Option<&syn::Type>;\n}\n\npub trait FnArgExt {\n    fn typed(&self) -> Option<(&syn::Ident, &syn::Type)>;\n    fn wild(&self) -> Option<&syn::PatWild>;\n}\n\npub trait TypeExt {\n    fn unfold_with_ty_macros(&self, names: &[&str], mapper: MacTyMapFn) -> Vec<Child<'_>>;\n    fn is_concrete(&self, generic_ident: &[&Ident]) -> bool;\n}\n\npub trait GenericsExt {\n    fn type_idents(&self) -> Vec<&Ident>;\n}\n\n#[derive(Debug)]\npub struct Child<'a> {\n    pub parent: Option<Cow<'a, syn::Type>>,\n    pub ty: Cow<'a, syn::Type>,\n}\n\nimpl Deref for Child<'_> {\n    type Target = syn::Type;\n\n    fn deref(&self) -> &Self::Target {\n        &self.ty\n    }\n}\n\nimpl IntoOwned for Child<'_> {\n    type Owned = Child<'static>;\n\n    fn into_owned(self) -> Self::Owned {\n        Child {\n            parent: self.parent.into_owned(),\n            ty: Cow::Owned(self.ty.into_owned()),\n        }\n    }\n}\n\ntype MacTyMapFn = fn(&TokenStream) -> Option<syn::Type>;\n\nimpl IdentExt for syn::Ident {\n    fn prepend(&self, string: &str) -> syn::Ident {\n        syn::Ident::new(&format!(\"{}{}\", string, self.unraw()), self.span())\n    }\n\n    fn append(&self, string: &str) -> syn::Ident {\n        syn::Ident::new(&format!(\"{}{}\", self, string), self.span())\n    }\n\n    fn with_span(mut self, span: Span) -> syn::Ident {\n        self.set_span(span);\n        self\n    }\n\n    fn rocketized(&self) -> syn::Ident {\n        self.prepend(crate::ROCKET_IDENT_PREFIX)\n    }\n\n    /// Create a unique version of the ident `self` based on the hash of `self`,\n    /// its span, the current call site, and any additional information provided\n    /// by the closure `f`.\n    ///\n    /// Span::source_file() / line / col are not stable, but the byte span and\n    /// some kind of scope identifier do appear in the `Debug` representation\n    /// for `Span`. And they seem to be consistent across compilations: \"#57\n    /// bytes(106..117)\" at the time of writing. So we use that.\n    fn uniqueify_with<F: FnMut(&mut dyn Hasher)>(&self, mut f: F) -> syn::Ident {\n        use std::collections::hash_map::DefaultHasher;\n\n        let mut hasher = DefaultHasher::new();\n        self.hash(&mut hasher);\n        format!(\"{:?}\", self.span()).hash(&mut hasher);\n        format!(\"{:?}\", Span::call_site()).hash(&mut hasher);\n        f(&mut hasher);\n\n        self.append(&format!(\"_{}\", hasher.finish()))\n    }\n}\n\nimpl ReturnTypeExt for syn::ReturnType {\n    fn ty(&self) -> Option<&syn::Type> {\n        match self {\n            syn::ReturnType::Default => None,\n            syn::ReturnType::Type(_, ty) => Some(ty),\n        }\n    }\n}\n\nimpl FnArgExt for syn::FnArg {\n    fn typed(&self) -> Option<(&Ident, &syn::Type)> {\n        match self {\n            syn::FnArg::Typed(arg) => match *arg.pat {\n                syn::Pat::Ident(ref pat) => Some((&pat.ident, &arg.ty)),\n                _ => None\n            }\n            _ => None,\n        }\n    }\n\n    fn wild(&self) -> Option<&syn::PatWild> {\n        match self {\n            syn::FnArg::Typed(arg) => match *arg.pat {\n                syn::Pat::Wild(ref pat) => Some(pat),\n                _ => None\n            }\n            _ => None,\n        }\n    }\n}\n\nfn macro_inner_ty(t: &syn::TypeMacro, names: &[&str], m: MacTyMapFn) -> Option<syn::Type> {\n    if !names.iter().any(|k| t.mac.path.last_ident().map_or(false, |i| i == k)) {\n        return None;\n    }\n\n    let mut ty = m(&t.mac.tokens)?;\n    ty.strip_lifetimes();\n    Some(ty)\n}\n\nimpl TypeExt for syn::Type {\n    fn unfold_with_ty_macros(&self, names: &[&str], mapper: MacTyMapFn) -> Vec<Child<'_>> {\n        struct Visitor<'a, 'm> {\n            parents: Vec<Cow<'a, syn::Type>>,\n            children: Vec<Child<'a>>,\n            names: &'m [&'m str],\n            mapper: MacTyMapFn,\n        }\n\n        impl<'m> Visitor<'_, 'm> {\n            fn new(names: &'m [&'m str], mapper: MacTyMapFn) -> Self {\n                Visitor { parents: vec![], children: vec![], names, mapper }\n            }\n        }\n\n        impl<'a> Visit<'a> for Visitor<'a, '_> {\n            fn visit_type(&mut self, ty: &'a syn::Type) {\n                let parent = self.parents.last().cloned();\n\n                if let syn::Type::Macro(t) = ty {\n                    if let Some(inner_ty) = macro_inner_ty(t, self.names, self.mapper) {\n                        let mut visitor = Visitor::new(self.names, self.mapper);\n                        if let Some(parent) = parent.clone().into_owned() {\n                            visitor.parents.push(parent);\n                        }\n\n                        visitor.visit_type(&inner_ty);\n                        let mut children = visitor.children.into_owned();\n                        self.children.append(&mut children);\n                        return;\n                    }\n                }\n\n                self.children.push(Child { parent, ty: Cow::Borrowed(ty) });\n                self.parents.push(Cow::Borrowed(ty));\n                syn::visit::visit_type(self, ty);\n                self.parents.pop();\n            }\n        }\n\n        let mut visitor = Visitor::new(names, mapper);\n        visitor.visit_type(self);\n        visitor.children\n    }\n\n    fn is_concrete(&self, generics: &[&Ident]) -> bool {\n        struct ConcreteVisitor<'i>(bool, &'i [&'i Ident]);\n\n        impl<'a> Visit<'a> for ConcreteVisitor<'_> {\n            fn visit_type(&mut self, ty: &'a syn::Type) {\n                use syn::Type::*;\n\n                match ty {\n                    Path(t) if self.1.iter().any(|i| t.path.is_ident(*i)) => {\n                        self.0 = false;\n                    }\n                    ImplTrait(_) | Infer(_) | Macro(_) => {\n                        self.0 = false;\n                    }\n                    BareFn(_) | Never(_) => {\n                        self.0 = true;\n                    },\n                    _ => syn::visit::visit_type(self, ty),\n                }\n            }\n        }\n\n        let mut visitor = ConcreteVisitor(true, generics);\n        visitor.visit_type(self);\n        visitor.0\n    }\n}\n\nimpl GenericsExt for syn::Generics {\n    fn type_idents(&self) -> Vec<&Ident> {\n        self.type_params().map(|p| &p.ident).collect()\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    #[test]\n    fn test_type_unfold_is_generic() {\n        use super::TypeExt;\n\n        let ty: syn::Type = syn::parse_quote!(A<B, C<impl Foo>, Box<dyn Foo>, Option<T>>);\n        let children = ty.unfold_with_ty_macros(&[], |_| None);\n        assert_eq!(children.len(), 8);\n\n        let gen_ident = format_ident!(\"T\");\n        let gen = &[&gen_ident];\n        assert_eq!(children.iter().filter(|c| c.ty.is_concrete(gen)).count(), 3);\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "da50980f0f816f1a8ad69cba33eb2b429819bdb5",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/actix-web/actix-files/tests/encoding.rs",
    "func": "use actix_files::{Files, NamedFile};\nuse actix_web::{\n    http::{\n        header::{self, HeaderValue},\n        StatusCode,\n    },\n    test::{self, TestRequest},\n    web, App,\n};\n\n#[actix_web::test]\nasync fn test_utf8_file_contents() {\n    // use default ISO-8859-1 encoding\n    let srv = test::init_service(App::new().service(Files::new(\"/\", \"./tests\"))).await;\n\n    let req = TestRequest::with_uri(\"/utf8.txt\").to_request();\n    let res = test::call_service(&srv, req).await;\n\n    assert_eq!(res.status(), StatusCode::OK);\n    assert_eq!(\n        res.headers().get(header::CONTENT_TYPE),\n        Some(&HeaderValue::from_static(\"text/plain; charset=utf-8\")),\n    );\n\n    // disable UTF-8 attribute\n    let srv =\n        test::init_service(App::new().service(Files::new(\"/\", \"./tests\").prefer_utf8(false))).await;\n\n    let req = TestRequest::with_uri(\"/utf8.txt\").to_request();\n    let res = test::call_service(&srv, req).await;\n\n    assert_eq!(res.status(), StatusCode::OK);\n    assert_eq!(\n        res.headers().get(header::CONTENT_TYPE),\n        Some(&HeaderValue::from_static(\"text/plain\")),\n    );\n}\n\n#[actix_web::test]\nasync fn partial_range_response_encoding() {\n    let srv = test::init_service(App::new().default_service(web::to(|| async {\n        NamedFile::open_async(\"./tests/test.binary\").await.unwrap()\n    })))\n    .await;\n\n    // range request without accept-encoding returns no content-encoding header\n    let req = TestRequest::with_uri(\"/\")\n        .append_header((header::RANGE, \"bytes=10-20\"))\n        .to_request();\n    let res = test::call_service(&srv, req).await;\n    assert_eq!(res.status(), StatusCode::PARTIAL_CONTENT);\n    assert!(!res.headers().contains_key(header::CONTENT_ENCODING));\n\n    // range request with accept-encoding returns a content-encoding header\n    let req = TestRequest::with_uri(\"/\")\n        .append_header((header::RANGE, \"bytes=10-20\"))\n        .append_header((header::ACCEPT_ENCODING, \"identity\"))\n        .to_request();\n    let res = test::call_service(&srv, req).await;\n    assert_eq!(res.status(), StatusCode::PARTIAL_CONTENT);\n    assert_eq!(\n        res.headers().get(header::CONTENT_ENCODING).unwrap(),\n        \"identity\"\n    );\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "712e1b32838042a07b89001848b18ab305c6fe81",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/actix-web/actix-http/src/body/sized_stream.rs",
    "func": "use std::{\n    error::Error as StdError,\n    pin::Pin,\n    task::{Context, Poll},\n};\n\nuse bytes::Bytes;\nuse futures_core::{ready, Stream};\nuse pin_project_lite::pin_project;\n\nuse super::{BodySize, MessageBody};\n\npin_project! {\n    /// Known sized streaming response wrapper.\n    ///\n    /// This body implementation should be used if total size of stream is known. Data is sent as-is\n    /// without using chunked transfer encoding.\n    pub struct SizedStream<S> {\n        size: u64,\n        #[pin]\n        stream: S,\n    }\n}\n\nimpl<S, E> SizedStream<S>\nwhere\n    S: Stream<Item = Result<Bytes, E>>,\n    E: Into<Box<dyn StdError>> + 'static,\n{\n    #[inline]\n    pub fn new(size: u64, stream: S) -> Self {\n        SizedStream { size, stream }\n    }\n}\n\n// TODO: from_infallible method\n\nimpl<S, E> MessageBody for SizedStream<S>\nwhere\n    S: Stream<Item = Result<Bytes, E>>,\n    E: Into<Box<dyn StdError>> + 'static,\n{\n    type Error = E;\n\n    #[inline]\n    fn size(&self) -> BodySize {\n        BodySize::Sized(self.size)\n    }\n\n    /// Attempts to pull out the next value of the underlying [`Stream`].\n    ///\n    /// Empty values are skipped to prevent [`SizedStream`]'s transmission being\n    /// ended on a zero-length chunk, but rather proceed until the underlying\n    /// [`Stream`] ends.\n    fn poll_next(\n        mut self: Pin<&mut Self>,\n        cx: &mut Context<'_>,\n    ) -> Poll<Option<Result<Bytes, Self::Error>>> {\n        loop {\n            let stream = self.as_mut().project().stream;\n\n            let chunk = match ready!(stream.poll_next(cx)) {\n                Some(Ok(ref bytes)) if bytes.is_empty() => continue,\n                val => val,\n            };\n\n            return Poll::Ready(chunk);\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use std::convert::Infallible;\n\n    use actix_rt::pin;\n    use actix_utils::future::poll_fn;\n    use futures_util::stream;\n    use static_assertions::{assert_impl_all, assert_not_impl_any};\n\n    use super::*;\n    use crate::body::to_bytes;\n\n    assert_impl_all!(SizedStream<stream::Empty<Result<Bytes, crate::Error>>>: MessageBody);\n    assert_impl_all!(SizedStream<stream::Empty<Result<Bytes, &'static str>>>: MessageBody);\n    assert_impl_all!(SizedStream<stream::Repeat<Result<Bytes, &'static str>>>: MessageBody);\n    assert_impl_all!(SizedStream<stream::Empty<Result<Bytes, Infallible>>>: MessageBody);\n    assert_impl_all!(SizedStream<stream::Repeat<Result<Bytes, Infallible>>>: MessageBody);\n\n    assert_not_impl_any!(SizedStream<stream::Empty<Bytes>>: MessageBody);\n    assert_not_impl_any!(SizedStream<stream::Repeat<Bytes>>: MessageBody);\n    // crate::Error is not Clone\n    assert_not_impl_any!(SizedStream<stream::Repeat<Result<Bytes, crate::Error>>>: MessageBody);\n\n    #[actix_rt::test]\n    async fn skips_empty_chunks() {\n        let body = SizedStream::new(\n            2,\n            stream::iter(\n                [\"1\", \"\", \"2\"]\n                    .iter()\n                    .map(|&v| Ok::<_, Infallible>(Bytes::from(v))),\n            ),\n        );\n\n        pin!(body);\n\n        assert_eq!(\n            poll_fn(|cx| body.as_mut().poll_next(cx))\n                .await\n                .unwrap()\n                .ok(),\n            Some(Bytes::from(\"1\")),\n        );\n\n        assert_eq!(\n            poll_fn(|cx| body.as_mut().poll_next(cx))\n                .await\n                .unwrap()\n                .ok(),\n            Some(Bytes::from(\"2\")),\n        );\n    }\n\n    #[actix_rt::test]\n    async fn read_to_bytes() {\n        let body = SizedStream::new(\n            2,\n            stream::iter(\n                [\"1\", \"\", \"2\"]\n                    .iter()\n                    .map(|&v| Ok::<_, Infallible>(Bytes::from(v))),\n            ),\n        );\n\n        assert_eq!(to_bytes(body).await.ok(), Some(Bytes::from(\"12\")));\n    }\n\n    #[actix_rt::test]\n    async fn stream_string_error() {\n        // `&'static str` does not impl `Error`\n        // but it does impl `Into<Box<dyn Error>>`\n\n        let body = SizedStream::new(0, stream::once(async { Err(\"stringy error\") }));\n        assert_eq!(to_bytes(body).await, Ok(Bytes::new()));\n\n        let body = SizedStream::new(1, stream::once(async { Err(\"stringy error\") }));\n        assert!(matches!(to_bytes(body).await, Err(\"stringy error\")));\n    }\n\n    #[actix_rt::test]\n    async fn stream_boxed_error() {\n        // `Box<dyn Error>` does not impl `Error`\n        // but it does impl `Into<Box<dyn Error>>`\n\n        let body = SizedStream::new(\n            0,\n            stream::once(async { Err(Box::<dyn StdError>::from(\"stringy error\")) }),\n        );\n        assert_eq!(to_bytes(body).await.unwrap(), Bytes::new());\n\n        let body = SizedStream::new(\n            1,\n            stream::once(async { Err(Box::<dyn StdError>::from(\"stringy error\")) }),\n        );\n        assert_eq!(\n            to_bytes(body).await.unwrap_err().to_string(),\n            \"stringy error\"\n        );\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "dbf694121820d58383c493eb604da5bb0649037c",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/actix-web/actix-http/src/body/body_stream.rs",
    "func": "use std::{\n    error::Error as StdError,\n    pin::Pin,\n    task::{Context, Poll},\n};\n\nuse bytes::Bytes;\nuse futures_core::{ready, Stream};\nuse pin_project_lite::pin_project;\n\nuse super::{BodySize, MessageBody};\n\npin_project! {\n    /// Streaming response wrapper.\n    ///\n    /// Response does not contain `Content-Length` header and appropriate transfer encoding is used.\n    pub struct BodyStream<S> {\n        #[pin]\n        stream: S,\n    }\n}\n\n// TODO: from_infallible method\n\nimpl<S, E> BodyStream<S>\nwhere\n    S: Stream<Item = Result<Bytes, E>>,\n    E: Into<Box<dyn StdError>> + 'static,\n{\n    #[inline]\n    pub fn new(stream: S) -> Self {\n        BodyStream { stream }\n    }\n}\n\nimpl<S, E> MessageBody for BodyStream<S>\nwhere\n    S: Stream<Item = Result<Bytes, E>>,\n    E: Into<Box<dyn StdError>> + 'static,\n{\n    type Error = E;\n\n    #[inline]\n    fn size(&self) -> BodySize {\n        BodySize::Stream\n    }\n\n    /// Attempts to pull out the next value of the underlying [`Stream`].\n    ///\n    /// Empty values are skipped to prevent [`BodyStream`]'s transmission being ended on a\n    /// zero-length chunk, but rather proceed until the underlying [`Stream`] ends.\n    fn poll_next(\n        mut self: Pin<&mut Self>,\n        cx: &mut Context<'_>,\n    ) -> Poll<Option<Result<Bytes, Self::Error>>> {\n        loop {\n            let stream = self.as_mut().project().stream;\n\n            let chunk = match ready!(stream.poll_next(cx)) {\n                Some(Ok(ref bytes)) if bytes.is_empty() => continue,\n                opt => opt,\n            };\n\n            return Poll::Ready(chunk);\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use std::{convert::Infallible, time::Duration};\n\n    use actix_rt::{\n        pin,\n        time::{sleep, Sleep},\n    };\n    use actix_utils::future::poll_fn;\n    use derive_more::derive::{Display, Error};\n    use futures_core::ready;\n    use futures_util::{stream, FutureExt as _};\n    use pin_project_lite::pin_project;\n    use static_assertions::{assert_impl_all, assert_not_impl_any};\n\n    use super::*;\n    use crate::body::to_bytes;\n\n    assert_impl_all!(BodyStream<stream::Empty<Result<Bytes, crate::Error>>>: MessageBody);\n    assert_impl_all!(BodyStream<stream::Empty<Result<Bytes, &'static str>>>: MessageBody);\n    assert_impl_all!(BodyStream<stream::Repeat<Result<Bytes, &'static str>>>: MessageBody);\n    assert_impl_all!(BodyStream<stream::Empty<Result<Bytes, Infallible>>>: MessageBody);\n    assert_impl_all!(BodyStream<stream::Repeat<Result<Bytes, Infallible>>>: MessageBody);\n\n    assert_not_impl_any!(BodyStream<stream::Empty<Bytes>>: MessageBody);\n    assert_not_impl_any!(BodyStream<stream::Repeat<Bytes>>: MessageBody);\n    // crate::Error is not Clone\n    assert_not_impl_any!(BodyStream<stream::Repeat<Result<Bytes, crate::Error>>>: MessageBody);\n\n    #[actix_rt::test]\n    async fn skips_empty_chunks() {\n        let body = BodyStream::new(stream::iter(\n            [\"1\", \"\", \"2\"]\n                .iter()\n                .map(|&v| Ok::<_, Infallible>(Bytes::from(v))),\n        ));\n        pin!(body);\n\n        assert_eq!(\n            poll_fn(|cx| body.as_mut().poll_next(cx))\n                .await\n                .unwrap()\n                .ok(),\n            Some(Bytes::from(\"1\")),\n        );\n        assert_eq!(\n            poll_fn(|cx| body.as_mut().poll_next(cx))\n                .await\n                .unwrap()\n                .ok(),\n            Some(Bytes::from(\"2\")),\n        );\n    }\n\n    #[actix_rt::test]\n    async fn read_to_bytes() {\n        let body = BodyStream::new(stream::iter(\n            [\"1\", \"\", \"2\"]\n                .iter()\n                .map(|&v| Ok::<_, Infallible>(Bytes::from(v))),\n        ));\n\n        assert_eq!(to_bytes(body).await.ok(), Some(Bytes::from(\"12\")));\n    }\n    #[derive(Debug, Display, Error)]\n    #[display(\"stream error\")]\n    struct StreamErr;\n\n    #[actix_rt::test]\n    async fn stream_immediate_error() {\n        let body = BodyStream::new(stream::once(async { Err(StreamErr) }));\n        assert!(matches!(to_bytes(body).await, Err(StreamErr)));\n    }\n\n    #[actix_rt::test]\n    async fn stream_string_error() {\n        // `&'static str` does not impl `Error`\n        // but it does impl `Into<Box<dyn Error>>`\n\n        let body = BodyStream::new(stream::once(async { Err(\"stringy error\") }));\n        assert!(matches!(to_bytes(body).await, Err(\"stringy error\")));\n    }\n\n    #[actix_rt::test]\n    async fn stream_boxed_error() {\n        // `Box<dyn Error>` does not impl `Error`\n        // but it does impl `Into<Box<dyn Error>>`\n\n        let body = BodyStream::new(stream::once(async {\n            Err(Box::<dyn StdError>::from(\"stringy error\"))\n        }));\n\n        assert_eq!(\n            to_bytes(body).await.unwrap_err().to_string(),\n            \"stringy error\"\n        );\n    }\n\n    #[actix_rt::test]\n    async fn stream_delayed_error() {\n        let body = BodyStream::new(stream::iter(vec![Ok(Bytes::from(\"1\")), Err(StreamErr)]));\n        assert!(matches!(to_bytes(body).await, Err(StreamErr)));\n\n        pin_project! {\n            #[derive(Debug)]\n            #[project = TimeDelayStreamProj]\n            enum TimeDelayStream {\n                Start,\n                Sleep { delay: Pin<Box<Sleep>> },\n                Done,\n            }\n        }\n\n        impl Stream for TimeDelayStream {\n            type Item = Result<Bytes, StreamErr>;\n\n            fn poll_next(\n                mut self: Pin<&mut Self>,\n                cx: &mut Context<'_>,\n            ) -> Poll<Option<Self::Item>> {\n                match self.as_mut().get_mut() {\n                    TimeDelayStream::Start => {\n                        let sleep = sleep(Duration::from_millis(1));\n                        self.as_mut().set(TimeDelayStream::Sleep {\n                            delay: Box::pin(sleep),\n                        });\n                        cx.waker().wake_by_ref();\n                        Poll::Pending\n                    }\n\n                    TimeDelayStream::Sleep { ref mut delay } => {\n                        ready!(delay.poll_unpin(cx));\n                        self.set(TimeDelayStream::Done);\n                        cx.waker().wake_by_ref();\n                        Poll::Pending\n                    }\n\n                    TimeDelayStream::Done => Poll::Ready(Some(Err(StreamErr))),\n                }\n            }\n        }\n\n        let body = BodyStream::new(TimeDelayStream::Start);\n        assert!(matches!(to_bytes(body).await, Err(StreamErr)));\n    }\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "59546a55c61b30f00a914c95b7628ea54629dbdf",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/actix-web/awc/tests/test_ws.rs",
    "func": "use std::io;\n\nuse actix_codec::Framed;\nuse actix_http::{body::BodySize, h1, ws, Error, HttpService, Request, Response};\nuse actix_http_test::test_server;\nuse actix_utils::future::ok;\nuse bytes::Bytes;\nuse futures_util::{SinkExt as _, StreamExt as _};\n\nasync fn ws_service(req: ws::Frame) -> Result<ws::Message, io::Error> {\n    match req {\n        ws::Frame::Ping(msg) => Ok(ws::Message::Pong(msg)),\n        ws::Frame::Text(text) => Ok(ws::Message::Text(\n            String::from_utf8(Vec::from(text.as_ref())).unwrap().into(),\n        )),\n        ws::Frame::Binary(bin) => Ok(ws::Message::Binary(bin)),\n        ws::Frame::Close(reason) => Ok(ws::Message::Close(reason)),\n        _ => Ok(ws::Message::Close(None)),\n    }\n}\n\n#[actix_rt::test]\nasync fn test_simple() {\n    let mut srv = test_server(|| {\n        HttpService::build()\n            .upgrade(|(req, mut framed): (Request, Framed<_, _>)| {\n                async move {\n                    let res = ws::handshake_response(req.head()).finish();\n                    // send handshake response\n                    framed\n                        .send(h1::Message::Item((res.drop_body(), BodySize::None)))\n                        .await?;\n\n                    // start WebSocket service\n                    let framed = framed.replace_codec(ws::Codec::new());\n                    ws::Dispatcher::with(framed, ws_service).await\n                }\n            })\n            .finish(|_| ok::<_, Error>(Response::not_found()))\n            .tcp()\n    })\n    .await;\n\n    // client service\n    let mut framed = srv.ws().await.unwrap();\n    framed.send(ws::Message::Text(\"text\".into())).await.unwrap();\n    let item = framed.next().await.unwrap().unwrap();\n    assert_eq!(item, ws::Frame::Text(Bytes::from_static(b\"text\")));\n\n    framed\n        .send(ws::Message::Binary(\"text\".into()))\n        .await\n        .unwrap();\n    let item = framed.next().await.unwrap().unwrap();\n    assert_eq!(item, ws::Frame::Binary(Bytes::from_static(b\"text\")));\n\n    framed.send(ws::Message::Ping(\"text\".into())).await.unwrap();\n    let item = framed.next().await.unwrap().unwrap();\n    assert_eq!(item, ws::Frame::Pong(\"text\".to_string().into()));\n\n    framed\n        .send(ws::Message::Close(Some(ws::CloseCode::Normal.into())))\n        .await\n        .unwrap();\n\n    let item = framed.next().await.unwrap().unwrap();\n    assert_eq!(item, ws::Frame::Close(Some(ws::CloseCode::Normal.into())));\n}\n"
  },
  {
    "project": "",
    "target": 0,
    "commit_id": "3b36c0dd0f6765b851328b56e105ff9a4d9877ee",
    "file_path": "/home/hieucien/Workspace/rust-parser/tests/projects/actix-web/actix-web/src/http/header/macros.rs",
    "func": "macro_rules! common_header_test_module {\n    ($id:ident, $tm:ident{$($tf:item)*}) => {\n        #[cfg(test)]\n        mod $tm {\n            #![allow(unused_imports)]\n\n            use ::core::str;\n\n            use ::actix_http::{Method, test};\n            use ::mime::*;\n\n            use $crate::http::header::{self, *};\n            use super::{$id as HeaderField, *};\n\n            $($tf)*\n        }\n    }\n}\n\n#[cfg(test)]\nmacro_rules! common_header_test {\n    ($id:ident, $raw:expr) => {\n        #[test]\n        fn $id() {\n            use ::actix_http::test;\n\n            let raw = $raw;\n            let headers = raw.iter().map(|x| x.to_vec()).collect::<Vec<_>>();\n\n            let mut req = test::TestRequest::default();\n\n            for item in headers {\n                req = req.append_header((HeaderField::name(), item)).take();\n            }\n\n            let req = req.finish();\n            let value = HeaderField::parse(&req);\n\n            let result = format!(\"{}\", value.unwrap());\n            let expected = ::std::string::String::from_utf8(raw[0].to_vec()).unwrap();\n\n            let result_cmp: Vec<String> = result\n                .to_ascii_lowercase()\n                .split(' ')\n                .map(|x| x.to_owned())\n                .collect();\n            let expected_cmp: Vec<String> = expected\n                .to_ascii_lowercase()\n                .split(' ')\n                .map(|x| x.to_owned())\n                .collect();\n\n            assert_eq!(result_cmp.concat(), expected_cmp.concat());\n        }\n    };\n\n    ($id:ident, $raw:expr, $exp:expr) => {\n        #[test]\n        fn $id() {\n            use actix_http::test;\n\n            let headers = $raw.iter().map(|x| x.to_vec()).collect::<Vec<_>>();\n            let mut req = test::TestRequest::default();\n\n            for item in headers {\n                req.append_header((HeaderField::name(), item));\n            }\n\n            let req = req.finish();\n            let val = HeaderField::parse(&req);\n\n            let exp: ::core::option::Option<HeaderField> = $exp;\n\n            // test parsing\n            assert_eq!(val.ok(), exp);\n\n            // test formatting\n            if let Some(exp) = exp {\n                let raw = &($raw)[..];\n                let mut iter = raw.iter().map(|b| str::from_utf8(&b[..]).unwrap());\n                let mut joined = String::new();\n                if let Some(s) = iter.next() {\n                    joined.push_str(s);\n                    for s in iter {\n                        joined.push_str(\", \");\n                        joined.push_str(s);\n                    }\n                }\n                assert_eq!(format!(\"{}\", exp), joined);\n            }\n        }\n    };\n}\n\nmacro_rules! common_header {\n    // TODO: these docs are wrong, there's no $n or $nn\n    // $attrs:meta: Attributes associated with the header item (usually docs)\n    // $id:ident: Identifier of the header\n    // $n:expr: Lowercase name of the header\n    // $nn:expr: Nice name of the header\n\n    // List header, zero or more items\n    ($(#[$attrs:meta])*($id:ident, $name:expr) => ($item:ty)*) => {\n        $(#[$attrs])*\n        #[derive(Debug, Clone, PartialEq, Eq, ::derive_more::Deref, ::derive_more::DerefMut)]\n        pub struct $id(pub Vec<$item>);\n\n        impl $crate::http::header::Header for $id {\n            #[inline]\n            fn name() -> $crate::http::header::HeaderName {\n                $name\n            }\n\n            #[inline]\n            fn parse<M: $crate::HttpMessage>(msg: &M) -> Result<Self, $crate::error::ParseError> {\n                let headers = msg.headers().get_all(Self::name());\n                $crate::http::header::from_comma_delimited(headers).map($id)\n            }\n        }\n\n        impl ::core::fmt::Display for $id {\n            #[inline]\n            fn fmt(&self, f: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result {\n                $crate::http::header::fmt_comma_delimited(f, &self.0[..])\n            }\n        }\n\n        impl $crate::http::header::TryIntoHeaderValue for $id {\n            type Error = $crate::http::header::InvalidHeaderValue;\n\n            #[inline]\n            fn try_into_value(self) -> Result<$crate::http::header::HeaderValue, Self::Error> {\n                use ::core::fmt::Write;\n                let mut writer = $crate::http::header::Writer::new();\n                let _ = write!(&mut writer, \"{}\", self);\n                $crate::http::header::HeaderValue::from_maybe_shared(writer.take())\n            }\n        }\n    };\n\n    // List header, one or more items\n    ($(#[$attrs:meta])*($id:ident, $name:expr) => ($item:ty)+) => {\n        $(#[$attrs])*\n        #[derive(Debug, Clone, PartialEq, Eq, ::derive_more::Deref, ::derive_more::DerefMut)]\n        pub struct $id(pub Vec<$item>);\n\n        impl $crate::http::header::Header for $id {\n            #[inline]\n            fn name() -> $crate::http::header::HeaderName {\n                $name\n            }\n\n            #[inline]\n            fn parse<M: $crate::HttpMessage>(msg: &M) -> Result<Self, $crate::error::ParseError>{\n                let headers = msg.headers().get_all(Self::name());\n\n                $crate::http::header::from_comma_delimited(headers)\n                    .and_then(|items| {\n                        if items.is_empty() {\n                            Err($crate::error::ParseError::Header)\n                        } else {\n                            Ok($id(items))\n                        }\n                    })\n            }\n        }\n\n        impl ::core::fmt::Display for $id {\n            #[inline]\n            fn fmt(&self, f: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result {\n                $crate::http::header::fmt_comma_delimited(f, &self.0[..])\n            }\n        }\n\n        impl $crate::http::header::TryIntoHeaderValue for $id {\n            type Error = $crate::http::header::InvalidHeaderValue;\n\n            #[inline]\n            fn try_into_value(self) -> Result<$crate::http::header::HeaderValue, Self::Error> {\n                use ::core::fmt::Write;\n                let mut writer = $crate::http::header::Writer::new();\n                let _ = write!(&mut writer, \"{}\", self);\n                $crate::http::header::HeaderValue::from_maybe_shared(writer.take())\n            }\n        }\n    };\n\n    // Single value header\n    ($(#[$attrs:meta])*($id:ident, $name:expr) => [$value:ty]) => {\n        $(#[$attrs])*\n        #[derive(Debug, Clone, PartialEq, Eq, ::derive_more::Deref, ::derive_more::DerefMut)]\n        pub struct $id(pub $value);\n\n        impl $crate::http::header::Header for $id {\n            #[inline]\n            fn name() -> $crate::http::header::HeaderName {\n                $name\n            }\n\n            #[inline]\n            fn parse<M: $crate::HttpMessage>(msg: &M) -> Result<Self, $crate::error::ParseError> {\n                let header = msg.headers().get(Self::name());\n                $crate::http::header::from_one_raw_str(header).map($id)\n            }\n        }\n\n        impl ::core::fmt::Display for $id {\n            #[inline]\n            fn fmt(&self, f: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result {\n                ::core::fmt::Display::fmt(&self.0, f)\n            }\n        }\n\n        impl $crate::http::header::TryIntoHeaderValue for $id {\n            type Error = $crate::http::header::InvalidHeaderValue;\n\n            #[inline]\n            fn try_into_value(self) -> Result<$crate::http::header::HeaderValue, Self::Error> {\n                self.0.try_into_value()\n            }\n        }\n    };\n\n    // List header, one or more items with \"*\" option\n    ($(#[$attrs:meta])*($id:ident, $name:expr) => {Any / ($item:ty)+}) => {\n        $(#[$attrs])*\n        #[derive(Clone, Debug, PartialEq, Eq)]\n        pub enum $id {\n            /// Any value is a match\n            Any,\n\n            /// Only the listed items are a match\n            Items(Vec<$item>),\n        }\n\n        impl $crate::http::header::Header for $id {\n            #[inline]\n            fn name() -> $crate::http::header::HeaderName {\n                $name\n            }\n\n            #[inline]\n            fn parse<M: $crate::HttpMessage>(msg: &M) -> Result<Self, $crate::error::ParseError> {\n                let is_any = msg\n                    .headers()\n                    .get(Self::name())\n                    .and_then(|hdr| hdr.to_str().ok())\n                    .map(|hdr| hdr.trim() == \"*\");\n\n                if let Some(true) = is_any {\n                    Ok($id::Any)\n                } else {\n                    let headers = msg.headers().get_all(Self::name());\n                    Ok($id::Items($crate::http::header::from_comma_delimited(headers)?))\n                }\n            }\n        }\n\n        impl ::core::fmt::Display for $id {\n            #[inline]\n            fn fmt(&self, f: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result {\n                match *self {\n                    $id::Any => f.write_str(\"*\"),\n                    $id::Items(ref fields) =>\n                        $crate::http::header::fmt_comma_delimited(f, &fields[..])\n                }\n            }\n        }\n\n        impl $crate::http::header::TryIntoHeaderValue for $id {\n            type Error = $crate::http::header::InvalidHeaderValue;\n\n            #[inline]\n            fn try_into_value(self) -> Result<$crate::http::header::HeaderValue, Self::Error> {\n                use ::core::fmt::Write;\n                let mut writer = $crate::http::header::Writer::new();\n                let _ = write!(&mut writer, \"{}\", self);\n                $crate::http::header::HeaderValue::from_maybe_shared(writer.take())\n            }\n        }\n    };\n\n    // optional test module\n    ($(#[$attrs:meta])*($id:ident, $name:expr) => ($item:ty)* $tm:ident{$($tf:item)*}) => {\n        crate::http::header::common_header! {\n            $(#[$attrs])*\n            ($id, $name) => ($item)*\n        }\n\n        crate::http::header::common_header_test_module! { $id, $tm { $($tf)* }}\n    };\n    ($(#[$attrs:meta])*($id:ident, $n:expr) => ($item:ty)+ $tm:ident{$($tf:item)*}) => {\n        crate::http::header::common_header! {\n            $(#[$attrs])*\n            ($id, $n) => ($item)+\n        }\n\n        crate::http::header::common_header_test_module! { $id, $tm { $($tf)* }}\n    };\n    ($(#[$attrs:meta])*($id:ident, $name:expr) => [$item:ty] $tm:ident{$($tf:item)*}) => {\n        crate::http::header::common_header! {\n            $(#[$attrs])* ($id, $name) => [$item]\n        }\n\n        crate::http::header::common_header_test_module! { $id, $tm { $($tf)* }}\n    };\n    ($(#[$attrs:meta])*($id:ident, $name:expr) => {Any / ($item:ty)+} $tm:ident{$($tf:item)*}) => {\n        crate::http::header::common_header! {\n            $(#[$attrs])*\n            ($id, $name) => {Any / ($item)+}\n        }\n\n        crate::http::header::common_header_test_module! { $id, $tm { $($tf)* }}\n    };\n}\n\npub(crate) use common_header;\n#[cfg(test)]\npub(crate) use common_header_test;\npub(crate) use common_header_test_module;\n"
  }
]